

Mojo video collection
1. [# Mojo Programming Language Modules and Packages || Mojo Tutorial](https://www.youtube.com/watch?v=1PQIHzls13s)
2.  [# SPICE Metric || Image Captioning || Deep Learning](https://www.youtube.com/watch?v=As441oo3yk8)
3.  [# Choosing Your Language: Python or Mojo?](https://www.youtube.com/watch?v=OJUorka-XLU)
4.  [# The Next-Gen AI Programming Language 35000x Faster Than Python](https://www.youtube.com/watch?v=8VPJCVeMQio)
5. [# Mojo Is FASTER Than Rust](https://www.youtube.com/watch?v=kmmqHV26Ukg)
6.  [# Mojo Langâ€¦ a fast futuristic Python alternative](https://www.youtube.com/watch?v=V4gGJ7XXlC0&t=4s)
7.  [# All you Need To Know About Mojo Programming Language](https://www.youtube.com/watch?v=RI2F6u9dnkU)
8. [# Modular Community Livestream - MojoðŸ”¥ SDK v0.7 edition!](https://www.youtube.com/watch?v=Ln8ZaJ0gaSA&t)
9. [# Mojo ðŸ”¥ Playground First Look: Walkthrough Part 1](https://www.youtube.com/watch?v=d9DcyGNUis8)
10. [# [TechBites] New language Mojo.ðŸ”¥ | Will Python be replaced?](https://www.youtube.com/watch?v=p0dCj1JL8AM)
11.  [# Say Goodbye to Python and Hello to Mojo](https://www.youtube.com/watch?v=s4ZUkwe0ZTI)
12. [# All-in-one C++, Rust, AND Python Successor? Mojo](https://www.youtube.com/watch?v=w14vohgjnKo&t)
13. [# The Current State of the Mojo Programming Language](https://www.youtube.com/watch?v=4f2JH_sK17o)
14.  [# Jeremy Howard demo for Mojo launch](https://www.youtube.com/watch?v=6GvB5lZJqcE)
15.  [# 2023 LLVM Dev Mtg - Mojo ðŸ”¥: A system programming language for heterogenous computing](https://www.youtube.com/watch?v=SEwTjZvy8vw)
16. [# Mojo - the BLAZINGLY FAST new AI Language? | Prime Reacts](https://www.youtube.com/watch?v=RZhTC33lStQ)
17. [# Mojo Programming Language: A Simple To-Do List](https://www.youtube.com/watch?v=WFjV528Iq3Q&list=PLSv2bgL9aQWSLwZjX-nll1UU_NcRKQCDr)
18. [# [UPDATE] Mojo Is Faster Than Rust - Mojo Explains More](https://www.youtube.com/watch?v=MDblUyz0PtQ)
19. 

-----
--99--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--98--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--97--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--96--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--95--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--94--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--93--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--92--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--91--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--90--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--89--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--88--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--87--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--86--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--85--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--84--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--83--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--82--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--81--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--80--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--79--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--78--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--77--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--76--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--75--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--74--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--73--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--72--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--71--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--70--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--69--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--68--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--67--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--66--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--65--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--64--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--63--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--62--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--61--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--60--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--59--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--58--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--57--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--56--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--55--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--54--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--53--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--52--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--51--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--50--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--49--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--48--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--47--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--46--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--45--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--44--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--43--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--42--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--41--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--40--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--39--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--38--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--37--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--36--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--35--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--34--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--33--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--32--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--31--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--30--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--29--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--28--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--27--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--26--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--25--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--24--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--23--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--22--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--21--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--20--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--19--

-----
Date:
Link:
Transcription:

paste here

----------

-----

--18--

-----
Date: 2024.02.16
Link:  [# [UPDATE] Mojo Is Faster Than Rust - Mojo Explains More](https://www.youtube.com/watch?v=MDblUyz0PtQ)

### Notes from the Discussion on Mojo vs. Rust

#### Advantages of Mojo:

- **Simplified Syntax for SIMD Operations:** Mojo is designed to make SIMD (Single Instruction, Multiple Data) optimizations more accessible and ergonomic compared to Rust, potentially offering significant performance improvements.
- **Early Object Destruction:** Mojo introduces eager destruction of objects, which could be particularly beneficial in AI for freeing GPU memory earlier. This contrasts with Rust, where objects are destructed at the end of scope, potentially delaying memory release.
- **Built on MLIR:** Mojo leverages MLIR (Multi-Level Intermediate Representation), offering potentially faster compile times and optimized code generation for both CPU and GPU compared to Rust's LLVM IR.
- **Pythonic Syntax with Performance Benefits:** Mojo aims to offer Python developers the ease of Python with the added performance benefits of a compiled language like Rust, without the steep learning curve.
- **Focus on AI Applications:** Mojo is being developed with a focus on AI, planning to include AI-specific libraries and optimizations that could make it particularly attractive for AI development. 

#### Drawbacks and Challenges:

- **Newness and Unproven in Production:** Mojo is relatively new and unproven in production environments compared to Rust, which might make developers hesitant to adopt it for critical projects.
- **Community and Ecosystem:** Rust boasts a large and active community with a wealth of libraries and tools. Mojo, being new, has yet to develop a comparable ecosystem, which is crucial for adoption and practical use.
- **Learning Curve for Rust Developers:** While Mojo is designed to be accessible for Python developers, those coming from Rust or other system programming languages might need to adjust to its design philosophy and syntax.

#### Tips and Advice:

- **Consider Mojo for AI Projects:** Developers working on AI and machine learning projects might find Mojo particularly appealing, especially if they are already familiar with Python.
- **Experiment with SIMD in Mojo:** The simplified syntax for SIMD operations in Mojo offers an opportunity to optimize performance with relatively low effort, making it worth exploring for computationally intensive tasks.
- **Keep an Eye on Mojo's Development:** Given its potential, developers should monitor Mojo's progress, community growth, and ecosystem development, especially those interested in AI and performance optimizations.

#### Summary:

The discussion highlights the potential of Mojo as a new programming language designed to offer the performance benefits of Rust with the ease of use similar to Python, particularly for AI development. With features like simplified SIMD operations, early object destruction, and the use of MLIR for optimized code generation, Mojo presents an intriguing option for developers. However, its newness, developing ecosystem, and the need for broader adoption remain challenges. Developers interested in the cutting edge of AI and programming language development should consider experimenting with Mojo while keeping an eye on its evolution

Comments:
### Interesting Observations and Smart Insights from the Comments

**1. Community Engagement and Humor:**

- The community's engagement with the discussion showcases a blend of humor, skepticism, and genuine curiosity about Mojo and its comparison with Rust. Comments like "Mojo programmers should clearly be called Jojos" and playful ideas for naming an IDE "Dojo" reflect a light-hearted take on the emerging language's ecosystem.

**2. Skepticism and Critical Analysis:**

- Several comments provide critical analysis of Mojo's performance claims, with some users decompiling binaries to investigate the legitimacy of benchmarks. These insights raise important questions about the transparency and accuracy of performance claims in programming language comparisons.

**3. Tail Call Optimization (TCO) Debates:**

- The discussion on TCO and its implementation in Rust versus Mojo sparked debates on the technical details and optimization capabilities of both languages. This indicates a keen interest in understanding the depth of language design decisions and their practical implications.

**4. Learning Curve and Accessibility:**

- Comments reflect concerns about the learning curve associated with Rust and whether Mojo presents a more accessible alternative for Python developers. This underscores the ongoing dialogue within the programming community about language complexity versus performance benefits.

**5. Community Nicknames and Identity:**

- Suggestions for Mojo community nicknames, such as "Mojicians" or "Mojitos," highlight a playful aspect of forming a new language community identity. These nicknames can contribute to building a unique culture around the language.

**6. Real-world Application and Job Market Impact:**

- Jokes about job listings requiring years of experience in a newly released language like Mojo touch on the real challenges and absurdities in the tech job market. This reflects broader industry trends where emerging technologies quickly become requisites for new positions.

**7. Language Evolution and Ecosystem Development:**

- Discussions around Mojo's potential to influence other languages and its own ecosystem development point to the broader dynamics of programming language evolution. The community seems to recognize the potential for cross-pollination of ideas and features among languages.

**8. Performance Optimization and SIMD:**

- Insights into SIMD (Single Instruction, Multiple Data) operations and Mojo's approach to simplifying their usage indicate a technical depth in the community's understanding of performance optimization.

**9. Proprietary Concerns:**

- Concerns about Mojo being proprietary and its implications for open-source development reflect the programming community's values around transparency, accessibility, and collaboration.

**10. Future Predictions and Speculations:**

- Speculations on Mojo's long-term impact, its place in AI and system programming, and comparisons with existing languages like C++, Rust, and Python showcase the community's forward-looking perspective and interest in how new tools fit into the broader technology landscape.

### Conclusion:

The discussion around Mojo vs. Rust reveals a vibrant community engaged in playful banter, deep technical analysis, and thoughtful speculation about the future of programming languages. The blend of humor, skepticism, and insightful observations underscores the complexity and dynamism of the programming world, highlighting the continuous dialogue between ease of use, performance, and the evolving needs of developers and industries.

### Analysis of Additional Comments on Mojo Programming Language

**Observations on Mojo's Characteristics and Community Reaction:**

1. **Lack of Garbage Collection (GC):** Multiple comments highlight that Mojo does not have a garbage collector, emphasizing its similarity to Rust's memory management model. This is a critical point of consideration for developers accustomed to languages with automatic memory management.
    
2. **Proprietary Concerns:** A significant portion of the community expresses concern over Mojo being proprietary. This skepticism towards closed-source languages suggests a preference for open-source alternatives that offer transparency and collaborative development opportunities.
    
3. **Recursion Optimization:** Some comments note Mojo's targeted optimization of recursion, a known challenging area for Rust. However, the practicality of writing for loops in a recursive manner is questioned, indicating that while Mojo may offer specific technical advantages, their real-world applicability could be limited.
    
4. **Comparison with Other Languages:** There's a recurring theme of comparing Mojo to existing languages, not only Rust but also Python, Go, and C++. Some comments suggest that Mojo's real competition is with Python, especially in the AI and data science domains, rather than Rust.
    
5. **Learning Curve and Accessibility:** The comments reflect a divided opinion on Mojo's learning curve and accessibility. While some users are excited about the simplicity and the potential for Mojo to make Python faster, others argue that the Rust-like memory management in Mojo could present a steep learning curve for Python developers.
    
6. **Community Nicknames and Engagement:** Suggestions for community nicknames like "Mojicians" or "Mojitos" indicate an interest in forming a distinct identity for Mojo users. However, the need for an account to download Mojo and its closed-source nature are criticized, which could hinder community growth and engagement.
    
7. **Performance Claims and Skepticism:** There's skepticism about Mojo's performance claims, especially when compared directly to Rust. Concerns about Mojo's documentation and examples not compiling, along with unfulfilled promises like GPU support, suggest that while Mojo aims high, it may still have a long way to go in delivering on its potential.
    
8. **Open Source and Proprietary Software Debate:** The debate between the benefits of open-source versus proprietary software is prominent. The preference for open-source languages in the programming community is clear, with many expressing reluctance to adopt Mojo due to its proprietary nature.
    
9. **Language Ecosystem and Library Support:** The success of a programming language is often tied to its ecosystem and library support. Comments hint at skepticism regarding Mojo's ability to match Python's extensive library ecosystem, particularly in specialized fields like AI and data science.
    
10. **License and Accessibility Issues:** The requirement to create an account to download Mojo and concerns about its licensing terms are viewed as barriers to adoption. Accessibility and ease of entry are crucial factors for a new programming language to gain traction.
    

### Conclusion:

While Mojo introduces interesting concepts, particularly in memory management and potential performance optimizations, its closed-source nature and proprietary concerns are significant barriers to widespread acceptance. The skepticism regarding its ecosystem, library support, and real-world application effectiveness highlights the challenges Mojo faces in establishing itself alongside established languages. For Mojo to succeed and improve in the competitive landscape of programming languages, addressing these concerns and fostering an open, inclusive community would be crucial steps forward.

Transcription:

all right all right let's get started on this thing okay so a few days ago we made a video uh on this blog post that I
saw by modular um and it's Mojo is 50% faster than rust right and I read it and
there are some like skeptical remarks and hey you're doing this and hey you're doing something else and hey you're not correct on this and they literally came
back and first off they quoted me I will say one thing um I was an individual I
wasn't a group of people okay I not an and second off I'm not sure if I would
call myself an expert okay I use rust regularly wouldn't call myself an expert
but I still agree with my state with my statement uh any who so followup to the
Articles they actually wrote a response to everything and they're saying that they're actually is it actually faster
this quote has been flying around everywhere for Mojo I think it's the best qu I honestly I fully agree with my
quote so for those that don't know what my quote was uh or didn't really understand when they saw it it's very
very simple if python can remain python you have to learn a little bit extra
like some extra apis a little bit of extra Syntax for some basic declaration and all that and you can have
effectively the benefits of performance of rust then everybody that's in AI that
is doing these fast small experiments throw away code and everything they're going to stick with python or in this
case Mojo they're not going to make the migration over to rust and I think that that's still absolutely true anyone that
thinks that somebody who's trying to do these really fast really gorilla experiments and throw away everything
they make why would they ever try to go and learn rust and spend this incredible
amount of time getting good at it just to do that one thing right it just doesn't make any sense it it it doesn't
it like it it doesn't feel like a good a good argument anyways so let's go into
this one this is their response because obviously they got called out saying hey you did all these things wrong so let's find out what they have to say Mojo is
built on the latest compiler technology in mlir an evolution on llvm which rust lowers to and so it can be faster it
depends largely on the skill of the programmer and how far they're willing to go with optimizations classic skill
classic skill issues isn't that all performance skill issues and uh tradeoffs because your boss wanted it
yesterday isn't that like most skill issues dude right now I'm dealing with the skill issue uh involving performance
which is literally just a massive performance black hole and simply that's just because things had to get done and
they had to get done quickly I mean that's honestly that's that's such a huge part of the professional world is just people ain't got time to make the
greatest thing ever and so if it's if it's a pretty fast easy path to make something good enough a lot of people
are happy Mojo's goal as a language is to meet python developers where they are and allow them to learn some new tricks
to optimize their code to the performant limits of any hardware see this is what I mean I don't see how you're ever going
to be able to win this argument if you could just immediately get benefits why would you change anything
right dude I would program if Mojo ends up being as good as they as they are if modular has perfectly sold us a like
assuming everything they say is great hell I'm G to probably start looking into using Mojo all the time you know
what I mean over the weekend Netflix engineer and rust Advocate hell yeah hell yeah that's me let's go um released
a re reaction video to the community guest blog we published outperforming rust DNA sequencing parsing parsing
benchmarks by 50% with Mojo uh by the way I do I mean I I do advocate for
using rust I think it makes like honestly if you write an LSP and you don't use rust I think you are a bad person or you wrote go please which is
an incredible is the best LSP ever created if you write an LSP in in in JavaScript you're you're being a bad
person stop it stop it stop it um
they're blaming me the blog post stirred up some Contra controversies uh rust uh
is being positioned as the potential successor to the dominant language in AI which is currently Python and C++ this
is the briag take on Mojo okay yes if Mojo is I did not I didn't imply
legitimate okay I think I said I thought I said if Mojo is like giving us okay whatever if Mojo is legitimate I think
Mojo will win just hands down the reason Mojo will win if you by way this is live streaming I don't I mince my words maybe
a little bit while live streaming is you don't change the Paradigm of any acclimated or professional individual you just have to learn a bit more and
you get amazing performance if Mojo compiles fast it looks like a language you're already familiar with and it's really close to being at the same speed
I just don't see how you're going to make that sell for rust pre-read pre-stated and then even
Luca yeah Luca agreed with me by the way great book I already he said thank you because I I promote his book on the
regular but I do mean it here hold on one second literally what probably the best one of
the best rust books if you're Vaguely Familiar with rust and you kind of already understand how the borrow Checker Works buy the book it's
fantastic I won't even give I I literally will not give anybody a Amazon
affiliate code just go buy it I'm not going to make money off that one because it's too good of a book all right
catching on the prime stream from yesterday Mojo versus rust he's right if Mojo delivers he did he did he did make
some specifications that they're not saying here if Mojo delivers we'll never see rust in user space for people working on AI the value proposition is
just too good if you're an ml engineer or data scientist who knows python well it is a great yeah it is the value
proposition is just simply too good but by user space I mean data scientist data analysis ml researcher Tinkers all folks
who need to validate an idea and or build a prototype that's good enough to be shipped they're uh they are the Lion
Share of the AI World a bit like compiler Engineers versus web devs depending on how much Mojo delivers rust
might struggle to settle in AI infrastructure space too that's the big one is if if Mojo good enough to also
settle into AI infrastructure that's going to be sweet by the way you could uh you
could you could by the way you can just link you can just link I I I have zero rules in my chat okay I just ban people
for being okay you can link I I assume you're I assume most people aren't and they'll just do the
right thing and then there's a couple and you just you make a game out of banning them right it's fun all
right so Mojo our goal our aim is to be intuitive to learn for python developers as Muhammad showed he was able to learn
Mojo and optimize an algorithm using simd in a matter of weeks as a side project while this article is focused on
performance differences the points that primagen and Luca uh palmary made are important to us we we are heavily
focused on AI where a three language problem exists ooh the three language problem a Minaj a language uh we are
heavily focused on AI where there is a three body problem uh and where CPU plus GPU programmability is so important
across Hardware but let's not forget the real goal of Mojo is is lifting the world's most popular AI language in
Python and empowering developers everywhere with Incredible performance Hardware uh portability and programmability is Mojo faster than x
language uh raised an important question rust is known for low-level performance how can Mojo provide better performance
out of the box than rust or C++ I I assume it can't I assume by the very definition that it should not be able to
but it will be able to or it will be able to compete on par with specific things right so a very simple example
would be a for Loop a for Loop doing some amount of work they should be able in some sense one would assume you'd be
able to do that but at the end of the day I assume this is still there's still garbage collection going on right it's
just like go will never be as fast as rust but go can be really fast if that makes sense we're going to let them cook
don't worry we're going to let them cook I'm just explaining I'm explaining a very simple principle that people seem to not realize about programming
languages which is very very simple there's like a pyramid of languages there is like your uh there's like your
P pretty much your like interpreted languages right and so you got things like Lua Lua
if you don't use Lua jit right um then you got yourselves like the slow interpreted languages like Python and
Ruby then you got yourself the Google has paid $10 billion to make it fast language JavaScript right then you got
yourself compiled but still garbage collected languages such as Java and go right these are these are faster
languages they tend to be a lot faster Java kind of Falls Java's somewhere between these two cuz Java has the
ability to kind of compile but it also bite codes so it's also interpreted but then it's also you know Java's in a
weird spot we're we're going to put Java in between these two but go is like a purely compiled language but it
has it it has no jitting right but it does c I think falls under the same
platform as Java right so C right it it is both compiled and
there's some sort of interpretation thing going on there I don't I don't know the exact lines in which things
happen uh but I know you have to warm up end points and like that uh but go on the other hand there's no warming up
it's just fast but it's garbage collected so it's not perfectly fast then you got things like C uh rust and
C++ this makes total sense that these guys are always on the tip just the tip
because they are compiled and you manage the memory so assuming you don't have
skill issues you should be going fast does that make sense oh assembly it
falls under the C is just fancy assembly okay sure you're right assembly Fortran
people don't cobal cobal falls under this we're not going to talk about those ones okay because those aren't
interesting very few people do assembly uh okay and the people that are doing
assembly and should be doing Zig is okay shut oh my goodness yes we get it the
compiled managed memory are are the ones in which fall into the most elite category of speed okay because they have
the they have the most possibility of being fast it doesn't mean they are the fastest in all situations they just have
the possibility of being the fastest but you suffer from skill issues way more frequently the the line of potential
skill issues go up really really fast and so like there's a graph that exists right so when it comes to uh Ruby uh
this is like uh this would be like speed and this would be uh skill issue
right so this is speed and skill issues Ruby goes like this cuz there's no skill issues it's just slow right that's just
how it goes JavaScript you know the speed and skill issues there's there's definitely like a line here you can make
JavaScript fast but most people just suffer too heavily from from skill issues actually
the line would be like this right it's really hard to get right whereas like go
you can have skill issues and you can be pretty fast rust though tends to be like
this as well to make rust fast you have to be pretty good same with C++ same
with those other languages because you have to like not suffer from skill issues to make it good so I always find
that go just has like just the right amount still can Goof yourself up but you can make it pretty fast so I'm
hoping that Mojo Falls right here honestly this is what I hope I hope Mojo Falls On The Go line if Mojo Falls On
The Go line then it's out of this world right it's a great great great thing a
common question when you uh users first during the Discord is how much faster is Mojo than x language there's a lot of
consideration surrounding any Benchmark implementation you can't choose any one Benchmark to say x language is faster than why language this is by the way
very good on them to do this people constantly say these dumb things about languages being faster and then what they what they do is they show you like
an HTTP request that does empty echoing of like hello world and that is just totally not totally not good totally not
good um a better question is how much overhead does mojo introduce compared compared to X better a major goal for
Mojo is to allow you to push Hardware to the limits of physics while remaining ergonomic and familiar to python
developers compared to the dynamic languages language like python compiled languages allow you to remove unnecessary CPU instructions such as
allocating objects to the Heap reference counting in periodic garbage collection we covered that Mojo takes
Lessons Learned uh and best practices from C+ plus rust and Swift to provide direct access to machine without these
kind of overheads okay Mojo and rust both allow to optimize at a lower level but in Rust for example you can still
wrap everything in an arc mutex box okay please I mean this is how many people
write a bunch of rust and make it really awesome and do all these great things only to end with an arc mutex hashmap
come on come on come on don't lie to me you know you know you little sons of
end with an arc mutex uh hash map okay don't even don't even lie
explain to me like I'm five what an Arc and Arc and a mutex ISS yes so Arc stands for automatic ref or it stands
for reference counting at the atomic level meaning that you can pass it between threads because what they count
H or effectively what is cloned is is is pretty much a pointer to where your data
is and the counter for how many people are holding on to that data is atomic so
that means if two threads try to increment at the same time it will appropriate appropriately increment it
by two whereas if you had just an RC and you tried to do that you could very well have two people incrementing uh two at
the exact same time thus it's three even though two people have ownership so it's a reference counter so it'll count how many people hold on to an object a mutex
is like a single Lane Road only one car can pass at a time that's the easiest
way to think about a mutex and so that means only one person can hold on to the
mutable access to an object so if you had a hashmap and you wanted to uh mutate it you'd want to use a
mutex a semaphor is just a mutex that has a wide road if that makes sense it
can allow four people to to do something at a time or eight or 12 or however many
you want can now explain to me like I'm four because I'm too dumb to be five no uh to avoid fights with the borrow
Checker at the cost of performance if you're writing an application code this might not have any significant impact but if you're writing a library or
performance sensitive code the overhead can add up quickly it's up to the pro programmer how much they care about reducing over head and optimizing
performance fair fair take this is a very fair take both uh let's see both of
the languages can use llvm for optimized Coden and both languages can let's see allow for the use of inline assembly but
of course no one can afford to do that what is this tweet agree you can
match perf with inline assembly argument is funny it implies that the language doesn't matter at all but obviously the
world can't afford to rewrite all software for chip SL Vari even more true with shift uh shift to accelerators
which Mojo built for yes this makes sense so someone
obviously made the argument uh that you can do you can be
faster if you use handroll assembly and it's just like yeah you can do that but that's dumb and it's true it's true it
is dumb like there should be only like I know TLS does it with their crypto stuff there's like some handrolled uh crypto
algorithms out there and that makes sense but most people ain't doing that so they both have the same potential on
traditional Hardware right well sure but the real question is how does the performance of idiomatic normal Mojo
code compared to normal rust code written by someone who isn't a world expert writing in assembly for every
chip and doesn't know the details of how the compiler works this is a much better question by the way what does the what
does the six Monon writer of code look like and when I say idiomatic I don't
you know idiomatic is funny because unless if you have a very strict way in which all code is formatted and expected
to be written there is no really such thing as idiomatic there's like localized ID idiomatic idiomatic right
so if you look at uh jav if you look at JavaScript there you could see these idiomatic lines I can look at a library
and tell you which five-year period something was written in and so if I look at certain things
it's very e like early JavaScript it was all about using that extends and classes and prototypical inheritance and you can
be like oh this was idiomatic Java script at one point for some set of people
anyways this is a really great thing so what would the six-month person look like reduced meem copy with borrow by
default when a new user is learning rust one of the first pitfalls they run into is that function arguments default to
taking an object by moving it this means that you pass something into function and try to reuse it you get a compiler
error correct but it's also beautiful I love this so uh I actually really this
is what I I actually do enjoy this level of the borrow Checker I find it to be very very useful in how I think about things the line with debug throws a
compile error because you've moved Foo into bar function uh this th because debug uses
Foo so that's why this thing breaks whereas bar uh bar
also effectively takes ownership of Fu because he didn't pass it by reference uh for those that don't know rust rust
is a little bit wild okay JavaScript is a bad example there is no idiomatic uh only different levels of ID idiotic yes
the M Copy can be optimized Away by llvm in some cases but this doesn't always occur and is hard to predict unless you
know how the rust llvm compiler Works Mojo simplifies this concept for a standard use case right main Foo string
uh bar print Foo Mojo uh arguments are Borrowed by default not only is this
much more gentle when learning Mojo compared to rust it's also much uh more efficient due to no implicit meem copies
if you want to get closer to rust Behavior you can change the argument to uh to owned
I didn't even know that this was like a thing owned what is owned I even I I I'm not I'm clearly not
an expert I I've never used this as a keyword I never I've never once used this as a keyword have you guys used
that as a keyword I like I have never seen it I've never seen it in any arguments oh this is Mojo oh no
wonder I was just like dude I've never seen this what is this rust no wait this is not wait this is this is Mojo
dude I can't tell the difference you can't use f you both can't use fed they're both using fed okay this is Mojo
this is Mojo okay nice nice sorry my bad my bad oh this is cool by the way I I do
want to say something about this so this is very oam meaning that you're sending an
explicit message about the variable but you're not tying it you're not tying a
lifetime as part of its type does that make sense so one thing that rust does that's
very you can call it frustrating is that a reference is effectively part of its
type which means that you have colored types whereas this whereas o camel and now apparently Mojo is that they're
orthogonal which is really nice it's very very very nice like this is I I
think this is one of the greatest things ever because that means the you know the outside can make a bunch of uh
assumptions about this meaning that okay this thing could be stack allocated due to how it's being used
really cool whereas all like all Dynamic languages you usually can't make that and everything has to be Heap allocated
but this one's being very explicit about it uh this still works because string implements a copy Constructor it is able
to move into bar and leave behind a copy under the hood this is still passing a reference for maximum efficiency but it
only creates a copy of f if mutated to fully opt into so that's called a cow copy on right uh or to cop a fully opt
into rust default of moving an object and losing ownership you need to use the operator whatever this is cool honestly
this is cool now you finally get a compiler error for uh trying to use fuo after a move and you have to work much harder to
fight the borrow Checker in Mojo this is better default Behavior not only is it more efficient it does it doesn't uh
roadblock Engineers from dynamic programming backgrounds they still get the behavior they expect by default with
the best performance possible I mean to me this is a little bit of a weak argument in the sense that uh you're
kind of like people would just use a reference here dog they' use anster right they' aner
that son of a bee so you know what I mean you know what I mean like kind of
feel kind of feels a little you know boilerplate rust though but then again
uh but then again you also have a lot of these types that you have to think about blah blah blah blah and then if this
thing has to be held on to longer for some amount of time then you run into lifetimes and
anyways all right no pin requirement in Rust okay every time I've asked somebody that
understands what pin is they can't ever explain what pin is they can just tell you how you should use
it it's very very funny how pin is like one of the most loosely understood concepts of rust
as far as I can tell pin is it's saying whether or not it can be moved in
memory is all it is so there's unpin and pin I believe that's like the the fundamental basis of it a pin equals
can't move exactly but to explain that to why you need it and and all those
things and how it actually performs it and all that that stuff it feels very confusing in Russ there is no concept of
value identity for a self-referential struct pointing to its own member the data can become invalid if the object
moves as it'll be pointing to the old memory location this creates a complexity Spike particularly in parts
of async rust where Futures need to be self-referential and store State you must wrap self with pin to guarantee
that it's not going to move by the way this might somehow Mojo just made one of the best explanations of of pin or of
pin they're doing a pretty good job in Mojo objects have an identity so referring to self. Fu always returns to
the correct location in memory without additional complexity required for the programmer uh there is a nice blog
titled pin and suffering which we've read that takes you on a journey of a ration working through the implications of pin these are complexities that a
mician I didn't mean to press that I was just so disappointed by people who
program Mojo calling them magicians okay I'm not I'm just saying I think it should come up with a different word
okay just saying I'm I am I am furious right I'm fur I'm I'm fuming I'm fuming
right now um all right rust was started in 2006 and Swift was started in 2010 um
and both are primarily built on top of LL of VM I Mojo started in 2022 and
built on L mlir which is Mo more modern Next Generation compiler stack than llvm
IR approach that rust uses okay so there could just be but this is like a uh one
could argue that this is a eventually fixable problem Mojitos there you go I like that Mojitos this is a an
eventually fixable problem there's a history here our CEO Chris lner started llvm in college in December 2000 and
learned a lot from its Evolution and development over the years he then led the development of mli at Google to
support their TPU other AI accelerator projects taking that learning from llvm IR to build the next step forward
described in this talk from 2019 okay so he may know a thing or two as it sounds like Mojo is the first programming
language to take advantage of all the advances in mli both to produce more optimized uh CPU code generation but
also to support gpus and other accelerators and to have much faster compile times than rust let's go get
dunked on I think actually this is a very important part if you're doing a bunch of really uh if you're doing a lot
of really fast iteration rust can become just
annoying and I don't want to sound like a diva which I will sound like a
diva compile times can take the joy out of programming sometimes I get like
compile allergic sometimes you know it's one reason again why my go Arc I've been
loving my go Arc because there's just like you just they're just compile times
are transparent you know it's just really enjoyable uh this is the let's see this
is an advantage that no other language currently provides and it's why a lot of AI and compiler nerds are excited about Mojo fire uh they can uh build their
fancy abstractions for exotic Hardware while us mere mortals can take advantage of them with pythonic syntax uh great
simd ergonomics CPUs have special registers and instructions to process multiple bits of data at the same time known as simd single instruction
multiple data but the ergonomics of writing this code has historically been very ugly and difficult to use yeah wild
every time I see simd code I'm like du uh these special instructions have been around for many years but most code is
still not optimized for it when someone Works through the complexities and writes portable simd optimized algorithm it blows the competition out of the
water for example simd Jon that's real that's what uh V8 uses and that's why
often I mean it's amazingly fast uh Mojo's Primitives are natively
designed to be simd first U 8 is actually a simd dtype u 81 which is a
simd ele or simd one of one element there is no performance overhead to represent it this way but it allows the
programmer to easily use it for simd optimizations that's actually pretty
cool okay okay that's pretty good okay so maybe magicians might be okay maybe
magicians Mojo has too many types what can you ever have too many types for
example you can split up the text into 64 byte blocks and represented as simd Type U and 864 then compareed to a
single new line character in order to find the index for every new line because the simd registers on your
machine can calculate operations on 512 bits of data at the same time this will improve performance of those operations
by 64x I don't know if it's like literally 64 I mean like yeah like in in
like the the the peer scope of that yeah but there I mean I'm sure it's not like a pier 64x always win there's probably
some some coefficient sounds like a skill issue it does sound like a skill issue but also not having to like write
out all that also sounds really fantastic uh so more examples of simd type float 64 824 whatever you can
multiply a float by float let's see by let's see you can multiply it by float
uh two improving performance by eight on most machines compared to multiplying each element individually so that is
like I mean this is super cool honestly this is super cool in the sense that you're able to do very simple operations
you know I mean just think about matrix multiplication right that's I mean I think that's what you got to have in your mind when you think about this like
vector operations and so if you just just say they're int 8s and it just does
it for you like there is something that's really good about that right it's really really good about that well it's not just great for ML these same ideas
can also probably be I assume they can be translated to some game programming math as well uh lovm and therefore rust has
automatic vectorization optimization passes but they'll never be able to reach the same level of performance as the programmer expressing exactly what
they intend because llm cannot change memory layout or other important details for simd Mojo has built from the ground
up to take advantage of simd and writing simd optimizations feels very close to writing normal
code all right eager destruction Russ was inspired by Ry resource acquisition is initialization resource acquisition
is initialization resource acquisition is initialization don't forget they also go
inverted uh so you know your destructors go backwards uh the interesting part about this is that they aren't focusing
on uh solving the automatic parallelism problem they're going straight for uh to instruction parallelism yeah it's it's
it's interesting preach dude C++ Doctrine yeah thank you for coming to my C++ sermon and implicitly rust sermon uh
from C++ which means that once an object goes out of scope the application developer doesn't have to worry about freeing the memory the programming
language takes care of it this is really nice Paradigm and you get ergonomics of dynamic language without the performance
drawbacks of a garbage collector exactly Mojo uh takes this one step further I am
curious about something though with this like is it always faster and here out on this one this is why I assume they do
like Arena Arena allocations and and you you you pretty much write your own allocators to avoid some of this where
if you're always deallocating as it's running is that better or worse than having something like a garbage
collector that can deallocate a bunch of things at once maybe it's like you know
there's obviously a trade-off we all know the tradeoff I'm just saying I wonder what the distributed efficiency versus the you know Point efficiency is
I have no idea I just assume allocating is more expensive it's allocating is more expensive in gc's because you have
to allocate bookkeeping memory along with the thing itself and then deallocating can be more expensive because it has to crawl a bunch of stuff
better throughput but worse overall that's what that would be my assumption as better throughput but but worse overall right like maybe that's if you
take a time period it's better but then if you take a time period long enough it becomes worse and that makes sense Mojo
takes one step further instead of waiting until the end scope it freeze memory on the last use of the object this this is advantageous in the field
of AI where freeing an object early can mean dealloc deallocating a GPU tensor
early therefore fitting a larger model in GPU Ram this is a unique Advantage for Mojo where the programmers gets the
best possible outcome without having to think about it the rust borrow Checker originally extended the lifetime of
everything to the end of its scope to match the destructor Behavior which has some confusing consequences for users
rust added new features to simplify this for developers with non-lexical lifetimes due to Mojo's eager
destruction we get these simplifications for free and it aligns with how objects are actually destroyed so we don't have
uh confusing edge cases I'm not going to lie to you Mojo is making really powerful arguments here
I really like that this is no longer like a 50% faster article but instead this is like a here are our tradeoffs we
are making and there's reasons why this is better and worse and I think I mean always garbage collection will always be
worse than not garbage collection I think everybody agrees with that statement but I I really like some of
these things it's saying I think it just makes it it it means that it's it's going to be fast Now is it going to be absolutely faster than
rust my guess is probably not uh if you have like you know expert in both
categories but i' again I really think a great measurement is take somebody with six months of familiarity and both
person gets thrown at a problem and see what comes out of it right then I want you to also take I want I want a boss to
be over each one of of those two people and I want them to also be in like hey you need to hurry up hey we got deadlines hey we got people that are
waiting for you hey we got this and I want to see what the outcome of that code is you know what I mean because anybody can make the world's most
optimized code given enough time and effort but can you do it under pressure under you know real world working
conditions all right tail call optimization oh yeah here we go another piece of overhead is the way that drop
Works in Rust it tracks if an object should be dropped at runtime with drop Flags rust can optimize these away in
some cases but Mojo defines them a way categorically to eliminate the overhead in all cases
okay okay okay there let's see there isn't much of a trade-off being described right they're explaining how a
fast Mojo is because Tech trademark but it's not describing what trade-offs they are
making well there I mean their claim was that representing something as a simd int contains no overhead change but has
the like opens the door to easier use of simd can we stop for a moment and recognize that this is also free good
python compiler facts that's basically Hotpot
elimination Mojo is using well Mojo is going to use a if it's if it's pythonic in nature it's going to use a garbage
collector it has to uh due to the previous I assume it has to I may be wrong there but I just assume tail call
optimization and elimination TCO and tce uh due to previous point about not having eager destruction and rust if
something is allocated inside a recursive function that D structure won't run until the end of the scope which means that tail call optimizations
and eliminations are off the table here's a minimal example that you can run yourself uh first function new cargo
rust looks like this again I don't know how true these
numbers are but that is wild I mean that is wild so so hold on
so rust doesn't have tail call
optimization is that true it
does let's yeah I know then then what I don't get
it uh personal hold
on is there is there a cargo nit can I provide a
name say what what what what just happened here
oh
what hold on what what is this supposed to what hold on what is happening
here like what what are they asking for remove these generics okay why are you
why are you why are you being like that I I thought you could turbo fish that side are you not able to Turbo fish
that side expect a type what is this type what are you asking what are you even asking me uh with capacity oh I
left those in I'm a stupid person okay so they didn't have a typee on it so it it blew up is that like some new feature
that I'm not that I'm not not aware of okay so I can do that cargo run
release
uh just make sure I I I did see that uh yeah all right oh my goodness
I I actually went to a different neovim instance uh i32 there we go
okay so it it's definitely running these
things I mean even if I throw a little time in there I guess I don't I what what are
they using to run and do the uh hyperfine I don't have hyperfine so I
don't have hyperfine yeah uh I don't have
hyperfine
just pseudo app install right am I right am I right am I right just pseudo app install super pseudo app install hyper
fine isn't that how you do it let's find out if that
works uh what am I supposed to let's see uh cargo build release I just wanted to make sure that
I was actually running the thing okay release hyper fine and what do they have here here uh build Target uh CD Target
oh here I'm going to take that uh hyper fine uh Target release uh
Foo okay well I'll be damned I don't so so the problem is is I
don't know what why this thing can't um I don't know why this thing can't be is
it is it is it because this thing is allocated on the stack and therefore it can't be tail call optimized is that
what they're saying I don't I don't really the problem is I don't really understand exactly how tail call optimization Works other than it it
literally it literally like unrolls it into a loop uh instead of having to
allocate a new stack frame per function call uh read the text above that's why they say why yeah yeah I saw I saw that
because they don't have eager destruction therefore it won't work I don't have Mojo installed so I can't actually I can't actually prove this to
be true but you know what we can do
since we're already here we I mean we might as well you know we might as well just go like this uh index.js let's
let's try this out let's uh let's try this out in the old um let's see how let's see how JavaScript does
huh yeah yeah yeah if uh if x equals zero oh yeah I was like why can't I see
why this is a problem there we go fantastic
uh all right let's let's see how let's see how node
does uh let's go like this let's go node um
Source why why why can't I what just happened there that was
weird
the okay that does that can't that like literally can't make sense okay that
can't make sense yeah I was about to say there's
just it that can't actually make sense okay that was just launching node
okay how do I make this do I have to like okay here do I have to create like a I have to create like a run
script is that what they're asking me to do uh node index I mean this is this is
at this point there's no way that this will be faster right there's just no
way
right there we go there ain't no way that could be faster right it has to be it has to be orders of magnitude worse
cuz we're starting up multiple processes it's going to it has it has to by the very definition be like way
worse why command terminated why why why why why
why I hate bash sorry sorry bad cop I hate bash okay I hate bash I hate bash I
don't I don't even want to hear about it Maxim okay
well node didn't win this node did not win node did not win the
argument increase Ram maximum old space increase okay
well can you try drop stuff before okay yeah yeah yeah yeah yeah yeah yeah yeah what what let's let's do yeah okay we'll
do one more little one more little search drop stuff let's throw that in there
okay uh let's go like this let's go cargo build release
hyperfine appears to be no difference
here if you aren't using VEC with capacity but normal VC new it's fast
I have no idea why there must be there must be a reason why that
is there's some there's something that goes on where you allocate an array with capacity that changes how how it goes on
there so I can't say I
understand that with a capacity pre- allocates sure but so I mean new new allocates what
five slots but look I mean they're doing they're doing something very similar
they're saying hey create an INT with 42 slots in it right so I mean they're they're also creating a similar sized
thing so it's not like so it's not like it's not like they're cheating I don't think new allocates one I don't believe
you on that I don't believe you at all new does oh V new does not allocate
until push is called I wonder what they're doing so
that so that's actually a really so that would actually be super
interesting it's it's just super interesting to think about which is what does this actually allocate because if
this actually allocates and allocates everything to that size then that's really impressive right but then why use
with capacity they're using with capacity to show you something right you do with capacity if you want to create a
vector that does not resize itself it's called Dynamic Vector for a
reason it doesn't allocate that's not true it's dynamic allocator or a dynamic vector and it has a size associated with
it I'm I one would assume that its capacity is respected okay
yeah I with capacity resizes itself yeah I would assume it resizes itself to the
size that you pass in but starts at 42 again I would assume that all happens uh anyways okay so this
is very interesting there's something going on here that I think we don't understand but we do know that when you
say with capacity rust clearly respects the fact that it's with capacity but it has implications if you if you don't do
that then it does not allocate therefore for it's just effectively a stack whatever and it can go by pretty quick
I'm just curious what they're doing we don't know what they're doing try Vex
042 I I I just don't think that really like I think we're kind of we're I don't think we're getting anywhere on this you
know what I mean I don't think we're we're I don't think this changes okay it does change a
little bit I don't
is that because this thing has the same this thing has the same behavior does this thing have the same
behavior as new except for when it's first pushed to it then it makes its first initial all a first initial push
become allocation that sets its size to 42 we know that I have a faster PC I do
have a faster PC uh the compiler must ensure that destructors are called an appropriate time uh which for rust is
when a value goes out of scope in the recurs in function the vect has a Destructor that needs to be ran after each function call this means the
function stack frame can't be discarded or overwritten as it required for tail call
optimization I am very Cur like is that is that true like are we seeing something that's true because you know
the obviously you guys the audience uh have shown something different that it
may be a misunderstanding that's going on here how do I know these things are happening
um uh let guarantees a stack allocation in Rust
what there there are magic so now I'm I'm just curious how Mojo what they're doing differently
right uh anyways we can just move on uh as is required for tail call optimizations because Mojo destructs
early uh it doesn't have this limitation and is able to optimize with TCO even with Heap allocated objects I wonder if
there's other ways you could kind of test this with rust with Heap allocated objects and expecting of destructors and all that kind of stuff being called such
that you're able to get out these results in a meaningful way right uh this is 126x the result for my
M2 Mac give it a try yourself if you don't have Mojo you can install it here why does okay so can we just do a quick
quick question why does my multi-year old lemur Pro apparently produce results twice as
fast as whatever the hell is going on here what is going on here uh
conclusion we all love a rust at modular and we are inspired by it the tooling is great the tooling is great the tooling
is fantastic install Mojo right now I don't want to install Mojo right now and it currently has one of the best
highlevel ergonomics for any system programming language absolutely this is probably the most Tru statement ever been uttered absolutely rust for being a
systems level language is feels like a highlevel language in a lot of
cases right there's also simd for rust yeah but I if I remember if I if I'm not
mistaken uh dehydrate mango um simd for rust is much more
cumbersome uh but it has pointed two out major problems in the field of AI uh it compiles slow and AI is about
experimentation and Rapid iteration most AI researchers are experienced with python won't take the time to learn a new language from
scratch I completely agree with these two things uh magicians uh but they the rust wizard that's why uh members of our
team tried to solve this problem with swift for tensor flow at Google which didn't catch on due to the issues
mentioned with AI researchers not willing to learn a brand new slower compiled language
interesting this is actually like this this point I find actually to be the most compelling or interesting part of
the entire article is that at I mean Google's a weird place I'm not saying Google's fantastic but the fact that
they struggled to get people to make changes and that Google was using Swift for tensor
flow all right two is also an AR argument against uh Mojo uh it's hard
for me to say it's an argument against Mojo in the sense that it's it's it's mostly
python right it's mostly Python and so you're already like if you're already at
85% understanding the language then that's not a huge jump if
you could if you could 100x Python's performance let's just call it a 100x I know it's not 100x but if you could py
if you could 100x python and you had to learn 15% more syntax to do it but keep
everything else about python the same would you do it of course everyone's going to do it right that make it
literally would make no sense right it's like typescript typescript is literally the same
argument would you want to add 15% more syntax to your JavaScript but get
notified when your dumbass thinks you're using something that's a string but it can also be an undefined yeah we're all dumb asses of
course we want that now me personally I use I use a JS doc which is like 40% more syntax but you get the idea Geico
can even save you 15% no based got I use I use JS do not typescript because I'm
actually based uh yeah uh free free your build pipeline stop using typescript anyways members of our team tried to
solve this problem uh with swift at Google blah blah blah blah we love python uh C++ Russ Swift Julia Etc but
over the decade of the industry hill climbing these Technologies we believe that a fresh start with Mojo embodies the only way to make a dent in these AG
old problems Mojo has already Optimal Performance for system Engineers but still has a long way to go for all the
dynamic features that python programmers expect Optimal Performance for system
Engineers maybe the phrase would be like good enough so easy a caveman can do it shut
up optimal is kind of you know optimal might be a little a little aggressive in this situation uh maybe it has optimal
ergonomics and performance cross-section
right rust is an excellent choice if you need to put something into production right now uh if you're curious and
looking towards the future and want to be early with a language that could be instrumental in the next 50 years of AI give Mojo a try we'll be adding AI
specific libraries to the package that comes with Mojo soon which will uh which we're working on as the killer app to
show the world what Mojo can do keep an eye out for Max in the coming weeks and Netflix used to have something called Max we killed Max so son of a Max
got taken out the pasture I believe it's on the Playstation only PlayStation 3 something like that anyways
uh money money worked on it great guy by the way love that guy at Netflix
um I'm curious if Mojo will go like the go route and have a really strong standard library because that's what it
kind of sounds like is that they're they're creating an environment for you to have everything you need like with go
effectively with go you could write a web server with with with zero dependencies like it's actually possible
for you to write a web server with no dependencies and it will be reasonably pretty good so like can that happen with this I
don't know kind of neat okay shut up about my hair okay we'd love to see you guys did this to me uh you did it to me
uh we'd love to see you in the Mojo Community here are some links to get you started there you go anyways
um I actually like this this is a great article this is a great article uh I
liked what they were trying to talk about and the things they were trying to say uh the pin thing is kind of an interesting one because this is more
just like this is purely skill issue this is purely skill issue right uh and
I suffer from this this this particular skill issue of rust um and so very
interesting this is a very interesting thing here um I'm curious how much this makes a
different and if if this is something that that rust is in the process of quote unquote transferring to or
whatever like is it actually that much better to the point where everyone is going to be adopting this over the next so much time because if this is the case
where it's like this is going to become the new standard then it's not really like an argument for why this thing is
good it's just good right now does that make sense it's good now it's not good forever this is not a
competitive Advantage uh assuming that mli is open source and
everyone you know everyone's movie there's there's a lot of assumptions going on there I do like the simd
ergonomics though that seems really exciting come to Brazil I am going to
Brazil anyways okay hey good job
Mojo keep on don't lose your mojo okay Austin
Powers I mean she uh I was a Discord with some uh larger streamers and
someone mentioned Brazil and so then I did the classic Brazil meme with Brazil mentioned and then nobody said anything
about it and I felt stupid

----------

-----
--17--

-----
Date: 2023.07.08
Link: [# Mojo Programming Language: A Simple To-Do List](https://www.youtube.com/watch?v=WFjV528Iq3Q&list=PLSv2bgL9aQWSLwZjX-nll1UU_NcRKQCDr)
Transcription:

Intro
welcome back to digestabyte your go-to
channel for all things programming I
highly apologize for the delay in
uploading videos but trust me it's worth
the wait because today we have an
exciting topic for you today we are
going to create a simple yet powerful
to-do list using Mojo but before we dive
into the coding part let me quickly
introduce what merger programming
languages to those who might not be
familiar with it Mojo is a beginner
friendly language that allows you to
write programs with ease and simplicity
it's perfect for anyone who wants learn
programming or build quick efficient
Solutions because it is very similar to
python
all right now that we know what Mojo is
all about let's jump into creating our
to-do list to get started we need to set
up our development environment
I am using jupyter notebook which is a
Mojo playground if you haven't applied
for the Early Access of moderate don't
worry you can easily find the
instruction in the description below
over to the editor
Data Sector
we have a
Jupiter notebook here and I have added
some steps to follow along the tutorial
so let's uh start with the first step
our data sector where we will store our
task
or to-do list so let's start importing
our data structure from vector
I will run the code here to import our
ToDo List
data structure
and then we will move to the next step
now let's define a struct name to-do
list where we will have methods add task
complete task or and display tasks
so let's start by defining our struct
to do
list
here I am using a parameter
and like this
now I have defined the struct tutorial
list
so let's define our variable where we
will store our task which is of type
inline fixed vector
y
tasks
and type of inline
fixed vector
and I will pass some parameter here so
the first parameter is the size which is
of our
its type of vector so it needs to be
some size and capacity
so I will pass here the size which I
will explain it later on
and the second one is the type of the
data structure we will so in our case it
is a string so I will use the same
like this now next we will Define a
Constructor for our structure
it
here I will Define a variable name
capacity
so we have a capacity of integer type
now I will initialize our
variable tasks
like this
and we will pass the capacity
to our initialized
variable
so now we will need to Define these
Code
three methods like add task complete
task and display tasks to
make the video shorter I will copy over
the task that I have previously created
and just copy paste it here so I will
explain it to you step by step
so let's hover to add task
we have created a function called add
task
that allows the user to enter a task and
add it to our to-do list if it is
already
completed so it will say it will just
print out it is completed or if it is
not completed so it will append the task
into our data structure and print this
task has been added to our list
now head over to the next step which is
complete task
we have created a function called
complete task that allows the user to
remove tasks from the list
so I have a variable named task length
which is the length of the task and
there is a temporary data sector that is
used to store a new list it will this
Loop is for looping over all that
previous task and remove the
task that is selected from the parameter
that I have passed in
so it will just clear out the previous
and copy over the new task
next method is called display task it is
low power all the tasks
that we have in our task variable data
structure so it will just display one by
one
so I have already defined and created a
instance of to-do list here and I have
passed a
size attribute which which we have
defined here in the start and we have
also defined the capacity of our
toothless
so let's add some test to
we are almost there now let's test our
to-do list and see how it works I will
add a few tasks to demonstrate its
capabilities like this
so we have add task and complete task
and add task and display tasks so let's
uh run our extract code first
so there is a error
this I have
a real mistake in the code
and then I will
create the instance and then I will run
the examples
so I will run the code
so you can see
so for for the first method it added the
task
for the second method it also
edit the task
and the third method is called a it will
just remove the first task that we have
created so it says completed task
and I have also added the new task
so it added the new task and we can
display all the tasks and see which are
the tasks like this
as you can see our module power to-do
list is working flawlessly it's a simple
yet effective tool for staying organized
and managing your tasks I apologize
again for the delay in uploading this
video but I hope it was worth the wait
if you enjoyed this tutorial and want to
see more programming content don't
forget to give this video a thumbs up
and subscribe to our Channel and if you
have any suggestions for future topics
let us know in the comments below thank
you for your patience and for joining me
today keep coding keep learning and
until next time happy programming bye

----------

-----
--16--

-----
Date: 2023.05.09
Link: [# Mojo - the BLAZINGLY FAST new AI Language? | Prime Reacts](https://www.youtube.com/watch?v=RZhTC33lStQ)
Transcription:

all right so let's watch the Jeremy
Howard demo and then we're gonna watch
the Fire Ship version of it by the way
we're learning about Mojo the brand new
super sexy very exciting programming
language that apparently is like 900 000
times faster than python what kind of
measurement are they doing how
much do you want to bet they're just
like sitting in a for Loop for one and
four Loop for the other and be like lock
python was terrible at Loops of course
Python's terrible Loops everybody knows
Python's terrible loops you all this now
I'd love to introduce Jeremy Howard who
will show you how Mojo Works in practice
all right show me Jeremy
wow bad person thanks Chris you know I
realized it's been 30 years since I
first trained a neural network and to be
honest I haven't been that satisfied
with any of the languages that I've been
able to use throughout that time
I think this guy realizes okay so he's
over there not being satisfied but what
he little does he even know if you go to
github.com the prime agend you will see
the beginning of my masters okay years
ago back when I was the shittiest
programmer in the world if you go there
and you look at my suppositories you
will be able to find everyone's favorite
uh is it a neural neural JS yeah
I created a trainable Network
okay look at that okay you see an Fizz
in there do you not see that look at
that look at that we got anphis adaptive
neural fuzzy inference systems okay
particle swarm optimizations and Colony
optimizations competitive clustering
okay we got probably got some rbfs in
their radial basis functions
see I don't even know see here's the
deal I did this a decade ago and I
didn't know that JavaScript was going to
be used for everything think if I would
have known that the world was being
Rewritten in
okay I didn't know okay I was brand new
I was a baby let me be a baby okay I was
a baby and Jeremy would have been proud
of me in fact I complained to Chris
about this when I first met him years
ago and Chris has been telling me ever
since don't worry Jeremy one day we are
going to fix this the thing that I
really want to fix is to see a language
where I can write
performant flexible hardcore code but it
should also be concise a lot of a lot of
young men all about that hardcore coding
okay I've heard about it I've seen it on
this okay I've I've
seen this I've seen this on the internet
there's some posts and it makes me feel
really uncomfortable
I don't like it I don't like it I don't
like it okay can we just go back to
standard softcore JavaScript programming
that's all I want to see okay this is
inappropriate all right
readable understandable code and I think
that actually Chris and his team here
have done it with this new language
called Mojo Mojo is actually a super set
of python so I can use my python code
here
did you just hear that
okay so I did I didn't see that one
coming the fact that you can just use
your python this wow wow uh that might
that might actually make this a very
sellable language then right if you
could like a theoretically if you could
instantaneously have your code be faster
and just write python
that's a lie okay that is a lie okay
just checking check this out I'll show
you what I mean okay and here is a
notebook actually this notebook is no
normal notebook this is yeah I can see
because there's a percent sign then the
word python which makes me feel strange
on the inside Mojo notebook
by the way does anyone think of Austin
Powers
like right now that's all I keep hearing
is Austin Powers in my head
and I like I can't get it out
frustration because this is the most
fundamental foundational algorithm in
deep learning we're going to look at
matrix multiplication now of course
Mojo's got its own we don't need to
write our own but we're just showing you
we can actually write our own Hive
performance matrix multiplication
isn't there like a better version of
matrix multiplication
right isn't there some new one that's
come out that's not like this
is there some sort of sweet algorithm
that somebody made anyways I stop by
comparing to python that's very easy to
do yeah and also I assume there must be
is there some sweet sweet CMD operations
that can be done with reading a bunch of
data and then making only a singular
multiplication I don't know how any of
these steps I don't know how this stuff
works I have no idea I you know I'm not
a machine level Enthusiast I'm too
stupid for it okay and then it actually
is going to run it on the C python
interpreter so here's our basic metrics
yeah go across the rows and the columns
multiplied together add it up let's
write little Matrix and a little
Benchmark and try it out and oh dear
0.005 gigaflops that's not great how do
we speed it up well actually believe it
or not we just take that code we copy
and paste it into a new cell without the
percent Python and because Mojo is a
super set of python
oh the percent python literally runs
python
he did say gigaflops Okay personally I
prefer these Sigma flops but some people
you know
they're honestly not as you know they're
not really into the flops so they don't
know about that this runs too but this
times it runs in Mojo not in Python and
immediately we get an eight and a half
times beta
now there's a lot of performance left on
the table here and to go faster we're
going to want a nice fast compact Matrix
tape okay of course we can use the one
that Mojo provides for us but just to
show you that we can okay from scratch
so we're actually creating a structures
this is nice compact in memory and it's
got the novel things we used to float
32s okay and probably should have chosen
a better float huh right it isn't it if
you choose a float32 what actually
happens underneath the hood isn't it
like more instructions if you're running
on a 64-bit I forgive me if I'm ignorant
on this one but in my head to do a
32-bit operation you have to take your
read line right and and actually like
bit mask out your data
if I'm correct I don't know I've only
theorized it in my head I haven't
actually
you know
I haven't actually tried
is that true with floats I don't even
know by the way this text is unreadable
it's unreadable and I have no idea what
you're saying other than yeah I do look
good I dude I totally agree this
mustache is wonderful stuff you don't
expect to see in Python like Alec 70s of
course you can see the whole thing fits
in about a page of code a screen of code
so that's our Matrix
and so to use it we take copy and paste
the code again but this time just added
type annotation these are matrices and
now it's a 300 time speed up Suddenly
things are looking pretty amazing but
there's a lot more we can do here comes
doing if our CPU supports it say eight
oh damn we're about oh damn we're about
to go full 70s nuts on them
um elements at a time using simdi
instructions
manually there's quite a bit of code but
we can do it manually I've always I've
always wanted to play with some Deez
Nuts you know what I mean like I've
always wanted to play with them I've
never actually got my hands around them
and I've never tried to do something you
know what I mean
have any of you tried to play with them
because that'd be great that's like that
is like what I want in life right now
maybe that's something we can do in zig
a 570 time speed up but better still we
can just call vectorize so just write a
product operation call vectorize and it
will automatically handle it on simdi
for us with the same performance speed
up so that's going to be happening in
the innermost point we're going to be
using the simdi and in the outermost
um what if we just call paralyze this is
something we can do now suddenly the
rows are going to be done on separate
cores for a 2000 times speed up so we've
only got four cores going on here so
it's not huge
how does parallelize work is this some
sort of is this some sort of like
lightweight green thread that just
happens that does something that rust
literally could never do is this what
Russ cannot do
no
okay
no okay well rust really sucks that like
if you have one place if you have one
buffer of memory and you want to write
to it with a bunch of threads going
super duper fast but you know that your
threads aren't going to stomp on each
other like you can't really do that in
Rust
easily if you've got more cores it'll be
much bigger this is something okay hold
on you tell me hold on then then how
does this run you just told me this
wasn't green threads but it says it's
running on these different chords what
kind of what kind of what is it running
on what is it doing here I assume it's
not spawning actual processes because
actual processes are probably too big
right
you can deal with lifetimes in Rust no
you cannot can you do that in Rust can
you actually split really I should try
that huh
an actual OS thread
oh okay
what they can't do with python you can
do some very very basic parallel
processing hey I'm glad to be wrong
multiple times creating separate
processes and having to move memory
around and it's pretty nasty and there's
all kinds of complexities around the
global interpreter like and so forth as
well this is how easy it is in Mojo and
so suddenly we've got a 2000 times
faster matrix multiplication written
from scratch we can also make sure that
we're using the cache really effectively
by doing tiling so doing a few bits of
memory that's close to each other at a
time and reusing them oh wowing is as
easy as creating this little tailing
function and then calling it to tile our
function so now we've got something that
is paralyzed tiled and vectorized for a
2170 times beat up over python tailing's
new to me okay I understand two out of
three of those words which I feel pretty
good about because if you understand two
out of three like you can pass a lot of
colleges you know these earn degrees in
some states and so that's like there's
definitely a w there somewhere you know
what I mean
we can also add unrolling
um
so vectorize unroll was already built
into Mojo so we don't even have to write
that
now there's a lot of complexity here
though like what tile size do we use how
many processors what's in these size all
this mess to worry about a lot of people
struggle with their CMD size I get it
you know a lot of Us wish it was we
could go bigger but you know there's
limits to Nature and each different
person you deploy to is going to have
different versions of these or have
different memory they're going to have
different CPUs and so forth no worries
look at what you can do we can create an
auto-tuned version by simply calling
auto-tune so if we want an auto-tune
tail size we just say hey Mojo try these
different tail sizes for us figure out
which one's the fastest compile the
fastest version for us cache it for this
individual computer and then use that
paralyzed titled unrolled vectorized
164 times speed up so this is pretty
remarkable right it's not just linear
algebra stuff we can do really iterative
stuff with my mankind
can't get into this what the hell just
happened right there
oh my goodness like attack lady
mandelbrot so we could create our own
complex number type and it's going to be
a strap so again it's going to be
compact in memory it looks like
absolutely standard python as you can
see multiplying subtracting using the
operations and to create the mandelbrot
kernel we just take the classic Mandel
brush set um everyone knows about that
um pop it in Python here yeah yeah and
then we can call it a bunch of times in
a loop yeah um uh returning at the
appropriate time to Accurate the
mandelbrot set that's all very well and
good did it work it'd be nice to look at
it so how would you look at it would be
nice to use matplotlib yeah yeah every
single python Library Works in Mojo and
you can import it check this out plot is
import the python module matplotlib NP
is import the module numpy and the rest
of it this is actually Mojo code but
it's also python code and
it was and I always hated rust anyways
honestly to tell you the truth I never
liked rust
um I think I've always thought python
was the best
you know python really is just the best
huh yeah I think so too I've always felt
that way and this obviously just
confirms all the things I've been
telling you guys for years at this point
and so really happy about this really
happy
I don't know if you remember but Chris
actually said the mandelbrot set is 35
000 times faster than Python and that's
because we could also do an even faster
version where we're handling it with
Cindy and we can actually create the
kind of iterative algorithms
can we auto-tune this even with the help
of stuff like numpy this is something
which is really unique to Mojo
so we now have something here which is
incredibly flexible incredibly fast can
utilize the hardware you have no matter
what it is and is really understandable
to python programmers like you and me I
think finally we're at a point where we
are going to have something where I
actually I hate real talk though
that was very incredible watching that
all right like that was really really
incredible
um
it was really incredible
you know I I like the dog you know you
know me and me and all my homies hate
python I get that but that was really
incredible like that
the fact that you can use all of the
libraries that you normally can use with
python or at least the ones that they
showed now whether it's true universally
whether some things that really suck
about it whether the blah blah blah blah
I get that and it's relatively a fresh
language if they come up with a good
package manager a good build Tool uh
some good linting and then even some I
saw some type definitions in there like
long as you can throw all those things
in there and you can really focus on
that kind of like that developer
integration notice I don't use the term
a developer experience uh long as you
can have those things and you go really
hard on the LSP you can make an
exceptionally successful language I
think I think that this has a lot of
opportunity but again you know
what opportunity does it have Beyond
just machine learning
I don't know again I don't know I I
could see myself using this for all my
visualizations right because I have to
do a lot of visualizations I have to do
a lot of that crap you know and it's
really annoying to do all that crap uh
it would be really sweet if this just
works it'd also be sweet does this thing
per does this does mojo produce an
executable does it have a lot of cross
compilation stuff is it is it easy to
use or is it still
more like pythony like is it more
interprety I don't know I would just
like a faster python apparently this is
just a faster python
anyways this is super cool rock on I
like this and now the fireship version
it is May 4th 2023 and you are watching
the code report python is a wonderful
language for productive programming but
it has a good meme right there one big
problem it's too slow and going slow
means you'll get made fun of by the rust
and C plus chats of the world but the
tables are about to turn thanks to a
brand new programming language called
Mojo a superset of python that's not
just two times faster not ten times
faster but up to 35 000 times faster
than your we okay well I didn't mean to
pause it right here but
if that number should just hurt us a
little bit right
this should just hurt us a little bit
and now we do know that it's not as it
is a superset but it doesn't work with
all the pythons yet but that should just
hurt us a little bit that this could
even exist that this is a real thing
that happens in a real language then
your grandpa's Python and that's a huge
deal because Python's the dominant
language for artificial intelligence but
behind the curtain whoa whoa go back
there why are those machines looking at
the keyboard okay you would expect the
machines to not look at keyboards
because Python's the dominant language
for artificial intelligence
hard
no no way people no way no this is okay
you know what Skynet can't happen if
they have to look at a keyboard okay if
robots literally come out and they're
and they go like this you know I spend
more time thinking than actually typing
so being a good typer doesn't actually
influence my programmer speed
I would I would literally realize that
there's no possible way Skynet can't
actually exist robots are just as stupid
as people but behind the curtain
anything that needs to go fast is
written in C or C plus plus in today's
video we'll take Mojo for a spin but
first here are five things that you need
to know about it one this is not some
random guy's side project on GitHub but
rather it comes from a company
the guy who created the Swift
programming language and the llvm
compiler tool chain if anybody could fix
Python's problems it's him and if you
have no idea what llvm is check out this
video two it's a language design for
programming on AI Hardware like gpus
running Cuda and other accelerators it
achieves this by leveraging multi-level
intermediate representation to scale to
Exotic Hardware types without it
those are a lot of words and when he
says a lot of words at me like that
it makes me feel stupid and when I feel
stupid I just feel like attacking him so
Fire Ship
um you know here's the deal Fire Ship
okay
first off Fire Ship you know earlier
earlier on Twitter when you asked what
should my next video be I kindly
reported a video and you said the top
liked one will win well guess what I did
that and you didn't make a video so now
I'm giving you an another response right
here
again for you to make it please make a
WinRAR video okay I'm still waiting on
WinRAR I want you
to make WinRAR and second
I'm gonna be back in Arizona if you want
to you know grab dinner again just just
wondering
[Laughter]
ton of complexity and it even has
built-in Auto tuning to optimize your
code for your Target Hardware three it's
designed yeah that auto-tune thing was
crazy
it was the craziest thing I've ever seen
in my lifetime that you can just be like
auto-tune and how does it make the
decision at compile time is that is
there some sort of like reading speed
that's related to the hardware you're on
so thus it's able to make a good
decision why do you even have to uh
why do you even have to
you know
put what sizes you want
as a super set of python in the same way
typescript is a superset of JavaScript
so you don't need to I am almost
ratioing dhh yeah he didn't respond
because he is a coward
you know here's the deal if you make a
tweet and it gets a thousand likes and
someone asks you a question and gets one
like you're probably not going to see it
real talk not trying to be mean that's
just how it works but if you make a
tweet that gets a thousand likes and
someone's reply to you gets 800 likes
you saw it you read it and you didn't
respond because you're a coward learn
another language to take advantage of it
and this is unique compared to other
modern systems languages like rust Zig
Nim and so on which would have a higher
learning curve for existing python
programmers it does have a bunch of
features on top of python like
declarations and structs but the base
language is fully compatible with python
and it can also is that how it does the
speed I didn't see that I didn't see the
struct part is that how they're doing
part of the speed up is that they're not
doing python crazy classes but instead
they're just doing like uh
structs underneath the hood uh and yes I
believe Mojo will finally be able to
tell me how big my dick is in bytes in
Python I believe it I truly believe it
partner up with the python ecosystem
which means you can still use your
favorite libraries like numpy pandas etc
for it adds strong type checking to the
language you can still use Dynamic types
if you love it but status types are
essential for optimized performance for
memory management I actually think
that's one of the coolest things ever to
me that's like what makes this so you
know because I I don't I'm not going to
learn Mojo real talk I'm not going to
learn Mojo but something that makes me
really excited about Mojo is the fact
that types have implications in how the
thing runs whereas
in typescript it doesn't the only thing
it accidentally gives you is uh you know
monomorphic optimizations right you
define your in you know you define your
end type by putting Types on it and
you'll accidentally only call a function
with a specific uh set of types right so
you'll accidentally jit it but this
thing actually being able to be like oh
it only takes in this one type well we
can make it special for this that's
super cool it has an ownership system
yeah similar to rust and also supports
manual memory management with pointers
super fast is like C plus plus it's a
pragmatic language that gives you safety
but also the flexibility to be unsafe
when needed now the final thing to know
is that currently it's not available to
the public it's still in very early
wait hold on are you telling me we just
got done watching multiple videos about
a language I can't even use all right Mr
latner with your big
your big claims on performance your big
claims on all these things and yet you
showed us a for Loop which we all know
is the slowest in Python you make these
claims of millions of percents faster
yet
we can't even look at it
right now
Mojo's kind of like aware to me okay
I want you to know that right now
development it will be open sourced in
the future but currently there's a wait
list to try it out I was lucky enough to
get Early Access so let's fire it up so
run it you can create a file ending in
dot Mojo or dot fire Emoji that's a huge
advantage over python which doesn't
allow you to name your files in dot
snake but we can also run the code in a
Jupiter notebook where it behaves like
an interpreted language here we have a
matrix multiplication demo that computes
a DOT product to demonstrate the crazy
performance gains we get with Mojo first
it benchmarks a basic function in Python
I I do say that this feels like a
cheating version you found the worst
case thing that python does which is
loops
and then by literally choosing the worst
possible answer which is loops
you
I I do feel like it's a little like this
test is a little weak python then by
simply importing that code into Mojo
it's executed 14 times faster with no
modifications to the code it was
actually eight times faster if you
remember the previous video fireship
which you didn't remember the previous
video okay okay we all remember this
part where he jumps in here instead of
telling you about this notebook is no
normal notebook
8.59 times faster okay some of us were
paying attention to Mr latner or whoever
that person was that was speaking Jeremy
Howard all right
Mr fireship but we're only just getting
started we can further optimize this
code by adding types to the python
implementation Mojo allows us to do that
with its own its construct keyword a
struct is very similar to a python class
but structs are static unlike classes
which are Dynamic inside this truck we
also have keywords like VAR and let
which can Define mutable and immutable
variables and death is replaced
can we just stop
with VAR let and const being different
in every language like
this language VAR obviously means change
let means no change in typescript let
means change
and const means you can still change it
it's okay we're typescript we love you
very much go ahead and do it and in Rust
you got let and let mute very
this whole thing is just really it's
really frustrating with that then which
is a stricter type of function also
notice single instruction multiple data
which is a built-in type that represents
a vector where a single instruction can
be executed across multiple elements in
parallel on the underlying Hardware once
we have this truck you can use it as a
type in the python implementation then
when we Benchmark the code again we get
a ridiculous 500x performance boost but
we're still not happy yet in the Inner
Loop we can query the vector width
instead of hard coding it and that gives
us a thousand X Games nothing compared
to what we're about to do linear algebra
is perfect for parallel Computing and we
can easily make our code multi-threaded
with the built-in parallelized function
and I'm using our speed bus I'm not
going to lie to you this version of this
code is like 10 times better than the
previous version the previous one he
went really into detail this is this is
the speed in which I want to get hit
with information okay I wanted High 2000
x but now I've got a fever and the only
prescription is more performance luckily
Mojo has built-in tiling utilities that
basically allow us to cache and reuse
data more efficiently and we can even
auto-tune it to find the optimal
parameters for our Hardware the end
result is over four thousand times
faster execution compared to the
original python code that's pretty crazy
and if you want to see this code broken
down in Greater detail I'd highly
recommend this video from Jeremy Howard
but I'm curious what you guys think do
you really think Mojo could kill Python
and C plus at the same time I'm a bit
skeptical but employers are already
hiring Mojo developers with 10 years of
experience this has been the code report
thanks for watching and I will see you
in the next one
like And subscribe please like And
subscribe like I'm subscribed to my
other channel hey look at that hey
that's me
like this
got em

----------

-----

--15--

-----
Date: 2023.11.22
Link: [# 2023 LLVM Dev Mtg - Mojo ðŸ”¥: A system programming language for heterogenous computing](https://www.youtube.com/watch?v=SEwTjZvy8vw)
Transcription:

thank you Alex wonderful we're very happy to be here and talk a little bit about what
we've been up to so we'll start with what is mojo um at a glance the top
level points of Mojo is that it's a pythonic systems programming language so
what does that mean that means we're here to do really cool things with systems and compilers and it happens to look like python but forget everything
you know about python please please so this thing is about one year old so it's still pretty early still in development
it's still quite interesting in doing some cool stuff though um and we also have a Vibrant Community we have over
150,000 users we have a b big community in Discord and there's a bunch of excitement around this so we'll dive
today into why did we do this in the first place that's often something we're asked we'll talk about how we approach
designing a new language from scratch we'll talk about internal implementation details including some of the horrible things we did to lvm talk about what
this means for accelerators and compute and then wrap things up so first why why why why why why right
so many of you are working on AI and if you work on AI the question I will ask of you all is if AI is so important to
the world why is all the software so bad this is a huge question a huge problem
and I think that many of us that have been working in this industry for a while have been struggling with solving this problem in many different ways and
so for me when I look at this I think that the challenge is really fragmentation complexity it's all these
systems that do not work very well together that are being built by well-meaning people in different groups and areas but they don't really actually
work together and so for a user this is a huge pain point and why is this well I'll speak for myself if you're enabling
a chip you're focused on the chip so many of us are paid to solve one specific problem we're not here to solve
an industry scale problem and you can't afford to do it you don't have the time you don't have the schedule you don't have the headcount you whatever often
the organization that you're within in my experience makes it very difficult to solve some of these problems and so our
Approach at modular is that we need fewer things that work better and so
that's what led us to building modul in the first place it's really kind of an organization that can span across many
different of these problems and invest for the long term in building and hopefully lifting the industry over time
so how do we do this specifically well we're building what we call the AI engine right well the AI engine if you
look at modern ml stack a lot of folks are trying to throw layers of python on top of all this AI Tech that has been
built up we're tackling it at the hardware software boundary reinvesting no surprise in compilers and so what we
want to do is we want to unify and integrate all these lowlevel technology systems so that Innovation can happen up
on top with programming models and Frameworks and all that kind of stuff our approach is to meet people where
they are so people use Pyers people use Jacks people use tens flow that's awesome these all have pros and cons and
there's other stuff as well and very few people actually want to rewrite all their code and so for us it's very
important to be drop in compatible meet people where they are and work with their existing systems the other thing
is that this is not a research project like there's a lot of really interesting and cool things that have been built over the last 8ish years of AI
infrastructure it often gets fragmented out into all these different systems we've learned from many of them and so
what we're doing is we're pulling this back together and doing hardcore engineering not research to build a
production quality system that we hope can scale for the world I'll go through this super quickly what is an AI engine well it's really
things one is this operator graph the operator graph in the interesting case
is heterogeneous so people often focus on for example a GPU and how do I make Matrix multiplications go fast and
that's a super important problem but often folks forget that AI today is a
distributed problem it involves the host involves the accelerator involves pre-processing data loading this whole thing and so you can't really solve the
AI problem for a user unless you really tackle this whole problem and furthermore like this is really
heterogeneous like as we've seen there's all kinds of different accelerators there's all kinds of different Hardware when you have a cluster of lots of
machines like microarchitectures don't always match there's a lot of complexity in this space so many of us have been
working on this again for a long time and so we've seen the rise of Kernel libraries this is how many of these
systems were first built and one of the challenges that I won't go into in depth many of you probably already agree is
that colel libraries don't scale right and so many of us for multiple years now have been building Ai
compilers and so there's lots of these lots of different approaches online kernel Fusion lots of cool algorithms
get invented and used we can talk about all the different pros and cons and trade-offs but the thing I want to claim
is that neither of these approaches scale kernels don't scale hopefully many people understand that but neither do ML
compilers and to a compiler audience that maybe is more controversial than to Kernel audience so I thought I'd dive a
little bit into why this is and the challenges that we see with this that led us to our approach with Mojo and the
system so the first is generality right I mean empirically today ml compilers
are not very general right generality includes not just matrix multiplication again data loading pre-processing all
this stuff but also Dynamic shape sparsity there's better and worse systems out there and I mean and there's
definitely progress in this area but if you're coming at it from a user's perspective they want things to just
work and if they don't just work then they'll move on and spend their time something else generality is also
important because you know if you're again coming from a hardware enablement perspective you don't really have time
to invest in all the other parts of the problem and so it makes sense that many of us working on bring up a chip don't
actually focus on the big the big picture parts of the problem another one is community so you all are wonderful
compiler nerds you know I'd love you all obviously um and I am myself a pretty
big compiler nerd but the problem is is that nobody can hire compiler Engineers this is pretty well known and so with AI
compilers this becomes even worse because how do you hire somebody who knows compilers who knows AI modeling and all
the different exotic new model of the day who knows all the numerics and the data types and knows all the specialized hardware and how do you find that that
unicorn person that knows all of these things together it's very very difficult out there and if you need a compiler
engineer to be in the loop of Novel research there's very few companies in the world that can afford attract to do
that so I believe that you cannot have a compiler first approach to this problem
simply because there's enough Talent out there I mean I love you all and you're all very valuable but this is very
difficult particularly for the scale of what AI research is today second if you're compiler engineer it seems really
weird that we're re-encoding all of compute into IR Builders and stamping out all this stuff and so you feel like there must be a problem here at some
point finally there's this fragmentation problem if you want to solve and build a heterogeneous compute system we have to
face the reality that AI developers the researchers are in Python the Frameworks
the host side computes all in C+ plus the device side is in Cuda and sickle and other things right and so if you
want to build a system that can scale across all these different levels of abstraction there's a huge fragmentation
problem here and we need to be able to unify this otherwise we can't have one system that can reason about it and so
if you want to be able to build this and solve this problem you have to kind of come back and look at the big picture of what's going on here and the nature of
compute has changed so this is what has led us to Mojo now how did we approach building
Mojo I mean you know the outcome we'll talk a lot more about how it works but how do we even get here well when we
started modular we started with a a thesis a hypothesis right we we believe that we
could get to state-of-the-art Performance against a lot of Ender
systems and do so with a single source of Truth in our code for numerics this
hasn't really been done before there's definitely systems been around the space but this this thesis if true can can
enable and unlock a huge amount of innovation in the industry and so what we did was we said okay let's go invest
in some very fancy compiler stuff generalized fusion and uh cashing integrated distributed compilation like
lots of cool stuff let's figure out what we want to do and then let's go validate that but for validation we didn't
actually care about syntax so what did we do well we went and we actually go went and built the
thing we went and built a compiler and completely ignored syntax right why well mlr is great you can write mlr by hand
you don't need a front end and so what we could do is we could actually go build major kernel libraries and things like this and validate architecturally
we could deliver the performance that we wanted to show that the compiler worked iterate rapidly on the compiler without
having to change a dependency and go and do this and what we found fortunately is that it works the technology we built
actually is good it worked it was proven out and then immediately we figure out that writing large amounts of mlr by
hand is maddening and it doesn't scale and there's no way a real normal user could actually do this right and so but
this validation of the algorithms of the compiler Tech of the low-l system which is very novel and Jee will talk about
later was really important to building our system and doing so without being anchored on syntax I think was very good
for both Focus but also for the ability to iterate so once you get that you get to
the point of saying what about syntax right syntax actually does matter and so the three major approaches we
looked at are do we take an existing language like C++ or Swift or something like that do we do an edsl do we do a
new language and so when we were talking about this we came back to our core principles right our values our goals
which is that we want to meet people where they are and whether you like it or not AI developers but also most
software Engineers are all in Python right Python's pretty arguably
the most popular programming language in the world and so if you're coming from a python Viewpoint arguing with people
trust me I've been there to try to get them to switch to a different thing is a huge amount of work and it doesn't really go anywhere and so we realize and
believe we had to go with python and what that meant is that meant that suddenly a bunch of existing systems
were just off the table like C++ is not python Swift is not python like these things are not Python and so that really
allows us to focus our our frame what about edsls well edsls are super common
they're super popular and they exist for lots of good reasons they're relatively easy to implement we've had several talks at the conference about how to use
Python so you can you you can extract and build IR from Python ests and things like this means you don't have to build
tooling you don't have to retrain you can get to Market fast the problem is that they provide a really bad developer
experience right you don't get a debugger this really can't fit into the existing systems if you care about host
performance in generality Python's not there right at least not the level of performance that we care about and so
what we really want is we want a system that allows us to to innovate at all layers of this
stack okay well how about a new language again you know kind of where we're going with this but a new language has the
advantage of you get the best quality of result you can control everything you can invest in in things you can Target
CPUs with high performance which is quite important to us but what you need is a strong vision for what you're
trying to do you need a long-term commitment because the demo is easy but a production quality thing hard you need
to be able to pay for it you need to be able to track people you need to be able to have a big Target of developers that
makes it worth doing in the first place and so this is actually well known to be
ridiculously expensive like building a new programming language is not a simple thing that you should reach for as your
first outcome but as you know yes we wanted baby little Mojo to be built and
what we decide to do is actually do this and why well it's because it's the only way to achieve our goals to achieve the
best quality quality of result for AI developers and many other developers worldwide and be able to lift the
industry there are many point solutions that demonstrate many different capabilities but we really want to go beyond this and integrate and unify the
world and so if you come back to what we need to do we think that we have all the constituent ingredients here with a good
Vision we think we know what we're doing we also know how hard this is so I've personally built several major
programming languages that are used in production and have seen the entire journey and made many mistakes and have learned from them and so with full
knowledge we step into this and say okay let's do this so I'll give you the high level
design points of Mojo um as you know it's a member of the Python family over time it will grow into being a full
superet because we don't want to do a python 2 to3 thing anymore to python programmers as we said before it's
focused on systems programming high performance working backwards from the capability the speed of light of
Hardware definitely not working forwards from what python can do today also lots of hardware anything
with the program counter can apply um but coming back to this also and we'll talk about this a little bit it's about
unlocking the modular compiler stack and so instead of talking about the high
level fluffy stuff I'll introduce Jeff and he can tell you a little bit more about how it actually
works chis for the introduction so we are started off by De risking the core
hypothesis and we have an ml based compiler that is different a little bit from the systems that predated it and
we've proven that we can beat state-of-the-art the problem is that we've got like 50,000 lines of handwritten ML and
handwritten ml is like right once read never it's soose you have to write the
types every time you use an SSA value it's pretty hard to actually write incorrect code but then it's not
readable it's unmaintainable and the new people being brought into the company are like what what is this so we need
syntax we need a programming language for ML um why all ml well it turns out that
modern computers are getting really complicated modern types are getting really complicated look at just floating
points most languages give or take have a float in a double but M has things like floate E4 M3 F I'm sure it's useful
okay and that means that we need to have access to it there's probably a piece of Hardware somewhere on it that uses this data type and it's very fast um that's
just the tip of the iceberg em is such a vast ecosystem with many different kinds of Hardware targets domain specific
dialects and so on and we would like Mojo to be able to take advantage of all of that so we need syntax sugar for ml
in general but then how do we approach something like that well we start with the types in a programming language
types tend to be the most loadbearing element you need types to do computations on them after all so let's
start by focusing on a library based language that means that we write all the parts of the language in the library
and the good news is anybody can write libraries so this scales the e e of engineering to everyone in the world who
can write Mojo not just a couple of people who work on the language and that's really important because we don't want built-in types in the language to
be special or be more performant than what you can enable in the library because that bottlenecks performance and
the scalability of the system to the people who work on the language so we need to give Lang we need to give people
who use the programming language Library authors the same power as language Engineers um it turns out actually that
python has a really extensible type system You could argue that userdefined types in Python are actually much more
powerful than the built-in types like inter float and the reason is because python provides this kind of ability to
encapsulate type semantics behind Thunder methods which are really syntactic wrappers so let's just use
that in Mojo right we use a struct which is like a class but it's densely packed in performance to wrap an ml type and
then we use Dunder methods as well as class methods to wrap mlr operations and
what you get is any mlr type will work any mlr operation will work and so now
we have 1 plus 2 dgar to mlr op index. add the other important aspect is we
need to make sure that these userdefined abstractions feel native that they're zero cost so how do you how does moo do
that well it has a couple of bells and whistles to tell the compiler that treat this type in a specific way effectively
giving a built-in like experience and one of these is say always inline no debug which will always inline the
function no question about it and for a better debugging experience it nukes out all the debug info so you don't step
into a plus of an integer so if we put this all together just this pieces of basic types so you
have a simple while loop in Mojo well the par will then spit a bunch of source level IR right but then Mojo has
guaranteed optimizations that run all the time such as the always in liner and M and then this gets desugared down to
IR that is pretty close to what we would have written by hand and that's important because it from the get-go
provides a predictable IR gen model for the programmer and it helps us get an offramp from all the handwritten
ml but so it turns out we've actually discovered what ml really stands for uh
it's Mojo fire Emoji language intermediate representation and the best part is your
dialect works too so this is zero cost substraction around any ml so let's say you have a shape dialect with a mos.
type and it implements plus to concat and subscript to get dim well now you
can write shape functions in Mojo it spits out some IR that's been desugared to and then you can ingest this ir and
do cool compiler stuff like shape inference and the best part is all of the language tooling just works so you
get code completion you get doc generation you get syntax highlighting and even debugging if that's
relevant but ml just forms the bottom level of the language it's how we talk to the hardware it's how we talk to the
various dialects building on top of that requires high level abstractions and the way you do that in Mojo is
metaprogramming so Mojo needs to build hardware generality and the way we do that is with metaprogramming so you can
write a kernel without caring about what the vector length is and then say in this example ask the compiler to pick
one for you it turns out that meta programming is also pretty cool uh generics are nice code reuse is great um
and it allows to have scalable development so where can we look at for metaprogramming system well I actually
like C++ I don't know about you and C++ has templates and duct typing in C++ is
really powerful let's you write some pretty crazy generic code the problem with that is that the usability is poor
I think template error messages get better every year but there's still some room to go and it turns out that for the
kind of metaprogramming high performance programming needs C++ templates just aren't good enough so imagine you have a
tensor type it has a static or dynamic rank it has a static or dynamic D type it has partially Dynamic shape partially
Dynamic stride it gets ugly pretty quickly so it's not good enough and let's see if we can build something
better so it turns out once again python actually has really powerful meta
programming decorators can arbitrarily modify objects and you know return a function where there is a type and it
with full a reflection in Python is what enables all these crazy libraries such as the ml Frameworks like pytorch
Jackson tensorflow as well as things like Numba the problem with the python metap programming is that it happens at
runtime which means it's slow it's not going to run an accelerator and it give us zero control over the generated code
so the challenge for us is let's try to do it at compile time so that brings us to modjo parameters modjo parameters are
compile time values that form the backbone of the meta programming system so structs can have parameters these are
compile time values functions can have input parameters and then you can declare name parameter values with Alias
declarations so you can kind of think of them as being like C++ templates but they're a little bit different for
example in C++ you have using declarations for type ilas and conexs for declaration for compile time values
but em Mojo types are just compile time values and so aliases and say compile
time floats and compile time ins are the same thing the most important thing that
gives is that the meta language is the same as the actual language and Zig really Blaze the trail here by having no
distinction between the meta program and the actual program and Mojo we strive to ensure that almost any user defined type
and function can be used and called in a parameter expression at compil time and the way we do that is with an mli
interpreter that has a full memory model so to really drive this point home
we have an example here it's Phil a vector with a bunch of integers okay not too bad this function can be called an
either compile or runtime and you know if it was compile called a compile time you can even return a type instance and
this Vector has Heap allocation that is computed at compile time and then Ed that
runtime so when does this happen when do we do say instantiation of parameter values function specialization and
interpreting of code well it doesn't happen in the parser like in C++ so in Mojo we do parameter instantiation in a
process called elaboration and it happens later in the compiler pipeline what that means is that now Mojo needs a
IR representation for parametric code so in this example we have a piece of ir and we have a parameter in the IR called
value importantly this parametric IR is Target agnostic it's portable so that
means something like size of lives directly in the IR and it is resolved by the elaborator so this enables something
like split compilation like Cuda and perhaps one day separate compilation of generics like
Swift so the elaboration pass is an ml pass that performs function
instantiation as an IR transformation so in this piece of ir we've got two calls
the function print int with two different parameters they get Stamped Out into two new functions and the callers are replaced
appropriately um one consequence of a pass to do elaboration is that the
language is late Bound By Design uh that poses a couple of language design challenges but that means that you can
do cool stuff like autotuning where any parameter value can be autotuned I.E the
elaborator says oh okay width can be 2 4 8 16 or 32 let me just go have five
instantiations of this function and then use some benchmarking to pick the best one for you so this is how we
get the very bottom layer of Hardware abstraction where the programmer can write an algorithm and then we let the
programming language pick the best parameter for you and this also allows us to avoid
some of the performance problems with C++ templates for example let's see you have a generic function add and for
generality we pass the arguments by con reference passing it by const reference is fine for a large struct type thing
that doesn't fit nicely in registers like a string but then for something like an integer this ends up becoming
con reference to an INT which for a trivial type like int is not very performant and so if this function
doesn't end up getting inlined what ends up happening is the inss get pinned to the stack this is bad for
performance with late elaboration in Mojo we can have late Avi low ring which basically means that the source code is
not the same as the ABI and this you know makes language interop slightly more involved but it's not big of a deal
but what it means is that for a generic function like add in Mojo when the elaborator instantiates the generic
types it can then change the callon conventions of the types to respect the guarantees uh that it has so for a heavy
type like string it stays in memory it gets passed around as a pointer it's nice and efficient but for an integer it
gets passed around in registers in SSA registers and returned out as a function
result so that's just an introduction to how Mojo meta programming Works let's talk now about more how the coent
architecture works and some of the more unique details of that one of them is that the entire Mojo compiler stack is
driven by the orc jit from bottom to top and this gives us lazy OnDemand compilation so you don't compile things
you don't have to it enables responsive tooling and turns out that having a jit is important for something like autot
tuning and search and we get compiler caching at each stage of the pipeline
meaning that you don't need something like ccache to get code compilation
caching uh well we also use orc jit not actually
as a jit uh we use it to generate static code like static archives and executables and in the OR jit we've
built a really dumb but fast Linker that just takes a bunch of object files pulls out the symbols and slams slams them
together into a static archive for a Linker we do call into the system Linker was we mentioned before we have a
pre- elaboration portable IR but that also means that we can ser I this into mlr B code and that makes Mojo packages
architecturally portable a Mojo package will contain this parser level Source level IR as well as the pre- elaboration
ir and optionally you have the post- elaboration and pre-compiled code for various targets so what this means is
you can ship Mojo packages without source code with just the bite code the parser is able to take out this Source
level ir and reconstruct metadata like function signatures and type members and
so on and with optimized and pre-compiled code in the packages Mojo packages become like portable build
caches so if you're on a common system like an M1 Mac and you pull a Mojo package it will probably already have
the pre-built code for you so what is a compilation with a package look like well if you start by
importing a function from a package the parser goes and reads out the Declarations from the package it will
then lower into the full pre-abortion ir and the reason why you need the full parametric IR so that you can instance
the function again and so that the elaborator can call The Interpreter on pre-compiled code during elaboration we
don't reoptimize and ranti all the functions we just drop them out with the
post post elaboration IR into the ml module so that gives us lto and ml but I
mean ml is pretty far away from link time but it's a similar idea but we actually trash these pre-compiled
functions out of the IR before we go to llvm and that has some interesting implications so Mojo is a bit of an
usual probably slightly controversial user of of llvm so llvm is fantastic we love lvm we
love everyone here but it's uh got a couple of issues the most standout of these is that it's single threaded and
what that means is on a modern system like an AWS 192 core machine you get arbitrary slowdown for compilation
speeds you only use one core the other problem with lvm has got a couple of passes that don't tend to be strong
enough for our use cases and that are difficult to control and predict a lot of the stuff in lvm was built for
something like clang but in Mojo we'd really love to be able to autotune and unroll Factor the good news is the m is a thing
so let's focus on the excellent strengths of lvm lvm is great at stuff like scalar optimizations from inst
combine and other function level optimizations like Loop strength reduction we ended up disabling passes
like the vectorizer the loop un roller and even the inliner as well as a couple of the other IPO passes and the solution
is to replace them in ml where we get inass Paralis and push many of these
optimizations out into the library which is something Abdul will talk about in a bit so what happens when you get rid of
all the IPO passes well you get to use LM as a per function code generator this gives you full Coden parm at a function
level across the entire stack and what that means is that pretty much the entire Mojo compiler pipeline is fully
paralyzed except for the linger and the parser parser could be paralyzed one day um and that's really just the tip of
the iceberg and what we could fit into one presentation there's so much more to Mojo and there'll probably be more talks
coming in the future but for now I'll pass it over to Abdul to show you all how to write some fast code in
Mojo So going back to what Chris said at the very beginning we had a hypothesis
to begin with we want to write fastcode that's why Mojo was written to begin with we wrote things when m we've proven
a lot of the tech L's right things in Mojo and let's show the performance so
let's step back how does existing performance libraries how are they built
today well the short answer is whatever it takes to get performance there's no
you know style guide or anything like that that's usually um like maintained
and that also means like there's a lot of suffering because there's lack of tooling Etc so what people do is they
write things in assembly oh great you know but please don't it's not a super
productive programming language others build compilers as C++
templates and God forbid you know you mess like one of the sevens becomes a
six and you get some nasty error message others build C++ DLS that
generate asms others write python programs that
generate assembly others write python templates
that generate C++ templates that then you feed into client and these are not like research
projects these are production libraries that are used today you probably used one already these are you know by the
big companies and as a result you're kind of losing a lot of things you lose on
maintainability debugging tooling and becomes hard to develop and iterate on
these performance libraries and that's why they call them performance ninjas right you lock them in a room give them
some coffee and then they give you speed up and we don't want to do that we want
to reduce suffering the other thing is what happens is these performance libraries are pre-built and shipped as kind of you
know black box binaries and what that means is you've encoded when you built
ahead of time you've encoded all the hardware semantics tile factors Etc in
the library you've made it into a blackbox so other higher level uh things
in the stack like a graph compiler cannot reason about uh what the library is doing you've also encoded like
specialized patterns popular things like a resin up block or a Transformer block
into your library and what happens if there's a you know Transformer version two or resonet you know 53 you're kind
of screwed in in that domain there's other things like there's no consistent API there's Bloss there's
Bliss there's one DNN Etc and the distribution story is even worse there's
a 1 DNN and then there's a Zen DNN but then if you are on arm you have to use you know something else as well so we
want to solve all of these things and that's the reason why we built Mojo we built it to solve our problem of writing
high performance libraries and the first thing we want to make sure is the developer is
happy and they have all the tools that they need to be productive so rather than as kind of Chris mentioned a lot of
developers are not compiler Engineers you know they can write libraries they probably cannot go and you know write a
pass and so on so let's put optimizations in the library and I'll have some examples later on let's also
Leverage What computers are good at so when I was in grad school a lot of of
grad students were essentially you know grid Searchers they would just enumerate everything try 50 things you lock them
again in a room for a month and they say oh the best tile factor is six and four
and so on let's not do that let's use computers computers are great at these sort of things they can scan things you
can do smart searches and so on so let's use autotuning let's use algorithmic selection and let's build that in the
language and let's make sure that we have tooling to make these people productive debuggers how do you like how
do you debug the python template that generates C++ template that you know does something else it's it's it's hard
to begin with to debug C++ templates let's Al also build like a
language that's aware of like the 21st century so Sims are a thing so let's be
you know simd first let's have scalers to be a generate form of simd of simd of length one and make the simd parametric
let's also make the library the one we ship the standard Library you know have
first class support for simd types also multie is a thing so let's build
parallelism and asynchrony into the language as well and finally you know we can have
these nice things but sometimes people are like I want my assembly back or I
want to use the lvm intrinsic well all of this is built on top of ML and lvm so
you you can get any of the intrinsics that you want uh you can reach into them
you can also write inline assembly which is kind of interesting given that you're in a python you know syntax
language and you can Target any llvm backend so we're not like we're standing on the shoulders of giants so we're
leveraging all lvm and M back at infra to do that let's also not build a DSL so
even though you know some of our use cases is AI the programming language should be General I should be able to do
you know some operations in Mojo but then do the plotting uh through our
python integration and that requires a general purpose programming
language so one of the things that we made a decision on is let's make the you know kind of compiler lean and let's
move a lot of the optimizations and the infra to be you know kind of functions in the
uh in the moo Library so we use very limited number of dialects in M cor and
I know this is might be controversial so we're not using vector arith linal or
any of these dialects mvvm any of these dialects we're only using the lvm and index dialect and there's a bunch of
reasons for them sometimes they're not General enough sometimes they don't fit in our use case they bring in a lot of
code that we don't care about and there's like you know you know for the lack of better terms sometimes like cylic dependencies and so on and we you
know having a lot of the functionality in Mojo code means you could iterate a lot more quickly so let's like Implement
something like a vector dialect type of thing in Mojo So we have the simd type
and we have a function called reduce Max and in you know if the size of the width of the simd vector is one we're just
going to return the scalar directly if we're on x86 it ends up like there's a you know lvm has an instruction for
horizontal Edition or horizontal Max that's not great for uh Intel so we
could do a kind of a tree reduction thing but if it's floating point we use
a different algorithm and we call directly to an lvm intrinsic this is compared to you know
how the vector dialect lowers you're writing essentially the same stuff minus the special case for x86 in essentially
C++ code to allow our directory to the lvm dialect we could also do similar things
like transforms so as Jeff mentioned we disable the lvm vectorizer and instead
we have folks be you know kind of opt in to the vectorizer and we've implemented
a vectorizer in you know these like five lines of code so in one case we are
going to we've parameterized the function on the simd width and we're going to call it when you know for the
specific simd withth and the leftovers we're going to call the function with a value of
one so what does this mean to the developers it means that when you're trying to do an optimization when you're
trying to add a new feature or Target a new hardware the first thing is not oh I'm going to need to write a dialect or
I'm going to reach into table J the first thing is I'm going to reach into Mojo and I'm going to do experiments and
so on you can invent new optimizations weird ones incorrect ones or maybe even
point optimizations that only works in this function in this domain in this
context this is all fine but I care about performance I'm also a compiler
engineer but I ultimately I care about performance so let's look at the performance of Mojo So one thing that people anchor on
is the mandle BR set the mandle BR set you know we have a blog post that was
recently published but essentially at the end of the blog post you end up with this like 10 lines of code and if you
run this 10 lines of code you get 68 times 68,000 times faster than
Python and you can kind of see the progression you know you can look at the uh blog post uh you know after this
presentation there's a progression how to go you know to 90x faster all the way to 68,000
faster and but at the end of the day this is the code that you're going to see but nobody cares about mandal bro
you know you can there's ways to cheat in mandle BR we're not cheating here but nobody cares about mandle BR so let's
solve a hard problem so let's look at matrix multiplication so matrix multiplication has been studied since a
lot of us have been born there's also a lot more papers that were published this
year about you know matrix multiplication it's also difficult you know the problem is dependent on the
cache size and microarchitecture so also core part part of La Pac and you know
the ml system which means Hardware companies to go in the top 500 supercomputers they have to optimize
matmo or to be on the top of the ml perf they need to optimize MMO so a lot of
effort goes in to you know optimize maal and these libraries have been
developed for decades you know before some of us were born as
well but we also don't want to write you know the python template that generates C++ template that you know
maybe goes to python again and so on uh let's be principle so let's have a few
kind of core things that we want from our maal we want a single source of Truth we don't have multiple F we don't
want to have multiple files we want to have one implementation we want it to be as fast
or competes with state-ofthe-art you know even though you know we can read assembly and we can program C++
let's not do that let's write everything in Mojo let's make it you know fusible
and do fancy stuff support Dynamic shape work on multiple architectures Etc our
core hypothesis from the very beginning and here's what we ended up with so this is again a blog post from a
few months ago uh we're actually faster than this now but we can compare against the best in class on their Hardware so
we're 1.4x faster than Intel uh on you know skyl systems and this is fully
Dynamic we're not specializing on shape we're not doing prepacking we're not you know I wish we were doing tricks uh it's
easy to get these results if we were doing tricks but that's what we're doing we have no inine assembly and let's like
run the same code but now on Intel or sorry on AMD 1.6x faster do the same
thing but on arm or 1.2x faster in fact like you know our
implementation is about 2,000 lines of code this is a toy implementation but this is putting everything together the
interesting thing thing about this toy implementation is this is what the Llama moojo uh there's a public GitHub repo
that's using this and this implementation beats using this they are beating the Llama CPP
implementation that's public so with that we've validated our
hypothesis you can build you know portable uh performance libraries with
less suffering and with that I'm going to hand it off to Chris
good awesome so to wrap things up um Mojo is still early in development as we
talked about there's still a lot more that is yet to be done um one of the things we're doing that's uh I think pretty cool is we're developing this all
in public and so we have a road map you can go see what we're doing we have new releases that come out very frequently
now one of the questions we get asked all the time is does a modular open source anything right and so the answer
is comes in two fold one is yes we have Upstream stuff all of the time including tons of core improvements to ml um
apparently the The Interpreter that Jeff was talking about on Tuesday is very popular and so we can work on that and
so we're very like good open source systems from that respect Mojo itself we
I think we'll take a little bit longer but we want to start the Open Source process later this year and so we'll start working on that now I expect that
to take some time because we want to make sure that we get the core design really right and not everything is best
done with designed by committee but we really want to see this thing scale and go and have a big impact for the
world so coming back all the way to the beginning we talked about Ai and the AI engine and this kind of stuff now we
don't have time to talk about it today but the cool thing about what Mojo means for the AI engine is that you can
actually tackle these heterogeneous compute problems because you can finally scale across lots of different hardware
and this is really cool don't have time to talk about it today if you're interested we have a keynote at the nurs
conference later this year where we'll talk a lot more about this in detail so that I think that's the end of
our talk and we're very happy to take any questions if You' like to check out Mojo you can go to the web page read about it download it and use it today
thank [Applause]
you thank you Chris Abdul and Jeff are there any questions you have miks in the
LA good time yeah thanks um thanks
for test test thanks for the great talk my question is I haven't seen anything
about uh GPU offloading in in your slide is that in in plan or what what are you
uh intend to do with it so there is one bullet point actually on that there's so much more and yeah Mojo does actually
support uh like GPU offloading and split compilation like Cuda but it's something that we did not talk about in the
presentation and sure would Shar like to talk about in the future yeah thank
you um hi um you mentioned that uh you don't need to use ccache because um you
kind of mentioned that like can you elaborate that a little bit like how you guys dealing with caching so it turns out that ml has a nice serializable
format called bite code and but bite code provides a predictable hashing and so we can use mlr bite code as the form
to hash and cache compiler Transformations across the stack okay thank you so we also didn't have time to
talk about but there's a whole distributed cast backing this thing and there's a whole bunch of fancy stuff put
into it hi uh how are you doing the autot
tuning is it offline or is it dynamically online and how do you define the objective function for the search
yeah so you have a choice you could do it offline or online if you compile to like file you've done it offline uh the
objective function right now is something that the user provides because it's data size dependent you know
Hardware dependent and so on so it's up to you to Define that we do provide a
benchmark module so that it makes benchmarking a lot simpler uh and that
allows you to do that yeah uh if you're doing it online how do you control for like variation in data or do you rely on
so The Benchmark library that we provide has you know good uh like you know number of iterations and
so on until you get stability and so on so it it handles that Al so it's not actually in production autot
tuning we use autot tuning today so I don't know what for that yeah so I mean
there's core capabilities then there's future stuff also I mean one of the things that it's designed for but we haven't actually done is the like send
the IR to an fpga and do evaluation remotely and then pull it back and things like this or or a simulator yeah
exactly yeah a great talk uh there was a point
in the slide about uh optimization in the providing optimization in the library as as opposed to the compiler
are there any uh maybe I misunderstood this but I
from my understanding it it's possible to come into like performance pitfalls because C++ has uh built-in likely built
in unlikely and then you can it's really easy to misuse those and end up in a
situation where your code is slower than without without these kinds of annotations so my question would be what
happens if a user provided annotation conflicts with something that the compiler would also have done at the
same time uh well so from a compiler design perspective one of the things jefff was talking about is we've removed
not all but a lot of the super unpredictable things in the lvm optimizer so our goal is to give full
control and predictability to the programmer which is very different from the make spec go fast
kind of approach to compiler design and what that does is that gives you the ability to then go and design Library features that do things like you know
you can Abdul you can talk about some of the crazy stuff you've done but what's also important is that um we have these
abilities to say please vectorize this Loop please unroll this Loop and so on but not everyone who's writing say
application code is going to think about vectorizing every single Loop and autot tuning every other loop so what's important is that we provide control to
the users who care but also provide a default called experience that is like
good and optimal and the compiler does its best but the important thing is what the user says will always take precedent
and that's how you get control sometimes a compiler does things and you end up with code that says you know optimize
you know compile the section of code with Dash o z type of stuff and you kind of want to opt out of compiler
optimization because it's interfering with how you laid out your code um uh
are there any plans I I have a followup question sure come after uh last
question please uh hi uh so you mentioned that uh you only use two dialects uh in Mojo llvm and um index
dialect two Upstream dialects two up okay so so so you don't use other things like f fine and stuff which means that
if you want to use Hardware specialized libraries then the programmer has to do
different tiling for ampere versus Hopper versus Volta and so on so isn't
that just pushing the burden out from the compiler and high level stuff into the into the programmer you're going to
that's exactly what that is very Hardware specialized performance libraries and then people who write this
thing would have to understand the architecture really really you know well I think the thing is that they're more
likely to understand the architecture really well than the compiler engineer right the compiler engineer has
to have two things writing C++ for on CPUs that Target gpus this is like okay
I'm a Cuda programmer I'm laser focused let me I see the trade yeah so that means that the people writing high
performance libraries for very specialized accelerators they need to be experts at those accelerators right okay
right so they need to be expert in one area not two areas so the go give a kernel programmer superpowers okay right
but um but that's that's that's our approach to it as Jeff talked about Mojo can talk to any dialect if you want to
you can use aine in Mojo we can plug and extend the system with dialects as well so so that's always an option okay so
that a conscious decision is what I'm that's the that's really the conscious decision you're making is that you going to get experts to do the the performance
library and they will just work well so so this is the thing design
it colonel libraries don't scale because of the magnitude of the problem that and the cross product of all the different
Integrations and all the stuff that chronal libraries struggle with but there are more Colonel programmers and
performance Engineers than there are compiler Engineers by far sure right and so and okay so it's really about
enabling the the talent that actually knows how to do all this kind of stuff versus having a compiler engineer in the loop that becomes a bottleneck okay
thanks and we'll be around as well like throughout the conference so feel free
to yank any of us thank you Chris Abdul and Jeff let's thank the speaker
again


----------

-----
--14--

-----
Date: 2023.05.03
Link: [# Jeremy Howard demo for Mojo launch](https://www.youtube.com/watch?v=6GvB5lZJqcE)
Transcription:

but instead of telling you all this now
I'd love to introduce Jeremy Howard who
will show you how Mojo Works in practice
[Music]
thanks Chris you know I realized it's
been 30 years since I first trained a
neural network and to be honest I
haven't been that satisfied with any of
the languages that I've been able to use
throughout that time in fact I
complained to Chris about this when I
first met him years ago and Chris has
been telling me ever since don't worry
Jeremy one day we are going to fix this
the thing that I really want to fix is
to see a language where I can write
performant flexible hardcore code but it
should also be concise readable
understandable code and I think that
actually Chris and his team here have
done it with this new language called
Mojo Mojo is actually a super set of
python so I can use my python code here
check this out I'll show you what I mean
so here is a notebook right but this
notebook is no normal notebook this is a
Mojo notebook and
by way of demonstration because this is
the most fundamental foundational
algorithm in deep learning we're going
to look at matrix multiplication now of
course Mojo's got its own we don't need
to write our own but we're just showing
who we can actually write our own Hive
performance matrix multiplication let's
start by comparing to python that's very
easy to do because we can just type
percent python in a Mojo notebook and
then it actually is going to run it on
the C python interpreter so here's our
basic matrix multiplication go across
the rows and the columns multiply
together add it up let's write little
Matrix and a little Benchmark and try it
out and odia 0.005 gigaflops that's not
great how do we speed it up well
actually believe it or not we just take
that code we copy and paste it into a
new cell without the percent Python and
because Mojo is a superset of python
this runs two but this times it runs in
Mojo not in Python and immediately we
get an eight and a half times beta
now there's a lot of performance left on
the table here and to go faster we're
going to want a nice fast compact Matrix
tape
of course we can use the one that Mojo
provides for us but just to show you
that we can here we've implemented it
from scratch so we're actually creating
a struct here so this is nice compact in
memory and it's got the normal things
we're used to done to get item and under
set item and stuff you don't expect to
see in Python like Alec and like simdi
and as you can see the whole thing fits
in about a page of code a screen of code
so that's our Matrix
and so to use it we take copy and paste
the code again but this time just added
type annotation these are matrices and
now it's a 300 times better suddenly
things are looking pretty amazing but
there's a lot more we can do
we can look at doing if our CPU supports
it say eight elements at a time using
simd instructions it's a bit of a mess
to do that manually there's quite a bit
of code but we can do it manually and we
get a 570 times beat up but better still
we can just call vectorize so just write
a DOT product operation call vectorize
and it'll automatically handle it on
simdi for us with the same performance
speed up so that's going to be happening
in the innermost loop we're going to be
using simdi and in the outermost Loop
what if we just call paralyze this is
something we can do and now suddenly the
rows are going to be done on separate
cores
for a 2000 time speed up so we've only
got four calls going on here so it's not
huge if you've got more cores it'll be
much bigger this is something you
absolutely can't do with python you can
do some very very basic parallel
processing with python but it's
literally creating separate processes
and having to move memory around and
it's pretty nasty there's all kinds of
complexities around the global
interpreter like and so forth as well
this is how easy it is in Mojo and so
suddenly we've got a 2000 times faster
matrix multiplication written from
scratch
we can also make sure that we're using
the cache really effectively by doing
tailings so doing a few bits of memory
that's close to each other at a time and
reusing them tiling is as easy as
creating this little tailing function
and then calling it to tile our function
so now we've got something that is
paralyzed tiled and vectorized for a
2170 times speed up over python we can
also add unrolling for a 2200 time speed
up so vectorize unroll is already built
into Mojo so we don't even have to write
that now there's a lot of complexity
here though like what tile size do we
use how many processors what's in these
size all this mess to worry about and
each different person you deploy to is
going to have different versions of
these or have different memory they're
going to have different CPUs and so
forth no worries look at what you can do
we can create an auto-tuned version by
simply calling auto-tune so if we want
an auto-tune tail size we just say hey
Mojo try these different tail sizes for
us figure out which one's the fastest
compile the fastest version for us cache
it for this individual computer and then
use that paralyzed tiled unrolled
vectorized
for a 4164 times better so this is
pretty remarkable right now it's not
just linear algebra stuff we can do
really iterative stuff like calculating
mandelbrot so we could create our own
complex number type and it's going to be
a strat so again it's going to be
compact in memory it looks like
absolutely standard python as you can
see multiplying subtracting using the
operations
and to create the mandelbrook kernel we
just take the classic mandelbrot set the
equation iterative equation and pop it
in Python here
and then we can call it a bunch of times
in a loop
returning at the appropriate time to
compute the mandelbrot set that's all
very well and good did it work it'd be
nice to look at it so how would you look
at it would be nice to use matplotlib
oh no worries every single python
Library
Works in Mojo and you can import it
check this out plot is import the python
module matplotlib NP is import the
module numpy and the rest of it
this is actually Mojo code but it's also
python code and
it works and I don't know if you
remember but Chris actually said the
mandelbrot set is 35 000 times faster
than Python and that's because we could
also do our even faster version where
we're handling it with simdi and we can
actually create the kind of iterative
algorithm that you just can't do in
Python even with the help of stuff like
numpy this is something which is really
unique to Mojo
so we now have something here which is
incredibly flexible incredibly fast can
utilize the hardware you have no matter
what it is and is really understandable
to python programmers like you and me I
think finally we're at a point where we
are going to have something where I
actually enjoy writing neural networks
wow how awesome was that

----------

-----
--13--

-----
Date: 2023.10.20
Link: [# The Current State of the Mojo Programming Language](https://www.youtube.com/watch?v=4f2JH_sK17o)

Transcription:

right all right hey everyone first stream ever thanks for
joining how many people we have here okay 26 nice can everyone hear
me say yes in the chat if you can hear
me
no
hello okay cool wow the chat's delayed hey everyone thanks for
joining thank you to everyone that's been following me over the past uh few years um really appreciate your support
uh this YouTube thing has been been awesome um yeah first live stream we'll
see how it goes all right so Mojo uh Mojo I I did a
video about it probably I don't know six months ago and it was in a really incomplete
state it wasn't ready for prime time at all uh the development of Mojo was kind of
it seemed to be focused on speeding up these this number crunching right these these low-level uh Matrix
multiplications that are so that Ai and machine learning are so dependent on and
obviously they did this amazing demo uh if you've you all seen it where they demonstrated like a 60,000 times
improvement over python for matrix multiplication which is incredible but
then when you go and try the language it's kind of restricted to um
a uh a jupyter notebook so you can't actually you couldn't actually at the time download the SDK to your local
machine and kind of play with it on your local machine uh a few months later they
released an SDK but it was Linux only and I tried it so I grabbed an AC ec2
instance and tried running the SDK locally and I could not get it to work
and I asked for some help and it turned out to be it was blamed on I guess um
not having enough memory on that machine uh but I was a little bit skeptical of that long story short they released a
Mac version a few days ago and so I gave it a little try so I wanted to share what I found with all of you and maybe
kind of test out some more things that I haven't tried so
yeah um for those of you that don't know about Mojo just taking a step back a bit
uh the goal so python is the king of the data science ecosystem
and pretty much Undisputed but there there's a few problems with python um
one is that python is slow right I don't think anyone's going to dispute that the second is and that's kind of related is
because Python's slow and machine learning and um and data science are
computationally intensive that means a lot of the low-level operations are written in C and then
hooks that are provided to these python apis that data science that data
scientists call in their application code and so there's there's two problems
with this one is you have to decide okay which parts of my program are or which
part of my stack is uh is performance critical right so
that's a a decision you have to make and then the second problem is and you can argue that you know my application code
the stuff that's actually running in Python is not performance CR critical enough for kind of the slowness of
python to to uh be a detriment to the the program because all the all the
computationally Intensive stuff is in the in kind of the C libraries um and there's two problems
with this so one you have to decide where that line is right you have to decide
okay this part of my program is not computationally intensive and this other part part of my program is and getting
that drawing that line is not really it's it's not always a clear decision um
and the second problem is your your your stack is not isomorphic so that means
it's if you have a a data scientist that's only worked in Python they're
probably never going to realistically they're probably never going to be able to contribute to a code base that's
doing the low-l computations um and so yeah that's the other problem
Mojo aims to fix both these problems by having a language that is performant no
garbage collection uh runs compiles the machine code runs on bare metal yet has
is a super set of pythons so you can actually technically copy and paste python code into em Mojo file and it
should work that doesn't work right now quite yet there is a python integration that maybe I'll get to but um that's
that's the long-term Vision so now that we've set the stage um emac yeah okay so
one of my gripes with the the current release uh is there's only a vs code plugin for CeX hyting so I am relegated
to using vs code I have the Vim plugin so I'm not too feeling too out of the water but um yeah we're going to go with
it um async yeah I haven't done acing stuff yet
that's we're not going to get too in depth in this one um we're g to kind of
You could argue Mojo is like a the main value or the main value prop
for Mojo is this low-level simd computation so you have arrays of
numbers and you're doing matrix multiplication is can be optimized at the CPU level by
m multiplying many numbers together all in one CPU cycle that's kind of the basis of of a lot the concept of simd
and something that Mojo leverages um at the low level to to speed things up that
is not a world that I live in and probably most of us live in but I I'm kind of looking at Mojo
from the perspective of an a general purpose programming language and that's not what that's not what modular is
marketing this toward right they're marketing it they're uh let's look at the website
um
see yeah the future of ai ai development starts here they're not even trying to Market this as a general purpose
language but if it becomes a good fit for AI it's hard to
imagine f not not starting to adopt it for other things too right if the vision
comes to fruition it's reasonable to assume that you could do anything with it um it may start out as many languages
do in kind of a niche Community like AI I don't know if you'd consider that a niche Community but
um yeah so all the marketing material is kind of geared toward AI but we're looking at it through the lens of an
average average Joe developer like me um
uh memory safety so yeah I didn't touch on that so the there's no garbage
collector um it aims to have rust likee semantics for borrow checking so you'll
see in a minute uh but anyway yeah it's it aims to be Memory safe I don't know
if there's kind of like rust has interior mutability
for things that are memory safe but will not compile as far as the borrow Checker is concerned I don't know if there's an
analog to that in Mojo I guess we'll have to see um if even if there is I don't I'm pretty sure it's not
implemented yet I could be wrong about that
um oh Def and function yeah we'll get to that in a second um thank you
Houston Bo yeah I just I just got it yesterday um that seems to be one of the main ways to
support the the lepos team so it was an easy easy decision um yeah check out the
lepto store if you want to support the the lepos project um okay yeah so why
don't we get started so let's look at the installation instructions for on a Mac um I think they're
similar on
Windows
okay uh where are
we okay download
now okay so the way this works I believe is modular has a home r
package um and the modular Homebrew package is
like a package manager for modular so you'd install the modular package manager whatever you want to call it and
then you you would install the uh you'd use modular to install Mojo and there's
kind of a weird step here I don't know if they fixed this there was an issue oh I see I think they did fix it uh but
basically you run this Cur command to get the modular or you kind of you download a script and the script
adds like a home RW repository and uh and then it does a mod or home brew install of the modular
package manager and then you run modular install Mojo So check that out
okay okay yeah so the script presumably has like a home
brew or Brew update in
it at the chat while I'm waiting
do they promise future compatibility with python yes that's my understanding they have a a narrative around that
already you have to explicitly import like a certain package and then you can use like numpy which is if if you're not
familiar with that's the canonical kind of um package for doing multiplication
matrix multiplication in uh in the python ecosystem
um new language every week uh is this just another way to that
they crap on devs I don't know their logo suck I think it's a pretty good logo I've seen I've seen far worse
logos um the the U logo is by far like say
what you want about the framework but um this is the most awful logo ever sorry
if anybody in the U team is on the on the stream but but this is just no
Mojo's Mojo's not moo Mojo's at least C tier or B tier for logo possibly a tier
yeah that's my opinion okay all right so now we'll do modular
install Mojo So now we've uh yes I I I already
have it I'm just kind of walking through the installation steps so um yeah so
let's just let's just do
modular update I don't know why it gives a URL
there updates okay well yeah so that's that's what you do modular install Mojo
that's all um and so now we have a repple um you can go you just do Mojo I
have a directory here Mojo test we can just do Mojo
and then we get a repple similar to what you get with python right there is a and it actually says outright right here and
I miss it the first time and I'm like why is this not working you have to press you can't
press enter once to execute a line of code you have to press enter twice so if
I do print hello like I expected hello to be output
right after pressing enter you have to press it again then it outputs like if you don't if you if you missed this
explanation here and I'm ambivalent about whether that's a good decision or not I I can kind of see why they did it
um I think there's issues in in like the python repple where you know
you if you want a new line if you want to add a new line to the existing command you have to I think you have to
hold down shift or something I don't know this this makes executing a multi-line command in the repple a lot
easier but it carries the risk of confusing people thinking their installation is not working when they
first start out so something to watch out for um yeah okay
so basic basic operations uh and we'll move to the ID
uh in a minute but okay 1 plus 1 equals 2
right uh variables AAL 2 Bal
4 uh a I think if you just in P in the python reppel this would actually output
to the console I forgot if this actually does oh it does okay so it gives you the
type of A and B and Mojo has your standard types in
float string so on and so forth um what else
can we do from the reppel um yeah let's move into the ID
actually um okay so there is a a again I mentioned
this a little bit earlier but if you're joining later you missed it the as far
as I know the only real way to get syntax highlighting for Mojo is via a vs code plugin so that's how we wind up
here if that wasn't the only option I likely would not be using it so you can trust that
um yeah we're not going to break out emex or Vim today unfortunately oh nice look at the
um so yeah pretty easy to find to search for
it I already have installed so that's it there um I do not know how to use vs
code like I want my
primaries explore there we go command command shift e
right okay uh basic stuff so I think right now if you so I have I have this
file test. moojo and then I have my terminal open down here that'll use to run Mojo test.
Mojo yeah it doesn't Define a main function I believe right now you have to define a main function it's not like a
python file where you can just throw random stuff in the file without a main function and it'll run just
fine so we're going to Define function Main and
print hello
okay and I'm trying to remember the there was a shortcut for control
control TI okay moving back and forth between the editor and the terminal control TIY got it chest.
Mojo cool and we get what we expect now functions so I mentioned Mojo is a
super set of python we can do your standard def uh do thing well we'll make an add
function A and B and don't forget your tabs your
indentation uh return a plus
b add two and
five okay control til turn oh oops Yeah so normal normal
python syntax applies forgot a call in there F the parse what what is going
on provide a Mojo that's right this is
new wait can I not call do I have to make this a function is
that what's going on and
then I tried the python syntax last time I tried Mojo and it it seemed to work
fine I didn't try it since I downloaded the SDK so um oh yeah specify return
type use an arrow to specify the return type and then you still have to have the colon that threw me off when I was
playing around with this I was like is it colon return type and then nothing after that and yeah use an arrow like
rust and and then but you do need the colon at the end of that function signature and looks like we're in better
shape now so I don't know what the story is with if I make
this def can I do def here maybe
yes okay so that's what's going on so maybe it seems it seems like maybe you can't
call a function defined with def in the python style from a
function defined as FN in the Mojo style which makes sense because so the zooming
back here so again the Mojo the Mojo mentality is that you have your python
code you start out by copying and pasting your python code into your rust code or rust into your mojo code
and it works out of the box nothing no changes that's the vision but with the python syntax
there's an upper bound to what optimizations you can apply to that that code because obviously you don't have
keywords like borrow and uh you don't have types necessarily so all this is
going to add a runtime penalty and then you would slowly migrate to the Mojo syntax
which the and you can there's an example of this right here right where there you
can add some Mojo syntax to functions that are defined using defa but I think
there's there's an upper Bound to You can't um there's a limit to the the Mojo
kind of syntax that you can add to the functions defined with defa and there's also a limit to the optimizations that
can be applied to that function is is as understand it so um ultimately you'd
you'd wind up changing this to uh function now can we here's a question
can we call a function defined with FN from a function define with def I
actually don't know looks like we can
okay okay what now so this is a a simple function um any uh just look through
comment or uh chat here yeah difference between function and Def I I kind of covered that
uh how do you use Mouse less use the Vim key bindings um yeah there's a a Vim Vim key
binding plugin for vs code if you need to stick with vs code I prefer neovim and emac or emac
one of two um but yeah I went I went cold turkey I went straight to to vim
and then Helix briefly and then to emac or yeah emac after that but probably an
easy I had the luxury of of learning these while while not having a full-time day job so I imagine if I were doing
that I would probably learn the bindings or start learning the bindings in in vs code or I was a jet brains
person um and then kind of slowly learn the bindings and then maybe ultimately
switch to to Vim or or emac or Helix um try accept yeah I didn't
I didn't Venture into exception handling yet my
understanding is that that's implemented but I don't know it's not maybe I'll take a look at that uh at some point but
yeah probably not today um function set a function raises after
okay compared to something like Nim yeah that's a good question how does it compare to something like Nim I I Nim is
something I've been wanting to explore and just not have the time it seems really elegant and and I think they have
it seems like they have a pretty good narrative around performance and memory safety I was trying to read about kind
of the default uh way of memory management and I didn't fully understand it um but I heard I don't know if it's
Nim or I'm conflating or confusing it with a different language but there's some Lang some bleeding EDS language
that they were going to add Rusty borrow checking too and this is part of the reason I'm interested in Mojo is because
I actually like I actually like the python syntax and using tabs to delineate Scopes I
personally love that I know many people hate it I also think the rust borrow
checking semantics make a lot of sense and it's a small price to pay for not
needing a garbage collector um things get messy when you need to do interior mutability that that
things are yeah that that's kind of tough but usually you don't need interior mut
ability at least in in libraries you probably do but in if you're building a web application I've never run into a
case where I needed interior mutability and so for use cases like that it makes
a lot of a lot of sense if you're if you're there was a video about this um if you're working with
graphs that kind of surfaces the the pain of the borrow Checker because you're you're um you're forced to use
interior mutability basically if you need to modify the the values in the the graph nodes anyway that's a tangent um
okay uh what's next open up my notes Here main um okay we did that okay to
how we doing on time here 25 okay um I mentioned this has rust style
borrow checking so but the difference is rust by default function parameters will
be owned so they'll be moved if I were to call if this is a rust program and I
called ad and if it was an integer it would be copied but forget about that
for a second if we're if we're calling a function with a and passing in a a structure of some
kind it's going to by default move that to that function and that variable will
no longer be usable from the call site or in the function that called it
uh Mojo kind of flips this on its head and makes borrow the default so and the
other thing the Syntax for this is much different so if I want to uh let's make it this is a good time to demonstrate
strs I guess so um struct
thing and then we have I'm trying to remember I can't remember the syntax right
offand um uh word
and then I don't know um in and then we do have to there there's
ways around this but let's start with this um you do have to define a default
it does not generate a default Constructor for you like a lot of languages do so you'd have to do
function I think it's the syntax is I fully anticipate making a bunch of syntax mistakes uh so bear with me but
um um and does this take self I can't
remember and then um
int and you have to do self oh yeah it does take self I believe that's similar to
python uh word goes word and then self.
num equals num so this is if you don't add it
annotate the struct with anything this is what you have to do let's make sure this works why is
this I'm doing something way
wrong all right time to bust out the docks language Basics that's pretty much
where I'm at okay oh do I need V I need I need let I
think is it structures yes I need letter VAR okay uh I'm going to do VAR so just
like um it let means the variable is not
mutable VAR means it is mutable I think what's the analog I guess the analog of
that is Javascript or typescript yeah and then we don't need
the commas I believe what's wrong with self oh inout okay so inout means inout
is the equivalent I think of a mutable reference in if we're in the Russ
world so this is the equivalent of doing uh at mute that I
think um I just keep I don't know how many of you are in the us but we have a
restaurant called In-N-Out that sells Burgers it's a fast food restaurant every time I see this
word I think in and out and it makes me hungry but uh yeah that's that's a
separate story um so let's try to instantiate this
uh and I believe we can just pass
um a string
literal and I forgot what it will do if we just try to print that's that's not g to let me do
that or from thing to string okay I don't know how to print
the entire struct I'm sure there's a way to do that but let's just print the individual
fields
okay let's try that out two yes okay that worked so that is
how you define a struct pretty straightforward I believe there's no I I
tried I wanted to do an example with a a graph or a tree or something um yeah
that's right um and I don't think recur C of data
structures are supported yet so if I wanted to do left and make
that a type thing I think that'll is it letting
me okay I'm not sure about this
let okay maybe that's the r the issue I ran into so maybe recursive structures are
supported because I'm not getting a compile time error can I do self. left
equals thing um well I would need it to be an option
I guess because I yeah let's save that for later because
I I haven't ventured down that path yet um there is a way I believe to get
this to generate the Constructor the default Constructor automatically um oh okay Houston
Boba so if I if I do
this um and then this returns a string
right I can do uh just for for testing
sake I can do
this self. word
no attribute two string oh well I sorry I can just do
this um so if I do so now if I
print print thing will that work
can't wait a minute what why is it complaining about
ad colie expects two input parameters but zero are
specified I don't know what's going on
to print full struct H
yeah thing to uh thing that oh I
see like that yeah I don't know
um okay uh let's go back to the there's an annotation I forgot what
it's called
it's uh value I think you can add an annotation called value on the
struct and that'll autogenerate this stuff see if that works
Yep looks like it does so so it makes it in cotlin the
equivalent is like what's that called a a data class or something like that so
if you do at Value it'll Auto automatically generate the Constructor and I think it generates some other stuff too because you you there are
situations where you have to write a move Constructor and a copy Constructor if if you familiar with C++
you'll know what a copy Constructor is but basically they're functions that allow you to explicitly specify the
logic that gets run in in these certain situations where things are moved or copied but let's tried passing thing to
a function um and then we'll see the kind of the barring
semantics oh is this the reason why that might have been the reason I
I'll try it later but
uh we'll do do something and then thing
thing uh print
thing word okay so we're printing thing. word
here let's called do something and that's pass thing into do something and
that's just going to print hello so we should see yeah we see Hello twice
right now let's let's try modifying thing let's do
thing. word equals uh
World immediately we get a compile time error expression must be muul in
assignment so let's we could do in out
here we could go the burger route um but yeah we still need to
Define in main Ju Just this is just like rust instead of let we need to do VAR
and then I think this should work right yeah and so do something changes the
world and that that change apply we know it's not copied because that change still has effect when we call
print on in the main function yeah so that's you know let's
try I mentioned default is borrowed
so yeah you would get you get an error whether you have that word or not obviously
and then the other one is owned so in this
case thing I would expect thing. word to
be that's interesting think was clear varb but never mutated consider switching to let
so is that a that's a warning I guess and we get so it it it looks like
it okay so it copied in Rust you would get an
error right it would it would you get an error on on this line printing thing.
word and you would say ownership is moved in this call to
do something so instead of it seems like instead
of it's moving the thing to do something but as it's doing that it's copying it
and keeping it in the main function I guess is what's happening I don't know if anyone if anyone knows exactly what's
going on here let me know um yeah that's
interesting but let's try I know there's this other there's like this carrot thing that I didn't fully
understand okay so this is so I think this makes it so it's not not copied if
you pass something to an owned function if if anyone from modular is in the chat please feel free to set me
straight here I don't want to miscommunicate but seems like when you put the
carrot now it's moved to do something and not
copied this is interesting so the the the function can specify that it needs an
owned type or it needs an owned value it doesn't care what the original
caller how the original caller gets it that own value so then the caller has this the
more I think about it this kind of makes sense because yeah the caller can decide
whether it wants to copy and in Rust there's a there's a there's a pattern where you do this explicity right you
you'd clone the thing before you pass ownership to the function and and then
you you could use the Clone in the
function this this kind of this seems more concise it's just the it's just the more
concise way of doing uh you know let Thing 2 equals thing. clone in Rust and
then using thing two down here that that that's the way I'm
understanding it that could be wrong but if that's the way it works I actually really like that I think that's cool
cuz this gets verbose and there's it seems like at least in the there's a lot
of scenarios where you need to do that or need to leverage that pattern so having a concise way to express it might
be nice um okay what's
next Fearless concurrency I haven't deled into concurrency I I I'd be
shocked if there wasn't a narrative around that um
yeah okay I think we're going to look at strings
next and when I first when I tried Mojo out
last time I couldn't even do what I'm about to do now so things are clearly progressing uh how we doing on time
we're got 20 minutes
okay I'm going to write a paland drum Checker um yes it's a silly problem
nobody cares about writing a paland drum Checker but it's a good way to demonstrate kind of the the string string
functionality so we're going to do let Auto equals Auto but Hannah equals Hannah
um there's a kids book with those two names uh that I remember from from
childhood um uh thing equals
thing and then so we want to our palum Checker is going to return true if it's
if it's a palindrome false otherwise pretty simple um is
palindrome
Auto
oops okay and we should get true true false
right so function is palindrome and it's going to take a
string and return a
Boolean we need half the so the idea here um I think most most people have
probably seen this problem before but you iterate up until like half the length of the
string and there's this corner case where it it works slightly differently
if the number of letters in the string is is even and uh let's do one with an
odd number of characters um I don't know Ava I think that's a
name right just to make sure that case is
covered and so you iterate up to half halfway through the the string but if it has an
odd number of characters you don't have to obviously that you don't have to check that middle letter because it's
already we already know it's a pandrum so you divide the length of the string in half and if it's a fraction
you can just take the floor of that because the only way it was it would be a fraction as if it's an odd number of
characters and you need to check up until the middle character so it's it's an example in the C++ world
it's an example where casting from a float to an INT is actually desirable
because you just chop off the the fraction anyway
um half length and this is going to be a float
64 for some reason the default type that comes out of a divide
is float 64 it's not a regular FL I I don't know the story behind that
um and we're going to do a for Loop we have range kind of like we do in Python
and we're going to go to from zero to half uh and then casting to an in so
casting I think casting and python would be like casting and python let's exit out
of here t-x
see this is python got to name your your windows here
oops so five yeah that's how you cast in
Python so that I'm pretty sure that doesn't work in Mojo let's run Mojo
here um so the equivalent of that would be what ins
2.5 yeah cannot construct int from flip literal but if we
do can we do 2.
2.52 in yes but it doesn't output
anything a equals
2.5 and then a out2 do int what about
that what why is it not
casting okay well that works but
it yeah anyway okay so casting is2 int instead of int and then put the thing in
the parenthesis right
so we're going to do so we can index into a string using square
brackets if a of I equals not um a
of length of a uh minus one and then minus I
right will return
false okay and then if we get to the end that means it is a palindrome so we'll
return true super simple why is this giving me
expected in after Target modifier
what oh yeah and this needs a
colon that looks right cool okay so you can I'm I I don't
think this was possible before I could be wrong um but yeah you can actually
start kind of building stuff now um obviously there are things that are not
implemented yet like glaring a mission right if if I wanted to make a
dictionary that is not going to work cannot emit dictionary literals yet um
and as far as I understand it there there are there's no analog to dictionary in the Mojo world yet so
that's a pretty big damper on for a lot of algorithms I think there is a hashmap
but the syntax is nothing like python dictionaries um and the syntax of python dictionaries can be pretty
convenient
um what else okay so we could do we could talk about simd we got 10 minutes any
questions about this obviously we haven't haven't gone too deeply into
Mojo there's a lot more to cover this is kind of like a surface level check-in on
how development is going and it it seems like there's definitely progress been
made but it does seem like the team is definitely optimizing for that kind of
Matrix low-level Matrix Matrix multiplication world that a lot of us don't live in that that probably makes
sense um I have high hopes for Mojo um I
don't know if you guys know about this but uh they have a pretty significant backing in terms of investment
so it's not telling me the the funny amount last last I looked they have 30 million in funding so I I I suspect that
gives them a pretty substantial Runway um so it's kind of hard to
imagine this going south anytime soon so I'm really excited to see how this develops if I were to cover something
else let me know what you want to see um do you want to see more like matrix multiplication stuff
um yeah I don't know do you want to see kind of how the language progresses as they they
Implement par as I get parody with python functionality and syntax do you want to see more of that like Elite code
algorithms um yeah let me know what you want to see let me just take a quick look at at the chat here sleet
um yeah compare
ah yeah that's probably true radar
okay um the take a look at the manual quick
[Music] here kind of the bread and butter of Mojo is simd
so and I haven't delv too deeply into this but essentially simd means
simultaneous instruction multiple data I believe and the idea is and every every
processor has or modern processors have some kind of simd functionality
where you can put an array of a certain size on a register and then another
array on another register and do a multiply of those arrays in in one go in one cycle but the sizes of those
registers vary across hardware and I think one of the goals of simd is to
kind of abstract that away from the developer and so it kind of does the
optimization for you you make a simd of whatever size you like and this could be
wrong but my understanding is that under under the hood it's actually optimizing for your specific Hardware so that's
kind of cool and Sims work kind of like normal arrays um I
don't think they're mutable uh but yeah maybe I'll maybe I'll go over those next time um I think
we're just about out of time uh thank you all for joining this was pretty fun
um if I have a couple minutes if anyone has any questions um yeah how many libraries and
Frameworks are available at this point there's nothing there's no no libraries or Frameworks as far as I know that
could be wrong but it's yeah still very early stages
um me a lot of tries okay cool well thank yeah thank
you everyone for watching uh let me know if you want more live streams um let me know about topics let me know I could do
like a walk through of my emac setup that's kind of a video I've been wanting to do for a while
um yeah anyway thanks everyone for joining is compilers in place is it
specific to AI uh it's it's marketed toward AI
developers but if the vision if their Vision comes to fruition there's no
reason I don't think it can be a general purpose language
um yeah but that's kind of the niche they're they're targeting to kind of get get their foot in the door uh and it is
it is their logic makes sense it is an area of need like I said the python
ecosystem kind of accepts that python slow and I know there's Julia and and
there's some attempted solutions to that problem and but then you also have the the language fragmentation where you
have the underlying libraries written in C++ or C um you
know I actually interviewed it for a position one time this is a long time ago but I interviewed at a for a
position at a company where the role was specifically to so there's some machine
learning phds at the company who came up with algorithms and they wrote their algorithm algorithms in Python because
that's that's the go-to in that in that world and the role that I was applying for is was specifically to translate
those python algorithms into C++ so it's a testament to two things
it's a testament that there's a need to write things in C and C++ instead of python I think everyone kind of knows
that and it also is a testament to the fact that
there like a world-class machine learning researcher might not
necessarily be able to delve into that C++ world like the overhead is too high for them to learn and kind of Master
that language so Lang because of that language
isomorphism or homogeny across your entire stack seems like it would be very valuable and uh it's it's a very real
problem that I think modular is attacking here and it's a tough problem how do you get and and I think they're
approaching it the right way I it's hard to imagine a language that aims to solve
these problems succeeding without being a super set of python
right I think I think deciding to make this a super set of python is the the kind of killer feature
that will allow this to gain industry traction so I think it's I probably wouldn't have
quite as much interest in it if it was not a super set of python
um but yeah I think they're doing the right thing so I'm excited to see where things go from here um my go-to language
these days is rust I know I haven't made a lot of rust content recently um but there there's
there's plenty more coming yeah cool all right thanks everyone see
I think there's a I think there's actually a modular live stream at 11 if I remember right unless
they changed it so maybe check that out I would I would D like dump you all into
there if I knew how but I I'm new to this so all right bye
everyone

----------

-----
--12--

-----
Date: 2023.05.21
Link: [# All-in-one C++, Rust, AND Python Successor? Mojo](https://www.youtube.com/watch?v=w14vohgjnKo&t)
Transcription:

if all those things can align if we can
get parity with python and we can get a
nice package manager good tooling I
think the sky is a limit for Mojo and
not just in the domain of AI I think
this could be adopted by developers
coming from a lot of different domains a
lot of different languages and I do
think there's huge potential for Mojo
there has been a lot of Buzz about the
Mojo programming language mainly because
it aims to have a simple python-like
syntax while still being as performant
as something like rust or C and it also
aims to be Memory safe without having a
garbage collector similar to rust it's
sort of marketed toward AI developers
but it is intended to be a general
purpose programming language so it could
be interesting for all developers if it
winds up fulfilling its promises and
that's one of the things I want to dive
into in this video because modular had
an amazing demo for doing matrix
multiplication with Mojo and comparing
it to the performance of python and Mojo
is just orders of magnitude faster than
python but what does Mojo look like for
average development tasks and I also
wanted to take a look at what state the
language is in right now is it ready for
use on your next project is it just for
x experimenting what promises has it
already fulfilled and which promises is
it yet to fulfill so let's take a look
at that all right so let's kick things
off with a nice print hello world
okay that looks pretty python-esque now
let's do some variable assignments a
equals 1 b equals two
and then a plus b
okay still looking pretty python-esque
now let's define a function add a and b
colon
return a plus b
and then print add one
two
okay still looking pretty python-esque
but hang on to your shorts now because
we're leaving Kansas we can add types
let's do def add a and we'll type that
int
the type comes after the identifier
similar to most modern languages
and oh we'll add a return type
returns an INT as well
to add to
actually we'll call this add typed
typo nice now let's try something else
let's try modifying a so let's just do a
plus equals
one so just for the heck of it we're
going to add one to a before we do that
add
and that works as you'd expect in Mojo
you can Define functions using the def
keyword
but the more idiomatic way to define
functions in Mojo is using the FN
keyword and the FN keyword changes some
of the constraints around how you have
to Define your function so if I do do FN
first of all this is not going to work
because by default if we Define our
function with FN by default parameters
are always immutable if we don't
decorate them with something which I'll
get into in a minute so we can't do this
a plus equals one expression must be
mutual for in place operator destination
the other thing we can't do if we Define
our function using FN is we have to
specify types so if we remove the types
and remove this modification
we're still going to get an issue so
for defining functions with FN need to
specify types for the parameters
and
we cannot modify parameters by default
what if we want to define a type called
planet in Python that would be class
planet
and then we do def in it this is our
Constructor
it would take a parameter itself and we
could set some Fields as we want so
we'll have a field called mass and we'll
just hard code that to be 200.
we'll instantiate the planet and then
print it out print out the mass that is
okay classes classes are not supported
yet I believe the intent is for them to
Support classes at some point but there
is an idiomatic way to define types of
Mojo similar to their the way there is
for functions and that's using struct
instead of class I'm pretty sure they
intend to support class at some point
but for now we have to do the idiomatic
way so we'll do struct planet
and see if that works oh self in init is
passed as a mutable reference now that
this is a Mojo struct we have to
actually specify in out in front of self
which means it's a mutable reference
see if that works
it has no attribute Mass so we have to
actually specify explicitly the fields
that the type is going to have so we'll
do let mass and that's going to be an
INT
up let fields and structure not
supported yet let's change that to a VAR
um
200 okay we finally get it I didn't
mention this yet but the idiomatic way
to declare things in Mojo is using let
or VAR it'll still let you declare
things without without lettervar like I
did here but if you do let that
indicates that it's immutable if you do
VAR
that indicates that it's mutable similar
to other languages okay what if we want
to make a Constructor that takes a mass
we can do def in it
it's going to take a parameter ins and
cell top Mass equals mass
so now we should be able to
pass in 300 and voila we get what we
expect now let's try defining a function
that takes a planet as a parameter so
we'll do function is gas giant
and these mass units I have no idea what
unit they are they're just arbitrary
mass units
and it's going to return a Bool
and it's going to turn true if the
planet's mass is greater than 400
whatevers
right
and then we're going to make a planet
and call
is gas giants
and print it
forgot to pass in Rocky right
okay so it's not a gas giant this
doesn't seem much different yet but
what's actually happening is by default
structs are borrowed when they're passed
to functions so there's an implicit
borrowed here which means that this is a
read-only reference similar to rust
except in Rust when you want to pass a
read-only reference you have to
explicitly specify that you're passing a
read-only reference
it's when you want to transfer ownership
that you don't specify anything so the
the borrow checking model is similar to
rust but the default behavior is much
different so we're passing read-only
references by default and again that
borrowed is implicit
what if we want to modify Planet okay so
let's create a function make larger
it's going to take a planet
and we're just getting to
we're just going to multiply the mass by
two times equals two
I'm going to call make larger and Rocky
and then print the mass
okay expression must be beautiful in
place operator destination we did Define
Rocky as immutable up here so let's
redefine it down here
with VAR
and yeah we get the same thing so we
need to specify somehow in for the
parameter of make larger that P is going
to be mutable so let's try doing a
mutable reference so in out
and that does the trick so now p is a
mutable reference and notice we don't
have to do anything at the call site to
make that work it just sort of happens
based on the function signature what if
we don't want to pass a mutable
reference what if we want make larger to
take ownership of the planet well
instead of in out we can do owned
and then we should be able to add a
carrot here to Rocky to specify that we
want to pass ownership of Rocky to make
larger so it seems like mutable
references are implicit but for
ownership changes you have to do
something explicit at the call site to
get that to work so let's try that again
and that works the thing I don't
understand right now is why I'm still
able to print like this should this
should give me an error right when I
print Rocky print rocky.mass because
make larger now has ownership
so I don't understand fully maybe
someone can explain this to me in the
comments I'm sure there's a good answer
but it seems like this should give me an
error
right it might be because it's copying
because the other interesting thing
about Mojo is you can explicitly Define
which types are movable and which are
not because you can specify a move
Constructor
so I could go
deaf move in it
and then in out self
and owned existing
self
so this is going to be invoked when
there's a change of ownership that
happens oops I forgot some underscores
here
so we're just going to do self.mass
equals existing.mass
which an INT will just be copied from
one field to the other so let's see if
the behavior changes when we do that we
need to change all these to
yeah let's change all these to functions
oop typo
okay
yeah same thing so I I don't know why
this is not
give me an error the other thing is if I
don't specify
a move Constructor I can specify a copy
Constructor which works similar to copy
Constructors in C plus
the difference there is the second
parameter is not owned
let's run that
and let's see what happens here
600 yeah no difference
so if I I make this parameter owned in
the signature for make larger all the
function cares about is that it has an
own version of a planet it doesn't care
whether that was copied or moved so I
can determine at the call site whether
it was copied or moved if I specify this
carrot
I don't think this should work because
so the documentation says okay if if a
struct has a copy in it function it's
copyable if it does not it's not
copyable and same thing for move so if
it has a move in it
so the copy case works because I I print
the mass which was not modified because
it passed a copy to make larger so
that's correct but the owned or the the
move case works it does it does seem
like it moves to make larger because it
updates the the mass value but I don't
know why this doesn't return this
doesn't give me an error and I also
don't know why it still works even
without
even without moving it
so if I take away move in it and rerun
this it's still and
yeah and and I'm still specifying that
this is an ownership change it still
works I I don't know if that's I don't
know if that's intentional or something
that is known that's not implemented or
if it's a bug not sure but yeah
generally speaking if the vision is if a
struct has a copy Constructor it is
copyable
if it if it has a move Constructor it is
movable
if it doesn't have either of those it is
neither movable nor copyable the other
cool thing is this is kind of verbose
right so you want it to be movable and
copyable
it will take care of all this for you if
you just
decorate this with value
so it automatically implements sensible
move-in copy Constructors if you
annotate it with value
now let's try making a list of planets
print those out that's what we expect
okay we're looking pretty python-esque
at this point
now let's try to iterate over that list
oops list literal does not implement the
itter method okay this is creating
what's called a list literal and that
does not Implement itter and you'll find
that a lot of the collections do not
currently in Mojo I'm assuming the plan
is for that to change uh but I haven't
seen that confirmed anywhere the other
thing we can't do
is append
so this is a a list literal which
doesn't Implement append let's try
making a dictionary
cannot admit dictionary literals yet
okay so dictionaries are not implemented
yet but there is a collection you can
use to arbitrarily add and remove
elements and that is dynamic Vector so
we'll do from Vector import Dynamic
vector
and then we'll do planets equals Dynamic
vector
of planets
and then we can do planets.push back
and then give it a planet
right and you currently you can't have a
struct and a dynamic Vector that is not
annotated with something called register
passable
so we're going to add register passable
which indicates that this is this
structure can what is going on here when
we decorate this with value we also
don't need the constructors as well I
believe
yeah so we've made it register passable
we're telling the Mojo compiler that
this type can be passed around in the
CPU registers that allows us to put it
in Dynamic vectors currently I don't
think it's going to be that way forever
that's just the for now thing so now we
can do print planets
and we can't print it because print is
not implemented for dynamic Vector so
we're going to go ahead and iterate over
the planets
okay but it doesn't implement it or
either so we're going to have to do for
I in
range of length of planets
prints planets I dot Mass
okay so now we got it so to iterate over
a dynamic Vector we have to index it we
can't iterate over it and we can't print
it using just the print function so
that's a quick first look at Mojo
the syntax is pretty nice it is very
python-esque but I can't imagine a
python developer being able to
immediately understand a Mojo code base
because they get the most out of Mojo
you need to use the Mojo idioms like FN
instead of Def and then struct instead
of class currently there is a lot of
stuff a lot of python patterns that are
not supported as you can see here I
believe the plan is for that to change
modular is not making any promises as to
the current state of the language if you
haven't seen the demo that modular did
comparing the performance of Mojo doing
Matrix multiplications against python
it's actually really incredible it seems
like a lot of the effort so far in
building the language has been dedicated
to those sorts of demos so a lot of the
general purpose functionality isn't
quite there yet but I'm pretty excited
about Mojo in general the vision is
really compelling to have this language
that has rust style borrow checking
memory safety like Russ does yet have a
simple syntax like python or it can
start out simple and then you can kind
of build on it as you become become more
familiar with the language I think
there's a huge potential for this to
really catch on as long as the tooling
around it matures as long as it has a
good package manager it has good ide
support things like that I think that's
sort of the Crux of whether this is
going to become mainstream or not and
also of course implementing these
language features that have sort of been
promised and getting parity with python
right we can't make python dictionaries
yet that needs to get going before this
is going to get any mainstream traction
if all those things can align if we can
get parity with python and we can get a
nice package manager good tooling I
think the sky is a limit for Mojo and
not just in the domain of AI I think
this could be adopted by developers
coming from a lot of different domains a
lot of different languages and I do
think there's huge potential for Mojo So
This is a quick first look at Mojo I
will post updates in a pin comment below
on anything that changes I expect the
language features to change pretty
rapidly so I'm going to try my best to
update that pin comment with anything
that in in the video that is no longer
true I imagine those will come pretty
quickly as they build more and more I'd
love to make another video on Mojo once
a few more of these things are
implemented very impressed with what
I've seen so far I can't imagine
building anything quite yet with it but
I wouldn't be surprised if the day where
you can build something with it comes
fairly soon hope you all liked it and
we'll see in the next one

----------

-----
--11--

-----
Date: 2023.05.04
Link:  [# Say Goodbye to Python and Hello to Mojo](https://www.youtube.com/watch?v=s4ZUkwe0ZTI)
Transcription:

ladies and gentlemen boys and girls this
is a remarkable day in the history of
programming now we are moving on to the
face where every day is exciting there
is some news that is dropping out and I
want to cover this one I'm super excited
for this one in this video I'll walk you
through that what possibly can be one of
the Python Killer python is an amazing
programming language but now it's going
to face heads up heat a heads up
competition from a language which is
newly here is modern but it's being
designed from the people who are very
very reliable in the industry I'm not
saying that python will go away tomorrow
but there are high chances that
eventually it might Fade Out now first
of all listen to this very carefully why
does python is gaining so much of
popularity not because it's easy not
because it's fast there are other
languages which are comparatively
equally easy there are other languages
which are faster than this the reason
why python is gaining its popularity is
not because it's easier to develop
application using Django or fast API
it's the hole and soul the era of
machine learning there is a hype going
on right around which is on machine
learning and we all know that the reason
why these machine learning and the
python are all sinking in and where the
python is getting it's all superpower
it's C plus plus because all the
libraries which you see in the machine
learning are actually written in C plus
plus because of the performance issue
but over the top of these libraries an
API layer is given to the python and
there's a lot of bridging that happens
and we all know python is not the
fastest of the language but it's a
choice to just do all of the things
because we don't have any other choice
to choose a programming language a
language which is totally designed for
machine learning work for AI work we
don't have an option so that's why we
all went into the rabbit hole of
learning the python and it's easy for a
lot of beginners to get attention that
hey you can learn this easy language and
can become a machine learning engineer
that's a good thing as well it attracted
a lot of people but now it's time that
we are designing and we are moving into
a language which is specifically
designed for this purpose is coming out
this is amazing and this language is
backed by developers or being created by
the developers who created Swift one of
my favorite programming language so
Elegance is there in the Swift I'm
pretty sure the same Elegance is going
to be coming up here the reason why I'm
so much excited about this language is
because
this language gives you the performance
which is arguably better than C plus
plus and a memory management like rust
and the type safety like what all you
need for that so let me introduce you to
this language which is designed by
modular now here is the modular website
I'm on to this one so modular is a new
company which is claiming to design a
language uh programming language for all
AI developers yes out of the box it
supports so much so together we are
going to be walking through this is more
of an introductory video where I'll just
walk you through with a couple of pages
documentation and how you can sign up
the beta I have already signed up for
that so this will be super interesting
for you this is exciting time I'm super
super excited for this one so notice
here what it says Mojo combines the
usability of python with the performance
of C unlocking unparallel programming
programmability of AI hardware and
extensibility of AI model this is really
really cool I don't know what extension
notice here it says softmax dot fire
icon are we using the fire icon now I'm
pretty sure not but uh this is all out
of the box and what they claim is that
it just out of the box supports Python
and all the things that you have already
written in Python you probably don't
need to convert that rest is going to
come up eventually as I get an access to
this one right python or scale all the
way down to the metal uh program uh the
multitude of low level so it's claiming
that we'll give you access if you want
to just brush through over the top layer
of abstraction you can do that but in
some cases if you need fine grain
control of the memory management and
memory allocation and all that you can
do that as well this is the most
interesting power of this one unlock the
python performance and all of that so
this is interesting here python is
obviously single thread execution and
this out of the box supports parallel
processing across multiple cores these
days all all computers are having
multi-course but the languages that were
designed were like in the 90s and at
that point of time we were only having a
single core now nobody has a single code
even the smallest computer on which you
are watching is a multi-core so now
programming languages should actually
need to take advantage of these
multi-core how long we are going to be
just blindly following the C and C plus
plus and python they are the best
language no the things are evolving fast
we need multi-processing now either
language needs to adopt or we are going
to be moving into different languages
now that's how it works in the iOS world
we move to Swift from Objective C I'm
pretty sure very soon people are going
to be migrating from python to such
languages the adoption rate these days
is crazy insane so notice here it says
that hey time a speed up versus python
35
000 times well what kind of magic Mojo
magic is the only thing that I can
recommend is uh change this logo of Mojo
instead use that old Mojo Jojo logo if
you remember that from old Powerpuff
Girls days I think that's what I have
anyways so coming up on to this this is
super exciting you can upgrade your
models or modular Stacks this actually
brings my interest back into machine
learning so yeah due to my college
actually I'm studying this a little bit
but now I'm more excited and you can get
access I've already signed up for the
beta access here in the Mojo you can
also sign up just say modular.com get
started I filled up for Mojo
just right now at the time of recording
of the video uh so make sure you also do
that in case you want to access and here
are the docs that are available so why
Mojo the programming manual and a whole
lot of low level hello world so you can
see just from the hello world it's not a
complex one but again nothing actually
proves you with the hello world we have
Latin War declaration so there's a basic
I was reading this there's a strong type
checking as well love that and there is
overload functions and methods function
definition there's a lot I studied I
spent my entire hour in just reading the
docs and probably very soon if they
allow me the access I would love to
record a few tutorials on that at least
just figuring it out playing it around I
would love to see that there's so much
so the modular docs are here and then
there's get ready I've already signed up
and here is something interesting so try
Mojo and why Mojo try Mojo is where they
say that hey there is going to be a Mojo
playground where you can play around the
things and you can just look around
what's happening you can chat and
there's a GitHub and the thing is that
on the get have right now there is
nothing which is a good approach I think
because if you have this kind of a
approach where you just dump all the
things you just burden down with a lot
of pull requests there are issues here I
was just looking through in them as well
that hey official site is blank yes of
course they are not going to be making
it open source on day one which is a
good approach in case you are working
with the open source community and
projects otherwise people just copy and
paste the product our one of the debut I
also got copied like ripped off copy
somebody else stay there this is my open
source project
surprisingly they send it to me on the
Discord as well very funny anyway so low
level IR on Mojo there's this lot of
interesting stuff one thing I would
recommend you to read is why Mojo
there's a lot of interesting material
and article on this one if you wish I
can make a summarized version video of
it but notice here mojo as a member of
python family so Mojo is to provide a
super set of python so they are kind of
a using the typescript approach just
like how the typescript is getting
popular it it's almost like JavaScript
but with added super power to it so
that's exactly and notice it says how
compatible Mojo with python really Mojo
already supports many core features in
Python including asyncavate error
handlakes and a whole lot more will be
supported Mojo doesn't even Support
classes yet very soon they will be
probably and there is a intentional
differences otherwise how it will be
super fast there's a detailed motivation
this is the pera which I absolutely
loved reading it that how they are
looking for what is the motivation
behind it that's that's great two world
problem so this is the entire thing
which I would highly highly recommend
you to try this out read this great
great interesting read on a final note I
would say that yes there is a great
enhancement that is going on in the
world of programming every single day
there's something which is dropping out
I'm just running behind in making a lot
of videos but hey this could be a killer
of python what do you say in the comment
section it could be a killer or it would
be another fsad anything the time will
tell only where the things are going to
lean forward but stay tuned hit that
subscribe I'm gonna be bringing up a lot
more such exciting updates which are
happening all around the places let's
catch up in another such video

----------

-----

--10--

-----
Date: 2023.09.06
Link: [# [TechBites] New language Mojo.ðŸ”¥ | Will Python be replaced?](https://www.youtube.com/watch?v=p0dCj1JL8AM)
Transcription:

welcome back to another episode of tech
bites this is your host Erickson let me
introduce you to Mojo a brand new
programming language for all AI
developers python is the current most
widely used language for AI developers
but Mojo is here to take the crown it is
said to perform up to 35
000 times faster than Python and you can
also use the cute fire Emoji as the file
extension if that appeals to you if Mojo
is actually 35 000 times faster than
python will python be replaced by Mojo
before we get into how Mojo Works let's
take a look at some characteristics of
python to understand how Mojo is
different from it python is currently
the most widely used programming
language for a lot of web developers
data scientists data analysts and more
it's also the most famous Choice as the
first programming language to learn for
beginners python is considered a high
level language because it is fairly
similar to the English language and it's
thus quite easy for humans to write and
understand another reason why python is
currently considered the best language
for AI and machine learning is because
of its huge libraries and Frameworks
numpy pandas tensorflow Keras and Pi
torch are some of the most widely used
python libraries for data science if
python is easy to learn and has all the
libraries and documentation for machine
learning why did Mojo developers think
that we need a replacement let's take a
look at some of the downsides of using
python most importantly python is slow
with the same algorithm python is
usually much slower than C which is the
language python is written in Python is
dynamically typed language which means
python variable types are not specified
and the codes are interpreted and
compiled during their runtime this makes
the code both easier to write but also
slower to run due to the slow running
time although most AI research is done
in Python most products end up being
programmed in C or C plus another major
downside to using python is that it is
difficult to distribute when a c
programmer wants to distribute a c
program they can simply compile the
program into a single file for
distribution now let's say a python
programmer wants to distribute a Python
program using the Keras Library the
users will have to download python Keras
library and all the other dependent
libraries to run the file this is also
mainly because python has to be
interpreted and compiled during this
runtime this is where Mojo comes in with
features that resemble python but could
tackle the downsides of it Mojo is
created by Chris lattner a legendary
engineer who has led several projects at
Apple Tesla Google and more Mojo is not
open source yet but will soon be after
its official release to try out Mojo you
can sign up to the waitlist you will be
able to get access to Mojo in only a few
hours after being on the waitlist now
let's take a look at how Mojo is
currently different from Python and how
the developers managed to make it 35 000
times faster Mojo is a superset of
python just like how typescript is a
superset of JavaScript this means that
Mojo uses all the python syntaxes and
libraries while bringing the speed up to
35 000 times faster Mojo is fully
compatible with the python ecosystem you
can use all the existing python
libraries that were previously mentioned
and so much more you can easily import
python libraries with the syntax
python.import module another very fun
feature of Mojo is that it supports the
fire Emoji to be the file extension you
can either name the same file hello.mojo
or hello.fireemoji now we know that Mojo
supports some fun Emoji extensions and
that is syntax is very similar to python
then let's take a look at some of the
features of Mojo that makes it faster to
be precise Mojo being up to 35 000 times
faster than python doesn't mean that the
same python code will magically run 35
000 times faster in Mojo with the exact
same code Mojo says it runs only
slightly faster than python these are
some of the differences that you have to
make in your code for it to run
significantly faster this is an example
of a function declaration in Mojo it
looks exactly like a python function
definition except for a few differences
instead of death Mojo function
decorations use FN also the types of
parameters and the return variables have
to be specified this switch the code
from dynamically typed to statically
typed modules objects can be both built
in a class or a struct a class is also
supported in Python but struck is added
in Mojo similar to a class A struct can
have variables and functions defined in
it the difference again is that
variables are static rather than dynamic
in this piece of code you can see that
the two variables first and second are
set as integers it also contains the
initializer and a user-defined function
that prints out the variables the
user-defined function dumps the FN
method that was introduced previously
moreover Mojo has two types of variable
VAR and let VAR is mutable and Lead is
immutable what does this mean let's take
a look at the simple code snippet as an
example the simple main function
increments the variable X after setting
it if you change the VAR to let however
you will be getting an error like this
this is because lead makes the variable
X immutable so an attempt to increment
it would lead to an error using static
types like this can optimize running
time and help in error checking but you
can still use the dynamic types like
python if it is not necessary Mojo also
allows parallel processing with the use
of a multi-level intermediate
representation compile
mlir in short python only allows single
threaded executions so many AI programs
had to use Cuda as a roundabout way for
parallel processing to shorten the
runtime however with mlir it's now
possible to scale to Exotic Hardware
types without too much complexity this
could become extremely handy since many
machine learning programs are currently
using Cuda to reduce the often extensive
training time Mojo adopts the ownership
and borrowing concept from rust the
ownership and borrowing concept is a
unique memory management feature in Rust
python has a garbage collection feature
that regularly looks for no longer used
memory as the program runs in C and C
plus plus the programmer must explicitly
allocate and free the memory ownership
and borrowing is the third approach that
could be a lot more convenient for
programmers who are familiar with the
concept of stacks and heaps and will not
slow down the program while it's running
another memory management feature that
Mojo has is the pointers from C and C
plus this could be used for more low
level customization pointers could be
employed with the command import pointer
finally the deployment of a program file
is much easier in Mojo than in Python
I've explained previously how python
codes are interpreted and compiled in
runtime on the other hand Mojo is
compiled ahead of time to machine native
code in other words program files are
packaged nicely into a single file and
the users wouldn't have to download
Python and all the dependent libraries
for them to run we have discussed the
new features of Mojo that were added on
top of its python compatible syntaxes
and how these new features could
dramatically shorten the running time
and make the deployment easier but will
it actually replace python or will it
just be another programming language
that's never actually been used and be
forgotten although Mojo is much faster
than python there's still a trade-off
between runtime speed and code
complexity this means that while Mojo
could be faster the code will be much
more complex than normal python codes
for example changing all the user
defined functions and variables from
Dynamic to static could improve the
runtime but will also make the code
significantly more complex while some
say even if it's more complex it could
be easier for python developers to learn
compared to learning a whole new
language like C plus or rust this could
perhaps fill in the gap between research
which is mainly written in Python and
development which is mainly written in C
or C plus a lot of people are skeptical
of how big Mojo could become but
programmers are still very excited with
the news if you'd like to hear more
follow-up stories on Mojo or want to
keep up with how machine learning is
evolving day by day stay tuned for the
coming episodes of Tech Bytes this was
your host Erickson and I'll see you
again in the next video
thank you

----------

-----

--09--

-----
Date: 2023.05.10
Link: [# Mojo ðŸ”¥ Playground First Look: Walkthrough Part 1](https://www.youtube.com/watch?v=d9DcyGNUis8)
Transcription: 

hello everyone uh today I thought I'd take you all along
as I play around with Mojo for the first time which is a new programming language
that I just got access to um and
I just watched the keynote uh a couple of days ago one of the founders is Chris lattner the
creator of Swift um and yeah I don't really know much to be
honest uh besides having watched the keynote and I know uh that they're
trying to work on a programming language that is sort of geared towards the AI
space and um performant
like C and as easy to use as Python and uh I guess on their website here they
say uh they're trying to bridge the gap between research and production by
combining the best of python syntax with systems programming and meta programming
so yeah this is the documentation but I
actually got access to their playground so let's just uh have a look this is
literally the first time that I'm looking at this so uh this is all live all right
hello Mojo we're excited to introduce you to Mojo with this interactive
notebook Mojo is designed as a superset of pythons so a lot of language features
and functions are the same for instance a hello world program Mojo looks exactly
like it does in Python all right let's run this
okay and uh
we want to see the logs all right let's see
did this not work hmm
where do I see the console output
where do I actually see the uh the output
all right there we go Okay so print hello Mojo hello Mojo
and as we'll show you later you can also import existing python packages and use
them like you're used to but Mojo provides a ton of powerful features on
top of python so that's what we'll focus on in this notebook to be clear this
guide is not your traditional introduction to a programming language this notebook assumes you're familiar
with python and some systems programming Concepts so we focus on what's special
about Mojo this runnable notebook is actually based on the Mojo programming
language but we've simplified a bunch of the explanation so you can focus on playing
with the code if you want to learn more about a topic refer to the complete manual let's get started all right
let's just open the manual here for a second
um Mojo is a programming language that is easy to use as easy to use as python
but with the performance of C plus plus and rust furthermore Mojo provides the
ability to leverage the entire python Library ecosystem
Mojo achieves this feat by utilizing Next Generation compiler Technologies
with integrated caching multi-threading and Cloud distribution
Technologies furthermore Mojo's Auto tuning and compile time meta programming
features allow you to write code that is portable to even the most exotic Hardware more importantly Mojo allows
you to leverage the entire python ecosystem so you can continue to use tools you're familiar with Mojo is
designed to be come a super set of python over time by preserving Python's
Dynamic features while adding New Primitives for systems programming
these new system programming Primitives will allow Mojo developers to build high
performance libraries that currently require C C plus plus rust Cuda and
other accelerator systems by bringing together the best of dynamic languages
and systems languages we hope to provide a unified programming model that works across levels of abstraction is friendly
for novice programmers and scales across many use cases from accelerators through
the application of programming and scripting all right what I'm thinking about uh is
what this is going to look like on iOS and apple platforms uh because I have a
an iOS background I used to be an iOS engineer and obviously Chris lapner is
probably sort of tightly integrated into the Apple ecosystem having created Swift
so I wonder if there's going to be any announcements at WWDC this year with
Mojo and whether there's any collaboration there because
that would be interesting to see if just having read this I would be curious
to know if and how easy it is to uh take a
an implementation of some uh AI model and basically
deploy it um on Apple platforms
um that's what I'm thinking about that because I'm familiar with those platforms um but obviously their goal is their
stated goal is to be uh you know super platform agnostic and essentially be
able to run everywhere with the ease of writing python code or python like code
by writing Mojo all right um
let's just have a quick look here using the Mojo compiler you can run a Mojo program from a terminal just like you
can with python so if you have a file name Hello dot Mojo
all right I didn't know this a file extension can be an emoji just type Mojo
hello Mojo all right again you can user you can use either
the Emoji or the dot Mojo suffix if you're interested in diving into the
internal implementation details of Mojo it can be instructive to look at types in the standard Library example code in
notebooks blogs and other sample code um all right let's have a look at the
actual playground here okay um
all right note the cloud environment running these notebooks is not very
powerful and the number of V CPU cores available to you may vary however as you
will see in the mat mul
notebook Mojo's relative performance over python is significant
all right basic systems programming extensions python doesn't uh
natively support systems programming so here's how we do it in Mojo
let antivar declarations all right that's taken from Swift
um and I don't actually know where Swift took that from but inside a function you
can assign values to a name and it implicitly creates a function scope
variable just like in Python this provides a very Dynamic and low
uh this should probably be Memory uh
this provides a very Dynamic and low memory way to write code
uh excuse sorry this provides a very
Dynamic and low memory way to write code but it also but it is also a challenge for two reasons
one systems programmers often want to declare that a value is immutable
they may want to get an error if they mistype a variable name in an assignment
all right so some compiler time safety checks
to support this Mojo supports let and VAR declarations which introduce a new
scoped runtime value lat is immutable and VAR is mutable these values use
lexical scoping and support name shadowing
I don't know what that is so
lexical scoping also known as static scoping is a convention used with many
modern programming language it refers to setting the scope or range of
functionality of a variable so that it may be called referenced from within the block of code in which it is defined all
right okay so like a function I suppose or something like that
um
all right here we have a function def your function taking a and b as parameters let's C equals a uncommon to
see an error C equals equals to B error C is immutable all right that
makes sense all right that's
if C is not b let D is equal to B print D all right
well let's see what happens if we uh uncomment this
all right we get an error as expected
let's comment that out all right
let and VAR declarations also support type specifiers patterns and late
initialization uh
okay so let X is equal so X is of type
int and we initialize it to 42. Y is of type uh
float64 and we initialize that to 17
let's just make sure I'm correct about this
a 64-bit floating Point type specifically the binary 64 type defined
in IEEE 754 this typical this type is very similar
to float32 but as increased Precision by using twice as many bits all right
I don't do much systems programming so uh
this is all a big learning experience
um all right we have y of type float64
um and we set that to 17. we have
Z which is a float type 32 x if x is not
equal to zero we set z21 else we print or recall
through or we set that to the return type of fill which is a float32
um Zed is of type 32 okay uh
and um yeah let's run this and it's one because we call it your
function and
your function X is set to 42 and 42 is not equal to
0 and therefore we call through and
wait a minute here all right maybe it's late but all right we call it your
function your function uh X is equal to 42 Y is equal to 17 Z
is just is not initialized it's just declared if
X is not equal to zero
we set it to one all right that makes sense X is not equal to zero because it's 42.
um and then we print one okay it all makes sense just uh
brain fart [Music] um struct types modern systems programming
requires the ability to build high level and safe abstractions on top of low level data
layout controls indirection free field access and other Niche tricks Mojo
provides that with the struct type
okay so we want to build high level abstractions uh for safety and so that's why Mojo
introduces structs struct types are similar in many ways to classes however
where classes are extremely Dynamic with Dynamic dispatch Dynamic method swizzling and dynamically bound instance
properties structs are static bound at compile time and are inlined into their
container instead of being implicitly indirect and referenced counted
um okay so what's tripping me up a little
bit always is that a lot of the uh the names are uh exactly like they are in
Swift and it does look like uh their uh
essentially the same as in Swift but there are some differences I believe because uh classes in Swift do not
support Dynamic dispatch and Method swizzling um
and dynamically bound instance properties those are all features of objective c
um but I think Swift got rid of that um but it does seem to be possible in
Mojo classes and then we have structs um
that are
that are static and not reference counted um and so
I believe that also means that they're then um
passed by reference although I'm not exactly sure yet that
is to be determined um so let's have a look at the example here
um we have this struck my pair
VAR first VAR second all right and we have a function
we use F and instead of Def here we'll explain that soon okay so we have a
function an initializer using python syntax
takes two parameters sets those parameters okay straightforward and then we have this one
uh less than and um
it returns a Boolean and it returns if if first
is less than right hand side DOT first
or self first is equal to right hand side first
um oh excuse me so either if first is less
than the right hand side first or
uh self DOT first is equal to right hand side DOT first
and self dot second is less than right hand
side.second we return uh that okay the biggest difference compared to a class
is at all instance properties in a struct must be explicitly declared with a VAR or let declaration
this allows Mojo compiler to layout and access property values precisely in memory without indirection or other
overhead and this makes it a lot faster I presume and that's probably also why sort of
like uh Swift encourages the use of structs
for Speed and Swift UI also uses structs for their views and it constantly
redraws them also for Speed so um
yeah that's what it says right here this allows the Mojo compiler to layout and access property values precisely in
memory without indirection or other overhead struct fields are bound statically they
aren't looked up with a dictionary in direction as such you cannot uh
Dell a method or reassign it at runtime I guess Dell is delete this enables the
Mojo compiler to have performed guaranteed static dispatch use guaranteed static access to fields and
inline as struck into the stack frame or enclosing type that it that uses it
without indirection or other overheads strong type checking although you can still use Dynamic types
just like in Python Mojo also allows you to use strong type checking in your
program one of the primary ways to employ strong type checking is with Mojo's struct type
a struct definition in Mojo defines a compile time bound name
a reference and references to that name in a type context are treated as strong
specification for the value being defined for example consider the following code that uses the my pair
struct shown above um deaf pair test let P equals my pair one two
um return p is less than equal to four
uh p is less than four uh
return true well let's let's run this here my pair
use of oh we didn't okay run this all right we ran this
boom boom boom all right boom
uh if you uncomment the first return
statement and run it you'll get a compile time error telling you that 4 cannot be
converted to my pair which is what the right hand side of less than requires
all right so we have static type checking which is uh epic because uh
I actually started mainly programming in Swift I mean uh in in
when I study computer science I programmed all sorts of things but then I started working as an iOS
engineer and just was doing Objective C in Swift and now over the past two years uh
I have been doing more Python Programming uh working
um on some Django back ends and like one of
the things that I've missed the most in that is uh static type checking and now
that I've been programming in Swift again for the past couple of months uh
I just I'm very happy because I personally I know people you know people have
different opinions here and some people like the freedom that
Python and JavaScript Etc provide but I just like to have
trust trust the compiler I suppose so this makes me happy
um okay let's see what happens here let's comment that out run it and see if we
actually get this compiler track invalid call to less than
right side cannot be converted from in to my pair nice all right
let's get this back into a good State and keep going so we have strong type
checking that is that is good to know that is that is very nice
um all right
overloaded functions and methods also just like python you can Define functions in Mojo without specifying
argument types and let Mojo and further data types but when you want to ensure type safety Mojo also ensures full
support for overloaded functions and methods essentially this allows you to Define
multiple functions with the same name but with different arguments this is a common feature seen in many languages
such as C plus plus Java and Swift let's look at an example
all right we have a struct complex two variables of float32
um and we have two initializers uh that have the same function name and
we overload the initializer uh and the difference is that they take
different parameters and we do not need a different name for
that function so uh
yeah that's uh that's good to know you can also Implement overloads anywhere you want for module functions and for
methods in a class or a struct uh Mojo doesn't support overloading solely
on a result type and doesn't use result type or contextual type information for
type inference keeping things simple fast and predictable Mojo will never produce an expression
too complex error because its type Checker is simple and fast by definition
all right just one more thing I just want to highlight here or make sure also
just like python you can Define functions Mojo without specifying argument types and let Mojo in further
data types so what happens if Okay so let's run this right here
um I suppose what happened so let's get rid of
the type
okay so if we're uh we can't omit the type and then overload
it seems because well my expectation right now is if I uh go here and comment
this out then it should work because we should be able to and let's let's see
what happens hmm
okay it says also just like in Python you can Define functions Mojo without specifying argument types and let Mojo
in further data types yes but
that does not seem to be working right now right like I would like to let this
okay maybe I'm missing something but I would expect this to run because it says
just like in Python you can Define functions in Mojo without specifying argument types
so we don't specify the type here and I would expect that to work and let Mojo in further data type
but it's not inferring it I mean what happens if we comment this out
nope um what happens if we
I see what happens if we just set this to one and we just print X
well let's see what happens here no
it says function parameter type must be specified why is this
um all right I don't know to be honest but
uh we'll leave this for now I will ask uh
maybe this is a bug maybe I'm missing something but um
yeah let's move on uh
all right all right let's keep going
you can Implement overloads anywhere you want for module functions and for methods in a class or struct
uh okay okay we had that all right let's move on to functions
FN definitions the extensions above are the Cornerstone that provide low-level programming and
provide abstraction capabilities but many systems programmers prefer more control and predictability than what
deaf and Mojo provides to recap deaf is defined by necessity to be very Dynamic
flexible and generally compatible with python arguments are mutable local
variables are implicitly declared on first use
and scoping isn't enforced this is great for high level programming and scripting
but it is not always great for systems programming to complement this Mojo provides a
function type um
excuse me to comple this to complement this Mojo provides a function declaration which is
like a static mode for Dev all right my dyslexia is maybe kicking
in a strict mode for death uh
function and Def are always interchangeable for uh from an
interface level there is nothing a Def can provide that a function cannot or
vice versa the difference is that function is more limited and controlled on the inside of its body
alternatively pedantic and strict specifically functions have a number of
limitations compared to Deaths one argument values default to being
immutable in the body of the function like a let instead of mutable like a VAR this catches accidental mutations and
permits the use of non-copyable types as arguments
argument values require a type specification except for self in a
method argument values require a type
specification except for itself in a method um
okay was this a function ah there we go that's why this didn't work so let's
just okay let's just read this here let's finish reading this argument values require a type specification
except for self in a method catching accidental emissions of type specifications similarly a missing
return type specifier is interpreted as returning none instead of an unknown return type note that both can be
explicitly declared to return object which allows one to opt into the
behavior of a def if desired okay so let's go up here
um I suppose can we just Define these as functions
we can now can we omit the the type
we sure can all right there we go um
I feel like this example should then uh
be rewarded but whatever um
fuel uh um
let's just go back and let's just um
run this cool oh and now we need to declare the type again
all right all right okay
let's just read this last bit one more time note um similarly a missing return type
specifier is interpreted as returning none uh okay so we can omit a return type for
a function uh and it's interpreted as returning none instead of an unknown return type so
it's not any it is nil or none note that both can be explicitly declared to
return object which allows one to opt into the behavior of a death if desired
so we have the flexibility even with a function to basically return a
uh unknown type but as long I mean and any object type or an object type in
Python I suppose and um so we can opt into to that higher level Behavior if we
want but it's probably more like an escape hatch
for situations where we don't want that behavior because uh
functions seem to be designed to be as strict as possible and we should probably keep it as strict as possible
at all times all right implicit Declaration of local variables is disabled so all locals must
be declared this catches name typos and dovetails
with the scoping provided by let and VAR implicit Declaration of local variables
is disabled so all locals must be declared okay explicit
both supporting raising exception both support raising exceptions but this must
be explicitly declared on a function with the raises function effect placed
after the functional argument list all right that makes sense the copy init and
moving its special methods Mojo supports value semantics as seen in languages
like C plus and Swift and it makes defining simple Aggregates of fields
very easy with its at Value decorator described in more detail in the
programming language for advanced use cases Mojo allows you
to Define custom Constructors using Python's existing init special
method custom destructors using the existing delete special method and
custom copy and move Constructors using the copy init and move in it special methods
um these low-level customization hooks can be useful when doing low level systems
programming example with manual memory management for example consider a heap
array type that needs to be that needs to allocate memory for the data when
it's constructed and destroyed when constructed and destroyed when the
value is destroyed um
let's just have a look at the add value decorator here for a second
Mojo supports full value semantics as seen in languages like C plus and Swift
and it makes defining simple Aggregates of fields very easy with the add value
decorator describe it more detail below
Mojo's approach provides simple and predictable hooks that give you the ability to express
exotic low level things like Atomic correctly this is
great for control and for a simple programming model but most structs
we all write are simple aggregations of other types and we don't want to have to
write a lot of boilerplate for them to solve this module provides a add value decorator for structs that synthesizes
the boilerplate for you at Value can be thought of an extension of Python's data
class handling the new moving it and copying it module methods the value decorator takes
a look at the fields of your type and generates members that are missing consider a simple struct like this for
example struck my pet VAR name String VAR H end
okay uh Mojo will notice that you do not have a member-wise initializer a move
Constructor or a copy Constructor and we'll synthesize these for you as if you
had written them okay that's nice it's like a property wrapper I guess is
a a decorator is the same as a property wrapper
although probably very similar I don't know if there's differences um
all right I got sidetracked there um let's go back here the copying it and moving it special methods Mojo supports
full value semantics as seen in languages like C plus plus and Swift and it makes defining simple Aggregates it
feels very easy with its add value decorator described in more detail in the programming manual for advanced use
cases Mojo allows you to Define custom Constructors using Python's existing
init special method custom destructors using the existing delete special method
and custom copy and move Constructors using the copy init and move in its special methods these low-level
customization hooks can be useful when doing low level systems programming example with manual memory management
for example consider a heap array type that needs to allocate memory for the
data when constructed and destroy it when the value is destroyed
so what what are we trying to do uh
these low-level customization hooks can be useful when doing low levels system programmings because
of things like this example which is consider a heap Ray type that needs to
allocate memory for the data when constructed and destroy it when the value is destroyed
all right let's go through the code from pointer endpointer from i o import print no new
line okay we have a struct heap array it has a property data
it's mutable it's a pointer
to an int we have a mutable property size
of type int and we have a mutable property cap of type int
we have two initializers one doesn't take any parameters
initialize the cap at 16. size at zero
and allocates memory for
the capacity of 16. and we have a second initializer that
allows you to specifically set a certain size and uh
you can set the size and a vowel and I don't know let's see what the value represents so we set the capacity at
twice the size we set
the size to size
and we allocate memory for the amount of capacity uh
we want which is twice the size and then for I inrange self dot size
we store
I
at Val uh oh sorry sorry we store the value at I
so basically we initialize it to the same value uh
okay that that makes sense uh so what what happens is we initialize uh
this Heap we set the capacity to twice its size and then we basically Set uh
the value for size amounts and then we have a delete method which just frees all the data and we have a
dump method which print new no new line uh open
angle Open Bracket and um
for ION range self.size if I is greater than zero
print no new line so we just print a comma
for all right so we basically just print all
the values and then um yeah this array type is implemented using low
level functions to show a simple example of how this works however if you go ahead and try this out you might be
surprised let's get surprised all right that worked
that worked
all right Heap three one a DOT dump should print 111 it does
print one one one uncommon to see an error uh
now
oh sorry dump doesn't uh yeah it just basically
prints the contents yeah
I don't like that name that is a misleading name dump um
I don't know maybe that's python to speak um anyway uh
I'm just thinking like dump it from memory but whatever uh the second thing that happens here is we say VAR B is
equal to Heap array for two B dot dump two two two two two
all right uh that makes sense and then a DOT dump is
one all right that makes sense uh
okay there's nothing unexpected here it says the compiler isn't allowing us to make a copy of our array Heap array
contains an instance of pointer which is equivalent to a low level C pointer and Mojo can't know what the pointer means
or how to copy it this is one reason why application Level programmers should use
higher level types like arrays and slices more generally some types like atomic numbers cannot be copied or moved
around at all because our address provides an identity just like a class instance does in this case we do want
our array to be copyable around and to enable this we implement the copy init
special method which conventionally looks like this
well let's uh first run this right here and that's gonna probably fail invalid
redefinition of B so we can't we can't
what is well let's see this is a struct um
we're trying to re-initialize it which means that we're passing
yeah we're creating a new object which also means that structs are
definitely not copied by uh reference they're copied by value
because we're trying to re-initialize a new value
all right um so that's like Swift
now the compiler isn't allowing us to make okay we just had that uh now uh
in this case we do want our array to be copular around and to enable this we implement the copy and its special
method which conventionally looks like this so we have everything we just had
now let's have a look at the copying it method here so
it takes a parameter of other to the new object I
suppose and it copies uh oh sorry we're the we're talking like
the copy initialize copying it is called on the new object
so it is getting past a uh
the it is getting past the
the the object word copying and it is it's assigning the other's capacity to its own the
other's size to its own and then it is uh
allocating memory for the data and
here we explicitly say that it's of type integer
and then we're copying the data all right that makes sense with this
implementation our code above works correctly and the B is equal to a produces a logically distinct instance
a logically distinct instance of the array with its own Lifetime and data
Mojo also supports the move init method which allows both rust style moves which
take a value when a lifetime ends and C plus plus style moves where the contents
of a value is removed but this Destructor still runs and allows
defining custom move logic please see the value lifecycle document for more
information all right I don't really have any rust experience so
um this is interesting rust style moves which take a value when
a lifetime ends and C plus plus style moves with a
contents of a value is removed but the destruct Destructor still runs
all right now we should be able to run everything and
boom everything works as expected we can comment that out and uh
we should get the original result all right perfect
lovely well this also needs to be updated but
whatever all right Mojo provides full control of the lifetime of a value including the
ability to make the types copyable move only and not movable
um this is more control than languages like Swift and rust which require values to
at least be movable if you're curious how existing can be passed into the copying it method without itself
creating a copy check out the section on board argument convention below
all right I'll leave it here for now um and I'll keep going tomorrow one of these days and if you want to see more
of this uh consider giving this video a like And subscribe and I'll see you soon

----------

-----
--08--

-----
Date: 2024.02.01
Link:  [# Modular Community Livestream - MojoðŸ”¥ SDK v0.7 edition!](https://www.youtube.com/watch?v=Ln8ZaJ0gaSA&t)

Resources: Blog post: [https://www.modular.com/blog/mojo-sdk...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2xNTVVCRVhZNEJrU0xXbEtxR1ZiMEZHdlJad3xBQ3Jtc0tsakxHSnBZOGFnbWs5dTA0UGQ3aHg3a3RXNE8zUFM2TnJDTmZZOXVfLXlKV0NQNUdQM000TjBxeDdpaEpyVlZwOGFldUJQSzFWT3JzWFBuRGVmU0NpN3hsT0x5N3JydE81VVVCbEJKdHh5cFM4UThlUQ&q=https%3A%2F%2Fwww.modular.com%2Fblog%2Fmojo-sdk-v0-7-now-available-for-download&v=Ln8ZaJ0gaSA) Mojo ðŸ”¥: [https://modul.ar/mojo](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbDRFTnFzeXR2Y1UyRGNwbGw1RjZNc1BBb1I3QXxBQ3Jtc0tuVzlkWXdRTHRhV2NRS3VneWs2T0czWXFsdXFtdllqR3lYNVdwblpTdEMzcE5EWi1CMUJaZnU1U3B4dXJZalFOWEdIcS04dEJfU1hUX3QtTXFSbURaNGQxd3lNdEpPNTFlM056Z3poRUIwREZwaXBBbw&q=https%3A%2F%2Fmodul.ar%2Fmojo&v=Ln8ZaJ0gaSA) MAX: [https://modul.ar/max](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqazdQMW45cW9GQTdxQ1RldXlSV1F0aTJtQWkzZ3xBQ3Jtc0tsVkk4Mm9wcE1wUW90LXFxUTNRYmVPUm85R3NKb0hxT0E4aE43UC01QUUzR2E4TFRYcFdLWFhVRHg2ZDh0bkZaUWltcWNORlFBa0Z4cHZTVjQ1eTU2YnBUbk1TbF9Ha1c0b2s5M2pUOWdQN3dHNDIzMA&q=https%3A%2F%2Fmodul.ar%2Fmax&v=Ln8ZaJ0gaSA) Join our Community! ðŸš€ Discord - [https://modul.ar/discord](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmJYeFVNeW50Q0NyYmtSNzJPLW5YRkpzSW1XZ3xBQ3Jtc0tuc2JjSHhlcm1FZ1c0TjV2NTRoT29EYzJyU2I0SDI2TUlTSlNlS3RycG9tNW5KOGJyV2xsRDUwNGs1U1c2V200cVQ2b3JzY1d0UmRzcndjQkgzRWtlYklpc1NvUkhxQWkwSm5rakYxLWhsTnpwNEV0UQ&q=https%3A%2F%2Fmodul.ar%2Fdiscord&v=Ln8ZaJ0gaSA) Github - [https://modul.ar/github](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUpQckpmNjBMSktUY2kxTlQyTnMzQ2tseFBFUXxBQ3Jtc0tsZ1BJd0ZNTHA2SmFYNm05YmxiZjRSTDRRVUN5UEl2ZEhBWFQ3UFMxN1VYSDdKVzM2SXI2cnJ0ZDJIcU9zWXJONXdyTEliUHBQVkVDTWdvY1Z2OVp1Ym5sSmF3MEl4a0pzR0dVc3VON3ZyS3BXSFYwYw&q=https%3A%2F%2Fmodul.ar%2Fgithub&v=Ln8ZaJ0gaSA) X (aka Twitter) - [https://x.com/modular_ai](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnhTdEFvUW9qVmI1WkpFdk9lTlVmV3NTVDlEUXxBQ3Jtc0tuTWt2c0FLVjZrRGdtSFIyT3Vlc3lONVpsdVVnQkJYTDJ0dnRfbzJ1VV8wbGpwU05IclVESUlCeTltMXYzRlR3SVhVZktWeER0Tk9zN0FsbW1BTk9wX25hSEtGU3dkMDFiaHhzOVZBakJiV2N3RU15UQ&q=https%3A%2F%2Fx.com%2Fmodular_ai&v=Ln8ZaJ0gaSA)

Transcription:


hey everybody Welcome to the modular Community live stream this this is our first live stream in 2024 so welcome
everyone hope you're having a great 2024 love the fireworks right uh yeah I like
this um this is a warm welcome to the community live stream the we have an
exciting list of topics today the main focus is the recent release of Mojo SDK
0.7 we'll talk about all the new features there we'll dive deep into deep into some of the specific features
uh come on in we'll give a minute for people to join in as you join in let us know where you're joining from it's
always nice to see folks joining from uh all over the world um so welcome uh and
this is primarily a Q&A live stream which means this is your opportunity to ask questions get them answered live uh
we do have topics that we'll walk through specific uh features and demos but we're really here to answer
questions um while you come in let us know where you're join joining us hi from uh uh Central Europe from uh
Switzerland awesome Toronto welcome welcome um I'm I'm here in California
Bay Area um so let's start uh with a quick round of introductions here and
we'll then dive into the topics so welcome again welcome uh I'll go first
uh I'm Shashank I'm a develop Advocate at uh modular and uh who wants to go
next hey I'm Jack I'm a developer abut as well at modula
awesome uh hey I'm Steph uh I'm one of the developers at modular I use Mojo a
lot and sometimes contribute back to Mojo welcome Steph and laslo hi I'm
laslo I'm a compiler engineer and I work on Mojo primarily on the front end awesome fantastic so Steph and llo
are here that makes me feel uh more comfortable taking some of your questions um all your deep technical
questions uh we have more folks joining in from Brazil from New York City Fremont California not too far away from
uh uh here how you enjoying the rain in Fremont we're having quite a downpour
here right now uh hi from Nigeria thank you so much for taking time I know many of you joining uh in uh from places
where the time zone is not the most uh uh comfortable for you to join uh it's
it's 11: a.m. here in California um all right I think uh let's get started now
we are a couple of minutes in uh let's get started so the topic of today's live
stream is uh Mojo STK 0.7 so this
version became uh available a few days ago and this is our latest release of Mojo SDK a bunch of new features uh also
some uh uh changes and fixes and all that we go through them we did do a blog
post uh feel free to uh walk through this uh if you haven't seen it after the live stream right now we'll briefly
touch upon some of the features and we'll dive deep into specific ones that you may be uh interested um more folks
joining in um I love the rain glad to hear uh people from Turkey uh Germany
thank you welcome um uh let us know if the time zone uh doesn't suit you very
well if you prefer it or other time we can try move this around uh welcome welcome and there are already few
questions in uh for feature requests uh we'll get to them so let's do a quick uh
recap of the launch uh we released this on Jan 25th when we release the Mojo s
is now available for download if you do modular um install Mojo or modular
update Mojo so uh one of the main uh uh
we have two buckets of features brly we come in the blog post and we'll go to specific ones a in a little more detail
so their language and standard Library features and there are some enhancements to the CLI and the language server which
is what you use with your IDE visual studio um we have now a Mojo native
dictionary type uh hooray like many of you who who have been asking for this um
that is awesome to have and I know Steph will dive a little more deeper into this
what you can do with it today uh what are some of the constraints and how to use it and all that uh there is also new
features for um getting access to sort of how many CPU cores are there which
which becomes relevant for specific tasks when you want to parallelize stuff there's also new uh reference type this
is an early prototype uh llo will be spending more time on this um as we get
started uh there's uh this is uh a new
feature as well and we labeled it prototype because uh we'll share what it is but also sort of what the
forward-looking direction of that will be uh there are a couple more features in the standard library that we briefly
talk about there are there are uh debug asss in in standard Library which you
can use the uh enable assertions flag when you when you do when you call Mojo
So that uh it can Surface some of these uh assertions and then uh the visual
studio uh gets new features thanks to the uh feature enhancements in the language server you can do now find
references get references so it makes coding a lot more uh convenient and easier and those are some of the main
ones but that's not everything because this is a block post we didn't go through everything the change log has
all the specific what's new what's removed what's changed and what fixed um
so uh those are uh I won't let you read through this now now uh what we'll do
now is sort of switch back into talking about specific features in little more
detail sound good uh let's quickly take a look at the chat and then we will get
started uh a lot more folks from Argentina welcome uh folks from India
Netherlands thank you so much for joining us uh honestly I can't say what time it is there I I'm I'm happy you're
here I'm glad that you are sharing your time with us on the live stream okay I
think we can get started now um lar do you want to take over and talk about
references and lifetime now sure I'd love to do you want to start with the demo or
do you want to give an overview I'll pull up your in any case thank you um yeah so lifetimes and the references are
um something that's uh starting to be uh accessible to users in this release uh
to be fair um the compiler has been internally reasoning about uh lifetimes
um since at least 0.6 and certainly this is a feature that has been in the works for a very very long time it's been uh
requested uh a lot and um yeah with 0.7 you actually uh start to have some of
some control and uh you can actually start to uh to take advantage of it um
as a user of Mojo So as if you don't mind for someone who is um not not used
to thinking about uh lifetimes uh what would be like a quick uh high level
overview definition before we jump into the specific language features like what what does it mean for someone um when
you say lifetimes in a language Yeah so basically what our um long-term goal
with Mojo is is we want to make sure that this is a memory safe language and
um and part of that is is um to provide the users with a model that's easy to
use and basically guarantees that you you know you don't leak memory and um
and also guarantees that if you don't want to deal with um low-level uh details of you know uh managing
particular resources then you don't have to and uh what we say what we mean when
we say lifetimes is is pretty much the infrastructure around this uh and the language features that uh allow you to
to form um to form references and um um make sure that uh you don't have to
think about destroying them destruction happens automatically um and um that you
can do this in a sort of very intuitive way if you will so if you come from a
python background then we hope that this will become something that's completely um completely invisible to you but Mojo
of course allows you to um to drill a little bit deeper um
and um and part of lifetimes when we say lifetimes is also the ability to to open
the box and and have a little more control over uh what's actually happening makes sense thanks thanks for
that uh quick definition so we looks like you have a demo yeah absolutely so
one of the things that um uh that is new in 0.7 is that now you can form
references to objects explicitly and um uh I just prepared a little example this
is actually straight out of the change log and then in the second part of this demo I'll um I'll put a little bit of
sugar on it um but for now I would just like to walk through this and this starts with some pretty uh
straightforward code we just have some strings um and then the new thing here
is that we're forming a reference explicitly to one of these strings and um the interesting thing here is what's
going to happen to to the object uh a in particular so now this object a has a
has something that references it so you know if object a was to destroy then of course this reference uh would be
pointing to something potentially um undefined or uninitialized and the idea with Modo references is that these
references actually extend the lifetime of the underlying object so when I say A
as long as a is in scope I can I can be sure that I can uh that I can access it
and uh I can be sure that the underlying object doesn't disappear so what does this mean in
practice uh this means that for example uh I can uh take um take this reference
and I can modify it in this case we're just concatenating another string to it and um and then of course being a
mutable reference uh I can try to just print the object that the reference was pointing to and so to uh to demonstrate
this let's see what happens if I run this and um you know as you would effect
uh you have something that um that uh prints uh the contents of a first which
is you know the original string let me just update this again uh the original
string concatenated with uh with the second one so we have hello references um and then I can keep M mutating it and
uh I can um I can keep using it and the beautiful thing is that even though
lexically uh the last use of a is here on line seven um the um
the compiler keeps a alive and make sure that even on line 12 you can still access its contents so this is this is
the idea behind references and um uh this is uh this of course it's not it's
not copying a or anything like that so this a ra it's a it's a very lightweight thing and if you are interested in the
implementation details this is implemented through point uh but um the there's a little bit of
extra metadata that allows us to to track these lifetimes um Shashank are there any
questions so far I haven't received any specific questions about uh this feature
specifically we do have some other questions we'll get to those uh but I I have a question I guess so as far as
syntax is concerned the square bracket is similar to like a star thing in C or
like how do you draw parallels to correct yeah so um right now and this is
going to change uh right now when you want to actually access the underlying thing from a reference you you have to
use this empty uh bracket operator which is admittedly not the most um uh
pleasing syntax and certainly we will improve upon this um if anything you
know one of the things that isn't fully uh uh baked out uh with respect to lifetimes is Sy text related to this um
so yeah that's exactly like like a d reference operator would be awesome there is a there's one question uh for
lifetimes any major differences on how Mojo lifetimes differ from rust lifetimes that we should watch out
for yes uh there are a couple um to uh
to get a full picture I recommend that you you read the change log and and the docs we have a couple things on this um
basically basically our philosophy was that we want to we want to learn uh and and take
ideas from rust but we want to do things a little bit differently we want to do it our own our own way which is uh going
to be more uh more convenient and more uh intuitive for people especially who
are coming from from perhaps python um and um and make it I would say a little
more user friendly um a little easier to use makes sense uh there's another question
which is um more for I guess a python type of user why should I even use a
reference instead of using the variable directly I guess the higher level question is what is the benefit of
having references and creating references and using references yeah so so sometimes you want
you don't want to take a copy of an object you just you just want to say hey here is this uh here is this string
somewhere else and I I just want to remember remember where it is and I want to and I want to pass around this
information that there's this string somewhere without actually having to copy it or move it and um so that's what
references do again it's under the hood it's similar to a pointer but it's safe
uh and it's lifetime checked so sort of where you would think to use a pointer uh very often references
work okay um I think I saw another question come in uh I guess you answer
this already will the Syntax for D referencing the pointer be kept in the future I mean if this will not be needed
for references I think you you kind of answered that this may change so that's
yeah and and in particular we probably want something uh you know like automatic D referencing for for
situations like this so you don't have to do anything the compiler just detects that this is a reference and and um and
when it's obvious it modifies the underlying object sounds good okay let's let's move on to the next part of demo
and we'll answer those other questions as they come in yeah awesome so the second example is it's almost the same
basically the only thing that changed is um instead of you can see here I I
directly modify this a ra um I concatenate something to it and in this
case I just replace that with a function call I'm actually passing the underlying string and so the question is like
what's going to happen to AR and what going to happen to a and and what do I get when I try to print this and you can
see the language server is already warning me that something is not right uh with this code and what what's going
on here is um is I'm trying to take this this string and this function
um as a uh what we call borrowed which is roughly the equivalent of a con
reference in C++ so this is an immutable um reference to this to this string and
of course if I have an immutable reference then I even if I form another reference to the underlying object I
should not be able to mutate it and indeed if I if I run this I should get
uh a compiler error that tells me explicitly that hey this CRF here this is trying to mutate an immutable
reference and so the question is H how could I change this code so that it works and one of the things I can do is
I can change this to uh inout and as you can see immediately the the language
server warning goes away uh which is great and when I try to run it um I get
actually what I would expect right I passed this uh this string a to this
function uh which formed uh internally another reference to it and modified
that reference and um the effects are visible right after I return from the
function um and then I can just like before I can keep U mutating um the underlying object a uh however I
want it and um I'll get the desired
Behavior awesome that makes sense yeah so um I don't know if there are any questions so far uh no those were all
the questions um so far on this topic again for all of you watching if you have more questions about this specific
feature please share them in the chat and we'll try to get them get to them
great yeah so uh that sort of concludes the demo uh unless anybody else has has
anything else to uh to add to it uh I'll hand it back I'm super excited for this
feature by the way I'm just like I've been asking for this for so long I mean like obviously we we knew that this is
in the works but like there's just this is going to really unlock a lot like kind of the next tier of Library
development for us there's just so many things that kind of cludes and hacks that we had to do because we didn't have
this yet and now that we finally have it we're we're kind of getting unlocked to write a bunch of great new code yeah and
and I would uh I would ask the community to you know stress test this please uh
please take take it and try to build cool stuff like you have before and if you run into issues um you know Open
tickets and uh we will triage it and we will do our best to fix fix bugs quickly
yeah I I I think um I don't know if you want to add more L I think we did
mention that this is a prototype and this is going to evolve this is like an early version of what you will come to
expect in a more full-fledged way in the future release right so expect some rough edges I suppose certainly I I
think there as I mentioned there will be syntactic changes those are definitely coming we're working on them um there
will be a lot more use of references uh in the standard Library as Steph pointed out this is going to be uh used heavily
um and uh there uh are some Corner cases where you know the lifetime checking
might not be working correctly right now we we do encourage you to try regardless
if you run into something as I said uh open a ticket um but um the uh the North
Star is to have a language where um unless you want to think about memory management you don't have to and you get
safety by default there are a few more questions
um about this specific feature there few which are not specific about this feature which we'll do when we switch
topics uh so are inout borrowed and owned going to uh keep with lifetime introduced I guess they're trying to ask
if those features will uh remain with
lifetimes yes they will they they will and uh they as far as we know they
should work correctly as as I showed in the demo uh with the with the lifetime
Checker so the the compiler can basically reason about what happens to
an object when it gets passed with either of these three conventions borrowed in out or owned uh in fact I
can show it what would happen with owned or which is actually the uh the default
um uh right so sorry which is not the default borrow is the default but if I
explicitly say this object is owned um what would happen uh is that a copy gets
created and uh when a copy gets created it still gets modified so under the hood
this Tak string does um you know post spand the fire Emoji but because a copy
was created sorry but you can't see it outside exactly because the object that
was modified is not a right it's it's a copy of a and it has a complet separate
lifetime um and so um yeah the compiler can reason about these and these are not going
away the another question yeah go ahead check yeah I was just going to point out this question here um asking when the
reference gets garbage collected um so there isn't a garbage collector but uh Mojo is a little bit different to rust
and C++ in that it destroys the value um like as soon as it on the last use so
instead of waiting for it to go out of scope um yeah it destroys it earlier which is kind of like a big deal for AI
type things because you might have like a ton of stuff allocated um so getting rid of it earlier can be a big benefit
sometimes and just one way that Mojo is unique yeah um plus one on that and uh
as I mentioned if you if you look at this particular example lexically it might look like a is less used here and
naively you might think that oh according to the rules of Mojo that's when the destruction happens uh and
that's sort of the big deal about these uh these references is that they actually extend the lifetime of a so a
doesn't get destroyed as long as there are any live references to it and um and
yeah absolutely what what Jack mentioned this is one of the things where MOJ is really unique in particular probably if
you come from C++ and you know have RI in in your mental model this is completely different um and there are
many reasons and and we could talk about why this is a design choice that Mojo makes but uh the for now this is just a
fact and um um and that's how the language is going to move forward so
another question uh can you take a ref of a ref in terms of Lifetime you you
you should be able to yeah try try try it and let us know yeah try try try and
let us know yeah certainly it's it's a thing that people do so yeah okay and uh
of course you know things are not working as expected please do file an issue and uh and let us know um there's another
question a couple more questions coming in now uh so it should still throw an error if a user tries to B mutably
borrow more than once I guess uh I'm not entirely sure about
that maybe uh maybe uh you can file a um maybe you can ask on Discord uh so we
can chat about exactly what you mean by that maybe with a code example yeah if you if you pass like an in out for m
like into two spots in the function then it should uh like reject that as a compiler error but it doesn't do that
right now but yeah we'll add that later it's a issue that we have
open great uh another question which is uh I think this was something Steph
mentioned right it's been useful to him you mentioned lifetimes have helped you get rid of hacks can you show discuss an
example I think are there any standout examples where this simplified your
life yeah so what what uh used to happen is if you wanted to write code like this
uh you would have to create a pointer to this string uh which was um which was
inconvenient to begin with but then the second thing you had to do is is you had to manually extend the lifetime uh of of
a and that's when you would see a sort of things like this uh I I don't know if
if anybody ran into it uh which is you know it's formally extends the lifetime away because there's there's a use of it
later um and basically with this you no longer have to do it okay now I I have run into this there
was a piece of code that wasn't working and I had to add the underscore equal to a d type pointer thingy and then okay
okay now I see yeah oh thank you thank you for that uh thanks for asking the question too there just to add on to
that there's also a lot of cases in our standard Library where we require things to be copiable or
movable um and that's because we didn't really have the ability to say like we
actually just want to reference this thing um and so incrementally we'll be
able to write like kind of more correct standard Library types that are operating on references and not
requiring everything to be like copied around everywhere awesome uh I are there any
other questions that uh I guess this was a followup to an
earlier question and I probably lost the train of thought here um I mean to re
renaming these keywords to St like mute mutf Etc Chris mentioned that about
somewhere I don't know did anyone catch what the conversation was a followup to uh there was like a proposal like a kind
of BU sheding proposal for changing changing keyword names except the decision was we'll wait till later until
more of the language is kind of uh buildt out before we make decisions about renaming stuff like
that got it okay awesome um this is awesome thank you for all the questions
uh I I know there are several questions here asking about um stuff like uh
platform support uh I think I think let's uh so there are a lot of questions
here a lot of folks asking for uh Windows support uh there is a open issue
I highly encourage you to go and upward I know it's on a radar it's something that uh we said we will eventually
support uh today it's supported on WSL of course on on Windows there is an open
issue and uh I guess the only thing I can say is we are hard at work at making
it available in the future I don't know if any of you want to add anything more to that on the
stream about window support okay yeah I guess that's the most we can share right
now uh all right uh question about I
don't know if this is relevant um about the topic we just discussed discussed question about functional programming in
Mojo some improvements of python model and inspiration from other languages is
there any quick thing we can share about functional programming in
Mojo or how we think about it yeah like Mojo has a lot of functional features like it's a it's important to the way
that uh we're doing things and um yeah I think like uh the you know like lots of the
performance heavy code like vectorizing and paralyzing stuff like it's all using functional type
code and yeah it opens up like a lot of uh better ways to do things so you know
like UI type stuff I think Mojo will have some good libraries in that later on down the track just because of all the functional features we have in the
language awesome yeah maybe a slightly technical point but since we were just
discussing this because Mo Mojo is different from uh like rust and that it destroys
objects as soon as possible and that's actually really important for functional programming that there's like a a
concept called tail recursion which is very like deeply Central to functional programming and Mojo supports tail
recursion and rust like can't really support tail recursion for types that
have destructors so yes there's like we're we're deeply considering functional programming and kind of the
language development awesome we'll take another question and move on to the next topic there's still
a lot of standard liary stuff we want to discuss uh GPU support uh someone's
asking and all I can say is stay tuned my friend uh if you watch the modcon uh
videos we did talk about uh some demos and example it's on YouTube you can go check out uh what GP support in Mojo may
look like but all I can say now is uh stay tuned uh I guess there there's the
last question uh I think this is interesting the difference uh is there any difference in
performance between using references and raw pointers after this we'll move on to the next
topic Bas where the goal is there that there shouldn't
be uh ideally lifetimes and lifetime checking this happens in the compiler
and under the hood a reference is just a pointer uh at runtime you should not be paying a cost for this
awesome all right there are still lot of good questions uh we'll get to them but let's move to the next topic and we'll
still continue to keep answering so answering these questions so thanks thanks I think this was very interesting
I learned I learned a bunch too um all right all right
so uh my bad there you go okay uh shall we move to the next topic Steph yeah
let's do it let's do it awesome what am I seeing here dick all right right so
I'm going to talk about some uh new data structures that we added to
some standard Library features basically um here's one that I think people uh
have been pretty excited about I know I uh have wanted to use this for a while in Mojo and have been sad that it's not
there that's the dictionary type um if you're coming from python this will look
familiar but probably like a little bit more Awkward than you're used to so far
um still like a lot of kind of like work to do to kind of like hit the usability that we want to get to but in the
meantime I just like kind of want to highlight that uh we like uh we added
this to the library um so a dictionary if you're not familiar is uh an
associative array it's something like if you want to check whether uh um you know
like let's say you want to have like a collection of things um and and then
uh like count that count how many of something exists right that like dicks are just like a very important part of
computer science and we we need them all over the place um so here you can see like from
collections import dict you got to import it um the dict type is parameterized on the key type and the
value type uh so this is true in Python kind of like you can type your
dictionaries in Python but you don't have to obviously in Python you can anything here this is more of like a
static type right now it's more lowlevel so you can only have one type of thing
in the dictionary um but then once it exists you can kind of use it the same
way you use a python dictionary you can access it um get the length uh get the
value associated with different elements um or remove elements that sort of
thing um one limit ation that I want to call out here is you can see that here
we're using something called a string key and not a string U this is something we're kind of actively working on but
didn't make it into the 7 release um but uh the key has to be this kind of like
where's the example of this sorry for scrolling around oh here we go the key has to uh uh conform to this key element
trait right now and that means uh it's got to be hashable and this is kind of which means
it has to be like you have to be able to get an integer out of it this is how we get a lot of the good performance out of
the dictionary is is being able to map a type to an integer that lets us sort of
uh internally efficiently access or look for that thing um and you have to check
whether it equals something else and that's sort of a a really typical dictionary requirement obviously if you
have a collection of things and you want to you know get that thing out of the collection you need to know whether you
found it or not so that's that's like I think like the two the sort of most minimal version of this um these other
methods here these Constructors are here for uh kind of the conversion so you can
see here even though we called it a string key um we're just passing in a string here right and the way and so
these these Constructors are allowing us to do that they're saying like hey you can just turn a string into a string key
it's fine awesome um there questions here uh
about this feature I yeah folks feel free to ask questions about i i i i find
I I was super excited when I saw this because and as Steph mentioned like dictionaries are something very very
fundamental in data science and in lot of projects where you want to keep you know key value pairs of stuff that you
want to maintain um I I know one of the first questions I asked St when I saw
this was like uh and he already addressed it is can I have like variable values right between inss and floats and
strings and stuff like that uh you did mention there was another variant or
something we could use right I I forget uh let me jump on this question in the chat really quick you can't use in for
dicks at the moment is find the way to do this yeah that's right uh we haven't implemented that's you know like on the
list of features please file an issue about that um you know all these usability things we really want to
improve uh but yes you can use find right now to to to do
that and I will share the link to the um place where you can file file the issue
so that's github.com modular ml Mojo issues so yeah anything and everything
please please find an issue we we love to see stuff from the community um use
it and thank you um and the it's the dict ordered uh yes so the underlying
implementation is very similar to uh to Python's dictionary so it's
extremely efficient Python's dictionary like because it's dictionaries are so important to the language it's extremely
optimized so we use a very similar dictionary implementation it's really
fast um and it but it does retain Python's uh kind of ordering feature so
although you can't uh iterate through a dictionary yet that's related to uh
references um we just like uh are are kind of getting unlocked on that uh but
when you can you will be able to see them in order uh like in insertion
order there are a few questions there Steph if you want to fire through them feel free to go ahead yeah um let's see
we'll get to optional in a minute I think uh adding n items to the dict is o
n yeah so this is a this is going to be kind of an efficient hashd the average
time this is there's a bit of nuance to this question but the short answer is yes it's amortized o of one for all the
operations so it's going to be all the kind of like nice behaviors that you expect with python dictionaries um in
terms of speed um see will there be a separate dict
implementation for heterogenous collections um so I think let's get to
that when we talk about uh uh variant but uh I think that
like we still you can still use the python dict the way the kind of like docs say that they can so that's really
nice um and uh and uh with variance you can
actually uh hold heterogenous data in in this dictionary
type all right should we jump on to the the next top the next topic here yeah
let's do that we'll answer some of the non-specific standard Library questions
um after we go through this exam okay so I'm going to talk about two other
features that uh I think made it in but we're not highlighted in the change log
but I think we're critical to implementing dictionary um one is variant and this is really
kind of the first uh like Dynamic type in the language everything else you know
Mojo really unless it's like kind of in its sort of like python mode um
everything else is like kind of a static type the compiler needs to know what type it is and with variant you can say
this is going to be one type or another type and you can put more types in here as well you can have like a variant of
many different types um and then when you pass something in you don't have to know whether it's an ENT string uh until
until you're running right you could load something in you know conditionally you could put a string in here an INT in
here um and then you can ask uh whether it's currently holding a string or not
um and get a string out um or you can uh you know get the other type out for
instance um and this is really great because uh I think like this is this is
just kind of like key to to a lot of usages Right Where You Like Json for
instance if you wanted to write something that represents
Json um you could have your dictionary type like hold a reference to you know
something that's a variant of several different types um does that make
sense yeah yeah the I the I guess the question I have and
it's a little forward-looking thing I guess um will the expectation moving forward would be to use the dictionary
as it is today with the variant or um should we see dictionaries that support by
default uh or if that even makes sense right because a lot of use cases do require different values or this is a
recommended thing or is that something we want to community ask and I think I
think that's right I think like this is what we're going to move forward with for now like this that's not to say that
this is going to be like what exists forever um you could also you know we have like an object type that supports
kind of uh are you know uh it's like a bag of things um and so if you want to
have your value type be an object you can still do that um and and kind of get
full dynamism that way um but I I really encourage the community to kind of play
around with this uh figure out what works if this is like really limiting like help us figure out the way
forward awesome uh is this in the same context as a question about uh what is
this the way for supporting enum types yeah so this is actually very
close to rust's enum type so enum is kind of a an overloaded term like
different languages think about it in a pretty different way um but this is this is essentially a rust enum just we don't
have the nice like matching sugar yet uh but you can think of this uh it's it's implemented very similarly to to like
rust enom type so that means you can uh you know have a variant of whatever
different types that you want um and then uh and then use them I think if you
want like a c style enum you really want something you really just like want an
integer with Alias names for the things and you can do that in Rus and or in
sorry in Mojo uh already here's the another question
object versus variant can we expect variant is much more space
efficient yeah um absolutely so variant is going to be uh it's going to take as
much space as the biggest thing that goes in it um and object will so it it
actually kind of depends um object is always going to have that overhead because object is basically like a
pointer plus some metadata about what's going in it um and then the underlying
data so if that metadata you know like let's say um I had like some really
expensive thing here you know it that like something like some type that like always took a megabyte of data here and
then I just put some like int here then if I you know like I might be wasting a lot of that space and then an object
might be more efficient but the vast majority of cases this is just going to be more efficient than object because
like these are going to be pretty uh these are going to be like essentially exactly the same size um and so you're
just not going to have that overhead from the object
type great the I think those are the dictionary and variant specific
questions had unless I miss something uh that sounds good yeah can I can I talk
about optional for a minute yeah go for it okay so optional you may recognize
from a lot of a lot of languages are are adopting something like this now optionals kind of like once we had
variant making optional was really easy um but one thing I really love about it and it you can't really tell from this
uh but it looks a lot more like the python optional while being just as as strongly typed as the other languages so
if I say if I if I need to pass an optional to a function I can just pass
the value none I don't need to tell you oh this is an optional but it's an empty optional I can just say none right and I
get the empty optional type which is really cool um but what an optional is
is it's a thing that might be there and it might not and so here you can see like a is an
optional int um and it is there and B is an optional int and it's not there um
and you can check uh you can say like if a so this is going to be true because a
does have a thing in it um we'll get the value out and print it um and if B well
B is a is a none it's an empty optional um so this is not gonna this this if is
going to resolve to false it's not going to print it um and then we have a couple helper methods um these are things that
will also benefit a lot from from references uh we'll be able to add more kind of like helper methods here um but
you can also uh you know like sort of get a thing or a default so here
like these are going to be uh uh you're these are going to be ins that you get
out but like the first one you know a exists it's one so or else two well it's
still going to be one B doesn't exist or else two so we're going to get two here
a question um um on the chat about dictionaries can you have a dictionary
of a key and a struct some custom struct that a
user yes absolutely yep that's yep you can do that right now any any type that
you want to put in the value uh I think the limitation is that the value needs
to be uh copyable and and that's for the this is like one of
those things that we're looking to relax once we have references kind of once we
push those through everything that's interesting so I could like have a dictionary of like tensor with label
layers and stuff like that right oh absolutely awesome um they for I think
uh here's a question about uh when these features are available so which version
of VAR which for which which version this variance and optional is coming well the answer is it's already there I
think um it's been around for a couple of releases now and I think we we should
do a better job highlighting and documenting them so everything you showed today Steph is stuff people can
go start using right now right yeah this is all in the standard library today it's all there so yeah thank you uh
thank for asking the question and yeah feel free to like start using them and let us know if you feed back the other
question if uh is if a is is equivalent to if if a is
equivalent to if a is not none yeah so this is a yeah this is a bit of a
technical python question but yeah it's it's the first one um it's it's saying
like there is something there it doesn't check so so for instance if I did
optional of zero here if a would still resolve to true because there is
something in the optional even though the the you know the truthiness value of
that interior thing is false that's a kind of like subtle point and that's great to bring
up here's another syntax related thing we have R else so there's a question
they're asking country do a or to instead of yeah that's a great question
um I I need to try that I think we have some things I uh please please try and
file an issue that should work um one issue is that when you do a or two
you're if a is is true you're going to get the optional value so it's not going
to quite do the thing that you want coming from Python and I think those are uh whether it works or not those are
both great issues to file because that that's like a great call usability
Wise uh another question can variant hold a Tuple with multiple different
types and then multiple tupes all with different types sure yeah go for
it try it try it and let us know right yeah awesome I think those were all the
questions about this uh I do want to go back and address this one question that came uh they said it's more of a product
question how do you determine what features roll out next is it based on demand I think there are a few different
signals one for sure is the issues that you all file so please go and file
issues uh a lot of things that get uped are ones that eventually make it for
example Mac version was one of the most highest voted uh issue of all time I
think and you know we promptly worked on that Windows is closed so that's you can be sure we working on it so please file
issues because that's the best way to let us know what you're working on the other thing I guess we also prioritize
based on on other internal needs like some language feature that L is working
on benefits step in building standard library right so there there are those kinds of signals internal signals and
then at modcon we also announced Max and Max engine um an inference engine um
that we announced so there are needs that those teams also uh expect from the Modo
language so the few different signals but as far as communities concerned like the GitHub issues we constantly look at
those and I think we have uh couple of topics related to prioritization where
we will discuss uh in a moment so yeah so the best thing you can do is go file
an issue or if something exists like go up vote it like do a thumbs up for a heart or something like that um all
right is the so this is all the topics you wanted to cover right step y that's it thanks
Shashank awesome uh I know there were few do other standard Library stuff but
um um I think we briefly touched upon those unless we want to spend more time
on uh what else did we talk about we uh we spoke about the dictionary types um
yeah I think this this is something that's uh a feature that that Jack
worked on which is you know being able to access number of physical course logical course and performance course
that's in the standard Library um we spoke about reference so yeah that those
those were all the key things that we wanted to discuss but we do have another topic um should we discuss this now the
Mojo committee stuff um who wants to
uh sure I can say a few few things about that yeah so um we have started a uh
should I pull up the uh so so people have contact should I pull up the newsletter or or
the yeah please uh please uh show the newsletter yeah absolutely and then and then Jack will talk a little bit more
about that in a bit uh but um basically for the community what this language
committee uh will mean is just a um more uh principled and uniform and
predictable way of communication uh when you uh file feature requests so nothing really
changes for you uh in terms of your workflow if you have an idea for something that you would like to see in
Mojo uh please um file a GitHub ticket and we will triage it the difference is
going to be that internally we will have um periodically recurring meetings when
we will with the committee discuss these and we will uh reason about um whether
that feature is something we want and on what uh time frame we might want that
and then we will communicate this uh very clearly with you uh through GitHub
uh but also uh also through the newsletter and uh maybe uh Jack you can say a few words about that yeah so every
couple of weeks we'll have this just summarizing all the different decisions we've made um so the comment will be in
that GitHub issue like leslo said and then if you just want to get a summary of what decisions we've made then you can come here um and yeah this is just a
kind of show that we do like take your feature requests seriously and we talk about them um and if you go to your next
tab the shank um so this is one that came from a feature request uh so Jeff
one of the engineers put forward a proposal internally um so we look at it internally and then we put it to the
community so you guys can make uh comments and ask questions um so yeah if
you want to talk about this one you can have a look at the proposal and then you can you can make a comment if you if you have any suggestions or you have any
questions so the call to action for the community um uh last one Jack is that
take a look at these discussions and have a conversation in GitHub right like go share your exactly
yeah the last one we had was getting rid of the let keyword which had tons of discussion like everyone had input on
that so if you have any input on this this is to make it so that parameters can infer types from other parameters um
so this is like an important feature that we want internally as well so if you have any comments about this just take a look and and and let us know okay
the best way to get to here is uh the Mojo and then discussions discussions
here right yep discussions then and in general okay and then
General so there was a question today about uh let keyword and if it's going
away and you you just mentioned that there was a discussion about uh let and
I should probably find it if I search for it here right yes okay so was there a decision made on this or um yeah yeah
it's uh we will be doing this in the future yes removing yeah I I think this this ties
into the answer I was trying to give the question about product prioritization so I think these are all good mechanisms
and uh ways to get your ideas surfaced and communicate with us and you know we
we we love to work with you and have your feedback in right um awesome the
anything else to share about the committee things so that's it and and the yeah I guess I'll reiterate the fact
that um Jack does these awesome newsletters that that's one of the best ways to get
a pulse on what's going on uh not just in the in in in the committee and the
updates that we share but also in the community uh I think we just published one yesterday right jack you just
published one yesterday and largely we just recap stuff that happened in the week the releases some block post that
we published or videos upcoming live streams like this one you're attending thank you for all being here um and if
there's a committee update then those will be here too so um this is where you can sort of get
the summary updates if you will uh if you're not constantly watching
GitHub any anything else uh to share on this topic oh no yeah that covers it yeah
just wanted to show that you know all the all the things that you raise in the feature requests like we do take Serious seriously and we care about so uh yeah
thank you for all the feature requests and issues awesome so uh I know we have just a couple more minutes uh we'll see
if there are questions that we couldn't get get to
um could you share some sneak peeks for 0.8 release I don't I don't I don't um I
definitely don't have that kind of insight but uh I I think the best thing I can say is uh there's some exciting
stuff um this month I think I think you all will agree uh on the stream there's
some exciting big new stuff that we've teased about at modcon nothing that that
is uh too surprising if you haven't been following um our news but um I would all
I would say is like stay tuned there's some exciting new stuff uh new products and features and stuff like that other
than that uh uh where will this video be published oh that's a good question so
all the live streams actually will be available on YouTube uh they're under the live section so you can go watch
there six of these now uh we started the very first one back in August where we had Chris latner he answered a bunch of
like directional questions about Mojo the language so feel free to check the past ones out they're very relevant um
the features obviously have been evolving but sort of the direction of Mojo and all of those are are there feel
free to catch those as well and uh there's one um earlier in the Stream about they get t-shirts we're wearing so
any community members that build something cool in Mojo I contact them and I get their like a dress and we send
out swag so we send out shirts and stickers and all that kind of stuff yeah join Discord I
think yeah if you're not on Discord join Discord share your work like uh folks
have built some amazing projects and shared with the community U many of you have seen llama many of you have seen
some of the other ml Frameworks that are there so those uh you know we see we ask
you for your information and we we we've been sharing uh uh there's a question about are you hiring compiler Engineers
I I think there are tons of openings right now in the company I highly encourage you to check the carriers page
and apply i i as far as I can tell we are actively investing and and growing
so yeah please please do do apply on the website um highly encourage you to do
that um I'm very happy with the speed Mojo is growing thank you uh thank you I
think the whole team and the company appreciates that and uh yeah one more
question there can we say the library code so um yeah that's something we'll be doing we'll be open sourcing the standard Library um so yeah stay tuned
for that yeah I think we uh Jack that was we we did you're right like we had a
couple of questions coming today about open source stuff I think we've been like sharing our plans consistently um
as I mentioned the very first live stream Chris like spoke about his philosophy uh on open sourc say be be sure to check
that out but also at modcon we open source the documentation now all the docs that we have is open source so
we're taking like small steps to head towards uh that that direction and uh uh
as Jack mentioned like it's in the plans to slowly open up and give more access to you the community to you know um grow
grow the standard Library add in your own sort of um features in the past but
that hasn't stopped many from building awesome awesome projects on GitHub uh I think we always impressed to see some
cool new libraries that show up uh all right I I guess I guess we are almost at
time we are actually 20 seconds away from the 1 hour mark uh I think we can start um wrapping up now I I want to say
thank you all for giving your time with us I know some of you even mentioned it was like 1:00 a.m. where you are uh we
deeply deeply appreciate you spending your time with us at ODS and uh we also are happy to try
other time slots feel free to share if something works for you better uh thank you for spending your time with us hope
you enjoyed the live stream hope you learned something new the video will be available you can watch them offline and
also the past ones and uh again I want to thank like llo and step who actually
built the product and took time to be on here um any any final words from all of
you uh before we close no that's it thanks awesome thanks
everyone and uh stay tuned uh watch out for the newsletters and uh we'll see you in the U next live stream
bye okay

----------

-----
--07--

-----
Date: 2023.05.06
Link: [# All you Need To Know About Mojo Programming Language](https://www.youtube.com/watch?v=RI2F6u9dnkU)
Transcription:

so after charge jpt right now the Talk
of the Town is about Mojo programming
language
and in this past two to three days I've
got a lot of mail from various people to
make a video on Mojo programming
language to just talk about like how it
is different from Python programming
language what are the advantages of
using Mojo programming language and many
more I even got a very interesting email
yesterday saying that one person was
saying that will Mojo programming
language take our jobs or not so guys
don't worry nothing is going to take
your jobs unless and until you're not
getting skilled right you don't have to
worry about your job right so let me go
ahead and let me share my screen and in
this video I'm going to talk about the
entire Mojo programming language step by
step will understand all the companies
will try to understand why this can be
better than Python programming language
but at the end of the day I'll be making
some kind of conclusions that will be my
suggestion based on my thinking you know
it may change with respect to your
overview okay I'll be talking about this
and how much time we may also think that
if this programming language is coming
how much time it may probably take to
replace python so we'll be talking about
all those things so please make sure
that you watch this video till the end
now yes about Mojo a fire Emoji this
looks like a Mozilla fired Fox Emoji I
guess a new programming language for all
developers uh if I talk about Mojo it
combines the usability of python with
the performance of C unlocked
unparalleled performability of AI
hardware and extensibility of models
okay
now yes this is basically saying it is
just going to combine the usability of
Python and the performance of C so if
you don't know with respect to C
programming language it is very very
fast right so that performance it wants
to include in this programming language
to know more about the Mojo right I have
just gone through this amazing
interesting article uh this was in the
theresister.com and we will try to read
this guys please make sure that you
watch this video till the end we will be
reading together because if you really
want to understand something it is
better to learn everything about this
right how it is Advantage what are what
all things are basically then based on
this article I was able to find out each
and everything okay so yes be with me
and let's let's read this I'll be
reading in front of you and we'll
discuss about everything that is
mentioned over here okay that is the
reason why I am saying you that if you
really want to understand whether this
can create a bigger impact in the future
please read along with me okay
modular and AI startup with the above
average technical cred has unveiled a
programming language called as Mojo that
aspires to combine the usability of
python with the speed of C so it is
basically going to combine the usability
of python not it is not going to take
Python and probably take C separately
and combine them no usability right and
with the speed of c and it is basically
going to create this new programming
language so as you all know Python
Programming is a language basically
people say that it is slow and obviously
it is a little bit slow when compared to
programming languages like C C plus plus
right so if we are able to get all the
features with respect to the python like
model or coding with respect to all the
things it has all the functionalities it
has and with the speed of speed
obviously this will lead us to train our
AI models very fast it will be able to
help us to even develop our application
very much quickly okay so there are
numerous ongoing projects to make python
faster it is not like this is the first
time it is coming right there are many
things they are like Jacks uh if you
don't know about Jax it is a high
performance array Computing you know it
provides you API uh which will be able
to do all the numerical computation very
much quickly so I will also be providing
this link you just need to probably
install it in this way and you this you
can do it in CPU GPU and on CPU also it
will try to use the uh course like what
are the default cores that you
specifically have it will try to use
that to do any numerical competition and
if I talk about machine learning deep
learning internally those are all about
numerical competition right now Jax was
already there along with this uh you can
also see that there is also a recent
compiler called as codon if I open codon
over here so codon is what codon is a
high performance python compiler that
compels python code to Native machine
code so directly it is compiling the
python code to the native machine code
and once it does that obviously the
execution will uh increase right so here
it is is basically saying 10 to 100
times faster right on just a single
thread right
so this is the thing about that right
and one more programming language I've
always made a playlist on that light
Julia right so Julia programming
language they also say that this is very
very fast and obviously it is fast right
and this is also an open source
programming language this will be super
helpful for visualization data science
and this is in the advanced stage right
people are able to do many many things
with this and the community with respect
to Julia programming language is also
increasing right and many people were
initially saying that can Julia replace
Python and still python is the favorite
right now right Julia has some good
amount of packages open source libraries
and all but python it has a huge huge
libraries right so still if Julia also
wants to overcome Python programming
language it is going to take time
because the fan following of python is
too much right with respect to companies
research and many more things right so
yes people are also using Julia I have
also explored Julia but still it is
going to take time to overcome them
right and it's going to take time a lot
of time basically because uh when I see
the number of packages and compared to
Julie and Python Programming there is a
huge difference okay when I say packages
I'm talking about libraries okay now
these are already there right but what
is so special about Mojo okay so Mojo
managed to distinguish itself from
python enhancement efforts through the
extremity of its alleged acceleration
that it is trying to make when compared
to python this will be 35
000 times faster than Python and this is
the main key term right and because of
this what I also feel that yes if Mojo
comes in the future this can really
really replace python but again there
are some more things that I really want
to talk about you know because directly
you launch a programming language and
cannot replace python over there python
has lot of different functionalities
still right we'll talk about that okay
but it is saying that okay fine 35 000
faster than Python and here also in the
documentation you can see like uh with
with respect to combined with other
programming language so yeah python 3.10
scalar C plus plus it is five five
thousand times faster than Python and
when I talk about Mojo it is 35
000 faster times right so this is the
basic difference and this is what is the
most interesting thing right
now when running numerical algorithms
such as thanks to the hardware
acceleration and pedigree of CEO Chris
lattner so Chris lattner uh uh is the
CEO of this modular and uh he had
basically announced about this specific
thing now Latina
uh developed something called as llvm
compiler tool chain okay so this is
based on the mlir compiler
infrastructure what is mlir mlir if you
don't know multi-level intermediate
representation and because of this only
that 35 000 times faster when compared
to the python is basically happening
because of this compiler okay mlir okay
and if you don't know guys the latner is
also he has also developed this Swift
programming language Swift programming
languages famous because it is very very
fast right so this is the overall idea
behind this and if you don't know how
this mlir compiler works you can
definitely read an article over here how
things are basically there all the links
I will be trying to give in the
description of this particular video
okay now there are two major things that
are coming up okay so this year old
startup this week announced two related
projects one is Mojo a programming
language built on top of python that
performance the performance of C so you
have something that is like a super set
of python and it will try to build all
the features that are available in the
python along with that we'll try to
build some more additional features uh
when compared to the python along with
that what it is going to do it is going
to take the speed of performance of C
right so obviously if you have that kind
of programming language it is obviously
very very good right and the second
thing that it is developing is something
called as modular inference engine
now modular inference engine is to run
AI models rest expensively in production
and this is specifically required what I
believe right because right now if I
really need to train a model it is
taking time right just with the help of
python by using libraries like
tensorflow or pytosh but with this
modular influence an engine will be able
to run AI models Less expensively in the
production okay so in short it is saying
that Mojo combines the parts of python
that researcher love with the system
programming features that the use of C C
plus plus and Coda okay
now this is the overall thing you can
probably read about this the main thing
is about the mlir okay that is what is
basically mentioned over here with
respect to this so this will be super
super amazing now whenever I talk about
this right we will uh just go through
this documentation and there are a lot
of documentation for this you know if
you really want to uh get this access
you can just apply it right now it has
just announced it if you say play with
Mojo over here you just go ahead and
fill your information I've just filled
it they will provide you probably if if
you get the access they will provide you
some Jupiter notebooks to play with
right but at the end of the day this
looks absolutely good uh with respect to
uh new programming language which has
that python qualities and all and they
have some examples right of this kind of
code see in Python in Mojo how different
it will look like and one more thing is
that over here since it is a superset of
python right it will also be able to
access the different different libraries
but now my main takeaway what is the
main takeaway in this specific thing is
that can it replace python see guys
many people initially when Julia came
they were saying that it will replace
python it will do multiple things it can
replace multiple it can do uh you know
that is the basically the future but
understand one thing guys right uh in
this Mojo right there is a very
important statement that has also been
written the features that are going to
get added in this module is going to
take time right and how much time I
don't know till then let's say after two
to three years it is going to take time
to add up all the features in this Mojo
So after two to three years don't you
think someone new invention something
new may come up right if everything goes
fine yes it has a chances that we as a
data scientist or AI researcher we may
use this for doing many things right
there are also other programming
languages like Matlab there are they're
Julia where people are also specifically
using but when I talk about using a
programming language I'm talking about
worldwide like maximum percentage of the
people even in companies Industries they
should be using it right what I feel is
that yes it this can be an impact it can
create an amazing amazing uh advantages
for the AI developer but yes I feel it
will take time okay it will take time so
don't worry whatever process because I
was just getting 100 of emails where
people are saying Chris should we stop
learning Python programming language
similarly in the case of Julia this had
said me once uh similar in the similar
way right so don't worry just focus on
your learning pattern focus on your
study pattern when things are going to
happen it will come at that time you
just need to update because this is
almost a super set of python you will be
able to use the python libraries itself
internally and all right so yes this was
more about the Mojo programming language
I will be providing you this amazing
link you can read about this everything
is very much clear and short over here
but my my main point is that yes this
can replace in the future but it is
going to take time because python has a
very huge Community when compared to
Julia when compared to other things
right so just to replace that company
and move it to something else it will
take time okay uh yeah this was it for
my side I hope you like this particular
video I will see you all in the next
video thank you take care

----------

-----
--06--

-----
Date: 2023.05.04
Link:  [# Mojo Langâ€¦ a fast futuristic Python alternative](https://www.youtube.com/watch?v=V4gGJ7XXlC0&t=4s)
Transcription:

it is May 4th 2023 and you are watching
the code report python is a wonderful
language for productive programming but
it has one big problem it's too slow and
going slow means you'll get made fun of
by the rust and C plus Chads of the
world but the tables are about to turn
thanks to a brand new programming
language called Mojo a superset of
python that's not just two times faster
not ten times faster but up to 35 000
times faster than your grandpa's Python
and that's a huge deal because Python's
the dominant language for artificial
intelligence but behind the curtain
anything that needs to go fast is
written in C or C plus plus in today's
video we'll take Mojo for a spin but
first here are five things that you need
to know about it one this is not some
random guy's side project on GitHub but
rather it comes from a company founded
by Chris lattner the guy who created the
Swift programming language and the llvm
compiler tool chain if anybody could fix
Python's problems it's him and if you
have no idea what llvm is check out this
video two it's a language designed for
programming on AI Hardware like gpus
running Cuda and other accelerators it
achieves this by Leverage multi-level
intermediate representation to scale to
Exotic Hardware types without a ton of
complexity and it even has built-in Auto
tuning to optimize your code for your
Target Hardware three it's designed as a
super set of python in the same way
typescript is a superset of JavaScript
so you don't need to learn another
language to take advantage of it and
this is unique compared to other modern
systems languages like rust Zig Nim and
so on which would have a higher learning
curve for existing python programmers it
does have a bunch of features on top of
python like VAR and Lut declarations and
structs but the base language is fully
compatible with python and it can also
interop with the python ecosystem which
means you can still use your favorite
libraries like numpy pandas Etc or it
adds strong type checking to the
language you can still use Dynamic types
if you prefer but static types are
essential for optimized performance and
error checking for memory management it
has an ownership system and borrow
Checkers similar to rust and also
supports manual memory management with
pointers like C plus plus it's a
pragmatic language that gives you safety
but also the flexibility to be unsafe
when needed now the final thing to know
is that currently it's not available to
the public it's still in very early
development it will be open sourced in
the future but currently there is a wait
list to try it out I was lucky enough to
get Early Access so let's fire it up to
run it you can create a file ending in
dot Mojo or dot fire Emoji that's a huge
advantage over python which doesn't
allow you to name your files in dot
snake but we can also run the code in a
Jupiter notebook where it behaves like
an interpreted language here we have a
matrix multiplication demo that computes
a DOT product to demonstrate the crazy
performance gains we get with Mojo first
it benchmarks a basic function in Python
then by simply importing that code into
Mojo it's executed 14 times faster with
no modifications to the code but we're
only just getting started we can further
optimize this code by adding types to
the python implementation Mojo allows us
to do that with its built-in struct
keyword a struct is very similar to a
python class but structs are static
unlike classes which are Dynamic inside
this truck we ALS have keywords like VAR
and let which can Define mutable and
immutable variables and Def is replaced
with FN which is a stricter type type of
function also notice single instruction
multiple data which is a built-in type
that represents a vector where a single
instruction can be executed across
multiple elements in parallel on the
underlying Hardware once we have this
struct we can then use it as a type in
the python implementation then when we
Benchmark the code again we get a
ridiculous 500x performance boost but
we're still not happy yet in the Inner
Loop we can query the vector width
instead of hard coding it and that gives
us a thousand X gain but that's nothing
compared to what we're about to do
linear algebra is perfect for parallel
Computing and we can easily make our
code multi-threaded with the built-in
parallelized function increasing our
speed buff to 2000x but now I've got a
fever and the only prescription is more
performance luckily Mojo has built-in
tiling utilities that basically allow us
to cache and reuse data more efficiently
and we can even auto-tune it to find the
optimal parameters for our Hardware the
end result is over four thousand times
faster execution compared to the
original python code that's pretty crazy
and if you want to see this code broken
down in Greater detail I'd highly
recommend this video from Jeremy Howard
but I'm curious is what you guys think
do you really think Mojo could kill
Python and C plus at the same time I'm a
bit skeptical but employers are already
hiring Mojo developers with 10 years of
experience this has been the code report
thanks for watching and I will see you
in the next one

----------

-----

--05--

-----
Date: 2024.02.10
Link: [# Mojo Is FASTER Than Rust](https://www.youtube.com/watch?v=kmmqHV26Ukg)
Transcription:

hey a community Spotlight outperforming
rust DNA sequencing parsing benchmarks
by 50% with Mojo okay look at this this
is my guest blog by Muhammad Mauk
Mohammad uh is the creator of Mojo fast
trim a Mojo Community project Mohammad
received 100x benchmarks improvements
over Python and 50% improvement over the
fastest implementation in Rust by the
way it's not surprising if you're doing
DN DNA stuff you know for a fact you
know for a 100% fact that there's a for
Loop in there you can't you can't just
be writing for Loop in Python okay you
can't be writing four Loops in Python
okay that's not that's not what Python's
for he learned the language quickly cool
story bro and it only took 200 lines of
code for the first implementation read
on for details for the extra
optimizations he's applied to beat the
fastest existing
benchmarks learned yeah learned is past
tense it's past tense learning he
learned it imagine showing something as
fast but comparing it to python yeah
dude Python's crazy that's a crazy one
the era of big data in bioinformatics
the challenge of for bioinformatics in
modern day are rooted in Big Data
manipulation thousands of multi-million
dollar DNA sequence machines are working
non-stop thousands of multi-million
dollar that is like that's a crazy
statement billions of dollars most
people say billions but man this is
thousands of multi-millions non-stop in
fields of Bio uh biotechnology medicine
and biomed research the annual
sequencing data size is expected to be
up to 40 exabytes of raw sequences by
2025 that's 20x the data uploaded to
YouTube Every year that's a lot of data
that's a lot of data so this makes sense
a 1% Improvement is insane that's it's a
lot that's a lot of data uh While most
of the final analysis is carried out in
high level languages like Python and R
the world of bioinformatics is powered
by an underlying uh under layer of black
magic highly optimized tools written in
C C++ and
Java say what now that pre-process and
summarize large amount of raw data Java
did some did someone just sneak in a
garbage collected language uh this
creates two World a two world problem or
at least it's not a three body problem
where bioin uh bioinformaticians uh who
are not skilled in low-level languages
are prohibited from understanding
customizing and implementing low-level
oper uh operations yeah uh I'm pretty
sure if you're a bioinformatician which
sounds like a madeup word you could
probably learn a low-level language
that's I mean literally smart people
suffering from skill
issues that's how I read that statement
is literally just like due to skill
issues
in addition typical bioinformatic
pipelines are a mixture of
bash Python scripts called into
pre-compiled binaries along with
analysis logic itself it's be it's
becoming increasingly complex and
frustrating for a new and experience bio
bioinformaticians this is the same issue
that a community AI is facing skill
issues skill issues and tooling issues
Mojo one tool to rule them all I first
heard about Mojo from a demo video by
Jeremy Harward its value offer is simple
a pythonic language that allows the
programmer that is a strange phrase that
I just said a pythonic language by the
way the idea that we're going that there
is a class of languages called the
pythonic languages I mean I've heard the
term c-based or ml-based but I've never
heard pythonic based that is like it's
Unique it's a unique way to describe a
language uh that allows programmers to
optimize a at a much lower level to
unify the fragmentation in fields such
as AI learning Mojo was relatively easy
for me coming from the python
I got used to the extra syntax in only a
few days I decided to try
Mojo in a serious project for low-level
bioinformatic task the fast Q parsing
and quality trimming fast Q is a basic
format for most DNA sequence operations
incorporating both the Geon the genomic
sequence and confidence scores in the
machine in each base call it is a simple
format to parse with most records
looking like this I I really do hope
that he used a a regx to parse this you
know what I mean you know what I mean
yeah definitely
100 too soon too soon Cloud Flare still
reeling uh however typical uncompressed
files are one to 50 gigabytes uh an
average sequence heavy study could
generate uh north of a one terabyte for
a single file performance is critical in
parsing and data manipulation I tried to
I tried to write a simple parser that
would read a chunk of file as a string
split the string on new line separators
take four uh take each four lines
validate that they are consistent and
correct uh fast Q record and return it
rinse and repeat until reaching end of
file okay seems reasonable on the first
try Mojo fast trim achieved 8X the
performance of Python's seek iio I was
pleasantly surprised with the
development time my code was still
pythonic by the way if you use this word
in a stack Overflow question you will
get more up votes just so you know I did
try to Farm Credit One Time concise at
around 200 lines and using features the
average python developer would
understand in quality trimming where
lowquality bases are removed from each
read it achieves 50 to 80% % of the
industry standard uh tool cat Adept that
was a surprising level of performance
for development time I put into the
project is X or why more pythonic
idiomatic rust canonical JavaScript dude
idiomatic I just hate that word it just
makes me want to die uh going down the
optimization Rabbit Hole uh the most
powerful benefit of Mo
Mojo is that it gives you access to
low-level optimizations the nent state
of Mojo standard Library meant that I
had to write test and Benchmark some
functions from the ground up Mojo's
first class support of sim D nuts uh
vectorization was really helpful and
surprisingly intuitive nent yeah nent
means like early on state right isn't
that just means early uh especially of
the process of organization just coming
into existence or beginning to display
signs of future potential nent it's what
smart people say instead of early you
know like like I would just say the
early state of Mojo but some people use
the nent state of no because you are
smarter if you use bigger words here is
the implementation of the vectorized
version of the function to find the
index of a new line separated in Mojo
okay always in line all right do a
little bit this love the dtype got to
get that dtype uh in tensor T generic T
chart int 10 start int zero int four I
and range all right start in tensor Char
return okay I mean that's very simple
code to I mean I can pretty much guess
everything but I don't know what a
tensor is I I I don't know what that
data type is but okay simd vectorization
all right all right oh gosh here we go
all right same same same header simd
width equals simd width of T length
equals element start this align start
math okay okay for record aligned with
simd load okay we load it up we mask for
this one and re uh mask reduce or all I
I I don't know what those two mean but
we're doing we're doing a little
something in here tensor is a faty ml
array okay okay interesting bit mask I
know it's doing a bit mask but I don't
know what it means to do the mask right
I don't know how V equals Char reduce or
I don't know how this is a mask right I
don't I I don't I don't there's some
there's some operation here that is
happening that I don't I don't know what
it means you know what I mean like the
equal sign is not just like a simple
equal sign it's it it must do an equal
sign across a vector is that what it's
doing and if any of those a reduce or
just simply means I assume to go across
that vector and see if there if any of
it's true right is that is that what
it's doing yeah across all elements okay
yeah got it got it okay the
vectorization version loads 32 elements
of int 8 and checks the presence of a
new line uh separator using a few
operations in the following graph you
can see the effect of s vectorization it
provides a 4X speed up with the average
of 3.2 similarly uh simd storing and
loading from tensors provid substantial
performance gain nice this is good this
is this I mean that looks great the nanc
means that I think you're probably
measuring it too explicitly this feels
kind of uh dangerous anyways in addition
I explored optimizations from cc++
implementations I was concerned that no
explicit memory buffer was allocated for
the loaded chunks but Mojo compiler was
already taking care of that and avoiding
new memory allocations okay nice nice
you like the white lines in the
background yeah they're beautiful I like
the white lines as well implementation
of those optimizations resulted in 3x
speed up and Mojo fast trim was on
average 24x more performant than
Python's SE iio in addition due to the
control over reference and value
semantics in
Mojo I applied the fast parser version
of the parser nice uh no memory copies
are made during parsing and the
individual reads are passed around
references to the chunk uh to loaded
Chunk in memory this approach
implemented in Rust NE needletail parser
although Mojo is still very young
language my implementation was 50%
faster than rust implementation on Apple
silicon and 100x faster than
seio I mean yeah he ran it once and
that's that's cool I'm not going to lie
to you you know do I I mean usually
whenever you see local benchmarks you
should just take this as a uh Direction
not necessarily truth right this sounds
like a skill issue well I mean they're
saying they used the exact same they
used all the same techniques that uh oh
my goodness how how how do I leave this
I'm pressing escape help me I'm pressing
escape help me uh contrl C control
d
uh okay we got it I had to click I had
to just click it turns out um please
don't make models that pop up like that
okay that's really annoying just just
don't do that don't don't don't do that
okay stop being clever because you're
not clever
uh for python programmers wanting to
write more performant code Mojo is a
great tool to try and easy to learn
however the language and the ecosystem
is still growing I had to use print to
bugging to gain insight into the bugs I
was encountering the debugger is still
in preview and undocumented although
they tell me it will be officially
launching soon in conclusion I think
Mojo can be a radical change for a wide
range of python trained scientists and
researchers across many fields by the
way this
is I saw an article I saw let's see on
Twitter who said this um let's go uh
Luca what's his name Luca who wrote the
rust the rust in production book what's
his last name Luca
what Luca Paul Luca Paul Luca Paul Luca
Paul Luca Paul he said something that I
thought was really interesting um this
right here rust is the Dark Horse of AI
a few are talking about it yet almost
everyone is using it the efficiency and
fearless concurrency do matter when
processing data of pades uh I think this
is where he's going to go wrong honestly
uh what I mean by that is that if Mojo
is true I think Mojo will win just hands
down and the reason why Mojo will win is
because you don't change the Paradigm of
any already acclimated and proficient
individual does that make sense you just
have to learn a slight bit more and you
get immediately amazing performance and
if it even is remotely on par with rust
like within a error rate which they will
clearly calculate it just means that
they're going to use they're going to
just use that I saw that tweet this
morning and and my my first thought was
I wonder how this is like I wonder
what's going to be going on with uh with
Mojo versus this I mean obviously Luca
is an extremely talented engineer I
don't even know why I'm not following
him very very talented engineer very
great I love his book he has one of the
best rust books I've ever read in my
lifetime which is zero to production I'm
look I'm Shilling it he doesn't even
know I'm Shilling it great book honestly
it's a great book uh so I mean I trust
that he's he's very smart about his
opinions but uh I just don't see uh rust
tooling is far superior it it could very
well be but you still got to you still
have to make the assumption that if
given a choice make your codee as fast
and learn virtually nothing new or make
your code as fast and learn an entire
new everything what do you think people
are going to pick you got to also
remember that AI is like uh John carac
just said this here John carac just said
this uh John carac Hero by the way great
guy absolutely think he's one of just
one of the best uh he just said it was
like a big
one here I retweeted it I retweeted it
he twe dude the man tweets like I do can
you just can you just shut up and let me
find what you're trying to say so when
he comes down to here working on AI I
have literally written hund little
literally hundreds of little experiments
more individual programs than I had in
Prior two decades so he's working in Ai
and he's written more in the last little
bit of time than he did in the two
decades previously for these little
tools and these little individual
programs and so the reason why I bring
this up is that if you want rust if you
think rust is going to be the successful
one the reality is that this is the
primary Moe of operation and so if Mojo
compiles fast and it looks like a
language you're already familiar with
and it is really close to being of the
same speed I just I I just don't see how
you're going to make the cell I just
don't I just don't see how you're going
to make that cell no cost of admission
it wins yeah anyways science labs are
not uh fo uh going to switch to rust
quickly yeah because the problem is Russ
rust big sale which people often
misunderstand is not Fearless
concurrency I do not think the currency
is that great yes it's somewhat Fearless
but it's not Fearless because it's just
Arc mutex everything or or or atomics or
you have to protect it in a certain kind
of way right the thing that's going to
make it the thing that makes Russ so
good is that it has all this memory
safety and when you're doing a bunch of
this ml stuff I don't think memory
safety is your Chief concern it's just
being able to process quick enough is
your like a quick efficient easy
experimentation and being able to
process fast
enough right like to me that's that's
just says like that's that's not that's
that's not necessarily a highly aligned
rust or uh that it doesn't it doesn't
feel like rust is highly aligned with
what ml needs it's mostly aligned and it
could get there rust has amazing macro
system and it could most certainly get
there but I'm not sure if it will get
there in the sense that if it has Mo
like I just don't think it's like quite
the right use case uh which is let's see
hold on Mojo uses mlir successor to llvm
which is specifically optimized for ML
Tas so it makes sense it' be faster yeah
this makes this also makes perfect sense
it's a compiler and everything designed
to be fast for this one task right
anyways super cool uh I mean I thought
this I I think this is really
interesting I think people should think
about this stuff a lot more um oh no uh
they do no checks yeah but that's that's
that's a benefit you can do no checks
I'm the author of fastq parsing Library
uh let's see and the maintainer of the
Julia Rex engine oh you got to like link
me to the one that I I don't really want
to do I have to read all this like hey
I'm happy for you uh the thing is is
that if you don't do any checks but your
program runs successfully and correctly
every time then I don't care if they are
identical operations and at the end of
the day they both do that then yeah all
right the tldr tldr is that Mojo
implementation is fast because it
essentially a meem Char M cars four
times per read uh to find a new line
without any kind of validation or
further checking uh the M car is
manually implemented by loading simd
vectors and comparing uh to a zero yeah
to a 10 effectively and continuing uh if
the result is all zeros this is not Ser
let's see this is not a serious fast CU
parser it cuts so many corners that it
uh doesn't really make it comparable to
other parsers although I'm not crazy
about needl Tal's somewhat similar
approach either okay I mean that's
that's cool okay
so reasonable can we all agree that
that's that that that's a reasonable
take so let let me ask you this
one let's say that when it's all done
it's all said and done Mojo is within
spitting de distance of rust do you
think it's going to do you think it's
going to be a problem I mean and also he
and also the author did say that after
finding the new lines he does a postline
processing to validate it Mojo is a
stupid name Mojo is a stupid name I'll
give you that rust is also a stupid name
because it's named after a fungus not
the stuff on metal and everyone thinks
it's named after the stuff on metal so I
mean really if you think about it go is
the only normally named language
JavaScript is a stupid name Julia
doesn't make any sense okay I I am
curious though I am curious what because
you know how many times have you seen
this by the way how many times have you
seen effectively this where someone
sells a faster version of something
that's not fully complete right like so
bun bun does this with their asnc
handling in node there's a lot more
Hooks and stuff involved in async
handling that bun simply doesn't have
and then bun sells itself as being a
faster version of node but it just
simply doesn't do the same checks like
this is a pretty this is a pretty old uh
programmer Pastime which is pretty
interesting I implemented the same
algorithm in less than 100 lines in
Julia and were 60% faster than the
provided needletail Benchmark beating
Mojo I'm confident it could be done in
Rust too interesting so Julia is really
trying to get in here isn't it a skill
issue okay well I mean this is all
interesting so it sounds like I mean it
honestly sounds like we got Julia in the
mix Julia is the one that does the full
implementation and the rest cut Corners
yet they're still used and people accept
them so I'm not I'm not perfectly I I
don't understand this does that make
sense I don't understand the fact that
this needle Tales has a similar approach
and it's used like what's the what's the
point what are these checks doing that
uh these checks aren't doing that make
it okay I don't I I don't quite get it
it sounds like bioinformaticians aren't
good developers who would have thought
that Julia yeah Julia uh yeah Chris lner
has a respect for Julia dude everyone
that I know that does Julia loves Julia
that's all I know anyways this is super
interesting I mean it goes to show it
dude we see this you see this over and
over again that anytime you see a
benchmark just be wary about it I mean I
think that's the biggest takeaway when
someone says something is 50% faster
than another thing you got to remember
that at the end of the day
you can do any type of low-level
operation in Rust you can do the same
low-level operations in C therefore
there really shouldn't be a difference
in speed unless if there's some sort of
uh compiler like difference right or how
it's being translated different right
like that's they're all technically
going down to like the same level where
it doesn't make sense like you you can
never say that go will be as fast as
rust or JavaScript will be as fast as go
or Ruby is is neat like you can never
say any of those things because they
each have their own like kind of they
each have their own bands of of runtime
is saying 10x faster the most realistic
estimate of every single case being 50%
faster yeah that's the Dax tweet I I
believe that's the Dax tweet or his
co-founder tweet which is when something
is when something is 10x faster you say
it's 10x faster when something's 100x
faster you say it's 10x faster when
something is 50% faster you say it's 10x
faster and if if something's half the
speed you say it's 10x faster you just
say Universal as a developer you just
say 10x faster yeah but goes pretty damn
close to rust Andy it's not damn close
it's it's not for simple stuff sure but
once you start getting into a bunch of
object allocations and deallocations it
is different it's it's it's it's
different and that's fine right that's
fine it's close it's very close I
wouldn't say it's close enough that's
that's a statement that has no meaning
because you has to Define you have to
define the task in which you're doing
something with anyways I like this
article it was interesting good thought
experiment good thing to remember I
think is really cool to see where Mojo
is going to go I think everybody should
be excited where Mojo's going not
necessarily the specifics we're seeing
right now uh you know in the next five
years will you just hear everybody
talking about Mo Mojo you very well
could like that very well could be the
future is that Mojo is the new one that
everybody talks about or maybe they just
call that python I don't know the
name is the primagen

----------

-----
--04--

-----
Date: 2024.02.02
Link: [# The Next-Gen AI Programming Language 35000x Faster Than Python](https://www.youtube.com/watch?v=8VPJCVeMQio)

Transcription:

let's talk about a new programming
language that has the potential to
completely revolutionize the world of
programming it's called Mojo and it's
created to be a superset of python
that's not just faster it's incredibly
faster reaching to B 4 000 times faster
for example for matrix multiplication
tests that the team has run and it can
be even faster than that for other use
cases so let's check it out and see what
the hype is all about the first great
thing about it is that Mojo is a
superset of python as I was saying
earlier which which means that you don't
really need to learn another programming
language in order to take advantage of
it and this is a huge advantage over
other new languages like rust for
example that really have a higher
learning curve for existing python
programmers now the second thing right
the second thing is that to run Mojo you
can create a file ending in the fire
emoji and this is a huge thing right for
emojis and it's a It's let's say a great
advantage over python which doesn't
really allow you to name your files in
the dot snake Emoji now I believe that
the world can handle Unicode extensions
and program programming may become even
more fun if we come back now to the
series aspects some actually say as I
was saying at the beginning that Mojo
really be the biggest programming
language advance in decades and the
reason is the third greatest thing which
is that Mojo has full compatibility with
the python ecosystem so you will still
be able to use libraries for example
like numpy or pandas and overall it will
improve the world of programming for AI
applications as it has predictable low
level performance now we still have to
keep in mind that Mojo is a brand new
code base but because it benefits from
embracing python syntax it actually
simplifies the the design efforts made
by the team and if we think about the
team of course they're an AI startup
right but they have impressive technical
credentials because Mojo CEO has an
impressive background as a co-developer
of a widely used compiler tool chain and
compiler infrastructure as well as the
Swift programming language and as the
team has great experience with projects
like c-lang and Swift they know exactly
how to tag Echo compatibility with the
python community and in terms of
compatibility right Mojo already
supports many core features of python
but it's still in its early stages so
the team expects that Mojo will be able
to cooperate directly with the c python
runtime and provide a progressive
migration approach over time and as Mojo
is being built the current Promises of
course are around reaching the
performance of of C while also using a
modular inference engine to run AI
models more efficiently in production
the reason why they can do that is
because Mojo can access AI tuned
Hardware features making it potentially
thousands of times faster than let's say
vanilla python 4 specific algorithms and
it's important to note that Mojo is
currently not available to the public as
it's still in a very early development
however you can request access and
hopefully you're going to be able to run
your own experiments with uh with the
language you know as it's being
developed but until you get access you
can check out some jupyter notebook code
and the results that were created in the
Mojo playground they show some tests on
matrix multiplication and some
visualizations and you can see for
yourself how fast Mojo really is but
what do you guys think right do you
think it will completely surpass python
in AI development or do you think it's
going to be more like what python 4 will
build up to be I'm also really
interested to see what's going to happen
in the next maybe I don't know 6 to 12
months because I'm sure we're gonna
we're gonna see employers that are going
to be looking for people with two three
years of Mojo experience and that's it
for me if you enjoyed the video please
give it a like And subscribe to my
channel for more videos like this thanks
for watching and I'll see you in the
next one

----------

-----
--03--

-----
Date: 2024.02.02
Link: [# Choosing Your Language: Python or Mojo?](https://www.youtube.com/watch?v=OJUorka-XLU)

Notes:
Based on the video transcription, here are the notes categorized as per your request:

#### Advantages:

1. **Performance Improvement**: Mojo offers a significant performance boost compared to Python due to being a compiled language.
2. **Strong Type Safety**: Static typing and compile-time checks contribute to fewer runtime errors and more reliable code.
3. **Memory Safety**: Mojo incorporates features like garbage collection and a Rust-style ownership model to manage memory more efficiently.
4. **Python Compatibility**: Mojo provides some level of compatibility with Python, allowing gradual transition and the use of existing Python libraries within certain constraints.

#### Drawbacks:

1. **Early Development Stage**: Mojo is not yet ready for production use and lacks stability and essential features.
2. **Setup and Installation Issues**: Setting up Mojo can be tricky and may require specific configurations, especially when integrating with environments like `pyenv`.
3. **Limited Platform Support**: Currently, Mojo works well mostly on Unix and Mac machines. Windows users need to rely on the Windows subsystem for Linux.
4. **Potential Syntax Changes**: As Mojo is still in development, its syntax and features might change over time, leading to compatibility issues with older codebases.

#### Tips and Advice:

1. **Use for Experimentation**: Mojo is suitable for exploring and experimenting with the performance benefits and features it offers.
2. **Learn Rust Principles**: Understanding Rust's ownership model and memory management can be beneficial, as Mojo incorporates similar concepts.
3. **Handle Python Compatibility Carefully**: When calling Python code from Mojo, ensure proper handling of exceptions and understand the performance trade-offs.

#### Lecture Content:

- The video introduces Mojo, a new programming language that combines Python's syntax with Rust's performance and safety features.
- The speaker explains the fundamental differences between Mojo and Python, such as compiled vs. interpreted execution, strong type safety, and memory management.
- Key features of Mojo, like structs, traits, and memory ownership keywords (in-out, owned, borrowed), are demonstrated through examples.
- The challenges of transitioning from Python to Mojo, including handling Python compatibility and understanding the ownership model, are discussed.

#### Main Challenges:

- Adapting to Mojo's strict type and memory management requirements coming from a dynamic language like Python.
- Dealing with the early stage of Mojo's development, which includes potential instability and frequent changes.

#### The Importance and Usefulness of the Topic:

- The topic is important for developers seeking to improve the performance of Python code without completely shifting to a new language paradigm.
- Understanding Mojo's capabilities and limitations can help developers make informed decisions about adopting new technologies in their projects.

#### Accomplishments:

- The video provides a comprehensive introduction to Mojo, explaining its core concepts and differences from Python.
- Practical examples and demonstrations illustrate how to write and structure code in Mojo.

#### Summary of the Content:

- Mojo is a new programming language that aims to offer Python-like syntax with the performance and safety features of Rust.
- While promising, Mojo is still in early development and not ready for production use.
- The video showcases Mojo's capabilities, limitations, and potential use cases, along with practical coding examples.

#### Interesting Quotes or Insightful Sentences:

- "Mojo is sort of a marriage of Python and Rust."
- "Mojo doesn't really solve a problem for me. It's a bit too early, but that might change in the future."
- "Mojo is an intriguing language... it gives us an idea of what it could look like if we have a language that marries the best things of both worlds, both Python with its flexibility and simplicity and Rust with its type safety and performance."

The video serves as a foundational guide to understanding Mojo, its relationship with Python and Rust, and its current stage in the development lifecycle. It emphasizes the potential of Mojo while also acknowledging its current limitations and the challenges of adopting it in its early stages.

Notes:
### Summary of the Content

The video introduces Mojo, a new programming language that combines Python's syntax with Rust-like features, aimed at improving performance while maintaining Python's ease of use. Mojo is a compiled language with static typing, memory safety, and garbage collection, making it an attractive option for Python developers seeking better performance without switching to a completely different language like C or Rust. However, the presenter shares mixed feelings about Mojo, noting its early development stage, compatibility issues, and the current lack of a clear advantage over using Python or Rust directly.

### Advantages

- Mojo offers a syntax similar to Python, making it accessible to Python developers.
- It provides higher performance through compilation and static typing.
- The language incorporates Rust-like memory safety and ownership models, enhancing code reliability.

### Drawbacks

- Mojo is still in early development, lacking stability and full feature support.
- Setting up and installing Mojo can be challenging, especially on systems using pyenv.
- The video suggests that Mojo does not yet solve a significant problem for the presenter, given the effectiveness of Python for most of his needs and Rust as an alternative for high-performance requirements.

### Tips and Advice

- For developers interested in exploring Mojo, start with experimentation and non-critical projects due to its early development stage.
- Consider the transition from Python to Mojo as a way to gradually adopt Rust-like safety and performance features without a steep learning curve.
- Keep an eye on Mojo's development progress to assess when it might become a viable option for production use.

### Main Challenges

- Navigating the early development stage of Mojo and dealing with potential syntax and feature changes over time.
- Deciding whether the performance benefits of Mojo justify the effort of adopting a new language amidst established alternatives like Python and Rust.

### The Importance and Usefulness of the Topic

Exploring Mojo is valuable for Python developers seeking performance improvements and those curious about combining Python's simplicity with Rust's safety and efficiency. The video provides insights into the potential of Mojo and considerations for adopting it as the language matures.

### Accomplishments

- The video effectively introduces Mojo, highlighting its key features and differences from Python.
- It provides practical examples and code comparisons to illustrate Mojo's syntax and capabilities.
- The presenter offers a balanced perspective, acknowledging Mojo's potential while recognizing its current limitations and development status.

### Interesting Quotes or Insightful Sentences

- "Mojo is sort of a marriage of Python and Rust."
- "Mojo doesn't really solve a problem for me...but that might change in the future."

### Lecture Content: Technical Insights

- Detailed overview of Mojo's syntax, type safety, and memory management features.
- Comparison of Mojo with Python and Rust, highlighting the unique aspects of each language.
- Discussion on the practical use of Mojo for Python developers and considerations for its adoption.

### Conclusion

While Mojo presents an intriguing option for Python developers seeking improved performance, its early development status and current challenges limit its immediate applicability. The video encourages keeping an eye on Mojo's progress and considering it for future projects as the language evolves and matures.


Transcription:

If you love using Python, but you need more performance,
there are a few options.
You can buy a really fast, really expensive computer,
which is not ideal.
You can also use C or Rust bindings
and code the part that needs more performance in C or Rust.
But that does mean you need to learn a new language,
switch context, et cetera.
Today, I want to talk about another option,
which is using another programming language altogether,
but one that looks a lot like Python.
I'm talking about Mojo.
I'm going to show you how to use Mojo
and how different from using plain old Python.
And I'm also going to share some of my thoughts about using it
and, well, some mixed feelings I have about it.
Before we start, if you want to learn more
about how to design a piece of software from scratch,
I have a free guide for you.
You can get it at arjan.codes/designguide.
This contains seven steps that I take
whenever I design a new piece of software.
And hopefully it helps you avoid
some of the mistakes that I made in the past.
arjan.codes/designguide.
The link is also in the description of this video.
Now, let's dive into Mojo.
Mojo is a relatively new programming language
that builds on the syntax of Python
and adds quite a few different features.
On top of that, it works internally
in a different way than Python.
There are quite a few differences there, actually,
and that actually helps it achieve
that much higher performance.
The main difference is that Mojo
is actually a compiled language versus Python,
which is interpreted.
In a sense, you can look at Mojo
as sort of a marriage of Python and Rust.
Instead of being interpreted like Python is,
Mojo is compiled.
It has much stronger type safety.
It supports static typing,
which makes a lot of sense in a compiled language.
There is memory safety.
There's garbage collection.
It uses a sort of Rust-style ownership model,
and I'm going to show you some examples
of that later in the video.
A caveat is that Mojo is still in early development,
so it's not ready for production.
It's still missing some essential features.
In fact, at the moment,
it mostly works well on Unix and Mac machines
and on Windows.
You can still use it,
but you have to use the Windows subsystem for Linux.
Also, that means that probably features that we have now
are going to be removed, replaced, improved over time.
So if you're looking for a really stable language,
Mojo is not what you should use.
But still, it can be fun to take a closer look at Mojo
as a form of experimentation and exploration.
Here's an example of a basic Hello World Mojo script.
And to run this, you can simply type Mojo
and then the name of the script.
Assuming, of course, that you have installed the tool.
Now, I did run into a few issues
with installing the tool, by the way.
That was related with using pyenv
and picking the right Python version,
and there were some issues with it
not being able to find some libraries.
Again, it's not production-ready,
so that's kind of how it is.
But anyway, I got it working,
and this is the result.
Let's take a closer look at some of the differences
with Python and some of the features
that Mojo has on top of what Python offers.
If you look at the Hello World file,
you see that there's a couple of minor differences,
like instead of having a def,
we write fn in front of the function name,
similar to what we have in Rust.
Also, main is the actual entry point of the script.
So that's the function that's going to be run
when you execute the script with Python.
That's not the case.
You simply write your commands
at the root indentation level,
and then that's gonna run.
Of course, my best practice that I recommend
is that you actually always define a main function
in your script and then call it explicitly
so it's clear what the entry point of the script is.
But in Mojo, this is by default the main function,
just like in Rust.
Just like Python, there are types.
In this case, we have strings, ambs strings,
and this also returns a string.
So that's the same syntax as with Python's type annotation,
but these are actually static types.
So that's an important difference.
These are checked at compile time.
Another couple of differences.
In Python, we can simply define a variable like this.
In Mojo, that doesn't work.
You see, we get some sort of error.
It doesn't know what x is.
So we need to actually declare it.
You can do that by writing the var keyword
in front of the variable name.
That makes it a mutable variable.
So you can change the value later.
For example, I can write x equals six after that.
But alternatively, you can also use the let keyword.
And then it's constant value.
And you also see that when we try to assign a value to x,
then this actually gives us an error
that this is not allowed.
Also, if you declare functions like this
and you have parameters like a or b in this case,
you need to supply a type.
So if I remove this,
you see that we actually also get an error here
because we need to indicate to Mojo
what the type is of a.
Otherwise, it can't compile the code.
So let's put that back.
In the function body itself,
you don't have to supply a type annotation.
So if I write, let's say,
let my name equals Arjan.
I don't need to indicate that my name
is actually of type string.
But of course, if you want to,
you can add a type annotation here.
It's just not necessary.
And typically, when I define variables like this,
I don't include the type annotation
unless it's completely unclear what the type is.
Normally, you can easily infer it from the right-hand side.
So there's no need to do it.
By the way, if you like talking about
different programming languages,
their pros and their cons,
how they affect software design,
you should definitely check out my free Discord server.
You can get access by going to discord.arjan.codes.
The link is also below.
A few other things that I want to show you.
So this is another version of that same
hello world example.
So we still have our main function.
And I've added a couple of other functions here as well.
There's a hello function,
but there's also a Python-style world function.
Mojo is, in principle, compatible with Python.
But of course, it's a compiled language.
So there needs to be some kind of boundary
between the unsafe, messy Python world
and the memory-safe, very strict Mojo world.
And the way Mojo does that is with the exception mechanism.
Here you see an example of that.
So I have a Python-style function here
called world that's simply going to print world.
And then when I want to call it,
I need to put that in a try-except block.
So if I turn this into a comment, like so,
then you see that now we actually get an error
that we cannot call a function that may raise
in a context that cannot raise.
So Mojo does these types of checks.
And that means that if you want to call a Python function
from a Mojo function,
you need to put it in a try-except block, like so.
If you write a Python-style function like this,
well, that comes at the cost of type safety
because Python doesn't enforce types.
And because of that, Mojo also uses
a different just-in-time compilation mechanism
in order to compile Python code.
And that's a bit slower than running Mojo code directly.
So that's something to be aware of.
Here's another example that shows a couple
of different things that Mojo offers.
So again, there's a main function at the bottom.
That's the entry point of the program.
And then there's a couple of other things here.
There's a struct and there's a trait.
So these things look very similar
to what we have seen in Rust before.
So let's go over how this actually works.
So we have a struct called user,
similar to what a struct is in Rust.
There's one difference, though.
You can define these sorts of functions
to be part of the struct.
In Rust, you need to use an input for that.
A struct can have variables.
So a user, in this case, has a username and an email.
You need to declare these
with the var keywords inside the struct.
And then we have an initializer with a couple of arguments,
and we can set the values inside the struct
in the initializer.
And there's a couple of other functions
that are added here as well, such as this type,
which means that we can have a string representation
of that struct.
So the struct user implements this stringable trait,
which simply says that the type
can be converted to a string.
Another thing that you can see here is a value decorator.
And this simply means that the user struct
can be copied and moved around,
similar to the copy trait in Rust.
So you may think, okay, so a struct is basically a class.
Well, it is slightly different
in that there is no inheritance mechanisms.
For example, classes are not yet supported in Mojo,
but that is a planned feature.
Another thing that I'm using here
is something called a dynamic vector.
And this is similar to Python's list.
You also see we supply a type of dynamic vector.
So this is a vector, a list of users.
And then we can append users to that dynamic vector.
Now, in order to be able to do that,
we need to implement the collection element trait.
That means this user struct
is allowed to be part of collections.
If I remove this, then you see we're going to get an error here
that this is not allowed
because it needs to have the collection element type.
And finally, similar to Python,
we can use a for loop to go through the list of users.
Now, unfortunately, if you try this,
then that doesn't work
because dynamic vectors currently
doesn't implement the iter method.
I don't know if they want to add that in the future,
but that would actually be helpful
to have something like that.
So things like stringable collection elements,
they're traits just like in Rust.
And you can also define your own traits.
I have here another trait called emailable
that I've defined here at the top.
So this trait defines two functions,
getEmail and sendEmail.
And then of course, if you add a trait,
then you also need to implement the methods here.
So if I change these two comments,
then again, we're going to get an error
because it doesn't implement
all the requirements for the trait.
So let me put that back.
So traits are also in the Rust programming language.
It's sort of comparable to what we have in Python with protocols.
But of course, protocol classes in Python are not enforced at all.
They're simply hints.
And with languages like Rust and Mojo,
these are actually enforced and checked when you compile the code.
The final thing that I want to mention about Python compatibility
and how you would transition from Python to Mojo
is that typically, like I've shown you here in this Hello World example,
you would have your Python code in a def function,
similar to how we would do it in Python.
And then you put it in a try-except block
when you call it from a Mojo-style function.
So if you want to transition from Python to Mojo
to benefit from the higher performance,
then one way that you can do it in steps
is simply call that Python code using a try-except block
and then slowly migrate the functions to Mojo functions
at type safety where necessary.
The final thing that I want to talk about is ownership.
So this is similar to how Rust also manages memory.
And we have a couple of different keywords in Mojo to handle ownership.
So there's in-out, there is owned, and there is borrowed.
And this indicates who owns the value at any given time.
And that in turn determines whether the value is actually still needed
or can be cleaned up by looking at who owns the value.
The first option is in-out.
This borrows ownership during the function call.
And it's also mutable.
But after that, it returns the ownership.
So that means that when we run this function,
we get a self object, and we can actually set values in it.
We can change it. That's what in-out does.
If we remove that, we get an error
because we're trying to set values in it.
So this needs to be mutable.
Next to the in-out keyword, we have the borrowed keyword,
which is exactly the same as in-out, except that it's immutable.
So you can't change the object.
And before there was a tiny mistake here, this actually returns ownership.
The final keyword that you can use to manage ownership is owned.
So this actually transfers the ownership of the value
from the caller of the function to the function itself.
So now username, if it's no longer being used afterwards,
then the value will be destroyed by the runtime after that.
By default, the parameter of mojo function is borrowed.
So if you look at the hello world example that I've shown you before,
so we have the add function.
So actually A and B, they're both borrowed.
So you don't need to write the borrowed keyword in front of it,
even though you can.
If you have a Python-style function, like the function here,
and you add a parameter to that,
then by default that parameter is going to be owned.
So ownership is transferred.
And that choice, that design choice,
also has to do with the more dynamic nature of Python.
So it makes more sense that because Python is more dynamic
and we have less control over what happens,
that we actually transfer the ownership of values
when we call Python code.
So I hope these examples gave you an idea of what Mojo is
and how it's different from Python.
Now, currently, like I said, mojo is not ready for production,
so don't use it for mission-critical applications,
even though it's a nice tool to experiment with
and see what is possible.
It can also help you if you are thinking about moving to Rust,
for example, to get a bit of an idea of how things work
in an ownership model of memory.
And then, you know, maybe later on transition to Rust
if you find that interesting.
So there's still several features that need to be implemented
that still need to be done.
And it also means that the syntax may change over time
and that if you write a program in Mojo now,
that in six months or a year,
it may no longer work correctly
because things have changed in the meantime.
Also, it was kind of finicky to set up, at least on my Mac.
I needed to set paths explicitly, run some commands explicitly,
so it wasn't as easy as just installing Python
and then off you go.
Granted, I think most of those issues were related to me using pyenv,
but still, that's a pretty standard setup for people using Python.
So I think if you introduce a new language like Mojo,
you should take that into account
and make sure that it actually also works in those cases.
But I did get it working as it should in the end,
so I'm sure the Mojo team is working on improving those things as well.
So final thoughts about this.
I think Mojo is an intriguing language.
It's an interesting marriage between Python and Rust.
And I find that intriguing because it gives us an idea of what it could look like
if we have a language that sort of marries the best things of both worlds,
both Python with its flexibility and simplicity
and Rust with its type safety and performance.
So am I going to use it personally?
No, it's not yet ready for production yet.
And when I look at how I use Python,
actually in most cases, by far most cases,
Python is actually perfectly suitable to me.
And if I really need high performance,
which is actually kind of rare for me,
then I think I would first investigate whether I could start using Rust more
and integrate that into Python.
Rust is a completely open programming language.
You don't need to sign up for anything,
and it's also quickly gaining popularity.
So I would put my chips on Rust at the moment.
So the bottom line for me is that Mojo doesn't really solve a problem for me.
It's a bit too early, but that might change in the future.
Who knows?
Now I'd like to hear from you.
Are you using Mojo?
Why are you using it instead of Python or Rust or something else?
What are your thoughts about mojo?
Let me know in the comments.
Talking about Rust, if you want to learn more about that,
I did an introduction video a while back
helping Pythonistas get started with Rust more quickly.
And you can watch that right here.
Thanks for watching and see you next time.

----------

-----
--02--

-----
Date: 2023.11.19
Link: [# SPICE Metric || Image Captioning || Deep Learning](https://www.youtube.com/watch?v=As441oo3yk8)

Notes:
### Video Notes on SPICE Metric for Image Captioning

#### Lecture Content

- The lecture discusses the SPICE metric, a method for evaluating the quality of image captions by comparing the semantic propositional content of captions rather than relying on n-gram overlap.
- The SPICE metric addresses the limitations of other automatic metrics like BLEU, METEOR, CIDEr, or ROUGE, which are sensitive to n-gram overlap but may not accurately reflect the semantic similarity between captions.
- The SPICE metric utilizes a scene graph (Sing graph) representation to encode the objects, attributes, and relationships in image captions, abstracting away the syntax of natural language.

#### Advantages

- **Semantic Accuracy:** SPICE focuses on the semantic propositional content of captions, providing a more accurate measure of the quality of image captioning.
- **Sing Graphs:** By using scene graph representations, SPICE captures the objects, attributes, and relationships in image captions, offering a richer understanding of the content.
- **Interpretability:** The SPICE score is simple to interpret, ranging between 0 and 1, where 1 indicates a high similarity between the candidate and reference captions.

#### Drawbacks

- **Complexity:** The construction and comparison of scene graphs are more complex than n-gram-based approaches.
- **No Partial Credit:** SPICE does not give partial credit for tupos where only one element is incorrect, potentially leading to lower scores for captions that are semantically similar but not identical in structure.
- **Dependency on Dependency Parsing:** The initial parsing of captions using a dependency parser is crucial and may affect the accuracy of the resulting scene graph.

#### Tips and Advice

- When evaluating image captioning, use a combination of metrics (SPICE, BLEU, METEOR, etc.) to get a comprehensive understanding of the performance.
- Pay attention to the semantic content of the captions rather than just the syntactic structure.
- Be mindful of the limitations of each metric and consider them when interpreting the results.

#### Main Challenges

- Constructing accurate scene graphs that represent the semantic content of captions.
- Ensuring that the spice metric's reliance on semantic propositional content aligns well with human judgment.

#### The Importance and Usefulness of the Topic

- The SPICE metric offers a significant improvement in evaluating image captioning systems, focusing on the semantic content rather than just syntactic similarity.
- Understanding and correctly implementing the SPICE metric can lead to more accurate and human-like performance in image captioning tasks.

#### Accomplishments

- Detailed explanation of how the SPICE metric works, including the construction of scene graphs and the computation of the SPICE score.
- Highlighted the limitations of n-gram overlap metrics and how SPICE addresses these issues.

#### Summary of the Content

- The video provides an in-depth overview of the SPICE metric for image captioning, explaining its advantages over traditional n-gram overlap metrics. It details the process of constructing scene graphs, simplifying quantifiers, resolving pronouns, handling plural nouns, and representing semantic relations as tuples. The video also discusses the interpretability and adaptability of the SPICE score, emphasizing its usefulness in evaluating the semantic accuracy of image captions.

#### Interesting Quotes or Insightful Sentences

- "Engram overlap is neither necessary nor sufficient for two sentences to convey the same meaning."
- "The SPICE metric suggests that the semantic propositional content is an important component of caption evaluation."
- "SPICE score is simple to understand and interpret as it naturally ranges between zero and one."

The video offers a comprehensive explanation of the SPICE metric, highlighting its significance in advancing the quality and accuracy of image captioning by focusing on semantic content over syntactic structure.

Transcription:

hey everyone how's it going welcome back
to another video today we'll be covering
the spice metric for image
captioning so the first question is
obviously what are some issues with
other automatic metrics used for image
captioning why do we need this new
metric called
spice well other metrics such as blue
meteor cider or rge they're all
sensitive to engram overlap and engram
overlap is neither necessary nor more
sufficient for two sentences to convey
the same meaning so to illustrate the
limitations of engram comparisons
consider the following caption from the
MS Coco data set the first caption says
a young girl standing on top of a tennis
court and the second caption says a
giraffe standing on top of a green field
these two captions have five fors that
overlap however they convey completely
different messages and thus these two
captions should not be considered
similar however using these engram
techniques these two captions are
actually considered very
similar so the main idea behind
spice spice suggest that the semantic
propositional content is an important
component of caption
evaluation so for example given an image
with the caption a young girl standing
on top of a tennis court we expect that
a human evaluation will consider the
following to score the caption there is
a girl the girl is Young the girl is
standing there is a court court is
tennis the girl is on top of court right
as human evaluators we'll probably have
these in mind so when we're looking at
the given image and the caption we'll be
like hey does the caption have these
criterias right so this is what the
spies metric is trying to model
model now they basically do this by the
construction of something called a sing
graph so they estimate caption quality
by transforming both the candidate and
reference captions into a graph-based
semantic representation called a sing
graph and the sing graph encodes the
objects attributes and relationships
found in image captions while
abstracting away all the syntactic
sugars of natural language so so uh for
example they provided this graph here to
show us what it looks like so we have a
girl here this is um a noun and it's the
subject right and it's connected to all
these other grammar stuff
right
okay now let's go into details of how we
can construct the actual sing graph and
how they actually constructed the in
graph so initial step the captions are
in initial parsed using a dependency
parser to establish syntactic
dependencies between
words so what is dependency
parsing parsing in natural language
processing is like analyzing a sentence
to understand its structure it's similar
to how you might break down a sentence
to understand its grammar in school
right so dependency parsing identifies
relationships like which word is the
main sub subject which is an action or
other words verb and how other words
modify or relate to these words right so
that's what we're doing here uh so like
here's an example if we input a caption
a young girl standing on top of a tennis
court we could assign a part of speech
to each token so uh is a
determiners uh Yan is adjective girl is
the noun and also the subject staning is
the a verb and right all these grammar
stuff so we established dependencies
using a dependency tree here okay and
this is you can see everything that's
going on in this diagram
here so after that we perform some
postprocessing
steps so first we simplify the
quantificational
modifiers so the purpose this step
involves simplifying modifiers that
quantify objects in the caption and
quantificational modifiers include words
or phrases that indicate amounts like
several many or specific numbers like
three right so how it works the parcel
identifies these quantifiers and
simplifies them to make the structure
more straightforward for example if we
have three dogs it will be simplified to
the object dog with an attribute
indicating the quantity three so instead
of representing three dogs as three
separate nodes in the sing graph it will
be represented as a single note dog with
an attribute indicating the quantity
three and we also have resolving
pronouns so pronouns like he she it or
they are used in place of nouns this
step aims to resolve these pronouns to
um the nouns they refer to so how it
works the system determines what each
pronoun refers to in the context of the
caption for example if a caption says it
is running and it refers to a previously
mentioned dog the parcel will link it to
dog and we'll see all of these steps in
more
detail and we have handling plural nouns
so the purpose of this step is to deal
with plural nouns ensuring that the same
graph correctly represents multiple
instan of an object so how it works
instead of creating multiple nodes for
each instance of a plural noun spice
treats plural nouns differently it
avoids duplicating notes and instead
represents pluralities as attributes for
instance dogs will be represented as a
single note dog with an attribute
indicating plurality
okay now the next step is representation
of semantic relation as tup so they
represent sing graphs as tuples the
semantic relations in the sing graph are
viewed as logical propositions or
tupos um this way right because the
machine cannot actually visualize this
graph we have here they represent this
entire graph with
tbos so how did they form this T right
uh they provide a function T and that is
defined
as a function that returns these two Po
from a sing graph so t g of C where G of
C represents the sing graph of the
caption and the twole contain elements
representing objects uh o of C
attributes K of C and relations e of C
so for the sing graph in the example
figure the TST might be girl Court girl
young girl standing court tennis girl on
top of court right so we can see all
these connections girl and young girl
and standing uh girl and court right um
all these stuff
right
okay and we basically match two posts
between SC graphs to see how similar
they are right and this is using the
binary matching operator a binary
matching operator this is the symbol is
used to identify
uh the matching tupos between two sing
graphs um the candidate caption and the
reference S graph right so the reference
sing graph is basically the ground truth
right this is what we're trying to reach
and the candidate caption is the sing
graph generated from uh the caption from
like a machine learning model for
example Right image captioning
model okay so we could calculate the
Precision recall and spice score so the
Precision is the ratio of the number of
matching tupos between the candidate and
reference sing graphs to the total
number of tupos in the candidate sing
graph right so we have TG of c and then
we're trying to find where they overlap
T of G of s and then divided by T of G
of C right this formula here and we also
have recall which is defined as the
ratio of the number of matching tupos
between the candidate and referencing
graphs to the total number of tupos in
the referencing graphs so basically pres
but uh the ratio is to referencing
graphs instead of candidate Sy graphs
okay and finally the Spy score which is
really the F1 score and that is the
harmonic meane of precision and recall
right um spice score is the F1 score so
we apply this form
and P and R we already know how to solve
for those up there so this one is pretty
free okay and this is how you calculate
the spice score if you have two uh two
captions
right so what are the matching criteria
right how can we determine that two
tupos actually match uh they use
something called word net synonym
matching so for matching TST the the
spice metric employs a word net synonym
matching approach similar to the meteor
metric so T post are consider a match if
their lemmatized word forms are equal or
if they are found in the same word net
sin set so lemmatized basically means
that uh for example the word running or
ran they're all simplified to the root
or most basic form run right basically
simplifying all these words to their
root form
and what is the word net right the word
net is a large lexical database of
English where nouns verbs adjectives and
adverbs are grouped into sets of
cognitive synonyms or also known as
sunsets each expressing a distinct
concept sunsets are interl by means of
conceptual semantic and lexical
relationss a sunset is a set of synonyms
that share a common meaning for example
the words sh bow and vessel might be in
the same Sunset because they all refer
to a medium-sized um water craft right
okay and another important thing to
acknowledge is that there is no partial
credit for incorrect tupos so unlike
other metrics spice does not give
partial credit for tupos where only one
element is incorrect right um this is
because many common relations in image
captions like in or on do not deserve
credit if they are applied incorrectly
right they could um change the caption
by a wide
margin and now let's talk about
interpretability and
actability ah that was a mouthful okay
so the spice score is simple to
understand and interpret as it naturally
ranges between zero and one so you know
one obviously means that uh two captions
are more similar so therefore your
candidate caption has a pretty high
score if you score one
right and it does not rely on Cross data
set statistics making it applicable to
both small and large data sets so
overall uh spice is a pretty good metric
but for image captioning um evaluation
you will typically use spies blue meteor
all of those at the same time just to
see what you get right it's not like you
have to choose one out of all of them
and nowadays they're actually uh trying
to expand uh automatic U metrics to
evaluate large Vision language models as
well but they use slightly different
approaches although they still use spy
score uh meteor blue right so it's still
important to understand how they work
and yeah that's it for this video if you
have any questions or suggestions or
comments um just leave them down in the
comment section below and I will try to
respond as soon as possible all right
thank you guys for watching and see you
next time

----------

-----
--01--

-----
Date:  2023.09.17
Link: [# Mojo Programming Language Modules and Packages || Mojo Tutorial](https://www.youtube.com/watch?v=1PQIHzls13s)

Notes:
### Video Notes on Organizing Code into Modules and Packages in Mojo

#### Lecture Content

- The lecture focuses on organizing code into modules and packages in Mojo, a programming language.
- A module is a file containing code that other files can import and use.
- A package is a collection of modules in a directory, marked by an `init.mojo` file.

#### Advantages

- **Modularity:** Allows for cleaner, more organized code by separating concerns into different files.
- **Reusability:** Modules can be reused across different parts of an application or in different projects.
- **Namespace Management:** Packages help in organizing and grouping similar modules, avoiding naming conflicts.

#### Drawbacks

- **Complexity in Configuration:** Importing modules and packages requires understanding of file structure and namespace.
- **Dependency Management:** Managing multiple modules and their interdependencies can be complex.

#### Tips and Advice

- Use `let` for constant definitions in Mojo, as it makes the variable immutable.
- Be cautious with the naming of packages and modules to avoid conflicts.
- Compile your package into a `.mojoPKG` file for ease of distribution and to avoid having source code in the same location as the main module.

#### Main Challenges

- Understanding the file structure and how Mojo recognizes modules and packages.
- Dealing with unexpected errors or bugs in the language or development environment.

#### The Importance and Usefulness of the Topic

- Understanding modules and packages is crucial for writing scalable and maintainable code.
- Helps in organizing large codebases, making them easier to navigate and manage.

#### Accomplishments

- Demonstrated how to create and import modules and packages in Mojo.
- Showed how to compile a package into a `.mojoPKG` file for distribution.
- Provided a workaround for naming issues with compiled package files.

#### Summary of the Content

- The video explains how to organize code in Mojo using modules and packages, starting with module creation, struct definition, and function implementation. It then moves on to package creation, including the necessity of an `init.mojo` file, and demonstrates code importation from modules. Finally, it covers the compilation of packages into distributable `.mojoPKG` files.

#### Interesting Quotes or Insightful Sentences

- "Modules are essentially files that include code for other files to use by importing it."
- "The `init.mojo` file is crucial because if you delete it, then Mojo doesn't recognize the directory as a package."
- "You can't just change the name [of a compiled package]... the package name is encoded in the file."

The video offers a comprehensive guide on using modules and packages in Mojo, addressing the importance of structure and organization in coding for efficiency and scalability. Despite some technical glitches, the content is informative, especially for those new to Mojo or looking to understand the concept of modularity in programming.

Transcription: 

Hey everyone, I hope you found this video to be helpful! If you have any suggestions, questions, or concerns, please let me know in the description below! I will answer as soon as possible, :) thanks for the support!

hey everyone I hope you're all doing
well today we are going to learn how to
organize our code into modules and
packages like how we do it in Python to
understand Mojo packages we first need
to understand Mojo modules so a module
is essentially a file that includes code
for other files to use by importing it
so let's see an example uh let's I'm
currently in the main. mod file but
let's create a new file called my pair.
module this is going to be our module
okay so it's another module file but
this is a module so let's define struct
called pair and we have a first which is
in and our second which is also in let's
deal with integers for now and to uh
simplify this and let's define our
Constructor in it uh in out self first
which is an in and second which is also
an end and self. first equal first self.
second equal second okay so basically we
set first to whatever we pass in for
this and second to what to whatever we
passing for this okay and now for this
struct also let's define a dump function
that basically prints out our pair so
self do first self. second so we can see
what our pair looks like now let's write
this so essentially what we have done is
that we Define a module that defines a
pair struct okay uh notice that this
module we don't see a main function like
we do in the main. modu file so we can't
actually execute our
code um this is the same for many
compiled languages where the main
function is the entry point for program
execution um so we have to import this
module into another file with a main
function so we can use it uh this is uh
so let's see how we can do
that so we have our main function here
and so far I only have print hello
YouTube right okay so now let's define a
pair right let my pair equal pair let's
do one and
two so you see an error here because we
don't know what pair is in this file we
can't access pair in this other file so
we have to import it
oops so let's import that really quick
from my pair import pair so basically
what we have done is that we import pair
from the my pair. modojo file here and
now we can use it to define a pair which
takes in two integers right first and
second and then we set those numbers we
set first s uh we set one and two um we
we set first and second to one and two
respectively
okay and notice I'm using let here which
means that it's constant we won't be
changing this in the future um this
might be counterintuitive if you're
familiar with
JavaScript but the let keyword and Mojo
makes this a
constant
okay um now let's
see my parent dump right let's see what
this looks like sorry you don't actually
need this semicolon at end but you could
includ it okay now let's run it we can
just do Mojo main. Mojo in the terminal
and we get one and
two okay so dot dump pretty much just
prints it out for
us okay and
alternatively we could also delete this
line and we can just do my pair do
pair
uh let's
see I know my
pair oh sorry we could do import my pair
right after we import my pair we can
just do my pair. pair right so if you
have a lot of functions or uh if you
have a lot of struct or functions Define
in um the my pair. modjo file you could
just use one import line and then um use
my pair. pair like this right um we can
also create an alias for the imported
member just like in Python so I could do
import my pair as
MP and then down here we can just do mp.
pair and this will also work so let's
run it boom one and two so this also
works awesome so I hope you guys
understand what modos are in Mojo now
and how they work so let's talk about
packages
now so what is a Mojo package uh a Mojo
package is just a collection of Mojo
modules in a directory that includes a
in it. Mojo file so your file structure
might look something like this you have
your main. moojo file up there
and you have this directory called uh
mik package you can name it whatever
right whatever the package name is and
in here you have to set a init Mojo file
in order to let Mojo know that this
directory is a package and inside this
directory you can Define several modules
like my pair for example that's a module
we can Define and you can Define several
as many as you want down here okay
um so the in it. Mojo file is actually
crucial because if you delete it then
Mojo doesn't recognize the directory as
a package so now let's see how this
works in code so I'm back in vs code
let's create a folder called my
package and inside here let's do
init Mojo So we have a init Mojo file WR
it and inside there we also have uh
let's just move my pair into my
package okay so now it's in my
package okay now how can we use my pair
now that it's in my package right my
pair is now in my package folder so what
we could do is that from my
package. my my pair import pair so what
we have done is that we're importing my
pair from my package and then we're
importing the pair function from my pair
which is the module
okay now let's use that let my pair
equal pair 1 and two let's
see a crash happened with the Mojo pars
okay so this is an unexpected error uh
this shouldn't be happening but so
ignore this error for now um let's just
continue so my pair.
dump um this should theoretically work
but it something is wrong with mod let's
see if we can run it so we can run it
just fine it prints out one and two so
this does work so I guess it's an error
with the um error system
here so basically what you have to know
is that the init
Mojo uh file allows us to recognize the
directory as a package thereby allowing
us to import the module my pair inside
the main. module uh
file now let's say we don't want the my
package source code in the same location
as main. modu we can compile into a
package using this in our terminal Mojo
package my package which is the name of
our directory - o uh whatever name we
want the do Mojo PKG file to be named so
in this case I'm naming it my pack and
then we end it with Mojo PKG which
stands for Mojo package okay then um so
your you your code your file structure
will look some something like this main.
moojo and then you will have a my
pack. mojo
PKG and let's see how we can use it
right so I'm back in vs code let's run
the
commands uh I'm not sure if you guys can
see this but we can run modu package my
package and then - o my
pack. modu PKG
so as you can see here we have a my
pack. modjo PKG file and let's use that
right in
our uh let's delete this in our main.
Modo file we can do from my pack. myair
import
pair so as you can see that didn't give
us any errors so it works so the my
pack. mojo PKG is different from my pack
package my pack is this modjo PKG file
and inside we are accessing my pair
which is this file and then we import
pair inside of my um my pair okay now
let's use that right um let my pair
equal pair 1 and
two and let's do my pair. dump to see
what we have and and let's run
it boom one and two so this works just
fine and we have a single. moojo PKG
file that does the same thing as my
package so what is the benefit of using
Mojo PKG right well you can share it
with other people so you can literally
just send a file to someone else and
they can run it so it's really easy to
use and if you don't want my package uh
this directory to be in the same
location as main. modu you can just
compile it into a modu PKG file
okay um just an important note here if
you want to modify the name of the Mojo
PKG file uh after you compiled it right
um you actually cannot simply edit the
name of this file because the package
name is encoded in in the file so if I
change this
to uh pack. modu
PKG this will still run because it's
technically still uh my pack right so
you can't just change the name that way
you have to uh run module package again
to specify the new name of the do Modo
PKG
file
okay um so now now you might be
wondering can we write any code in the
inet the modjo file since it's currently
empty right and the answer is yes we are
going to see what we can use it for so
let's add the following line in our mojo
inet Mojo file from my pair import pair
so we're importing pair from my pair
which is in the same directory as in it
the modu
okay now what does this actually
do well if we go to main.
module
um so we can let me clear this first we
can simply do from so let's see what we
had to do before right we had to do my
package do my pair import pair right
this is what we had to do before but now
since we imported PA inside the in it.
Mojo file we can just
do my pack from my package import pair
oops sorry I have to save this
file um now it should
work uh package my package does not
contain
pair
interesting let's see if this run
uh sometimes vs code can be buggy so
let's define a my pair equal pair
one2 yep another crash happened uh I
think it's something wrong with this
plug-in uh let's just ignore that error
message for now and let's do my pair.
dump and see if this works let's save it
let's clear our
terminal that did not work okay
unable to locate module my
pair um
move that's
annoying um let's
see
well
okay so I think it's something wrong
with uh Mojo right now because this
should theoretically work according to
the modu
documentation I'm not sure what's
causing this error or how to fix it for
now but in the future if you're watching
this just know that this should
technically print out one and two okay
um yeah
I'm not sure what's causing
there um okay so I hope you guys found
this video helpful except the LA the
last part
maybe um hopefully they'll fix that
error I will definitely report a issue
to the GitHub repo okay so yeah I hope
you guys found this video to be helpful
and hope you learned something if you
enjoyed this video please like And
subscribe I'll definitely be posting
more Mojo videos in the future so if
you're interested in this language so
far please like And
subscribe and yeah hope you guys do well
and see you next time
bye

----------
