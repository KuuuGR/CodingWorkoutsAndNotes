
[The TWIML AI Podcast with Sam Charrington](https://www.youtube.com/@twimlai/videos)

-----
--99--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--98--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--97--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--96--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--95--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--94--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--93--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--92--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--91--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--90--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--89--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--88--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--87--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--86--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--85--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--84--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--83--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--82--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--81--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--80--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--79--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--78--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--77--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--76--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--75--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--74--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--73--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--72--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--71--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--70--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--69--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--68--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--67--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--66--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--65--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--64--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--63--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--62--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--61--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--60--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--59--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--58--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--57--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--56--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--55--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--54--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--53--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--52--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--51--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--50--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--49--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--48--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--47--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--46--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--45--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--44--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--43--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--42--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--41--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--40--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--39--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--38--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--37--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--36--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--35--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--34--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--33--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--32--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--31--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--30--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--29--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--28--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--27--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--26--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--25--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--24--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--23--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--22--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--21--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--20--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--19--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--18--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--17--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--16--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--15--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--14--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--13--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--12--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--11--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--10--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--09--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--08--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--07--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--06--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--05--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--04--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--03--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--02--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--01--

-----
Date: 2017.03.01
Link: [Engineering Practical Machine Learning Systems with Xavier Amatriain - #3](https://www.youtube.com/watch?v=PjI24wKYfcw)
Transcription:

My guest this time is Xavier Amatriain. Xavier is a former researcher who went on to lead the machine learning recommendations team at Netflix, and is now the vice president of engineering at Quora, the Q&A site. We spend quite a bit of time digging into each of these experiences in the interview. Here are just a few of the things we cover in our discussion: Why Netflix invested $1 million in the Netflix Prize, but didnâ€™t use the winning solution; What goes into engineering practical machine learning systems; The problem Xavier has with the deep learning hype; And, what the heck is a multi-arm bandit and how can it help us.


Intro
[Music]
hello everyone and welcome to twill talk the podcast where I interview interesting people doing interesting
things and machine learning and artificial intelligence I am very excited to share this interview with you
for the show my guest is cha VA imani a chav EA is a former researcher who went
on to lead the machine learning recommendations team at netflix and is now the vice president of engineering at
Quora the Q&A site cha VA and I spend quite a bit of time digging into each of
these experiences in the interview here are just a few of the things you'll learn from our discussion why Netflix
invested 1 million dollars in a Netflix prize it didn't use the winning solution
what goes into engineering practical machine learning systems anyway the
problem that cha VA has with the deep learning hype and what the heck is a multi-armed bandit and how can it help
us of course I'll be linking to the resources we mentioned in the show notes which you'll be able to find at twillie
Icom slash talk slash three its twi mla i comm slash ta lk slash the number
three a quick note before the interview you've got just a few days left to enter
into my drawing to win a free ticket to the O'Reilly AI conference I'll talk
about how to enter after the interview and in the show notes and now onto the show [Music]
hey everyone I'm here with javi I'm at 3 on and javi hey why don't we get started
Xaviers background
by your at your core now why don't we have you talk a little bit about what you do there sure so I'm at kora and VP
of engineering so I leave the whole engineering organization right now my
background though is more in machine learning previously - Korra I was at Netflix and I was leaving the machine
learning recommendation steam at Netflix and even before that I was doing
research and I was in academia and my background again is on recommendations
machine learning and so on and I've published papers on that space for some years so it's kind of interesting that
somebody with this kind of background is now the VP of engineering of a growing
company like Korra where I I need to deal with a lot of different controllers not only machine learning right but it
also tells you a little bit of story of what is important for Korra as a company
as a product and that also aligned with with some of the trends that we're seeing in industry right that more and
more the machine learning AI people that used to be like closed in a room by a
corner and they were like the weirdos in the lab now they're having a lot more influence on decisions that are being
made on how to design products and how to run companies and in my case I'm
that's probably like one of the reasons that I'm in this position now leading
the whole engineering organization because for us machine learning it's like like a big part of our success and
how we're growing all right so there's there's a ton in there and and we'd really like to get to know you a little
How did you learn machine learning
bit better so let's let's rewind a bit you mentioned that you spend some time in academia yeah how did you learn
machine learning where did you go to school and where did you where were you working in academia yeah that's a good
question so I'm I'm actually kind of old for what you see right now and I have a
long history behind me and I'm saying that because so I when I did my PhD which by
the way I did it back in Spain I'm originally from Barcelona Spain so when I did my PhD I was mostly interested in
signal processing and particularly in signal processing and systems design
related to audio and music actually that's what my PhD was based on and at
that point in time it was that age when
multimedia and signal processing was kind of like the hot thing and machine learning was not so much so I did use
some machine learning here and there for different aspects of my research and particularly for some of the initial
recommendation system that I work on that were related to music but it wasn't my core area so I was more into signal
processing and systems doing my PhD so I would say that I I got into machine learning more on the chops and after I
left my you know my I did my PhD I went
did some more multimedia related research in the University of California
Santa Barbara UCSB so I was there I was working on virtual reality and mersive
environments and that was also very cool it's kind of coming back again now but I
was really interested in that space combining signal processing and multimedia and this kind of immersive
and virtual reality environment but after that I became more and more
interested on the data side I was like how do we use the data and how do we infer information from the data and
particularly very interested in how do we understand users from the data right so that's what kind of led me to cook
forget a little bit more about the signals so that we're a little bit like you know more there's they're also data
but they're like cold data that come from systems and focus more on the human
generated data and try to build intelligent systems that understand so I
I did then I switched my research and went into working for a few years in
recommendations and using machine learning and different kind of approaches know in machine learning but
also human-computer interaction approaches to build this intelligent
sort of like assistance that tell you what you like and what you don't like so that's what actually led me eventually
internet person to leading the recommendations team there okay now you you dangled a big shiny object
Signals processing and machine learning
in front of my eyes and that is signals processing that was an area that I studied in grad school as well and I'm
curious well hey I'm curious if you could explain wavelets to me because
that was one thing that he's getting be a hard time but actually no we're not going to talk about that I'm wondering
if you see any parallels I'm wondering if there are any interesting things
happening at the intersection of signals processing and machine learning just out
of curiosity do you have you seen anything there's actually a ton of those
intersections there's there's more of like the principles and how they intersect that I would say probably more
interesting now there is the intersection and the application side of things right so if you think about it a
lot of the systems that are now being being that are being built using mmm
machine learning approaches particularly deep learning to understand things like
speech recognition or image recognition those were considered in the past like
signal processing applications and and for example although I didn't
professionally focus too much in speech recognition I did study quite a lot of that ran you know at that time where we
were using hidden Markov models and these other techniques that for us
in the signal processing world it wasn't you know they were just tools and means to an end so it wasn't like the most important
part of the system although you know it would really like the core of it but now that's moved towards some the
learning and RN ends and so on so there's always been an intersection right between machine learning and
signal processing and there's always a lot to say about how to interpret
signals wherever they come from and those signals again could be audio could
be meat speech music video images and you need to build system that actually
either understand those things or even able to generate them in some way and
there's always a well not always but at some point it's clear that that's evolved more into having a layer of
intelligence in the middle that it's going to be learned and that comes from a machine learning system that it's sort
of like at the heart of any of those systems mm-hmm right great so you you
Netflix
made your way from academia and ended up at Netflix immediately prior to where
you are now Quora and your focus there was on recommendation systems yeah I
started with a very specific focus on recommendation systems we which you
could consider there's a continuation and natural continuation of the Netflix
prize the famous 1 million dollar Netflix prize which by the way that's what got me connected to Netflix as I
was dabbling with it and also part of using that data set port for some of my
research ok so so yeah so I started with wood you could consider like the
continuation of that Netflix price but already working for Netflix and we eventually grew the team to be more of a
core machine learning algorithms team that was building not only recommendations but algorithms for
search and for different things where they two images and it was it grew to
sort of like being a core machine learning / algorithms team that was serving different purposes beyond
recommendations but recommendations is something that is very important for an
epoch right so that was really like probably the core of the team at any given time okay
Netflix Prize
so in terms of the you mentioned the next the Netflix prize am I correct that
the the winning prize entry was never
really implemented at Netflix I'm glad you asked this because I get this
question all the time and I I react to
it by saying it is correct the final entry that doesn't mean that it was
useless right so there's I'm saying that because people immediately when I say
that and we wrote it in a blog post at net when I was in Netflix at some point and even though it was very clearly
explained people still took away like Oh Netflix wasted a million dollars and they didn't use the outcome that's not
true actually net we've got way more than 1 million dollar back in research and in interesting stuff that is being
used and was used in different parts of different systems so so if there's a
difference between was the final entry used and the answer is no it was not used there were over a hundred and
thirty different machine learning models combined in an example most of the
different models that were there were adding just a tiny increase in accuracy and a lot of complexity and they were
not worth it so the reality is that two of the models on their own gave like
enough accuracy that the other hundred and thirty-some were not needed or they
were not worthy are I that's it doesn't mean that they were not useful to understand what they were adding and how
they were adding it so again the story is the final Prize winning entry with
the complex combination of all those methods in an example was not used as it was but the learnings were worth much
more than what was invested in the prize and part of the final winning entry the
most important method were actually used directly in production okay yeah this is I came across this recently
Economics of Machine Learning
in an interesting blog post by Josh bloom over at wise and he talked about
the economics of machine learning basically all of the various trade offs
that get you know that come up when real business is trying to figure out how to
put machine learning into production and that was one of the examples he used about how I forget how many pages or
something the the final algorithm was but a hundred Garrity models that's a huge that's a huge model yeah we're
friends okay and he knows a lot about so we've talked about this in person and
you know the thing is that story is so juicy that you can spin it in many
different ways I actually recently got this is pretty crazy but I did get in my
facebook feed and advertisement from MathWorks trying to sell me MATLAB that was using
that story and saying something like Netflix did not use their final winning entry we can help you with MATLAB and
all that was so I don't even I don't get
where they're going at all with that well I don't know but you know that's the point is that yeah the real story is
yes you do need to be concerned and I'm always say the same I mean you know you
need to be concern about system complexity and about making sure that whatever you do in research it's
actually be playable and it's and it's good too or easy to build engineering
around it but that's very different from saying that the Netflix prize was a waste of time or money
sure so can you maybe spend some time walking walking through some of the
System Complexity
various factors right so you mentioned engineering time and there's you know so
there's obviously like an implementable 'ti from a complexity perspective you know they're going to be data aspects
there's computational obviously you know when you think about
you know practical machine learning and the the issues of you know urine you're an engineering VP of engineering now not
a VP of machine learning research or some when you think about you know engineering these systems at large-scale
what are the things that you need to think about oh there's like a long list
of things and you mentioned a few of them system complexity is one which
actually spans into different sub areas
and different concerns are related to the system to the complex of the system one of them which is often overlooked is
simply cost right it's like if you can do something in a single machine which I
have this kind of infamous slide that I when I show people some people don't
like very much is I tell people that they can do probably almost everything they need to do in machine learning in a
single machine and I have reasons to say that but the point is that if you add
unnecessary system complexity first of all you're gonna have a lot more cost so you're gonna have this now huge number
of machine of machines that you and I have to maintain in a cluster or paid Amazon for hey double you guys cost
rahab so that's one and it's probably obvious and it's probably not the most important the most important one is
system complexity reduces your speed of
innovation and if you have a system that it's really complex from the get-go in the waiting on it becomes like a huge
pain right because then I'm trying to tweak something and it turns out that that's something it's just one of the
10,000 knobs that are in the system and it's hard to know what it did it's hard to understand whether it improve things
and if you keep your system as simple as possible as long as possible your
innovation is going to improve and your innovation speed because you're going to be in a much better position to then
change things dramatically improve them understand what you're doing and what is improving and at some point you need to
add complexity there's no way around it it's like complexity at enough improvement and either in
accuracy or basically whatever metric you care about that it's worth adding but the problem is you don't want
arbitrary complexity from the start because that mid term and long term is
gonna impact you're gonna be end up in a local optima so to sort of speak and
you're never going to reach that global one that you would be getting if you keep your options simple as much as
possible interesting to me the thing that it brought up was the the notion of
Algorithmic Debt
technical debt that's typically applied to code write code debt isn't has anyone have you come across anyone that's
thought this through in terms of algorithmic debt oh yeah there's this
interesting paper that was published actually originally was published in the works of that ICO organizing nips and
it's called a high interest credit car of machine learning depth and it's it's
a very good read it's by a couple of authors from Google by the way so they
know what they're talking about in terms of machine learning death and so it's
something that it's been discussed again even in papers right so all right so it's it's it's an something that any
organization will face at some point and it's something that it's really important and it's really important and
many levels not only at the level of the system itself but also and I would go
further that that's part of like the the core of the machine learning algorithm
algorithmic design right it's like it's a camp razor principle of you know if
you have a possibility of choosing between two things always to the simplest one and part of the reason is
because you want to minimize your depth as long as possible and only make things more complicated when they really need
to be and they're adding up enough so that goes back to the lesson learned
from the Netflix prizes like you know yeah sure you can have you can go for the more complex solution but it's the
Delta an improvement that is adding more the huge increase in complexity and many times the answer is gonna be no that's
Know Deep Learning
an interesting segue to one of the topics that I wanted to chat with you about you recently tweeted about a
natural language processing course and the hashtag you use was know deep
learning across a number of your public appearances you've maybe developed a
little reputation for mr. hashtag know deep learning and of course I'm being I'm being artificially you know
controversial here yeah I understand it this is you know it's a it's a tool in the toolbox but some of our earlier
discussion about system complexity I think is one of the issues that you have with deep learning maybe walk us through you know what your position how you
think of your position on deep learning and you know why you bring it up interesting when I talk about deep
learning I always start by having a few slides in my presentation that explain how deep learning works right so I want
to get that out of the way and say hey I know the deep learning works and it's great for a few things actually
particularly for natural language processing I think that it's getting to a point where it's the default tool for
many things and it's great so the reason I was using the hashtag is just to warn
people that if they were looking for deep learning it wasn't available in that course so I think it is it's very
important for people to understand what
is the right tool for the right task and for example we use deep learning at
Quora for several things but we have a lot of text and going back to the NLP example there's many things now in text
processing that RNN are you know they're actually the simplest solution there is
because you can you can find some of this ready available open source to to
kids that have already been trained and you can even use the model as it is you don't even need to have your own data
set or then you can retrain it but that basically becomes simple enough that
that could be your for approach to a an NLP task that you
have in hand but that's very different from saying that that's equally true for
all machine learning applications and you need to understand like what is the
complexity you're paying for defaulting to machine learning for everything you have and I've seen a couple of examples
recently where I think we're you know in a dangerous situation where a lot of
people especially like more junior researchers or engineers that they're
you know they've come into industry right at the cusp of the deep learning
bubble or wave or whatever we want to call it and their their mind goes straight into deep learning as the
default solution for anything and I've seen cases where I've had engineers in
some companies tell me hey I'm using this central flow architecture on a
problem where I have ten thousand examples and thirty features and I want
to ask you a question and my answer like why are you doing this to yourself I mean if you have ten thousand example
than thirty features do you really think you need deep learning model with a
bunch of layers and most of the time the answer is no and even if the classifier
you're building with that deep learning
architecture is let's say in the best case one percent better than the one you
could be building with a simple logistic regression you're still going to be better off going for the logistic
regression because what I'm going back to what I was saying before your ability to innovate on that initial model is
gonna be much bigger than your ability to innovate on a very complex the neural
net that you don't really understand what's going on in inside so I guess my the point that I'm trying to make when I
talk about quote-unquote know deep learning is that deep learning should be
another of the tools we have in our toolkit and there's a lot of other very interesting machine learning tools and
even research that is going on that it's we should still pay attention to there's
a problem also in the research world right now with deep learning is that because it's so new and there are so
many so much low-hanging fruit it feels like you know that it's the easiest way
to get a paper except that is to an incremental improvement or not so incremental an improvement on some deep
learning approach and that's why we're seeing all the conferences now dominated with deep learning things right even
when you go to a comfort like KDE or the
ACM recommender systems conference that I'm going to be attending in September
you start seeing like a bunch of deep learning papers because it's new it's easily innovating using deep learning
but we run the risk of like saying oh yeah this is the one thing that works for everything and we're going to try to
find all the nails that apply to this hammer and we'll think that they're all
they all look the same and and I think that's there is a danger in that so
Cora
you've touched a little bit on some of the things you're doing it Cora maybe tell us a little bit about you know tell
us a bit about your experiences there and you know what are some of the interesting problems that you face there
yeah sure so I that's a great question
one of the things that I love about Cora and one of the reasons as I said before
that we have a VP of engineering with this kind of background in machine learning and algorithms is that
everywhere I look on our product and our day shoes that we're dealing with I see
problems that are solvable and should be solved through machine learning right so
now if I sorry for interrupting but it's likely that most of the people listening
What is Cora
know what Cora is but maybe you can start with just an explanation of the
site and the mission sure that's yeah that's that's a very good point and it's a very
good point because also even people that know us and users frequently they have a misconception about what core is so core
is on the surface is a question and answer site and application mmm but our
mission goes beyond that so the mission of Cora is to grow and share the world's
knowledge and we think that the question/answer paradigm is really well-suited for actually growing and
sharing knowledge just to give a different example of the only other
quote/unquote company that has a similar mission which would be Wikipedia Wikipedia also believes in the spreading
or growing the knowledge but they believe in the encyclopedic format and that leads to a bunch of different
product decisions of course so we feel like question entering and a broader
notion of what knowledge is so Wikipedia is about factual knowledge we think that
for example an expert opinion is also knowledge and should be included in any knowledge base so all of that defines
our decisions and using question answer for now it's working really well and we
think it's the ideal vehicle but we are not close to trying different things and actually we do have even different
things as of today in our product that enable that knowledge growing and knowledge sharing so so another way to
look at and to understand Cora is the different sort of like networks that
overlay in the product so we do have obviously a knowledge network and even
another one that it's a topical network so we have entities of knowledge that are connected to each other topics that
are related to each other and then on top of that we add the social aspect
right so then we have people and we have people that are connected to other people and we have people are connected
to topics and to knowledge entities and this sort of like different overlays of
different graphs at different levels and the different connections between them is what makes the whole data problem
very exciting because we have a lot of applications that cross the different networks in different directions and we
have for example algorithms that are purely on the content space and they tell us how good is the quality of a
given piece of content we have other algorithms that tell us how likely is a person to answer a question on a given
topic we have different kinds of machine learning algorithms that their purpose
is sort of like trying to understand and predict different aspects of this dynamic system and the relations between
all these different entities so again examples of things that we do we do a
lot of recommendations you have initially in your home page you'll see a
feed of different stories that include questions and answers that we're
optimizing for you to be interested on and that's kind of similar to the
Facebook feed but has other implications and a different objective function so
recommendations like that recommendations that you get through email we optimize the notifications that
you get through different devices also using machine learning that's all on the personalization side of things then we
have content approaches to infer the quality of a content to do things like
ranking answers according to how good they are we have things related to a lot of the
text side of things automatic topic labeling hunting for a topic out of a given text how to find
similarities and questions and answers how to find duplicates and then also we
have the whole abuse side of things which also uses machine learning we need
to one of the things that cor is known about for is you know keeping high quality content and that's the quality
piece but also keeping a very healthy positive community and we do that with
very good Norm's and also algorithms that detect any form of spam harassment bad actors
and so on so forth and each one of them is a different machine learning algorithm so it's really exciting in
that sense because we have covering sort of like a huge space of applications and data tabs that go into this applications
interesting can you talk a little bit about the extent to which you use hybrid
Hybrid ML
machine learning plus human yeah obviously there's a big component of the site that you could argue as hybrid as
users are ranking different answers but are there ways that you're using hybrid
approaches behind the scenes yes we are so so one way to think about it is
initially all everything all of this was manual right then the first initial better version of korah
there were no algorithms in place and all of it needed to be manual so we do
have a team of moderators and people that look at content and there's always
a point where algorithms are not gonna be sufficient and you need somebody to look at the nuances of like is this
answer about this politician really violating our norms yet or no and it's
like really nuanced and we need to have person look at it so the way we think about it is there's if you think about
any content moderation issue there's always gonna be a high portion of the
stuff that you have on your side that is gonna be good and it's gonna be good with no doubt so you can have algorithms
that say hey above this threshold I'm totally positive this is good stuff we don't need to worry about it there's
always gonna be a huge another huge but at some part of your content is going to be really bad and there's no doubt about
it so there's another threshold that tells you below this threshold I'm just gonna remove this stuff because it's basically
crap and you don't want it that's how you keep the quality of your content in
the side right now there's this gray area between those two thresholds and the tricky part right so you have to do
two things one is there's you know you have to have people then look at this
gray area and decide yeah this is not really that bad it should where it should be okay with it and at the same
time you need to improve your algorithms to get those two thresholds as close to each other as possible and that's very
interesting right because it represents sort of like a research challenge for us to improve our machine learning algorithms say hey we won the gray area
of the things are uncertain too over time become as small as possible and
we're doing that and at the same time the gray area is still there and when when we have things in the gray area we
need to use some humans in the loop to understand what's going on uh-huh so if
Challenges
if Cora were to do a corner prize analogous to the next Netflix plot
surprise what would it be about what are some of the biggest challenges that you
face well there's in each of those dimensions
that I mentioned before there's there's challenges that are still not resolved
but I guess thinking of the Netflix Brydon is something that would be kind
of similar and I think it's very interesting and probably that an obvious
direction we would go is that for something like knowledge there's also a
problem which is similar to a network price of how do you get the right piece of content to the right person and
content is expressed in two ways right one is a content that you can consume so
that's an answer that you can read and you can enjoy you can learn from it and the other one is a question that you can
answer so both of those things how to route them to the right person and how
to optimize algorithm for those two things are at the core of what we're doing and they're very important for us
so I think we could think of like again drawing the analogy of the Netflix prize
of like question and answer recommendation being like a very interesting
topic that for us it's like a super interesting challenge it also connects
like many different dimensions on the different overlays that I was talking
about because it's not only about personalization but you also have to care about content quality right and you
have to care about those different aspects and how they feed into what the
users are going to be doing and reacting to short term but more importantly what
they're going to be reacting to long term I've talked about that in the past in some of my presentations like this serve
like tension between short term metrics and long term metrics and that's
something that a lot of companies have done the wrong thing and they've gone downhill because of that and it's really
important to understand for example in the context of content how to avoid
clickbait right and if you're optimizing for some things you're gonna get clicks sure but those clicks are gonna turn
into people not visiting your site ever again after a number of weeks so all
those things sort of like fit into this picture of like content recommendation
or knowledge recommendation how do you address the short term long term
Tradeoff
trade-off now maybe even in the context of a clickbait type of application so so
there's different things that go into it I would say that that that's one of the
most interesting research areas that I don't think it's been really solved even
in research literature because there's it's very hard to get enough good quality data sets to even do something
about it if you're if you're a research in academia and in the industry I mean
as far as I know from the people that I talk there's obviously different things that we're all doing but a holistic
approach to it is it's hard the one important thing is you do need to make
sure that you're running your a B test with right sort of metrics right because at
the end of the day you can be optimizing whatever you want in the lab and say oh it's a ranking problem I'm going to be
optimizing NBC G but the reality of that metric that you're optimizing in the lab
with your algorithm might not really correlate perfectly to what you want to
get and the product in that long term metric so first you need to make sure that you whatever you tune in you're in
the lab you run a b test long enough term with the right metric to understand
like what is the met what what are the effects that whatever you're doing have
on the users and then you kind of work backwards from that right once you have
the right metric on your a B test you know oh if I do this my users end up not coming back after two weeks what did I
do then you back you kind of work backwards from that and try to understand like what are the metrics in the lab that you
could have used to sort of like predict that kind of behavior in the kind of effect right so building regression
models from sort of like your easy to compute metrics which they're all gonna
be related to some kind of error or some kind of information retrieval precision
and recall whatever you will into the real world of usage I think that's
that's very important and then there's a there's a ton of other things that you can do once you understand those
dynamics in trying to define your training set in a way that actually mmm
defines the problem in the right way and and sometimes I have talked about this
also in the past people have this mistake of I need to use all the data
that I have and I need to use the raw data that I have and sometimes that's
not really the answer you might need to use some data and not others because some of the data that you might be
feeding into the into your model might be teaching them all the wrong thing or you might need to wake your data in a
way that some is more important than because it leads to longer term effects that you're interested on while other
might lead to a click but nothing else so there's there's a lot of sort of like
different details going into the recipe but again I don't think there is a very
holistic approach to it or not that I'm aware of okay one thing that that came to mind
Deep Learning
for me was and this is maybe going back to our discussion around deep learning
there is some research happening around our n ends and you know when the the
reinforcement or the score you know comes later and how the RNA and can optimize for you know this delayed
gratification so to speak and so you know maybe this is where you know if this gets sophisticated enough this is
where you get some benefit from the introducing the complexity of our n ends
where an otherwise simple model might come into play yeah that's definitely
true so multiples or approaches that have any sense of sequencing or time or
evolution over time to have some depth
some benefits and and and you can use them it's not only about a RN and another thing that comes to mind it's
some reinforcement learning approaches I mean the typical one of the typical ways
to deal with this is to use and some form of multi-armed bandit approach to
deal with the exploration exploitation trade-off it's it's more of like yeah you know I know that you're picking on
this but let me try to explore more things let me try to come up over time have you know my model converged to
something that is a global optimal rather than getting stuck on that local one where I am right now so yes you're
right I mean and some of the sequential RN ends with some form of memory and and
ability to sort of like remember different stages and sort of like end up
converging over time into a better optimal they're super interesting
before we before we get too far can you explain simply multi-armed
Multiarmed bandit
bandit yeah so the idea is pretty simple
I mean multi-armed bandit comes from this notion of you have the typical
image that people use is the slot machines in a casino you imagine that
you go into a casino and you have ten slot machines in front of you and you don't know which arm you should pull
that where the multi-armed bandit come from and you start trying one you say oh this one is giving me some interesting
prices but should I try another one because maybe the one that I have next to me it's actually better than this one
and how to deal with this dilemma of out of multiple arms that you could be pulling there's some that you have more
information about and you know with a degree of certainty how well they're
doing and there are others that you don't really know anything about them should you risk yourself and go into the
ones you don't know anything about them or should you just stick to the one that kind of works but maybe it's not the
optimal one so I think that's the whole point of the multi-armed bandit
approaches it's like they try to find a way in which you can have an optimal
policy to deciding whether you should continue pulling from the same arm or you should go to a different one and
there's there's a lot of literature on
on this in and you can read about it and
I usually joke about it there's a lot of literature about multi-armed bandit but
there's only one that actually works in practice but I don't know if I want to
give that away I mean it's it's it's pretty it's pretty well known in an
industry that comes from sampling is the easiest and sort of like more practical
approach to multi-armed bandit so I think that and I'm not giving too much away by saying that
right so what uh what what are you finding most exciting about machine
Most exciting thing about machine learning
learning right now obviously there is a ton of things going on there's deep
learning stuff there's the work that's happening around BOTS there's applying deep learning to NLP like you know given
everything that's going on like what what's the most exciting and and do you
get to apply that in your work and what's the most exciting thing that you're actually working on so I think
the most exciting thing for me it's almost a non-technical thing it's more
of a this thing coming from society as a whole that it's accepted as a given that
machine learning and AI is inevitably part of making a better future and I
think you know there are still so people that were argue about dangers and and about robots taking over and so on but I
think generally speaking society is convinced and it's pretty much you know
all bought in you know self-driving cars a couple years ago people thought we
were crazy about self-driving cars and now they're already being tested with people writing in them so so I think
this sort of like change in society and in mindset and people realizing that oh
machine learning is not really evil it can be it's a tool it can be used in my
benefit and it's something that I expect things to have to have so not very long
ago seeing something that was an algorithm or machine learning was like
whoa what's going on I'm losing control this is not something I like and now it's shifting to the opposites like you
expect applications you expect gadgets to have intelligence and to have machine
learning otherwise you're disappointed like oh my gosh I need to tell this phone everything I want the phone should
know what I want right so I think that's that's a very very interesting shift and
and it kind of connects a lot with some things were doing at Quora right in kora
we are very user focused and we want to we want to keep this warm feeling of
you're in the community you're sharing knowledge this is very important for you it's very important for the people but
you're gonna be surrounded by all this different algorithms that make your life much better and they protect you from
bad people and they protect you from horrible content that you don't want to read and they help you get your content
to the right people that want to read about it and they're going to be helped by it so this combination of silver the
warmth of community social aspects and knowledge but also surrounded by all
this different algorithms in a seamless way I think that's super exciting and it's something that you need to strike
the right balance but it's something that just a few years ago we wouldn't thought about because you know again
algorithms were the this cold evil thing that you kind of like wanted to stay
away from so I think that's that's a very interesting trend and something that I'm excited about mm-hmm we're
Favorite conferences
coming to the end of our time but I've got a couple more quick questions for you the first is you go to a lot of
conferences what are your favorite conferences in the space I would say I
go to a lot of conferences unfortunately especially now since my time as a VP of
engineering is pretty precious and I don't get that much time there's some
confidence that I have ties for a very long time and I keep going to them because I am very interested in the
content but also I'm interested in the community one of them is it's a small conference actually the it's the ACM
recommender systems conference that's a conference that is purely focus on personalization and recommendations and
I help start the whole thing I was a the general chair for that in 2010 back in
Barcelona and I kept kind of keep in touch it's in one of the interesting things about this community which I
think it's a little bit similar to for example kdd is that it's a very diverse
kind of audience and you don't get machine learning nips audience everyone
focus on the algorithm and you know squeezing 1% more or less pharmacy or
maa out of their algorithm there's a combination of algorithms but also
application and then user oriented research which I think connects to the
vision that I was saying right this connection between user orientation and algorithms it's very interesting so yeah
the ACM recommender systems conference which by the way is happening in Boston if anyone is listening from Boston or
wants to travel there this year is in the US and it's gonna be super interesting and when is it it's coming
up right yeah it's in September 15 so yeah in a few weeks we're gonna be there
and just to give an example I'm giving a tutorial with together with Deepak our
well from LinkedIn on all the latest research and all the evolution of
recommendation systems in industry and we're going to be giving a holistic perspective of me coming from Netflix
and now Cora and him having been at Yahoo and now reading machine learning at LinkedIn so it's gonna be sort of
like an overview of all this kind of machine learning techniques for
recommendations so that's that's an example of a small focus conference but
also with a very broad audience which I kind of enjoyed kdd which just happened
to be in San Francisco recently I like the community a lot and I think I can
find all of very interesting approaches in applications I usually yeah I'm very
application driven in my approach to machine learning so although I will I will read all the papers or not not all
sorry some papers from nips and ICML I I
tend to go to more sort of like application driven conferences and and there's also a lot
of small conferences that are organized now there are kind of local and focused
on the industry side of machine learning ml comp is one that comes to mind that I
attend regularly because I find the audience to be very interesting and very
engaging and it's a lot of practitioners from industry mixed together with a
bunch of researchers and that intersection I think it's it's really interesting mm-hmm great great and then
one more question that you're in a particularly good place to answer for us
and that is who are the people to follow the machine learning folks to follow on Quora oh that's a great question but we
have a lot of them so we've been doing actually a very strong push for this
product feature that we have with these sessions which is similar to an MA AMA and we brought in I would say like all
the top machine learning researchers to do some session in the past we've had
people like I mean most of the deep learning folks like young laocoÃ¶n and
joshua banjo and we've had Andrew Inc we've had Peter Norbeck we've had a lot
of different researchers and I would say most of the authors of the famous
machine learning books like Kevin Murphy from Google and so on or we we had Ian
Goodfellow the main author of the deep learning book also recently so there's
like a good you I would say 50 people that you would follow we've also had
people that leave machine learning in different companies like Amazon we have
my friend Ralph furbish from Amazon or Joaquin from Facebook
so there's like a huge machine learning community in kora that it's very active and very strong so it's one of our
strongest areas right now so I would recommend people who are interested in
machine learning there's like a ton of knowledge there and growing so yeah
great great well chubby thank you so much for spending the time with us I
Outro
learned a ton and I'm sure the folks that listen well as well anything you'd
like to leave us with no I mean thanks for having me and it was great to share
a little bit of that knowledge in this different format which it's also a way
of spreading knowledge and I look forward to interacting with people especially on Quora I myself write a lot
of different answers on different topics in doing machine learning oh that's a good point before we go where can folks
find you how can folks engage with you I'm pretty public on Twitter as you
mentioned you you had seen a bunch of my tweets so I'm they can find me on Twitter on
Chama at X am eighty or on Korra I'm also very active so you can follow me on
Korra and message me there I usually keep a very active public profile so
it's not hard to find me and I have a pretty weird name and last name so it's like it's really to go into the wrong
direction if you if you google my name yeah alright great thanks so much have you yeah thank you Sam
alright everyone that's it for today's interview before we go a reminder that
this week in machine learning and AI and O'Reilly have partnered to offer one lucky listener a free pass to the
inaugural O'Reilly AI conference which will be held at the end of September in New York City you can enter via Twitter
or the twill Malaya comm website by doing one of the following three things the preferred way of entering is via
Twitter just follow at twimble AI Twi la i and retweet the contest tweet that
I'll pin to the account and post in the shownotes do those two things and you'll be entered if you're not on Twitter you can
sign up for my newsletter at twill Malaya com / newsletter and add a note please enter me in the additional
comments field finally if you're not on Twitter and you aren't interested in the newsletter no problem just go to the
contact form on - Malaya comm and send me a message with that form using AI
contest as the subject the drawing will be open to entries through September 1st
and I'll announce the winner on the September 2nd show good luck and hope to see you in New York thanks again for
listening

**Introduction**

- Podcast: TwiML Talk, discussing machine learning and AI.
- Guest: Xavier Amatriain, VP of Engineering at Quora, former leader of Netflix's machine learning recommendations team.

**Xavier's Background**

- Initially focused on signal processing and multimedia research.
- Transitioned to focus on machine learning, especially in understanding user preferences through data.
- Shifted from academia to Netflix, leading their machine learning recommendations team, and later to Quora as VP of Engineering.

**Key Discussions**

1. **Netflix Prize**
    
    - Netflix invested $1 million but didn't use the final winning solution directly.
    - The prize led to valuable research and learnings.
    - Final entry's complexity outweighed its benefits, though some components were used.
2. **Engineering Practical Machine Learning Systems**
    
    - Importance of balancing system complexity with the ability to innovate.
    - Avoiding unnecessary complexity helps in maintaining a fast pace of innovation.
    - The concept of 'algorithmic debt' â€“ the cost of maintaining complex ML systems.
3. **Deep Learning Hype**
    
    - Xavier acknowledges deep learning's effectiveness in certain domains like NLP.
    - Warns against using deep learning as a default solution for all ML problems.
    - Emphasizes understanding the right tool for the task to avoid unnecessary complexity.
4. **Quora's Engineering Challenges**
    
    - Quora's focus on knowledge sharing and the importance of machine learning in their product.
    - Various ML applications in Quora, from content quality assessment to user behavior prediction.
    - The use of hybrid machine learning-human approaches, especially in content moderation.
5. **Challenges and Future Directions**
    
    - The balance between short-term metrics and long-term goals.
    - The challenge of optimizing content delivery to users.
    - The importance of using the right metrics and data in training models to align with long-term objectives.
6. **Exciting Aspects of Machine Learning**
    
    - Societal acceptance and expectation of ML/AI integration in products and services.
    - The blend of community warmth and algorithmic intelligence in products like Quora.
7. **Conferences and Community**
    
    - Favorite conferences include ACM Recommender Systems Conference, KDD, and ML Conf.
    - The value of conferences lies in their blend of algorithmic, application-driven content and community engagement.
8. **Influencers on Quora**
    
    - Quora hosts many ML experts and conducts AMAs with prominent figures in the field.
    - Xavier recommends following these experts for insights and discussions on ML topics.

**Conclusion**

- Xavier shares insights on the intersection of engineering, machine learning, and community-driven products.
- Emphasizes the importance of understanding the tools and methodologies in ML to apply them effectively in real-world applications.
- Highlights the growing integration of ML in everyday products and the societal shift in perception towards AI and ML.


----------
