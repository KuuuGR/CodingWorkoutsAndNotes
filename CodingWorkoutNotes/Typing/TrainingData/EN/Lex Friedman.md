I discovered that the Lex Fridman Podcast covers some of the most interesting topics, and the people he interviews are incredible. Therefore, I've decided to use his channel as the initial subject for testing language data.
[Lex Clips](https://www.youtube.com/@LexClips/videos) -> Mostly Short
[Lex Fridman](https://www.youtube.com/@lexfridman/videos)

-----
--99--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--98--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--97--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--96--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--95--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--94--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--93--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--92--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--91--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--90--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--89--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--88--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--87--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--86--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--85--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--84--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--83--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--82--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--81--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--80--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--79--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--78--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--77--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--76--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--75--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--74--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--73--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--72--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--71--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--70--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--69--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--68--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--67--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--66--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--65--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--64--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--63--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--62--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--61--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--60--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--59--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--58--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--57--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--56--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--55--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--54--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--53--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--52--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--51--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--50--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--49--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--48--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--47--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--46--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--45--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--44--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--43--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--42--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--41--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--40--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--39--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--38--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--37--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--36--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--35--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--34--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--33--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--32--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--31--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--30--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--29--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--28--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--27--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--26--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--25--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--24--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--23--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--22--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--21--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--20--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--19--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--18--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--17--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--16--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--15--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--14--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--13--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--12--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--11--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--10--     https://www.youtube.com/@lexfridman/videos

-----
Date:
Link:
Transcription:

paste here

----------

-----
--09--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--08--

-----
Date:
Link:
Transcription:

paste here

----------

-----

--07--  

-----
Date:
Link:
Transcription:

paste here

----------

-----

--06--

-----
Date: 2016.09.27
Link: [Sequence to Sequence Deep Learning (Quoc Le, Google)](https://www.youtube.com/watch?v=G5RY_SUJih4)
Transcription:

eating that were divided in two parts so number one and we work with you and
develop the sequence to sequence learning and then that's the second part I would I will place sequin to sequence
in a broader context or a lot of exciting work in this area now so let's
multiply this by a an example so a week
ago I came back from vacation and my in my inbox I have five hundred and eight
emails and reply emails and a lot of emails I basically just require just yes
and no answer so let's try to see whether we can do a system that can
automatically reply these emails to say yes and no and for example so some of
the email would be you know from my my friend on she said hi in the subject and
she said are you visiting Vietnam for the New Year walk that would be her content and then my probable reply would
be yes so you can gather another set like this and then you know you have
some inputs content so less for now let's ignore the the the on the author
of the email and the subject but let's focus on the content so let's suppose that you gather some email and some
input would be something like are you visited in Vietnam for the New Year Kwok and the answer will be yes and then the
another email would be are you hanging out with us tonight the answer is no because I'm quite busy
so the third email would be did you read the coolness paper on breast net the
answer is yes because I liked it now let's let's do a little bit of
processing we're basically in the in the previous slide we have gear and comma
and then kwok and then question mark and so on so let's let's do a little bit of
processing and then put the the comma a
space between gear and comma and then Kwok and question mark and so on so this
step a lot of people call tokenization and normalization so let's do that with our emails now so and then the second
step I would do would be to do feature representation so in this step what I'm going to do is the following I'm going
to construct a 2,000 dimensional vector 2,000 represent the size of English
vocabulary and then I'm going to go through email I'm going to count how many times a particular word occur in my
email for example for example the world
are occur one in my email so I increase the counter and then you occur one so I
increased another counter and s etc and then I will reserve at the end a token
to reserve to just count all the words that just our vocabulary okay and then
now you now use successful you if you do this project a process you're going to
convert all of you or your email from input to output pairs where the input would be fixed line representation of
20,000 dimensional vector and output would be either year or one okay any
questions so far okay good
okay so I will get so as you said somebody in the audience that the order
of the words don't matter matter and the answer is yes so I'm going to get back to that issue later now so
that's x and y and now your job my job now is to try to find some W search that
W time X can approximate Y Y is the output right and Y here is yes and no so
because of this problem is has two categories you can think of it as a
logistic regression problem now if anybody follow the gray cs2 10:29 class
by andrew probably can formulate this very quickly but in a very short you the
album comes as follow you kind of try to come up with a vector for every email
your w is a two column matrix okay
the first column will find the probability for the eat whether the email have to be answer as yes second
column will be answered as no and then you basically take the dot product
between w1 at the first column now Adam is called the stochastic gwendy set so
you run for iteration one to like a million you run for a long long time you sample a random email X and then some
reply and then if the reply is yes then you want to update your w1 and w2 such
that you increase the probability that the answer is yes so you increase the
first probability now if your reply is if the correct reply is no then you're
gonna update w1 and w2 so that you can increase the probability of the is email
to be answered as you know so the second probability okay so let's call those a p1 and p2 now so because to
update I said to update the increase what does that mean what that means is that you find the gradient of the
partial gradient of the objective function with respect to some parameter so now you have to pick some alpha which
is the learning rate and then you say W 1 is equal to W 1 plus some alpha the
partial derivative of block of P 1 with respect to D of W 1 ok
now I cheated a little bit here because I used the log function it turns out because the log function is a mono is a
monotonic increasing function so increasing P 1 is equivalent to increase in the log of P 1 ok and it usually with
this formulation stochastic gradient descent works better any question so far
and then you can also update you know W 2 if the email is to be reply is yes and
you can you can have different way to update and to if the reply is no so
what's a and then if you have a new email coming in then you take X and then
then you control into the vector then you compute the first probability ok W 1
time X divided by W exponential W 1 time X plus exponential or W 2 time X and if
that probability is larger than 0.5 then you say yes and if that probability is
less than 0.5 then you say no ok so that's how you do prediction with this
now now this there's a problem with this representation is that there's some
information loss so somebody in the audience just said that the order of the words don't matter and that's that's
true now let's let's fix this problem by using something called the recurrent
Network and I think a rigid soldier already talked about recurrent networks
and some part of it yesterday and Andrei as well now there the idea of a
recurrent Network is basically you have also have fixed representation for your
input but it actually preserves some sort of info ordering information and
the way that you compute the hidden units the following so the function hash of Euro is
basically hyperbolic hyperbolic tangent of some some matrix you time the work
vector for the world are okay so Richard also talk about what vectors yesterday
so you you can take what vectors coming out of what to back or you can just
actually randomly initialize them if you want to okay so let's suppose that that's H of zero now H of one would be a
function of H zero and the vector for
you which is a times H of zero plus u
times V of vector u and then you can keep going with that to see one of my
three three most complicated slides so you are you should ask questions no
questions so everybody familiar with recording that sir well
okay so to make predictions with this but you you tack on the label at the
last step and then you say try to predict why for me how do you do that now here I I basically you you went the
way you did before and basically you make update on the W matrix which is the
the classifier at the top like what I said earlier now but you also have to
update all the relevant matrices which is the matrix you the matrix a and some
work vectors right so this is basically you have to compute the partial
derivative of the last function with respect to those parameters now that's
going to be very complicated and usually I when I do that I do that myself I get
that wrong but there's a lot of tools out there that you can use which is you
can use auto auto differentiation in tensor flow or you can call torch or you
can call piano to actually compute the derivatives and once you have the derivatives you can just make the update
right yeah yes so you the matrix you are
share so I'm going to go back to one side so this matrix you I share all for
all vertical matrices right and the size
you have to determine ahead of time for example the number of column would be
the size of the work vectors but the number of rows must be like like a
thousand if you want or maybe 255 you want so this is model selection and it
depends on whether you under fit in over fitting to choose a bigger model or a smaller model and your compute power so
that you can train a larger model a smaller model
the matrix you yeah so the the work
vectors the world vectors the number of work vectors that you use are the size
of vocabulary right which is so you gonna tend to end up with 20,000 work
vectors right but the the size of so that means you have 20,000 rows in
matrix U but the number of column you can sorry the number of column is 20,000
but the number of row would be you have to determine up just yourself okay any
other questions now okay so what's a big
picture so the big picture is I started with bag-of-words representations and
then I talked about a and n as a new way to represent variable size input that
can capture some sort of ordering information then I'll talk about Auto differentiation so that you can compute
the partial derivatives and these you can find auto intensive flow or piano or
torch now then I talked about stochastic when descent as a way to train the
neural networks and the question so far
okay you have a question oh that's also
depends on how big your your training set and how big is your computer and so
on right but usually if you use an N and if you used like a hidden state of a hundred you should take like a couple
hours yeah but it depends largely largely depends on you know size of
training data because you want to iterate for all a lot of you sample a lot of emails right you and you want
your algorithm to see as many emails as possible right so okay so if you use
such algorithm to just say yes no and just know then you might end up losing a lot of friends
because because because we don't just
say yes no because we went to say when
for example my friend asked me are you visiting Vietnam for the new year walk then maybe the better answer would be yes see you soon right that's not better
nicer way to approach this and then if if my friends ask me are you hanging out
with us tonight so instances say no I would say no I'm too busy or did you read the coop ok
right so let's let's see how we're going to fix this so so before I'm gonna tell
you the solution I would say this is the this problem is drew it basically
requires you to map between variable size input and some variable to some
variable size output right and if you can do something like this then there's a lot of applications because you can do
auto reply which is what we've been working on so far but we can also work on user to do translation just like
between English French you can do image captioning so input would be an a fixed
like vector or representation coming from conflict and then output would be the cat sat on the mat right or you can
do summarization the input will be a document and output would be some summer summary of it or you can do two speech
transcription where you can have input would be speech frames and output would
be words or you can do conversation so basically the input would be the
conversation so far and the output could be might reply or you can do cue night etc etc so we can keep going on now so
how do we solve this problem so so this is this is hard so let's check out what
Android capacity has to say about recurrent networks okay so so Android
say that there's more than one way that you can configure your network to do things so we can do you could use your
network to map recurrent networks to map one two right so the at the bottom that's an
input the the green would be the hidden state and the output would be the what
you want to predict now 1 1 2 1 is not what we want right because we have many
too many so it's probably more like the last two to the right right but we
arrived as the solution that I said in the red box and the reason why it does
that's a better solution is because the the the size of the input and the size
of output can vary a lot sometimes you have smaller input but larger output but
sometimes you have larger input and smaller output so if you do the one in
the red circle you can be very flexible right if you do the one to the extreme
right then maybe the output has to be smaller or at least the same with the
with the input right which what we are that's what we don't want so let's construct a solution that look
like that so okay so here's the solution so the input would be something like hi
how are you right and then let's put a special token unless let's say the token
is end and then you're going to predict the first token which is M and then you
predict the second token fine and then you predict the throat Oken thanks and then you keep going on until you predict
the world end and then you stopped now I
want to mention that B in the previous set of slides I was just talking about
yes and no and ingest no you have only two choices okay now you have more than
two choices you have actually 20,000 choices and you can actually use the
algorithm that are the the logistic regression and you can expand it to cover that more than one more than two
choices you can have a lot of choices okay and then the algorithm uses just
follow the same way now so dizzy my first solution when I say walk - sick
- sick but it turns out it didn't work very well and the reason why I didn't work very well is the model never know
what it actually predicted in the in the last step so it keep a keep going and
you keep synthesizing output but it didn't know what it said it didn't know what decision it committed in the
previous step so a better simpler solution would look like this a better solution is you back basically you feed
what the model predicts in the previous step as input to the next step alright
so for example in this case I'm going to take am I'm going to feed it in to the next step so that I'm conduct completing
the dance in the second world which is fine and etc so a lot of people call
this concept auto regressive so you you take your you eat your own output and
make it as your input any questions so far or whenever it produced end then
just stop there's a special token end yeah now okay so the so relevant architecture
here would be the end code people also call the encoder as the what the
recurrent network in the input and the decoder would be the recurrent network in the output okay okay so how do you
train this so again so you basically you run for a million steps you see all your
emails and then you say you sample and for each iteration you sample an email X
and a reply why why would be you know I'm fine thanks right and then the
sample random work YT in Y and then you update the iron and encoder and decoder
parameters so that you can increase the probability that Y of T is correct given
all what you seen before which is your YT minus 1 YT minus 2 etc and also all
the axes right and then you have to compute the partial derivatives to make
it work so the computing part partial this is very difficult so again I recommend you to use something like Auto
differentiation intensive flow or torch or Tiano okay you have a question yeah
but the recurrent Network the number of parameters didn't change because you have U and V a UV and I are fixed right
okay so the question in the in the audience is that there's um if the iron
and are different in four different example and the answer is yes so the number of steps and are different I have
a question there okay yeah I'm gonna get
to that in the next slide yeah okay all right so the question is a
in practice how long would I go to for the RN I would say if you usually stop
at like 400 steps or something like that because outside of that it's going to be too long to make the update and compute
it's very expensive to compute but you
can go more if you want to yeah I have a question yeah
yeah yeah yeah so that's a problem so if I'm going to talk about the prediction
next so let me go to the prediction and then you can ask questions so okay so how do you do prediction so this the
first algorithm that can we can you can do is go greedy decoding okay in greedy
decoding is for any incoming email X I'm going to find I'm going to predict the
first word okay and then you find the most likely word and then you feed back in and then you find the next most
likely word and then then you feed back in and etc so if you keep going you keep
going until you see the world end and then stop all it is exceed a certain length you stop okay
now that's just do greedy okay so let's let's do a little bit less greedy so it
turns out that so given X you can predict more than one candidate so let's say you can predict a candidate's let's
say three okay so you take three candidates and then for each candidate
you're going to feed in the next step and then you arrive at three so the next step you're going to be have nine candidates right and then you're going
to end up going that way so here's a picture so given input X I'm going to
predict the first token there would be hi yes and please and given every first
token like this I'm going to feed back into the network and the network will produce another three and etc so you're
going to end up with a lot of a lot of candidates so how did you select the best candidate well you can traverse
each beam and then you compute the John probability at each step and then you
find the sequence I have the highest probability to be the sequence of choice
what is your reply any question to see
the most complicated slide in my talk oh yeah yes so the question is what do
you do with our vocabulary works now it turns out in this algorithm what you do is that for any word that is our
vocabulary you create a token call unknown and you map everything to
unknown or anything that our vocal every vocabulary to be unknown so it doesn't
seem very nicely but usually it works well there's a bunch of algorithms to
address these issues for example they break it into like characters and things like that and then it you could fix this problem
yeah yeah the cost function is that so I
go back one slide so the cost function one more slide so the cost function is
that you sample a random were YT here
let's suppose that here I this is my input sofa or an input and I'm sample YT
let's say T is equal to 2 so which means the work fine okay I'm at the work fine
I want to increase the probability of the model to predict whoa fine
so the every time the model will make a lot of predictions some a lot of them
will be incorrect right so you have a lot of probabilities you have probability for the water and
the probably a and etc and then probably for zzzzz right and you have a lot of
probabilities you want the probability probabilities for the worst for the work
fine to be as high as possible you increase the probability does that make
sense or you condition on IIM so you condition
so when I'm at fine my input would be hi how are you and and um okay that's
that's all I see and then I need to make a prediction and I have to make that prediction right right and you know if
I'm at the world thanks my input would be hi how are you and I'm fine and I
gotta get my thanks for probability right okay yeah I have a question here
oh I haven't thought about it yet so the
question is how do you personalize so well one way to do it is basically embed a user as a vector so let's suppose that
you have a lot of users and you embed a user as a vector that's one way to do it yeah I have a question here
yeah yeah so the question is that let's
suppose that my beam search is 10 then you go to from 10 like a hundred and
then a thousand and suddenly it grows very quickly right it go to rule a if
you if your sequence is long then you end up with K to the N or something like that well one way to do it is basically
you do truncate that beam search where any any sequence with very low probability you just pick it up you
don't use it anymore so you go so you can do this you can do 3 9 and then you
ten to seven and then you go back up to 9 right and then you keep going so that
way you don't end up with a huge beam and usually in practice using like a
beam size of three or ten would work just fine and whoops wait yeah yeah I
have a question okay so for because it's
a 9n we don't have to Pat the input now to be fast sometimes we have to Pat the
input because we want to make use make sure that batch processing what's very
well so you'd be bad but we paired with only like zero tokens
okay yeah so let's suppose that you have
a sequence of ten then you have a graph of ten when you have a sequence a batch of all twenty you haven't made a graph
for twenty and etc yeah that will make the GPU very happy I have a question
that oh so so you are you asking sort of so
my interpretation of your question is how do you insert the world embedding into the model is that correct our user
embed an old if you want to personalize the thing then at the beginning you have a vector and that's a vector for quoc
with a ID one two three four five and then if is Peter then the vector would
be five six seven eight yeah yeah that's
one way to do it yeah well there's more than one way you can do it at the end or you can do it at
the beginning or you can insert a tab at every prediction steps but my proposal
is just predict put it at the beginning the simpler okay I have a question there yeah you
yeah
that's a very good question the question is what if the model details right if we
make a prediction and then that's a bad prediction and your model never see and then it keeps detailing and it will
pretty produce garbage yeah that's a that's a good question so I'm going to get to that so well so this is sly so
there's an algorithm for scheduled sampling so in scheduled sampling what you do is you you instead of feeding the
truth during training you can fee feet what sample from the sub max so what
generated by the model and then feed in as input so that the model understands
that if it produce something bad it would suck actually can recover from it right so that's that's one way to
address this issue is that make sense yeah any question there's a question
here okay yeah yeah yeah so in this
algorithm yeah the question is how large is the the size of the Dakota well my
answer is that try to be as large as possible but it's going to be very slow and in this algorithm what happens is
that you you use the same you use like
fixed length embedding for like to represent the very very much the long
term dependency like a huge input right and that's going to be a problem so I'm
going to come back to that issue with the attention model in a second okay
any question okay here's a question
ah so does the model learn synonyms is
that a question or what's the question oh I see well yeah it turns out that if
you learn it turns out that it mapped good and if you visualize embedding the good and fine and so on I'm not very
closely to the to the embedding space but in the output there's we don't know
what else to do the other approach is basically to train the world embeddings using water vac and then try to ask the
model to regress to the world imbalance right so that's one way to address this issue we tried something like that did
not work very well so whatever we have in here was pretty good okay I have to
keep going but like any way the algorithm that you've seen so far turns
out actually answer some emails so if you use the smart reply feature in inbox
it's already used this system in production now for example in the indc
me email my colleague Ricardo got an email from his friend saying that hey we
wanted to invite you to join us from the early Thanksgiving on November 22nd
beginning around 2:00 p.m. please bring your favorite dish and reserve by next week and then it would propose three
answers for example the first answer would be telecine second answer would be
will be there and the third answer is sorry we won't be able to make it now
this where do these three answer come from those those are the beams now there's an algorithm to actually figure
out the diversity as well of the beams so that you don't end up with very similar answers so there's an algorithm
that like a heuristic that make these beams a little bit more diverse and then
they pick the best three to present to you
okay any question yeah I have a question here
yeah there's no guarantees so the question is how do I guarantee that the the beam would terminate an end now
there's no guarantee it can go on forever the indeed there are certain cases like that if you don't train the
model very well now but if you train the model well with with very good accuracy then the model usually terminates highly
see any cases that it don't terminate it doesn't terminate yeah but there are
some corner cases that it will do funny things but you you can stop the model
after like a thousand or hundred or something like that so that you make sure that the model doesn't do that
doesn't go on crazy right I have a question here
that's very interesting yeah it just comes out because there's a lot of emails and if you invite someone there's
more than one person and it might be it learns about Thanksgiving it just mean inviting the whole family things like
that yeah it just learned from statistics yeah or
maybe that something like that yeah okay okay oh in industry algorithm so the
question is do I do any post processing to correct the grammar of the beams in this algorithm we did not have to do it
yeah okay I have another question
so okay so the question how contextual so I would say we don't have any user embedding in this so it's pretty general
the input would be the previous emails and the output would be the prediction
the reply that's all we have so it sees a context which is the threat sofa okay
did I answer your question okay yeah we
you can catch me up after the talk yeah oh yeah it ran down too so yeah slow
question oh oh I see
so the question is there's some some emails are not relevant for a smart apply maybe they've too long or you
should not reply or something like that so in fact we have two algorithms so one hour with them this is to say yes or no
to reply right and then after it passes
the threshold there's an algorithm to run to produce the threshold so it's a combine of two our rhythms that are
actually I presented earlier yeah I have
to get going but you can get back to the question so there's a lot of a more interesting stuff coming along okay so
so what's a big picture so far so the big picture is that we have an i NN encoder that it's all the input and then
we have an iron and decoder the trying to predict one token at a time in the output now everything else force is the
same way so you can use stochastic when you sent to train the algorithm and then
you you do beam search decoding usually you do app in search of up 3 and then
you should be able to find good food good beam with the highest probability now someone in the audience brought up
the issue that we use fixed length representation so just before you you make a prediction
the Japan the hm and the white thing right before you go to the Dakota okay
that is the fixed-line representation and you can think of it as like it's a vector that capture all everything in
the in the input right it could be a thousand words or could be five words
and you use a fixed length representation for a variable length input which is kind of not so nice so we
want to to fix that issue so there's an algorithm coming along and it's actually
invented at a at University of Montreal you're sure he's here so the idea is to
use an attention so how does an attention work so in principle what you
want is something like this every time before you make a prediction let's say you predict the world am you kind of won
a loop again at all the hidden state so far you want to look at all what you see
in the input software okay now say when you do fine you also want to see all the
all the hidden state of the input sofa and and on now how do you do that in as
a program so well you can do this so you H of M you predict a vector C let's say
that vector is the same dimension with all the H okay
so if the your H of one each dimension of 100 then C also have a dimension of
100 okay and then you take C and then you do dot product dot product with all the H okay and then you have
coefficients a 0 a 1 blah blah blah to a
to the N okay and those are scalars okay
and then after you have those scalars you compute something called the beta which is basically I stop max of all the
Alpha right so 2q compute that you take the exponent bi is an exponential our AI
divided by the sum of Exponential's okay okay and then you take those bi and then
multiply by H by and then you take the weighted average and then you take the sum and then you
send it to add additional signal to predict the war and and then you keep
going with that right so in the next step you also predict another C and then you take that C to compute the dot
product you compute the B the a and then you can compute the B you can take the B you do the weighted average and then you
send it to the next time to send it to the prediction and then you use stochastic when you send to Train
everything okay and this autumn is implemented in
tensorflow okay so how how into table
what is going on here so let's suppose that you want to use this for translation so in translation you wanna
for example the input would be hi how are you and the output is Ola combos
paths or something like that okay and then when you put it the first word you
want Ola to correspond to the world hi okay because there's an one-to-one
mapping between the word high and Ola so if you use the attention model the
beta's that you learn will put a strong wait for the words Ola for the world
high and then it has a smaller wait for all the stuff and then if you keep going then when you say Como's then it will
focus on how and etc okay so it moves that coefficient it put a strong
emphasis on the relevant world and especially for translation it's extremely useful because you know the
one-to-one mapping between the input and output any question so far this is
definitely very complicated yeah I have a question
all right now the beta other day and be alone so I don't I don't
and so the question is how do I deal with languages where the order them like reverse for example English to Chinese
Japanese right so some of the verbs get moved and things like that well I didn't I did not have cold air be they are
learned so by virtue of learning they will figure out what beta to put right
to wait the input and those are computer basically computed migrated set right so
they just keep on learning okay I have a
questionnaire okay yeah so the question
is are they any work on putting attention in the output yeah I think I think you can do that I'm not too
familiar with any work in here but I think it's possible to do it I think some people explore something like that
yeah any question oh I have a question another question
yeah yeah yeah yeah yeah so so the question
is less about because right now the world hi is capitalized at the first
character it doesn't mean I'm using two n or n vocabulary size so in practice
you we should do some normalization if you have a small data set what you should do is you normalize the tax so
high will be like lowercase and etc now if you have a huge data set doesn't
matter we just learn okay yeah I have a question there right yeah so it
so the question is in a sense it's capture the the positional information in the import yeah I agree I have a
question there a pattern punctuation ah
so the question is what do I do with punctuation well they are in right now
I just present the algorithm as if it's a very simple implementation like the
very basic but one thing that you can do is you you before you train the
algorithm you put a space between the world and the punctuation so that you do
some that is that step is called tokenization or normalization in language processing so you can use any
like a stanford NLP package or something like that to normalize your text so that
is easy to train now if you have infinite data then if you just learn itself okay so I should get going
because there's a lot of other interesting stuff okay so it turns out that the the basic implementation but if
you want to get good results and if you have big data sets so one thing that you can do is to make the network deep and
one way to make deep is is in the following way so you stack your your recurrent network
on top of each other right so you know like in the first sequence of sequence paper we use a network of four but
people are gradually increasing to like six I and so on right now and they getting better and better result like in image
net if you make a network people you also get better results okay so i if you
wanna train sequin to sequins with attention then do a couple years ago
when we like many laps working on this problem were behind the state-of-the-art
but right now in translation many translation tasks basically this model
our audio already achieved state-of-the-art without in a lot of these the pomt datasets so to train this
model so number one is that as i said you might end up with a lot of
vocabulary our vocal vocabulary issues
so what Barack Obama will be this an unknown right Hillary Clinton and season
unknown now you you might use something like what segments right so you segment
the words out for example Barack Obama would be bar and drag and etc or you can
use all the smart algorithms for example word character split you can split words
that have unknown to be in two characters and then you treat the meta character there's some work at Stanford
and they prove that it works very well so that's one way to do it you know tip number two is that you you when you
train this algorithm because you when you do back propagation or forward propagation you multiply you essentially
multiply a matrix many many times so you have explosion of function value or or
the gradient or implosion as well now one thing that you can do is you click
the grade in a certain value right so you say that if the gradient magnitude
of the gradient is larger than 10 set it to ten okay then tip number three is to
use giu or in our work we use a long short term memory okay so I want to
revisit this long short-term memory business a little bit okay so what's the long short-term memory so in
use an iron cell basically you can catenate your input and your the the
hidden state and then you multiply by some theta and then you apply with some
activation function let's say that's a hyperbolic tangent okay now that's the
simple function for n n now in lsdm you
basically you multiply the input and hash by a huge big matrix let's call
that theta that theta is four times bigger than the theta I said in the iron
and cell and then you're going to take that Z okay that coming out you split it
into four blocks its block you can compute the gates and then you you use
the the value of a something called like the cell and then you keep adding the newly computed computed values to the
cell so there's this apart here that I say that the integral of C is that what
it does is basically it keep a hidden state where it keep adding information to it so it doesn't multiply information
but it's keep adding information you don't need to know a lot of this if you want to just apply a SDM because it's
already implemented intensive law any
questions so far okay so in terms of applications you can
use this thing to do summarization so I've seen I started seeing work in some radiation pretty
exciting you can do image captioning so and the input in that case would just be
a representation of an image coming out from vgg or coming out for google net
and etc and then you send it to the I end and and we do the decoding for you or you can use it for speech recognition
or transcription or you can use it for QA so to the next part of the project
the top and we'll talk a little bit about speech recognition okay so well in speech recognition the
input could be maybe waveforms right and then an output could be some words you know hi how's it well
one thing that you can do is you drop your input into Windows that's the green
box is there and then you crop a lot of them and then you send a lot of them to an iron and then you convert it into MFC
see before you send to Ana MFC see or spectrogram or something like that okay and then you use the algorithm that I
said earlier and then with attention and then you do the transcription you
predict one word at a time in the output now the problem with this algorithm is
that in turn when it comes to speech you end up with a lot of input right you can
end up with thousands and thousand steps so back propagating in time even with attention can be difficult now one thing
that you can do is basically you do some kind of a pyramid to map the input so
you if you do enough layers you can divide your input into a factor of eight
or sixteen if you do enough layers right and then you produce the output so we we
work in on an implementation where the output is actually characters like like
the in the by - squawk where they have the ctc now I have to say that the
strength of this algorithm is that you actually have an implicit language model in the output so when I say I when I
have the word how is actually conditioned on hi and stop before right and including the
input so there's an implicit language model already but the problem with this
is that actually you have to wait until the end of the input to do the coding so
the decoding has to be done offline okay so if you use this for voice search it
might not be too nice because people want to see the some some output right
away okay so in that case there's an algorithm that can use it do it in an online fashion
block-by-block now also I have to
mention that in translation this hour the sequence sequence a wit attention
works great it's a among the stay of the art but when it comes to speech it doesn't work
as well as the CDC at least in published results we're not as good as CDC which
is whatever what Adam talked earlier or some of the hmm DNN hybrid which is
which is the most Wylie speech system currently so I want to pause there and
then I can take questions any questions I have a question at the back yeah yeah
yeah yeah
Oh so how does the book in translation
well in translation what we do is basically we have pairs of sentences so
for example hi how are you and then hola como estas right and then we have pairs
of sentences like this and then we just feed it into the turns out into the sequence two sequences attention at
every step we again we're going to predict one word at a time but before we make a prediction the model has the
attention so it actually see the the input once more before it makes a
prediction that's how it works now what is can you repeat okay what is the issue with with a model again please
yeah
I see well I I can't quite follow the question but let's take it offline
is that okay yeah yeah and then we can do some paper okay together
I have a question yeah yeah yeah okay so
the model I did the inbox thing that I presented it was on in English but there's no limitation in the model in
terms of language so let's suppose that you in your inbox that you sometimes you
write in English and sometimes you you write in in Vietnamese or sometimes you write it in Spanish whatever and you
personalize by user embedding that I would say that it will just learn your behavior and then we will basically
predict the world that you want you make you but make sure that your your output bank vocabulary is large enough so that
it covers not only the English words but also the Spanish word and etc like
Vietnamese and so on so your vocabulary gonna be not going to be 20,000 it's going to be like a hundred thousand
because you have more choices and then you have to change your model on on those examples yeah it's a matter of the
training data that's all okay I have a questionnaire yeah
yeah yeah I saw the question is that in the case of voice search right now you have to wait at the end to make a
prediction is there any otherwise yeah yeah the answer yes you can make a prediction block by block so you can
actually figure out like an algorithm a simple algorithm to actually segment the speech and then make a prediction and
then take the prediction and feed it it as input at the next block so you can keep going like that so you in theory
you can actually do online decoding but but I'm saying that the work on you can
do online decoding but that work is currently work in progress how about
that okay I have a question there yeah
over here so we have some input email and then some output email where export
written emails reply and then you can just strain it that way yeah yeah okay I
have a couple questions
yeah yeah the question is that in speech
recognition the CDC seems to be a very nice framework because it match it laser like a monotonic increase Minh in the
output and the input but let CTC make this independent assumption it doesn't
have a language model in it maybe that's the the sequence of sequence I can address this oh yeah I
think that's a great idea maybe we should write a paper together okay I think I think I haven't seen it
but I think that's a very good idea question
I say okay great so so the question is that is there because right now we
predict one step at a time is there any way to actually look globally at the output and maybe use some kind of
reinforcement learning to adjust the output and the answer is yes so there's a recently a recent paper at Facebook
who I think sequence level training or something like that where they don't optimize for one step at time but they
predict they look at the globally and then they try to improve world at a rate or they try to improve blue score or
things like that for translation and it seems to be making some improvement in the metrics that they care about now if
you show it to humans though people still prefer the output from this model
so some of the metrics that we use in translation and so on might not be what
the metrics that we optimize and the next step prediction seem to be what people like a lot in translation yeah so
so the question is can we add the GaN loss like it again lost yeah I think that's a great idea yeah I have a
question here yeah yeah
change yeah yeah
so let's suppose that you type the first ha hola then you can actually start the
beam from there so the question is is there any way to incorporate user input
so I say yeah it let's suppose that you wanna you say hola sorry
hi how are you right and then as soon as the person type hola that actually restrict your beam so you
can actually condition your beam on the first world Ola and your beam will be better yeah I think that's a good idea
I have a question oh so how much data
did we use so in translation for example we use the several several WMT coppices
Cobra and the W empty copper I usually have tens of millions of seven pairs of
tendencies something like that and every every sentence have like 20 words on
average twenty thirty words on average I can't remember but that's something like that order of magnitude yeah yeah I have a question there I
can't really hear also how's it compared
to Google search auto-completion I honestly I don't know what to use
underneath a Google search auto-completion but if I were if they you if I think they should use something
like this because it's okay I have still
lots of interesting stuff coming along so okay okay so what's a big picture so
the big picture is so far I talked about sequin to sequence learning and
yesterday Andrew was talking about most of the big trends in deep learning and
it talking about the second trend was basically doing end-to-end deep learning so you can characterize sequence of
sequence learning as an 2n deep learning as well now so the framework is very
general so it should work from a lot of NLP related tasks because a lot of them
you would have input sequence and output sequence in our NLP it could be input
would be some text and output would be some you know passing trees that's also possible but it works great when you
have a lot of data now when you don't have enough data then maybe you want to consider dividing your problems into
smaller components and then creating your sequin to sequence in the sub components and then merge them okay now
if you don't have a lot of data but you have a lot of related tasks then it's
also possible to actually merge all these tasks by combining the data and then have an indicator bit to say this
is translation this is summarization this is email reply and then change only
and that should improve your your output to now this basically conclude the parts
about sequence sequence and then the next part I'm going to apply sequence to sequence in a big picture of the active
on ongoing work in neural nets for NLP
so if you have any questions you you can ask now I take maybe two questions because I think I running out of time so
I have a question yeah
also the question is does the modem handle emoji I don't know but it's emoji
is like a piece of text to write so you can just like feed it into as another extra token if you make them if you make
your vocabulary 200,000 then you should be able to cover emoji as well yeah I
have a question also if you have new
data coming in so should I return the model where you I think towards the end
we lower the learning rate so if you add new data it just it will not make a lot
of good updates so usually we make you you can add new data increase the learning rate and then continue to Train
yeah that should work okay so I already took two questions let's keep going so
so this is an active area that actually is a very exciting which is in the area
of automatic unite so you can think that maybe the set up would be can you read a
Wikipedia page and then answer a question or can you read a book and answer your question now you in theory
you can use sequin to sequence with attention and then to do this task so
it's going to look like this you're going to read the book right one token a time and with the book then treat a
question and then you're going to use the attention to look at all the pages
and then you make a prediction of the tokens right so so that cut up that's
kind of sometimes you do we do answer this question that way sometimes we don't have knowledge about the fact so
we actually read the book again to answer the fact but a lot of the time if you ask me is Barack Obama the president
of the United States I would say yes because it's already in my memory so
maybe it's better to actually akhmet the iron with some kind of memory okay so that it will not to do this look
back again right it's kind of annoying look back again so there's an active area of this research
I'm not a definite expert but I'm very aware so I can place you in the right
context here so work in this area would be memory networks by Western and folks
at Facebook there will be new rotating machines that deepmind dynamic memory networks would
be a richer soldier presented yesterday and then stuck augmented iron ends by
Facebook again and etc now well let's list so I want to show you a like
high-level what is this augmented memory means okay so let's think about the
attention so the attention looked like this so you and in the end coder you're going to look at at some input okay and then
you have a controller which is your H variable and then you keep updating very high variable but along the side you're
gonna write down into memory your h1 h2 h3 and etc right you store it into a
memory clear-rite and in the decoder what you're going to do is you gonna continue
continue producing some output right are you going to update your controller G but you're going to read from memory
your H okay right so that so so again so
in the import you write to memory in and then in the output you read from memory
now now let's let's try to be a little bit more general and the general would
be at any point in time you can read and write right you have a controller and
you can read and write read and write all the time now to do that you you have to follow in architectures you have some
memory bank big memory back ok and then you you can use the right you can decide
to write some information into it from by a combination of the memory bank in
the previous step and the hidden variable in the previous step and then you also read into the hidden state to
and then you could make an amount update and then you can keep going forever like that so this concept is called an N with
augmented memory okay is that is that
somewhat clear any question you have a
question the question is when you read
do you read the entire memory bank a lot of these algorithms are actually soft
attention so yes it will look the entire memory you can actually predict where to
look right and then read that only that block now with the problem with that is
you end up with very it's not differentiable anymore right because this the thing that you
don't read don't contribute to the gradient so it's going to be hard to train but you can use to reinforce and
so on to train it so there's a reason our paper reinforcement learning new row
Turing machines but actually so there's something like this right not exactly but it will deal with discrete actions
okay any question no question Wow okay
so the another extension that a lot of people talk about is using an N with
augmented operations so you want to augment the neural network with some
kind of operations like addition subtraction multiplication the sine
function etc lot of love functions so to motivate you you can think about Q and I
can fall into this for example histor context the building was constructed in the year 2000 and then it was in later
all people say oh it was then destroyed in the year 2010 and then the question
would be how long it the building survived and the answer would be ten years now how would you answer this
question where you say 2010 subtract two thousand ten years now neural nets if
you can train with a lot example it can do that too you can learn too subtract numbers and things like that it
requires a lot of data to do so all right so maybe is better to augment them
with functions like addition and subtraction right so the way you can do
it is that the neural network will read all the token so far and we'll push the
numbers into a stack and then you get the more the neural net is augmented by
a subtraction and a addition function and these two phone and then you assign
these a probability for these two functions so green the more duck does
mean the higher probability okay so you aside to probability and these two you compute the weighted average of the
values coming out of these two function and then you take that and then you pop it and you push it into the stack in the
next step and then in the next step you will call the addition and subtraction again and etc that's the principle of
something called neural programmers or new neural programmer interpreters so there are two papers last year from
Google brain and nygma was talking about this so so that's that's some of the
related work in the area of augmenting recurrent networks with with operations
with memory etc now what's a big picture ok so the big picture I want to revisit
and I say so what I've talked to today
is sequin to sequence learning and it's an end-to-end deep learning task so it's
one of the big trends happening in natural language it's very general so
you can use if you have a lot and a lot of supervised data it's a very supervised learning algorithm so if you
have a lot of data it should work well but if you don't have enough supervised data then you consider dividing your
problem and then training different in different components or you can train jointly in an multitask settings and
people also train it jointly with auto encoder namely to read the input sentence and then predict the output
sentence again and that's also and then you train jointly with all the tasks and
works as well if you if you go home and
then you want to make impact at your work tomorrow then so far that that's so far so good that that can make some
impact now if you want to do some research and I think like things with memory operation operation augmentation
are some of the exciting areas but but it seems like still work in progress but
I would expect a lot of advances in this area in the near future so so you if you
want to know more you can take a look at pre-solar block you talk about attention
and of my augmented recurrent networks I also wrote some tutorials pretty simple
this the sequin to sequence with attention for translation is implemented
intensive flow so you can download and you can use you can actually download tensor flow and train it what I said
today now this there's a lot of work going on
in this area not on many of these are not mine so I so as you can see you can
even read the world just means how many papers come along in this this area so I
can pause there and I have five minutes to answer questions I have a question
there yeah yeah
yeah
yeah I see okay can you speak to the
microphone because I can't hear very well add a microphone and then I think people can hear that as well when you're
treating a Q&A network so you're taking the example of training from a book to answer questions yeah so if let's say
Harry Potter who was Harry Potter's father now there could be many books that have a character Harry so he has a
context resolution issue which is which Harry should I answer the question for ya how do you solve the context context
problem in your training this kind of Q&A type Network I think that's a great question so I think one thing is that
you can always personalize for example you know that the guy when I talk about you can have a representation for the
user and then you know that when he say Harry his because he actually been reading a lot of books about Harry
Potter so it's more likely to be Harry Potter but I think with the hour time I
said I just want to make sure that it's as simple as possible so the father if you do the juicer has to ask the
question Harry Potter rather than Harry but I'm saying if you
represent user vectors and then you inject more additional knowledge about
the users about the context into as additional token in the input of the net
the net can figure it out by itself yes so that's one way to do it yeah okay I
have a question yeah you did some work on Doc to Vic yeah do you have an idea
what the state of the art in generalizing were two veggies to more than one word oh I see
I think skip thoughts are interested in
directions here so dr. that is one way but skip thought so that the idea of
skip thoughts was Ruslan salakhutdinov with author on this a his idea is basically using sequence
to sequence to predict the next sentence so the input would be the current
sentence the output we would be the the the the previous sentence all connect sentence and then you can train a model
like that if the model is called skip four and I have heard a lot of good things about skip thoughts where you can
take the embedding at the end and then you can do document classification and
things like that and it works very well so that's that's probably one place that you can you know can go my colleague at
Google is also working on something called auto encoder so he instead of predicting the next sentence he predict
the current sentence so trying to repeat the current sentence and and that's kind of work well too yeah yeah see what was
your thoughts on how to solve the common sense reasoning problem Oh common sense I'm deeply interested in common sense
but I gotta say I have no idea I think maybe you can do something like I think
common sense is about a lot of first of all there's a lot of knowledge about the world that is not captured in text right
for example gravity and things like that so maybe you really need to actually combine a lot of morality that's that's
one way to think about it all the way all the thing is do you make sure that unsupervised learning work that's
another approach but I think this digital research area I think I'm just
making guesses right now is there a good way to have sent all these rules and you
know using some soft yes yes so the question is how do you represent
Dru's so so if you think about this network the neural programmer network that it actually augmented by addition
and and subtraction then these are rules
right you can augment it with a table of proofs and then ask the network to
actually attend into the truth table people have looked
to this direction so that's one way to do it okay saying basically argument is to do some logical reasoning yeah yeah
yeah hey okay great talk yeah thank you um are is there like a practical rule of
thumb for how many sequence pairs you need to train such a model successfully yes a is there are there any tips to
reduce how many pairs you need if you don't I said okay so usually the bigger
data set the better but like the corpus that people train this on translation for example English to German it's only
about about 3 5 million pairs of sentences or something like that so that's kind of small 3 million right and
still people are able to make it to the state of the art so that's that's pretty encouraging now if you don't even don't
have a lot of data that I would say things like pre-trained your work vectors with language models or a word
to vac right that's that's one area that you have a lot of parameters you can pre
train your model with some kind of language model and then you reduce the sub max that's another area that you
have a lot of parameters or use drop out in the input embed in or drop out some random word in the input sentence so
those things can improve the regular radiation when you don't have a lot of data okay yeah thank you okay yeah
thank you all so we'll reconvene at 6 o'clock for yoshua bengio
closing keynote

----------

-----

--05-- 

-----
Date: 2016.09.27
Link: [TensorFlow Tutorial (Sherry Moore, Google Brain)](https://www.youtube.com/watch?v=Ejec3ID_h0w)

Summary:
In this lecture, Sherry Moore from the Google Brain team delivers a comprehensive tutorial on TensorFlow, a machine learning library developed by Google. The session begins with an introduction to TensorFlow, explaining its purpose, functionalities, and its extensive use at Google. Sherry emphasizes TensorFlow's flexibility and suitability for machine learning applications, attributing its design to close collaboration with researchers.

The tutorial progresses to hands-on coding, guiding attendees through building models to address classic machine learning problems, particularly focusing on linear regression and classification. Sherry meticulously explains the core concepts, such as tensors, dataflow graphs, nodes, and how TensorFlow's architecture enables asynchronous operations.

The practical part of the session includes the construction of neural networks, with detailed walkthroughs of creating variable objects, inference graphs, training graphs, and the use of placeholders. Sherry introduces TensorFlow's modular design, emphasizing its front-end libraries, execution runtime, and compatibility with various devices, including CPUs, GPUs, TPUs, and mobile devices.

Throughout the tutorial, Sherry engages with the audience, answering questions, and encouraging exploration of TensorFlow's capabilities. She introduces advanced features like saving checkpoints, loading models, running evaluations, and adjusting hyperparameters. The practical exercises are designed to solidify understanding, encouraging attendees to modify and experiment with the code.

Sherry underscores TensorFlow's capability to streamline the process from research to prototyping to production, encouraging contributions to the open-source project and highlighting the active support and continual development of TensorFlow by the team.

In the Q&A session, Sherry and her team address various inquiries about TensorFlow's functionalities, including C++ API usage, Windows support, model portability, data loading, and integration with other frameworks. The session concludes with a note on TensorFlow's commitment to advancing machine learning, fostering a collaborative environment, and the availability of resources and support for users.

Transcription:

Introduction
so I'm going to take a picture so I remember how many of you are here smile
like Sammy says my name is sherry Moore I work in a Google brain team so today
I'll be giving a tutorial on tensor flow first I'll talk up a little bit about what tends to flow is and how it works
how we use it at Google and then the important part is that I'm going to work
with you together to build a couple models to solve the most classic machine
learning problems so Cal get your feet beat for those of you from New Zealand anybody from New Zealand so hopefully at
the end you'll be going home with all the tools that you have to build all the
wonderful things that you have watched today like all the image recognition the
training of different colors arts making music so that's the goal so before I go
any further has everybody installed tensorflow yay
Thank you
brilliant thank you and I would like to acknowledge so I know the link here says Syrian but if you have Wolff g TF
tutorial is perfectly fine Wolff is actually the my colleague who spent all the time verifying installation and
every single platform so I would really like to thank him thanks wolf if you're watching and also I have my wonderful
product bus a product manager in the audience somewhere so if you guys have any requests for tensorflow
make sure that you go find him and tell him why that tencel must support this
feature or exact somewhere all right so there he is so with that we can move
forward to talk about tensor flow so what exactly is tends to flow tensor
flow is a machine learning library that we developed at Google and we open-source the last November and ever
What is TensorFlow
since then we have become the most most popular machine learning library and get
help how do we know because we have over
32,000 stars those of you who track github you know how hard it is to get
rid of those acknowledgement and we also have over 14,000 Forks and we have over
800 no 8,000 contributions from 400 developers 400 individual developers and
we designed this specifically for machine learning however is your see
later because of its really flexible dataflow infrastructure it makes it
really suitable for pretty much any application that can fit into that model basically if your model can be
asynchronous in fire on when data is ready you can probably use tinder for it
originally we worked alongside with all the researchers as a matter of fact I was really fortunate when I joined the
team I sit right next to Alex the person who invented alex net so that's how closely we work together as we develop
tends to flow they would tell us no this is how we use it yes when you do this it
makes our lives a lot easier and this is why we believe that we have developed an infrastructure that will work really
well for researchers and also being Google we also always have in mind that we would like to take from research to
prototyping to production in no time we don't want to want you to write all the code that's typically you're just
throwing away we want to write code that can learn to cut and paste and save in the file and privatize it immediately so
tensile is really designing with that in mind so we will have way into your deep
learning school so can anybody tell me if you want to build a neural net what
must you have what are the primitives what are the yeah primitive I think is
the word I'm looking for what must you have to build neural net
anybody what is in the neural net
This American history so in an Iran that you have neurons that's right
so in and you need so all these neurons what do they operate on what do all
these neurons do they process data data and they operate on data and they do
something such as convolution matrix multiplication max pooling average
pooling dropout whatever that is so intensive flow all the data is held in
something called a tensor tensor is nothing more than a multi-dimensional
array for those of you who are familiar with numpy arrays it's very similar to the ND array and the graph I think one
of the gentlemen earlier this morning described there's this concept that the graph which is a composition of all
these neurons that do different functions and all these neurons are
connected to each other through the inputs and outputs so as data become available they would fire by firing men
they do what they're designed to do such as doing matrix multiplication or convolution and then they will produce
output for the next competition know that's computer connected to the output so by doing this so I don't know how
many of you can actually see this animation yeah so this is to really
How TensorFlow works
visualize how tensor flow works all these nodes the Oval ones are
computation this rectangle ones are staple nodes so all these nodes they would generate
output or they take input and as soon as all the inputs for a particular node are
available it would do its thing produce output and then the tensor all the data
which are how in tensors will flow through your network therefore tensor
flow yeah so everybody's like wow this sounds like
magic how does it work so who said is it sir other car glasses any sufficiently was
the word any sufficiently advanced technology is indistinguishable from magic so that's what this is it's just
really awesome excuse me for a second I
know I want I want to get through this as quickly as possible so we can actually do the lab that you're all dying to do so as any good
infrastructure so this is I want to give you a little image of you know how we design this in tensorflow just like any
well-designed infrastructure has to be really modular because being module allows you to innovate to upgrade to
improve to modify to do what everyone with any piece as long as you keep the api's consistent everybody can work in
parallel it's really empowering I think that's one of the wonderful things that's done at Google pretty much any
infrastructure at Google is really modular they talked really about to to each other all you need to maintain is
the API was stability so in this case we
have a front end I think you guys must have seen some examples of how you construct a graph so we have the
Frontend libraries
front-end libraries written your favorite language and if C++ and Python is no your favorite language feel free
to contribute we always welcome contribution so you write you can show your graph in your favorite language and
this graph will be sent to we call the core a tensile execution system that's
your runtime and that's what you all will be running today on your laptop when you open your up your Python
notebook or should be the notebook so the execution runtime depending on where
you are going to run this application it will send the kernel to the
corresponding device so it could be a CPU could be GPO could be your phone could be CPU anybody knows what TPU is
brilliant very nice I was a stratum say anybody knows what TPU is ever there's
like mmm translation so this is good so just to highlight our portability today
Portability
you'll be running intensive roll in your laptop we run it in our data center you everybody can run on your iOS on your
iPhone your Android phone I would love to see people putting it on Raspberry Pi
because can you imagine you can just write on tensorflow application it could
be your security system because you know somebody just stole my bike and my security camera capture all this grainy
stuff that I cannot tell wouldn't it be nice if you do machine learning on this
thing and they just start taking high-resolution pictures you know when when things are moving rather than
constantly capturing all this grainy images which is totally useless so I think the application literally
applications are limitless you know your imagination is delivered so we talked
about what tensorflow is how it works how do we use it at Google we use it
How we use it
everywhere I think you have seen some of the examples we use it to recognize pictures this is actually done with
inception they can recognize after the box one of thousand images you have to
retrain it if you wanted to recognize they're all your relatives or you know your pets it's not difficult and we I
have links you know for you to actually if you want to train on your own images it's really easy they should totally try
it will they be funny we go to your relative your own 40 year reunion you just go hi you know you who you I know
who you are you know just show off a little it would be brilliant and we also use it to do Google Voice Search this is
the one that's super awesome so how many of you use smart reply have you ever
Smart Reply
used smart reply yeah yeah this is awesome especially for those of you who are doing what you're not supposed to do
you know texting while driving your new song email coming in and you can just say oh yes I'll be there you know so
based on the statistics that collected in February over 10% of the
other responses and on mobile is actually done by our smart reply that's or I believe if we have maybe exact can
collect some stats for me later maybe by now you'll be like 80% it's actually
really funny at the very beginning when we train it the first answer is always I love you like that's probably it right
not the right answer we also play games
of you I'm sure have follow this the all kinds of games that are being developed
Games
it's really fun to watch if you watch it literally come up with scenarios for you to play as well it not only learns to
play the game but learns how to make a game for you is fascinating and of
course art everything many of you have done the Steve dream if we have time in the end of the lab we can we can try
this so if you're super fast we can all try to mix a Mart and all those what I
Models
just talked about of course Google being this wonderful generous company and wants to share our knowledge so we have
actually published our models so if you go to that link you'll find all these
inception and captioning language model on the billion words the latest rest net
on c14 sequence the sequence which I think Kwok will be talking about tomorrow and in the world we have many
Highlevel libraries
other high-level libraries so today my lab the lab that we would do will be on
the core tensorflow api's but there are tons of new higher level API such as
some of the mentioned cares and we have slim we have pretty tensor we have TF
learn we have many libraries that's developed on top of the court in several api's then we encourage people to do so
if whatever is out there does not fit your needs perfectly go for it develop yo and we welcome the contribution we
published a lot of that here I might have blurred some of the boundaries but these are basically all the models and
libraries that we have produced and we really love contribution if you have
developable really cool model please do send to us and we would you know we would showcase
your your work so that's the
introduction of tensorflow how does everybody feel are you all ready to get started
alright so okay before you bring up your Python notebook I want to say what we
are going to do first okay so as I mentioned there are two classic machine learning problems everybody does one is
linear regression the other is classification so we are going to do two simple laps to cover those I do have a
lot of small exercises you can play with I encourage you to play with it to be a lot more comfortable so the first one is
Linear Regression
a linear regression so I'm sure it has been covered yeah in today's lectures
somebody must have covered linear regression can you can anybody give me a
one-line summary what is the linear regression problem anybody the
professors well if you don't know go
google it so I didn't know the the audience you know when when semi asked
Mystery Creation
me to do this so I wanted to I wrote this for one of the high schools so I
think it's doom kind of makes sense right because all of us have done have played this game at one point of our
lives like I you know if you if you tell me a five or tell you ten and you try to
guess you know about the equation is we must have all done this I think my friends are still doing on Facebook
saying oh you know only Genius can solve this kind of equation and then they would be like yeah you I solved it I was
like my god if anybody you know I one friend you guys if you click on another one of those sir
but basically this is what we are trying to do in the first lab so we will have a
mystery creation it's really simple it's just a linear you know literally a line and then we I will tell you that this is
you know the formula but I'm not going to give you a weight W and B you know
all of you have learned by now W stands for weight and bias B stands for bias so the idea is that if you are given
enough samples if you're given enough x and y values you should be able to make
a pretty good guess what W and B is so that's what we are going to do so now
Jupiter Notebook
you can bring up your Jupiter notebook if you don't have it up already
yeah everybody have it up yes can I see show them hands everybody
those are yeah brilliant alright so um for pretty much any models
these are going to come up over and over again and just to make sure that you're all paying attention I do have I asked
them if I was supposed to bring Shrek and he said no but I do have a lot of tensorflow stickers and I have all kinds
of little toys so later I'm going to ask this question whoever can answer will
get some mystery present so really pay attention okay so pretty much with it
whenever you build any model there are I would say four things that you need you need input you need data so you're going
to see in both labs we're going to be defining some data you're going to be built building an inference graph I
think in other lectures is also called a forward graph to the point that it produces logits or the logistic outputs
and then you're going to have a training training operations which is where you
would define a loss an optimizer and I
think that's pretty much it hanging and there's the fourth thing yeah and then
you will basically run the graph so the three important things okay you'll always have your data your inference
graph you always have to define your laws and your optimizer and the training is
basically to minimize your loss so I'm going to be asking that later all right so now we know what we're going to do so
you can go start go to that lab yeah everybody have it so shift returned
we'll run the first one you said I have no idea what happening here return again still
nothing however let's see what we are producing here so you can also do the
same on your laptop you can uncomment that plot you can say so you know what
kind of data you're generating so in this case when he returned why are we seeing this is your input data this is
when you try to make a guess when your friend tell me oh you don't give me your x and y so this is how you know when
your X is 0.2 you know your Y is 0.32 so this is basically your input data
yeah everybody following if at any point you're kind of lost raise your hand and
your buddy next you will be able to help you so now
it's all okay I want to say one more thing so today the laughs are all on really core tends to flow ap is the
reason I want to do that I know there are a lot of people who will use carrots use another thing that we have heavily
advertised which is contribute contribute you've learned so I feel like I'm giving you all the ingredients so
even though you could go to Whole Foods and buy the packaged meal you know maybe
one day you don't like the way they cook it so I'm giving you all your lobsters your Kobe beef okay so that you can
actually assemble whatever you want to build to yourself so this next one is
very key it's a very key concept here you see variables so variable intensive
flow is how is corresponding to the square any of you remember this slide
okay I'm going to switch quickly don't freak out so actually I wanted you all
to commit this little graph to to your memory because you'll be seeing this
over and over again and it makes a lot more sense when you have this visual representation so intensive flow the way
we hold all the data the ways and the biases associated associated with your
network is using something called variable it's a state fold operation I'm going to switch back
okay so this is what we are doing in Section 1.3 we are building those square
Variable Objects
nodes in your network to hold these ways and variables and they are the ones when you train that's where their gradients
will be applied to so that they will eventually resemble the target network
that you are trying to to train for so now you have built it wonderful okay so
you can shift return do you see anything nope so exactly we'll have rebuilt let's
uncomment and take a look so these are called the variable objects so at the
bottom of the slide for this lab I have a link which is our Google 3 dogs the
API Docs which is available in github I think you should always have that up so
whenever you want to do something you will know what kind of operations are possible with this object for example I
can say here what's the name of this oh it's called variable 6y so call
variable 6 oh it's because when I create this variable I didn't give it a name so
I can say Sherri's sure you wait I hope that's not
but so see now my variable is called Sheree wait same thing with my so this
would be a good practice because late later
cheery-bye is
well because I ran this so many times every single time you run if you don't restart that it's going to continue to
grow your current path so to avoid that confusion let me restart it restart
ja I had the word sorry
so now so we have done built our input build an inference graph now we can
Training Graph
actually build our training graph and as you have all learned we need to define a
loss function we need to define an optimizer I think it's also called
something else record regulator maybe some other terms and your ultimate goal
is to minimize your loss so I'm not going to do it here but you can do it at your your leisure you can you know
income and all the these things that you have created and see what they are and I
can tell you these are different operations so that's how you actually get to learn about the network that you
have built really well in the next line I'm also not going to uncomment but you should at one point this is how you
cannot you can see what you have built so actually why don't do that because this is really critical and as you debug
this will become so this is the network
that you have built they have names different names they have inputs and outputs they have attributes and this is
how we connect all these nodes together this is your neural net so what you have
what you're seeing right now is your neural net that you have just built yeah everybody following so now the next step
now you're done right you build your network you build all your training now you can let's do some training so in
tensor flow do you remember in the architecture that I showed you have the front-end C++ and Python front-end you
use that to build your graphs and then you send a graph to your runtime and this is exactly what we're doing here
whenever you this is how we talk to the runtime we create something called session you get a handle to the session
and then when you say run you're basically sending this session your graph so this is different from the
other machine learning libraries I forgot which one those are so comparative your happens as you type
tensor flow is different you have to construct your graph and then you'll create session to talk to your runtime
so that it knows how to run on your different devices that's a very important concept
because people constantly compare and it's just different okay so now you can
also commented to see what the initial values are but we're not going to do that we're just going to run it and now
we're going to train the data is not so
what do you think of the data did we succeed in guessing is everybody
following what we're trying to do yeah yes no so what was our job objective
before I started the lab what did I say my objective was yes to guess the
Results
mystery function so have we succeeded it's really hard to tell all right so
now all of you can go to the end and income in this part let's see how
successful we are
so the Greenline was what we have initialized our weight and buyers - yeah
the blue dots were the initial value of the target values and the red dots is
our trained value makes sense so how successful are we great big success yeah
I would say so so any questions any questions so far so
other things so everybody should play with this you're not going to break it this is a notebook Python notebook the
worst that happens is they're just they okay clear all like what I just did and change it so what can you play with
since today you learn all these concepts about different loss motions different optimizers all this crazy different
inputs different data so now you can play with that how about instead of let's pick one so instead of gradient
Other optimizers
descent what are the other optimizers how can you find out I guess that's a
better question if I want to know what other optimizers are available in tensor flow how can I find out very good yes
the github good Google 3 the G 3 doc link with the AP is I'm going to switch
one more tab bear with me so this is when you go there this is what you can
find you can find all that I mean make it bigger so you can find all the
different optimizers so you can play with that so maybe gradient descent is not the
best optimizer you can use so you go there and say why the other optimizers and then you can learn a come here in
search optimizer oh you can say wow you know I have added Delta a dag red Adam
I'm sure there are more a momentum so we also welcome contribution if you don't
like any of these please do you know go contribute write a new optimizer send a
pull request we would love to have it so I would like to say this over and over again we love contribution is an open-source project
so keep that in mind we would love to see your code or your models on github so back to this one how is everybody
feeling this is too simple yeah should we go wet just yes can I say that
oh is that right
Learn something new
he tapped to see all the other optimizers human Oh brilliant
see I didn't even know that learn something new every day let me go there tap here oh yay so this is even easier
thank you clearly I don't program in notebook as often as I should have
so this is where you can all the wonderful things that you can do thank you this is probably a little too low
level I think it has everything but that's a very good tip thank you so
anything else you would like to see what linear regression is too simple you guys all want to register commend some digits
alright so that sounds like a consensus to me so let's move if you just go to
the bottom you can say click on this one
What is M
so this is our M this model so before you start the lab so once again more
return to do so we have all these handwritten digits what does M this
stand for does anybody know what is M does stand for
very good see somebody can Google very good so it has a stencil I think makes
National Institute of Standards and Technology something like that so they
have this giant collection of digits so you know if you go to the post office
you already know that it's the trivial to solve problem but I don't know if they actually use machine learning but
our goal today is to build little never using tensorflow that can recognize these digits once
again we will not have all the answers right so all we know is that the network
the input will give us a 1 and it will say it's a 9 and then the IMP and then
we have the so-called ground truth and then they will look at and say no you're wrong and then we have to say ok fine
this is a difference we are going to train the network that way so that's our goal yeah everybody see the network on
the side so now we can go to the lab so
What is important when building a network
can anybody tell me why the three or four things that's really important whenever you build a network what's the
first one your data second one inference
graph third one your train graph and with this slab I'm going to teach you a
little bit more they are like the rock you know it like when you go to restaurant I not only give you your
lobstery or your Kobe beef I'm also going to give you a little rock so you can cook it ok so in this lab I've also
teach some absolute absolutely critical additional infrastructure pieces such as
how to save a checkpoint how to load from a checkpoint and how do you evaluate your network I think somebody
at one point asked how do you know the network is enough you evaluated to see if it's good enough so those are the
three new pieces of information that I'll be teaching you and also I'll teach
you a really really useful concept is called place holder that was requested
by all the researchers we didn't used to have it but they they all came to us and say when I trained I want to be able to feed my
network any day that we want so that's a really key concept that's really useful for any practical training whenever you
start writing real training code I think you that will come in handy so those are the I think four concepts now that I
will introduce in this lab that's slightly different from the previous on how to save checkpoint how to go from
checkpoint how to run evaluation and how to use placeholders I think the placeholder is actually going to be the
first one so once again we have our typical boilerplate stuff so that you hit return you import a bunch of
libraries the second one this is just for convenience I define a set of
constants some of them you can play with such as the maximum number of steps
where you're going to save all your data how big the batch sizes are but some
other things that you cannot change because of the data that I am providing you for example the amnesties any
questions so far so now we'll read some data it's
everybody there in 2.3 I'm a 2.3 right now so now I use if you don't have slash
temp it might be an issue but hopefully you do if you don't have slash lim
change the directory directory name so
the next one is where we build inference so can anybody is just glancing and tell me what we're building what kind of
network how many layers am i building
I have two hidden layers you have all learned hidden layers here today and I
also have a linear layer which will produce logits that's correct so that's
what all the inference graphs will always do they always construct and they
produce logistic outputs so once again here you can uncomment it and see it what kind of graph you have built once
you have done the whole tutorial by yourself you can actually run tensor
board and you can actually load this graph that you have saved and you can visualize it like what I have shown in
the slide I didn't draw the slide by hand it's actually produced by tensor
boards so you can see the connection of all your notes so I feel that that visual representation is really
important also it's very easy for you to validate that you have indeed build a graph that you thought sometimes people
call something repeatedly and they have generated this check and they grab they're like oh that wasn't what I meant
so being able to visualize it's really important any questions so far see here
I have good habits I actually gave all my variables names once again the hidden layer one hidden layer two they all have
weights and biases weights and biases etc so now we're going to build our
train graphs so here is actually here
Train graphs
there's no new concept once again you define a loss function we once again pick gradient descent as our optimizer
we added a global step variable that's what we will use later when we save our
checkpoints so you actually know at which point what checkpoint this
corresponds to otherwise if you'll always save it to the same name then later you know you said wow this this
result is so wonderful but how long did it take you have no idea so that's a
training concept that we introduced it's called global step basically how long you have trained and we usually save
that with a chair point so you know which chair point has the best information yeah everybody is good
at 2.5 so now the next one is the additional stuff that I just mentioned oh that piece of rock that I'm giving
Placeholders
you now to cook yourself so one is the place holder so we are going to define
two one two hold your image and the other two hold your labels there we
build it this way so that we only need to build a graph once and we will be able to use it for both training
inference and evaluation later it's very handy you don't have to do it this way
and one of the exercises I put in my slides to try to do it differently but this is a very handy way and get you
very far with minimum work so as I said in the slides I know I don't have any
highlighters beam's but you see there it says after you create your placeholders
I said add to collection and remember this up and later we'll see how we're
going to recall this up and how we're going to use it in the next one we're
going to call inference build our inference is everybody following this
part okay and once again we remember our logits and then we create our train up
and our los up just like with linear regression just like with the linear
regression we're going to initialize all variables and now at the bottom of this
Saver
cell that's the second new concept that I'm introducing which is the saver this
is what you will use to do checkpoints to save the states of your network so that later you can evaluate it or if
your training was interrupted you can know from a previous checkpoint and continue training from there rather than
always we initialize all your variables and start from scratch when your training really big networks such as
Inception is absolutely critical because when I I think when I first trained
inception it took probably six days and then later when we have 50 replicas it
took still like stay of the Rs do two and a half days you don't want to have to start from scratch every single time so yeah
everybody got that the placeholder and the saver so now it's 2.7 we're going to
Reduce Loss
go to 2.7 hmm lots of code can anybody
tell me what it's trying to do so this
is an yes so it's trying to minimize loss we can actually see this so I will
run it once okay where did I go okay
very fast it's done but what if I really
want to see what it's doing so python is wonderful so I would like to actually
see did somebody show like how you know your training is going wow they show the
loss going down going down low I think my training is going really well so we're going to do something similar
sorry so I'm going to create a variable audio car losses which is just an array
so here I'm actually going to remember
it
pinned so am i collecting
man plot map la lip anybody remember
this is a plot let's try this whoa look
at that now do you see you're lost going down so it's you train your loss
actually goes down so this is how when you do large-scale training this is what
we typically do we have a gazillion of this jobs running in the morning with just glanced at it and we know which one
is doing really really well so of course you know that that's just when you are up for the typing that's a really really
handy tool but I'm going to show you something even better oh that's part of the exercise me and I
don't have it so it's one of the exercise I also put the answers in the
backup slides that you guys are welcome to cut and paste into a cell they can
actually run all all the evaluation sets against your checkpoint so that you know
how well you're performing so you don't have to rely on your eyes you know cleansing or my loss is going down or
relying on validating a single image but see this is how easy it is this is how
easy the prototype and you can learn it very often our researchers would cut and
paste their collab code and put in a file and and that's basically their
algorithm and they will publish that with their paper they would send it to
our data scientists or production people we would actually privatize some of their research this this is how easy
literally from research to prototyping to production really streamlined and you can do it in no time so for those of you
LS
who have run the step can you do an LS in your data path wherever you'll save
to that wherever you declare your trainer to be what do you see in there
checkpoints that's right that's the that's the money that's after all this
work well the Oldham one during all this training on all these gazillion machines that's where all your ways your biases
are stored so that later you can you know load this network up and do your
inception to recognize images to reply to email to do art etc etc so that's
really critical but how do we use it have no fear all right let's move on to
Checkpoint
2.8 if you are not already there so can somebody tell me what we're trying to do
first that's right first we load the
checkpoint and you remember all the things that we told them told our program to remember the logits
and the image placeholder in the label placeholder how are we going to use it now we're going to feed in some images
from our evaluation and see what it thinks so now if you hit return
Return
what's the ground truth 5 what's our prediction 3 what's the
actual image could be 3 could be 5 you
know but so the machine is getting pretty close why I would I would say that's a 3 ok let's try a different
different one so you can hear return again in the same cell ohai need to
somehow move this so what's the ground truth this time yeah I got it right so you can keep
hitting you know you can keep hitting return and see you know how well it's doing but instead of validating you know
instead of hitting return a hundred times and count how many times I had gotten it wrong as I said in one of the
exercises and I also put the answer in the slide so you can cut and paste and
actually do a complete validation on the whole validation set but what do you
think I really so you can actually hand write a different digit but the trick is that
a lot of people actually try there and told me it doesn't seem to work so remember in on the slide I said this is
what the machine sees this is where I see s and this is more the machine sees so in the end instead of set all the
numbers are between 0 and 1 I believe I could be wrong but I believe it's between 0 & 1 so if you just use a
random tool like your phone you write the number and you upload it number one the picture might be too big and need to
scale it down number two it might have a different representation sometimes it's
from 0 to 255 and you need to scale it you know to the range that M this that
how you have trained your network if you train your network with those data and then it should be able to recognize the
same set of data just like when we teach a baby right if if you have never been exposed to something you're not going to
be able to recognize it just like with oriole one of our colleagues caption was at that program a
while ago anytime when I see something that it doesn't recognize have anybody play with that captioning software is
super fun so you can take a picture and say you know two people eating pizza or
you know dog surfing but any time it sees something that has never been
trained on it would say men talking on the cell phone so for a while we had a
lot of fun with it we would put a watermelon on the post and they would say men talking on the cell phone you put a bunch of furniture in the room you
know with nothing and it was they men talking on the cell phone so it was really fun but just like with your
numbers if you have never trained it with that style like if I write Chinese
characters here it's never going to recognize it but this is pretty fun so you can play with it you know you can
Exercises
see how well see every time see so far is 100 percent other than the first one which I cannot tell either so what are
some of the exercises that we can do here what do you want to do with this lab it's too easy huh because I made it
so easy because know that you guys are all experts but now otherwise I would have done it much harder now let me see what things we can
do so you can uncomment all the graphs
oh so here's one actually you already see it so try this can you guys try
saving the checkpoints say every 100 steps and you're going to have a
gazillion but they're tiny tiny checkpoints so it's okay and try to run evaluation with a different checkpoint
and see what you get do you know how to do that yeah everybody not to do that so the idea is
that when you run the evaluation is in the it's very similar so we typically
run training in the evaluation in parallel or validation so us it trains
Training Evaluations
every so often say every half an hour depending on the the depending on your
problem so with inception every ten minutes we're also the run evaluation to see how well our model is doing so if
our model gets to say 78.6% which I believe is the state of the art we'll be like ooh my mother's done training so
that's how that's why you want to save checkpoints often and then you know validate them often if you're done with
that already did you notice anything if you try to load from a really already checkpoint how is your how good is it
when it tries to identify the the digits just take a wild guess
yeah very bad maybe whenever you every other one is wrong but this M this is
such a small data set is very easy to train and we have such a you know deep network if you only have one layer or
maybe it won't get it right so another
exercise I think all these you can you can do after the lecture after this session is that really try to learn too
evaluation from scratch rather than actually another part but run evaluation
on the complete validation set that's a that's a really necessary skill to
develop as you build bigger models and need to run validation so I think this
is the end of my my lab I do have bonus laughs but I want to cover this first
the bottom line is that tensorflow is really it's for machine learning is really from research to prototyping to
TensorFlow is for Machine Learning
production it's really designed for that and I really hope everybody in the audience can give it a try and if there
are any features that you find it lacking that you would like to see implemented either send us pour requests
Questions
we always welcome contribution I'll talk to my wonderful product manager Zack sitting over there he is taking requests
for features so with that yeah things
that have fun
Thank You Shari did we have time for questions for those who actually tried
it see you so well done and everybody feel like their experts are all ready to
go make arts now right right goes deep dream cool if there are no questions I
hope there's one question I think someone who's trying desperately hi my
Peachy
name is peachy low and first of all thank you for the for introducing tensorflow and for designing it I have
two questions so the first questions is I know the tensorflow have C++ API right so let's
say if I use Kira's or any of the Python front-end I train a model can I have
that sense of loss support adjust I can pull out the C++ model of it and then
just use that yes you can so even if I use for example Kira's custom layer that
I caught using Python I still can get those things correct oh it's just a front-end that's different how you
construct the graph nice but we are not as complete on our C++ API designs for
example a lot of the training libraries are not complete yes so but for the
simple models yes you can do well let's say not the training but let's say if I just want the testing part because I
don't need to do I mean the training I was doing is we do have that already Oh actually if you go to our website
there's a label images does CC I think that's literally just loading from SharePoint and run the inference in C
then that's all written in C++ so that's a good example to follow Oh a second one so another thing that I
noticed that you support almost everything except windows everything acceptable I mean I always Android have
no fear actually we are actively doing that but when I first joined the team I
think there were 10 of us and we have to do everything like before open sourcing all of us were in the in the
in the conference from together we're all riding dog we're fixing everything so now we have more people that's like
the top of our list we would love to support it so so I'm just curious because I I mean when I look at the road
man I didn't see a clear timeline for Windows but the thing I know they just
like the reason why you cannot support Windows is because of basil basil doesn't support Windows so let's say
theoretically well I mean what you think just like I know basil they're just that you will get window Phi at some someone
November that is why they say so once Plato can run in Windows can I expect
wedges I could immediately do tens of law do you foresee some other problem maybe Zac would like to take that
question okay this so yeah let's talk
offline yeah sure thank you very much sorry I great presentation yeah my name
is Yuri fish I have a question about GPUs are they available right now for testing and playing for non Google
employees are we I don't think so at the
moment and do you know when it might be available in the Google well would you like to take that one
I'm so glad we have a Prada boss here so he can okay thank you nice to Tori I
Tori
have a question are there any like plans to integrate tensorflow
with the like open-source framework like my sauce and HDFS to make the distribute
tensorflow easy so there are definitely plans we are also always actively
working on new features but we cannot provide a solid timeline right now so
that we do have like like is you know we do have plans we do have projects in
progress but we cannot commit on a timeline so I cannot give you a time
saying yes by November you have so thank you but if you have this type
of question I think Zac is the best person to answer today oh hi I was
Load your own data
wondering um the sensor flow having examples to load your own data of what witch did um so the current example has
a m nest of data set are there examples out there to load your own data set yes yes definitely I think we have two ones
called the tencel flow poet I think that one that example shows you how you can
know your own data set I think is there
another one Zack are you aware of another one that might be a loading your own data set I know we have retraining
model you know if you go to tensorflow we have an example to do retraining those you can download from anywhere so
in our example we just downloaded a bunch of flowers so you can definitely download whatever pictures that you want
to return thank you hello thank you for
your presentation I have a question concerning the the training you can't you can train using throw tensorflow
in any virtually any system like Android and what about the model is do you
provide anything to move the model to Android is there because I'm generally
you programming Java there and yes so that's a beautiful thing you remember the architecture that I showed yes you
build a model and they just send it to the runtime it's the same model running on any of the different platforms it can
be a laptop and Roy you have your own specific format for the model or it's
Justin you build a model is just bunch of matrix and matrix and values yeah is
there any special special format for your model because I sometimes it will
it is big yes comparable I will not recommend training the inception on your phone because all the convolution is a
bad problem probably kill it ten times over so definitely
so there will be that type of limitation like I think you guys talked about the number of parameters if it blows the
memory footprint on your phone it's just not going to work and if the compute like it special for convolution it uses
of other computers yes that's for straining but what inference you can run it anywhere okay thank you it's the same
model you just restore actually are examples like label image that's our C++
version I think I also wrote one's called classify images in Python that's all so you can run it on your phone so
any of these you can write your own and though the sharepoint and run it on your phone as well so definitely I encourage
you to do that thank you hi I have a question related to tens of
Writing TensorFlow in Python
flow solving so I went through the the online documentation and currently I
think it requires some coding in C++ and then combined with Python is there only
going to be you know only Python solution that's going to be provided or is it always going to be you know I
think you need to do some first step you need to create a module and then you know it just imported into water I am
actually surprised to hear that because I'm pretty sure that you can write the model in just Python or just C++ you
don't have to write it in one way or the other they might have a special exporter tool at one point that was the case they
wrote their exporter in C++ I think that's well probably what you were talking about but you don't have to
build it in any specific way the model is just you can write in whatever
language you like as long as it produces that graph and that's all it needs so so
tender for serving the tutorial actually if you go on the side it had yeah a
little steps actually okay so I will look into that so maybe you can come find me later and now I'll see what the
situations I do know that at one point they were writing the exporter in C++ only but that should have changed by now
because we are doing another version of the serving tensorflow serving and is
there any plan to you know provide API is for other languages like you know
like MX night has something called MX like J's and you know you mean that the front-end front-end yeah yeah we have Co
I think we have Co we have some other languages maybe as I can speak more to it and once again if those languages on
our favorite please do contribute and if you would like us to do it talk to Zach
and maybe he can put out you know maybe I don't know because there's somebody else for the Android you need Java for
nicely so I think that's going to help out in integrating these models with us yeah that's great great feedback will
definitely take note thank you thank you I have a caution I'm having embedded GP
board TX 1 which is an ARM processor and I really wanted to work with the tensorflow but I got to know that it can
only run on x86 boards so when can we expect the tensorflow can support ARM
processors we will have to get back to you after I have consulted with my Prada
boss say when we can add that support thank you sorry one last question thanks
for the presentation sherry I have a question regarding D when you have the model you want to run variants is it
possible to make an executable out of it so we can drop it into a container or
run it separately from serving is that that's something that you guys are looking into just run the inference yeah
just have it as the time as a binary yeah yeah you can definitely do that right now you can yeah you can all use
you are always able to do that you mean just save you man just save the you
won't what I mean is that if you can package it into a single binary source
that you can just pass around yes yes we actually do that today that's how the label image works it's just it's only
individual binary okay they actually converted all the chair points into constants so it doesn't even
need to do this lo etc it just reads a bunch of constants and runs it so it's super fast
yep okay that's a thanks sherry again
we are going to take a short break of ten minutes let me remind you for those who haven't noticed yet but all the
slides of all the talks will be available on the website so do not worry they will be available at some point as
soon as we get them from the speakers oh I forgot to ask my bonus question but in any case I have a lot of tensorflow
stickers up here if you like one to put proudly display your laptop come get it

----------

-----

--04--

-----
Date: 2016.09.27
Link: [Foundations of Deep Learning (Hugo Larochelle, Twitter)](https://www.youtube.com/watch?v=zij_FTbJHsk)
Transcription:

The talks at the Deep Learning School on September 24/25, 2016 were amazing. I clipped out individual talks from the full live streams and provided links to each below in case that's useful for people who want to watch specific talks several times (like I do). Please check out the official website ([http://www.bayareadlschool.org](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbks4OTJuUFNUSkNVeFZEQWRhdkM0cmNNSkN0UXxBQ3Jtc0ttNEY4RVk3QlhKMmJfZk4tRzJ2M25CUlRiaDY2a3hxMHJkMXhtRV84T1U0eUlxN09jczdUZVdzd3k1ZHlkSjd2dGhscnJuazZNMXBYcGplNWJYNmRMOFNuNi1jWmt1VXpFbGhxZzM3eUk3VDZWUmhyRQ&q=http%3A%2F%2Fwww.bayareadlschool.org%2F&v=zij_FTbJHsk)) and full live streams below. Having read, watched, and presented deep learning material over the past few years, I have to say that this is one of the best collection of introductory deep learning talks I've yet encountered. Here are links to the individual talks and the full live streams for the two days:
Intro

that's good all right cool so yes I was asked to give this presentation on the

foundations of deep learning which is mostly going over basic feed-forward neural networks and motivating a little

bit deep learning and some of the more recent developments and and some of the topics that you'll see across the next

two days so I as Andrew mentioned I have

just an hour so I'm gonna go fairly quickly on a lot of these things which I think will mostly be fine if you're

familiar enough with some machine learning and a little bit about neural nets but if you'd like to go into some

of the more specific details you can go check out my online lectures on YouTube it's now taught by a much younger

version of myself and so just search for you go to a shell and I am NOT the guy

doing a bunch of skateboarding and the geek teaching about neural nets so go

check those out if you want more details but so well I'll cover today is I'll

start with just describing and laying out the notation on feverel neural

FOUNDATIONS OF DEEP LEARNING

networks that is models that take an input vector X that might be an image or some text and produces an output f of X

so I'll just describe for propagation and the different types of units and the type of functions we can represent with

those and then I'll talk about how we actually train neural nets describing things like loss functions back

propagation that allows us to get a gradient for training with stochastic gradient descent and mention a few

tricks of the trade so some of the things we do in practice to successfully Train neural nets and then I'll end by

talking about some developments that are specifically useful in the context of

deep learning that is neural networks with several hidden layers that came out you know at the very after the beginning

of deep learning say in 2006 that is things like drop out batch normalization and if I have some time unsupervised

pre-training so let's get started and just talk about assuming we have some

neural network how do they actually functions how do they make predictions so let me lay down the notation so a

multi-layer neural feed-forward neural network is a model that takes as input

some vector X which I'm representing here with a different note for each of the dimensions in my input vector so each

dimension is essentially a unit in that neural network and then it eventually produces at its output layer a an output

and we'll focus on classification mostly so you have multiple units here and each

unit would correspond to one of the potential classes in which we would want to classify our input so if we're

identifying digits in handwritten character images and so we're focusing

on digits you'd have ten digits or you would have sort of zero from zero to nine so you'd have ten output units and

to produce an output the neural net will go through a series of hidden layers and

those will be essentially the components that introduce non-linearity that allows us to capture and perform very

sophisticated types of classification functions so if we have L hidden layers

the way we compute all the layers in our neural net is as follows we first start

by computing what I'm going to call a pre activation I'm going to note that a and imma go I'm going to index the

layers by K so a K is just the pre activation at layer K and that is only

simply going to be a linear transformation of the previous layer so

I'm going to note HK as the activation and the layer and by default I'll assume

that layer zero is going to be the input and so using that notation the pre

activation at layer K is going to correspond to taking the activation at the previous layer K minus one

multiplying it by a matrix WK those are the parameters of the layer those

essentially corresponds to the connections between the units between adjacent layers and I'm going to add a

bias vector that's another parameter in my layer so that gives me the pre activation and then next I'm going to

get a hidden layer activation by applying an activation function this will introduce some non-linearity in the

model so I'm going to call that function G and we'll go over a few choices we

have four common choices for the activation function and so I do this from

layer 1 to layer L and when it comes to the output layer I'll also compute a pre

activation by performing a linear transformation but then I'll usually apply a different activation function

depending on the problem I'm trying to solve so having said that let's go to

some of the choices for the activation function so some of the activation functions you'll see one common one is

this sigmoid activation function it's this function here it's just 1 divided by 1 plus the exponential of minus the

pre activation the shape of this function you can focus on that is this here it takes the pre activation which

can vary from minus infinity to plus infinite and it squashes this between 0 & 1 so it's bounded by below and above

below by 0 and above by 1 okay so it's a it's a function that saturates if you

have very large or very large magnitude positive or negative pre activations

another common choice is the hyperbolic tangent or tange activation function on

this picture here so squash is everything but instead of being between 0 & 1 s between minus 1 and 1 and 1

that's become quite popular in neural nets is what's known as the rectified

linear activation function or in papers you will see the relative unit that

refers to the use of this activation function so this one is different from

the others in that it's not bounded above but it is bounded below and it's actually it will output zeros exactly if

the pre activation is negative so those are the choices of activation functions

for the hidden layers and for the output layer if we're performing classification as I said in the our output layer we

will have as many units as there are classes in which an input could belong and what we'd like is potentially and

what we often do is interpret each units activation as the probability according

to the neural network that the input belongs to the corresponding class that it's labeled Y is the corresponding

class C so C would be like the index of that you in the output layer so we need an

activation function that produces probabilities produces a multinomial distribution over all the different

classes and the activation function we use for that is known as the softmax activation function it is simply as

follows you take your pre activations and you exponentiate them so that's going to give us positive numbers and

then we divide each of the exponentiated pre activations by the sum of all the PD

exponentiated pre activations so because I'm normalizing this way it means that all my values in my output layer are

going to sum to 1 and they're positive because I took the exponential so I can interpret that as a multinomial

distribution over the choice of all the SI different classes ok so that's what I'll use as the activation function at

the output layer and and now beyond the math in terms of conceptually and also

in the way we're going to program neural networks often we will do is that all these different operations the linear

transformations the different types of activation functions will essentially implement all of them as an object and

object that take arguments and the arguments would essentially be what other things are being combined to

produce the next value so for instance we would have an object that might correspond to the computation of pre

activation which would take as argument what is the weight matrix and the bias vector for that layer and take some

layer to transform and that would this object we sort of compute its value by applying the linear activation the

linear transformation and then we might have objects that correspond the specific you know activation functions

or like a sigmoid object or a 10 shop jacked or raloo object and we just combine these objects together chain

them into what ends up being a graph which I refer to as a flow graph that represents the computation done when you

do a forward pass in your neural network up until you reach the output layer so I mentioned it now because that's you'll

see you know the different software's that we presented over a weekend will essentially sort of you know exploit

some of that representation of the computation and neural nets it also be handy for computing gradients which I'll

talk about in a few minutes and so that's how we

perform predictions in neural network so we get an input we eventually reach an

output layer that gives us a distribution over classes if we're performing classification if I want to actually classify I would just assign

the class corresponding to the unit that has the highest activation that would correspond to classifying into the class

that has the highest probability according to the neural net and but then

you might ask the question okay what kind of problems can we solve with neural networks or more technically what

kind of functions can we represent mapping from some input X into some arbitrary output and so if you look at

if you go look at my videos I try to give more intuition as to why we have this result here but essentially if we

have a single hidden layer a neural network it's been shown that with a linear output we can approximate any continuous function arbitrarily well as

CAPACITY OF NEURAL NETWORK

long as we have enough hidden units so that is there's a value for these biases and these weights such that any

continuous function I can actually represent it as well as I want I just need to add enough hidden units so this

result applies if you use activation functions nonlinear activation functions like sigmoid and tan H so as I said in

my videos if you want a bit more intuition as to why that would be you can go check that out but that's a

really nice result it means that by focusing on this family of machine learning models that our neural networks

I can pretty much potentially represent any kind of classification function however this result does not tell us how

do we actually find the weights and the bias values such that I can represent a given function it doesn't essentially

tell us how do we train a neural network and so that's what we'll discuss next

let's talk about that how do we actually from a data set train a neural network

to perform good classification on for that problem so what we'll typically do

is use a framework that's very generic in machine learning known as empirical risk minimization or structural risk

MACHINE LEARNING

minimization if you're using regularization so this framework essentially transformed

a problem of learning as a problem of optimizing so what we'll do is that will

first choose a loss function that I'm noting as L and the last function it

compares the output of my model so the output layer of my neural network with the actual target

so I'm indexing with it exponent here with T to essentially ask the index over

all my different examples in my training set and so my loss function will tell me

is this output good or bad given that the label is actually Y and well I'll do

I'll also define a regularizer so theta here is you can think of it as it's just

the concatenation of all my biases and all of my weights in my neural net so those are all the parameters of my

neural network and the regularizer will essentially penalize certain values of

these weights so as I'll talk more specifically later on for instance you might want to have your way to not be

too far from zero that's a frequent intuition that we implement with regularizer and so the optimization problem that

we'll try to solve when learning is to minimize the average loss of my neural

network over my training example so summing over all training examples I have capital T examples plus some weight

here that's known as the weight DK some hyper parameter lambda times my regular Iser so in other words I'm going to try

to have my loss on my training set as small as possible over all the training

example and also try to satisfy my regularizer as much as possible and so now we have this optimization

problem and we learning will just correspond to trying to solve this problem so performing this finding this

argument here for over my weights and my biases and if I want to do this I can

just invoke some optimization procedure from the optimization community and the

one algorithm that you'll see constantly in deep learning is stochastic gradient descent this is the optimization

algorithm that will often use for training neural networks so SGD

stochastic gradient descent functions as follows you first initialize all of your parameters that

is finding initial values for my weight matrices and all of my bio C's and then

for a certain number of epochs so an epoch will be a full pass over all my examples that's what I'll call an epoch

so for a certain number of full iterations over my training set

I'll draw each training example so I pair X input X target Y and then I'll

compute what is the gradient of my loss with respect to my parameters all of my

parameters all my weights and all my biases this is what this notation here so nabla for the gradient of the loss

function and here I'm indexing with respect to which parameter I want the gradient so I'm going to compute what is

the gradient of my last function with respect to my parameters and plus lambda

times the gradient of my regularizer as well and then I'm going to get a direction in which I should move my

parameters since the greyman tells me how to increase the loss I want to go in

the opposite direction and decrease it so my direction will be the opposite so that's why I have a minus here and so

this Delta is going to be the direction in which I'll move my parameters by taking a step and the step is just a

step size alpha which is often referred to as a learning rate times my direction

which I just add to my current values of my parameters my biases and my weights

and that's going to give me my new value for all of my parameters and I iterate like that over going over all pairs x

wise computing my gradient taking a steps out in the opposite direction and then doing that several times okay so

that's how stochastic gradient descent works and that's essentially the learning procedure it's represented by

this this procedure so in this algorithm there are few things we need to specify to be able to implement it and execute

it we need a loss function the choice for the loss function we need a procedure that's efficient for computing the

gradient of the loss with respect to my parameters we need to choose a regularizer if you want one and we need

a way of initializing my parameters so next what I'll do is go through each of these these four

different things we need to choose before actually being able to execute the classic gradient descent so first

LOSS FUNCTION

the last function so as I said we will interpret the output layer as assigning probabilities to each potential class in

which I can classify my input X well in this case something that would be

natural is to try to maximize the probability of the correct class the actual class in which my example XT

belongs to I'd like to increase the value of the probability assigned by computed by my neural network and so

because we set up the problem in which we have a loss that we minimize instead

of maximizing the probability what we'll actually do is minimize the negative and the actual log probability so the log

likelihood of assigning X to the correct class Y so this is represented here so

given my output layer and the true label Y my loss will be minus the log of the

probability of Y for minor according to my neural net and that would be well take my output layer and look at the

unit so index the unit corresponding to the correct class so that's why I'm indexing by Y here we take the log

because numerically it turns out to be more stable we get nicer looking gradients and sometimes in certain

software's you'll see instead of talking about the negative log likelihood or log probability you'll see it referred as

the cross entropy and that's because you can think of this as performing a sum

over all possible classes and then for each class checking well is this potential class the target class so I

have an indicator function that is one if Y is equal to C so if my iterator

Class C is actually equal to the real class I'm going to multiply that by the

log of the probability actually assigned to that class C and this this function

here so this expression here is like a cross entropy between the empirical distribution which assigns 0 probability

to all the other classes but a probability of 1 to the correct class and the actual distribution over

that my neural net is computing which is f of X okay that's just a technical

detail you can just think about this here I only mention it because in certain libraries it's actually mentioned as the cross-entropy a loss so

that's for the loss then we need also a procedure for computing what is the gradient of my loss with respect to all

of my parameters in my neural net so the biases and the weights you can go look

at my videos if on the actual derivation of all the details for all of these different expressions I don't have time

for that so all I'll do and presumably a lot of you I actually seen you know these derivations if you haven't just go

check out the videos in any case I'm going to go through what the algorithm is I'm going to highlight some of the

key points that will come up later in understanding out actually back propagation functions so the basic idea

is that we'll compute gradients by exploiting the chain rule and we'll go from the top layer all the way to the

bottom computing gradients for layers that are closer and closer to the input as we go

and exploiting the chain rule to exploit or reuse previous computations we've made at upper layers to compute the

gradients at the layers of below so we usually start by computing what is the

gradient at the output layer so what's the gradient of my loss with respect to

BACKPROPAGATION

my output layer it actually it's more convenient to compute the loss with respect to the pre activation it's

actually a very simple expression so that that's why I have the gradient of this vector a L plus 1 that's the pre

activation at the very last layer of the loss function which is minus the log f of XY and it turns out this gradient is

super simple it's minus II of Y so that's the one Hut vector for class Y so

what this means is a of Y is just a vector filled with a bunch of zeros and then the one at the correct class so if

Y was the fourth class then in this case it would be this vector we have a one at the fourth dimension so e of Y is just a

vector it's we call it the one Hut vector full of zeros and the single one at the position corresponding to the

correct class so this part of the grain is essentially saying is that I'm going to increase I

want to increase the probability of the correct class I want to increase the pre activation which will increase the

probability of the correct class and I'm going to subtract what is the current probabilities assigned by my neural net

to all of the classes so f of X that's my output layer and that's the current beliefs of the neural net as to in which

class what's the probably of signing the input to each class so what this is

doing is essentially trying to decrease the probability of everything and specifically decrease it as much as I

the neural net currently believes that the input belongs to it and so if you

think about the subtraction of these two things well for the class that's the correct class I'm going to have one

minus some number between zero and one because it's a probability so that's going to be positive so I'm going to

increase the probability of the correct class and for everything else it's going to be zero minus a positive number so

it's going to be negative I'm actually going to decrease the probability of everything else so in two Li and it

makes sense this gradient has the right behavior and I'm going to take that pre activation gradient I'm going to

propagate it from the top to the bottom and and essentially iterating from the

last layer which is the output layer l plus 1 all the way down to the first layer and as I'm going down I'm going to

compute the gradient with respect to my parameters and then compute what's the gradient for the pre activation that the

layer below and then iterate like that so at each iteration of that loop I take

what is the current gradient of the loss function with respect to the pre

activation at the current layer and I can compute the gradient of the loss function with respect to my weight

matrix so not doing the derivation here it it's actually simply this vector so

my in my notation I assume that all the vectors are column vectors so this pre activation gradient vector and I

multiply it by the transpose of the activations so the value of the layer right below the layer K minus one so

because I take the transpose that's a multiplication like this you can see if I do the outer product essentially between these two vectors

I'm going to get a matrix of the same size as my weight matrix so it all checks out that makes sense it turns out that the

gradient of the loss with respect to the bias is exactly the gradient of the loss with respect to the pre activation so

that's very simple so that gives me now my gradients for my parameters and now I need to compute okay what is going to be

the gradient of the pre activations at the layer below well first I'm going to get the gradient

of the last function with respect to the activation at the layer below well

that's just taking my pre activation gradient vector and multiplying it by for some reason does it show here but

and multiplied by the transpose of my weight matrix super simple operation just a linear transformation of my

gradients at layer cake linear and transform to get my gradients of the activation at the layer K minus one and

then to get the gradients of the pre activation so before the activation function

I mean to I'm gonna take this gradient here which is the gradient of the activation function at the layer K minus

one and then I applied the gradient corresponding to the partial derivative of my nonlinear activation function so

this here this refers to an element-wise product so I'm taking these two vectors this vector here in this vector here I'm

going to do an element-wise product between the two and this vector here is just a partial derivative of the

activation function for each unit individually that I've put together into a vector okay this is what this

corresponds to now the key things to notice is first that this path computing

all the gradients and doing all these iterations is actually fairly cheap its complexity is essentially the same as

the one is doing a forward pass so all I'm doing are linear transformations

multiplying by matrices in this case the transpose of my weight matrix and then I'm also doing this sort of nonlinear

operation where I'm multiplying by the gradient of the activation function that's the first thing to notice and the

second thing to notice is that here I'm doing this element-wise product so if any of these terms here for a unit is

very close to zero then the pre activation gradient is going to be zero for the next layer and I highlight this

point because essentially whenever that's something to think about a lot when you're training neural nets

whenever this gradient here these partial derivatives come close to zero that it means the grain will not

propagate well to the next layer which means that you're not going to get a good gradient to update your parameters

now when does that happen when will you see these terms here being close to zero

ACTIVATION FUNCTION

well that's going to be when the partial derivatives of these nonlinear activation functions are close to zero

or zero so we can look at the partial derivative say of the sigmoid function it turns out it's super easy to compute

it's just the Sigma itself times 1 minus the sigmoid itself so that means that

whenever the activation of the unit for sigmoid unit is close to 1 or close to 0 I essentially get a partial there that's

close to zero you can kind of see it here the slope here is essentially flat and the slope here is flat that's the

value of the partial derivative so in other words if my pre activations are

very negative or very positive so if my unit is very saturated then gradients will have a hard time propagating to the

next layer that's the key inside here same thing for the tension so the turns

out the partial derivative is also easy to compute you just take the tangible you square it and going to subtract it

to 1 and yeah indeed if it's close to minus 1 or close to 1 you can see that

the slope is flat so again if the unit is saturating gradients will propagate I

have a hard time propagating to the next layer and for the relu the rectified

linear activation function the gradient is even simpler it's you just check

whether the pre activation is greater than 0 if it is the partial derivative is 1 if it's not at 0 so actually either

we're going to multiply by 1 or 0 you essentially get a binary mask when you're performing the propagation

through their value and you can see it the the slope here is flat and otherwise you have a linear function so actually

here at the shrinking of the grade and toward 0 is even harder it's exactly multiplying by

zero if your have a unit that's saturating below and beyond all the math

in terms of actually using those in practice during the weekend you'll see three different libraries that

essentially allows you to compute these gradients for you you actually usually don't write down backdrop you just use

all of these modules that you've implemented and it turns out there's a way of automatic automatic ly differentiating your loss function and

getting gradients for free in terms of effort in terms of programming effort with respect to your parameters so

conceptually the way you do this and you see essentially three different libraries doing it in slightly different

ways what you do is you up meant your flow graph by adding at the very end the

FLOW GRAPH

computation of your loss function and then each of these boxes which are conceptually objects that are taking

arguments and computing a value you're going to augment them to also have a method that's a backdrop or B prop

method you'll often see actually this expression being used be prop and what this method should do is that it should

take as input what is the gradient of the loss with respect to myself and then it should propagate to its arguments so

the things that its parents in the flow graph the things that takes to compute its own value it's going to propagate them using the chain rule what is their

gradients with respect to the loss so what this means is that you would sort

of start the process by initializing well the gradient of the loss with respect to itself is 1 and then you pass

the B prop method here 1 and then it's going to propagate to its argument what

is by using the chain rule what is the gradient of the loss with respect to f of X and then you're going to call B

prop on this object here and it's going to compute well add the gradient of the loss with respect to myself f of X from

this I can compute what's the gradient of my argument which is the pre activation at layer 2 which is back to

the loss so I'm going to reuse the computation I just got and update it using my what is essentially the

Jacobian and then I'm going to take the pre activation here which now knows what is the gradient of the loss with respect

to itself activation it's going to propagate to the weights and the biases and the layer

below update them with informing them of what is the grain into the last with respect to themselves and you continue

like this essentially going through the flow graph but in the opposite direction so the library torch the basic library

torch essentially functions like this quite explicitly it you construct you chain these elements together and then

when you're performing back propagation you're going in the reverse order of these chained elements and then you have

libraries like torch other grand piano and tens of which you learn about which are doing things slightly more

sophisticated there and you'll learn about that later on okay so that's the

REGULARIZATION

discussion of how you actually compute gradients of the last with respect to the parameters so that's another

component we need in stochastic grain in this end we can choose a regular Weiser one that's often used is the l2

regularization so that's just the sum of the squared of the all the weights and the gradient of that is just twice times

the weight so it's a super simple gradient to compute we usually don't regularize the biases

there's no particularly important reason for that it's just it there much for

your by see so it seems less important and often this l2 regularization is

often referred to as weight DK so if you hear about weight decayed that often refers to l2 regularization and then

INITIALIZATION

finally and this is also a very important point you have to initialize

the parameters before you actually start doing back prop and there are a few tricky cases you need to make sure that

you don't fall into so the biases often we initialize them to 0 there are

certain exceptions but for the most part we initialize them to 0 but for the weights there are a few things we can't

do so we can't initialize the weights to 0 and especially if you have 10 H activations the reason and I won't

explain it here but it's not a bad exercise to try to figure out why is that essentially when you do your first

pass you're going to get gradients for all your parameters that are going to be 0 so I'm going to be stuck at this 0

initialization so we can do that we can't initialize all the weights to

exactly the same value if again you think about it a little bit what's going

to happen is essentially that all the weights coming into a unit within the layer are going to have exactly the same

gradients which means they're going to be updated exactly the same way which means they're going to stay constant the

same that comes them but they're going to stay the same the whole time so it's as if you have multiple copies of the

same unit so you essentially have to break that initial symmetry that you would create if you initialize

everything to the same value so we end up doing most of the time is initialized the weights to some randomly generated

value often we generate them there are few other recipes but one of them is to initialize them from some uniform

distribution between lower and upper bound this is a recipe here that is

often used that has some theoretical grounding that's was derived specifically for the 10h there's this

pepper paper here by exactly Goho and yoshua bengio you can check out for some intuition as to oh you know how you

should initialize the weights but essentially this should be initially random and this should be initially close to zero random to break symmetry

and close to zero so that initially the units are not already saturated because

if the units are saturated then there are no gradients that are going to pass through the units you essentially going to get gradients very close to zero at

the lower layers so that's the main intuitions they have weights that are small and close to zero small and random

okay so those are the pieces we need for running stochastic gradient descent so

that allows us to take a training set and run the certain number of epochs and app the neural nets learn from that

training set now there are other quantities in our neural network that we haven't specified out to choose them so

those are the hyper parameters so usually we can have a separate validation set most people here are

familiar with machine learning so that's a typical procedure and then we need to select things like ok how many layers do

I want how many units per layer do I want what's the step size the learning rate of my stochastic gradient descent

procedure that alpha number what is the weight decay that I'm going to use so a

standard thing in machine learning is to perform a grid search that is if I have to our

MODEL SELECTION

parameters I list out a bunch of values I want to try so for the number of hidden units maybe I want to try a hundred a thousand and two thousand say

and then for the learning rate maybe I want to try 0.01 and 0.001 so a grid

search would just try all combinations of these three values for their hidden units and these two values for the

learning rates so that means that the more I providers there are it's the

number of configurations you have to try out blows up and grows exponentially so

another procedure that is now more more common which is more practical is to

perform a form of random search in this case what you do is for each parameter you actually determine a distribution of

likely values you'd like to try so it could be so for the number of hidden units maybe I do a uniform distribution

over all integers from a hundred to a thousand say or maybe a log uniform distribution and for the learning rate

may be again the log uniform distribution but from 0.001 to 0.01 say

and then to get an experiment to get values for my hyper parameters to do an

experiment with and get a performance of my validation set I just independently sample from these distributions for each

hyper parameter to get a full configuration for my experiment and then because I have this way of getting one

experiment I do it independently for all of my jobs all of my experiment that I will do so in this case if I know I have

like enough compute power to do 50 experiments I just sample 15 dependent

samples from these distributions for parameters perform these 50 experiments

and I just take the best one what's nice about it is that there are no unlike grid search there are never any holes in

the grid that is you just specify how many experiments you do if one of your jobs died well you just have one less

but there's no hole in your experiment and also one reason why it's particularly useful this approach is

that if you have a specific value in grid search for one of the hyper parameters that just makes the

experiment not work at all so learning rates are a lot like this if you have a learning rate that's too high it's quite

possible that convergence of the optimization will not converge well if you're using a grid search it means that

for all the experiments that use that specific value of the learning rate they're all going to be garbage they're all not going to be useful and you don't

really get this sort of big waste of computation if you do random search because most likely all the values of

your hyperparameters are going to be unique because their sample say from a uniform distribution over some some

range so that actually works quite well and and and quite recommended and there

are more advanced methods like methods based on machine learning bayesian optimization and or sometimes known as

sequential model based optimization that I won't talk about but that works a bit

better than random search and and that's another alternative if you think you

have an issue finding good hyper parameters is to investigate some of these more advanced methods now you do

KNOWING WHEN TO STOP

this for most of your hyper parameters but for the number of epochs the number of times you go through all of your

examples in your training set what we usually do is not grid search or random

search but we use a thing known as early stopping the idea here is that if I've trained a neural net for 10 epochs while

training a neural net with all the other hyper parameters kept constant but one more epoch is easy I just do one more

epoch so I shouldn't try to I shouldn't start over and then do say eleven epochs from scratch and so what we would do is

we would just track what is the performance on the validation set as I do more and more epochs and what we will

typically see is the training error will go down but the validation set performance will go down and eventually

go up the intuition here is that the gap between the performance on the training

set and the performance on the validation set will tend to increase and since the training curve cannot go below

usually some bound then eventually the validation set performance has to go up

sometimes it won't sell go up oh is sort of stay stable so with early stopping what we do is that if we reach a point

where the validation set performance hasn't improved from some certain number of iterations which we refer to as the

look-ahead we just stop we go back to the neural net that had the best performance overall in the validation set and that's

my neural network so I have now a very cheap way of actually getting the number of iterations or the number of epochs

over my training set a few more tricks of the trade so it's always useful to

OTHER TRICKS OF THE TRADE

normalize your data it will often have the effect of speeding up training if you have real valued data for binary

data that usually keep it as it is so what I mean by that is just subtract for

each dimension what is the average in the training set of that dimension and then dividing by the standard deviation

of each dimension again in my input space so this can speed up training we

often use a decay on the learning rate there are a few methods for doing this

one that's very simple is to start with a large learning rate and then track the performance on the validation set and

once on the validation set it stops improving you decrease your learning rate by some ratio maybe you're divided

by two and then you continue training for some time hopefully the validation set performance starts improving and

then at some point it stops improving and then you stop or you divide again by two so that sort of gives you an

adaptive using the validation set an adaptive way of changing your learning rate and that can again work better than

having a very small learning rate than waiting for a long time so making very fast progress initially and then slower

progress towards TM also I've described

so far the approach for training neural nets that is based on a single example

at a time but in practice we actually use what's called mini batches that is we compute the last function on the

small subset of example say 64 128 and then we take the average of the loss of

all these examples in that mini batch and that's actually we compute the gradient of this average loss on that

mini batch the reason why we do this is that it turns out that you can very

efficiently implement the forward pass over all of these 64 128 examples in my

mini batch in one pass by instead of doing vector matrix multiplications when

we come the pre activations doing matrix matrix multiplications which are faster than

doing multiple matrix vector multiplications so in your code often there will be this other hyper parameter

which is mostly optimized for speed in terms of how quickly training will proceed of the number of examples in

your mini batch other things to improve optimization might be using a thing like

momentum that is instead of using as the descent direction the gradient of your

last function I'm actually going to track a descent direction which I'm going to compute as the current gradient

for my current example or mini-batch plus some fraction of the previous

update the previous direction of update and better now is a hyper parameter you

have to optimize so what this does is if all the update directions agree oh across multiple updates then it will

start picking up momentum and actually make bigger steps in those directions and there are multiple even more

advanced methods for adding adaptive types of learning rates I mentioned them

here very quickly because you might see them in papers there's a method known as a de grab where the learning rate is

actually scaled for each descent for each dimension so for each weight and each by seize it's going to be scaled by

what is the square root of the cumulative sum of the squared gradients

so what I track is I take my gradient vector at each step I do an element-wise square of all the dimensions on my

gradients my gradient vector and then I accumulate that in some variables that I'm noting as gamma here and then for my

descent direction I take the gradient and I do an element-wise division by the square root of this cumulative sum of

squared gradients there's also rmsprop which is essentially like a de grab but instead of doing a cumulative stuff a sum we're

going to do an exponential moving average so we take the previous value x sub factor plus one minus this factor

times the current squared gradient so that's rmsprop and then there's adam which is essentially a combination of

rmsprop with momentum which is more involved and i won't have time to describe it here but that's

method that's often you know actually implemented in these different softwares and that people seem to use with a lot

of success and finally in terms of

GRADIENT CHECKING

actually debugging your implementations so for instance if you're lucky you can

build your neural network without difficulty using the current tools that are available in torch or 10 to Flora

Theano but maybe sometimes you actually have to implement certain gradients for a new module and a new box in your flow graph

that isn't currently supported if you do this you should check that you've implemented your gradients correctly and

one way of doing that is to actually compare the gradients computed by your code with a finite difference of

estimate so what you do is for each parameter you add some very small epsilon value say 10 to the minus 6 and

you compute what is the output of your module and then you subtract the same thing but where you've subtracted the

small quantity and then the divide by 2 epsilon so if epsilon is converges to

zero then you actually get the partial derivative but if it's small it's going to be an approximate and usually this

finite difference estimate will be very close to a correct implementation of the real gradient so you should definitely

do that if you actually implemented some of the gradients in your code and in another useful thing to do is to

DEBUGGING ON SMALL DATASET

actually do a very small experiment on the small data set before you actually run your full experiment on your

complete data set so you say 50 examples so just taking a random subset of 50

examples from your your data set actually just make sure that your code can over fit to that data can

essentially classify it perfectly given you know enough capacity that you would

think it should get it so if it's not the case then there's a few things that

you might want to investigate maybe your initialization is such that the units are already saturated initially and so

there's no actual optimization happening because some of the gradients on some of the weights are exactly zero so you

might want to check your initialization maybe your gradients are just you know you're using a model you implemented

gradients for and maybe there are gradients are not properly implemented maybe you haven't normalized your input

which creates some instability making it harder for stochastic gradient descent to work successfully maybe your

learning rate is too large then you should consider trying smaller learning rates that's actually a pretty good way

of having a some idea of the magnitude of the learning rate you should be using and and then once you actually over fit

in your small trainings that you're ready to do a full experiment on on a larger data set that said this is not a

replacement for gradient checking so backdrop is and stochastic gradient descent it's a great algorithm that's

very bug resistant you will pretend potentially see some learning happening

even if some of your gradients are wrong or say exactly zero so you should that's great you know if you're an engineer and

you're implementing things spun would code is somewhat bug resistant but if you're actually doing science and try to

understand what's going on that's that can be a complication so do do both gradient checking and a small experiment

like that all right and so for the last few minutes I'll actually try to

motivate what you'll be learning quite a bit about in the next two days that is

the specific case for deep learning so I've already told you that if I have a

neural net win enough hidden units theoretically I can potentially represent pretty much any function any

classification function so why would I want multiple layers so there are a few motivations behind this the first one is

taken directly from our own brains so we know in the visual cortex that the light

that hits our retina eventually goes through several regions in the visual cortex eventually reaching narrow known

as v1 when you have units that are or neurons that are essentially tuned to small forms like edges and then it goes

on to v4 where it's likely more complex patterns that the units are tuned for and then you reach AIT where you

actually have neurons are specific to certain objects or certain units and so the idea here is that perhaps that's

also what we want another artificial say you know vision system we'd like it if

it's detecting faces to have a first layer that detects simple edges and then another layer that perhaps puts these

edges together detecting slightly more complex things nose or mouth or eyes and then eventually have a layer that combines

these slightly less abstract or more abstract units to get something even

more abstract like a complete phase there's also some theoretical justification for doing using multiple

layers so the early results were mostly based on studying boolean functions or a

function that takes as input can think of it as a vector of just zeros and ones and you could show that there are

certain functions that if you add the essentially a boolean neural network or

essentially a boolean circuit and you restricted the number of layers of that

circuit that there are certain functions that in this case to represent certain boolean functions exactly you would need

an exponential number of units in each of these layers whereas if you allowed yourself to have multiple layers then

you could represent these functions more compactly and so there's that's another motivation that perhaps with more layers

we can represent fairly complex functions in a more compact way and then

there's the reason that they just work so we've seen in the past few years great success in speech recognition

where it's essentially revolutionized the field where everyone's using deep learning for speech recognition and same

thing for visual object recognition where again deep learning is sort of the method of choice for identifying objects

and images so then why are we doing this only recently why didn't we do deep

learning way back when back prop was invented which is essentially in 1980s and even

before that so it turns out training deep neural networks is actually not that easy there are few hurdles that one

can be confronted with I've already mentioned one of the issue which is that some of the gradients might be fading as

you go from the top layer to the bottom layer because we keep multiplying by the derivative of the activation function so

that makes training hard it could be that the lower layers at very small gradients are barely moving and

exploring the space of correct you know features to learn for a given problem so

that sometimes that's the problem you find you have a hard time just fitting your data and you're essentially underfitting

or it could be that with you know deeper neural nets Oh bigger neural nets we

have more parameters so perhaps sometimes actually overfitting we're in a situation where all the functions that

we can represent with the same neural net represented by this gray area function actually includes yes the right

function but it's so large that for a finite training set the odds that I'm going to find the one that's close to

the true classifying function the real system that like to have is going to be very different so in this case I mean

I'm essentially overfitting and that might also be a situation we're in and

unfortunately there's never there are many situations where one problem is

observed over fitting or under fitting and so we essentially have you know in

the field develop tools for finding both situations and I'm going to rapidly touch a few of those which you will see

will come up later on in multiple talks so one of the first hypothesis which

might be that you're under fitting well you can essentially just fight this by waiting longer so training longer if you

have your grayness are too small and this is essentially why you're progressing very slowly when you're training well if you're using GPUs and

are able to do more iterations over the same training set within less time that

might just you know solve your problem of underfitting and I think we've seen some of that and this is partly why GPUs

have been so game-changing for deep learning or you can use just better optimization methods also and if you're

overfitting well we just need better regularization i've been involved early

on in my PhD on using unsupervised learning as a way to regularize neural

nets if I have time I'll talk a little bit about that then there's another method you might have learned heard

about known as dropout so I'll try to touch at least two methods that are

essentially trying to address some of these issues so the first one that I'll talk about this dropout it's actually

DROPOUT

very easy very simple so the idea of if our neural net is essentially

overfitting so it's too good at training on the training set well we're essentially going to training

when I make it harder to fit the training set and where we're going to do that and dropout is that we will

stochastically remove hidden units independently so for each hidden unit

before we do a forward pass we'll flip a coin and we'd probably have we will

multiply the activation by zero with probability 1/2 we'll multiply it by 1

so what this means is that if a unit is multiplied by 0 it's effectively not in the neural net anymore and we're doing

this independently for each hidden units so that means that in a layer a unit

cannot rely anymore on the presence on any other units to try to sort of

synchronize and adapt to perform a complex classification or learn a

complex feature and that was partly the motivation behind dropout is that this procedure might encourage types of

features that are not co-adapted and are less likely to overfit so we often use

0.5 as the probability of dropping out a unit it turns out it often surprisingly

is the best value but that's another hyper parameter you might want to tune and in terms of how it impacts an

implementation of back prop it's it's very simple so the forward pass before I do it I just sample my binary masks for

all my layers and and then when I'm performing back drop well my gradient on

the oh sorry so that's the Ford pass yeah I'm just multiplying by this binary mask here so super simple change and

then in terms of back prop well I'm also going to multiply by the mask when I get

my gradient on the pre activation and also you know don't forget that the activations are now different they

actually include the masks in in my notation it's a very simple change the forward and backward pass when you're

training and also another thing that I shouldn't emphasize is that the mask is being resampled for every example so

before you do a forward pass you resample the mask you don't keep it you know sample at once and then use it the

whole time and then that test time because we don't really like a model

that sort of randomly changes its output because it will if we stochastically change the masks what we do is we

replace the mask by the probability of dropping out a unit so actually of

keeping a unit so if we 0.5 that's just 0.5 we can actually show

that if you have a neural net with a single hidden layer doing this transformation at test time multiplying

by 0.5 is equivalent to doing a geometric average of all the possible neural networks with all the different

binary mask patterns so it's essentially one way of thinking about drop out in the single layer case is that it's kind

of an in sembly method we have a lot of models an exponential number of models which are all sharing the same weights

but have different masks that intuition though doesn't transfer for deep neural

nets in the sense that you cannot show this result it really only applies to a single neural networks in gold hidden

layer so in practice it's very effective but do expect some slowdown in training

so often we tend to see that training or network to completion will take twice as many epochs if you're using dropout with

0.5 and here you have the reference if you want to learn more about different variations of dropouts and so on and

I'll and I'll probably won't talk about the unsupervised retraining for lack of time but I'll talk about another thing

that you'll definitely probably hear about and that's implementing these different packages which is Bachelor

organization Bachelor ization is kind of interesting in the sense that it's been shown to better optimize that is certain

networks that would otherwise under fit would not under fit as much anymore fuse Bachelor ization

but also it's been shown that when you use batch normalization dropout is not as useful and drop out being a

regularization method that suggests that perhaps patch normalization is also regularizing in some way so these things

are not you know one or the other they're not mutually exclusive you can have a regularizer that also turns out

helps you better optimize so the intuition behind batch normalization is

BATCH NORMALIZATION

you know much like I've suggested that normalizing your inputs actually can help speeding up training well how about

we also normalize all the hidden layers when I'm doing my forward pass so now

the problem in doing this is that I can compute the mean and the standard deviations of my inputs once and for all

because they're constant but my hidden layers are constantly changing because I'm training these parameters

so the mean and the standard deviation of my units will change and so I it

would be very expensive if every time I did an update of my parameters I recomputed the means and the standard

deviations of all of my units so bachelors ation addresses some of these issues as follows so the way works is

first batch the normalization is going to be applied on actually the pre activation so not the activation of the

unit but before the non-linearity during training to address the issue that we

don't want to compute means over the full training set because that would be too slow I'm actually going to compute it on each mini batch so I have to do

mini batch training here I'm going to take my small mini batch of 64 128 examples and that's the set of examples

on which I'm going to compute my means and standard deviations and then when I do back prop I'm actually going to take

into account the normalization so now there's going to be a gradient going through the computation of the mean and

the standard deviation because they depend on the parameters of the neural network and then that test time we'll

just use the global mean and global standard deviation once I finished training I can actually do a full pass

over the whole training set and got all of my means and standard deviations so

that's the essentially the pseudocode for that taken out of the paper directly so if X is a pre activation for a unit

and have multiple pre activations for a single unit across my mini batch I would

compute what is the average for that unit pre activation across my examples in my mini batch compute my variance and

then subtract the mean and divide by the square root of the variance plus some epsilon for numerical stability in case

the variance is too close to zero and then another thing is that actually batch normalization doesn't just perform

this normalization and outputs the normalize pre activation it then actually performs a linear

transformation on it so it multiplies it by this parameter gamma which is going to be trained by gradient descent and

it's often called a gain parameter of batchelomez ation and it adds a bias

better and the reason is that if I'm subtracting by the mean then each of these you

have the biased parameter so if I subtracted then this essentially here

there's no bias anymore it was present here was present here and now it's been subtracted to have to add the bias but

after the bachelor ization essentially so these betters here are essentially the new bias parameters and those will

actually be trained so we do gradient descent also on those so bachelor ization adds a few parameters all right

and I as I said I'm just gonna skip over this and you know I'm not showing what the gradients are when your backdrop through the mean and so on it's

describing the paper for Necedah gradients but otherwise in the different packages you actually have access to

you'll get the gradients automatically it's usually been implemented skipping

UNSUPERVISED PRE-TRAINING

over that I'll just finish if you actually want to learn about unsupervised retraining and why it works

NEURAL NETWORK ONLINE COURSE

videos on that so you can check that out and I guess that's it thank you

thanks you go so we have a few minutes for questions which are intermingled with a break so feel free to I your go

for our break or ask questions to Google I believe there are microphones and I'll also stick around so if you want to ask

your questions offline that's also fine if you want ask questions you can go to the mic

go to the microphone hi I mentioned the

rail ooh adds varsity can you explain why yeah so um so the first thing is

that it's observed in practice and they add some sparse some sparsity in part because you have the non-linearity at

zero below so it means that units are going to be exactly potentially exactly sparse exactly essentially absent of the

hidden layer the real there are a few reasons to sort of explain why you get

sparsity it turns out that this process of doing a linear transformation followed by the value activation

function is very close to some of the steps you would do when you're optimizing for sparse codes in the

sparse coding model if you know about sparse coding so they're like essentially in optimization methods that

given some sparse coding model we'll find what is the sparse representation hidden representation for some input and

it's mostly a sequence of linear transformations followed by this sort of like relu like activation function and I

think this is partly the explanation otherwise I don't I don't know a like solid you know explanation for why that

is beyond you know it's observed in practice more questions if not let's

thank you again and we are we reconvene

in ten minutes

summary:
**Key Points**:

1. **Introduction to Deep Learning**:
    
    - Hugo Larochelle presented on the foundations of deep learning, focusing on feed-forward neural networks, deep learning motivation, and recent developments.
    - Covered topics include basic neural network structure, loss functions, backpropagation, stochastic gradient descent, and various practical tips for training neural networks effectively.
2. **Neural Network Functioning**:
    
    - Explained the computation of neural networks starting with input vectors, going through hidden layers introducing non-linearity, and producing outputs for classification tasks.
    - Discussed the importance of non-linear activation functions like sigmoid, hyperbolic tangent (tanh), and rectified linear activation (ReLU) for hidden layers.
    - For the output layer, the softmax activation function is used for classification tasks to produce probabilities for each class.
3. **Training Neural Networks**:
    
    - Discussed the use of empirical risk minimization framework which includes choosing a loss function, an optimizer like stochastic gradient descent, a regularizer, and parameter initialization methods.
    - Highlighted the importance of the loss function in training, specifically the negative log likelihood or cross-entropy for classification tasks.
    - Emphasized the backpropagation algorithm, which is used to efficiently compute gradients of the loss function with respect to network parameters, utilizing the chain rule.
    - Talked about the importance of proper weight initialization to avoid issues like vanishing or exploding gradients.
4. **Challenges and Solutions in Deep Learning**:
    
    - Addressed common challenges such as underfitting and overfitting, emphasizing the use of GPUs for faster training and methods like dropout and batch normalization for regularization.
    - Dropout randomly deactivates neurons during training to prevent co-adaptation and overfitting.
    - Batch normalization normalizes the output of each layer to stabilize learning and also acts as a regularizer.
5. **Hyperparameter Tuning and Model Selection**:
    
    - Discussed methods for selecting hyperparameters like the number of layers, units per layer, learning rate, and weight decay, including grid search, random search, and more advanced methods like Bayesian optimization.
    - Introduced the concept of early stopping to prevent overfitting and select the number of training epochs based on validation set performance.
6. **Debugging and Improving Models**:
    
    - Highlighted the importance of normalizing input data, using learning rate decay, mini-batch training, momentum, and other optimization methods like AdaGrad, RMSprop, and Adam.
    - Advised on using gradient checking to ensure correct implementation of gradients and starting with a small dataset to ensure the model can overfit to it, indicating a correctly functioning model.
7. **Closing Remarks**:
    
    - Hugo concluded by reiterating the potential and challenges of deep learning, referencing his online course for a deeper understanding of the topics discussed.
    - The session ended with a Q&A, addressing specific questions about the ReLU activation function and its ability to add sparsity to the model.

The presentation provided a comprehensive overview of deep learning foundations, practical training tips, and strategies for effectively training and tuning neural network models.


----------

-----

--03--

-----
Date: 2014.12.23
Link: [Jimmy Pedro: Judo | Take It Uneasy Podcast](https://www.youtube.com/watch?v=7bO8rKtvDoE)
Transcription:

Jimmy Pedro is an American judo competitor and coach, World champion, 3x World medalist, 2x Olympic medalist; we talk about his father (Big Jim Pedro Sr), his early career, the times he wanted to quit, overcoming a neck injury, coming back from retirement, the life of an athlete vs the life of a coach, a system for developing elite-level judoka, Japanese vs Russian judo, periodization, a weekly program for an elite-level judoka, toughest moment as a coach, watching Travis Stevens lose the semifinals at the Olympics, mental game, visualization, IJF, judo as a spectator sport, the future of judo in the United States and the rest of the world, and more.
Based on the comments, the interview with Jimmy Pedro, an acclaimed American judo competitor and coach, was highly appreciated and resonated deeply with the judo community and listeners. The interview appears to have covered a comprehensive range of topics, reflecting Jimmy Pedro's extensive experience in the judo world. Here are the main takeaways based on the audience's reactions:

1. **Inspiring and Sincere**: Viewers found Jimmy Pedro's narrative inspiring and appreciated his sincerity and straightforwardness. His experiences, especially those involving his father, his early career struggles, and his coaching journey, seemed to strike a chord with many.
    
2. **Insightful on Professional Judo**: The interview provided valuable insights into the professional life of a judoka, discussing the intricacies of training, competition, and coaching at an elite level. Comments indicated that listeners found the discussion on the development of elite-level judoka, periodization, and weekly training programs particularly enlightening.
    
3. **Emotional Connection**: Some comments reflected a personal connection with Jimmy Pedro, indicating that his guidance and career had a significant impact on their judo journey. The mention of watching Travis Stevens lose in the Olympics suggested that the interview didn't shy away from discussing the emotional aspects of the sport.
    
4. **Educational Content**: The interview seems to have offered an in-depth look into the mind of an Olympic-level athlete, with Jimmy Pedro sharing detailed insights into mental preparation, visualization techniques, and the overall mindset required for high-level competition.
    
5. **Addressed Contemporary Judo Topics**: The interview tackled current issues and developments in judo, such as the rule changes by the International Judo Federation (IJF) and the future of judo in the United States and globally. This aspect of the discussion appeared to resonate well with judo enthusiasts concerned about the sport's direction and representation in the Olympics.
    
6. **Judo as a Martial Art and Sport**: Comments indicated that the interview addressed the balance between judo as a martial art and as a competitive sport. Discussions about judo's self-defense applications and its evolution for television ratings and Olympic standards seemed to engage listeners who are passionate about the sport's integrity and future.
    
7. **Affirmation of Jimmy Pedro's Legacy**: Numerous comments recognized Jimmy Pedro as a legendary figure in American judo, applauding his contributions to the sport both as a competitor and a coach. His influence on American judo and his role in shaping the careers of other notable judokas like Kayla Harrison, Ronda Rousey, and Travis Stevens were highlighted and celebrated.
    

In summary, the interview with Jimmy Pedro was well-received, with listeners praising the depth, honesty, and comprehensiveness of the conversation. It seemed to offer a blend of personal storytelling, professional insights, and thoughtful discussions on the future of judo, making it a valuable and enjoyable experience for the audience.

The interview with Jimmy Pedro, an American judo competitor and coach, covers a broad range of topics related to his illustrious career in judo, his coaching experiences, and his insights into the sport. Key discussion points include:


1. **Early Life and Career**: Jimmy talks about his upbringing and the influence of his father, Big Jim Pedro Sr, on his judo career. He reflects on the initial phase of his career and moments when he contemplated quitting.
    
2. **Injury and Comeback**: The conversation delves into a significant neck injury Jimmy sustained and how he overcame this obstacle, including his remarkable comeback from retirement.
    
3. **Athlete vs. Coach**: Jimmy contrasts the life of an athlete with that of a coach, shedding light on the different challenges and rewards each role presents.
    
4. **Development System for Elite Judoka**: The discussion covers Jimmy's approach and system for nurturing and developing elite-level judoka, offering insights into his coaching philosophy.
    
5. **Judo Styles and Techniques**:
   
   

----------

-----

--02--

-----
Date: 2014.06.05
Link:  [Ryan Hall: Value of Competition | Take It Uneasy Podcast](https://www.youtube.com/watch?v=94MBVD_tZeU)
Transcription:

Ryan Hall is an American black belt and instructor in Brazilian jiu-jitsu, and a professional mixed martial artist currently competing in the featherweight division of the Ultimate Fighting Championship (UFC). He is known for a number of competitive achievements, ranging from Mundial and ADCC victories to dozens of Grapplers Quest championships. He is the winner of The Ultimate Fighter Season 22. He holds notable victories over former UFC Lightweight and Welterweight Champion BJ Penn, former UFC Lightweight Title challenger Gray Maynard and Artem Lobov.

  
you have been in both the supporter and

a critic of competition what do you

think is the value of competition for

martial artists I believe that the value

of competition is in that it teaches you

the true purpose of martial arts and in

ending and the true purpose of martial

arts is being able to defend yourself

and whatnot in all of these other things

in real life yes because you let's say

you win a DCCC gold medal but you know

you get slapped around by someone bigger

and stronger you at a bar that people

will talk about how sweet that gold

medal is but for the rest of your life

it'll feel pretty Hollow that wouldn't

you know that's not what we're looking

for but what I'm talking about I guess

is what I believe competition develops

if approached properly is proper focused

proper dedication because anytime you

have a very defined goal and strong

opposition it will force you to be

better period the better your opposition

is if you focus and you take your what

you're doing seriously the better you

become period people are better

wrestlers today than they once were

people are better basketball players

today than they once were military is

better now that it was in the past

because of all of the competition

that you know that is existed over the

course of time and you know if you go

out competition if you go out and just

kind of it if you're like oh

I'm going to go out and see how it

happens like that's a cowardly way to

approach competition and that gets you

nothing that doesn't teach you to really

do the right things and the same thing

not for pot not properly preparing even

if you win that was a cowardly way to

approach it because you intentionally

left yourself an out which was if I win

man I'm talented in blah-dee-blah and if

I lose it's well you know I mean I could

I didn't really train that hard well if

that's the case then you shouldn't have

been out there win lose or draw I don't

care if I've got a student that I think

is going to win gold at the World

Championships he or she does not train

properly ahead of time I will not allow

them to go and if they go I will send

them off the team you know and hey they

can do what they want they're a grown

adult I'm not the boss of them but I am

the boss of my team it wasn't my gym and

that's not how we conduct ourselves and

it has way less to do about the physical

you know the result and it does about

the proper preparation is proper

preparation and proper focus and

dedication over the long haul yields

positive results but most importantly

it's about are we conducting ourselves

in a in an honorable and respectable

manner so I believe that the competition

really teaches us that because in the

room you know there's always like oh it

was practice so I was kind of this -

that happened today the other thing when

you go to competition everyone is that's

on everyone is on that day because

everyone is trained

for that specific moment and we'll see

what happens so you get the most honesty

out of it out of a time like that and

the higher the level the better it gets

in you know provided that there's not a

lot of cheating but regardless you know

from an athletic performance perspective

it is the most honest thing because and

it's the it's the toughest as well

because it takes it takes courage and it

takes some heart to really properly

prepare and put it on the line because

you're risking horrible disappointment

I've prepared so hard before and tried

so hard and I've won and I've prepared

other times and I've tried so hard and

I've failed and it hurts it really hurts

it doesn't hurt nearly as much if you

kind of half-ass it because you didn't

put that much into it but again that's

how a coward approaches things if you

have if you're going to conduct yourself

the right way you prepare properly you

train hard and then win lose or draw you

deal with the results and that's what I

believe is the real benefit of

competition if approached properly do

you admire somebody who sacrifices you

know like 10 20 years of their life in

that singular pursuit of competition

towards a gold medal at the Olympics a

almost of the Olympians do goodness

absolutely I mean I admire anyone that's

willing to sacrifice and willing to work

hard in any area of life actually a book

that I'm reading again that I really

really like is dune it's a I'm kind of

like sci-fi nerd hangout on everybody

but basically a you know one of the

things that you know one of the one of

the you know things that the the author

was going to Frank Herbert and it's why

the regarded is one of the you know

greatest science fiction novels ever if

not the preeminent but anyway well the

things you said you know is if you if

you search for freedom you actually end

up becoming a slave to your own desires

ironically and if you search for

discipline you find liberty because

you're able to make yourself do what you

want in the long run whereas if I'm like

oh I'm going to do whatever I want all

the time and screw you dead I'm going to

do what I want that's kind of like a

teenager type attitude you end up

getting into a bunch of nonsense but

anyone that's able and again this

doesn't matter it doesn't mean that it's

athletic it could be in any area of

human endeavor any area of life it could

be parenting it could be military it

could be athletics to be business it

could be school to be anything but as

long as you're making you know an

incredibly large commitment I have an

immense amount of respect for the for

the level of dedication that and the

level of commitment and a level of

risk that it that you're taking

emotionally psychologically because hey

like you said you work twenty years you

get that gold medal but there's other

people that work twenty years and got

the silver most people know the medal

now most people most people that think

they work hard don't I'll be frank

you know like seriously I said that in

class the other day like again it's like

I don't want to be too negative but most

the people that most people to think

they work hard do not how do you know

that if you're working hard or not I

think you know but most people are not

very honest with themselves they were

most people would press a button in my

experience you know they would prefer to

be look like the thing and then be the

thing and you know that's that's fine

but it really I can't I think Sun Tzu

said it's a victory is reserved for

those willing to pay its price and there

is a price and now that doesn't

guarantee that if you pay the price that

you will have victory but you guarantee

but I mean from a physical perspective

but you will have the moral victory

regardless because you will have you

will have learned discipline you'll have

shown not only to others forget others

you do it not for others but for

yourself you you show that you are the

master of your own mind and of your own

body and of your own circumstance and

you can discipline yourself and focus

and you deny yourself certain things in

the pursuit of something something that

is valuable to you and that is

incredibly useful in any area of life

and that's not mean not shocking to me

why the same reason that you'll see guys

that were you know like high-level

military like kind of big dogs on SF

world get hired by let's say for

instance a fortune 500 company because

what would they know about business

nothing but also everything because that

level of focus and dedicate like you

don't get to that level of ability in

something by accident and that's what I

think you know like again the value of

competition and what they do competition

only it's as serious as it gets you know

because if you don't get the gold medal

it you may not you may not walk out of

it but basically I have an immense

amount of respect for anyone that is

willing and able to over the long haul

put that time in but I have to trying

hard doesn't mean just getting on an air

Don bike and walking off the mat or

having to be carried off the mat it

means thinking approaching reassessing

reevaluating saying how could I be

better and it takes honest on a

self-analysis and

and also it takes a lot of times because

let's say you know I think I'm doing

well but I got to say hey Lex you know I

mean no matter how how well I believe I

look at myself I'm still biased I'm

still looking at myself what should I be

doing better I'm gonna find other people

that I respect and people that I think

can tell me and I'm gonna ask them and

then I'm gonna have the courage to

listen to them and not just dismiss what

they're saying out of hand and if you're

doing those things then I believe that a

lot of times you're working hard but I

know plenty of people that come in it's

just like in jiu-jitsu this point if you

limit training for 15 years it frankly

suck and there's plenty of people that

have been training for four that are

pretty dang good you know for real and

again are they the best person that's

been training for four years is still

compared to like Kareena not that good

but they could be really really really

good because they understand how to be

directed and how to focus and I believe

this is something I've discussed you

know before with some other you know

friends of mine you know that some of

whom were at a very high level may

others that are the high level of

jiu-jitsu wrestling or whatever um look

at guys like Randy Couture guys a Rick

Hawn they're on their second career they

started MMA when they were like 32 and

yet they got to the top maybe they

weren't always champion but they were

fricking good why because they're 26

year old self would be scary but you

know like hey um they know what it is to

be dedicated and work hard and because

again they're Olympians like you said on

a level that a regular person has no

concept of so I think that that is

ultimately the skill it's not the oh man

this person's dangerous because he's got

good judo or good wrestling no this

person is dangerous because he or she

knows how to work their ass off and be

focused on a level that most people

can't comprehend and that's what

produces success in any area of life in

might hit you yeah be brutally honest

with yourself at all times and it stings

sometimes you know I think yeah it's

like the price of of looking inward you

know objectively is that you're not

going to like what you see a lot you

know and because even if you're like oh

man I'm 90% the way I want to be it's

like that if you are going to take that

next step in my opinion it's you're

going to focus on the 10% because it's

like oh man we're doing a lot of things

good yeah who gives a let's talk

about what we need to improve on you

know and that's a little bit less fun

but in the long run I think it's what's

it's what's going to drive you to a

higher level but at the same time I

think it's what makes a lot of people

that are like that a little bit neurotic

and nutty by compared by a normal

standard

right but again you show me someone

that's super well adjusted and I'll show

you someone that's probably not a high

achiever

you talked about moral victory can you

explain how your morality contributes to

the way see the value of winning sure

I think there's absolutely such a thing

as a moral victory and sometimes people

that are trying to manipulate you or

trying to get you to buy something will

tell you differently and you know there

is there it goes in two directions for

instance let's say you're a blue belt

and you compete against you know a real

black goal and there's plenty of people

running around plat belts that are not

particularly at this point but you know

let's say for instance your blue belt

and you compete against a real black

belt the likelihood of you winning is

almost zero however if you go out there

and you try hard and you do your best

and again whether you come off the mat

you know a winner which would be very

fortunate and unlikely but or you come

off the mat you know on the other side

of things if you went after and you

tried and you you know let's say you had

some nerves but you kept that in check

and you fought hard you didn't let it

get the better of you you know that

would be in my opinion a moral victory

and and there would be nothing wrong for

recognizing it as such now that's not

the same thing as an actual physical

victory but there's nothing wrong with

saying let's say you're your opponent's

260 pounds in your 120 and you tie they

get the decision hey you know I remember

that happened to me at the quarter-final

or not the quarter-final rather in the

the third round at the absolute in the

Worlds in 2008 you know and you know

it's against a heavyweight or a super

heavyweight and in the 0-0 and I wasn't

happy about losing by any stretch of the

imagination but looking back I'm like

okay well you know generally speaking if

you end up level considering that I have

all of the resources you don't that is

you know you definitely performed a

little bit better than I did now at the

end of the day you know wins and losses

do matter and you do want to try to make

sure that I'm not shooting for the moral

victory I'm shooting for the actual

victory but every now and then it's very

very important to keep in mind that you

know am I just actually myself am i

conducting myself in a way that I

respect that hopefully other people of

value or respect and also a way that I

believe is going to produce actual

victory and actual positive results in

the long run as well I think it's

important to recognize that because

sometimes you'll see people get very

frustrated let's say for instance if I

box against people that are much more

experienced than me all the time

you know I'm not going to win anyone

that tells you differently has either

not training with people that are very

good or B they have no idea what they're

talking about

but what I can say is hey did I do a

little bit better today and better

doesn't mean that I land more punches in

this it was I more under control was I

more able to kind of keep my keep my

focus and execute what I wanted to

execute and if the answer to that is yes

you know I'm moving in the right

direction so as far as I'm concerned

there's all sorts of different types of

moral victory but it would be the the

same thing as you know let's say for

instance you know fade or slaps your

mother you got to hit him

you have to he's going to kick the

out of you almost certainly but you have

to hit him it would not be it would be a

technical like well I didn't get hurt so

that's a win if you ran away but that

would be the opposite of the moral

victory in that case trying your best

and losing would still be I would say

the honorable thing to do so what you're

saying is sometimes you have to pay the

price for a moral victory

absolutely but the reality is is that

martial arts doesn't just teach us about

how to beat someone up or technique or

this is that that's really not the core

of the martial arts the core of the

martial arts is heart discipline

dedication focus and if you have those

things they'll always be people better

than you and they'll always be people

lesser than you but that's not the only

metric by which you can judge

performance or judge a person

yeah I competed in boxing judo wrestling

jujitsu MMA have a man yeah now what do

you think is the best martial art for

defending yourself against an untrained

opponent there's so many different

factors but let's say for instance okay

most fights I've seen are one-on-one

they're the fights we hear about are an

ass-whipping like seven people versus

three people and okay the more variables

you add in it gets very very difficult I

would say them the best fighting style

is using your brain and because less

voiding the fight well avoid in the

fight but I would say intelligent it's

just like investment now I know nothing

about investing which is why I don't do

it but um let's say for instance a

Warren Buffett is looking at a stock

page now I'm speculating because I don't

know mr. Buffett but I do have someone

who's standing up how the world works so

I would say that some days he looks at

the page it says haha there's a good

investment here and other days

regardless of his skill and investment

he says there's nothing to do the best

thing to do is wait but your Warren

Buffett tell me the best investment yeah

the best investment today still sucks

and I'm not going to make it talked to

me next week and I'll see what's out

there

so till next week we're gonna make we're

gonna we're going to invest some money

maybe and then you know he'll make the

read as he sees it so let's say for

instance you walk into a room and your

goal was to kill everyone in the room

and you are armed but you walk in to

50/50 Jitsu and you're going to shoot

everybody but for whatever reason it's

bringing your gun to the gym Tuesday and

everyone else is sitting there polishing

their fully-loaded again rounding the

chamber safety off weapons hot all that

good stuff and you see everyone else is

armed what do you do wait until

Wednesday

you come back in on Wednesday when no

one's armed then you shoot us all to be

great so it's that would being the best

tactical shooter you could be as ninja

as you want we're going to kill you

there's too many of us in too few of you

could you make it out of there and like

some sort of Boondock Saints awesome

luckiness and managed to get everybody

sure I wouldn't bet on it

that's like Floyd Mayweather against

three people I would bet on him sometime

seriously anybody that tells you

differently is never fought an untrained

person because regular people can't

fight for [ __ ] and the other thing is

they get scared so the one Floyd

literally cripples the first guy with a

right hand the other two guys unless

they're really seriously probably go

oh and then hesitate but they may not

but let's so if you think about it

though four people five people three

people ah let's say it's one on one but

Floyd's minding his own business against

snuck over the shoulder as he's sitting

there ordering a drink at a bar all

these different things factored in so I

would say that when it comes to the

physical expression of how to best

defend yourself the most important thing

is situational awareness and

understanding what's going on around you

because you could be the world's

greatest ninja warrior and still run

yourself into a lose-lose situation

could I knock out Floyd Mayweather yeah

sure I could if you let me hit him but I

don't think I would come within spitting

distance of him if he didn't want me to

I would have no teeth before I even

tried but if he sits there and lets you

hit him he is a man he is mortal so

basically under the right circumstances

anyone can win onto the wrong

circumstances anyone can lose so I would

say that understanding that is two step

one to being able to be an effective

effective strategist who can read a

situation you say should I fight this

one out should I not should I get out of

here should I fight for four seconds and

run for it and you know when you take

into account the physical expression of

everything and you want to let's say for

instance you know the most important

things for defending yourself in real

life I would say probably wrestling or

jiu-jitsu probably jiu-jitsu really in

my opinion but that's just perfect for

fighting I would say other things if I

want to be able to beat up more than one

person I know it implies that I can

wrestle or I can because regular people

can't wrestle for [ __ ] you will you

could pick him up and slam your head on

the ground or something horrible you

know but boxing would be nice as well

but let's say you're a great boxer and

someone tackles you could a regular

person tackle a good boxer yes alright

could a regular person sucker a good

jujitsu guide for sure but it also

really comes down to the to the mental

and everything like that but basically

if I had to pick one art and the

everyone knows nothing I would picture

issue but in my opinion jiu-jitsu at a

high level involves wrestling so just

like you said grappling is this bigger

thing that involves wrestling's you know

everything no doubt that's like you take

an Olympic level wrestler and you let

him lean on top of your inside control

it's not pleasant

in class you you emphasize that we're

working with basic laws of physics so I

just read Einstein's biography he was

obsessed with finding a single theory

that would unify all the fundamental

forces of nature Wow

do you think there exists the unified

theory of grappling we can boil

everything down to just a few principles

I will

well first off if Einstein wasn't able

to come up with a unified theory I would

sincerely question my ability to go that

way but do I believe that something like

that could potentially exist absolutely

and I think that even if it doesn't a

belief in the possibility of it and the

search for it would would leave you

better off than where you started

whereas if I was a no no that's [ __ ]

that would never and then I don't look

even if I'm right because I didn't look

there's certain things I won't learn so

I think you know a lot of times just

let's say alchemy the idea that you're

going to turn lead to gold all right

let's a little bit nuts but who knows

maybe that's that kind of nutty and you

know on highly unlikely is highly

unlikely probability of success pursuit

yielded scientific progress elsewhere in

the search for that even though again

someone would look back and say oh

that's stupid who would blush and who

would do that

well if you spent years trying to figure

it out I guarantee you're going to learn

some other things as well so I think

that there at the very least the

principle based approach to grappling is

incredibly important with your process

like for learning new details and

understanding the principles behind the

techniques I certainly don't believe

that I have like a singular or perfect

approach by any stretch of the

imagination but you know I guess what I

try to do is block out extraneous

nonsense like for instance both Pete a

lot of people want to talk about 55

details and reasons for something that's

going on and the reality is is that

you're clouding your thought process for

instance there was a recent not to get

too political but there was a recent

issue where I remember an inmate was

executed and they used a new drug and it

was painful and oh my god and he died it

was horrible again that's when whether

you believe that capital punishment is

valid or not I think there's plenty of

arguments against it in fact I think

most of the arguments that make sense

are against it but pain has fuck-all to

do with it you know I don't care that's

like done hey Lex I'm going to kill you

but don't worry it's not going to hurt

man I mean don't know okay then yeah

it's like that doesn't make it okay it's

like believe me I'm for free I'm is

again if you're gonna kill me I prefer

that you don't burn me at the stake but

if someone was like don't worry it's not

even a sting I'm still going to try to

fight you to the death I'm absolutely

not allowing this to happen if someone

wants to say okay hold on let's get

let's cut the [ __ ] like feely

feelings out of here and say look forget

the pain does this person deserve it

uh-uh

let's let's step that back again is

there a potential for human error is

there potential for someone having this

guy behind bars for political gain like

okay these are the real reasons that you

say hey no way on the death penalty it

has nothing to do with does it hurt or

which drug is it are blah-dee-blah

or is it inhumane it's like none of that

if hey we're focusing on the wrong thing

so it reminds me of jiu-jitsu in the

same sense and again we're fighting were

generally speaking in my opinion debates

that happen in the public you know arena

they always focus on the wrong dang

thing and always focus on the wrong

aspect again there's 25 good reasons or

bad reasons to do almost anything but

generally speaking people will focus on

the hundred other ones that are

extraneous and [ __ ] so what I want I

guess what I would say is it reminds me

of jiu-jitsu is striking like man Floyd

likes to hold his hand this way or that

way or the other way and and this guy

likes to jab like this and it's really

important this person says you land with

this knuckle in that person says you

land with net knuckle and in jiu-jitsu

it's very very important that you grip

three inches up on the lapel and two to

the right

but Roger Gracie doesn't like this but

cabrini says it like this clearly they

all work under the right circumstances

and don't work on to the wrong ones and

it has nothing to do or very little to

do with these other things like hey does

it matter again I'm going to kill you

would you prefer for it to be painless

or horrific ly painful okay if it's

already a foregone conclusion death

alright yeah now we'll start to talk

about the the extreme like whether or

not it's going to sting but until we get

to that point

hey let's focus on the do we is it even

right or do I have the ability or the

capacity to do this justifiably okay so

that's where you come down to the

principles in my opinion say all right

yeah it doesn't matter which knuckle you

land with yeah I'm sure it does but it's

a hell of a lot less important than 25

other little things that make all of the

difference and in my experience a lot of

coaches and a lot of people particularly

guys that are trying to [ __ ] you

will focus on 45 little details and oh

it's there's 15 details to this ten

okay that's true but what are the two

most important ones because hey don't

get me wrong I'm not saying that these

details don't matter but just like

anything else in life there's a

hierarchy because would you say that

would you say that happiness and

self-actualization is a valuable thing

in life yes I would as well and you know

what we have the luxury of saying that

type of thing because we're sitting at

fifty fifty Jitsu in Falls Church

Virginia and there's no one trying to

kill us rape us and we are also I know

where food is tonight yeah if you were

to walk down if you were to talk to

someone like 2,000 years ago I'll be

like how are you feeling they would

stare a chili what are you [ __ ]

[ __ ] I'm starving yeah I'm hungry

that's my issue

are you are you satisfied in your life

it's like I'll be satisfied when you get

out of my way so I can find some food so

that's even the deeper question is are

you eating something tonight right and

so it's Maslow's hierarchy of needs when

we take care of the base needs first

then we start to work our way up toward

self-actualization and this and that and

but until you got your food water

shelter don't tell me about where you're

placing your grip it's like you're all

leaning out and you're you know your

posture is poor and you're out of

balance and you want to tell me your

grip that's like I'm starving to death

the you know the barbarians are at the

gates but I'm sitting here giving you a

philosophy lesson it's like this is

[ __ ] it doesn't make any sense

build a better wall a sharper knife and

get some food and then we'll cover all

the other stuff so I think that in my

when it comes to how I approach martial

arts in terms of learning as well as

teaching I really try to boil it down to

what I feel to be the most important

component parts and then if I one day

reached the level of where these tiny

details matter that's fantastic because

again the difference between you know

the ability to pass that try to pass

successfully against a cabrini or how

file Mendez and against a regular

run-of-the-mill black belt or you know

does come down to little details but

it's also presupposing that you're in

proper position that even allow these

details become relevant and I think that

a lot of times we put the cart before

the horse and that's not that's

problematic there's still in your

opinion undiscovered position

submissions of techniques and you just I

would say that there have to be there

absolutely are um you know I think that

what we see is jiu-jitsu now don't get

me wrong the core never changes because

physics doesn't change physics is the

same thing that's why I get a kick out

of

love like self-defense arguments it's

like [ __ ] it has another no physical

difference in self-defense beyond the

fact yes you can I guess mean though

I've never seen anything like that in

real life that you're crossing a pretty

serious psychological line if you're

putting your knuckles to you know your

thumb to knuckles deep into somebody's I

forget the fact that did you know that

we're legal more all other things like

that it's like I've never done that

before I wouldn't do it lightly there

probably be some hesitation there what

is so anyway what makes it different is

the the psychological component and all

these other things going on but

physically there's no difference again

people like Aldridge it's is really

different in MMA no it's not not in my

opinion not in my experience it is

absolutely not what are you talking

about physics are different inside of a

cage than they are on a mat and they are

out in a field

it's exactly the same now if I try to

sport grapple you under a non sport

grappling rule set then I may run myself

into trouble but that had nothing to do

with jiu-jitsu jiu-jitsu is physics is

proper expression of physics the same

way boxing is and the same way of

wrestling is the same way all these

things are so I would say that as long

as something adheres to the principles

that that allow something to be

effective and you know and fundamentally

sound that you can do almost anything

and I think that people will continue

particularly in the ghee it's going to

get nuts you know just the level of the

amount of things that you can get away

with and do and different grips that you

can make but I'd say what we're looking

at right now is going to look only

somewhat like what jujitsu is going to

look like in 30 years the same way the

jujitsu we see now is so much

fundamentally better honestly and and

more evolved and adaptive than it was

twenty years ago and people will swear

up and down like all back in the day

it's back in the day people did not

fight very well even twenty years ago

the level of people understanding how to

deal with jujitsu was very reduced so

you could get away with all sorts of

pretty questionable stuff like sitting

in front of someone in close guard and

have them not completely kick the [ __ ]

out of you but um yeah I think you know

with particularly the advent of Baron

bull the 50/50 position all these

different things which have always

existed there's they've always existed

and one that's I always hesitate to say

invent I don't like the word invent like

that certain people use a lot

I'd say Discoverer because you could

show me I can come up with something

let's say Lex you know you've got a

really good straight foot lock I was

watching a train last night

and I could be doing that in a way that

no one ever taught me that doesn't mean

I invented it because you've been doing

it forever but basically it's let's say

no one showed me the details you were

using and I managed to stumble across

them I didn't invent those details eyes

go yeah I discovered them that was neat

but again none of us have invented a

dang thing people have had two arms and

two legs for certainly as long as I can

remember and probably longer than that

and today here yeah that's that's the

word so in the history books

you

summary:

Ryan Hall, a notable martial artist and UFC fighter, delves into the intricacies of competition, dedication, and the essence of martial arts in this insightful interview. Here are the key points from the discussion:

1. **Value of Competition in Martial Arts**:
    
    - Hall recognizes competition as a means to understand the real purpose of martial arts: self-defense and real-life applicability. He emphasizes that the worth of a competition medal pales in comparison to the ability to defend oneself in practical situations.
2. **Competition as a Catalyst for Improvement**:
    
    - He argues that defined goals and formidable opposition in competitive environments compel individuals to improve. This principle, he notes, is evident in the evolution of various fields, including sports and the military, over time.
3. **Approach to Competition**:
    
    - Hall criticizes a lackadaisical approach to competition, labeling it cowardly. He stresses the importance of proper preparation, focus, and dedication, regardless of the outcome, and condemns using lack of preparation as an excuse for failure.
4. **Integrity and Team Standards**:
    
    - He maintains strict standards for his team, insisting on proper training and preparation for competitions. Hall values the process and integrity over results, advocating for honorable and respectable conduct in and out of competition.
5. **Honesty in Competition**:
    
    - According to Hall, competitions are the most honest platform where everyone brings their best due to the focused preparation for the specific moment, making it the toughest and most revealing environment.
6. **The Pain of Failure and Moral Victory**:
    
    - He openly discusses the pain associated with trying hard and failing in competitions, highlighting the importance of full commitment and dealing with the results, whether positive or negative. Hall believes in the concept of moral victory, where the effort and character shown in competition are as important as the actual outcome.
7. **Respect for Dedication in Any Field**:
    
    - Hall expresses immense respect for individuals who show long-term dedication and sacrifice in any field, emphasizing the importance of discipline and focus, which are applicable and beneficial across various aspects of life.
8. **Unified Theory of Grappling**:
    
    - While skeptical about formulating a unified theory of grappling akin to Einstein's pursuit of a unified theory of physics, Hall believes in the value of searching for fundamental principles that govern effective grappling techniques.
9. **Principle-based Approach to Learning**:
    
    - He advocates for focusing on the most important components in martial arts, cautioning against getting lost in minor details. Hall emphasizes the importance of understanding the fundamental principles and building upon them.
10. **Evolution and Discovery in Martial Arts**:
    
    - Acknowledging the constant evolution of martial arts, Hall anticipates future discoveries and innovations, especially in disciplines like jiu-jitsu. He prefers the term "discovery" over "invention," recognizing that martial arts techniques are often rediscoveries of pre-existing principles given the unchanging nature of human physiology.

The interview with Ryan Hall offers a profound look into the mindset of a dedicated martial artist, highlighting the importance of commitment, integrity, and continuous learning in the pursuit of mastery in martial arts and beyond.

----------

-----
--01--

-----
Date: 2014.05.08
Link: [Ido Portal: Movement](https://www.youtube.com/watch?v=o8nZaDw_mOs)
Transcription:

Ido Portal has spent the past few decades honing a physical credo and method that's now practiced by thousands of people all over the world - from office workers, to former CrossFitters, to NBA players, to the ever-controversial UFC titan Conor McGregor. Known as The Ido Portal Method, or simply "movement," his approach purports to take the "most potent" parts from a range of physical disciplines by shedding the dogmas that often accompany them. As he puts it: "I want the contents, not the container."
Intro

we choose to go to the moon and district eight and do the other things not

because they are easy but because they are hard

[Music]

in any particular sport with well-defined rules mastery is achieved

through specialization taking a few skills and perfecting them so naturally

most experts and teachers of movement are specialists of skillsets like

gymnastics hand balancing Olympic lifting capoeira Jitsu wrestling judo

and other martial arts so it's rare to come across a generalist someone who

takes a holistic approach to movement my guest today is IDO portal he is a guru

of movement a teacher with a large and quickly growing following as he says

movement is big bigger than any specific discipline were all human first mover

second and only then specialists I actually just finished reading a

Journey to becoming a generalist

biography of Albert Einstein by Walter Isaacson and the two of you have

something in common I desire to arrive at a unified theory in his case there's

a unified theory of physics you know like forces of nature in your case it's a unified theory of movement can you

tell me the story of your journey to becoming a generalist first I'd just say

that I'm no guru you know it's something that people use but I have a really hard

time with the word master or guru and I didn't arrive with the gospel truth I'm

not sitting on any mountains and I'm I'm on my way so people who join me as students are

basically following you know in the same journey maybe in certain circumstances

I'm a bit further ahead or sometimes I'm a bit behind and but it's definitely

walk along and not walk behind kind of thing yeah my journey I started as a

mover first and then I became a specialist and then I went back to

movement basically so yeah it all started in a young age and some some

Chinese martial arts and developed into some physical sports and

games in school primary school and high school and then I met capoeira and I I

was completely amazed basically by this dis art form and then pursued that for a

good 15 years in the middle somewhere military service and other physical a

physical pursuit and throughout changing and developing and moving between

disciplines and exploring just kind of got the same realization again and again

that there is some thread through all these disciplines something that is

attracting me back and basically it was movement I realized and the next thing

was okay I want to learn movement I want to get better as a mover in a general

way I seeked out a movement teachers and went around the world and looked around

and read a lot of books and there were some people who mentioned the word movement and I went to them and you know

heard myself as a student and they kept on teaching me disciplines another

isolated approach another speciality and I was very disappointed so eventually I

decided okay I'm going to become that person I'm going to become the movement teacher and the next realization after

years and years of trying was it's impossible and with that I stayed

basically because I realized if that's impossible it's a good goal to have in life something that will keep on moving

myself and my students and anybody involved forward that's where I'm at

right now I'm in teaching and learning moving around and trying to try to gain

some more knowledge about this impossible task yes you're still yourself or forever a student I would

prefer I prefer to be a student any day of the week than a teacher and but being

a teacher is part of human culture we are all teachers we we teach all the

time but whether you want it or not somebody asks you for direction in to it you become the teacher you have a

child he looks at you you're a teacher practicing teaching and practicing to

the student the discipleship both of them are extremely important for your development as a movie what is the price

of specialization what do we lose when we specialize we lose humanity first and foremost as humans we we evolved to

become humans as generalist we are the most generalist of all animals we are

able to imitate the ape and imitate the tiger and and we can hold our breath

underwater and we can do everything just a tiny bit we can't really run very fast

we can't really fight very well we can't you know climb as good as other animals

but we can do the most complex and generalize tasks out of all animals and

no animal even come close so speciality the price is humanity the price is your happiness the price is

your fulfillment as a human being it's deep beats it's philosophical but that's

that's we are do you think there is some beauty and fulfillment and some value

Specialization

and specialization in becoming the best at a very specific movement at a particular sport giving your body to you

know dedicating it to that sport that's an interesting thing because as a human race we benefited tremendously from the

work of specialists but those specialists suffered that's a very very

important points like without specialists we would never be here we would never be skyping right now on

these computers and and you know wearing these t-shirts and all kinds of stuff

but those specialists those human beings suffered the result of their highly

specialized nature and we become more and more specialized the reason move

towards being generalist again in the last few years maybe the last decade

there is a bit more talk about that but definitely we are also still

pursuing highly specialized fields if I make a joke in my workshop and I say

nowadays you go to it if you break your you know you break your hand you go to a hand specialist orthopedic surgeon in

five or ten years you'll go to a left hand specialist and the most evident problem is also our

leaders who are experts but now they're required to be generalist leaders of a

lot of stuff and their shitty leaders we keep on having the same problems again

and again because they are ex specialists whether it's a lawyer or a

military person or an economist these are not specialities that allow you the

full grasp of running a country yeah I think I think you put it beautifully that in my specialization might lead to

innovation but you lose the humanity mmm what do you find is the most

underdeveloped range of motion in athletes like what movement is most

restricted in pi level athletes in your experience is there any one that stands

out shoulders any particular other joints well it's it all depends on their

speciality of course in habits the shoulder the glenohumeral joint is the

most hyper mobile joint in the body even when it's restricted it still offers tremendous range of motion compared to

other areas but when it's restricted even if it's just a little bit it can

cause huge problems because we are dependent on that range of motion and

mobility around the glenohumeral joint and the simple reason is because with

the hands humans manipulate that's what we're meant to do with our hands and we

need that complexity around the scapula it's been a few years since I've said it

first that the scapula craves complexity but this complexity around the scapula

and range of motion is so important across the board I've read of your concept of isolate in

are graded and improvised okay describe the role of improvisation in movement

Improvisation

any profession and speciality should arrive at improvisation in the top and

tier the top level and whether you play the violin or you know you box you're

going to reach improvisation improvisation above all is the human condition it's the human the human

ability the highest form of living is improvisation you improvise basically life is improvisation you're born you

die and in between you improvise a shitload of improvisation movement is no

different the thing is people started to isolate concept and some people went the

next level and integrated them they present themselves as improvisation but

actually they're cheating people it's just a bit more integration yet it's

just another integration improvisation open improvisation real improvisation as

we call it that's very rare and that's the most enjoyable state it's also

called the zone it's also called the tunnel you just experience this

beautiful thing to be empty just to let things happen through you as Bruce Lee said I don't hit it hit it just happens

you know and that is improv that's what you need to do with movement if you

aspire for the highest things I like how a guy on reddit described you as IDO

portal may not be the nicest guy in the world but he's a great coach so that nicest

guy part I come from the wrestling world where the goal of a good coach and a

good program is to basically make you quit to break you there's zero patience for people who don't want to put in the

work to work hard do you find that tough love is the best approach to coaching

Tough Love

people whatever their level of ability no not necessarily I don't like the term

tough love because it kind of assumes the it's importance is itself it's not

enough for me it's like that's how that's the best way why that's the best way but on the other hand I don't think

people are made of sugar and I really believe that we've lost a bit side of

you know how resilient we are and another is people don't like the truth

you know it's dishonesty is above all so when people describe me is tough love

it's not because I believe in Tuffle 100% of the people who has been who have

had issues with me on a personal level or through coaching are people who

couldn't accept criticism what I offered you know took it personally weren't able

to deal with it etc I can't even you know in my head find one example of a person I've been

working with who received the criticism worked with it and still complained but

it's always these complainers and who cares complain first and do nothing yes yeah yeah you know it's like

when you go mainstream as we've went to a certain level you have to deal with it

because I'm not operating my elite unit my Special Op unit anymore now it's an

army and I need to accept the fact that I'm gonna meet a lot of slackers a lot of Poindexter's and all kinds of

you know they don't want to work they want to talk about it they want to do this they want to do that they don't

want to hear the truth they don't want to accept criticism or hear how much they suck and I just don't do that so

you know I'll have to accept the fact that from now from now and again you know what I'll have this issue and I'm

sure it will continue you've travelled all over the world you think there's a difference in this aspect in attitudes

in the United States and Israel and other countries big time horse big time

yeah there are many countries where I don't have this issue or very rarely we

have a word in in Hebrew actually it comes from Jay and I think or Yiddish it says touchless

it's like down to it you know the heart of it tough less people are people who

are like no you know directly tell me as it is and this stuff less it

it exists in certain cultures in other cultures it's a lot of chitchat and walk

around and you know I didn't know how to chitchat a few days ago one of my

students told me you know I can't cheat you it's exactly how I felt you know when I first came out of Israel started

to teach around it was Russia thank God and that was so similar to him where I

come from in many ways so no problem but then when I went to the US or Canada I

had a lot of issues with the chitchat with politically correct and walking

around the bush and don't give it to me too harshly you know cover it with a lot of sponges around it soft in the heat

and yeah it's definitely different between various countries and I need

nowadays I need filters which are my my stood my top students were helping me

teach and some of them are great filters in and in certain countries they'll do

much better than me what is perfect practice look like for you so do you believe in the value maybe this applies

more to specialized sports but like I I come from Russia actually and from the

wrestling world where repetition you know putting in ten fifty thousand hundred thousand repetitions on a

specific movement is is how you achieve success do you believe in the value of

that repetition even for generalist framework the repetition is the mother of skill yes there have been those that

corrected and said perfect repetition is the mother of skill well those who

usually say it are those who don't achieve Heights usually usually so I'll

be very frank again I'll be very extremely honest a lot of people talk about perfect perfect perfect but but

life is not perfect itself our surroundings are not perfect and when I

practice and when I move it's never on the perfect conditions it's never with the right optimal blood

sugar level and under the specific you know height of I don't know what and and

riding the wave of super compensation in the perfect way and usually when people try to adhere to that concept in a

perfect way they end up falling off the wagon on the other side don't be don't

be stupid don't just drill yourself into the wall and lose sight of everything it's not black and white the truth is

somewhere in between and it varies between people for me after seventeen

years teaching 18 years now teaching moving seeing people the hardest workers

are usually the elite performers of course some of them are carrying a

certain talent or this or that but it's always with very dedicated practice they

have built up that work capacity through that dedicated practice and they can then move that ability to other

disciplines true in a grappling world I'm not sure how much you're aware of it but Marcel Garcia is one of the Great's

and he believes boldly against the status quo I think that you should only

train jiu-jitsu his sport jiu-jitsu and not do anything else so to achieve

success trained only that but the majority of other athletes in the sport believe that you should do strength and

conditioning programs and all around that so they at least move slightly towards the more generalist framework

what do you think do you think that's value for the generalist mindset for like an elite athlete or should they

Generalist Mindset

just focus on their sport to some level to some level speciality can can reach a

plateau because of lack of general base of the pyramid in some cases but it's

not a very high level of you know Janet generalism nowadays you're you're

practicing against specialists and they devote more and more time to this specialty

when you're doing other stuff so it's a complex rhythm you know and and to each case his own but I'll tell you something

else when you reach the top of your field like marcelo garcia did in BJJ you

stopped being inspired by your own scene you can't gain inspiration knowledge and

motivation from your own scene because you are the leader you're on top of the mountain you have nowhere else to climb

so what you do you look to other scenes and that's where it's really really

valuable to become a bit more generalized yes you mentioned an

interview related to that a very interesting point the many people in the US in particular focus on learning more

than doing so focus too much on acquiring knowledge versus using that knowledge do you struggle this yourself

like how do you approach learning new things versus putting more time into old

things that you've already met Sinead it's not only a u.s. thing or North

American thing it's generally all across the globe all those are more practical people and less practical people you

know in each country has its own orientation habits you know characteristics but it's a good question

you need to be it's kind of being super intelligent and oriented towards the

information but then have this dumbed down practical mind it's like okay now I need

to work you know and having a balance across that and that's probably it that

probably means that you know a certain IQ for example will start to work

against you in certain fields and vice versa so you when you become too much

you know as the Chinese say the man who lives inside his head you start to have

this issue you know you you have a thirst for information great thirst but

information is toxic it's exactly like water water is toxic as well almost all compounds

toxic and then we drink we drink with it we kill ourselves we kill the process

and the knowledge it turns against us and that's a serious problem and that's

the problem of the age of misinformation that we live in it's not only that the

knowledge is toxic even when it's good knowledge now we also have bad knowledge

mostly bad knowledge mostly shitty advice the combination is listen just

people become paralyzed or just you know move from link to link to link with a

you know glazy eyes and just never actually do anything yes I know you

advocate building a huge word capacity so how many hours a day do you think this is also a debate for specialists

how many hours a day do you think is the most a person can train movement

intelligently before becomes not sustainable before their mind becomes

uninspired maybe as you said 24 hours 24 hours 24 hours a day there is a

choreographer in Israel very known choreographer called ohad Naveen he says when you wake up in the morning in bed

between the sheets you can you can practice movement and and is not there

talking about with your partner yeah so even there you can practice you know breathing moving it's it's all the time

around you but serious practice you know practice oriented that you know

repetition and success and building skill and moving from isolation to integration to improvisation in most

disciplines it's around six to eight hours a day some people go more and reach even the

ten hour mark and I've done that for periods of time in the military you go

even further than that other disciplines require less and it's also a highly

individual thing so let's say even within the sports of gymnastics you have a woman like in Nast who trains eight

hours a day and neck to her the same team also winning gold medals at the same level more or less

you have Shawn Johnson training three hours a day and she reached the top of

her field or liquid gold medal in the Olympics so how highly individual this

is very rare to see this three hour gold medal thing but definitely it

exists the difference there might be mental so the question I have is out of

the various elements like mind breathing developing muscular strength or joints

which is the biggest challenge to master as a student a movement highly

individual it depends on the person depends on is orientation some people

never require any form of mental training for example or psychological training especially in fields and like

sports and then team sports yeah so so that aspect is covered they're winners

they're oriented they're focused you know and then other people require help

in that regard some people have great difficulty developing mobility and just the nervous

system is panicked it holds on it protects them too much other people are hyper mobile and have a

difficulty creating tonus and in strength and that is a great challenge

for them and other people are you know great complex learners they can name

they can coordinate complex actions and learn movement very quickly while others are highly limited so it's very

individual for that process of learning that journey is individual to everyone

Listen to your body

so how does one take that journey just listen to your own body now now you can

listen to your body until tomorrow Hypatia you're not hearing anything you

know you're not hearing anything you need to learn you need to create a relationship with your body and you need

the help of of teachers right that's there is only you know a lot of

people say no I'll do it myself then you deny collective knowledge the most

powerful knowledge that mankind holds you know because we're the only animal that have collective knowledge we've

been able to move knowledge across generations and that's how we have reached space build the Internet

you know do all these crazy surgeries and and you know solve you know genetic

issues and etc it's you're not gonna do it by yourself you're just one small

person and we have collected knowledge generations upon generations so listen

to your body that's nice to say most people don't hear it's completely

silent and then you need to start to decipher the signals that the body gives

you and that goes through a practice and learning discipleship and exploring a

lot of different different stuff and it's a highly individual thing nowadays we don't have so much any anymore this

mentor student or teacher disciple relationship but I I really believe in

that I wouldn't be here without my mentors and my teachers the shoulders of

giants that lifted me up I still believe in it in in a way there is no other way

yeah on that do you think that training and learning movement for the majority

of the time is a fundamentally solitary activity or do we gain from like the

presence of others so when you when you think of movement when you're training is most of your training like the

repetitions done alone or with others both and I've trained years you know

alone and with my students and I spend large periods of time alone just

training alone but I also spend a lot of time being in a community in movement is

the best reason for gathering around in a community and you know people for

example nowadays they go do CrossFit or they do yoga what ever and then they have their yoga

friends and they have the real friends that that's you know your yoga friends can be your real friends because

we've been gathering around movement since the age of time creating communities around movement around

hunting gathering dance around the fire we've been moving together nowadays I can recommend move with your loved ones

moved with the people around you you know you join a BJJ Club it's a community you know you go there you meet

you move around you go to a capoeira Club it's a tribe you go to a CrossFit

gym it's a community you go to yoga it's a community you can move with your

children you can move with your dog in the park and it's important to move

together but it can also be done alone and some things are better done alone and some things are better than together

how do you think movement changes from solo movement you know that that whole

Movement

pattern of movement where you're moving alone versus the pattern of movement where there's two people either working

together against each other so together is like dancing partner dancing and against each other is like wrestling or

jiu-jitsu do you think the principles of movement are different for when it's two

people versus one person this is a whole nother world first they spend more time

moving with others against others in martial art because I spend most of my

life in martial arts and less time exploring stuff alone but definitely

there are some concepts that still exist like the quality of movement how you

organize your body in space not in relation to the partner only but first a

BJJ practitioner or or a stand up fighter he needs to organize his body in

relation to space first and then in relation to the partners well so some of

the concepts exist in both while others are very different and you can train

alone or all your life when somebody else is in the equation it's going to change the game completely a major

reason why we are under the fight laboratory we've departed in reality from a lot of

traditional martial arts and the delusions of training alone and doing forms and and repetitive you know

movements alone and then it's a shitstorm and you can't apply anything

and you you don't have any live practice and now we see that and definitely in

the fight game and the practices that stayed very real stayed very dirty in a

way but very real they are the ones who are providing tools for the chaotic

environment of a fight terms of injury how do you treat recover and work around

Injury

injury hmm injuries are a certainty

they're not a learnt the probability injuries and diseases they are also

required as nothing talib one of my biggest inspirations this day is a great

philosopher and in order to to anti fragile eyes to become anti fragile to

become robust to become more than resilient you must be able to enjoy

volatility you must be able to grow from this stuff and so first I oh I said I

said it before and I'll say it again I injure my students this happens and I

can do anything beneficial without it and basically we all get injured

constantly on a micro level a macro level it's part of our lives of course

we don't want to push into meaningless injury and we want to be able to grow

from it an in and basically develop from it how do you train around it how do you

train around it it's a hard question it involves a lot of stuff first and a big

believer in movement as a therapeutic tool movement itself if it offers you

adaptation and it does it's the way out not lack of movement rest

I don't believe in rest I believe in moving which means when I'm resting

I might help on the short term with certain aspects of the injury but at the

same time I'm creating a new problem because there that the adaptive process is taking me somewhere else

I'm not recovering towards movement I'm recovering towards no movement so we

have a problem here now in some cases you must rest and then deal with the

consequences later but in most cases there is a better approach than just

resting in that that requires a lot more taking responsibility which doctors

don't believe in your ability to take responsibility for yourself to be

intelligent and to know the amounts and the levels and that requires some some

form of a knowledge and experience and most people can't be trusted with it so we offer them you know this advice of

like just rest resting stop yeah but but definitely after years and years of working with

people and and taking them through crazy injuries near my right hand or Delia she

she went through a car accident she lost the kidney she broke her back she went through three knee surgeries which my

sister performed by the way nowadays she can move like few people I know on this

planet and and just the answer was always movement movement going back into

movement beautiful continue move continue to move yeah don't move

stupidly don't don't hurt yourself but that's an obvious no I guess not because when I say these things people write a

comment the but the bad people you know yeah but you're gonna injure yourself yeah genius

haha don't go into the injury and and

again deteriorate the escalate the situation of course not you must move

around it and you must be smart in the way that you allow adaptation to take you out like a wave you need to ride the

wave of adaptation out of the out the problem and that's tricky we know

and that's something that we need to educate people on and we need to believe in people's intelligence and ability to

take this responsibility in China where they still have in some areas and they

used to have bone setters they didn't put you in a cast you broke your hand or they they did it through bone setting

and yes they didn't have x-ray so that's a lot more complex to do and not as

successful as nowadays but having said that they did achieve amazing rates of

recovery because these reps that they use and the process allows some form of

movement and that creates an adaptation now take an arm a healthy arm your right

arm put it in a cast for six months take it down the cast what do you see the

observer the arm is basically moving towards death yes it's gotten good at not moving the arm

is great you have weird hairs growing out of it it stinks it really smells and

looks like death because movement is life no movement death we know that we like to just kill your

arm a tiny bit so that so the bones can reform together and then we'll bring it

back to life that's one approach but in other cases you can maintain the life

and the demands on the tissue safely enough at the same time allow the

recovery to happen yes and diet what are

Diet

some diet principles you follow well diet is very individual thing I've

been personally following a Paleolithic a caveman diet for a long time long

before it was called the Paleo diet and since 1997 or even 96 I've been doing

this for a long time I feel great on it still you know growing older and older

and functioning only better and being able to sustain maintain improve but that is

very very individual there is a lot of exploration to be done there what you can withstand how resilient is your

system yes nowadays there is a new movement towards not improving the fuel

sources not improving the quality and the quantities of the food but actually

making the system more resilient so it's able to basically withstand any almost

any quality and source and that's where we have been lacking and we will be

neglecting this area and that's something that and I believe is the latest innovation although it's still

highly misunderstood and a lot of a lot of folks are abusing this concept and

giving really poor advice just to be different just to say I'm not the paleo

guy you know so that's that's a small addition that will get bigger and bigger

I think so it's almost like how you recommend a movement to go outside of

quote-unquote proper alignment this is kind of the diet version of that is going outside of some kind of proper

framework of diet to some level but that's so that was an obvious thing you

know always right the problem is it's not enough because in fact it's more

what I'm suggesting with movement to go outside of the proper alignment it creates an adaptation but what if

that adaptation cannot happen for example a celiac disease person you'll

expose him to gluten and you'll have terrible consequences now maybe if you

can minimize enough the amounts and the dosages you can actually train him out

of tell yak to some level but death adaptational last very very far down the

road he's going to get some gains and then is going to plateau but what if you could take that celiac disease person

put them in the garage fix his mechanisms change his tires change his

engine you know oil him up everything and then put him back on the track as a

new animal and that that is where you know a lot of stuff is happening

nowadays so the genetic part of it and the gut biome and our digestive tract

that is is so so complex and and we discover that you know we live in

symbiosis with all these microorganisms that just are all over skin inside of us

and we live in combination with them and that's how you see some dudes in Brazil

and in Russia walking around with you know 5% body fat eating one cracker for

breakfast one cracker for dinner and you know training BJJ all day long

high-performance fueling with coca-cola and then at the same time you see people

doing everything almost perfectly and still having poor poor performance and

inability and they gain weight with any you know extra calorie or macronutrient

that they brought in because their system is different and it's not only

about genetics it's more about epigenetics and it's more about what

kind of system besides your own DNA what about these organisms that are supposed

to help us and live in symbiosis with you what kind of a system do you have there and that's just two areas and I

think it's going to get it's going to expand more and more in work and we're going to realize that there is a lot to

learn there do you think technology and science is ultimately a positive force for you know you look at movement as as

an element of our humanity do you think technology is taking humanity away or

it's adding to it I'm not smart enough to answer you that man yeah it's a big

question you know it's a I have no idea it's just it's a huge question and I think we're going to

struggle with that question for many generations to come still it definitely

created a lot of positive stuff but also brought tremendous suffering and

problems and perhaps will be the you know the end of us so technology might

have been you know the most terrible thing that ever happened to us who knows yes that beautiful no how can

people join the IDO portal movement if you have a website a hero portal calm

yeah IDO portal calm in phase B we are

on facebook you can find us on Facebook they do aim it or portal method a little

portal I do P ort al you can join the

movement culture on our website and that will lead to some updates coming up soon

you have a beautiful website by the way amazing thanks very much hey thank you very much I've been a very

fortunate to have a great team around me that helped me with that so I saw that you posted a couple of Tom

Waits songs and I even a Bukowski reference on your Facebook page and I

immediately understood something that I think only another fan or maybe I should

say student of weights and Bukowski can understand you don't shy away from the

strange and the profound wherever you can find it maybe that's how one way to put it is there a Tom Waits song that you find

yourself returning to often in your life mmm so many man so many is just that Tom

way you know I I can barely listen to anything else frankly it's been a real issue and Tom Tom Waits is his

discography it's like it it's a lifetime of discoveries I I it's been

accompanying me for years now it's not only it's not you know it's not something you go through very quickly

and I've spent a lot of time on Alice for example and

yeah just so much stuff so much that's always discover also you know I I find

this this weirdness this is eccentric part of things it's so important it's

the only thing really that can be you in many ways because as a culture

we're so blend we're becoming this one thing you know like you walk around in London it looks exactly like Hong Kong

it looks exactly like Tokyo it looks exactly like you know Sydney and we have

this like huge human thing going on which is great and we communicate very

easily but then we lost a lot on our our own stuff there is only one Tom Waits

you know because of his eccentric part because of his you know this this weird

genius and that's why it's so beautiful to me and then I try not to not to shy

away from my own eccentric side and when I was younger I I definitely hit that part more and you know you know guarded

and try to try to be to fit in but that's definitely an important thing I think so you recommend we cultivate the

weird yeah yeah cultivating the words cultivating yourself because that that's

truly you you know everybody's weird everybody there is no Homer Simpson you

know and everybody has this bar everything he'll everybody has this interesting stuff that's what also

interests me when I teach I want to see that weird you know I want to see that weird in your movement I want to see

that weird in you and that then I really met you but most people they hide it and

they don't a lie and they put this perfect picture but it well I'm not

stupid I know it's not perfect you know so just allow the weirdness to come out I think

it's a great lesson yeah from-from weights and and Bukovsky as well or so if you don't mind I'm gonna torture you

or something I would like to close by reading a Bukowski poem roll the dice

I want to force you to listen to it go ahead if you're going to try go all the way

otherwise don't even start this could mean losing girlfriends wives relative's

jobs maybe your mind it could be not eating for three or four days it could mean freezing on a park

bench it could mean jail it could mean division it could mean mockery isolation

isolation is the gift all the others are a test of your endurance of how much you

really want to do it and you'll do it despite rejection and the worst odds and it will be better than anything else you

can imagine if you're going to try go all the way there's no other feeling

like that you will be alone with the gods and the nights will flame with fire you will ride life straight to perfect

laughter it's the only good fight there is amen thanks al thanks for talking to

Daymond thank you so much man for

Summary:
The interview with Ido Portal, a prominent figure in the movement culture, offers a wealth of insights into his philosophy and approach to physical movement, teaching, and the human experience. Here are the key points from the interview:

1. **Holistic Approach to Movement**:
    
    - Ido Portal emphasizes a holistic, generalist approach to movement, transcending the confines of specialized disciplines like gymnastics, martial arts, or Olympic lifting. He believes movement is fundamental to human experience, preceding specialization.
2. **Journey to Generalism**:
    
    - Portal's journey began with early involvement in martial arts, evolving through various physical disciplines. His realization that movement is the common thread across all these led him to seek a generalist path, ultimately deciding to become a movement teacher himself.
3. **Challenges of Generalism**:
    
    - The quest to become a generalist in movement is an ongoing, perhaps impossible goal, which Portal embraces. It's a journey shared with his students, not a fixed destination or a set of absolute truths.
4. **Humanity and Specialization**:
    
    - Portal warns against the loss of humanity and fulfillment when one over-specializes. While specialization has driven technological and societal advancements, it often comes at the individual's expense, leading to a narrow, less fulfilled human experience.
5. **Movement and Community**:
    
    - Movement is not just a solitary activity but also a communal one. Portal values the communal aspect of movement seen in practices like yoga or martial arts, where people come together, forming communities and bonds.
6. **The Role of Improvisation**:
    
    - Improvisation is seen as the pinnacle of any discipline, including movement. It represents the ability to adapt, create, and live in the moment  an expression of the highest form of human ability.
7. **Approach to Coaching and Criticism**:
    
    - Portal believes in honesty and directness in coaching, distancing himself from the notion of 'tough love'. He emphasizes the importance of criticism and feedback for growth, acknowledging that not everyone is receptive to this approach.
8. **Movement and Adaptation**:
    
    - The human body is adaptable and should be exposed to a variety of movements and conditions. Over-specialization can lead to a plateau in performance. Exposure to a range of movements contributes to a broader base of skills and physical capabilities.
9. **Dealing with Injuries**:
    
    - Portal views injuries as opportunities for growth and adaptation. Rest is not always the best response to injury; instead, intelligent, adaptive movement can lead to better recovery and resilience.
10. **Diet and Individuality**:
    
    - Diet is highly individual. Portal follows a Paleolithic diet but acknowledges the need for resilience and adaptability in dietary habits. The relationship with food should be flexible and responsive to individual needs and environmental conditions.
11. **Technology and Humanity**:
    
    - Portal is cautious about the role of technology in human life, recognizing its immense benefits but also acknowledging the potential for it to lead to disconnect and even existential threats.
12. **Cultivating Individuality and Eccentricity**:
    
    - Embracing one's unique, 'weird' qualities is essential for true self-expression and fulfillment. Portal encourages embracing individual eccentricities, believing that they make us authentically human and contribute to genuine connections and learning.

The interview provides a rich tapestry of ideas on movement, teaching, human nature, and the importance of embracing a broad, adaptable, and deeply human approach to life and learning.

----------
