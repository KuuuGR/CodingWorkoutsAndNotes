I discovered that the Lex Fridman Podcast covers some of the most interesting topics, and the people he interviews are incredible. Therefore, I've decided to use his channel as the initial subject for testing language data.
[Lex Clips](https://www.youtube.com/@LexClips/videos) -> Mostly Short
[Lex Fridman](https://www.youtube.com/@lexfridman/videos)

-----
--99--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--98--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--97--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--96--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--95--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--94--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--93--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--92--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--91--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--90--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--89--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--88--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--87--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--86--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--85--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--84--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--83--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--82--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--81--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--80--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--79--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--78--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--77--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--76--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--75--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--74--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--73--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--72--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--71--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--70-- https://www.youtube.com/@lexfridman/videos

-----
Date:
Link:
Transcription:

paste here

----------

-----
--69--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--68--

-----
Date: 2019.04.18
Link: [# Ian Goodfellow: Generative Adversarial Networks (GANs) | Lex Fridman Podcast #19](https://www.youtube.com/watch?v=Z6rxFNMGdn0)
Transcription:

the following is a conversation with Ian good fellow he's the author of the popular textbook on deep learning simply
titled deep learning he coined the term of generative adversarial networks
otherwise known as Ganz and with his 2014 paper is responsible for launching
the incredible growth of research and innovation in this subfield of deep learning he got his BS and MS at
Stanford his PhD at University of Montreal with yoshua bengio and Erin
Kerrville he held several research positions including an open AI Google
brain and now at Apple as the director of machine learning this recording
happened while Ian was still a Google brain but we don't talk about anything specific to Google or any other
organization this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on YouTube
iTunes or simply connect with me on Twitter at lex friedman spelled fri d
and now here's my conversation with Ian good fellow you open your popular deep
Deep learning limitations
learning book with a Russian doll type diagram that shows deep learning is a subset of representation learning which
in turn is a subset of machine learning and finally a subset of AI so this kind
of implies that there may be limits to deep learning in the context of AI so what do you think is the current limits
of deep learning and are those limits something that we can overcome with time
yeah I think one of the biggest limitations of deep learning is that right now it requires really a lot of
data especially labeled data there's some unsupervised and semi-supervised
learning algorithms that can reduce the amount of labeled data you need but they still require a lot of unlabeled data
reinforcement learning algorithms they don't need labels but they need really a lot of experiences as human beings we
don't learn to play pong by failing at pong two million times so just getting
the generalization ability better is one of the most important bottlenecks and the capability of the technology today
and then I guess I'd also say deep learning is like a of a bigger system so far nobody is
really proposing to have only what you'd call deep learning as the entire
ingredient of intelligence you use deep learning as sub modules of other systems
like alphago has a deep learning model that estimates the value function most
reinforcement learning algorithms have a deep learning module that estimates which action to take next but you might
have other components here basically as building a function estimator do you
Function estimators
think it's possible you said nobody is kind of in thinking about this so far but do you think neural networks could
be made to reason in the way symbolic systems did in the 80s and 90s to do
more create more like programs as opposed to functions yeah I think we already see that a little bit I already
kind of think of neural nets as a kind of program I think of deep learning as basically learning programs that have
more than one step so if you draw a flowchart or or if you draw a tensor
flow graph describing your machine learning model I think of the depth of that graph is describing the number of
steps that run in sequence and then the width of that graph is the number of steps that run in parallel now it's been
long enough that we've had deep learning working that it's a little bit silly to even discuss shallow learning anymore but back when I first got involved in AI
when we used machine learning we were usually learning things like support vector machines you could have a lot of
input features to the model and you could multiply each feature by a different weight but all those multiplications were done in parallel to
each other there wasn't a lot done in series I think what we got with deep learning was really the ability to have
steps of a program that run in sequence and I think that we've actually started
to see that what's important with deep learning is more the fact that we have a multi-step program rather than the fact
that we've learned a representation if you look at things like res nuts for
example they take one particular kind of representation and they update it
several times back when deep learning first really took off in the academic world in 2006 when Geoff Hinton
showed that you could train deep belief networks everybody who was under ested in the idea thought of it as each layer
learns a different level of abstraction but the first layer trained on images learn something like edges and the
second layer learns corners and eventually you get these kind of grandmother's cell units that recognize specific objects today I think most
people think of it more as a computer program where as you add more layers you
can do more updates before you output your final number but I don't think anybody believes the layer 150 of the
resin it is a grand grandmother cell and you know layer 100 is contours or
something like that okay so you think you're not thinking of it as a singular representation that keeps building you
think of it as a program sort of almost like a state the representation is a
state of understanding and yeah I think of it as a program that makes several updates and arrives it better and better
understandings but it's not replacing the representation at each step its refining it and in some sense that's a
little bit like reasoning it's not reasoning in the form of deduction but it's reasoning in the form of taking a
thought and refining it and refining it carefully until it's good enough to use do you think and I hope you don't mind
we'll jump philosophical every once in a while do you think of you know a
cognition human cognition or even consciousness as simply a result of this
kind of cincuenta sequential representation learning do you think that can emerge cognition yes I think so
consciousness it's really hard to even define what we mean by that I guess
there's consciousness is often defined as things like having self-awareness and that's relatively easy to turn into
something actionable for a computer scientists the reason about people also defined consciousness in terms of having
qualitative states of experience like qualia and there's all these philosophical problems like could you
imagine jambe who does all the same information processing as a human but
doesn't really have the qualitative experiences that we have that sort of thing I have no idea how to formalize or
turn it into a scientific question I don't know how you could run in experiment to tell whether a person is a
zombie or not and similarly I don't know how you could run an experiment to tell whether an advanced AI system had become conscious
in the sense of qualia or not but in the more practical sense like almost like self attention you think consciousness and cognition
Selfawareness
can in an impressive way emerge from current types of architectures though
yes yeah or or if if you think of consciousness in terms of self-awareness and just making plans based on the fact
that the agent itself exists in the world reinforcement learning algorithms are already more or less forced to model
the agents effect on the environment so that that more limited version of consciousness is already something that
we get limited versions of with reinforcement learning algorithms if they're trained well but you say limited
so the the big question really is how you jump from limited to human level yeah right and whether it's possible you
know the even just building common-sense reasoning seems to be exceptionally difficult so K if we scale things up
forget much better on supervised learning if we get better at labeling forget bigger datasets and the more
compute do you think we'll start to see really impressive things that go from limited to you know something echoes of
human level cognition I think so yeah I'm optimistic about what can happen just with more computation and more data
I do think it'll be important to get the right kind of data today most of the
machine learning systems we train our mostly trained on one type of data for
each model but the human brain we get all of our different senses and we have
many different experiences like you know riding a bike driving a car talking to people reading I think when you get that
kind of integrated data set working with a machine learning model that can actually close the loop and interact we
may find that algorithms not so different from what we have today learn really interesting things when you scale
them up a lot and a large amount of multimodal data so multimodal is really interesting but
Difficult cases
within like you're working adversarial examples so selecting within modal
within up one mode of data selecting better at what are the difficult cases
from which are most useful to learn from oh yeah like could we could you get a whole lot of mileage out of designing a
model that's resistant to adverse fare examples or something like that right yeah question but my thinking on that
has evolved a lot over the last few years one nice thing when I first started to really invest in studying adversarial examples I was thinking of
it mostly as that versus aryl examples reveal a big problem with machine learning and we would like to close the
gap between how machine learning models respond to adversarial examples and how humans respond after studying the
problem more I still think that adversarial examples are important I think of them now more of as a security
liability then as an issue that necessarily shows there something uniquely wrong with machine learning as
opposed to humans also do you see them as a tool to improve the performance of the system not not on the security side
but literally just accuracy I do see them as a kind of tool on that side but
maybe not quite as much as I used to think we've started to find that there's a trade-off between accuracy on
adversarial examples and accuracy on clean examples back in 2014 when I did
the first adversary trained classifier that showed resistance to some kinds of
adversarial examples it also got better at the clean data on M NIST and that's something we've replicated several times
an M NIST that when we train against weak adversarial examples Emnes classifiers get more accurate so far
that hasn't really held up on other data sets and hasn't held up when we train against stronger adversaries it seems
like when you confront a really strong adversary you tend to have to give
something up interesting this is such a compelling idea because it feels it
feels like that's how us humans learn yeah the difficult cases we we try to think of what would we screw up
and then we make sure we fix that yeah it's also in a lot of branches of engineering you do a worst case analysis
and make sure that your system will work in the worst case and then that guarantees that it'll work in all of the
messy average cases that happen when you go out into a really randomized world
you know with driving with autonomous vehicles there seems to be a desire to just look for think I'd viscerally tried
to figure out how to mess up the system and if you can be robust to all those difficult cases then you can it's a hand
waving empirical way to show that your system is yeah yes today most adverse early example
research isn't really focused on a particular use case but there are a lot of different use cases where you'd like
to make sure that the adversary can't interfere with the operation of your system like in finance if you have an
algorithm making trades for you people go to a lot of an effort to obfuscate their algorithm that's both to protect
their IP because you don't want to research and develop a profitable
trading algorithm then have somebody else capture the gains but it's at least partly because you don't want people to
make adversarial examples that fool you our algorithm into making bad trades
or I guess one area that's been popular in the academic literature is speech
recognition if you use speech recognition to hear an audio waveform
and then in turn that into a command that a phone executes for you you don't
want and a malicious adversary to be able to produce audio that gets interpreted as malicious commands
especially if a human in the room doesn't realize that something like that is happening in speech recognition has
Hidden voice commands
there been much success in in being able to create adversarial examples that fool
the system yeah actually I guess the first work that I'm aware of is a paper called hidden voice commands that came
out in 2016 I believe and they were able to show that they could make sounds that
are not understandable by a human but are recognized as the target phrase that
the attacker wants the phone to recognize it as since then things have gotten a little bit better on the
attacker side when worse on the defender side it's become possible to make sounds
that sound like normal speech but are actually interpreted as a different
sentence than the human here's the level of perceptibility of the adversarial perturbation is still kind of high the
when you listen to the recording it sounds like there's some noise in the background just like rustling sounds but
those rustling sounds are actually the adversarial perturbation that makes the phone hear a completely different sentence yeah that's so fascinating
Peter Norvig mention that you're writing the deep learning chapter for the fourth edition of the artificial intelligence
Writing a deep learning chapter
the modern approach book so how do you even begin summarizing the field of deep
learning in a chapter well in my case I waited like a year before I actually
read anything is it even having written a full length textbook before it's still pretty
intimidating to try to start writing just one chapter that covers everything
one thing that helped me make that plan was actually the experience of having ridden the full book before and then
watching how the field changed after the book came out I realized there's a lot of topics that were maybe extraneous in
the first book and just seeing what stood the test of a few years of being published and what seems a little bit
less important to have included now helped me pare down the topics I wanted to cover for the book it's also really
nice now that the field is kind of stabilized to the point where some core ideas from the 1980s are still used
today when I first started studying machine learning almost everything from the 1980s had been rejected and now some
of it has come back so that stuff that's really stood the test of time is what I focused on putting into the book there's
also I guess two different philosophies about how you might write a book one
philosophy is you try to write a reference that covers everything and the other philosophy is you try to provide a high level summary that gives people the
language to understand a field and tells them what the most important concepts are the first deep learning book that I
wrote with Yahshua and Aaron was somewhere between the the two philosophies that it's trying to be both
a reference and an introductory guide writing this chapter for Russell and
Norvig book I was able to focus more on just a concise introduction of the key
concepts and the language you need to read about them more and a lot of cases actually just wrote paragraphs that said here's a rapidly evolving area that you
should pay attention to it's it's pointless to try to tell you what the latest and best version of a you know
learn to learn model is right you know I can I can point you to a paper that's
recent right now but there isn't a whole lot of a reason to delve into exactly what's going on with the latest learning
to learn approach or the latest module produced by learning to learn algorithm you should know that learning to learn
is a thing and that it may very well be the source of the latest and greatest convolutional net or recurrent net
module that you would want to use in your latest project but there isn't a lot of point in trying to summarize exactly which architecture in which
learning approach got to which level of performance so you maybe focus more on the basics of
What is deep learning
the methodology so from back propagation to feed-forward to recur in your
networks convolutional that kind of thing yeah yeah so if I were to ask you I remember I took algorithms and data
structures algorithm there of course remember the professor asked what is an
algorithm and yelled at everybody in a good way that nobody was answering it
correctly everybody knew what the alkyl it was graduate course everybody knew what an algorithm was but they weren't able to answer it well let me ask you in
that same spirit what is deep learning I would say deep learning is any kind of
machine learning that involves learning parameters of more than one consecutive
step so that I mean shallow learning is things where you learn a lot of
operations that happen in parallel you might have a system that makes multiple steps like you might have had designed
feature extractors but really only one step is learned deep learning is anything where you have multiple
operations in sequence and that includes the things that are really popular today like convolutional networks and
recurrent networks but it also includes some of the things that have died out like Bolton machines where we weren't
using back propagation today I hear a lot of people define deep learning as
gradient descent applied to these differentiable functions and I think
that's a legitimate usage of the term it's just different from the way that I use the term myself so what's an example
What is an example of deep learning
of deep learning that is not gradient descent on differentiable functions in
your I mean not specifically perhaps but more even looking into the future what's
your thought about that space of approaches yeah so I tend to think of machine learning algorithms as
decomposed into really three different pieces there's the model which can be
something like a neural nut or a Bolton machine or a recurrent model and I
basically just described how do you take data and how do you take parameters and you know what function do
you use to make a prediction given the data and the parameters another piece of the learning algorithm is the
optimization algorithm or not every algorithm can be really described in terms of optimization but what's the
algorithm for updating the parameters or updating whatever the state of the network is and then the the last part is
the the data set like how do you actually represent the world as it comes into your machine learning system so I
think of deep learning as telling us something about what does the model look like and basically to qualify as deep I
say that it just has to have multiple layers that can be multiple steps in a
feed-forward differentiable computation that can be multiple layers in a graphical model there's a lot of ways
that you could satisfy me that something has multiple steps that are each parameterised separately
I think of gradient descent as being all about that other piece the how do you actually update the parameters piece so
you can imagine having a deep model like a convolutional net and training it with something like evolution or a genetic
algorithm and I would say that still qualifies as deep learning and then in
terms of models that aren't necessarily differentiable I guess Boltzmann machines are probably
the main example of something where you can't really take a derivative and use
that for the learning process but you you can still argue that the model has
many steps of processing that it applies when you run inference in the model so that's the steps of processing that's
What could an alternative direction of training neural networks look like
key so geoff hinton suggests that we need to throw away back prop back propagation and start all over what do
you think about that what could an alternative direction of training nil networks look like I don't know that
back propagation is going to go away entirely most of this time when we decide that a machine learning algorithm
isn't on the critical path to research for improving AI the algorithm doesn't
die it just becomes used for some specialized set of things a lot of algorithms like logistic
regression don't seem that exciting to AI researchers who are working on things
like speech recognition or autonomous cars today but there's still a lot of use for logistic regression and things
like analyzing really noisy data and medicine and finance or making really
rapid predictions in really time-limited contexts so I think I think back propagation and gradient descent are
around to stay but they may not end up being everything that we need to get to
real human level or superhuman AI are you optimistic about us discovering
Are you optimistic about us discovering something better
you know back propagation has been around for a few decades so I optimistic bus about us as a
community being able to discover something better yeah I am I think I think we likely will find something that
works better you could imagine things like having stacks of models where some
of the lower level models predict parameters of the higher level models and so at the top level you're not
learning in terms of literally calculating gradients but just predicting how different values will perform you can kind of see that already
in some areas like Bayesian optimization where you have a Gaussian process that predicts how well different parameter
values will perform we already used those kinds of algorithms for things like hyper parameter optimization and in
general we know a lot of things other than back prep that work really well for specific problems the main thing we
haven't found is a way of taking one of these other non back based algorithms and having it really advanced the
state-of-the-art on an AI level problem right but I wouldn't be surprised if eventually we
find that some of these algorithms that even the ones that already exists not even necessarily a new one we might find
some way of customizing one of these algorithms to do something really
interesting at the level of cognition or or the the level of I think one system
that we really don't have working quite right yet is like short-term memory we
have things like LST M's they're called long short-term memory they still don't do quite what a human
does with short-term memory like gradient descent to learn a
specific fact has to do multiple steps on that fact like if I I tell you the
meeting today is at 3 p.m. I don't need to say over and over again it's at 3 p.m. it's not 3 p.m. it's at 3 p.m. it's
a 3 p.m. right for you to do a gradient step on each one you just hear it once and you remember it there's been some
work on things like self attention and attention like mechanisms like the neural Turing machine that can write to
memory cells and update themselves with facts like that right away but I don't think we've really nailed it yet and
that's one area where I'd imagine that new optimization algorithms are
different ways of applying existing optimization algorithms could give us a way of just lightning-fast updating the
state of a machine learning system to contain a specific fact like that without needing to have it presented
over and over and over again so some of the success of symbolic systems in the
How do we build knowledge representation
80s is they were able to assemble these kinds of facts better but dude there's a
lot of expert input required and it's very limited in that sense do you ever look back to that as something that will
have to return to eventually sort of dust off the book from the shelf and think about how we build knowledge
representation knowledge place well we have to use graph searches searches right and like first-order logic and
entailment and things like that a thing yeah exactly in my particular line of work which has mostly been machine learning security
and and also generative modeling I haven't usually found myself moving in
that direction for generative models I could see a little bit of it could be useful if you had something like a
differentiable knowledge base or some other kind of knowledge base where it's possible for some of our fuzzier machine
learning algorithms to interact with the knowledge base immanuel Network is kind of like that it's a differentiable
Differentiable knowledge bases
knowledge base of sorts yeah but if if we had a really easy way of giving
feedback to machine learning models that would clearly helped a lot with with generative models and so you could
imagine one way of getting there would be get a lot better at natural language processing but another way of getting there would be take some kind of
knowledge base and figure out a way for it to actually interact with a neural network being able to have a chat within
y'all network yes so like one thing in generative models we see a lot today is you'll get things like faces that are
not symmetrical like like people that have two eyes that are different colors and I mean there are people with eyes
that are different colors in real life but not nearly as many of them as you tend to see in the machine learning
generated data so if if you had either a knowledge base that could contain the fact people's faces are generally
approximately symmetric and eye color is especially likely to be the same on both sides being able to just inject that
hint into the machine learning model without it having to discover that itself after studying a lot of data it
would be a really useful feature I could see a lot of ways of getting there without bringing back some of the 1980s
technology but I also see some ways that you could imagine extending the 1980s technology to play nice with neural nets
and have it help get there awesome so you talked about the story of you coming up with idea of Gans at a bar
GANs at a bar
with some friends you were arguing that this you know Gans would work Jenner of
adversarial networks and the others didn't think so then he went home at midnight coated up and it worked so if I
was a friend of yours at the bar I would also have doubts it's a really nice idea but I'm very skeptical that it would
work what was the basis of their skepticism what was the basis of your intuition why he should work I don't
want to be someone who goes around promoting alcohol for the science in this case I do actually think that
drinking helped a little bit mm-hmm when your inhibitions are lowered you're more willing to try out things that you
wouldn't try out otherwise so I I have noticed it in general that I'm less
prone to shooting down some of my own ideas when I'm when I have had a little bit to drink I think if I had had that
idea at lunch time yeah I probably would have thought it it's hard enough I mean one neural net you can't train a second
neuron that in the inner loop of the outer neural net that was basically my friends action was that trying to train two
neural nets at the same time would be too hard so it was more about the training process unless so my skepticism
Deep Boltzmann machines
would be you know I'm sure you could train it but the thing would converge to
would not be able to generate anything reasonable and any kind of reasonable realism yeah so so part of what all of
us were thinking about when we had this conversation was deep Bolton machines which a lot of us in the lab including
me were a big fan of deep bolts and machines at the time they involved two
separate processes running at the same time one of them is called the positive
phase where you load data into the model and tell the model to make the data more
likely the owners called the negative phase where you draw samples from the model and tell the model to make those
samples less likely in a deep Bolton machine it's not trivial to generate a
sample you have to actually run an iterative process that gets better and better samples coming closer and closer to the
distribution the model represents so during the training process you're always running these two systems at the
same time one that's updating the parameters of the model and another one that's trying to generate samples from the model and they worked really well on
things like Amnesty a lot of us in the lab including me had tried to get the Boltzmann machines to scale past em
inist to things like generating color photos and we just couldn't get the two processes to stay synchronized so when I
had the idea for Gans a lot of people thought that the discriminator would have more or less the same problem as the negative phase in the Boltzmann
machine that trying to train the discriminator in the inner loop you just couldn't get it to keep up with the
generator and the outer loop and that would prevent it from converging to anything useful yeah I share that
intuition yeah what turns out to not be the case a lot of the time with machine
learning algorithms it's really hard to predict ahead of time how well they'll actually perform you have to just run the experiment and see what happens
and I would say I still today don't have like one factor I can put my finger on
it say this is why ganz worked for photo generation and deep Boltzmann machines
don't there are a lot of theory papers showing that under some theoretical settings the
the gun algorithm does actually converge but those settings are restricted enough
that they don't necessarily explain the whole picture in terms of all the results that we see in practice so
What are GANs
taking a step back can you in the same way as we talked about deep learning can you tell me what generative adversarial
networks are yeah so generative adversarial networks are a particular kind of generative model a generative
model is a machine learning model that can train on some set of data like so you have a collection of photos of cats
and you want to generate more photos of cats or you want to estimate a
probability distribution over cats so you can ask how likely it is that some new image is a photo of a cat ganzar one
way of doing this some generative models are good at creating new data other generative
models are good at estimating that density function and telling you how likely particular pieces of data are to
come from the same distribution as a training data gans are more focused on generating samples rather than
estimating the density function there are some kinds of games like flow gun that can do both but mostly guns are
about generating samples of generating new photos of cats that look realistic and they do that completely from scratch
it's analogous to human imagination when again creates a new image of a cat it's
using a neural network to produce a cat that has not existed before it isn't
doing something like compositing photos together you're not you're not literally taking the eye off of one cat on the ear
off of another cat it's it's more of this digestive process where the the neural net trains on a lot of data and
comes up with some representation of the probability distribution and generates entirely new cats there are a lot of
different ways of building a generative model what's specific against is that we have a two-player game in the game
theoretic sense and as the players in this game compete one of them becomes able to generate
realistic data the first player is called the generator it produces output data such as just images for example and
at the start of the learning process it'll just produce completely random images the other player is called the
discriminator the discriminator takes images as input and guesses whether they're real or fake you train it both
on real data so photos that come from your training set actual photos of cats and you try to say that those are real
you also train it on images that come from the generator network and you train
it to say that those are fake as the two players compete in this game the discriminator tries to become better at
recognizing where their images are real or fake and the generator becomes better at fooling the discriminator into
thinking that its outputs are are real and you can analyze this through the
language of game theory and find that there's a Nash equilibrium where the generator has captured the correct
probability distribution so in the cat example it makes perfectly realistic cat photos and the discriminator is unable
to do better than random guessing because all the all the samples coming from both the data and the generator
look equally likely to have come from either source so do you ever do sit back
How do GANs work
and does it just blow your mind that this thing works so from very so it's
able to estimate that density function enough to generate generate realistic images I mean does it yeah do you ever
sit back yeah how does this even why this is quite incredible especially
where Gant's have gone in terms of realism yeah and and not just to flatter my own work but generative models all of
them have this property that if they really did what we asked them to do they would do nothing but memorize the
training data right some models that are based on maximizing the likelihood the
way that you obtain the maximum likelihood for a specific training set is you assign all of your probability
mass to the training examples and nowhere else forgets the game is played using a
training set so the way that you become unbeatable in the game is you literally memorize training examples
one of my former interns wrote a paper his name is a Vaishnav nagarajan and he
showed that it's actually hard for the generator to memorize the training data hard in a statistical learning theory
sense that you can actually create reasons for why it would require quite a
lot of learning steps and and a lot of observations of of different latent
variables before you could memorize the training data that still doesn't really explain why when you produce samples
that are new why do you get compelling images rather than you know just garbage that's different from the training set
and I don't think we really have a good answer for that especially if you think about how many possible images are out
there and how few images the generative model sees during training it seems just
unreasonable that generative models create new images as well as they do especially considering that we're
basically training them to memorize rather than generalize I think part of the answer is there's a paper called
deep image prior where they show that you can take a convolutional net and you don't even need to learn the parameters
of it at all you just use the model architecture and it's already useful for things like in painting images I think that shows us
that the convolutional network architecture captures something really important about the structure of images
and we don't need to actually use learning to capture all the information coming out of the convolutional net that
would that would imply that it would be much harder to make generative models in other domains so far we're able to make
reasonable speech models and things like that but to be honest we haven't actually explored a whole lot of
different data sets all that much we don't for example see a lot of deep
learning models of like biology datasets where you have lots of microarrays
measuring the amount of different enzymes and things like that so we may find that some of the progress that
we've seen for images and speech turns out to really rely heavily on the model architecture and we were able to do what
we did for vision by trying to reverse-engineer the human visual system and
maybe it'll turn out that we can't just use that same trick for arbitrary kinds of data all right so there's aspects of
Types of GANs
the human vision system the hardware of it that makes it without learning
without cognition just makes it really effective at detecting the patterns we've seen the visual world yeah that's
yeah that's really interesting what in a big quick overview in your view in your
view what types of Gans are there and what other generative models besides games are there yeah so it's maybe a
little bit easier to start with what kinds of generative models are there other than Gans so most generative models are likelihood
based where to train them you have a model that tells you how how much
probability it assigns to a particular example and you just maximize the probability assigned to all the training
examples it turns out that it's hard to design a model that can create really
complicated images or really complicated audio waveforms and still have it be
possible to estimate the the likelihood function from a computational point of
view most interesting models that you would just write down intuitively it turns out that it's almost impossible to
calculate the amount of probability they assign to a particular point so there's a few different schools of generative
models in the likelyhood family one approach is to very carefully design the
model so that it is computationally tractable to measure the density it assigns to a particular point so there
are things like auto regressive models like pixel CN n those basically break
down the probability distribution into a product over every single feature so for
an image you estimate the probability of each pixel given all of the pixels that came before it hmm there's tricks where
if you want to measure the density function you can actually calculate the density for all these pixels more or
less in parallel generating the image still tends to require you to go one pixel at a time and that can be very
slow but there again tricks for doing this in a hierarchical pattern where you can keep the runtime under control or the
quality of the images it generates putting runtime aside pretty good
they're reasonable yeah the I would say a lot of the best results are from Gans
these days but it can be hard to tell how much of that is based on who's
studying which type of algorithm if that makes sense the amount of effort invest in it but yeah or like the kind of
expertise so a lot of people who've traditionally been excited about graphics or art and things like that have gotten interested in Gans and to
some extent it's hard to tell our Gans doing better because they have a lot of graphics and art experts behind them or
our Gans doing better because they're more computationally efficient or our
Gans doing better because they prioritize the realism of samples over the accuracy of the density function I
think I think all of those are potentially valid explanations and it's it's hard to tell so can you give a
History of GANs
brief history of Gans from 2014 we paid
for 13 yeah so a few highlights in the first paper we just showed that Gans
basically work if you look back at the samples we had now they looked terrible on the CFR 10 dataset you can't even
recognize objects in them your papers I will use CFR 10 we use em NIST which is
little handwritten digits we used the Toronto face database which is small grayscale photos of faces
we did have recognizable faces my colleague Bing Xu put together the first again face model for that paper we also
had the CFR 10 dataset which is things like very small 32 by 32 pixels of cars
and cats and dogs for that we didn't get recognizable objects but all the deep
learning people back then we're really used to looking at these failed samples and kind of reading them like tea leaves
right and people who are used to reading the tea leaves recognize that our tea
leaves at least look different right maybe not necessarily better but there was something unusual about them
and that got a lot of us excited one of the next really big steps was lap gown
by Emily Denton and seemeth chintala at Facebook AI research where they actually
got really good high-resolution photos working with gans for the first time they had a complicated system where they
generated the image starting at low res and then scaling up to high res but they were able to get it to work and then in
2015 I believe later that same year palek Radford and sumh intelli and Luke
Metz published the DC gain paper which it stands for deep convolutional again
it's kind of a non unique name because these days basically all gans and even
some before that were deep in convolutional but they just kind of picked a name for a really great recipe
where they were able to actually using only one model instead of a multi-step process actually generate realistic
images of faces and things like that that was sort of like the beginning of
the Cambrian explosion of gans like you know once once you got animals that had a backbone you suddenly got lots of
different versions of you know like fish and right they have four-legged animals and things like that so so DC Gann
became kind of the backbone for many different models that came out used as a baseline even still yeah yeah and so
from there I would say some interesting things we've seen are there's a lot you can say about how just the quality of
standard image generation ganz has increased but what's also maybe more interesting on an intellectual level is
how the things you can use guns for has also changed one thing is that you can
use them to learn classifiers without having to have class labels for every
example in your your training set so that's called semi-supervised learning my colleague at open AI Tim Solomon's
who's at at brain now wrote a paper called improved techniques for training guns I'm a co-author on this paper but I
can't claim any credit for this particular part one thing he showed in the paper is that you can take the gun
discriminator and use it as a classifier that actually tells you you know this image is a cat this image is a dog this
image is a car this image is a truck and so and not just to say whether the image is real or fake but if it is real to say
specifically what kind of object it is and he found that you can train these classifiers with far fewer labeled
examples learn traditional classifiers so a few supervised based on also not
Semisupervised GANs
just your discrimination ability but your ability to classify you're going to do much you're going to convert much
faster to being effective at being a discriminator yeah so for example for
the emne status set you want to look at an image of a handwritten digit and say whether it's a 0 a 1 or 2 and so on
to get down to less than 1% accuracy required around 60,000 examples until
maybe about 2014 or so in 2016 with this semi-supervised degan project tim was
able to get below 1% error using only a hundred labeled examples so that was
about a 600 X decrease in the amount of labels that he needed he's still using more images in that but he doesn't need
to have each of them labeled as you know this one's a 1 this one's a 2 this one's a 0 and so on then to be able to for
Class labels
Ganz to be able to generate recognizable objects so object for a particular class you still need labelled data because you
need to know what it means to be a particular class cat dog how do you
think we can move away from that yeah some researchers at brain Zurich actually just released a really great
paper on semi-supervised de Gans whether their goal isn't to classify its to make
recognizable objects despite not having a lot of label data they were working off of deep minds big gun project and
they showed that they can match the performance of began using only 10% I
believe of the of the labels big gun was trained on the image net dataset which is about 1.2 million images and had all
of them labelled this latest project from brain Zurich shows that they're able to get away with only having about
10% of the of the images labeled and they do that essentially using a
clustering algorithm where the discriminator learns to assign the objects to groups and then this
understanding that objects can be grouped into you know similar types helps it to form more realistic ideas of
what should be appearing in the image because it knows that every image it creates has to come from one of these
archetypal groups rather than just being some arbitrary image if you train again
with no class labels you tend to get things that look sort of like grass or water or brick or dirt but but without
necessarily a lot going on in them and I think that's partly because if you look at a large image net image the object
doesn't necessarily occupy the whole image and so you learn to create realistic sets of pixels but you don't
necessarily learn that the object is the star of the show and you want it to be in every image you make yeah you've
Zebra cycle
heard you talk about the the horse the zebra cycle Gann mapping and how it
turns out again thought provoking that horses are usually on grass and zebras
are usually on drier terrain so when you're doing that kind of generation you're going to end up generating
greener horses or whatever so those are connected together it's not just yeah
yeah be able to you're not able to segment yeah it's generating the segments away
so there are other types of games you come across in your mind that neural
networks can play with each other to to to be able to solve problems yeah the
the one that I spend most of my time on is insecurity you can model most
interactions as a game where there's attackers trying to break your system and you order the defender trying to
build a resilient system there's also domain adversarial learning which is an
approach to domain adaptation that looks really a lot like Ganz the the author's had the idea before the game paper came
out their paper came out a little bit later and you know they they're very
nice and sighted again paper but I know that they actually had the idea before I came out domain adaptation is
when you want to train a machine learning model in 1:1 setting called a domain and then deploy it in another
domain later and he would like it to perform well in the new domain even though the new domain is different from
how it was trained so for example you might want to train on a really clean
image data set like image net but then deploy on users phones where the user is taking you know pictures in the dark or
pictures while moving quickly and just pictures that aren't really centered or composed all that well
when you take a normal machine learning model it often degrades really badly when you move to the new domain because
it looks so different from what the model was trained on domain adaptation algorithms try to smooth out that gap
and the domain adverse oral approach is based on training a feature extractor where the features have the same
statistics regardless of which domain you extracted them on so in the domain adversarial game you have one player
that's a feature extractor and another player that's a domain recognizer the domain recognizer wants to look at
the output of the feature extractor and guess which of the two domains oh the features came from so it's a lot like
the real versus fake discriminator and ends and then the feature extractor you
can think of as loosely analogous to the generator in games except what's trying to do here is both fool the domain
recognizer and two not knowing which domain the data came from and also extract features that are good for
classification so at the end of the day you can in in the cases where it works
out you can actually get features that work about the same in both domains
sometimes this has a drawback where in order to make things work the same in both domains it just gets worse at the
first one but there are a lot of cases where it actually works out well on both do you think gas being useful in the
Data augmentation
context of data augmentation yeah one thing you could hope for with Kenz is you could imagine I've got a limited
training set and I'd like to make more training data to train something else like a classifier you could train Magan
on the training set and then create more data and then maybe the classifier would
perform better on the test set after training on those big ERG and generated data set so that's the simplest version
of of something you might hope would work I've never heard of that particular approach working but I think there's
some there's some closely related things that that I think could work in the
future and some that actually already have worked so if you think a little bit about what we'd be hoping for if we use the gun to make more training data we're
hoping that again we'll generalize to new examples better than the classifier would have generalized if it was trained
on the same buddy at us and I don't know of any reason to believe that the Gann would generalize better than the classifier would but
what we might hope for is that the Gann could generalize differently from a specific classifier so one thing I think
is worth trying that I haven't personally tried but someone could try is what have you trained a whole lot of
different generative models on the same training set create samples from all of them and then train a classifier on that
because each of the generative models might generalize in a slightly different way they might capture many different
axes of variation that one individual model wouldn't and then the classifier can capture all of those ideas by
training in all of their data so we'd be a little bit like making an ensemble of classifiers and I say oh of gans
yeah in a way I think that could generalize better the other thing that gans are really good for is not
necessarily generating new data that's exactly like what you already have but by generating new data that has
different properties from the data you already had one thing that you can do is you can create differentially private
data so suppose that you have something like medical records and you don't want to train a classifier on the medical
records and then publish the classifier because someone might be able to reverse-engineer some of the medical records you trained on there's a paper
from Casey greens lab that shows how you can train again using differential privacy and then the samples one again
still have the same differential privacy guarantees as the parameters that again so you can make fake patient data for
other researchers to use and they can do almost anything they want with that data because it doesn't come from real people
and the differential privacy mechanism gives you clear guarantees on how much
the original people's data has been protected that's really interesting actually I haven't heard you talk about
Fairness
that before in terms of fairness I've seen from triple AI your talk
how can an adversarial machine learning help models be more fair with respect to
sensitive variables yeah there was a paper from Amos Torquay's lab about how
to learn machine learning models that are incapable of using specific variables so to say for example you
wanted to make predictions that are not affected by gender it isn't enough to just leave gender out
of the input to the model you can often infer gender from a lot of other characteristics like say that you have
the person's name but you're not told their gender well right if if their name is Ian they're kind of obviously a man
so what you'd like to do is make a machine learning model that can still take in a lot of different attributes
and make a really accurate informed prediction but be confident that it
isn't reverse engineering gender or another sensitive variable internally you can do that using something very
similar to the domain adversarial approach where you have one player that's a feature extractor and another
player that's a feature analyzer and you want to make sure that the feature analyzer is not able to guess the value
of the sensitive variable that you're trying to keep private right that's yeah I love this approach so we'll yeah with
the with the feature you're not able to infer right this sensitive variables
yeah brilliant it's quite quite brilliant and simple actually another way I think that Ganz in particular
could be used for fairness would be to make something like a cycle again where you can take data from one domain and
convert it into another we've seen cycle again turning horses into zebras we've seen other unsupervised gains made by
Ming Yue Lu doing things like turning day photos into night photos I think for
fairness you could imagine taking records for people in one group and transforming them into analogous people
in another group and testing to see if they're they're treated equitably across those two groups there's a lot of things
that be hard to get right to make sure that the conversion process itself is fair and I don't think it's anywhere
near something that we could actually use yet but if you could design that conversion process very carefully it might give you a way of doing audits
where you say what if we took people from this group converted them into equivalent people in another group does
the system actually treat them how it ought to that's also really interesting
you know in a popular in popular press and in general in our imagination you
think well gangs are able to generate data and use to think about deep fakes or being able
to sort of maliciously generate data that fakes the identity of other people
is this something of a concern to you is this something if you look 10 20 years into the future is that something that
pops up in your work in the work of the community that's working on generating models I'm a lot less concerned about 20
years from now than the next few years I think there will be a kind of bumpy cultural transition as people encounter
this idea that there can be very realistic videos and audio that aren't real I think 20 years from now people
will mostly understand that you shouldn't believe something is real just because you saw a video of it people
will expect to see that it's been cryptographically signed or or have some
other mechanism to make them believe the the content is real there's already
people working on this like there's a startup called true pic that provides a lot of mechanisms for authenticating
that an image is real there they're maybe not quite up to having a state actor try to to evade their their
verification techniques but it's something people are already working on and I think we'll get right eventually
so you think authentication will will eventually went out so being able to
authenticate that this is real and this is not yeah as opposed to gas just
getting better and better or generative models being able to get better and better to where the nature of what is
real I don't think we'll ever be able to look at the pixels of a photo and tell
you for sure that it's real or not real and I think it would actually be
somewhat dangerous to rely on that approach too much if you make a really good fake detector and then someone's
able to fool your fake detector and your fake detector says this image is not fake then it's even more credible than
if you've never made a fake detector in the first place what I do think we'll get to is systems
that we can kind of use behind the scenes for to make estimates of what's going on and maybe not like use them in
court for a definitive analysis I also think we will likely get better
authentication systems where you know if a match every phone cryptographically signs
everything that comes out of it you wouldn't go to conclusively tell that an image was real but you would be able to
tell somebody who knew the appropriate private key for this phone was actually
able to sign this image and upload it to this server at this timestamp so you
could imagine maybe you make phones that have the private keys Hardware embedded in them if like a State Security Agency
really wants to infiltrate the company they could probably you know plant a private key of their choice or break
open the chip and learn the private key or something like that but it would make it a lot harder for an adversary with
fewer resources to fake things most of us yeah okay okay so you mentioned the beer and the bar and the new ideas you
were able to implement this or come up with this new idea pretty quickly and implement it pretty quickly do you think
there are still many such groundbreaking ideas and deep learning that could be developed so quickly yeah I do think
that there are a lot of ideas that can be developed really quickly guns were probably a little bit of an outlier on
the whole like one-hour timescale right but just in terms of a like low resource
ideas where you do something really different on the algorithm scale and get a big payback I think it's not as likely
that you'll see that in terms of things like core machine learning technologies like a better classifier or a better
reinforcement learning algorithm or a better generative model if I had the gun idea today it would be a lot harder to
prove that it was useful than it was back in 2014 because I would need to get
it running on something like image net or celibate high resolution you know
those take a while to train you couldn't you couldn't train it in an hour and know that it was something really new
and exciting back in 2014 shredding an amnesty was enough but there are other
areas of machine learning where I think a new idea could actually be developed
really quickly with low resources what's your intuition about what areas of machine learning are ripe for this yeah
so I think fairness and interpretability our areas where we just really don't
have any idea how anything should be done yet like for interpretability I don't think we even have the right definitions and
even just defining a really useful concept you don't even need to run any experiments could have a huge impact on
the field we've seen that for example in differential privacy that uh Cynthia Dworkin her collaborators made this
technical definition of privacy where before a lot of things are really mushy and then with that definition you could
actually design randomized algorithms for accessing databases and guarantee that they preserved individual people's
privacy in a in like a mathematical quantitative sense right now we all talk
a lot about how interpretable different machine learning algorithms are but it's really just people's opinion and
everybody probably has a different idea of what interpretability means in their head if we could define some concept
related to interpretability that's actually measurable that would be a huge leap forward even without a new
algorithm that increases that quantity and also once once we had the definition
of differential privacy it was fast to get the algorithms that guaranteed it so you could imagine once we have
definitions of good concepts and interpretability we might be able to provide the algorithms that have the
interpretability guarantees quickly to what do you think it takes to build a
system with human level intelligence as we quickly venture into the philosophical so artificial general
intelligence what do you think I I think that it definitely takes better
environments than we currently have for training agents that we want them to have a really wide diversity of
experiences I also think it's going to take really a lot of computation it's
hard to imagine exactly how much so you're optimistic about simulation simulating a variety of environments is
the path forward I think it's a necessary ingredient yeah I don't think
that we're going to get to artificial general intelligence by training on fixed datasets or by thinking really
hard about the problem I think that the the agent really needs to interact and have a variety of
experiences within the same lifespan and today we have many different models that
can each do one thing and we tend to train them on one data set or one RL environment sometimes they're actually
papers about getting one set of parameters to perform well in many different RL environments but we don't
really have anything like an agent that goes seamlessly from one type of experience to another and and really
integrates all the different things that it does over the course of its life when we do see multi agent environments they
tend to be there are so many multi environment agents they tend to be similar environments like all of them
are playing like an action based video game we don't really have an agent that goes from you know playing a video game
to like reading The Wall Street Journal to predicting how effective a molecule
will be as a drug or something like that what do you think is a good test for intelligence in you view it's been a lot
of benchmarks started with the with Alan Turing a natural conversation being good
being a good benchmark for intelligence what what are what would you and good
fellows sit back and be really damn impressed if a system was able to accomplish something that doesn't take a
lot of glue from human engineers so imagine that instead of having to go to
the CFR website and download CFR 10 and then write a Python script to parse it
and all that you could just point an agent at the CFR 10 problem and it
downloads and extracts the data and trains a model and starts giving you predictions I feel like something that
doesn't need to have every step of the pipeline assembled for it it definitely
understands what it's doing is Auto ml moving into that direction are you thinking wave and bigger autosomal has
mostly been moving toward once we've built all the glue can the machine
learning system to design the architecture really well so I'm we're saying like
if something knows how to pre-process the data so that it successfully accomplishes the task then it would be
very hard to argue that it doesn't truly understand the task in some fundamental sense and I don't necessarily know that that's
like the philosophical definition of intelligence but that's something that would be really cool to build that would be really useful and would impress me
and would convince me that we've made a step forward in real AI so you give it like the URL for Wikipedia and then next
day expected to be able to solve CFR 10 or like you type in a paragraph
explaining what you want it to do and it figures out what web searches it should run and downloads all the whole
unnecessary ingredients so you have a very clear calm way of speaking no arms
easy to edit I've seen comments for both you and I have been identified as both
potentially being robots if you have to prove to the world that you are indeed human how would you do it but I can
understand thinking that I'm a robot it's the flipside yeah touring test I
think yeah yeah the proof prove your human test I mean I lecture so you have
to is there something that's truly unique in your mind I suppose it doesn't
go back to just natural language again just being able to so proving proving that I'm not a robot with today's
technology yeah that's pretty straightforward too like my conversation today hasn't veered
off into you know talking about the stock market or something because in my training data but I think it's more
generally trying to prove that something is real from the content alone it was incredibly hard that's one of the main things I've gotten out of my can
research that you can simulate almost anything and so you have to really step
back to a separate channel to prove that slang is real so like I guess I should have had myself stamped on a blockchain
when I was born or something but I didn't do that so according to my own research methodology there's just no way
to know at this point so what last question problem stands all for you that you're really excited about
challenging in the near future so I think resistance to adversarial examples figuring out how to make machine
learning secure against an adversary who wants to interfere it in control with it is one of the most important things
researchers today could solve in all domains in image language driving in I
guess I'm most concerned about domains we haven't really encountered yet like like imagine twenty years from now when
we're using advanced day eyes to do things we haven't even thought of yet like if you ask people what are the
important problems in security of phones in in like 2002 I don't think we would
have anticipated that we're using them for you know nearly as many things as we're using them for today I think it's
going to be like that with AI that you can kind of try to speculate about where it's going but really the business opportunities that end up taking off
would be hard to predict ahead of time well you can predict ahead of time is
that almost anything you can do with machine learning you would like to make sure that people can't get it to do what
they want rather than what you want just by showing it a funny QR code or a funny input pattern and you think that
the set of methodology to do that can be bigger than you want domain and that's I think so yeah yeah like one methodology
that I think is not not a specific methodology but like a category of
solutions that I'm excited about today is making dynamic models that change every time they make a prediction so
right now we tend to train models and then after they're trained we freeze them and we just use the same rule to
classify everything that comes in from then on that's really a sitting duck from a security point of view if you
always output the same answer for the same input then people can just run
inputs through until they find a mistake that benefits them and then they use the same mistake over and over and over again I think having a model that
updates its predictions so that it's harder to predict what you're going to get will make it harder for the for an
adversary to really take control of the system and make it do what they want it to do yeah models that maintain a bit of
a sense of mystery and bought them because they always keep changing yeah and thanks so much for talking today it
was awesome thank you for coming in that's great to see you
you

----------

-----
--67--

-----
Date: 2019.04.12
Link: [# Elon Musk: Tesla Autopilot | Lex Fridman Podcast #18](https://www.youtube.com/watch?v=dEv99vxKjVI)
Transcription:

- The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink,
and a co-founder of several other companies. This conversation is part of the Artificial Intelligence Podcast.
This series includes leading researchers in academia and industry, including CEOs and CTOs of automotive,
robotics, AI and technology companies. This conversation happened after the release
of the paper from our group at MIT on driver functional vigilance during use of Tesla's Autopilot.
The Tesla team reached out to me offering a podcast conversation with Mr. Musk. I accepted with full control of questions I could ask
and the choice of what is released publicly. I ended up editing out nothing of substance.
I've never spoken with Elon before this conversation, publicly or privately. Neither he nor his companies have any influence
on my opinion, nor on the rigor and integrity of the scientific method that I practice
in my position at MIT. Tesla has never financially supported my research and I've never owned a Tesla vehicle,
and I've never owned Tesla stock. This podcast is not a scientific paper,
it is a conversation. I respect Elon as I do all other leaders and engineers I've spoken with.
We agree on some things and disagree on others. My goal, as always with these conversations, is to understand the way the guest sees the world.
One particular point of disagreement in this conversation was the extent to which camera-based driver monitoring
will improve outcomes and for how long it will remain relevant for AI-assisted driving.
As someone who works on and is fascinated by human-centered artificial intelligence,
I believe that, if implemented and integrated effectively, camera-based driver monitoring is likely to be of benefit
in both the short term and the long term. In contrast, Elon and Tesla's focus
is on the improvement of Autopilot such that its statistical safety benefits
override any concern for human behavior and psychology. Elon and I may not agree on everything,
but I deeply respect the engineering and innovation behind the efforts that he leads. My goal here is to catalyze a rigorous,
nuanced and objective discussion in industry and academia on AI-assisted driving,
one that ultimately makes for a safer and better world. And now, here's my conversation with Elon Musk.
The Dream of Autopilot
What was the vision, the dream, of Autopilot in the beginning? The big picture system level when it was first conceived
and started being installed in 2014, the hardware in the cars? What was the vision, the dream?
- I wouldn't characterize it as a vision or dream, it's simply that there are obviously two massive revolutions
in the automobile industry. One is the transition to electrification,
and then the other is autonomy. And it became obvious to me that, in the future,
any car that does not have autonomy would be about as useful as a horse.
Which is not to say that there's no use, it's just rare, and somewhat idiosyncratic, if somebody has a horse at this point.
It's just obvious that cars will drive themselves completely, it's just a question of time. And if we did not participate in the autonomy revolution,
then our cars would not be useful to people, relative to cars that are autonomous.
I mean, an autonomous car is arguably worth five to 10 times more than a car which is not autonomous.
- In the long term. - Depends what you mean by long term but, let's say at least for the next five years,
perhaps 10 years. - So there are a lot of very interesting design choices with Autopilot early on.
Autopilot Design
First is showing on the instrument cluster, or in the Model 3 and the center stack display,
what the combined sensor suite sees. What was the thinking behind that choice?
Was there a debate, what was the process? - The whole point of the display is to provide a health check on
the vehicle's perception of reality. So the vehicle's taking in information from a bunch of sensors, primarily cameras,
but also radar and ultrasonics, GPS and so forth.
And then, that information is then rendered into
vector space with a bunch of objects, with properties like lane lines
and traffic lights and other cars. And then, in vector space, that is re-rendered
onto a display so you can confirm whether the car knows what's going on or not,
by looking out the window. - Right, I think that's an extremely powerful thing for people to get an understanding,
Computer Vision Uncertainty
sort of become one with the system and understanding what the system is capable of. Now, have you considered showing more?
So if we look at the computer vision, like road segmentation, lane detection, vehicle detection, object detection, underlying the system,
there is at the edges, some uncertainty. Have you considered revealing the parts
that the uncertainty in the system, the sort of-- - Probabilities associated with say,
image recognition or something like that? - Yeah, so right now, it shows the vehicles in the vicinity, a very clean crisp image, and people do confirm
that there's a car in front of me and the system sees there's a car in front of me, but to help people build an intuition
of what computer vision is, by showing some of the uncertainty. - Well, in my car I always look at this with the debug view.
And there's two debug views. One is augmented vision, which I'm sure you've seen,
where it's basically we draw boxes and labels around objects that are recognized.
And then there's we what call the visualizer, which is basically vector space representation,
summing up the input from all sensors. That does not show any pictures,
which basically shows the car's view of the world in vector space.
But I think this is very difficult for normal people to understand, they're would not know what thing they're looking at.
- So it's almost an HMI challenge through the current things that are being displayed is optimized
for the general public understanding of what the system's capable of. - If you have no idea how computer vision works or anything,
you can still look at the screen and see if the car knows what's going on. And then if you're a development engineer,
or if you have the development build like I do, then you can see all the debug information.
But this would just be like total gibberish to most people.
How to best distribute effort
- What's your view on how to best distribute effort? So there's three, I would say, technical aspects
of Autopilot that are really important. So it's the underlying algorithms, like the neural network architecture,
there's the data that it's trained on, and then there's the hardware development and maybe others.
So, look, algorithm, data, hardware. You only have so much money, only have so much time.
What do you think is the most important thing to allocate resources to? Or do you see it as pretty evenly distributed
between those three? - We automatically get vast amounts of data because all of our cars have
eight external facing cameras, and radar, and usually 12 ultrasonic sensors,
GPS obviously, and IMU.
And we've got about 400,000 cars on the road that have that level of data. Actually, I think you keep quite close track of it actually.
- Yes. - Yeah, so we're approaching half a million cars on the road that have the full sensor suite.
I'm not sure how many other cars on the road have this sensor suite, but I'd be surprised if it's more than 5,000,
which means that we have 99% of all the data. - So there's this huge inflow of data.
- Absolutely, a massive inflow of data. And then it's taken us about three years,
but now we've finally developed our full self-driving computer, which can process an order of magnitude as much
as the NVIDIA system that we currently have in the cars, and to use it, you unplug the NVIDIA computer
and plug the Tesla computer in and that's it.
In fact, we still are exploring the boundaries of its capabilities. We're able to run the cameras at full frame-rate,
full resolution, not even crop the images, and it's still got headroom even on one of the systems.
The full self-driving computer is really two computers, two systems on a chip, that are fully redundant.
So you could put a boat through basically any part of that system and it still works. - The redundancy, are they perfect copies of each other or--
Fully redundant SOCs
- Yeah. - Oh, so it's purely for redundancy as opposed to an arguing machine kind of architecture where they're both making decisions,
this is purely for redundancy. - Think of it more like it's a twin-engine commercial aircraft.
The system will operate best if both systems are operating,
but it's capable of operating safely on one. So, as it is right now, we can just run,
we haven't even hit the edge of performance so there's no need to actually distribute
functionality across both SOCs. We can actually just run a full duplicate on each one.
- So you haven't really explored or hit the limit of the system. - [Elon] No not yet, the limit, no.
Learning from edge cases
- So the magic of deep learning is that it gets better with data. You said there's a huge inflow of data,
but the thing about driving, - Yeah. - the really valuable data to learn from is the edge cases.
I've heard you talk somewhere about Autopilot disengagements
being an important moment of time to use. Is there other edge cases or perhaps can you speak to those edge cases,
what aspects of them might be valuable, or if you have other ideas, how to discover more and more and more edge cases in driving?
- Well there's a lot of things that are learnt. There are certainly edge cases where, say somebody's on Autopilot and they take over,
and then that's a trigger that goes out to our system and says, okay, did they take over for convenience,
or did they take over because the Autopilot wasn't working properly? There's also, let's say we're trying to figure out,
what is the optimal spline for traversing an intersection.
Then the ones where there are no interventions are the right ones.
So you then you say, okay, when it looks like this, do the following. And then you get the optimal spline for
navigating a complex intersection.
Manual control
- So there's kind of the common case, So you're trying to capture a huge amount of samples of a particular intersection when things went right,
and then there's the edge case where, as you said, not for convenience,
but something didn't go exactly right. - So if somebody started manual control from Autopilot.
And really, the way to look at this is view all input as error. If the user had to do input, there's something,
all input is error. - That's a powerful line to think of it that way 'cause it may very well be error,
but if you wanna exit the highway, or if it's a navigation decision
that Autopilot's not currently designed to do, then the driver takes over, how do you know the difference? - Yeah, that's gonna change
with Navigate on Autopilot, which we've just released, and without stalk confirm.
Assuming control in order to do a lane change, or exit a freeway, or doing a highway interchange,
the vast majority of that will go away with the release that just went out. - Yeah, so that, I don't think people quite understand
how big of a step that is. - Yeah, they don't. If you drive the car then you do.
Big leaps
- So you still have to keep your hands on the steering wheel currently when it does the automatic lane change.
There's these big leaps through he development of Autopilot, through its history and,
what stands out to you as the big leaps? I would say this one, Navigate on Autopilot without having to confirm is a huge leap.
- It is a huge leap. - What are the-- It also automatically overtakes slow cars. So it's both navigation and seeking the fastest lane.
So it'll overtake slow cars and exit the freeway
and take highway interchanges, and then we have traffic light recognition,
which introduced initially as a warning. I mean, on the development version that I'm driving,
the car fully stops and goes at traffic lights. - So those are the steps, right?
Technological roadblocks
You've just mentioned some things that are an inkling of a step towards full autonomy. What would you say are the biggest technological
roadblocks to full self-driving? - Actually, the full self-driving computer that we just,
the Tesla, what we call, FSD computer that's now in production,
so if you order any Model S or X, or any Model 3 that has the full self-driving package,
you'll get the FSD computer. That's important to have enough base computation.
Then refining the neural net and the control software. All of that can just be provided as an over-the-air update.
The thing that's really profound, and what I'll be emphasizing at the investor day
that we're having focused on autonomy, is that the car is currently being produced, with the hard word currently being produced,
is capable of full self-driving. - But capable is an interesting word because--
Selfdriving cars
- [Elon] The hardware is. - Yeah, the hardware. - And as we refine the software, the capabilities will increase dramatically,
and then the reliability will increase dramatically, and then it will receive regulatory approval. So essentially, buying a car today
is an investment in the future.
I think the most profound thing is that if you buy a Tesla today, I believe you're buying an appreciating asset,
not a depreciating asset. - So that's a really important statement there because if hardware is capable enough,
that's the hard thing to upgrade usually. - Yes, exactly. - Then the rest is a software problem--
- Yes, software has no marginal cost really. - But, what's your intuition on the software side?
How hard are the remaining steps to get it to where the experience,
not just the safety, but the full experience is something that people would enjoy?
- I think people it enjoy it very much so on highways. It's a total game changer for quality of life,
for using Tesla Autopilot on the highways. So it's really just extending that functionality
to city streets, adding in the traffic light recognition,
navigating complex intersections, and then being able to navigate complicated parking lots
so the car can exit a parking space and come and find you, even if it's in a complete maze of a parking lot.
And, then it can just drop you off and find a parking spot, by itself.
Full autonomy
- Yeah, in terms of enjoyabilty, and something that people would actually find a lotta use from,
the parking lot, it's rich of annoyance when you have to do it manually,
so there's a lot of benefit to be gained from automation there. So, let me start injecting the human
into this discussion a little bit. So let's talk about full autonomy,
if you look at the current level four vehicles being tested on row like Waymo and so on,
they're only technically autonomous, they're really level two systems
with just a different design philosophy, because there's always a safety driver in almost all cases, and they're monitoring the system. - Right.
- Do you see Tesla's full self-driving as still,
for a time to come, requiring supervision of the human being.
So its capabilities are powerful enough to drive but nevertheless requires a human to still be supervising, just like
a safety driver is in other fully autonomous vehicles?
- I think it will require detecting hands on wheel for at least six months or something like that from here.
Really it's a question of, from a regulatory standpoint,
how much safer than a person does Autopilot need to be, for it to be okay to not monitor the car.
And this is a debate that one can have, and then, but you need a large amount of data,
so that you can prove, with high confidence, statistically speaking, that the car is dramatically safer than a person.
And that adding in the person monitoring does not materially affect the safety.
So it might need to be 200 or 300% safer than a person. - And how do you prove that?
- Incidents per mile. - Incidents per mile. - Yeah. - So crashes and fatalities--
- Yeah, fatalities would be a factor, but there are just not enough fatalities to be statistically significant, at scale.
But there are enough crashes, there are far more crashes then there are fatalities.
So you can assess what is the probability of a crash.
Then there's another step which is probability of injury. And probability of permanent injury,
the probability of death. And all of those need to be much better than a person,
by at least, perhaps, 200%.
- And you think there's the ability to have a healthy discourse with the regulatory bodies
on this topic? - I mean, there's no question that regulators paid
a disproportionate amount of attention to that which generates press, this is just an objective fact.
And it also generates a lot of press. So, in the United States there's, I think,
almost 40,000 automotive deaths per year. But if there are four in Tesla,
they will probably receive a thousand times more press than anyone else. - So the psychology of that is actually fascinating,
Functional vigilance
I don't think we'll have enough time to talk about that, but I have to talk to you about the human side of things.
So, myself and our team at MIT recently released a paper on functional vigilance of drivers
while using Autopilot. This is work we've been doing since Autopilot was first released publicly, over three years ago,
collecting video of driver faces and driver body. So I saw that you tweeted a quote from the abstract,
so I can at least guess that you've glanced at it.
- Yeah, I read it. - Can I talk you through what we found? - Sure. - Okay, it appears that in the data that we've collected,
that drivers are maintaining functional vigilance such that, we're looking at 18,000 disengagements from Autopilot,
18,900, and annotating were they able to take over control in a timely manner.
So they were there, present, looking at the road to take over control, okay.
So this goes against what many would predict from the body of literature on vigilance with automation.
Now the question is, do you think these results hold across the broader population.
So, ours is just a small subset. One of the criticism is that, there's a small minority
of drivers that may be highly responsible, where their vigilance decrement would increase
with Autopilot use. - I think this is all really gonna be swept, I mean, the system's improving so much,
so fast, that this is gonna be a moot point very soon.
Where vigilance is, if something's many times safer
than a person, then adding a person does, the effect on safety is limited.
And, in fact, it could be negative. - That's really interesting, so the fact that a human may,
some percent of the population may exhibit a vigilance decrement, will not affect
overall statistics, numbers on safety? - No, in fact, I think it will become,
very, very quickly, maybe even towards the end of this year, but I would say, I'd be shocked if it's not next year
at the latest, that having a human intervene will decrease safety.
Decrease, like imagine if you're in an elevator. Now it used to be that there were elevator operators.
And you couldn't go on an elevator by yourself and work the lever to move between floors.
And now nobody wants an elevator operator, because the automated elevator that stops at the floors
is much safer than the elevator operator. And in fact it would be quite dangerous to have someone with a lever
that can move the elevator between floors. - So, that's a really powerful statement,
Driver monitoring
and a really interesting one, but I also have to ask from a user experience and from a safety perspective,
one of the passions for me algorithmically is camera-based detection of just sensing the human,
but detecting what the driver's looking at, cognitive load, body pose, on the computer vision side that's a fascinating problem.
And there's many in industry who believe you have to have camera-based driver monitoring. Do you think there could be benefit gained
from driver monitoring? - If you have a system that's at or below a human level
of reliability, then driver monitoring makes sense. But if your system is dramatically better,
more reliable than a human, then driver monitoring
does not help much. And, like I said,
if you're in an elevator, do you really want someone with a big lever, some random person operating the elevator between floors?
I wouldn't trust that. I would rather have the buttons. - Okay, you're optimistic about the pace of improvement
of the system, from what you've seen with the full self-driving car computer. - The rate of improvement is exponential.
Operational design domain
- So, one of the other very interesting design choices early on that connects to this,
is the operational design domain of Autopilot. So, where Autopilot is able to be turned on.
So contrast another vehicle system that we were studying is the Cadillac Super Cruise system that's,
in terms of ODD, very constrained to particular kinds of highways, well mapped, tested, but it's much narrower
than the ODD of Tesla vehicles. - It's like ADD (both laugh).
- Yeah, that's good, that's a good line.
What was the design decision in that different philosophy of thinking,
where there's pros and cons. What we see with a wide ODD is Tesla drivers are able to explore more
the limitations of the system, at least early on, and they understand, together with the instrument cluster display,
they start to understand what are the capabilities, so that's a benefit. The con is you're letting drivers
use it basically anywhere-- - Anywhere that it can detect lanes with confidence.
- Lanes, was there a philosophy, design decisions that were challenging,
that were being made there? Or from the very beginning was that done on purpose,
with intent? - Frankly it's pretty crazy letting people drive a two-ton death machine manually.
That's crazy, like, in the future will people be like, I can't believe anyone was just allowed to drive
one of these two-ton death machines, and they just drive wherever they wanted.
Just like elevators, you could just move that elevator with that lever wherever you wanted, can stop it halfway between floors if you want.
It's pretty crazy, so, it's gonna seem like a mad thing in the future
that people were driving cars. - So I have a bunch of questions about the human psychology, about behavior and so on--
Neural network security
- That's moot, it's totally moot. - Because you have faith in the AI system,
not faith but, both on the hardware side and the deep learning approach of learning from data,
will make it just far safer than humans. - Yeah, exactly. - Recently there were a few hackers,
who tricked Autopilot to act in unexpected ways for the adversarial examples. So we all know that neural network systems
are very sensitive to minor disturbances, these adversarial examples, on input. Do you think it's possible
to defend against something like this, for the industry? - Sure (both laugh), yeah.
- Can you elaborate on the confidence behind that answer?
- A neural net is just basically a bunch of matrix math. But you have to be a very sophisticated,
somebody who really understands neural nets and basically reverse-engineer how the matrix
is being built, and then create a little thing that's just exactly causes the matrix math
to be slightly off. But it's very easy to block that by having,
what would basically negative recognition, it's like if the system sees something that looks like a matrix hack, exclude it.
It's such a easy thing to do. - So learn both on the valid data and the invalid data,
so basically learn on the adversarial examples to be able to exclude them. - Yeah, you like basically wanna both know
what is a car and what is definitely not a car. And you train for, this is a car,
and this is definitely not a car. Those are two different things. People have no idea of neural nets really,
They probably think neural nets involves, a fishing net or something (Lex laughs).
General AI
- So, as you know, taking a step beyond just Tesla
and Autopilot, current deep learning approaches still seem, in some ways,
to be far from general intelligence systems. Do you think the current approaches
will take us to general intelligence, or do totally new ideas need to be invented?
- I think we're missing a few key ideas for artificial general intelligence.
But it's gonna be upon us very quickly, and then we'll need to figure out what shall we do,
if we even have that choice. It's amazing how people can't differentiate
between, say, the narrow AI that allows a car to figure out what a lane line is, and navigate streets,
versus general intelligence. Like these are just very different things.
Like your toaster and your computer are both machines, but one's much more sophisticated than another.
- You're confident with Tesla you can create the world's best toaster-- - The world's best toaster, yes.
The world's best self-driving... yes, to me right now this seems game, set and match.
I mean, I don't want us to be complacent or over-confident, but that's what it, that is just literally how it appears right now,
I could be wrong, but it appears to be the case that Tesla is vastly ahead of everyone.
- Do you think we will ever create an AI system that we can love, and loves us back
in a deep meaningful way, like in the movie Her? - I think AI will capable of convincing you
to fall in love with it very well. - And that's different than us humans?
- You know, we start getting into a metaphysical question of, do emotions and thoughts exist in a different realm
than the physical? And maybe they do, maybe they don't, I don't know. But from a physics standpoint, I tend to think of things,
you know, like physics was my main sort of training, and from a physics standpoint, essentially,
if it loves you in a way that you can't tell whether it's real or not, it is real.
- That's a physics view of love. - Yeah (laughs), if you cannot prove that it does not,
if there's no test that you can apply that would make it,
allow you to tell the difference, then there is no difference. - Right, and it's similar to seeing our world a simulation,
they may not be a test to tell the difference between what the real world - Yes. - and the simulation, and therefore,
from a physics perspective, it might as well be the same thing. - Yes, and there may be ways to test whether
it's a simulation, there might be, I'm not saying there aren't. But you could certainly imagine that
a simulation could correct, that once an entity in the simulation found a way to detect the simulation,
it could either pause the simulation, start a new simulation, or do one of many other things
that then corrects for that error. - So when, maybe you, or somebody else creates
an AGI system, and you get to ask her one question,
what would that question be?
- What's outside the simulation? - Elon, thank you so much for talking today,
it's a pleasure. - All right, thank you.

----------

-----
--66--

-----
Date:
Link:
Transcription:

paste here

----------

-----
--65--

-----
Date: 2019.04.03
Link: [# Greg Brockman: OpenAI and AGI | Lex Fridman Podcast #17](https://www.youtube.com/watch?v=bIrEM2FbOLU)
Transcription:

the following is a conversation with Greg Brockman he's the co-founder and CTO of open AI a world-class research
organization developing ideas and AI with the goal of eventually creating a
safe and friendly artificial general intelligence one that benefits and
empowers humanity open AI is not only a source of publications algorithms tools
and datasets their mission is a catalyst for an important public discourse about
our future with both narrow and general intelligence systems this conversation
is part of the artificial intelligence podcast at MIT and beyond if you enjoy
it subscribe on youtube itunes or simply connect with me on twitter at Lex Friedman spelled Fri D and now here's my
conversation with Greg Brockman so in high school and right after you wrote a
draft of a chemistry textbook I saw that that covers everything from basic structure of the atom to quantum
mechanics so it's clear you have an intuition and a passion for both the
physical world with chemistry and now robotics to the digital world with AI
deep learning reinforcement learning so on do you see the physical world in the digital world is different and what do
you think is the gap a lot of it actually boils down to iteration speed right that I think that a lot of what
really motivates me is is building things right is the I you know think about mathematics for example where you
think you're really hard about a problem you understand it you're right down in this very obscure form that we call proof but then this is in humanities
library right it's there forever this is some truth that we've discovered you know maybe only five people in your
field will ever read it now but somehow you've kind of moved humanity forward and so I actually used to really think that I was going to be a mathematician
and then I actually started writing this chemistry textbook one of my friends told me you'll never publish it because
you don't have a PhD so instead I decided to build a website and try to promote my ideas that way and then I
discovered programming and I you know that in programming you think hard about a problem you understand it you write
down in a very obscure form that we call a program but then once again it's in humanities library right and anyone
could get the benefit from and the scalability is massive and so I think that the thing that really appeals to me about the digital world is that
you can have this this this insane leverage right a single individual with an idea is able to affect the entire
planet and that's something I think is really hard to do if you're moving around physical atoms but you said
mathematics so if you look at the the what thing you know over here our mind do you ultimately see it as just math is
just information processing or is there some other magic as you've seen if you've seen through biology and
chemistry and so on I think it's really interesting to think about humans is just information processing systems and that it seems like it's actually a
pretty good way of describing a lot of kind of how the world works or a lot of what we're capable of to think that that
you know again if you just look at technological innovations over time that in some ways the most transformative
innovation that we've had it has been the computer right in some ways the internet you know that what is the right
the Internet is not about these physical cables it's about the fact that I am suddenly able to instantly communicate
with any other human on the planet I'm able to retrieve any piece of knowledge that in some ways the human race has
ever had and that those are these insane transformations do you see the our
society as a whole the collective as another extension of the intelligence of the human being so if you look at the
human being is an information processing system you mentioned the internet then networking do you see us all together as
a civilization as a kind of intelligence system yeah I think this is actually a really interesting perspective to take
and to think about to you sort of have this collective intelligence of all of society the economy itself is this
superhuman machine that is optimizing something right and it's all in some ways a company has a will of its own
right that you have all these individuals we're all pursuing their own individual goals and thinking really hard and thinking about the right things
to do but somehow the company does something that is this emergent thing and that is it so there's a really
useful abstraction and so I think that in some ways you know we think of ourselves as the most intelligent things
on the planet and the most powerful things on the planet but there are things that are bigger than us that these systems that we all contribute to
and so I think actually you know it's a it's interesting to think about if you've read as a guys a models
foundation right that that there's this concept of psychohistory in there which is effectively this that if you have
trillions or quadrillions of beings then maybe you could actually predict what that being that that huge macro being
will do I and almost independent of what the individuals want I actually have a
second angle on this I think is interesting which is thinking about a technological determinism one thing that
I actually think a lot about with with open a tie right is that we're kind of coming on onto this insanely
transformational technology of general intelligence right that will happen at some point and there's a question of how
can you take actions that will actually steer it to go better rather than worse and that I think one question you need
to ask is as a scientist as an inventor as a creator what impact can you have in general right you look at things like
the telephone invented by two people in the same day like what does that mean what does that mean about the shape of innovation and I think that what's going
on is everyone's building on the shoulders of the same giants and so you can kind of you can't really hope to create something no one else ever would
you know if Einstein wasn't born someone else would have come up with relativity you know he changed the timeline a bit
right that maybe it would have taken another 20 years but it wouldn't be that fundamentally humanity would never discover these these fundamental truths
so there's some kind of invisible momentum that some people like Einstein or open the eyes plugging into that's
anybody else can also plug into and ultimately that wave takes us into a certain direction that's me that's right
that's right and you know this kind of seems to play out in a bunch of different ways that there's some exponential that is being ridden and
that the exponential itself which one it is changes think about Moore's law an entire industry set its clock to it for
50 years like how can that be right how is that possible and yet somehow it happened and so I think you can't hope
to ever invent something that no one else will maybe you can change the timeline a little bit but if you really
want to make a difference I think that the thing that you really have to do the only real degree of freedom you have is
to set the initial conditions under which a technology is born and so you think about the internet right that
there are lots of other competitors trying to build similar things and the internet one and that the initial
conditions where that was created by this group that really valued people being able to be you know anyone being
able to plug in this very academic mindset of being open and connected and I think that the Internet for the next 40 years
really played out that way you know maybe today things are starting to shift in a different direction but I
think if those initial conditions were really important to determine the next 40 years worth of progress that's really
beautifully put so another example of that I think about you know I recently looked at it I looked at Wikipedia the
formation of Wikipedia and I wonder what the internet would be like if Wikipedia had ads you know there's a interesting
argument that why they chose not to make it put advertisement wikipedia i think
it's i think wikipedia is one of the greatest resources we have on the internet it's extremely surprising how
well it works and how well it was able to aggregate all this kind of good information and they essentially the
creator of wikipedia I don't know there's probably some debates there but set the initial conditions and now it
carried it itself forward that's really interesting so you're the way you're thinking about AGI or artificial
intelligences you're focused on setting the initial conditions for the for the progress that's right that's powerful
okay so look into the future if you create an AGI system like one that can
ace the Turing test natural language what do you think would be the interactions you would have with it what
do you think are the questions you would ask like what would be the first question you would ask it her/him that's
right I think it at that point if you've really built a powerful system that is capable of shaping the future of
humanity the first question that you really should ask is how do we make sure that this plays out well and so that's
actually the first question that I would ask a powerful AGI system is so you wouldn't ask your colleague you wouldn't
ask like Ilya you would ask the AGI system oh we've already had the conversation with Ilya right and
everyone here and so you want as many perspectives and a piece of wisdom as you can for it for answering this
question so I don't think you necessarily defer to whatever your powerful system tells you but you use as
one input I like to try to figure out what to do but and I guess fundamentally what it really comes down to is if you
built something really powerful and you think about think about for example the creation of of shortly after the
creation of nuclear weapons right the most important question the world was what's the world order going to be like how do we set ourselves up in
where we're going to be able to survive this species with a GI I think the question is slightly different right
that there is a question of how do we make sure that we don't get the negative effects but there's also the positive side right you imagine that you know
like like what won't AGI be like like what will be capable of and I think that one of the core reasons that an AGI can
be powerful and transformative is actually due to technological development yeah right if you have something that's capable as capable as a
human and that it's much more scalable that you absolutely want that thing to go read the whole scientific literature
and think about how to create cures for all the diseases right you want it to think about how to go and build technologies to help us create material
abundance and to figure out societal problems that we have trouble with like how we're supposed to clean up the
environment and you know maybe you want this to go and invent a bunch of little robots that will go out and be
biodegradable and turn ocean debris into harmless molecules and I think that that
that positive side is something that I think people miss sometimes when thinking about what an AGI will be like
and so I think that if you have a system that's capable of all of that you absolutely want its advice about how do
I make sure that we're using your your capabilities in a positive way for Humanity so what do you think about that
psychology that looks at all the different possible trajectories of an AGI system many of which perhaps the
majority of which are positive and nevertheless focuses on the negative trajectories I mean you get to interact
with folks you get to think about this maybe within yourself as well you look
at sam harris and so on it seems to be sorry to put it this way but almost more fun to think about the negative
possibilities whatever that's deep in our psychology what do you think about
that and how do we deal with it because we want AI to help us so I think there's
kind of two problems so I entailed in that question the first is more of the
question of how can you even picture what a world with a new technology will any like now imagine were in 1950 and
I'm trying to describe Buber to someone apps and the internet yeah I mean your
yeah that's that's going to be extremely complicated but it's imaginable it's imaginable right but and now
imagine being a 1950 and predicting goober right and you need to describe the internet you need to describe GPS
you need to describe the fact that everyone's going to have this phone in their pocket and so I think that that
just the first truth is that it is hard to picture how a transformative technology will play out in the world
we've seen that before with technologies that are far less transformative than AG I will be and so I think that that one
piece is that it's just even hard to imagine and to really put yourself in a world where you can predict what that
that positive vision would be like and you know I think the second thing is
that it is I think it is always easier to support the negative side than the
positive side it's always easier to destroy than create and you know less than in a physical sense and more just
in an intellectual sense right because you know I think that with creating something you need to just get a bunch
of things right and to destroy you just need to get one thing wrong yeah and so I think that that what that means is
that I think a lot of people's thinking dead ends as soon as they see the negative story but that being said I
actually actually have some hope right I think that the the positive vision is something that I think can be something
that we can we can talk about I think that just simply saying this fact of yeah like there's positive there's
negatives everyone likes to draw them the negative people have to respond well to that message and say huh you're right there's a part of this that we're not
talking about not thinking about and that's actually something that's that's that's I think really been a key part of
how we think about AGI at open AI right you can kind of look at it as like okay like opening eye talks about the fact
that there are risks and yet they're trying to build this system like how do you square this those two facts so do
you share the intuition that some people have I mean from Sam Harris even Elon Musk himself that it's tricky as you
develop AGI to keep it from slipping into the existential threats into the
negative what's your intuition about how hard is it to keep a a development on the positive track and
you what's your intuition there to answer the question you can really look at how we structure open AI so we really have three main arms
we have capabilities which is actually doing the technical work and pushing forward what these systems can do there's safety which is working on
technical mechanisms to ensure that the systems we build are lined with human values and then there's policy which is
making sure that we have governance mechanisms answering that question of well whose values and so I think that
the technical safety one is the one that people kind of talk about the most right you talk about like think about you know
all of the dystopic AI movies a lot of that is about not having good technical safety in place and what we've been
finding is that you know I think that actually a lot of people look at the technical safety problem and think it's just intractable right this question of
what do humans want how am I supposed to write that down can I even write down what I want no way and then they stop
there but the thing is we've already built systems that are able to learn things that humans can't specify you
know even the rules for how to recognize if there's a cat or a dog in an image turns out its intractable to write that
down and yet we're able to learn it and that what we're seeing with systems we build it open it yeah and there's still
an early proof of concept stage is that you are able to learn human preferences you're able to learn what humans want
from data and so that's kind of the core focus for our technical safety team and I think that they're actually we've had
some pretty encouraging updates in terms of what we've been able to make work so you have an intuition and a hope that
from data you know looking at the value alignment problem from data we can build
systems that align with the collective better angels of our nature so aligned
with the ethics and the morals of human beings to even say this in a different way I mean think about how do we align
in humans right think about like a human baby can grow up to be an evil person or a great person and a lot of that is from
learning from data right that you have some feedback as a child is growing up they get to see positive examples and so
I think that that just like them that the the only example we have of a general intelligence that is able to
learn from data I too aligned with human values and to learn values I think we shouldn't be surprised
that we can do the same sorts of techniques or whether the same sort of techniques end up being how we we saw
value alignment for AG eyes so let's go even higher as I don't know if you've read the book sapiens mm-hmm but there's
an idea that you know that as a collective is us human beings who kind of develop together and ideas that we
hold there's no in that context objective truth we just kind of all agree to certain ideas and hold them as
a collective if you have a sense that there is in the world of good and evil do you have a sense that to the first
approximation there are some things that are good and that you could teach systems to behave to be good so I think
that this actually blends into our third team right which is the policy team and this is the one the the aspect I think
people really talk about way less than they should all right because imagine that we built super-powerful systems
that we've managed to figure out all the mechanisms for these things to do whatever the operator wants the most
important question becomes who's the operator what do they want and how is that going to affect everyone else right
and and I think that this question of what is good what are those values I mean I think you don't even have to go
to those those very grand existential places to start to realize how hard this problem is you just look at different
countries and cultures across the world and that there's there's a very different conception of how the world
works and you know what what what kinds of of ways that society wants to operate
and so I think that the really core question is is is actually very concrete
um and I think it's not a question that we have ready answers to right is how do you have a world where all the different
countries that we have United States China Russia and you know the hundreds
of other countries out there are able to continue to not just operate in the way
that they see fit but in that the world that emerges in these where you have
these very powerful systems I operating alongside humans ends up being something
that empowers humans more that makes like exhuming existence be a more meaningful thing and the
people are happier in wealthier and able to live more fulfilling lives it's not nob vyas thing for how to design that
world once you have that very powerful system so if we take a little step back and we're having it like a fascinating
conversation and open eyes in many ways a tech leader in the world and yet we're
thinking about these big existential questions which is fascinating really important I think you're a leader in
that space and it's a really important space of just thinking how AI affect society in a big-picture view so Oscar
Wilde said we're all in the gutter but some of us are looking at the Stars and I think open air has a charter that
looks to the Stars I would say to create intelligence to create general intelligence make it beneficial safe and
collaborative so can you tell me how that came about how a mission like that
and the path to creating a mission like that open yeah I was founded yeah so I think that in some ways it really boils
down to taking a look at the landscape alright so if you think about the history of AI that basically for the
past 60 or 70 years people have thought about this goal of what could happen if you could automate human intellectual
labor right imagine you can build a computer system that could do that what becomes possible well out of sci-fi
that tells stories of various dystopian and you know increasingly you have movies like heard that tell you a little bit about maybe more of a little bit
utopic vision I you think about the impacts that we've seen from being able
to have bicycles for our minds and computers and that I think that the the
impact of computers and the Internet has just far outstripped what anyone really
could have predicted and so I think that it's very clear that if you can build an AI it will be the most transformative
technology that humans will ever create and so what it boils down to then is a question of well is there a path is
there hope is there a way to build such a system and I think that for 60 or 70 years that people got excited and I they
you know ended up not being able to deliver on the hopes that the people I pinned on them and I think that then you
know that after you know two to winters of AI development that people I you know I think kind of almost stopped daring to dream right the
really talking about a GI or thinking about a GI became almost this taboo in the community but I actually think that
people took the wrong lesson from AI history and if you look back starting in nineteen fifty nine is when the
perceptron was released and this is basically you know one of the earliest neural networks it was released to what
was perceived as this massive overhype so in the New York Times in nineteen fifty-nine you have this article saying
that you know the the perceptron will one day recognize people call out their names instantly translate speech between
languages and people at the time looked at this and said this is Jack your system can't do any of that and
basically spent ten years trying to discredit the whole perceptron direction and succeeded and all the funding dried
up and you know people kind of went in other directions and you know the 80s there was a resurgence and I'd always
heard that the resurgence in the 80s was due to the invention of back propagation and these these algorithms that got
people excited but actually the causality was due to people building larger computers that you can find these
these articles from the 80s saying that the democratization of computing power suddenly meant that you could run these larger neural networks and then people
start to do all these amazing things the backpropagation algorithm was invented and you know that the the neural nets
people running were these tiny little like 20 neuron neural nets right what are you supposed to learn with 20 neurons and so of course they weren't
able to get great results and it really wasn't until 2012 that this approach that's almost the most simple natural
approach that people have come up with in the 50s right in some ways even in the 40s before there were computers with
a Pitts McCullen air and neuron suddenly this became the best way of solving
problems right and I think there are three core properties that deep learning has that I think are very worth paying
attention to the first is generality we have a very small number of deep learning tools SGD
deep neural net maybe some some you know RL and it solves this huge variety of
problems speech recognition machine translation game playing all these problems small set of tools so there's
the generality there's a second piece which is the competence you want to solve any of those problems throw it
forty years worth of computer vision research replacing the deep neural net it's kind of work better and there's a third piece which is the
scalability right the one thing that has been shown time and time again is that you if you have a larger neural network
for a more compute more data at it it will work better those three properties together feel like essential
parts of building a general intelligence now it doesn't just mean that if we scale up what we have that we will have
an AGI right there are clearly missing pieces they're missing ideas we need to have answers for reasoning but I think
that the core here is that for the first time it feels that we have a paradigm
that gives us hope the general intelligence can be achievable and so as soon as you believe that everything else
becomes comes into focus right if you imagine that you may be able to and you know that the timeline I think remains
uncertain on the but I think that that you know certainly within our lifetimes and possibly within a much shorter
period of time than then people would expect if you can really build the most transformative technology that will ever
exist you stop thinking about yourself so much right and you start thinking about just like how do you have a world
where this goes well and that you need to think about the practicalities of how do you build an organization and get together a bunch of people and resources
and to make sure that people feel motivated and ready to do it but I think
that then you start thinking about well what if we succeed and how do we make sure that when we succeed that the world
is actually the place that we want ourselves to exist then and almost in the Rawls the unveils sense of the word
and so that's kind of the broader landscape and opening I was really formed in 2015 with that high level
picture of AGI might be possible sooner than people think and that we need to
try to do our best to make sure it's going to go well and then we spent the next couple years really trying to
figure out what does that mean how do we do it and you know I think that typically with a company you start out very small so
you in a co-founder and you build a product you got some users you get a product market fit you know then at some point you raise
some money you hire people you scale and then you know down the road then the big companies realize you exist and try to
kill you and for opening I it was basically everything in exactly the order let me just pause for a second he
said a lot of things and let me just admire the jarring aspect of what open
AI stands for which is daring to dream I mean you said it's pretty powerful you
caught me off guard because I think that's very true the-the-the step of just daring to dream
about the possibilities of creating intelligence in a positive in a safe way but just even creating intelligence is a
much needed refreshing catalyst for the
AI community so that's that's the starting point okay so then formation of open AI was
just I just say that you know when we were starting opening AI that kind of the first question that we had is is it
too late to start a lab with a bunch of the best people possible that was an
actual question so those were those that was the core question of you know hey there's dinner in July of 20 2015
and there's that was that was really what we spent the whole time talking about and you know cuz it's the you
think about kind of where AI was is that it transitioned from being an academic pursuit to an industrial pursuit and so
a lot of the best people were in these big research labs and that we wanted to start our own one that you know no
matter how much resources we could accumulate it would be you know pale in comparison to the big tech companies and
we knew that and there's a question of are we going to be actually able to get this thing off the ground you need
critical mass you can't just do you and a co-founder build a product right you really need to have a group of you know
five to ten people and we kind of concluded it wasn't obviously impossible so it seemed worth trying well you're
also dreamers so who knows right that's right okay so speaking of that competing
with with the the big players let's talk about some of the some of the tricky
things as you think through this process of growing of seeing how you can develop
these systems a task at scale that competes so you recently recently formed
open ILP a new cap profit company that
now carries the name open it so open has now this official company the original
non profit company still exists and carries the opening I nonprofit name so can you explain what
this company is what the purpose of us creation is and how did you arrive at the decision yep to create it openly I
the whole entity and opening I LP as a vehicle is trying to accomplish the
mission of ensuring that artificial general intelligence benefits everyone and the main way that we're trying to do
that is by actually trying to build general intelligence ourselves and make sure the benefits are distributed to the world that's the primary way we're also
fine if someone else does this all right it doesn't have to be us if someone else is going to build an AGI and make sure
that the benefits don't get locked up in one company or you know one one want with one set of people like we're
actually fine with that and so those ideas are baked into our Charter which
is kind of the the foundational document that are describes kind of our values and how we operate
but it's also really baked into the structure of open at LP and so the way that we've set up opening ILP is that in
the case where we succeed right if we actually build what we're trying to build then investors are able to get a
return and but that return is something that is capped and so if you think of AGI in terms of data the value that you
could really create you're talking about the most transformative technology ever created it's going to create orders of
magnitude more value than any existing company and that all of that value will
be owned by the world like legally title to the nonprofit to fulfill that mission and so that's that's the structure so
the mission is a powerful one and it's a it's one that I think most people would
agree with it's how we would hope a I progresses and so how do you tie
yourself to that mission how do you make sure you do not deviate from that mission that you know other incentives
that are profit driven wouldn't don't interfere with the mission so this was
actually a really core question for us for the past couple years because you know I'd say that like the way that our
history went was that for the first year we were getting off the ground right we had this high level picture but we
didn't know exactly how we wanted to accomplish it and really two years ago it's when we
first started realizing in order to build a GI we're just going to need to raise way more money than we can as a
nonprofit I mean you're talking many billions of dollars and so the first
question is how are you supposed to do that and stay true to this mission and we looked at every legal structure out
there and concluded none of them were quite right for what we wanted to do and I guess it shouldn't be too surprising if you're going to do something like
crazy unprecedented technology that you're gonna have to come up with some crazy unprecedent structure to do it in and a lot of a lot of our conversation
was with people at opening I write the people who really join because they believe so much in this mission and
thinking about how do we actually raise the resources to do it and also stay true to to what we stand for and the
place you got to start is to really align on what is it that we stand for right what are those values what's really important to us and so I'd say
that we spent about a year really compiling the opening I'd charter and that determines and if you even look at
the first the first line item in there it says that look we expect we're gonna have to marshal huge amounts of resources but we're going to make sure
that we minimize conflicts of interest with the mission and that kind of aligning on all of those pieces was the
most important step towards figuring out how do we structure a company that can
actually raise the resources to do what we need to do I imagined open AI the
decision to create open ILP was a really difficult one and there was a lot of discussions as you mentioned for a year
and there was different ideas perhaps detractors with an open AI sort of
different paths that you could have taken what were those concerns what were the different paths considered what was
that process of making that decision like yep um but so if you look actually at the opening I charter that there's
almost two paths embedded within it there is we are primarily trying to build AGI ourselves but we're also ok if
someone else does it and this is a weird thing for a company it's really interesting actually yeah there there is
an element of competition that you do want to be the one that does it but at
the same time you're ok somebody else's and you know we'll talk about that a little bit that trade-off that's the day that's really interesting and I think
this was the core tension as we were designing open an ILP and really the opening eye strategy is how do you make
sure that both you have a shot at being a primary actor which really requires building an organization raising massive
resources and really having the will to go and execute on some really really hard vision all right you need to really
sign up for a long period to go and take on a lot of pain and a lot of risk and to do that normally you just import the
startup mindset right and that you think about okay like how do we how to execute everyone you give this very competitive angle but you also have the second angle
of saying that well the true mission isn't for opening high to build a GI the true mission is for AGI to go well for
Humanity and so how do you take all of those first actions and make sure you don't close the door on outcomes that
would actually be positive in fulfill the mission and so I think it's a very delicate balance right I think that
going 100% one direction or the other is clearly not the correct answer and so I think that even in terms of just how we
talk about opening I and think about it there's just like like one thing that's always in the back of my mind is to make
sure that we're not just saying opening eyes goal is to build AGI right that
it's actually much broader than that right that first of all I you know it's not just AGI it's safe AGI that's very
important but secondly our goal isn't to be the ones to build it our goal is to make sure it goes well for the world and so I think that figuring out how do you
balance all of those and to get people to really come to the table and compile the the like a single document that that
encompasses all of that wasn't trivial so part of the challenge here is your
mission is I would say beautiful empowering and a beacon of hope for people in the research community and
just people thinking about AI so your decisions are scrutinized more than I
think a regular profit driven company do you feel the burden of this in the creation of the Charter and just in the
way you operate yes so why do you lean
into the burden by creating such a charter why not to keep it quiet I mean
it just boils down to the to the mission right I'm here and everyone else is here because we think this is the most
important mission right dare to dream all right so what do you think you can be good for the world or create an a GI
system that's good when you're a for-profit company from my perspective I
don't understand why profit interferes with positive impact on society I don't
understand by Google that makes most of its money from ads you can't also do
good for the world or other companies Facebook anything I don't I don't understand why those have to interfere
you know you can profit isn't the thing in my view that affects the impact of a
company what affects the impact of the company is the Charter is the culture is the you know the people inside and
profit is the thing that just fuels those people so what are your views there yeah so I think that's a really
good question and there's there's there's some some you know real like long-standing debates in human society that are wrapped up in it the way that I
think about it is just think about what what are the most impactful nonprofits in the world what are the most impactful
for profits in the world right is much easier to lists the for profits that's right and I think that there's there's
some real truth here that the system that we set up the system for kind of
how you know today's world is organized is one that that really allows for huge impact and that that you know kind of
part of that is that you need to be you know for profits are our self-sustaining and able to to kind of you know build on
their own momentum and I think that's a really powerful thing it's something that when it turns out that we haven't
set the guardrails correctly causes problems right think about logging companies that go and DeForest you know you know the rain forest that's really
bad we don't want that and it's actually really interesting to me the kind of this this question of how do you get
positive benefits out of a for-profit company it's actually very similar to how do you get positive benefits out of
an AGI right that you have this like very powerful system it's more powerful than any human and it's kind of
autonomous in some ways you know super human and a lot of axes and somehow you have to set the guardrails to get good
to happen but when you do the benefits are massive and so I think that the when
when I think about nonprofit vs. for-profit I think it's just not enough happens in nonprofits they're very pure
but it's just kind of you know it's just hard to do things they're in for profits in some ways like too much happens but
if if kind of shaped in the right way it can actually be very positive and so with open NLP we're picking a road in
between now the thing I think is really important to recognize is that the way that we think about opening ILP is that
in the world where AGI actually happens right in a world where we are successful we build the most transformative technology ever the amount of value
we're going to create will be astronomical and so then in that case that the if it the the cap that we have
will be a small fraction of the value we create and the amount of value that goes back to investors and employees looks
pretty similar to what would happen in a pretty successful startup and that's
really the case that we're optimizing for right that we're thinking about in the success case making sure that the
value we create doesn't get locked up and I expect that in another you know for-profit companies that it's possible
to do something like that I think it's not obvious how to do it right and I think that as a for-profit company you
have a lot of fiduciary duty to your shareholders and that there are certain decisions you just cannot make in our
structure we've set it up so that we have a fiduciary duty to the Charter that we always get to make the decision
that is right for the Charter rather than even if it comes at the expense of our own stakeholders and and so I think
that when I think about what's really important it's not really about nonprofit vs. for-profit it's really a question of if you build a GI and you
kind of you know humanities now in this new age who benefits whose lives are
better and I think that what's really important is to have an answer that is everyone yeah which is one of the core
aspects of the Charter so one concern people have not just with open the eye but with Google Facebook Amazon anybody
really that's that's creating impact that scale is how do we avoid as your
Charter says avoid enabling the use of or AGI to unduly concentrate power why
would not a company like open a I keep all the power of an AGI system to itself the Charter the Charter so you know how
does the Charter actualize itself in day
to day so I think that first to zoom out right there the way that we structure
the company is so that the the power first sort of you know dictating the actions that opening eye takes
ultimately rests with the board right the board of the nonprofit I'm and the board is set up in certain ways certain
certain restrictions that you can read about in the opening hi LP blog post but effectively the board is the is the
governing body for opening ILP and the board has a duty to fulfill the mission
of the nonprofit and so that's kind of how we tie how we thread all these
things together now there's a question of so day to day how do people the individuals who in some ways are the
most empowered ones ain't no the board sort of gets to call the shots at the high level but the people who are actually executing are the employees the
way that people here on a day-to-day basis who have the you know the the keys to the technical Kingdom and their I
think that the answer looks a lot like well how does any company's values get actualized right I think that a lot of
that comes down to that you need people who are here because they really believe in that mission and they believe in the
Charter and that they are willing to take actions that maybe are worse for them but are better for the Charter and
that's something that's really baked into the culture and honestly I think it's I you know I think that that's one
of the things that we really have to work to preserve as time goes on and that's a really important part of how we
think about hiring people and bringing people into opening I so there's people here there's people here who could speak
up and say like hold on a second this is
totally against what we stand for cultural eyes yeah yeah for sure I mean I think that that we actually have I
think that's like a pretty important part of how we operate and how we have even again with designing the Charter
and designing open alp in the first place that there has been a lot of conversation with employees here and a
lot of times where employees said wait a second this seems like it's coming in the wrong direction and let's talk about it and so
I think one thing that's that's I think I really and you know here's here's actually one thing I think is very unique about us as a small company is
that if you're at a massive tech giant that's a little bit hard for someone who's aligned employee to go and talk to
the CEO and say I think that we're doing this wrong and you know you look at companies like Google that have had some
collective action from employees to you know make ethical change around things like maven and so maybe there are
mechanisms that other companies that work but here super easy for anyone to pull me aside to pull Sam aside to
Balilla aside and people do it all the time one of the interesting things in the Charter is this idea that it'd be
great if you could try to describe or untangle switching from competition to collaboration and late-stage AGI
development it was really interesting this dance between competition and collaboration how do you think about that yeah assuming you can actually do
the technical side of AGI development I think there's going to be two key problems with figuring out how do you actually deploy it make it go well the
first one of these is the run-up to building the first AGI you look at how
self-driving cars are being developed and it's a competitive race I'm the thing that always happens in a competitive race is that you have huge
amounts of pressure to get rid of safety and so that's one thing we're very concerned about right is that people
multiple teams figuring out we can actually get there but you know if we
took the slower path that is more guaranteed to be safe we will lose and so we're going to take the fast path and
so the more that we can both ourselves be in a position where we don't generate
that competitive race where we say if the race is being run and that you know someone else's is further ahead than we
are we're not gonna try to to leapfrog we're gonna actually work with them right we will help them succeed as long
as what they're trying to do is to fulfill our mission then we're good we don't have to build AGI ourselves and I
think that's a really important commitment from us but it can't just be unilateral right I think that's really important that other players who are
serious about building AGI make similar commitments right I think that that you know again to the extent that everyone
believes that AGI should be something to benefit everyone then it actually really shouldn't matter which company builds it and we should all be concerned about the
case where we just race so hard to get there that something goes wrong so what role do you think government our favorite
entity has in setting policy and rules about this domain from research to the
development to early stage to late stage a a inhi development so I think that
first of all is really important the government's in their right in some way shape or form you know at the end of the
day we're talking about building technology that will shape how the world operates and that there needs to be
government as part of that answer and so that's why we've we've we've done a
number of different congressional testimonies we interact with a number of different lawmakers and the you know
right now a lot of our message to them is that it's not the time for regulation
it is the time for measurement right that our main policy recommendation is that people and you know the government
does this all the time with bodies like NIST um spend time trying to figure out just where the technology is how fast
it's moving and can really become literate and up to speed with respect to what to expect
so I think that today the answer really is about about about measurement and I think if there will be a time in place
where that will change and I think it's a little bit hard to predict exactly I what what exactly that trajectory should
look like so there will be a point oh it's regulation federal in the United
States the government steps in and and helps be the I don't want to say the
adult in the room to make sure that there is strict rules may be conservative rules that nobody can cross
well I think there's this kind of maybe to two angles to it so today with narrow AI applications that I think there are
already existing bodies that are responsible and should be responsible for regulation you think about for example with self-driving cars that you
want the you know the National Highway it's exactly to be very good mat that
makes sense right that basically what we're saying is that we're going to have these technological systems that are
going to be do performing applications that humans already do great we already have ways of thinking about standards
and safety for those so I think actually empowering those regulators today is also pretty important
and then I think for for a GI you know that there's going to be a point where
we'll have better answers and I think that maybe a similar approach of first measurement and you know start thinking
about what the rules should be I think it's really important that we don't prematurely squash you know progress I
think it's very easy to kind of smother the budding field and I think that's something to really avoid but I don't
think it's the right way of doing it is to say let's just try to blaze ahead and not involve all these other stakeholders
so you've recently released a paper on GPT two language modeling but did not
release the full model because you have concerns about the possible negative effects of the availability of such
model it's uh outside of just that decision is super interesting because of
the discussion as at a societal level the discourse it creates so it's fascinating in that aspect but if you
think that's the specifics here at first what are some negative effects that you envisioned and of course what are some
of the positive effects yeah so again I think to zoom out like the way that we thought about GPT 2 is that with
language modeling we are clearly on a trajectory right now where we scale up
our models and we get qualitatively better performance right GPT 2 itself
was actually just a scale-up of a model that we've released in the previous June right and we just ran it at you know
much larger scale and we got these results we're suddenly starting to write coherent prose which was not something
we'd seen previously and what are we doing now well we're gonna scale up GPT 2 by 10x by hundred X by thousand X and
we don't know what we're going to get and so it's very clear that the model that we were that we released last June
you know I think it's kind of like it's it's it's it's a good academic toy it's not something that we think is something
that can really have negative applications or you know to the sense that it can the positive of people being able to play with it is you know far far
outweighs the possible harms you fast forward to not GPT to buy GPU 20
and you think about what that's gonna be like and I think that the capabilities are going to be substantive and so if
there needs to be a point in between the two where you say this is something where we are drawing the line and that
we need to start thinking about the safety aspects and I think for GPT too we could have gone either way and in fact when we had conversations
internally that we had a bunch of pros and cons and it wasn't clear which one which one outweighed the other and I
think that when we announced that hey we decide not to release this model then there was a bunch of conversation where
various people said it's so obvious that you should have just released it there other people said it's so obvious you should not have released it and I think
that that almost definitionally means that holding it back was the correct decision right if it's contra if there's
if it's not obvious whether something is beneficial or not you should probably default to caution and so I think that
the overall landscape for how we think about it is that this decision could have gone either way there are great
arguments in both directions but for future models down the road and possibly sooner than you'd expect because you
know scaling these things up doesn't have to take that long those ones but you're definitely not going to want to
release into the wild and so I think that we almost view this as a test case and to see can we even design you know
how do you have a society or how do you have a system that goes from having no concept of responsible disclosure where
the mere idea of not releasing something for safety reasons is unfamiliar to a
world where you say okay we have a powerful model let's at least think about it let's go through some process and you think about the security
community it took them a long time to design responsible disclosure right you know you think about this question of well I have a security exploit I send it
to the company the companies like tries to prosecute me or just sit just ignores it what do I do right and so you know
the alternatives of oh I just just always publish your exploits that doesn't seem good either right and so it really took a long time and took this
this it was bigger than any individual right is really about building the whole community that believed that okay we'll
have this process where you send it to the company you know if they don't act in a certain time then you can go public and you're not a bad person you've done
the right thing and I think that in AI part of the response of gbt to just
proves that we don't have any concept of this so that's the high level picture um and
so I think that I think this was this was a really important move to make and we could have maybe delayed it for D BT
3 but I'm really glad we did it for GPT too and so now you look at GPT 2 itself and you think about the substance of
okay what are potential negative applications so you have this model that's been trained on the Internet
which you know it's also going to be a bunch of very biased data a bunch of you know very offensive content and there and you can ask it to generate content
for you on basically any topic right you just give it a prompt and we'll just start start writing and all writes content like you see on the internet you
know even down to like saying advertisement in the middle of some of its generations and you think about the
possibilities for generating fake news or abusive content and you know it's interesting seeing what people have done
with you know we released a smaller version of GPT too and the people have done things like try to generate now I
you know take my own Facebook message history and generate more Facebook messages like me and people generating
fake politician content or you know there's a bunch of things there where you at least have to think is this going
to be good for the world there's the flip side which is I think that there's a lot of awesome applications that we
really want to see like creative applications in terms of if you have
sci-fi authors that can work with this tool and come up with cool ideas like that seems that seems awesome if we can
write better sci-fi through the use of these tools and we've actually had a bunch of people write in to us asking hey can we use it for you know for a
variety of different creative applications so the positive I actually pretty easy to imagine there if you know
the usual NLP applications are really interesting but let's go there it's kind of
interesting to think about a world where look at Twitter where that just fake
news but smarter and smarter BOTS being able to spread in an interesting complex
in that working way in information that just floods out us regular human beings
with our original thoughts so what are your views of this world with deep
t20 right what are you how do we think about again it's like one of those things about in the 50s trying to
describe the the internet or the smartphone what do you think about that
world the nature of information do we and one possibility is that we'll always
try to design systems that identify it robot versus human and we'll do so
successfully and so we will authenticate that we're still human and the other world is that we just accept the part
the fact that we're swimming in a sea of fake news and just learn to swim there well have you ever seen the there so you
know popular meme of of robot eye with a
physical physical arm and pen clicking the I'm not a robot button yeah I think
I think the truth is that that really trying to distinguish between robot and human is a losing battle ultimately you
think it's a losing battle I think it's a losing battle ultimately right I think that that is that in terms of the content in terms of the actions that you
can take I mean think about how captures have gone alright the captures used to be a very nice simple you have this image all of
our OCR is terrible you put a couple of of artifacts in it you know humans are gonna be able to tell what what it is an
AI system wouldn't be able to today like I can barely do CAPTCHAs yeah and I think that that this is just kind of
where we're going I think CAPTCHAs where we're a moment in time thing and as AI you systems become more powerful that they're being human capabilities that
can be measured in a very easy automated way that the a eyes will not be capable of I think that's just like it's just an
increasingly hard technical battle but it's not that all hope is lost right and you think about how do we already
authenticate ourselves right the you know we have systems we have social security numbers if you're in the u.s.
or you know you have you have uh you know ways of identifying individual people and having real world identity
tied to to digital identity seems like a step towards you know authenticating the
source of content rather than the content itself now there are problems with that how can you have privacy and
unanimity in a world where the only content you can really trust is or the only way you can trust content is by
looking at where it comes from and so I think that building out good reputation networks maybe maybe one possible
solution but yeah I think that this this question is it's not an obvious one and I think that we you know maybe sooner
than we think we'll be in a world where you know today I often will read a tweet and be like I feel like a real human
wrote this or you know don't feel like this is like genuine I feel like I kind of judge the content a little bit and I think in the future it just won't be the
case you will get for example the FCC comments on net neutrality it came out
later that millions of those were auto-generated and that the researchers were able to do various statistical tik
techniques to do that what do you do in a world where those statistical techniques don't exist it's just
impossible to tell the difference between humans at any highs and in fact the the the the most persuasive
arguments are written by by AI all that stuff it's not sci-fi anymore you okay
GPT to making a great argument for why recycling is bad for the world you got to read that be like huh you're right
yeah that's that's quite interesting I mean ultimately it boils down to the physical world being the last frontier
of proving so you said like basically networks of people humans vouching for humans in the physical world and somehow
the authentication and ends there I mean if I had to ask you I mean you're way
too eloquent for a human so if I had to ask you to authenticate like prove how
do I know you're not a robot and how do you know I'm not a robot you know I think that's so far were this in the
space this conversation we just had the physical movements we did is the biggest gap between us and AI systems is the
physical relation so maybe that's the last frontier well here's another question is is you know why why is why
is solving this problem important right like what aspects are really important to us I think that probably where we'll
end up is will hone in on what do we really want out of knowing if we're talking to a human and and I think that
again this comes down to identity and so I think that the Internet of the future I expect to be one that will have lots
of agents out there that will interact with with you but I think that the question of is this you know a real
flesh-and-blood human or is this an automated system be less important let's actually go
there it's GPT two is impressive and let's look at GPT 20 why is it so bad
that all my friends are GPT 20 well why
is it so why is it so important on the internet do you think to interact with
only human beings why can't we live in a world where ideas can come from models
trained on human data yeah I think this is I think is actually a really interesting question this comes back to the how do you even picture a world with
some new technology right and I think that that one thing I think is important is is you know Gosei honesty um and I
think that if you have you know almost in the Turing test style sense sense of technology you have a eyes that are
pretending to be humans and deceiving you I think that is you know that that feels like a bad thing right I think
that it's really important that we feel like we're in control of our environment right that we understand who we're
interacting with and if it's an AI or a human um that that's not something we're being deceived about but I think that
the flipside of can I have as a meaningful of an interaction with an AI as I can with a human well I actually
think here you can turn to sci-fi and her I think is a great example of asking this very question right and one thing I
really love about her is it really starts out almost by asking how meaningful are human virtual relationships right and and then you
have a human who has a relationship with an AI and that you really start to be drawn into that right and that all of
your emotional buttons get triggered in the same way as if there was a real human that was on the other side of that
phone and so I think that that this is one way of thinking about it is that I think that we can have meaningful
interactions and that if there's a funny joke some sense it doesn't really matter if it was written by a human or an AI
but what you don't want anyway I think we should really draw hard lines is deception
and I think that as long as we're in a world where you know why do why do we build AI systems at all alright the
reason we want to build them is to enhance human lives to make humans be able to do more things to have human humans feel more fulfilled and if we can
build AI systems that do that I you know sign me up so the process of language modeling
how far do you think it take us let's look at movie her do you think a dialog
natural language conversation is formulated by the Turing test for example do you think that process could
be achieved through this kind of unsupervised language modeling so I think the Turing test in it seems real
form isn't just about language right it's really about reasoning to write that to really pass the Turing test I
should be able to teach calculus to whoever's on the other side and have it really understand calculus and be able
to you know go and solve new calculus problems and so I think that to really solve the Turing test we need more than
what we're seeing with language models we need some way of plugging and reasoning now how different will that be
from what we already do that's an open question right might be that we need some sequence of totally radical new
ideas or it might be that we just need to kind of shape our existing systems in a slightly different way but I think
that in terms of how far language modeling will go it's already gone way further than many people would have
expected right I think that things like and I think there's a lot of really interesting angles to poke in terms of
how much does GBT to understand physical world like you know you you read a
little bit about fire under water in ng bt - so it's like okay maybe it doesn't quite understand what these things are
but at the same time I think that you also see various things like smoke coming from flame and you know a bunch
of these things that gbg - it has no body it is no physical experience it's just statically read data and I think
that I think that if the answer is like we don't know yet then these questions though we're
starting to be able to actually ask them to physical systems the real systems that exist and that's very exciting do
you think what's your intuition do you think if you just scale language modeling maintain like significantly
scale that reasoning can emerge from the same exact mechanisms I think it's unlikely that if we just scale
gbt - that will have reasoning in the full-fledged way and I think that there
is like you know the type signature is a little bit wrong right that like there's something we do with that we call
thinking right where we spend a lot of compute like a variable amount of compute get to better answers right I think a
little bit harder I get a better answer and that that kind of type signature isn't quite encoded in a gbt all right G
BT well kind of like it's been a long time and it's like evolutionary history baking and all this information getting
very very good at this predictive process and then at runtime I just kind of do one forward pass and and am able
to generate stuff and so you know there might be small tweaks to what we do in order to get the type signature right
for example well you know it's not really one forward pass right you know you generate symbol by symbol and so maybe you generate like a whole sequence
of thoughts and you only keep like the last bit or something right um but I think that at the very least I would
expect you have to make changes like that yeah yeah just exactly how we you said think is the process of generating
thought by thought in the same kind of way you like you said keep the last bit the thing that we converge towards you
know and I think there's there's another piece which is which is interesting which is this out of distribution
generalization right that like thinking somehow lets us do that right that we have an experience a thing and yet
somehow we just kind of keep refine our mental model of it this is again something that feels tied to whatever
reasoning is and maybe it's a small tweak to what we do maybe it's many ideas and we'll take as many decades
yeah so the the assumption they're generalization out of distribution is
that it's possible to create new new ideas the pot you know it's possible
that nobody's ever creating new ideas and then was scaling GPT 2 to GPT 20 you
would you would essentially generalize to all possible thoughts the Aussie was
gonna have I think just to play devil's ne how many new new story ideas have we
come up with since Shakespeare right yeah exactly it's just all different forms of love and drama and so on okay
not sure if you read bitter lesson a recent blog post by Ray Sutton no I have
he basically says something that echoes some of the ideas that you've been talking about which is he says the
biggest lesson that can be read from so many years of AI research is that general methods the leverage
computation are ultimately going to ultimately win out do you agree with
this so basically and openly I in general about the ideas you are
exploring about coming up with methods whether it's GPT to modeling or whether its opening i-5 playing dota or a
general method is better than a more fine-tuned expert to tuned a method yeah
so I think that well one thing that I think was really interesting about the reaction to that blog post was that a
lot of people have read this as saying that compute is all that matters and it's a very threatening idea right and I
don't think it's a true idea either right it's very clear that we have algorithmic ideas that have been very important for making progress and to
really build a GI you want to push as far as you can on the computational scale and you want to push as far as you can on human human ingenuity and so I
think you need both but I think the way that you phrase the question is actually very good right that it's really about what kind of ideas should we be striving
for and absolutely if you can find a scalable idea you'd pour more compute
into you pour more data into it it gets better like that's that's the real Holy Grail and so I think that the answer to
the question I think is yes that that's really how we think about it that part of why we're excited about the power of
deep learning the potential for building an AGI is because we look at the system that exists in the most successful AI
systems and we realize that you scale those up they're gonna work better and I
think that that scalability is something that really gives us hope for being able to build transformative systems so I'll
tell you this is a partially an emotional you know a thing that responds
that people often have is computers so important for state-of-the-art performance you know individual
developers maybe a 13 year old sitting somewhere in Kansas or something like that you know they're sitting they that
might not even have a GPU and or may have a single GPU a 1080 or something like that and there's this feeling like well how
can I possibly compete or contribute to this world of AI if scale is so
important so for if you can comment on that and in general do you think we need
to also in the future focus on democratizing compute resources more
more or as much as we democratize the algorithms well so the way that I think about it is that there's this space of a
possible progress right there's a space of ideas and sort of systems that will work that will move us forward and
there's a portion of that space and to some extent increasingly significant portion in that space that does just
require massive compute resources and for that fit I think that the answer is
kind of clear and that part of why we have this structure that we do is because we think it's really important
to be pushing the scale and to be you know building these large clusters and systems but there's another part portion
of the space that isn't about the large scale compute that are these ideas that and again I think that for the a is to
really be impactful and really shine that they should be ideas that if you scaled them up would work way better
than they do at small scale um but you can discover them without massive computational resources and if
you look at the history of recent developments you think about things like began or the VA II that these are ones
that I think you could come up with them without having and you know in practice people did come up with with them
without having massive massive computational resources alright I just talked to being good fellow but the thing is the initial gaen produce pretty
terrible results right so only because it was in a very specific it was because only because they're smart enough to
know that this is quite surprising can generate anything that they know and do
you see a world there's that too optimistic and dreamer like to imagine that the compute resources are something
that's owned by governments and provided as utility actually some extent this
this question reminds me of of blog post from one of my former professors at Harvard this guy map Matt Welsh
who was a systems professor I remember sitting in his tenure talk right and you know that he had literally just gotten
tenure he went to Google for the summer and I then decided he wasn't going back
it's academia right and that kind of in his bog post makes this point that look as a systems researcher that I come with
these cool system ideas right and I kind of a little proof of concept and the best thing I can hope for is that the
people at Google or Yahoo which was around at the time I will implement it and like actually make it
work at scale right that's like the dream for me right I built the little thing and they the big thing that's actually working and
for him he said I'm done with that I want to be the person who's who's actually doing this building and and
deploying and I think that there's a similar dichotomy here right I think that there are people who really actually find value and I think it is a
valuable thing to do to be the person who produces those ideas right who builds the proof of a concept and yeah
you don't get to generate the coolest possible Ganim ajiz but you invent it again right and so that there's that
there's there's a real trade-off there and I think that's a very personal choice but I think there's value in both sides do you think creating AGI
something or some new models would we would see echoes of the brilliance even
at the prototype level so you would be able to develop those ideas without scale the initial so seeds you know I
always like to look at at examples that exist right look at real precedent and so take a look at the June 2018 model
that we released that we scaled up to turn into GPT - and you can see that at small scale it set some records right
this was you know the devotional GPT we actually had some some cool generations that weren't nearly as amazing and
really stunning as the GPT - ones every but it was promising it was interesting and so I think it is the case that with
a lot of these ideas do you see prominence at small-scale but there is an asterisk here a very big asterisk which is sometimes we see
behaviors that emerge that are qualitatively different from anything we saw it's small scale and that the
original inventor of whatever algorithm looks at and says I didn't think it could do that this is what we saw in
DotA all right so PPO was was created by John Schulman who's a researcher here and and
with with dota we basically just ran PPO at massive massive scale and I there's
some tweaks and in order to make it work but fundamentally it's PPO with the core and we were able to get this long-term
planning these behaviors to really play out on a time scale that we just thought
was not possible and John looked at that and it was like I didn't think it could do that that's what happens when you're at three
orders of magnitude more scale contest to that yeah but it still has the same flavors of you know at least echoes of
the expected billions although I suspect with GPT is scaled more and more you
might get surprising things so yeah yeah you're right it's it's interesting that
it's it's difficult to see how far an idea will go when it's scaled it's an
open question we've also at that point with with dota and PPO like I mean here's a very concrete one right it's like it's
actually one thing that's very surprising about dota that I think people don't really pay that much attention to is the decree of
generalization out of distribution that happens right that you have this AI that's trained against other bots for
its entirety the entirety of its existence sorry to take a step back and you can't talk through in his you know a
story of dota a story of leading up to opening high five and that passed and
what was the process of self play it's a lot of training yeah yeah yeah yeah so with donors dota
yeah it's a complex video game and we started training we started trying to solve dota because we felt like this was
a step towards the real world relative to other games like chess or go right those various free board games where you
just kind of have this board very discrete moves dota starts to be much more continuous time so you have this
huge variety of different actions that you have a 45 minute game with all these different units and it's got a lot of
messiness to it that really hasn't been captured by previous games and famously all of the hard-coded bots for dota were
terrible right just impossible to write anything good for it because it's so complex and so this seems like a really
good place to push what's the state of the art in reinforcement learning and so we started by focusing on the one versus
one version of the game and and and were able to solve that we were able to beat the world champions and that the
learning you know the skill curve was this crazy exponential right it was like constantly we were just scaling up that
we were fixing bugs and you know that you look at the at the skill curve and it was really very very smooth one it's
actually really interesting to see how that like human iteration loop yielded very steady exponential progress and to
want one side note first of all it's an exceptionally popular video game this effect is that there's a lot of
incredible human experts at that video again so the benchmark the trying to reach is very high and the other can you
talk about the approach that was used initially and throughout training these agents to play this game yep and so they
person that we used is self play and so you have cue agents they don't know anything they battle each other they
discover something a little bit good and now they both know it and they just get better and better and better without bound and that's a really powerful idea
right that we then went from the one versus one version of the game and
scaled up to four five versus five right so you think about kind of like with basketball where you have this like team sport you know I need to do all this
coordination and we were able to push the same idea the same self play to to
really get to the professional level at the full thigh versus by version of the game and and and the things I think are
really interesting here is that these agents in some ways they're almost like an insect like intelligence right where
the you know there's they've a lot in common with how an insect is trained right insect kind of lives in this environment for a very long time or you
know the the ancestors of this insect I've been around for a long time and had a lot of experience it gets baked into into into this agent and you know it's
not really smart in the sense of a human right it's not able to go and learn calculus but it's able to navigate its
environment extremely well and simple they handle unexpected things in the environment that's never seen before pretty well and we see the same sort of
thing with our dota BOTS right they're able to in within this game they're able to play against humans
which are something that never existed in its evolutionary environment totally different playstyles from humans versus
the bots and yet it's able to handle it extremely well and that's something I think was very surprising to us was
something that doesn't really emerge from what we've seen with PPO at smaller
scale writing the kind of scale we're running the stuff out was you know I could take a hundred thousand CPU cores
running with like hundreds of GPUs it's probably about I you know like you know it's something like hundreds of years of
experience going into this bot every single real day and so that scale is
massive and we start to see very different kinds of behaviors out of the algorithms that we all know and love Dora he mentioned beat the world expert
1v1 and then you didn't weren't able to win
505 this year yeah at the best in the world so what's what's the comeback
story what's first of all talk through that does exceptionally exciting event and what's what's the following months
and this year look like yeah yeah so well one thing that's interesting is that you know we lose all the time
because we we so the dota team at opening I we played the bot against
better players than our system all the time or at least we used to it right like you know the the first time we lost
publicly was we went up on stage at the International and we played against some of the best teams in the world and we
ended up losing both games but we gave them a run for their money right the both games were kind of 30 minutes 25 minutes and that they went
back and forth back and forth back and forth and so I think that really shows that we're at the professional level and
that kind of looking at those games we think that the coin could have gone a different direction and it could have could have had some wins and so that was
actually very encouraging for us and you know it's interesting because the international was at a fixed time right
so we we knew exactly what day we were going to be playing and we pushed as far as we could as fast as we could two weeks later we had a bot that had an
80% win rate versus the one that played at ti so the march of progress you know you should think of as a snapshot rather
than as an end state and so in fact well we'll be announcing our our finals pretty soon I actually think that we'll
announce our final match I prior to this podcast being released Cassell's
there should be will be playing will be playing against the the world champions and you know for us it's really less
about like that the way that we think about what's upcoming is the final
milestone the file competitive milestone for the project right that our goal in all of this isn't really about beating
humans at dota our goal is to push the state of the art and reinforcement learning and we've done that right and
we've actually learned a lot from our system and that we have I you know I think a lot of exciting next steps that we want to take and so you know kind of
a final showcase of what we built we're going to do this match but for us it's not really the success or failure to see
you know do do we have the coin flip go in our direction or against where do you see the field of deep learning heading in
the next few years what do you see the work and reinforcement learning perhaps
heading and more specifically with open AI all the exciting projects that you're
working on what is 2019 hold for you massive scale scale I will put a naturist on that and
just say you know I think that it's about ideas plus scale you need both so that's a really good point so the
question in terms of ideas you have a lot of projects that are exploring
different areas of intelligence and the question is when you when you think of scale do you think about growing scale
those individual projects so do you think about adding new projects and society today in if you are thinking
about adding new projects or if you look at the past what's the process of coming up with new projects and new ideas so we
really have a life cycle of project here so we start with a few people just working on a small scale idea and
language is actually a very good example of this that it was really you know one person here who was pushing on language
for a long time I mean then you get signs of life right and so this is like let's say you know with with the
original gbt we had something that was interesting and we said okay it's time to scale this right it's time to put
more people on it put more computational resources behind it and and then we just kind of keep pushing and keep pushing
and the end state is something that looks like dota or robotics where you have a large team of you know 10 or 15
people that are running things at very large scale and that you're able to really have material engineering and and
and and you know sort of machine learning science coming together to make systems that work and get material
results that just would've been impossible otherwise so we do that whole lifecycle we've done it a number of times you know typically end to end it's
probably to two years or so to do it I you know the organization's been around for three years so maybe we'll find it
we also have longer life cycle projects but you know we we will work up to those
we have so so one one team that we were actually just starting Illya and I are kicking off a new team called the
reasoning team and that this is to really try to tackle how do you get neural networks to reason and we think that this will be a
long-term project and we're very excited about in terms of reasoning super
exciting topic woody what kind of benchmarks what kind of tests of
reasoning oh do you envision what what would if you set back with whatever
drink and you would be impressed that this system is able to do something what would that look like not fear improving
they are improving so some kind of logic and especially mathematical logic I
think so right I think that there's there's there's kind of other problems that are dual to if you're improving in particular you know you think about
programming I think about even like security analysis of code that these all
kind of capture the same sorts of core reasoning and being able to do some amount of distribution generalization it
would be quite exciting if open ai reasoning team was able to prove that P equals NP that would be very nice I be
very very very exciting especially if it turns out the P equals NP that'll be interesting too
it just it would be ironic and humorous you know so what problem stands out to
you is uh the most exciting and challenging impactful to the work for us as a
community in general and for open AI this year he mentioned reasoning I think that's that's a heck of a problem yeah
so I think reasoning is an important one I think it's gonna be hard to get good results in 2019 you know again just like we think about the life cycle takes time
I think for 2019 language modeling seems to be kind of on that ramp right it's at the point that we have a technique that
works we want to scale 100 X thousand X see what happens awesome do you think we're living in a
simulation I think it's I think it's hard to have a real opinion about it I you know it's actually interesting I
separate out things that I think can have like you know yield materially different predictions about the world
from ones that are just kind of you know fun fun to speculate about and I kind of view simulation it's more like is there
a flying teapot between Mars and Jupiter like maybe but it's a little bit hard to
know what that would mean for my life so there is something actionable I'd so some of the best work opening has done
is in the field of reinforcement learning and some of the success of reinforcement learning come from being
able to simulate the problem you trying to solve so it do you have a hope for
reinforcement for the future of reinforcement learning and for the future of simulation like what we're
talking about autonomous vehicles or any kind of system do you see that scaling so we'll be able to simulate systems and
enhance be able to create a simulator that echoes our real world and proving
once and for all even though you're denying it that we're living in a simulation question right so you know
kind for the core thereof like can we use simulation for self-driving cars take a look at our robotic system dactyl
right that was trained in simulation using the DOTA system in fact and it
transfers to a physical robot and I think everyone looks at our dota system the wreck okay it's just a game how are
you ever going to escape to the real world and the answer is well we did it with the physical robot the noble could program and so I think the answer is
simulation goes a lot further than you think if you apply the right techniques to it now there's a question of you know
are the beings in that simulation gonna wake up and have consciousness I think that one seems a lot a lot harder to
again reason about I think that you know you really should think about like where where exactly just human consciousness
come from and our own self-awareness and you know is it just that like once you have like a complicated enough neural net do you have to worry about the
agents feeling pain and I think there's like interesting speculation to do there
but but you know again I think it's a little bit hard to know for sure well let me just keep with a speculation do
you think to create intelligence general intelligence you need one consciousness
and to a body do you think any of those elements are needed or as intelligence
something that's that's orthogonal to those I'll stick to the kind of like the the non grand answer first
right so the non grand answer is just to look at you know what are we already making work yoga GPG to a lot of people
would have said that even get these kinds of results you need real-world experience you need a body you need grounding how are you supposed to reason
about any of these things how are you supposed to like even kind of know about smoke and fire and those things if you've never experienced them and GPT
two shows it you can actually go way further than that kind of reasoning would predict so
I think that the the in terms of doing any consciousness do we need a body it seems the answer is probably not right
that we can probably just continue to push kind of the systems we have they already feel general they're not as
competent or as general or able to learn as quickly as an aged guy would but you know they're at least like kind of proto
AGI in some way and they don't need any of those things now now let's move to
the grand answer which is you know if our neural next Nets conscious already
would we ever know how can we tell right yeah here's where the speculation starts
become become you know at least interesting or fun and maybe a little bit disturbing it depending on where you
take it but it certainly seems that when we think about animals that there's some continuum of consciousness you know my
cat I think is is conscious in some way right I you know not as conscious as a human and you could imagine that you
could build a little consciousness meter right you pointed a cat gives you a little reading we ran a human gives you much bigger reading what would happen if
you pointed one of those at a dota neural net and if your training of this massive simulation do the neural nets
feel pain you know it becomes pretty hard to know that the answer is no and
it becomes pretty hard to to really think about what that would mean if the answer were yes and it's very possible
you know for example you could imagine that maybe the reason these humans are have consciousness is because it's a
it's a convenient computational shortcut all right if you think about it if you have a being that wants to avoid pain
which seems pretty important to survive in this environment I'm and once you like you know eat food then that may be
the best way of doing it is to have a being that's conscious right that you know in order to succeed in the environment you need to have those
properties and how are you supposed to implement them and maybe this this consciousness is way of doing that if
that's true then actually maybe we should expect that really competent reinforcement learning agents will also have consciousness but you know it's a
big if and I think there a lot of other arguments they can make in other directions I think that's a really interesting idea that even GPT to has
some degree of consciousness that's something is actually not as crazy to think about
it's useful to think about as we think about what it means to create intelligence of a dog intelligence of a
cat and the intelligence of human so last question do you think we will ever
fall in love like in the movie her with an artificial intelligence system or an
artificial intelligence system falling in love with a human I hope so if there's any better way to end it on
love so Greg thanks so much for talking today thank you for having me
you

----------

-----
--64--

-----
Date: 2019.03.20
Link: [# Eric Weinstein: Revolutionary Ideas in Science, Math, and Society | Lex Fridman Podcast #16](https://www.youtube.com/watch?v=2wq9x2QcZN0)
Transcription:

- The following is a conversation with Eric Weinstein. He's a mathematician, economist,
physicist and the managing director of Thiel Capital. He coined the term and you could say,
is the founder of the Intellectual Dark Web, which is a loosely assembled group of public intellectuals
that includes Sam Harris, Jordan Peterson, Steven Pinker, Joe Rogan, Michael Shermer and a few others.
This conversation is part of the artificial intelligence podcast at MIT and Beyond.
If you enjoy it, subscribe on YouTube, iTunes, or simply connect with me on Twitter @lexfridman,
spelled F-R-I-D. And now, here's my conversation with Eric Weinstein.
Who influenced your thinking
- Are you nervous about this? - Scared shitless. - Okay, (speaking foreign language).
- You mention Kung Fu Panda as one of your favorite movies. It has the usual profound master student dynamic going on,
so who has been a teacher that significantly influenced the direction of your thinking and life's work?
So, if you're the Kung Fu Panda, who was your Shifu? - Oh, well that's interesting, because I didn't see Shifu as being the teacher.
- Who was the teacher? - Oogway, Master Oogway, the turtle. - Oh, the turtle, right.
- They only meet twice in the entire film and the first conversation sort of doesn't count.
So, they magic of the film, in fact, it's point
is that the teaching that really matters is transferred
during a single conversation and it's very brief. And so, who played that role in my life?
I would say either my grandfather, Harry Rubin
and his wife Sophie Rubin, my grandmother or Tom Lehrer.
- Tom Lehrer? - Yeah. - In which way? - If you give a child Tom Lehrer records,
what you do is you destroy their ability to be taken over by later malware,
and it's so irreverent, so witty, so clever, so obscene,
that it destroys the ability to lead a normal life for many people.
So if I meet somebody who's usually really shifted
from any kind of neuro typical presentation, I'll often ask them, are you a Tom Lehrer fan
and the odds that they will respond are quite high. - Now Tom Lehrer is Poisoning Pigeons in the Park,
Tom Lehrer? - That's very interesting. There are a small number of Tom Lehrer songs that broke into the general population.
Poisoning Pigeons in the Park, the Element Song and perhaps the Vatican Rag.
So, when you meet somebody who knows those songs, but doesn't know-- - Oh, you're judging me right now, aren't you?
- Harshly. - Okay. - No, but you're Russian, so. - Yes. - Undoubtedly you know Nikolai Ivanovich Lobachevsky.
That song. - Yes, yeah, yup. - So that was a song about plagiarism that was in fact plagiarized,
which most people don't know, from Danny Kaye. Where Danny Kaye did a song called
Stanislavsky of the musky arts. And, so Tom Lehrer did this brilliant job
of plagiarizing a song and making it about plagiarism, and then making it about this mathematician,
who worked in Non-Euclidean geometry. That was like giving heroin to a child.
It was extremely addictive and eventually led me to a lot of different places.
One of which may have been PhD in mathematics. - And he was also at least a lecturer in mathematics,
I believe at Harvard, something like that? - Yeah, I just had dinner with him, in fact.
When my son turned 13, we didn't tell him, but his Bar mitzvah present was dinner
with his hero, Tom Lehrer, and Tom Lehrer was 88 years old, sharp as a tack,
irreverent and funny as hell and just, you know, there are very few people in this world
that you have to meet while they're still here and that was definitely one for our family. - So that wit is a reflection of intelligence
in some kind of deep way. Like where that would be a good test of intelligence whether you're a Tom Lehrer fan.
So, what do you think that is about wit? About that kind of humor,
ability to see the absurdity in existence? Do you think that's connected to intelligence or are we just
two Jews on a mic that appreciate that kind of humor. - No, I think that it's absolutely
connected to intelligence. You can see it, there's a place where Tom Lehrer decides
that he's going to lampoon Gilbert of Gilbert and Sullivan and he's going to out due Gilbert with clever,
meaningless wordplay and he has, I forget the, well let's see.
He's doing Clementine as if Gilbert and Sullivan wrote it and he says that I missed her, depressed her young sister named Esther.
This mister to pester she'd tried. A pestering sister's a festering blister you're best to resist her, say I! The sister persisted, the mister resisted,
I kissed her, all loyalty slipped. When she said I could have her her sister's cadaver must surely have turned in its crypt.
That's so dense. It's so insane. - Yeah. - That that's clearly intelligence because
it's hard to construct something like that. If I look at my favorite Tom Lehrer lyric, you know,
there's a perfectly absurd one which is, once all the German's were warlike and mean, but that couldn't happen again.
We taught them a lesson in 1918 and they've hardly bothered us since then. - Right. - That is a different
kind of intelligence. You know, you're taking something that is so horrific and you're sort of making it palatable and funny,
and demonstrating also just your humanity. I mean, I think the thing that came through as Tom Lehrer
wrote all of these terrible, horrible lines, was just what a sensitive and beautiful soul he was,
who was channeling pain through humor and through grace. - I've seen throughout Europe, throughout Russia,
the same kind of humor emerged from the generation of World War II. It seemed like that humor is required to somehow deal
with the pain and the suffering of that that war created. - Well, you do need the environment
to create the broad Slavic soul. I don't think that many Americans really appreciate
Russian humor, how you had to joke during the time
of let's say, Article 58 under Stalin. You had to be very, very careful. You know, the concept of a Russian satirical magazine,
like Krokodil, doesn't make sense. So you have this cross cultural problem that there
are certain areas of human experience that it would be better to know nothing about and quite unfortunately,
eastern Europe knows a great deal about them, which makes the songs of Vladimir Voevodsky so potent.
You know, the prose of Pushkin, whatever it is. You have to appreciate the depth of the Eastern European
experience and I would think that perhaps Americans knew something like this around the time of the Civil War
or maybe under slavery and Jim Crow or even the harsh tyranny of the coal
and steel employers during the labor wars. But in general I would say, it's hard for us to understand
and imagine the collective culture, unless we have the system of selective pressures,
that for example, Russians were subjected to. - Yeah, so if there's one good thing that comes outta war,
it's literature, art and humor and music. - Oh, I don't think so. I think almost everything is good
about war except for death and destruction. - Right. Without the death it would bring the romance of it,
the whole thing is nice but-- - Well, this is why we're always caught up in war. We have this very ambiguous relationship to it,
is that it makes life real and pressing and meaningful, and at an unacceptable price
and the price has never been higher. - So to jump into AI a little bit,
in one of the conversations you had or one of the videos, you described that one of the things AI systems can't do
and biological systems can is self replicate in the physical world. - [Eric] Oh, no, no.
- In the physical world. - Well, yes. The physical robots can't self replicate,
but there's a very tricky point, which is that the only thing that we've been able
to create that's really complex that has an analog of our reproductive system is software.
- But, nevertheless, software replicates itself, if we're speaking strictly for the replication
is this kinda digital space. So let me, just to begin, let me ask a question. Do you see a protective barrier or a gap
between the physical world and the digital world? - Let's not call it digital. Let's call it the logical world versus the physical world.
- Why logical? - Well, because even though we had, let's say Einstein's brain preserved,
it was meaningless to us as a physical object because we couldn't do anything with what was stored in it at a logical level.
And so, the idea that something may be stored logically and that it may be stored physically, are not necessarily,
we don't always benefit from synonymizing. I'm not suggesting that there isn't a material basis to the logical world, but that it does warrant
identification with a separate layer that need not invoke logic gates and zeros and ones.
Telogens
- And, so connecting those two worlds, the logical world and the physical world or maybe just connecting to the logical world inside our brain,
Einstein's brain, you mention the idea of outtelligence.
- [Eric] Artificial outtelligence. - Artificial outtelligence. - Yes, this is the only essay that John Brockman every invited me to write
that he refused to publish in Edge. (Lex chuckling) - Why? - Well, maybe it wasn't well written, but I don't know.
- The idea is quite compelling. It's quite unique and new, at least from my stance point.
Maybe you can explain it? - Sure. What I was thinking about is why it is that we're waiting
to be terrified by artificial general intelligence. When in fact, artificial life is terrifying
in and of itself and it's already here. So, in order to have a system of selective pressures,
you need three distinct elements. You need variation within a population,
you need heritability, and you need differential success. So, what's really unique and I've made this point,
I think elsewhere, about software, is that if you think about what humans
know how to build that's impressive. So, I always take a car and I say does it have an analog of each of the physiological systems?
Does it have a skeletal structure, that's its frame. Does it have a neurological structure, it has an onboard computer.
It has a digestive system. The one thing it doesn't have is a reproductive system.
But if you can call spawn on a process, effectively you do have a reproductive system.
And that means that you can create something with variation, heritability and differential success.
Now, the next step in the chain of thinking was where do we see inanimate non intelligent life
outwitting intelligent life? And I have two favorite systems and I try to stay
on them so that we don't get distracted. One of which is the Ophrys orchid sub species or sub clave,
I don't what to call it. - Is that a type of flower? - Yeah, it's a type of flower that mimics the female of a pollinator species
in order to dupe the males into engaging in what is called pseudocopulation, with the fake female,
which is usually represented by the lowest pedal, and there's also a pheromone component to fool the males
into thinking they have a mating opportunity. But the flower doesn't have to give up energy in the form of nectar as a lure, because it's tricking the males.
The other system is a particular species of muscle,
lampsilis in the clear streams of Missouri and it fools bass
into biting a fleshy lip that contain its young and when
the bass see this fleshy lip, which looks exactly like a species of fish that the bass like to eat,
the young explode and clamp onto the gills and parasitize the bass and also use the bass to redistribute
them as they eventually release. Both of these systems, you have a highly intelligent dupe,
being fooled by a lower life form. And what is sculpting these convincing lures?
It's the intelligence of previously duped targets for these strategies.
So when the target is smart enough to avoid the strategy, those weaker mimics fall off, they have terminal lines,
and only the better ones survive. So it's an arms race between the target species
that is being parasitized, getting smarter, and this other less intelligent
or non intelligent object getting as if smarter. And so, what you see is, is that artificial general
intelligence is not needed to parasitize us. It's simply sufficient for us to outwit ourselves,
so you could have a program, let's say, one of these Nigerian scams that writes letters
and uses whoever sends it Bitcoin to figure out which
aspects of the program should be kept, which should be varied and thrown away, and you don't need it to be in anyway intelligent
in order to have a really nightmare scenario being parasitized by something that has no idea what it's doing.
- So you phrased a few concepts really eloquently, so let me try to, there's a few directions this goes.
So one, first of all, in the way we write software today, it's not common that we allow it to self modify.
- But we do have that ability now. - We have the ability. - It's just not common. - I just isn't common.
So your thought is that that is a serious worry if there becomes--
- But self modifying code is available now. - So there's different types of self modification right?
There's personalization, you know your email app, your Gmail is self modifying to you after you login
or whatever, you can think of that way. But ultimately it's central, all the information is
centralized, but you're thinking of ideas where you're, this is a unique entity operating under
selective pressures and it changes-- - Well, you just, if you think about the fact that our
immune systems don't know what's coming at them next, but they have a small set of spanning components,
and if it's a sufficiently expressive system in that any shape or binding region can be approximated with the Lego
that is present, then you can have confidence that you don't need to know what's coming at you
because the combinatorics are sufficient to reach any configuration needed.
Open AI
- So that's a beautiful, well terrifying thing to worry about because it's so within our reach.
- Whenever I suggest these things I do always have a concern as to whether or not I will bring them into being by talking about them.
- So there's this thing from OpenAI next week,
to talk to the founder of OpenAI, this idea that their text generation,
the new stuff they have for generating text is, they didn't wanna bring it, they didn't wanna release it because they're about the--
- I'm delighted to hear that, but they're going to end up releasing. - Yes, that's the thing is I think talking about it,
well at least from my end, I'm more a proponent of technology preventing,
so further innovation preventing the detrimental effects of innovation.
- Well we're in a, we're sort of tumbling down a hill at accelerating speed.
So, whether or not we're proponents or-- - It doesn't really matter. - It may not matter. - But I. - Well, may not.
- Well, I do feel that there are people who have held things back and you know, died poorer than they might have otherwise been.
We don't even know their names. I don't think that we should discount the idea that having
the smartest people showing off how smart they are by what they've developed may be a terminal process.
I'm very mindful in particular of a beautiful letter that Edward Teller of all people wrote to Leo Szilard
where Szilard was trying to figure out how to control the use of atomic weaponry at the end of World War II and Teller
Edward Teller
rather strangely, because many of us view him as a monster, showed some very advanced moral thinking talking about
the slim chance we have for survival and that the only hope is to make war unthinkable.
I do think that not enough of us feel in our gut, what it is we are playing with when we are working on
technical problems, and I would recommend to anyone who hasn't seen it, a movie called A Bridge on the River Kwai,
about I believe captured British POWs who just in a desire to do a bridge well,
end up over collaborating with their Japanese captors. - Well, now you're making me question
the unrestricted open discussion of ideas and AI. - I'm not saying I know the answer,
I'm just saying that I could make a decent case for either our need to talk about this and
to become technologically focused on containing it or need to stop talking about this and try to hope that
the relatively small number of highly adept individuals who are looking at these problems is small enough that
we should in fact be talking about how to contain it. - Well, the way ideas, the way innovation happens,
what new ideas develop, Newton with calculus. Whether if he was silent, the idea would emerge elsewhere,
well in case of Newton, of course, but you know, in case of AI, how small is this set of
individuals out of which such ideas would arise?
Is it in question-- - Well, the ideas of the researchers we know and those that we don't know. Who may live in countries that don't wish us to know
what level they're currently at and are very disciplined in keeping these things to themselves.
Of course, I will point out that there is a religious school in Kerala that developed something
very close to the calculus, certainly in terms of infinite series in, I guess religious prayer
All telogens
and rhyme and prose. So, you know, it's not that Newton had any ability to hold that back and I don't really believe
that we have an ability to hold back. I do think that we could change the proportion of the time we spend worrying about the effects of what
if we are successful, rather than simply trying to succeed and hope that we'll be able to contain things later. - Beautifully put.
So, on the idea of outtelligence, what form, treading cautiously 'cause we've agreed
as we tumbled down the hill. What form-- - Can't stop ourselves can we? - We cannot.
What form do you see it taking? So one example, Facebook, Google, do want to,
I don't know a better word, you want to influence users to behave a certain way.
And so that's one kind of example of outtelligence, is systems perhaps modifying the behavior
of these intelligent human beings in order to sell more product of different kind.
But do you see other examples of this actually emerging in? - Just take any parasitic system, you know?
Make sure that there's some way in which that there's differential success, heritability and variation,
Building a nightmare machine
and those are the magic ingredients. And if you really wanted to build a nightmare machine, make sure that the system that expresses the variability
has a spanning set, so that it can learn to arbitrary levels
by making it sufficiently expressive. That's your nightmare. - So, it's your nightmare, but it could also be,
it's a really powerful mechanism by which to create, well, powerful systems.
So, are you more worried about the negative direction that might go versus the positive?
So, you said parasitic, but that doesn't necessarily need to be what the system converges towards.
It could be, what is it, symbiotic-- - Well, parasitism, the dividing line between parasitism
and symbiosis is not so clear. - [Lex] That's what they tell me about marriage. I'm still single, so I don't know.
- Well, yeah I do. Would could go into that too, but um. (Lex laughing)
No, I think we have to appreciate, you know, are you infected by your own mitochondria?
- Right. Yeah. - Right, so in marriage
you fear the loss of independence, but even though the American therapeutic community
may be very concerned about co-dependence, what's to say that co-dependence isn't what's necessary
to have a stable relationship in which to raise children who are maximally K-selected and require
incredible amounts of care, because you have to wait 13 years before there's any reproductive payout and most of us don't want our 13 year olds having kids.
That's a very tricky situation to analyze. I would say that predators and parasites drive much
Metrics
of our evolution and I don't know whether to be angry at them or thank them. - Well, ultimately, I mean, nobody knows the meaning of life
or what even happiness is, but there is some metrics-- - Oh, they didn't tell you? - They didn't, they didn't.
That's why all the poetry and books are bought. You know, there are some metrics under which
you can kinda measure how good it is that these AI systems are roaming about.
So, you're more nervous about software than you
are optimistic about ideas of self replicating larceny?
- I don't think we've really felt where we are.
The Great Mystery of Our Time
You know, occasionally we get a wake up. 9/11 was so anomalous compared to everything else
we've experienced on American soil, that it came to us as a complete shock that that was even a possibility.
What it really was, was a highly creative and determined RND team deep in the bowels of Afghanistan showing
us that we had certain exploits that we were open to, that nobody had chosen to express. I can think of several of these things that I don't talk
about publicly, that just seem to have to do with how relatively unimaginative those who wish to cause
havoc and destruction have been up until now. The great mystery of our time,
of this particular little era, is how remarkably stable we've been since 1945 when we
demonstrated the ability to use nuclear weapons in anger. And, we don't know why things like
that haven't happened since then. We've had several close calls, we've had mistakes,
we've had brinkmanship and what's now happened is that we've settled into a sense that oh, it'll always be nothing.
It's been so long since something was at that level
of danger, that we've got a wrong idea in our head and that's why when I went on the Ben Shapiro Show,
I talked about the need to resume above ground testing of nuclear devices because we have people whose
developmental experience suggests that when, let's say Donald Trump and North Korea engage on Twitter,
oh it's nothing, it's just posturing, everybody's just in it for money, there's a sense that people are in
a video game mode, which has been the right call since 1945.
We've been mostly in video game mode. It's amazing. - So you're worried about a generation which has not seen any existential--
- We've lived under it. See, you're younger. I don't know if, and again, you came from Moscow.
- [Lex] From, yeah. - There was a TV show called The Day After that had
a huge effect on a generation growing up in the US,
and it talked about what life would be like after a nuclear exchange.
My Leading Concern
We have not gone through an embodied experience collectively where we've thought about this,
and I think it's one of the most irresponsible things that the elders among us have done,
which is to provide this beautiful garden in which the thorns are cut off of the rosebushes
and all of the edges are rounded and sanded, and so people have developed this totally unreal idea
which is everything is going to be just fine. And do I think that my leading concern is AGI
or my leading concern is thermonuclear exchange or gene drives or any one of these things?
I don't know. But I know that our time here in this very long experiment
here is finite, because the toys that we've built are so impressive and the wisdom to accompany
them has not materialized. And I think we actually got a wisdom uptick since 1945.
We had a lot of dangerous, skilled players on the world stage who nevertheless, no matter how bad they were,
managed to not embroil us in something that we couldn't come back from.
- The Cold War. - Yeah, and the distance from the Cold War, you know, I'm very mindful of,
there was a Russian tradition, actually, of on your wedding day going to visit
a memorial to those who gave their lives. Can you imagine this? Where on the happiest day of your life,
you go and you pay homage to the people who fought and died in the Battle of Stalingrad?
I'm not a huge fan of communism, I gotta say, but there were a couple of things that the Russians did
that were really positive in the Soviet era, and I think trying to let people know
how serious life actually is, is the Russian model of seriousness is better than the American model.
- And maybe, like you mentioned, there was a small echo of that after 9/11, but--
- We wouldn't let it form. We talk about 9/11, but it's 9/12 that really moved the needle.
When we were all just there and nobody wanted to speak. We witnessed something super serious
and we didn't want to run to our computers
Gated Institutional Narrative
and blast out our deep thoughts and our feelings. And it was profound because we woke up, briefly,
and I talk about the gated institutional narrative that sort of programs our lives,
I've seen it break three times in my life. One of which was the election of Donald Trump,
another time was the fall of Lehman Brothers, when everybody who knew that Bear Stearns wasn't that
important, knew that Lehman Brothers met AIG was next,
and the other one was 9/11. And so, if I'm 53 years old and I only remember three times
that the global narrative was really interrupted, that tells you how much we've been
on top of developing events, you know? We had the Murrah Federal Building explosion,
but it didn't cause the narrative to break, it wasn't profound enough. Around 9/12, we started to wake up out of our slumber,
and the powers that be, did not want a coming together.
You know, the admonition was go shopping. - The powers that be, so what is that force?
As opposed to blaming individuals-- - We don't know. - So whatever that-- - Whatever that force is. - In silence. - There's a component of it
that's emergent and there's a component of it that's deliberate. So, give yourself a portfolio with two components.
Some amount of it is emergent, but some amount of it is also an understanding that if people come together,
they become an incredible force. And what you're seeing right now, I think is,
there are forces that are trying to come together and there are forces that are trying to push things apart,
and you know, one of them is the globalist narrative versus the national narrative. Where to the globalist perspective,
the nations are bad things in essence. That they're temporary, they're nationalistic,
they're jingoistic, it's all negative, to people more in the national idiom, they're saying look,
this is where I pay my taxes, this is where I do my army service, this is where I have a vote,
this is where I have a passport. Who the hell are you to tell me that because you've moved into some place that you can make money globally,
that you've chosen to abandon other people to whom you have a special and elevated duty. And I think that these competing narratives have been
pushing towards the global perspective from the elite and a larger and larger number of disenfranchised
people are saying, hey, I actually live in a place and I have laws and I speak a language, I have a culture,
and who are you to tell me that because you can profit in some far away land, that my obligations to my fellow
countrymen are so much diminished. - So these tensions between nations and so on, ultimately you see being proud of your country and so on,
which creates potentially the kind of things that led to wars and so on.
They ultimately, it is human nature and it is good for us, for wake up calls of different kinds.
- Well, I think that these are tensions. And my point isn't, I mean nationalism run
amuck is a nightmare. And internationalism run amuck is a nightmare.
And the problem is we're trying to push these pendulums
to some place where they're somewhat balanced. Where we have a higher duty of care to those who share our
laws and our citizenship, but we don't forget our duties of care to the global system.
Nuclear Weapons
I would think this is elementary, but the problem that we're facing concerns the ability for
some to profit by abandoning their obligations to others
within their system and that's what we've had for decades. - You mention nuclear weapons.
I was hoping to get answers from you since one of the many things you've done as economics,
maybe you can understand human behavior of why the heck we haven't blown each other up yet.
But okay, so we'll get-- - I don't know the answer. - Yeah. It's really important to say that we really don't know--
- [Eric] A mild uptick in wisdom. - A mild uptick in wisdom, Steven Pinker who I've talked
with has a lot of really good ideas about why, but he-- - I don't trust his optimism.
(Lex chuckling) - Listen, I'm Russian, so I never trust a guy who's that optimistic--
- No, no, no, it's just that you're talking about a guy who's looking at a system in which more and more
of the kinetic energy, like war, has been turned into potential energy like unused nuclear weapons.
- Wow, beautifully put. - And you know now I'm looking at that system and I'm saying, okay, well if you don't have a potential energy trim,
then everything's just getting better and better. - Yeah, yeah, wow, that's beautifully put. Only a physicist could, okay.
- [Eric] I'm not a physicist. - Well, is that a dirty word? - [Eric] No, no, I wish I were a physicist.
- Me too, my dad's a physicist. I'm trying to live up to that probably for the rest of my life.
He's probably gonna listen to this too, so. - Hey dad. - Yeah, (chuckling). So, your friend, Sam Harris,
worries a lot about the existential threat of AI. Not in the way that you've described, but in the more.
- Well, he hangs out with Elon. I don't know Elon. - So, are you worried about that kind of,
you know, about the, about either robotics systems
or traditionally defined AI systems essentially becoming super intelligent, much more intelligent
than human beings and getting-- - Well, they already are, and they're not.
- When seen as a collective, you mean? - I can mean all sorts of things,
but certainly, many of the things that we thought were peculiar to general intelligence
do not require general intelligence. So that's been one of the big awakenings that you can write
a pretty convincing sports story from stats alone.
Without needing to have watched the game. So, you know, is it possible to write lively
prose about politics? Yeah, no, not yet. So, we're sort of all over the map.
Chess
One of the things about chess, there's a question I once asked on Quora
that didn't get a lot of response, which was, what is the greatest brilliancy ever produced by a computer in a chess game?
Which was different than the question of what is the greatest game ever played. So if you think about brilliancies,
is what really animates many of us to think of chess as an art form.
Those are those moves and combinations that just show such flair, panache and soul.
Computers weren't really great at that. They were great positional monsters. And recently we've started seeing brilliancies.
- [Lex] Yeah, a few grandmasters have identified with AlphaZero that things were quite brilliant.
- Yeah, so that's an example of something. We don't that that's AGI, but in a very restricted set
of rules like chess, you're starting to see poetry of a high order.
And so I don't like the idea that we're waiting for AGI. AGI is sort of slowly infiltrating our lives in the same way
that I don't think a worm should be, you know C. Elegans shouldn't be treated as non conscious
because it only has 300 neurons. Maybe it just has a very low level of consciousness. Because we don't understand what
these things mean as they scale up. So, am I worried about this general phenomena? Sure, but I think that one of the things
that's happening is that a lot of us are fretting about this in part because of human needs.
We've always been worried about the Golem, right? - [Lex] Well, the Golem is the artificially created--
- Life, you know? - [Lex] It's like Frankenstein type of character-- - Yeah, sure, it's a Jewish version.
Frankenberg, Franken-- - Yeah, that makes sense. - Sorry, so the, but we've always been worried about
creating something like this and it's getting closer and closer and there are ways in which we have to realize
The Future
that the whole thing, the whole thing that we've experienced are the context of our lives,
is almost certainly coming to an end. And I don't mean to suggest that we won't survive, I don't know.
And I don't mean to suggest that it's coming tomorrow. It could be 300, 500 years, but there's no plan
that I'm aware of, if we have three rocks that we could possibly inhabit that are sensible within current
technological dreams; the Earth, the Moon and Mars, and we have a very competitive civilization
that is still forced into violence to sort out disputes that cannot be arbitrated.
It is not clear to me that we have a long term future until we get to the next stage, which is to figure out whether
or not the Einsteinian speed limit can be broken, and that requires our source code.
- Our source code, the stuff in our brains to figure out? What do you mean by our source code? - The source code of the context.
Whatever it is that produces the quarks, the electrons, the neutrinos. - Oh, our source code, I got it, so this is--
- You're talking about the stuff that's written in a higher level language. - Yeah, yeah, that's right. You're talking about the low level, the bits or even lower--
- Right, that's what is currently keeping us here. We can't even imagine, you know, we have hair brain schemes
for staying within the Einsteinian speed limit. You know, maybe if we could just drug ourselves
and go into a suspended state or we could have multiple generations of that. I think all that stuff is pretty silly.
But, I think it's also pretty silly to imagine that our wisdom is going to increase to the point that
we can have the toys we have and we're not going to use them for 500 years.
- Speaking of Einstein, I had a profound breakthrough when I realized you're just one letter away from the guy.
- Yeah, but I'm also one letter away from Feinstein. - Well, you get to pick.
Okay, so, unified theory. You know, you've worked, you enjoy the beauty of geometry.
Well, I don't actually know if you enjoy it. You certainly are quite good at it-- - I tremble before it. - Tremble before it.
If you're religious that is one of the-- - I don't have to be religious. It's just so beautiful, you will tremble anyway.
- I just read Einstein's biography and one of the ways,
one of the things you've done is try to explore a unified theory talking about a 14 dimensional observerse
that has the 4D space time continuum embedded in it. I'm just curious how you think,
philosophically at a high level, about something more than four dimensions.
How do you try to, what does it make you feel talking
in the mathematical world about dimensions that are greater than the ones we can perceive?
Is there something that you take away that's more than just the math? - Well, first of all, stick out your tongue at me.
Okay, now. (Lex chuckling) On the front of that tongue. - Yeah? - There was a sweet receptor.
Temporal Dimensions
And next to that were salt receptors on two different sides. A little bit farther back there were sour receptors,
and you wouldn't show me the back of your tongue where your bitter receptor was. - [Lex] I show the good side always. - Okay, but that was four dimensions of taste receptors.
But you also had pain receptors on that tongue and probably heat receptors on that tongue. So let's assume that you have one of each.
That would be six dimensions. So when you eat something, you eat a slice of pizza
and it's got some hot pepper on it, maybe some jalapeno.
You're having a six dimensional experience, dude. - Do you think we over emphasize the value of time
as one of the dimensions or space? Well, we certainly over emphasize the value of time
'cause we things to start and end, or we really don't like things to end, but they seem to. - Well, what if you flipped one of the spacial dimensions
into being a temporal dimension? And you and I were to meet in New York City and say,
well where and when should we meet? And I say, how about I'll meet you on 36th and Lexington
at 2:00 in the afternoon and 11 o'clock in the morning?
That would be very confusing. - Well, it's so convenient for us to think about time, you mean?
- We happen to be in a delicious situation in which we have three dimensions of space and one of time,
and they're woven together in this sort of strange fabric where we can trade off a little space for a little time.
But we still only have one dimension that is picked out relative to the other three. It's very much Gladys Knight and the Pips.
- So, which one developed for who? Did we develop for these dimensions? Or did the dimensions, or were they always
there and it doesn't-- - Well, do you imagine that there isn't a place where there are four temporal dimensions? Or two and two of space and time?
Or three of time and one of space? And then would time not be playing the role of space?
Why do you imagine that the sector that you're in is all that there is? - I certainly do not, but I can't imagine otherwise.
I mean, I haven't done ayahuasca or any of those drugs. I hope to one day, but--
- Instead of doing ayahuasca, you could just head over to Building Two. - That's where the mathematicians are? - [Eric] Yeah, that's where they hang.
- [Lex] Just to look at some geometry? - Well just ask about pseudo-Riemannian geometry, that's what you're interested in. (Lex chuckling) - [Lex] Okay.
- Or you can talk to a shaman and end up in Peru. - And then some extra money for that trip-- - Yeah, but you won't be able to do any calculations
if that's how you choose to go about it. - Well, a different kind of calculation-- - So to speak. - Yeah. One of my favorite people, Edward Franco,
Berkeley professor, author of Love and Math, great title for a book, said that you were quite a
remarkable intellect to come up with such beautiful, original ideas in terms of unified theory and so on.
But you were working outside academia. So, one question in developing ideas
that are truly original, truly interesting, what's the difference between inside academia and outside
academia when it comes to developing such ideas? - Oh, it's a terrible choice, a terrible choice.
So, if you do it inside of academics, you are forced to constantly...
show great loyalty to the consensus and you distinguish yourself with small,
almost microscopic heresies to make your reputation in general.
And you have very competent people and brilliant people who are working together who formed very deep social networks,
and have a very high level of behavior, at least within mathematics and at least technically
within physics, theoretical physics. When you go outside, you meet lunatics and crazy people.
Madmen and these are people who do not usually subscribe
to the consensus position and almost always lose their way.
And the key question is will progress likely come from
someone who is miraculously managed to stay within the system and is able to take on a larger amount
of heresy, that is sort of unthinkable? In which case, that will be fascinating.
Or, is it more likely that somebody will maintain a level of discipline from outside of academics and be able to make
use of the freedom that comes from not having to constantly affirm your loyalty to the consensus of your field.
- So you've characterized in ways that academia, in this particular sense is declining.
You posted the plot, the older population of the faculty is getting larger.
The younger is getting smaller and so on. So, which direction of the two are you more hopeful about?
- Well, the Baby Boomers can't hang on forever. - Which is first of all in general true, and second of all in academia--
- But that's really what this time is about-- - Is the Baby Boomers control. - Is we didn't, we're used to
like financial bubbles that last a few years in length and then pop. - Yes. - The Baby Boomer bubble
is this really long lived thing and all of the ideology, all of the behavior patterns, the norms, you know,
for example string theory is an almost entirely Baby Boomer phenomena. It was something that Baby Boomers were able to do because
it required a very high level of mathematical ability.
- You don't think of string theory as an original idea? - Oh, I mean it was original to Veneziano
who probably is older than the Baby Boomers and there are people who are younger than the Baby Boomers who are still doing string theory.
And I'm not saying that nothing discovered within the large string theoretic complex is wrong.
Quite the contrary. A lot of brilliant mathematics and a lot of the structure of physics was elucidated by string theorists.
What do I think of the deliverable nature of this product that will not ship called string theory?
I think that is largely an affirmative action program for highly mathematically and geometrically
talented Baby Boomer physicists so that they can say that they're working on something within
the constraints of what they will say is quantum gravity. Now there are other schemes.
You know, there's like asymptotic safety. There are other things that you could imagine doing. I don't think much of any of the major programs,
but to have inflicted this level of loyalty through
a shibboleth, well surely you don't question x. Well, I question almost everything in the string program,
and that's why I got out of physics. When you called me physicist, was a great honor, but the reason I didn't become a physicist
wasn't that I fell in love with mathematics. As I said, wow, in 1984, 1983, I saw the field going mad,
and I saw that mathematics, which has all sorts of problems, was not going insane.
And so instead of studying things within physics, I thought it was much safer to study the same objects within mathematics.
And there's a huge price to pay for that. You lose physical intuition. But the point is, is that it wasn't
a North Korean reeducation camp, either. - Are you hopeful about cracking open
the Einstein Unified Theory in a way that has, in really understanding whether uniting everything
together with quantum theory and so on? - I mean, I'm trying to play this role myself. To do it to the extent of handing it over to the more
responsible, more professional, more competent community.
So, I think that they're wrong about a great number of their belief structures, but I do believe,
I mean I have a really profound love hate relationship with this group of people. - On the physics side? - Oh yeah.
- 'Cause the mathematicians actually seem to be much more open minded and-- - Well, they are and they aren't.
They're open minded about anything that looks like great math. - Right. - Right, they'll study something that isn't very important physics,
but if it's beautiful mathematics then they'll have, they have great intuition about these things.
As good as the mathematicians are, and I might even intellectually at some horsepower level give them the edge.
The theoretical physics community is bar none, the most profound intellectual community
that we have ever created. It is the number one, there is nobody in second place
as far as I'm concerned. Like, in their spare time, in the spare time they invented molecular biology.
- What was the origin of molecular biology? You're saying physicists-- - Well somebody like Francis Crick. A lot of the early molecular biologists--
- Were physicists? - Yeah, I mean you know, Schrodinger wrote What is Life and that was highly inspirational.
I mean, you have to appreciate that there is no community
like the basic research community in theoretical physics. And it's not something, I'm highly critical of these guys.
I think that they would just wasted the decades of time with
and your religious devotion to their misconceptualization of where the problems were in physics.
But this has been the greatest intellectual collapse ever witnessed within academics.
- You see it as a collapse or just a lull? - Oh, I'm terrified that we're about to lose the vitality.
We can't afford to pay these people. We can't afford to give them an accelerator just to play
with in case they find something at the next energy level. These people created our economy.
They gave us the RAD Lab and radar. They gave us two atomic devices to end World War II.
They created the semi-conductor and the transistor to power our economy through Moore's law.
As a positive externality of particle accelerators, they created the World Wide Web
and we have the insolence to say, why should we fund you with our taxpayer dollars?
No, the question is, are you enjoying your physics dollars?
Right, these guys signed the world's worst licensing agreement. - Right. - And, if they simply charged
for every time you used a transistor or a URL or enjoyed the peace that they have provided during this period
of time through the terrible weapons that they developed, or your communications devices.
All of the things that power our economy, I really think came out of physics, even to the extent that chemistry came out of physics,
and molecular biology came out of physics. So, first of all you have to know that I'm very critical of this community.
Second of all, it is our most important community. We have neglected it, we've abused it,
we don't take it seriously, we don't even care to get them to rehab after a couple of generations of failure.
Right, no one, I mean I think the youngest person to have really contributed to the standard model
at a theoretical level was born in 1951, right? Frank Wilczek.
And almost nothing has happened that in theoretical physics
after 1973, '74, that sent somebody to Stockholm
for theoretical development that predicted experiment. So, we have to understand that we are doing this to ourselves.
Now, with that said, these guys have behaved abysmally, in my opinion, because they haven't owned up
to where they actually are, what problems they're really facing, how definite they can actually be.
They haven't shared some of their most brilliant discoveries, which are desperately needed in other fields like gauge theory,
which at least the mathematicians can share, which is an upgrade of the differential calculus of Newton and Leibniz,
and they haven't shared the importance of renormalization theory, even though this should be standard operating procedure for people across
the sciences dealing with different layers and different levels of phenomena, so-- - And by shared you mean communicated in such a way
that it disseminates throughout the different sciences? - These guys are sitting, both theoretical physicists
and mathematicians are sitting on top of a giant stockpile of intellectual gold, right?
They have so many things that have not been manifested anywhere. I was just on Twitter I think
I mentioned the Hoberman switch pitch that shows the self duality of the tetrahedron realizes that it linkage mechanism.
Now this is like a triviality and it makes an amazing toy that's,
you know, built a market. - Yeah. - Hopefully a fortune for Chuck Hoberman. Well, you have no idea how much great stuff
that these priests have in their monastery. - So, it's a truly a love and hate relationship for you?
It sounds like it's more on the love side-- - [Eric] This building that we're in right here. - Yes. - Is the building in which I really put together
the conspiracy between the National Academy of Sciences and the National Science Foundation through
the Government University Industry Research round table to destroy the bargaining power of American
academics using foreign labor. On microfiche in the base. - Post docs and so on?
- Oh yeah, that was done here in this building. Isn't that weird? - I'm truly speaking with a revolutionary and a radical--
- No, no, no, no, no, no, no, no. At an intellectual level, I am absolutely garden variety.
I'm just straight down the middle. The system that we are in. This University is functionally insane.
- [Lex] Yeah. - Harvard is functionally insane and we don't understand that when we get these things wrong,
the financial crisis made this very clear. There was a long period where every grownup, everybody with a tie who spoke in baritone tones
with a right degree at the end of their name. - Yeah. - Were talking about how we banished volatility, we were in the great moderation.
Okay, they were all crazy. And who was right? It was like Nassim Taleb. - Right. - Nouriel Roubini.
Now, what happens is is that they claimed the market went crazy. But the market didn't go crazy.
The market had been crazy and what happened is is that it suddenly went sane. Well that's where we are with academics.
Academics right now is mad as a hatter and it's absolutely evident. I can show you graph after graph.
I can show you the internal discussions. I can show you the conspiracies. Harvard's dealing with one right now over its admissions
policies for people of color who happen to come from Asia. All of this madness is necessary to keep the game going.
What we're talking about, just while we're on the topic of revolutionaries, is we're talking about
the danger of an outbreak of sanity. - Yeah, you're the guy pointing out
the elephant in the room here and-- - The elephant has no clothes.
- Is that how that goes? I was gonna talk a little bit to Joe Rogan about this,
ran out of time, but I think you have some,
just listening to you, you can probably speak really eloquently to academia on the difference between the different fields.
So, do you think there's a difference between science, engineering and then the humanities in academia,
in terms of tolerance, that they're willing to tolerate? So, from my perspective I thought computer science
and maybe engineering is more tolerant to radical ideas, but that's perhaps innocent of me.
'Cause I always, you know all the battles going on now are a little bit more of the humanities side and gender studies and so on.
- Have you seen the American Mathematical Society's publication of an essay called Get out the Way.
- I have not, what's the-- - The idea is that white men who hold positions within Universities in mathematics
should vacate their positions so that young black women can take over or something like this.
- That's in terms of diversity, which I also wanted to ask you about, but in terms of diversity of strictly ideas.
- Oh, sure. - Do you think, 'cause you're basically saying physics as a community, has become a little bit intolerant to some degree,
to new radical ideas or at least you said that-- - But it's changed a little bit recently.
Which is that even string theory is now admitting, okay, this doesn't look very promising in the short term.
Right, so the question is what compiles, if you wanna take the computer science metaphor.
What will get you into a journal? Will you spend your life trying to push some paper into a journal or will it be accepted easily?
What do we know about the characteristics of the submitter and what gets taken up and what does not?
All of these fields are experiencing pressure because no field is performing so brilliantly well that it's
revolutionizing our way of speaking and thinking,
in the ways in which we have become accustomed. - But don't you think, even in theoretical physics,
a lot of times, even with theories like string theory, you could speak to this, it does eventually lead to
what are the ways that this theory would be testable? - Yeah, ultimately, although look,
there's this thing about Popper and the scientific method that's a cancer and a disease in the minds of very smart people.
That's not really how most of the stuff gets worked out, it's how it gets checked.
- Right, so-- - And there is a dialog between theory and experiment. But, everybody should read Paul Dirac's 1963
Scientific American article where he, you know, it's very interesting.
He talks about it as if it was about the Schrodinger equation and Schrodinger's failure to advance his own work because of his failure
to account for some phenomena. The key point is that if your theory is a slight bit off, it won't agree with experiment,
but it doesn't mean that the theory is actually wrong. But Dirac could as easily have been talking about his own
equation in which he predicted that the electrons should have an anti-particle.
And since the only positively charged particle that was known at the time was the proton, Heisenberg pointed out,
well shouldn't your anti-particle, the proton, have the same mass as the electron and doesn't that invalidate your theory?
So, I think that Dirac was actually being, potentially quite sneaky in talking about the fact
that he had been pushed off of his own theory, to some extent, by Heisenberg. But look, we fetishize the scientific method
and Popper and falsification because it protects us from crazy ideas entering the field.
So, you know, it's a question of balancing type one and type two error and we were pretty maxed out in one direction.
- The opposite of that. Let me say what comforts me. Sort of biology or engineering at the end of the day,
does the thing work? - Yeah. - You can test the crazies away.
Well see now, you're saying but some ideas are truly crazy and some are actually correct, so.
- Well there's pre-correct currently crazy. - Yeah. - Right? And so you don't wanna get rid of everybody
who's pre-correct and currently crazy. The problem is is that we don't have standards in general,
for trying to determine who has to be put to the sword in terms of their career
and who has to be protected as some sort of giant time suck pain in the ass who may change everything.
- Do you think that's possible? Creating a mechanism of those selective-- - Well, you're not gonna like the answer, but here it comes.
- [Lex] Oh, boy. - It has to do with very human elements.
We're trying to do this at the level of like rules and fairness, it's not gonna work.
'Cause the only thing that really understands this,
you ever read The Double Helix? - It's a book? - Oh, you have to read this book-- - Oh, boy. - Not only did Jim Watson
half discover this three dimensional structure of DNA, he was also one hell of a writer before he became an ass.
No, he's tried - Yes, like he is. - To destroy his own reputation-- - I knew about the ass, I didn't know about the good writer.
- Jim Watson is one of the most important people now living, and as I've said before, Jim Watson is too important
a legacy to be left to Jim Watson. That book tells you more about what actually moves the dial.
I mean, there's another story about him which I don't agree with, which is that he stole everything from Rosalind Franklin.
I mean, the problems that he had with Rosalind Franklin are real, but we should actually honor that tension
in our history by delving into it, rather than having a simple solution. Jim Watson talks about Francis Crick being a pain in the ass
that everybody secretly knew was super brilliant. And there's an encounter between Chargaff who came up with
the equimolar relations between the nucleotides, who should've gotten the structure of DNA and Watson and Crick,
and you know, he talks about missing a shiver in the heartbeat of biology and this stuff is so gorgeous,
it just makes you tremble even thinking about it. Look, we know very often who is to be feared,
and we need to fund the people that we fear. The people who are wasting our time need
to be excluded from the conversation. You see, and you know, maybe we'll make some errors
in both directions, but we have known our own people.
We know the pains in the asses that might work out, and we know the people who are really just blowhards who
really have very little to contribute most of the time. It's not 100%, but you're not gonna get there with rules.
- Right, it's using some kind of instinct. I mean, to be honest, I'm gonna make you roll your eyes
for a second, but in the first time I heard that there was large community of people who believe the earth is flat,
actually made me pause and ask myself the question-- - Why would there be such a community? - Yeah, is it possible the earth is flat?
So I had to like, wait a minute. I mean, then you go through a thinking process that I think is really healthy.
It ultimately ends up being a geometry thing I think. It's an interesting thought experiment at the very least.
- Well, see I don't, I do a different version of it. I say, why is this community stable? - Yeah, that's a good way to analyze it.
- Interesting that whatever we've done has not erased the community. So, you know, they're taking a long shot bet
that won't pan out, you know? Maybe we just haven't thought enough about the rationality of the square root of two
and somebody brilliant will figure it out. Maybe we will eventually land one day on the surface of Jupiter and explore it.
Right, these are crazy things that will never happen. - So, much of social media operates by AI algorithms,
we talked this a little bit, recommending the content you see. So, on this idea of radical thought, how much should AI show
you things you disagree with on Twitter and so on? In the Twitterverse in the--
- I hate this question. - Yeah? - Yeah. - 'Cause you don't know the answer? - No, no, no, no.
Look, they've pushed out this cognitive Lego to us that will just lead to madness.
It's good to be challenged with things that you disagree with. You answer is, no. It's gonna to be challenged with interesting things with
which you currently disagree, but that might be true. I don't really care about whether or not I disagree
with something or don't disagree, I need to know why that particular disagreeable thing is being pushed out.
Is it because it's likely to be true? Is it because, is there some reason? Because I write a computer generator to come up
with an infinite number of disagreeable statements that nobody needs to look at. So, please before you push things at me
that are disagreeable, tell me why. - There is an aspect in which that question is quite dumb,
especially because it's being used to almost
very generically by these different networks to say, well we're trying to work this out, but you know, basically how much,
do you see the value of seeing things you don't like? Not you disagree with, because it's very difficult to know
exactly what you articulated, which is the stuff that's important for you to consider that you disagree with.
That's really hard to figure out. The bottom line is the stuff you don't like. If you're a Hillary Clinton supporter,
it might not make you feel good to see anything about Donald Trump. That's the only thing algorithms can really optimize for currently.
They really can't-- - No, they can do better. - You think so? - No, we're engaged in some
moronic back and forth where I have no idea why people who
are capable of building Google, Facebook, Twitter are having us in these
incredibly low level discussions. Do they not know any smart people? Do they not have the phone numbers
of people who can elevate these discussions? - They do, but this--
- Please, no, no, no. - They're optimizing for a different thing and they are pushing those people out of those rooms. - No, they're optimizing for things we can't see,
and yes, profit is there. Nobody's questioning that. But they're also optimizing for things like political
control or the fact that they're doing business in Pakistan and so they don't wanna talk about all the things that they're going to bending to in Pakistan.
So, we're involved in a fake discussion. - You think so, you think these conversations
at that depth are happening inside Google? You don't think they have some basic metrics under user engagements?
- You're having a fake conversation with us, guys. We know you're having a fake conversation. I do not wish to be part of your fake conversation.
You know how to cool these units. You know high availability like nobody's business.
My Gmail never goes down, almost. - So you think just because they can do incredible work on
the software side with infrastructure, they can also deal with some of these difficult questions
about human behavior, human understanding, you're not, (chuckling). - I mean, I've seen the developer's screens
that people take shots of inside of Google. - [Lex] Yeah. - And I've heard stories inside of Facebook and Apple.
We're not, we're engaged, they're engaging us in the wrong conversations.
We are not at this low level. Here's one of my favorite questions. - Yeah. - Why is every piece
of hardware that I purchase in text base equipped as a listening device?
Where's my physical shutter to cover my lens? We had this in the 1970s.
They had cameras that had lens caps, you know? How much would it cost to have a security model?
Pay five extra bucks. Why is my indicator light software controlled?
Why when my camera is on, do I not see that the light is on by putting it as something that cannot be bypassed?
Why have you setup all of my devices, at some difficulty to yourselves,
as listening devices and we don't even talk about this. This thing is total fucking bullshit.
- Well, I hope, so. - Wait, wait, wait. - These discussions are happening about privacy, 'cause they're more difficult than you give 'em credit for--
- It's not just privacy. - Yeah? - It's about social control. We're talking about social control.
Why do I not have controls over my own levers? Just have a really cute UI, where I can switch,
I can dial things or I can at least see what the algorithms are. - You think that there are some
deliberate choices being made here-- - There's emergence and there is intention.
There are two dimensions. The vector does not collapse onto either axis. But the idea that anybody who suggests
that intention is completely absent is a child.
- That's really beautifully put and like many things you've said is gonna make me-- - Can I turn this around slightly though?
- Yeah. - I sit down with you and you say that you're obsessed with my feed. - Uh huh. - I don't even know what
my feed is, what are you seeing that I'm not? - I was obsessively looking through your feed on Twitter,
'cause it was really enjoyable because there's the Tom Lehrer element, there's the humor in it. - By the way that feed is ericrweinstein on Twitter.
- That's great. - @ericrweinstein. - Yeah. - No, but seriously, why? - Why did I find it enjoyable or what was I seeing?
- What are you looking for? Why are we doing this? What is this podcast about? I know you got all these interesting people.
I'm just some guy who is sort of a podcast guest. - Sort of a podcast, you're not even wearing a tie.
I mean, - I'm not even wearing a tie. - It's not even a serious interview.
I was searching for meaning, for happiness, for a dopamine rush, so short term and long term.
- And how are you finding your way to me? What is, I don't honestly know what I'm doing to reach you.
- The representing ideas which field common sense to me and not many people are speaking.
So it's kinda like, the Intellectual Dark Web folks, right?
These folks, from Sam Harris to Jordan Peterson, to yourself, are saying things where it's like,
you're like saying, look there's an elephant and he's not wearing any clothes and I say, yeah, yeah,
let's have more of that conversation. That's how I'm finding you. - I'm desperate to try to change
the conversation we're having. I'm very worried we've got an election in 2020. I don't think we can afford four more years of
a misinterpreted message, which is what Donald Trump was, and I don't want the destruction of our institutions.
They all seem hellbent on destroying themselves. So, I'm trying to save theoretical physics, trying to save the New York Times,
trying to save our various processes and I think it feels delusional to me that this is falling to a tiny group
of people who are willing to speak out without getting so freaked out that everything they say
will be misinterpreted and that their lives will be ruined through the process. I mean, I think we're in an absolutely bananas period
of time and I don't believe it should fall to such a tiny number of shoulders to shoulder this weight.
- So, I have to ask you on a capitalism side, you mentioned that technology is killing capitalism
or has effects that are, well not unintended, but not what economists would predict
or speak of capitalism creating. I just wanna talk to you about in general,
the effect of even then, artificial intelligence or technology automation taking away jobs and these kinds
of things and what you think is the way to alleviate that. Whether the Andrew Ang presidential candidate with
universal basic income, UBI, what are your thoughts there? How do we fight off the negative effects
of technology that-- - All right, you're a software guy, right? - Yep. - A human being is a worker, is an old idea.
- Yes. - A human being has a worker is a different object, right? - Yes.
- So if you think about object oriented programming as a paradigm, a human being has a worker
and a human being has a soul. We're talking about the fact that for a period of time, the worker that a human being has,
was in a position to feed the soul that a human being has. However, we have two separate claims
on the value in society. One is as a worker and the other is as a soul,
and the soul needs sustenance, it needs dignity, it needs meaning, it needs purpose.
As long as you're means of support is not highly repetitive,
I think you have a while to go before you need to start worrying. But if what you do is highly repetitive
and it's not terrible generative, you are in the crosshairs of for loops and while loops and that's
what computers accel at; repetitive behavior and when I say repetitive I may mean things that have never happened
through combinatorial possibilities, but as long as it has a looped characteristic to it, you're in trouble.
We are seeing a massive push towards socialism because capitalists are slow to address
the fact that a worker may not be able to make claims. A relatively undistinguished median member of our society
still has needs to reproduce, needs to dignity
and when capitalism abandons the median individual or the bottom tenth or whatever it's going to do,
it's flirting with revolution and what concerns me is that the capitalists aren't sufficiently
capitalistic to understand this. You really want to court authoritarian control
in our society because you can't see that people may not be able to defend themselves in the marketplace
because the marginal product of their labor is too low to feed their dignity as a soul?
So, my great concern is that our free society has to do with the fact that we are self organized.
I remember looking down from my office in Manhattan when Lehman Brothers collapsed and thinking,
who's gonna tell all these people that they need to show up at work when they don't have a financial system
to incentivize them to show up at work? So, my complaint is first of all, not with the socialists,
but with the capitalists, which is you guys are being idiots. You're courting revolution by continuing to harp on the same
old ideas that well, try harder, bootstrap yourself. Yeah, to an extent that works, to an extent.
But we are clearly headed in a place that there's nothing that ties together our need to contribute and our need
to consume and that may not be provided by capitalism, because it may have been a temporary phenomena.
So, check out my article on anthropic capitalism and the new gimmick economy.
I think people are late getting the wake up call, and we would be doing a better job saving capitalism
from itself because I don't want this done under authoritarian control, and the more we insist that
everybody who's not thriving in our society during their reproductive years in order to have a family,
is failing at a personal level. I mean, what a disgusting thing that we're saying.
What a horrible message. Who the hell have we become that we've so bought in to the Chicago model that we can't see the humanity
that we're destroying in that process and I hate the thought of communism, I really do.
My family has flirted with it decades past, it's a wrong, bad idea, but we are going to need to figure
out how to make sure that those souls are nourished and respected and capitalism better have an answer.
And I'm betting on capitalism, but I gotta tell ya, I'm pretty disappointed with my team. - So you're still on the capitalism team,
just there's a theme here-- - [Eric] Well, radical capitalism. - Right, hyper capitalism, yeah. - Look, I want, I think hyper capitalism is gonna
have to be coupled to hyper socialism. You need to allow the most productive people to create wonders and you gotta stop bogging them down
with all of these extra nice requirements. You know, nice is dead. Good has a future.
Nice doesn't have a future because nice ends up with gulags.
- Damn, that's a good line. Okay, last question. You Tweeted today, a simple, quite insightful equation
saying "Imagine that every unit f of fame you picked up, "s stalkers and h haters".
So, I imagine s and h are dependent on your path to fame, perhaps a little bit-- - Well, it's not a simple.
I mean, people always take these things literally when you have like 280 characters to explain yourself.
- So you mean that's not a mathematical-- - No, there's no law. - Oh, okay, all right. - I just, I put the word imagine because I still
have a mathematicians desire for precision. - Yes. - Imagine that this were true. - But there was a beautiful way to imagine
that there is a law that has those variables in it-- - [Eric] Yeah, yeah. - And you've become quite famous these days,
so how do you yourself optimize that equation with the peculiar kind of fame that you've gathered along the way?
- I wanna be kinder. I wanna be kinder to myself, I wanna kinder to others, I wanna be able to have heart,
compassion and these things are really important, and I have a pretty spectrumy kind of approach to analysis.
I'm quite literal. I can go full Rain Man on you at any given moment. No, I can, I can.
It's facultative autism, if you like, and people are gonna get angry because they want autism to be respected, but.
When you see me coding or you see me doing mathematics, you know, I speak with speech apnea, (stutters),
be right down for dinner, you know? - [Lex] Yeah. - We have to try to integrate ourselves in those tensions between, you know,
it's sort of back to us as a worker and us as a soul. Many of us are optimizing one at the expense of the other.
And I struggle with social media and I struggle with people making threats against our families and I struggle
with just how much pain people are in. And if there's one message I would like to push out there,
you're responsible, everybody, all of us, myself included, with struggling.
Struggle mightily because it's nobody else's job to do your struggle for you. Now with that said, if you're struggling and you're trying,
and you're trying to figure out how to better yourself and where you've failed, where you've let down your family, your friends, your workers, all this kind of stuff,
give yourself a break, you know? If it's not working out, I have a lifelong relationship
with failure and success. There's been no period of my life where both haven't been present in one form or another.
And, I do wish to say that a lot of the times people think this is glamorous.
I'm about to go, you know, do a show with Sam Harris. - Yeah. - People are gonna listen in on two guys having a conversation on stage.
It's completely crazy when I'm always trying to figure out how to make sure that those people get maximum value
and that's why I'm doing this podcast, you know, just give yourself a break.
You owe us your struggle. You don't owe your family or your coworkers or your lovers or your family members success.
As long as you're in there and you're picking yourself up, recognize that this new situation with the economy
that doesn't have the juice to sustain our institutions, has caused the people who've risen to the top
of those institutions to get quite brutal and cruel. Everybody is lying at the moment.
Nobody is really truth teller. Try to keep your humanity about you. Try to recognize that if you're failing,
if things aren't where you want them to be and you're struggling and you're trying to figure out what you're doing wrong, what you could do,
it's not necessarily all your fault. We are in a global situation. I have not met the people who are honest,
kind, good, successful. Nobody that I've met is checking all the boxes.
Nobody's getting all 10s. So, I just think that's an important message that doesn't get pushed out enough.
Either people wanna hold society responsible for their failures, which is not reasonable.
You have to struggle, you have to try. Or they wanna say you're 100% responsible for your failures, which is total nonsense.
- Beautifully put. Eric, thank you so much for talking today. - Thanks for having me, buddy.

----------

-----

--63--  

-----
Date: 2019.03.12
Link: [# Leslie Kaelbling: Reinforcement Learning, Planning, and Robotics | Lex Fridman Podcast #15](https://www.youtube.com/watch?v=Er7Dy8rvqOc)
Transcription:

Intro
the following is a conversation with Leslie Kayla bling she's a roboticist and professor at MIT
she's recognized for her work and reinforcement learning planning robot navigation and several other topics in
AI she won the edge KY computers and thought award and was the editor-in-chief of the prestigious
journal machine learning research this conversation is part of the artificial
intelligence podcast at MIT and beyond if you enjoy it subscribe on youtube
itunes or simply connect with me on twitter at Lex Friedman spelled Fri D
and now here's my conversation with Leslie Kael Blaine what made me get
What made you get excited about AI
excited about AI I can say that as I read girdle Ashur back when I was in high school that was pretty formative
for me because it exposed the
interestingness of primitives and combination and how you can make complex
things out of simple parts and ideas of AI and what kinds of programs might
generate intelligent behavior so so you first fell in love with AI reasoning
logic versus robots yeah the robots came because my first job so I finished an undergraduate
degree in philosophy at Stanford and was about to finish master's in computer science and I got hired at SR I in their
AI lab and they were building a robot it was a kind of a follow-on to shaky but
all the shaky people were not there anymore and so my job was to try to get this robot to do stuff and that's really kind
of what got me interested in robots so maybe taking a small step back your bachelor's in Stanford and philosophy
Philosophy and computer science
did masters and PhD in computer science but the bachelors in philosophy so what was that journey like what elements of
philosophy do you think you bring to your work in computer science so the
part of the reason that I didn't do a computer science undergraduate degree was that there wasn't one at Stanford at
the time but that there's part of philosophy and in fact Stanford has a special sub major in something called
now symbolic systems which is logic model theory formal semantics of natural
language and so that's actually a perfect preparation for work in AI and
computer science that that's kind of interesting so if you were interested in artificial intelligence what what kind
Majors in AI
of majors were people even thinking about taking what is it in your science was so besides philosophies what were
you supposed to do if you were fascinated by the idea of creating intelligence there weren't enough people who did that for that even to be at
conversation okay I mean I think probably probably philosophy I mean it's
interesting in my class my graduating class of undergraduate philosophers
probably maybe slightly less than half went on in computer science
slightly less than half went on in law and like one or two went on in philosophy so it was a common kind of
connection do you think AI researchers have a role be part time philosophers or should they stick to the solid science
AI philosophers
and engineering without sort of taking the philosophizing tangents I mean you
work with robots you think about what it takes to create intelligent beings aren't you the perfect person to think
about the big picture philosophy of it all the parts of philosophy that are closest to AI I think or at least the
closest to AI that I think about are stuff like belief and knowledge and
denotation and that kind of stuff and that's you know it's quite formal and it's like just one step away from the
kinds of computer science work that we do kind of routinely I think that there
are important questions still about what you can do with a machine and what you
can't and so on although at least my personal view is that I'm completely a materialist and I don't think that
there's any reason why we can't make a robot be behaviorally indistinguishable
from a human and the question of whether it's in the distinguishable internally
whether it's a zombie or not in philosophy terms I actually don't I don't know and I
don't know if I care too much about that right there there's a philosophical notions they're mathematical and
The philosophical gap
philosophical because we don't know so much of how difficult it is how difficult is a perception problem how
difficult is the planning problem how difficult is it to operate in this world successfully because our robots are not
currently as successful human beings and many tasks the the question about the
gap between current robots and human beings borders a little bit on philosophy you know the expanse of
knowledge that's required to operate in this world and the ability to form common-sense knowledge the ability to
reason about uncertainty much of the work you've been doing there's those
open questions there that I don't know require to activate a certain
big-picture view to me that doesn't seem like a philosophical gap to me it's a there is a big technical
gap yes technical gap but I don't see any reason why it's more than a
technical gap perfect so when you mention AI you know sorry
The first robot
and maybe can you describe to me when you first fell in love with robotics
with robots or inspired which so you should mention flaky or shaky shaky
flaky and what was the robot that first captured your imagination what's possible right well this so the first
robot I worked was like shakey was a robot that the SR I people had built but
by the time I think when I arrived it was sitting in a corner of somebody's office dripping hydraulic fluid into a
pan but its iconic and really everybody should read the shaky tech report
because it has so many good ideas in it I mean they invented a star search and
symbolic planning and learning macro operators they had the level kind of
configuration space planning for the robot they had vision they had all this the basic ideas of a ton of things okay
take a step by the shaky have arms that was a job could push objects and so it
would move things around with which actuator itself with its base okay so it
could but it and they had painted the baseboards black so it used it used
vision to localize itself in a map it detected objects it could detect objects that were surprising to it it would plan
and re plan based on what it saw it reasoned about whether to look and take pictures I mean it really had the basics
of of so many of the things that we think about now how do you represent the
space around it so it had representations that are bunch of different levels of abstraction so it
had I think a kind of an occupancy grid of some sort at the lowest level at the
high level it was abstract symbolic kind of rooms and connectivity it's a word as
flaky coming yeah okay so at us RI and we were building a
brand-new robot as I said none of the people from the previous project were kind of there or involved anymore so we
were kind of starting from scratch and my advisor was Stan resin shine he ended
up being my thesis advisor and he was motivated by this idea of situated
computation or situated automata and the idea was that the tools of logical
reasoning were important but possibly only for the engineers or designers to
use in the analysis of a system but not necessarily to be manipulated in the head of the system itself right so I
might use logic to prove a theorem about the behavior of my robot even if the robots not using logic and it's headed
to prove theorems right so that was kind of the distinction and so the idea was
to kind of use those principles to make a robot do stuff but a lot of the basic
things we had to kind of learn for ourselves because I had zero background in robotics I didn't know anything about
control I don't know anything about sensors so we reinvented a lot of wheels on the way to getting that robot to do
stuff do you think that was an advantage or hindrance oh no it's I mean I I'm big in favor of
wheel reinvention actually I mean I think you learn a lot by doing it it's
important though to eventually have the pointers to so that you can see what's really going on but I think you can
appreciate much better the good solutions once you've messed around a little bit
on your own and found a bad one yeah I think you mentioned reinventing reinforcement learning yeah and referring to rewards as pleasures by a
Reinventing reinforcement learning
pleasure yeah I think yeah I think it's a nice name for it it's more it's more
fun almost do you think you could tell the history of AI and machine learning
reinforcement learning and how you think about it from the 50s to now one thing
is that its oscillates right so things become fashionable and then they go out
and then something else becomes cool and that it goes out and so on and I think there's so there's some interesting sociological process that actually
drives a lot of what's going on early days was kind of cybernetics and control right
and the idea that of homeostasis people have made these robots that could I
don't know try to plug into the wall when they needed power and then come loose and roll around and do stuff and
then I think over time the thought well that was inspiring but people said no no
we want to get maybe closer to what feels like real intelligence or human intelligence and then maybe the expert
systems people tried to do that but maybe a little too superficially right
so oh we get the surface understanding of what intelligence is like because I
understand how a steel mill works and I can try to explain it to you and you can write it down in logic and then we can make a computer infer that and then that
didn't work out but what's interesting I think is when a thing starts to not be
working very well it's not only do we change methods we change problems right
so it's not like we have better ways of doing the problem of the experts those people are trying to do we have no ways
of trying to do that problem oh yeah I know I think maybe a few but we kind of
give up on that problem and we switch to a different problem and we we work that
for a while and we I guess there's a broad community as a community and there's a lot of people who would argue you don't give up on the problem it's
just you decrease the number of people working on it you almost kind of like put it on the shelf so we'll come back to this 20 years
later yeah I think that's right or you might decide that it's malformed like
you might say it's wrong to just try to make something that does superficial
symbolic reasoning behave like a doctor you can't do that until you've had the
sensorimotor experience of being a doctor or something right so there's arguments that say that that's problem
was not well formed or it could be that it is well for it but but we just weren't approaching it well you mention
Roadblocks in symbolic reasoning
that your favorite part of logic and symbolic systems is that they give short names for large sets
so there is some use to this they use just as a symbolic reasoning though the
looking at expert systems and symbolic computing what do you think are the roadblocks that were hit in the eighties
and nineties ah okay so right so the fact that I'm not a fan of expert
systems doesn't mean that I'm not a fan of some kinds of symbolic reasoning right so let's see road blocks but the
main road block I think was that the idea that humans could articulate their
knowledge effectively into into you know some kind of logical statements so it's
not just the cost the effort but really just the capability of doing it right because we're all experts in vision
right but not totally don't have introspective access into how we do that right and it's true that I mean I think
the idea was well of course even people then would know of course I wouldn't ask you to please write down the rules that you use for recognizing water bottle
that's crazy and everyone understood that but we might ask you to please write down the rules you use for
deciding I don't know what tie to put on or how to set up a microphone or
something like that but even those things I think people maybe I think what
they found I'm not sure about this but I think what they found was that that so-called experts could give
explanations that sort of post hoc explanations for how and why they did things but they weren't necessarily very
good and then they different they depended on maybe some kinds of
perceptual things which again they couldn't really define very well so I think I think fundamentally I think that
the underlying problem with that was the assumption that people could articulate how and why they make their decisions
all right so it's almost in call encoding the knowledge from converting
from expert to something that a machine could understand and reason with no no not even just encoding but getting it
out of you just not not writing it I mean yes hard also to write it down for
the computer yeah but I don't think that but can produce it you can tell me a
story about why you do stuff but I'm not so sure that's the way great so there
Where symbolic reasoning is useful
are still on the hierarchical planning side places where symbolic reasoning is
very useful so as you've talked about so
where so don't where's the gap yeah okay good so saying that humans can't provide
a description of their reasoning processes that's ok fine but that
doesn't mean that it's not good to do reasoning of various styles inside a computer those are just two orthogonal points so then the question is what kind
of reasoning should you do inside a computer right and the answer is I think you need to do all different kinds of
reasoning inside a computer depending on what kinds of problems you face I guess
Why abstractions are critical
the question is what kind of things can you encode symbolically so you can
reason about I think the idea about an even symbolic I don't even like that
terminology because I don't know what it means technically informally I do believe in abstractions so abstractions are
critical right you cannot reason a completely fine grain about everything
in your life right you can't make a plan at the level of images and torques for getting a PhD right so you have to
reduce the size of the state space and you have to reduce the horizon if you're gonna reason about getting a PhD or even
buying the ingredients to make dinner and so so how can you reduce the spaces
and the horizon of the reasoning you have to do and the answer is abstraction spatial abstraction temporal abstraction
I think abstraction along the lines of goals is also interesting like you might or well abstraction and decomposition
goals this may be more of a decomposition thing so I think that's where these kinds of if you want to call
it symbolic or discrete models come in you you talk about a room of your house
instead of your pose you talk about you know doing something during the
afternoon instead of at 2:54 and you do that because it makes your reasoning
problem easier and also because you have you don't have enough information to
reason in high fidelity about your pose of your elbow at 2:35 this afternoon
anyway right when you're trying to get a PhD okay except for at that moment at
that moment you do have to use it about the pose of your elbow maybe but then you maybe you do that in some continuous joint space kind of modeling so I again
I my biggest point about all of this is that there should be the dogma is not
the thing right we shouldn't it shouldn't be that I'm in favor against symbolic reasoning and you're in favor
against neural networks it should be that just just computer science tells us
what the right answer to all these questions is smart enough to figure it out oh yeah when you try to actually solve the problem with computers the right
Automated construction of abstractions
answer comes out you mentioned abstractions mm-hmm I mean you all networks form abstractions or rather
there's there's automated ways to form strategies and there's expert driven ways to form abstractions and export
human driven ways and humans just seems to be way better at forming abstractions currently and certain problems so when
you're referring to 2:45 and PM versus afternoon how do we construct that
taxonomy is there any room for automated construction of such abstractions oh I
think eventually yeah I mean I think when we get to be better and machine learning engineers will build algorithms
that build awesome abstractions that are useful in this kind of way that you describe yeah yeah so let's then step
from the the abstraction discussion and let's talk about BOM mdps partially
observable Markov decision processes so uncertainty so first water Markov decision processes and maybe how much of
our world could be models and mdps how much when you wake up in them morning me making breakfast how do you
think of yourself as an MDP so how do you think about MVPs and how they relate
to our world well so there's a stance question right so a stance is a position
that I take with respect to a problem so I as a researcher or person who design
systems can decide to make a model of the world around me in some terms right so I take this messy
world and I say I'm gonna treat it as if it were a problem of this formal kind
and then I can apply solution concepts around rhythms or whatever to solve that formal thang right so of course the
world is not anything it's not an MDP or a pom DP I don't know what it is but I can model aspects of it in some way or
some other way and when I model some aspect of it in a certain way that gives me some set of algorithms I can use you
Markov decision process
can model the world in all kinds of ways some have some are more accepting of
uncertainty more easily modeling uncertainty of the world some really force the world to be deterministic
and so the certainly NDP's model the uncertainty of the world yes model some
uncertainty the model not present state uncertainty but they model uncertainty in the way the future will unfold right
so what are Markov decision process so marketers process is a model it's a kind
of model that you could make that says I I know completely the current state of my system and what it means to be a
state is that I that all they have all the information right now that will let me make predictions about the future as
well as I can so that remembering anything about my history wouldn't make my predictions any better and but it but
then it also says that that then I can take some actions that might change the state of the world and that I don't have
a deterministic model of those changes I have a probabilistic model of how the world might change it's a it's a useful
model for some kinds of systems I think it's a I mean it's certainly not a good
model for most problems I think because for most problems you don't actually
know State for most problems you it's partially observed so that's now a
different problem class so okay that's where the poverty P is the partially
Partial observable Markov decision process
observable Markov decision process step n so how do they address the fact that
you can't observe most your incomplete information about most of the world around you right so now the idea is we
still kind of postulate that there exists a state we think that there is some information about the world out
there such that if we knew that we could make good predictions but we don't know the state and so then we have to think
about how but we do get observations maybe I get images right here things are I feel things and those might be local
or noisy and so therefore they don't tell me everything about what's going on and then I have to reason about given
the history of actions I've taken in observations I've gotten what do I think is going on in the world and then given
my own kind of uncertainty about what's going on in the world I can decide what actions to take and so difficult is this
Planning under uncertainty
problem of planning under uncertainty in your view and you know long experience
of modeling the world trying to deal with this uncertainty in special and
real of all systems optimal planning for even discrete hamdi peas can be
undecidable depending on how you set it up and free so lots of people say I
don't use pom D peas because they are intractable and I think that that's are kind of a very funny thing to say
because the problem you have to solve is the problem you have to solve so if the
problem you have to solve is intractable that's what makes us AI people right so we saw we understand that the problem
we're solving is is compute wildly intractable that we can't we will never be able to solve it optimally at least I
don't yeah right so later we can come back to an idea about bounded optimality
and something but anyway I don't we can't come up with optimal solutions to these problems so we have to make
approximations approximations in modeling approximations in the solution algorithms and so on and so I don't have
a problem with saying yeah my problem actually it is pom DP in continuous space with continuous
observations and it's so computationally complex I can't even think about it's you know Big O whatever but that doesn't
prevent me from it helps me gives me some clarity to think about it that way and to then take steps to make
approximation after approximation to get down to something that's like computable in some reasonable time when you think
Optimality
about optimality you know the community broadly is shifted on that I think a
little bit in how much they value the idea of optimality of chasing an optimal
solution positive views of chasing an optimal solution changed over the years
and when you work with robots that's interesting I think we have a little bit
of a methodological crisis actually from the theoretical side I mean I do think
that theory is important in that right now we're not doing much of it so
there's lots of empirical hacking around and training this and doing that and reporting numbers but is it good is it
bad we don't know we very hard to say things and if you look at like computer science
theory so people talked for a while everyone was about solving problems optimally or
completely and and then there were interesting relaxation so people look at
oh can I are their regret bounds or can I do some kind of you know approximation
can I prove something that I can approximately solve this problem or that I get closer to the solution as I spend
more time and so on what's interesting I think is that we don't have good
approximate solution concepts for very difficult problems right I like to you
know I like to say that I I'm interested in doing a very bad job of very big problems but I would I wish I could say
something I wish I had a I don't know some kind of a formal solution concept
that I could use to say oh this this algorithm actually it gives me something
like I know what I'm gonna get I can do something other than just run it and get out so that having that notion is still
Science vs Engineering
somewhere deeply compelling to you the notion that you can say you can drop
thing on the table says this you can expect this this out gonna give me some good results
I hope science will I mean there's engineering in there science I think
that they're not exactly the same and I think right now we're making huge engineering like leaps and bounds so
that engineering is running away ahead of the science which is cool and often how it goes right so we're making things
and nobody knows how and why they work roughly but we need to turn that into
science there's some form it's yeah there's some room for formalizing we
need to know what the principles are why does this work why does that not work I mean for awhile people built bridges by
trying but now we can often predict whether it's going to work or not without building it can we do that for
learning systems or for robots so your hope is from a materialistic perspective that
intelligence artificial intelligence systems robots okay I were just more fancier bridges believe space what's the
difference between belief space and state space I mentioned MDPs fond appease you reasoning about you sense
the world there's a state what's this belief space idea I believe
space that is instead of thinking about what's the state of the world and trying
to control that as a robot I think about what is the space of beliefs that I
could have about the world what's if I think of a belief as a probability distribution over ways the world could
be a belief state is a distribution and then my control problem if I'm reasoning
about how to move through a world I'm uncertain about my control problem is
actually the problem of controlling my beliefs so I think about taking actions not just what effect they'll have on the
world outside but what effect I'll have on my own understanding of the world outside and so that might compel me to
ask a question or look somewhere to gather information which may not really
change the world state but it changes my own belief about the world that's a powerful way to to empower the agent to
Belief vs State Space
reason about the world to explore the world what kind of problems does it allow you to solve to to consider belief
space versus just state space well any problem that requires deliberate information gathering right so if in
some problems like chess there's no uncertainty or maybe there's uncertainty
about the opponent there's no uncertainty about the state and some
problems there's uncertainty but you gather information as you go right you might say oh I'm driving my autonomous
car down the road and it doesn't know perfectly where it is but the Llyod ours are all going all the time so I don't
have to think about whether to gather information but if you're a human driving down the road you sometimes look
over your shoulder to see what's going on behind you in the lane and you have to
side whether you should do that now and you have to trade off the fact that you're not seeing in front of you and
you're looking behind you and how valuable is that information and so on and so to make choices about information
gathering you have to reasonably spaced also also I mean also to just take into
account your own uncertainty before trying to do things so you might say if I understand where I'm standing relative
to the door jamb pretty accurately then it's okay for me to go through the door but if I'm really not sure where the
door is then it might be better to not do that right now the degree of your uncertainty ball
about the world is actually part of the thing you're trying to optimize in forming the plan right so this idea of a
long horizon of planning for a PhD or just even how to get out of the house or
how to make breakfast you show this presentation of the the WTF was the fork
of robot looking at a sink and can you
describe how we plan in this world of this idea of hierarchical planning we've mentioned this is a yeah how can a robot
hope to plan about something this was such a long hallway people since
probably reasoning began have thought about hierarchical reasoning the temporal hierarchy and particular
spatial hierarchy but let's talk about temporal hierarchy so you might say oh I have this long execution I have to do
but I can divide it into some segments abstractly right so maybe you have to
get out of house I have to get in the car I have to drive so on and so you can
plan if you can build abstractions so this we started out by talking about abstractions and we're back to that now
if you can build abstractions in your state space and abstractions sort of
temporal abstractions then you can make plans at a high level and you can say I'm gonna go to town and then I'll have
to get gas and then I can go here and I can do this other thing and you can reason about the dependencies and constraints among these
actions again without thinking about the complete details what we do in our
hierarchical planning work is then say alright I make a plan at a high level of abstraction I have to have some reason
to think that it's feasible without working it out in complete detail and that's actually the interesting step I
always like to talk about walking through an airport like you can plan to go to New York and arrive at the airport
and then find yourself in an office building later you can't even tell me in advance what your plan is for walking
through the airport partly because you're too lazy to think about it maybe but partly also because
you just don't have the information you don't know what gate you're landing in or what people are gonna be in front of
you or anything so there's no point in planning in detail but you have to have
you have to make a leap of faith that you can figure it out once you get there and it's really interesting to me how
you arrive at that how do you they say
you have learned over your lifetime to be able to make some kinds of predictions about how hard it is to achieve some kinds of sub goals and
that's critical like you would never plan to fly somewhere if you couldn't didn't have a model of how hard it was
to do some of the intermediate steps so one of the things we're thinking about now is how do you do this kind of very aggressive generalization to situations
that you haven't been in and so on to predict how long will it take to walk through the Kuala Lumpur Airport like
you give me an estimate and it wouldn't be crazy and you have to have an estimate of that in order to make plans
that involve walking through the Kuala Lumpur Airport even if you don't need to know it in detail so I'm really
interested in these kinds of abstract models and how do we acquire them but once we have them we can use them to do
hierarchical reasoning which is I think it's very important yeah there's this notion of gold' regression and preimage
Starting at the goal
back chaining this idea of starting at the goal and it's just for these big clouds of states you get I mean it's
almost like saying to the airport you know you you know once you show up
to the airport that that's you you're like a few steps away from the goal so
like thinking of it this way it's kind of interesting I don't know if you have sort of further comments on them of
starting at the goal why that yeah I mean it's interesting that Simon herb
Simon back in the early days of AI did talked a lot about means-ends reasoning and reasoning back from the goal there's
a kind of an intuition that people have that the number of that state space is
big the number of actions you could take is really big so if you say here I sit and I want to search forward from where
I am what are all the things I could do that's just overwhelming if you say if you can reason at this other level and
say here's what I'm hoping to achieve what can I do to make that true that somehow the branching is smaller now
what's interesting is that like in the AI planning community that hasn't worked out in the class of problems that they
look at and the methods that they tend to use it hasn't turned out that it's better to go backward it's still kind of
my intuition that it is but I can't prove that to you right now all right I'd share your intuition at least for us
Planning human life
mere humans speaking of which when you
maybe never take it and take a look take a little step into that philosophy circle how hard would it when you think
about human life you should give those examples often how hard do you think it is to formulate human life is a planning
problem or aspects of human life so when you look at robots you're often trying to think about object manipulation tasks
about moving a thing when you when you take a slight step outside the room let
the robot leave and go get lunch or maybe try to pursue more fuzzy goals how
hard do you think is that problem if you were to try to maybe put another way try to formulate human life as a planning
problem well that would be a mistake I mean it's not all the planning problem right every think it's really really
important that we understand that you have to put together pieces and parts
that have different styles of reasoning representation and learning I think I think it's it's seems probably clear to
anybody that that you you can't all be this or all be that brains aren't all
like this are all like that right they have different pieces and parts and substructure and so on so I don't think
that there's any good reason to think that there's going to be like one true algorithmic thing that's gonna do the
whole job just a bunch of pieces together designed to solve a bunch of
Modelbased vs modelfree
specific problem one the specific styles of problems I mean there's probably some
reasoning that needs to go on in image space I think again there's this model
based vs. model free idea it's I only enforce spent learning people talk about it oh should I learn I could learn a
policy just straight up a way of behaving I could learn it's popularly a
value function that's some kind of weird intermediate ground or I could learn a
transition model or it tells me something about the dynamics of the world if I take a trip if imagine that I
learned in a transition model and I couple it with a planner and I draw a box around that I have a policy again
it's just stored a different way right right it's in but it's just as much of a
policy as the other policy it's just I've made I think the way I see it is it's a time-space trade-off in
computation right a more overt policy representation maybe it takes more space
but maybe I can compute quickly what action I should take on the other hand maybe a very compact model of the world
dynamics plus a planner let's make compute what action to take to just more slowly there's no I mean I don't think there's
no argument to be had it's just like a question of what form of computation is
best for us for the various subproblems right so and and so like learning to do
algebra manipulations for some reason is good I mean that's probably gonna want naturally is sort of a different
representation than riding a unicycle at the time constraints on the unicycle or serious this thing space is maybe
smaller I don't know but so I could be the more human-sized of falling in love
Perception vs planning
having a relationship that might be another yeah another style of no idea
how to model that yeah that's let's first solve the algebra an object may patient what do you think is harder
perception or planning perception that's understanding that's so what do you
think is so hard about perception by understanding the world around you well I think the big question is
representational a hugely the question is representation so perception has made
great strides lately right and we can classify images and we can play certain
kinds of games of predict I to steer in the car and all this sort of stuff I don't think we have a very good idea of
what perception should deliver right so if you if you believe in modularity ok
there's there's a very strong view which says we shouldn't build in any
modularity we should make a giant gigantic neural network trained it end-to-end to do the thing and that's
the best way forward and it's hard to argue with that except on a sample
complexity basis right so you might say oh well if I want to do end-to-end Rio first of all anything on this giant
giant neural network it's going to take a lot of data and a lot of like broken robot system so then the only answer is
to say ok we have to build something in build in some structure or some bias we
know from theory of machine learning the only way to cut down the sample complexity is to kind of cut down somehow cut down the hypothesis space
you can do that by building in bias there's all kinds of reason to think that nature built bias into humans
[Music] convolution is a bias right it's a very strong bias and it's a very critical
bias so my own view is that we should look for more things that are like
convolution but that other aspects of reasoning right so convolution helps us a lot with a
certain kind of spatial reasoning that's quite close to the imaging I think
there's other ideas like that maybe some amount of forward search maybe some
notions of abstraction maybe the notion that objects exist actually I think that's pretty important and a lot of
people won't give you that to start with right so almost like a convolution in the in the object semantic object space
Convolution
of some kind sometimes some kind of ideas in there that's right people who started like the graph graph convolutions are an idea that are
related to racial relational representations and so so I think there
are so you I've come far afield from perception but I think I think the thing
that's going to make perception that kind of the next step is actually understanding better what it should
produce right so what are we going to do with the output of it right it's fine when what we're gonna do with the output
is Sudhir it's less clear when we're just trying to make a one integrated
intelligent agent what should the output of perception be we have no idea and how
should that hook up to the other stuff we don't know so I think the pressing question is what kinds of structure can
we build in that are like the moral equivalent of convolution that will make a really awesome super structure that
then learning can kind of progress on efficiently I agree very compelling description of actually where we stand
Selfawareness
with the perceptual mom you're teaching a course on embodying intelligence what
do you think it takes to build a robot with human level intelligence I don't
know if we knew we would do it if you were to I mean okay so do you think a
robot needs to have a self-awareness consciousness fear of mortality or is it
is it simpler than that or is consciousness a simple thing like do you think about these notions I don't think
much about consciousness even most philosophers who care about it will give
you that you could have that are zombies right that behave like humans but are not conscious and I at
this moment we'd be happy enough for that so I'm not really worried one way or the other to the technical side you're not thinking of the use of
self-awareness no but okay but then what is self-awareness mean I mean that you
need to have some part of the system that can observe other parts of the system and tell whether they're working
well or not that seems critical so does that count this I mean does that kind of
self-awareness or not well it depends on whether you think that there's somebody
at home who can articulate whether they're self-aware but clearly if I have like you know some piece of code that's
counting how many times this procedure gets executed that's a kind of self-awareness right so there's a big
spectrum it's clear you have to have some of it right you know quite far away at many dimensions but there's a direction of
Humanlevel intelligence
research that's most compelling to you for you know try to achieve human-level
intelligence in our robots well to me I guess the thing that seems most compelling to me at the moment is this
question of what to build in and what to learn I think we're we don't we're
missing a bunch of ideas and and we you know people you know don't you dare ask
me how many years it's gonna be until that happens because I won't even participate in the conversation because
I think we're missing ideas and I don't know how long it's gonna take to find them so I won't ask you how many years but maybe I'll ask you what it when
Test of intelligence
you'll be sufficiently impressed that we've achieved it so what's what's a good test of intelligence do you like
the Turing test the natural language in the robotic space is there something wait you would sit back and think us
that's pretty impressive as a test as a benchmark do you think about these kinds
of problems no I resist I mean I think all the time that we spend arguing about
those kinds of things could be better spent just making the robots work better so you
competition so I mean there's a nature of benchmark benchmarks and data sets or
touring test challenges or everybody kind of gets together and tries to build a better robot because they want to
compete each other like the DARPA challenge with the autonomous vehicles do you see the value of that I can get
in the way I think in the way I mean some people many people find it motivating and so that's good I find it anti motivating but I think I
mean I think you get an interesting cycle where for a contest a bunch of
smart people get super motivated and they hack the brains out and much of what gets done is just hacks but
sometimes really cool ideas emerge and then that gives us something to chew on after that so I'm it's not a thing for
me but I don't I don't regret that other people do it yeah it's like he says with
Journal of Machine Learning Research
everything else that makes is good so jumping topics a little bit he started the journal of machine
learning research and served as its editor-in-chief how did the publication
come about and what do you think about the current publishing model space and
machine learning artificial intelligence ok good so it came about because there
was a journal called machine learning which still exists which was owned by Kluwer and there was I was on the
editorial board and we used to have these meetings and really where we would complain to Kluwer that it was too expensive for the libraries and that
people couldn't publish and we would really like to have some kind of relief on those friends and they would always
sympathize but not do anything so we just decided to make a new journal and
there was the Journal of AI research which has was on the same model which had been and exists us for maybe five
years or so and it was going on pretty well so uh we just made a new journal it
wasn't I mean they don't know I guess it was work but it wasn't that hard so basically the editorial board probably
75% of the editorial board of machine learning resigned and we founded the
Neuse new journal but it was sort of it was more open yeah right so it's completely open its open
Open Access
access actually I I had a postdoc George Kennedy artists who wanted to call these
journals free for all because there were I mean it both has no page charges and
has no access restrictions and the
reason and so lots of people I mean there were there were people who are mad about the existence of this journal who
thought it was a fraud or something it would be impossible they said to run a journal like this with basically I mean
for a long time I didn't even have a bank account I paid for the lawyer to incorporate and the IP address and it
cost a couple hundred dollars a year to run it's a little bit more now but not that much more but that's because I
think computer scientists are competent and autonomous in a way that many
scientists and other fields aren't I mean at doing these kinds of things we already typeset around papers we all
have students and people who can hack a website together in an afternoon so the infrastructure for us was like not a
problem but for other people in other fields it's a harder thing to do yeah and this kind of open access journal and
Review Process
there's nevertheless one of the most prestigious journals so it's not like a
prestige and it can be achieved without any other paper it's not required yeah
for prestige it turns out yeah so on the review process side of actually a long
time ago I don't remember when I reviewed a paper where you were also a reviewer and I remember reading your if
you were being influenced by it and it was really well-written it influenced how I write future reviews you disagreed with me actually and you
made it my review but much better so I but nevertheless the review process you
know has its flaws and how do you think what do you think works well how can it
be improved so actually when I started Djamel our I wanted to do something completely different
and I didn't because it felt like we needed a traditional Journal of record
and so we just made jam art be almost like a normal Journal except for the open-access parts of it basically
increasingly of course publication is not even a sensible word you can publish something about putting it in archives
that I can publish everything tomorrow so making stuff public is there's no
barrier we still need curation and
evaluation I don't have time to read all of our kyv and you could argue that kind
of social thumbs up being of articles
suffice is right you might say oh heck with this we don't need journals at all
we'll put everything on archive and people will upload and down about the articles and then your CV will say oh
man they he got a lot of buzz so that's good but I think there's still value in
careful reading and commentary of things and it's hard to tell when people are voting and down voting or arguing about
your paper on Twitter and reddit whether they know what they're talking about
right so then I have the second order problem of trying to decide whose opinions I should value and such so I
don't know I what I if I had infinite time which I don't and I'm not gonna do this because I really want to make
robots work but if I felt inclined to do something more in a publication direction I would do this other thing
which I thought about doing the first time which is to get together some set of people whose opinions I value and who
were pretty articulate and I guess we would be public although we could be private I'm not sure and we would review
papers we wouldn't publish them and you wouldn't submit them we were just fine papers and we would write reviews and we
would make those reviews public and maybe if you you know so we're Leslie's
friends who review papers and maybe eventually if if we are opinion was officially valued like the
opinion of Jay mor is valued then you'd say in your CV that Leslie's friends gave my paper a five-star reading and
that would be just as good as saying I got it so you know accepted into this journal so I think I think we should
have good public commentary and organize it in some way but I don't really know
how to do it it's interesting at times the way the way you describe text is really interesting and you would do it for movies IMDB done know there's
experts critics come in they write reviews but there's also regular yeah
non critics humans write reviews and they're separated I like open review the
the eye I cleared process I think is interesting it's a
Paper Reviews
step in the right direction but it's still not as compelling as reviewing movies or video games I mean it
sometimes almost it might be silly it's my perspective to say but it boils down to the user interface how fun and easy
it is to actually perform the reviews how efficient how much you as a reviewer
get street cred for being a good reviewer those element those human
elements come into play now it's a big investment to do a good review of a paper and the flood of papers is that
control right so you know there aren't 3,000 new I don't know how many new movies are there any year I don't know
but that's probably gonna be less than how many machine learning papers are in a year now and I'm worried I you know I
I and right so I'm like an old person so of course I'm gonna say rawrrr things
are moving too fast I'm a stick in the mud so I can say that but my particular
flavor of that is I think the horizon for researchers has gotten very short
that students want to publish a lot of papers and there's a huge there's value
it's exciting and there's value in that and you get patted on the head for it and so on but and some of that is fine
but I'm worried that we're driving out
people who would spend two years thinking about something back in my day
when we worked on our theses we did not publish papers you did your thesis for years
you picked a hard problem and then you worked and chewed on it and did stuff and wasted time and a long time and when
it was roughly when it was done you would write papers and so I I don't know
how to inside and I don't think that everybody has to work in that mode but I think there's some problems that are hard enough that it's important to have
a longer her research horizon and I'm worried though we don't incentivize that at all at this point in this current
Hopes and Fears
structure right so what do you see as what are your hopes and fears about the
future of AI and continuing this theme so AI has gone through a few winters ups
and downs do you see another winter of AI coming are you more hopeful about making robots
work as he said I think the cycles are inevitable but I think each time we we
get higher right I mean so you know it's like climbing some kind of landscape with a noisy optimizer yeah so it's
clear that the the you know the deep learning stuff has made deep and
important improvements and so the high-water mark is now higher I there's no question but of course I think people
are over sawing and eventually investors I guess and other people look around and
say well you're not quite delivering on this grand claim and that wild
hypothesis it's so probably it's going to crash them out and then it's okay I
mean but I don't I can't imagine that there's like some awesome monotonic
improvement from here to human level III so in you know I have to ask this
Existential Threats
question I probably anticipate answers the answers but do you have a worry
short term and long term about the existential threats of AI and maybe short-term less
existential but more robots taking away jobs actually let me talk a little bit
about utility actually I had an interesting conversation with some
military ethicists who wanted to talk to me about autonomous weapons and there
they were interesting smart well-educated guys who didn't know too much about AI are machine learning and
the first question they asked me was has your robot ever done something you didn't expect and I like burst out
laughing because anybody who's ever done something other robot right knows that they don't do it and what I realized was
that their model of how we program a robot was completely wrong their model of how we can put program robot was like
Lego Mindstorms like oh go for it a meter turn left take a picture do this
do that and so if you have that model of programming then it's true it's kind of weird that your robot would do something
that you didn't anticipate but the fact is and and actually so now this is my new educational mission if I have to
talk to non experts I try to teach them the idea that we don't operate we
operate at least one or maybe many levels of abstraction about that and we say oh here's a hypothesis class maybe
it's a space of plans or maybe it's a space of classifiers or whatever but there's some set of answers and an
objective function and then we work on some optimization method that tries to optimize a solution a solution in that
class and we don't know what solution that's going to come out right so I
think it's important to communicate that so I read of course probably people who listen to this they they know that
lesson but I think it's really critical to communicate that lesson and then lots of people are now talking about you know
the value alignment problem so you want to be sure as robots or software systems
get more competent that their objectives are aligned with your objectives or that our objectives are compatible in some
way or we have a good way of mediating when they have different objectives and so I think it is important to start
thinking in terms like you don't have to be freaked out by the robot apocalypse - except that it's
important to think about objective functions of value alignment yes and that you have to really everyone who's
done optimization knows that you have to be careful what you wish for that ah you know sometimes you get the optimal
solution and you realize man that was that objective was wrong so
pragmatically in the shortest term it seems to me that that those are really
interesting and critical questions and the idea that we're gonna go from being people who engineer algorithms to being
people who engineer objective functions I think that's that's definitely going to happen and that's gonna change our
thinking and methodology and we're gonna you started at Stanford philosophy that's where she comes I will go back to
because as we also know as machine learning people right when you're design
in fact this is the lecture I gave in class today when you design an objective function you have to worry about with
hats there's the Hat that says what do I want and there's the hat that says but I know
what my optimizer can do to some degree and I have to take that into account okay so it's it's always a trade-off and
we have to kind of be mindful of that the part about taking people's jobs I
understand that that's important I don't understand sociology or economics or
people very well so I don't know how to think about that so that's yeah so there might be a sociological aspect there the
Most Exciting Research
economical aspect that's very difficult to say well okay I mean I think other people should be thinking about it but I'm just that's not my strength so what
do you think is the most exciting area of research in the short term for the community and for your for yourself well
so I mean there's the story I've been telling about how to engineer intelligent robots so that's what we
want to do we all kind of want to do well I mean some set of us want to do this and the question is what's the most
effective strategy and we've tried and there's a bunch of different things you could do at the extremes right one super
extreme is we do introspection then we write a program okay that has not worked
out very well another extreme is we take a giant bunch of neural and we trying to train it up to do
something I don't think that's gonna work either so the question is what's
the middle ground and and again this isn't a theological question or anything
like that it's just like going how do just how do we what's the best way to make this work out and I think it's
clear it's a combination of learning to me it's clear it's a combination of learning and not learning and what
should that combination be and what's the stuff we built in so to me that's the most compelling question and when you say engineer robots you mean
engineering systems that work in the real world is that that's the emphasis
last question which robots or robot is your favorite from science
fiction so you can go with Star Wars Arthur r2d2 or you can go with more
modern maybe Hal this is this is back to
you like to make robots work in the real world here not Madden I mean I love the
process and I care more about the process engineering process yeah I mean
I do research because it's fun not because I care about what we produce well that's a that's a beautiful note
actually to end on Leslie thank you so much for talking today sure it's been fun
you

----------

-----

--62--

-----
Date: 2019.02.26
Link: [# Karl Iagnemma & Oscar Beijbom (Aptiv Autonomous Mobility) - MIT Self-Driving Cars](https://www.youtube.com/watch?v=p5AtrKqQ3Fw)
Transcription:

Introduction to Karl Iagnemma and Oscar Beijbom
all right welcome back to 6 s 0 9 for deep learning for self-driving cars today we have Carling yama and oscar
baby boom from active karl is the president of apt of autonomous mobility
where Oscar is the machine learning lead karl founded in autonomy as many of you
know in 2013 it's a boston-based autonomous vehicle company and new tommy
was acquired by active in 2017 and now it's part of active karl and team are
one of the leaders in autonomous vehicle development and deployment with cars on roads all over the United States several
sites but most importantly Karl is MIT through-and-through is also some of you
may know getting his PhD here he led a robotics group here as a research scientist for many years so it's really
a pleasure to have both karl and oscar with us today please give them a warm welcome
Karl - Aptiv Background
all right thanks Lex yeah very glad to be back at MIT very impressed that you guys are here during
IEP my course load during IEP was usually ice skating and sometimes like there was
a wine tasting course this is now almost twenty years ago and that was pretty much it that's where the academic work
stopped so you guys are here to learn something so I'm gonna do my best and try something radical actually sometime
president now of apps of autonomous driving I'm not allowed to talk about anything technical or interesting I'm gonna flout that a little bit and and
raise some topics that we think about that I think are interesting you know questions too to keep in the back of
your mind as you're thinking about deep learning an autonomous driving so I'll raise some of those questions and then Oscar will actually present some
real-life technology and some of the work that he has been doing Oscar's our machine learning lead some of the work
that he and his outstanding team have been doing around machine learning based
detectors for the deception problem so let me first introduce apt of a little bit because
people usually ask me like what's an active when I say I work for active apt
has actually been around for a long time but in a different form after it was previously Delphi
technologies which was previously part of General Motors so everybody's heard of General Motors some of you may have heard of Delphi
active spun from Delphi about 14 months ago and so after the tier 1 supplier
they're an automotive company that industrialize --is technology essentially they take software and
hardware they industrialize it and put it on car so it can run for many many hundreds of thousands of miles without
failing which is a useful thing when we think about autonomous driving so the themes for active they develop what they
say is safer greener and more connected solutions safer means safety systems
active safety autonomous driving systems of the type that we're building greener
systems to enable electrification and green vehicles and then more connected
connectivity solutions both within the vehicle transmitting data around the vehicle and then externally wireless
communication all of these things as you can imagine feed very very nicely into the future transportation systems that
the software will actually only be a part of so active is in a really interesting spot when you think about
the future of autonomous driving and give you sense of scale
still kind of amazes me the biggest my research group ever was at MIT was like 18 18 people active is a hundred and
fifty six thousand employees so significant sized organization about a thirteen billion dollar company by
revenue in about 50 countries around the world my groups about seven hundred
people so of which Oscar is is one very important person we're about seven hundred working on autonomous driving we've got about a hundred twenty cars on
the road in in different different countries and I'll show you some examples of that but first let me take a
trip down memory lane and show you a couple of snapshots about where we were
not too long ago kind of as a community but but also you know me personally and
this will either inspire or horrify you I'm not sure which but the fact is 2007
you know there were groups driving around with cars like running blade servers in the trunk that we're
generating so much heat you had to install another air conditioner which then was drawing so much power you have
to add another alternator and then kind of rinse and repeat so it wasn't a great situation but people did enough
algorithmically computationally to to enable these cars and this is the DARPA
urban challenge for those who that may be familiar to enable these cars to do something useful and interesting on a
closed course and it kind of convinced enough people that given enough devotion
of you know thought and resources that this might actually become a real thing someday so I was one of those people
that got convinced 2010 this is now I'm gonna crib from my co-founder Emilio who
was a former MIT faculty member and aero-astro Emilio started up an operation in Singapore through smart who
somebody had probably worked with so this is some some folks from smart that's James who looks really young in
that picture he was one of emilio students who was basically taking a golf cart and and turning it into an
autonomous shuttle it turned out to work pretty well and it got people in Singapore excited which in turn got us
further excited 2014 they did a demo where they led people of Singapore coming right around these carts in in a
garden and that worked great over the course a weekend course of a weekend around this time we'd started new autonomy we'd actually
started a commercial enterprise it kind of stepped least partly away from MIT at that point 2015 we had cars on the road
this is a Mitsubishi i-miev electric vehicle when we had all our equipment in
it the front seat was pushed forward so far that me I'm about six foot three actually couldn't sit in the front seat
so I couldn't actually accompany people on rides it wasn't very practical we ended up switching cars to a Renault
Zoe platform which is the one you see here which had a little more legroom we were giving at that point open to the
public rides in our cars in Singapore in the part of the city that we were allowed to operate in
it was a quick transition as you can see just even you know visually the evolution of these systems has come a
long way in a short time and we're just a point example of this phenomena which is kind of broadly speaking of you know
similar across the industry but 2017 we joined active and we were excited by
that because we as primarily scientists and technologists didn't have a great idea how we're gonna industrialize this
technology and actually bring it to market and make it reliable and robust and make it safe which is what I'm going
to talk about a little bit here today so we joined active with its global footprint today we're primarily in
Pittsburgh Boston Singapore and Vegas and we've got connectivity to actives other sites in
Shanghai and Wolfsburg let me tell you a little bit about what's happening in Vegas I think people were here when was
Luke talking a couple days ago yesterday so Luke from lift Luke Vincent probably talked a little bit about Vegas Vegas is
really an interesting place for us we've got a big operation there 130,000 square foot garage we've got about 75 cars
we've got thirty of those cars on the lift Network so apt of technology but connecting to the customer through lift
so if you go to Vegas and you open your lyft app it'll ask you do you want to take a ride in autonomous car you can
opt in you can opt out it's up to you if you opt in there's a reasonable chance one of our cars will pick you up if you call for a ride so anybody can do this
competitor's innocent bystanders totally up to you we have nothing to hide our cars are on the road 20 hours a day
seven days a week if you take a ride when you get out of the car just like any lifts ride you got to give us a star
rating one through five and that to us is actually really interesting because you know it's a scaler it's it's not too
rich but that star rating to me says something about the ride quality meaning
the comfort of the trip the safety that you felt and the efficiency of getting to where you want it to go and our star
rating today is four point nine five which is pretty good key numbers we've given this point
over 30,000 rides to more than 50,000 passengers we've driven over a million miles in Vegas and a little bit
additional but primarily there and as I mentioned the 4.95 so what's it look
like on the road I'll show just one video today I think Oscar has a few more this one's actually in Singapore but
it's all kind of morally equivalent you'll see a sped up slightly sped up
view of a run from this is now probably six seven months old on the road in
Singapore but it's got some interesting stuff in a fairly typical run some of
you may recognize these these these roads we're on the wrong side of the road remember because we're in Singapore but to give you an example of the some
of the types of problems we have to solve on a daily basis so let me run this thing and you'll see is this car is
cruising down the road you have obstacles that we have to avoid
sometimes in the face of oncoming traffic we've got to deal with sometimes
situations where other road users are maybe not perfectly behaving by the rules we got to manage that in a natural
way Construction is Singapore like everywhere else is pretty ubiquitous and so you have to navigate through these
less structured environments people who are sometimes doing things or indicating
some future action which you have to make inferences about that can be tricky to navigate so typical day a route that
any one of us as humans would you know drive through without batting an eye no problem is actually presents some really
really complex problems for autonomous vehicles but it's the table stakes these days these are the things you have to do
if you want to be on the road and certainly if you want to drive millions of miles you know with very few
accidents which is what we're doing so that's an introduction to active and a little bit of background so let me talk
Dimensions of Safety for AVs
about we're going to talk about learning and how we think about learning in the
context of autonomous driving so there was a period a few years ago where I think as a community people thought that
we would be able to go from pixels to actuator commands with a single learned architecture a single black box
I'll say generally speaking we no longer believe that's true and I should include we in that I didn't believe that was
ever true but some of us maybe thought that was true and I'll tell you part of the reason why and in part of this talk
a big part of it comes down to safety a big part of it comes down to safety and
the question of safety convincing ourselves that that system that black box even if we could train it to
accurately approximate this massively complex underlying function that we're trying to approximate can we convince
ourselves that it's safe and it's very very hard to answer that question affirmatively and I'll raise some of the issues around
why that is this is not to say that learning methods are not incredibly useful for autonomous driving because
they absolutely are and Oscar will show you examples of why that is and how active is using some learning methods
today but this safety dimension is tricky because there's actually there's actually two axes here one is the actual
technical safety of the system which is to say can we build a system that's safe that's provably in some sets safe that's
we can validate which we can convince ourselves achieves the intended functionality in our operational design
domain that adheres to whatever regulatory requirements might be imposed
on our jurisdictions that we're operating and there's a whole longer list related to technical safety but
these are technical problems primarily but there's another dimension which appear is you know called perceived
safety which is to say when you ride in a car even if it's safe do you believe
that it's safe and therefore will you want to take another trip which sounds kind of squishy and as engineers we're
typically uncomfortable with that kind of stuff but it turns out to be really important and probably harder to solve because it's a little bit squishy and
you know quite obviously we got to sit up here right we got to be in this upper right-hand corner where we have not only a very safe car from a technical
perspective but one that feels safe that inspires confidence in riders in regulators and and everybody else so how
do we get there in the context of elements of this system that maybe black boxes for lack of a better word what's
required is trust you know how do we get to this point where we can trust neural networks in the context of safety critical systems
Trusting neural networks behind the wheel
which is what an autonomous vehicle is it really comes down to this question of how do we convince ourselves that we can
validate these systems again validating the system ensuring that it can it can meet the requirements the operation
requirements in the domain of interests that are imposed by the user alright there's three dimensions to to this this
this this key question of understanding how to validate and I'm gonna just briefly introduce some questions some some topics of interest around each of
these but the first one trusting the data trusting the data so do we actually
have confidence about what goes into this algorithm I mean everybody knows garbage in garbage out there's various
ways that we can make this garbage we can have data which is insufficiently covering our domain not representative
of the domain we can have data that's poorly annotated by our third party trusted partners so we've trusted to to
label certain things of interests so do we trust the data that's going in to the algorithm itself do we trust the
implementation you've got a beautiful algorithm super descriptive super robust not brittle at all well-trained and
we're running it on poor hardware we've coded it poorly we've got buffer overruns right and left do we trust the implementation to
actually execute in a safe manner and do we trust the algorithm again
generally speaking we're trying to approximate really complicated functions I don't think we typically use neural
networks for to approximate linear systems so this is a gnarly nasty function which has topics of which has
problems of critical interest which are really rare in fact they're the only ones of interests so there's these
events that happen very very infrequently that we absolutely have to get right it's a hard problem to
convince ourselves that the algorithm is going to perform properly in these unexpected and rare situations so these
are the sorts of things that we think about and that we have to answer in an intelligent way to convince ourselves
that we have a validated neural network based system
okay let me just step through these each of these topics really quickly so the
Validation of black-box systems
topic of validation you know what do we mean by that or why it is hard there's a number of different dimensions here the
first is that we don't have insight into the nature of the function that we're trying to approximate you know the underlying phenomena is really
complicated again if it weren't we'd probably be possibly be modeling it using different techniques we'd write a
closed-form equation to describe it so that's a problem second again you know
the accidents the actual crashes on the road what's going crashes and not accidents these are rare luckily they're
very rare but it makes the statistical argument around these accidents and
being able to avoid these accidents really really difficult if you believe rant and they're pretty
smart folks they say you got to drive 275 million miles without accident
without a crashed you can claim a lower fatality rate than a human with 95% confidence but how we gonna do that can
we think about using some correlated incident maybe some kind of close call as a proxy for accidents which may be
more frequent and maybe back in that way there's a lot of questions here which I won't say we don't have any answers to
because I wouldn't go that far but there there's heart they're hard questions they're not questions with obvious answers so this is one of them these
this this issue of rare events the regulatory dimension is one of these
known unknowns how do we evaluate a system if the requirements that may be imposed upon us from outside regulatory
bodies are still to be written other that's difficult so there's a lack of
consensus on what the safety target should be for these systems this is obviously evolving smart people are
thinking about this but today it's not at all clear if you're driving in Las Vegas if you're driving in Singapore if
you're driving in San Francisco or in or in between what this target needs to be and then lastly and this is a really
interesting one we can get through a validation process for a build of code let's assume we can do that well what
happens when we're gonna update the code because obviously we will does that mean we have to start that validation process
again from scratch which will unavoidably be expensive and lengthy well what if we only change a little bit
of the code would have I only changed one line but what if that one line is like the most important line of code in
the whole code base this is one that I can tell you keeps a lot of people up at
night this question of revalidation and then not even you know again now we'll keep that code base fixed what if we
move from one city to the next and let's say that city is quite similar to your previous city but not exactly the same
how do we think about validation in the context of new environments so this continuous development issue is a
challenge all right let me move on to talking about the data there's probably people in this room who are doing active
Trusting the data
research in this area because it's a really interesting one but there's a couple of questions I would say that we think
about when we think about data we can have a great algorithm and if we're training it on poor data for one reason
or another we won't have a great output so one thing we think about is this
efficiency the completeness of the data and the bias that may be inherent in the data for our operational domain if we
want to operate 24 hours a day and we only train on data collected during day time we're probably going to have an
issue annotating the data is another dimension of the problem we can collect raw data
that's sufficient that covers our space but when we annotate it when we hand it off to a third party because it's
typically a third party to mark up the interesting aspects of it we provide
them some specifications but we put a lot of trust in that third party and-and-and and trust that they're gonna
do a good job annotating the interesting parts and not the uninteresting parts that they're going to catch all the
interesting parts that we've asked them to catch etc so this annotation part which seems very mundane very easy to
manage and kind of like low-hanging fruit is in fact another key aspect of
ensuring that we can trust the data ok and this just kind of point to the fact that
there are again smart people thinking about this problem which rears its head in many domains beyond autonomous
driving now what about the algorithms themselves so moving on you know from
Trusting the algorithms
the data to the actual algorithm you know how do we convince ourselves that
that algorithm that you know like any kind of learning based auger we've trained on a training set is going to do
well on some unknown test set well there's a couple kind of properties of
the algorithm that we can look at that we can kind of interrogate and kind of poke at to convince ourselves that that
algorithm will perform well you know one is in variance and the other one we can
say is stability if we make small perturbations to this function does it
behave well given kind of let's say a bounded input do we see a bounded output or do we see some wild response you know
I'm sure you've all heard of examples of adversarial images that can confuse
learning based classifiers so it's a it's a it's a turtle you show it a
turtle that says well that's a turtle and then you show it a turtle that's maybe fuzz with a little bit of noise that the human eye can't perceive so it
still looks like a turtle and it tells you as a machine gun obviously for us in
the driving domain we want to stop sign to be correctly identified as a stop sign a hundred types of a hundred we
don't want that stop sign if somebody goes up and puts a piece of duct tape in the lower right hand corner to be
interpreted as a yield sign for example so this question of the properties of
the algorithm its invariance its stability is something of high interests and then lastly
and one more point to this this notion of interpretability so interpretability understanding why an
algorithm made a decision that it made this is the sort of thing that may not be a nice-to-have may actually be a
requirement and would likely to be a requirement from the regulatory groups that I was referring to a minute ago so
let's say imagine the case of a crash where the system that was governing your trajectory generator was a was a was a
data-driven system was a deep learning based trajectory generator well you may
need to explain to someone exactly why that particular generate trajectory was generated at that particular moment and
this may be a hard thing to do if the generator was a was a data driven model
now obviously there are people working and doing active research into this specific question of interpretive all
learning methods but it's it's it's a thorny one it's a very very difficult topic and it's not at all clear to me
when and if we'll get to the stage where we can - even a technical audience but
beyond that to a lay jury be able to explain why algorithm X made decision
why okay so with all that in mind let me
Safety architecture for neural networks
talk a little bit about safety that all
maybe sounds pretty bleak you think well man well I've been taking this course with Lex because we're never really use this stuff but in fact we we can we can
and will as a community there's a lot of tools we can bring to bear to think
about neural networks and they're generally speaking within the context of
a broader safety argument I think that's the key we tend not to think about using a neural network as an holistic system
to drive a car but we'll think about it as a sub-module that we can build other
systems around generally speaking that which we can say maybe make more rigorous claims about their performance
their underlying properties and then therefore make a convincing holistic safety argument that this end-to-end
system is safe we have tools functional safety is maybe familiar to some of you
it's something we think about a lot in the automotive domain and so diff which stands for safety of
the intended functionality we're basically asking ourselves the question is this overall function doing what it's
intended to do is it operating safely and is it meeting its specifications there's kind of an analogy here to
validation and verification if you will and we have to answer these questions
around functional safety and soda if affirmative lis even in the even when we
have neural network based elements in order to eventually put this car on the road all right so I mentioned that we
need to do some embedding this is an example of what it might look like we refer to this as sometimes we call this
caging the learning so we put the learning in a box it's this powerful animal we want to control and in this
case it's up there at the top in red that might be you know that trajectory proposer I was talking about so let's
say we've got a powerful trajectory proposer we want to use this thing we've got it on what we call our performance compute our high-powered compute it's
maybe not automotive grade it's got some potential failure modes but it's generally speaking you know good performance let's go there and we've got
our neural network based generator on it which we can say some things about but maybe not everything we'd like to well
we make the argument that if we can surround that says we can cage it kind of underpin it with a safety system that
we can say very rigorous things about its performance then generally speaking
we may be okay there may be a path to using neural networks on autonomous vehicles if we can wrap them in a safety
architecture that we can say a lot of good things about and this is exactly what this represents so I'm going to
conclude my part of the talk here handed over to Oscar with kind of a quote and
assertion one of my engineers insisted I show today the argument is the following
engineering is inching closer to the Natural Sciences I won't say how much closer but closer we're creating things
Engineering is inching closer to the natural sciences
that we don't fully understand and then we're investigating the properties or creation we're not ready down close for
closed form functions that would be too easy we're generating these immensely
complex function approximator x' and then we're just poking at ways of saying boy well what does this
thing do under these situations and I'll leave leave you with one image which I'll present without comment and then
hand it over to Oscar all right Thank You Karl
Oscar - DL for 3D Detection
thanks Lex for the invite yes my name is Oscar run the the machine learning team
at active autonomy so every weekend with this slide
specification was you know quite literally a joke so this is an actual comic I won't have seen this before
okay well I was doing my PhD in this era where you know building a bird
classifier was like a PhD project right and it was it was you know it's funny
because it's true and then of course as you well know the deep learning revolution happened and unless you know
previous introductory slides gives a great overview I don't want to redo that I just want to say sort of a straight
line from what I consider the breakthrough paper by Chris Jeff's key at all to the to the work I'll be
talking about today I was sort of these three so you had the you know deep learning and to end learning for you is
genetic classification by Christian Hinton that papers been cited 35,000 times I checked yesterday then 2014 Ross
Kirsch ago at Berkeley basically showed how to you know repurpose the deep
learning architecture to do a detection in images and that was the first time when the visual community really started
seeing okay so classification is more general I can classify anything an image an audio signal whatever right but detection
images was very intimate to the computer vision community we thought we were best in the world right so in this paper came
out that was sort of the the final the final argument from I okay we all need to do deep learning now right and then
2016 this this paper came out the single shot multi box detector which i think is a great paper finally at all
so if you haven't looked at you haven't looked at this paper by all means read them carefully
you know that's the result you know performance is no longer a joke
right so this is this is a network that we developed in our in my group so it's
a it's an image joint image classification segmentation network this thing we can run this at 200 Hertz on a
single GPU and in this video in this rendering there is no tracking apply
there is no temporal smoothing every single frame is analyzed independently from the other one and you can see that
we can model several different classes you know both both boxes and and and the
surfaces at the same time there's my cartoon drawing of a perception system an autonomous vehicle so you have the
three different main sense of analyses typically have some module that does
detection and tracking you know this tons of variations of the dis of course we you have some sort of sense of
pipelines and then in the end you have a tracking infusion step right so what I
showed you in the previous video is basically at this part so I did like I said it was a tracking but it's like going from the camera to detection and
if you look you know when I started so I come strict from the computer science
learning community so when I start looking at this pipeline I'm like why are there so many steps why aren't we
optimizing things you know end to end so obviously like there is a there's a real temptation to just wrap everything in a
kernel it's very well defined input output function and like like Karl alluded to it's it's one that can be
verified quite quite well assuming you have the right data I'm not going to be
talking about this I am going to talk about this namely the building a a deep
learning kernel for the liteup pipeline and a lot of pipeline is arguably the backbone of the reception system for for
for most autonomous driving systems so what we're going to do is so this is basically going to be the goal here so
we're going to have a point cloud simple and we're gonna have a have a neural network that takes that in simple and
then generates 3d bounding boxes that are in the world coordinate system so it's like 20 meters that way it's two
meters wide so long this this rotation and this orientation and so on so yeah
PointPillars
so that's what this talk is about so I'm going to talk about point pillars which is a new method we developed for this and new scenes which is a benchmark data
that we released okay so the supporters point bill as well it's a novel point cloud encoder that's what we do is we
learn a representation that is suitable for downstream detection it's almost like the main innovation is the
translation from a point cloud to a to a canvas that can then be processed by by
a similar architecture that you would use in an image and we are sure it outperforms the you
know all publish measures on kitty by a large margin especially with respect to
inference speed and there's a pre printout and some code available if you
guys want to play around with it so the architecture that we're going to use
looks like something like this and I should say most papers in this space use
this architecture so it's it's kind of a natural design right so you have the point cloud and at the top you have this
encoder and that's where we introduced the point pillars but you can have I'll show you guys you can have various types
of encoders and then after that that fits into backbone which is now a standard convolutional 2d backbone you
have a detection head and you have you might have you may or may not have a segmentation at all that right the point
is that after the encoder everything looks just like dark - is very similar to the SSD architecture of the our CNN
architecture so so let's go into a little bit more
detail right so so the range so what you're given here is it's a range of the meter say you wanted a model you know 40
meters afforded me to circle around example you have certain resolution of
your bins and then a number of output channels right so input is a set of pillars or and the pillar here is a
vertical column right so you have n m of those that are non-empty in this space
and you say a pillar P contains all the points which are a lot of point XYZ and intensity and there's n sub M indexed by
M points in each pillar right so just to say that it varies right so it could be
one single point at a particular location it could be 200 points and then it's centered around the spin and the
goal here is to produce a tensor as a fixed size so it's height which is you
know range of a resolution with inter resolution and then this parameter C C
is the number of channels so in an image C will be three we don't necessarily care about that we call it a pseudo
image but it's the same thing it's a fixed number of channels that the back broken and operate on
yes here's a same thing without math right so you have a lot of points and
you have this space with you just grid it up in these pillars right some are
empty some one of them so in this sort of with this notation let me give a little bit of a literature review people
tend to do is you take each pillar and you divide it into voxels right so now I have a 3d box or grid right and then you
say I'm gonna extract some sort of features for each box so for example how many points are in this voxel or what is
the maximum intensity of all the points in this voxel then you extract feature for the whole pillar right what is the
max intensity across all the points in the whole pillar right all of these are ten engineer functions
that generates the fixed length output so what you can do is you can now concatenate them and their output is a
this tensor X Y see
so then Vox on that came came around I'd say year or so ago maybe a little
bit more by now so they do the first this first step is similar right so you divide each pillar into voxels and then
you take you map the point in each voxels and the normal thing here is that they they got rid of the future
engineering so they said we'll we'll map it from a voxel to two features using a
point net and I'm not going into the details of a point net but but it's
basically a network architecture that that allows you to take a point cloud and map it to again a fixed length
representation it's a series of 1d convolutions and max pooling layers this
is a very neat paper right so what they did is they okay we say we apply that to each voxel but now I end up with this
awkward four dimensional tensor because I still have X Y Z from the voxels and then I have this C dimensional output
from the appointment so then they have to consolidate this Z dimension through a 3d convolution right and now you
achieve your X Y C tensor so now you're ready to go so it's very nice in the
sense that it's an turn method they show good performance but in the day was very slow as I got like five Hertz run time
and then the the culprit here is is this last step so the 3d convolution it's
it's much much slower than a standard 2d convolution alright so here's what we
did we basically said let's just forget about voxels we'll take all the points in the pillar and we'll put it straight
through a point in it that's it so just that single change gave a 10200 fold you
know speed up from walks on that and then we simplify the point net so now instead of having so a point that can
have several layers and several modules inside it so it we simplified it to a single one deconvolution and max falling
layer and then we showed you can get a really fast implementation by taking all
your pillars that are not empty stack them together into nice dense tensor with a little bit of padding here and
there and you can run that you know run the forward pass with a single you can post it as a 2d
convolution with a one by one kernel so in the final encoder runtime it's not
1.3 milliseconds which is which is really really fast so the full method
looks like this right so you have the point cloud you have this pillar feature net which which is the encoder so the
different steps there that feeds straight into the backbone and your detection heads and and there you go so
it's still a multi-stage architecture but of course the key is that none of the steps are all the steps are you know
fully parameterized and we learnt we can back propagate through the whole thing and learn it so putting these things
together these were the sort results we got on the Qt benchmark so if you look
at the core class right we actually got the highest performance so this is I
think the bird's eye view metric and we even outperformed the the methods that relied on lidar ambition and we did that
running at you know over a little bit over 60 Hertz and we you know and this
is like I said this is a bird's eye view we can also measure the 3d the 3d benchmark and we get the same very
similar performance yeah so you know
recorded well cyclist did well pedestrian there was there was one or two map methods fusion methods that did
a little bit better but then in aggregate on the top left we ended up on top and I put a little asterisk here
this is compared to publish methods at the time of submission it's so many
things happening so quickly so there's tons of you know submissions not a kiddie leaderboard that are a completely
anonymous oh we don't even know you know what was it what was the input what they did they use so we only compared to
publish methods so here's a some quantitative results
you have the we you know just for visualization you can project them into the image so you see the gray boxes are the ground truth and the the corridor
ones are the predictions and yeah some
some challenging challenging us is so smaller but them so we have for example the person right there that's a you know
a person with a little stand get interpreted as a bicycle we have this
man on the ladder which is an actual annotation error so we discovered it as a person but it wasn't annotated in the
data here's a young child on a bicycle
that didn't get detected so that's a you know that's that's a bummer
okay so stubs Kitty and then I just wanted to show you guys of course we can
run this on our vehicle so this is a rendering we just deploy the network by
two Hertz on on the full 360 sensor sweet input is still alive you know if
you lidar sweeps but just projected into the images for visualization and again
no tracking or smoothing applied here so it's every single frame is is analyzed
independently see those arrows sticking out that's the velocity estimate so we
actually show how you can yeah you can actually cumulate multiple point clouds
into this method and now you can start reasoning about velocity as well
you so the second part I want to talk about is new scenes which is a
nuScenes - a dataset for multimodal 3d object detection
data said that we have published alright so what is new scene so it's one
thousand twenty second scenes and that we collected with our development
platforms it's a full it's the same platform that called show I sort of previous generation platform the so a
vehicle so it's full you know the full automotive sends to sweep data is
registered and synced in 360-degree view and it's also fully annotated with 3d
bounding boxes I think there is over 1 million 3d bounding boxes and we
actually make this freely available for research so you can go to new scene store right now and download a teaser a
teaser release which is 100 scenes the full release will be in about a month
and a person motivation is straightforward right so you know the whole field is driven by benchmark and
you know without image and I don't think none of it might be the case that none of us are here we're here right because
they may never have been able to write that first paper and sort of start this whole thing going
looking at 3d I looked at the kiddie benchmark which is which is truly groundbreaking I don't want to take anything away but it was becoming
outdated that they don't have full 3d view they don't have any radar so I
think this this offers the opportunity to sort of push push the field forward a little bit right and just as a
comparison this is sort of the the most similar benchmark and really the only one that is the that you can really
compare to is kitty but so there's other data sets that have maybe lidar only tons of data sets I
have image only of course but it's it's a it's quite a big step up from from
kidney yeah some some details so you see the layouts with the the Raiders along
the edge all the cameras on the roof and the top top lidar and some of the
receptive fields and this data is all on the website the taxonomy so we model
several different sub sub categories of pedestrians several types of vehicles some static objects barrier cones and
then in addition all the bunch of attributes on the vehicles and on the pedestrians all right so with without
further ado let's just look at some data so this is one of the thousand scenes right so all I'm showing here is
just just playing the frames one by one of all the images and again the
annotations are living the in the world coordinate system right so there are full three full 3d boxes I've just
projected them into the image and that's what's so neat so we're not really annotating the lidar or the or the
camera or the radar we're annotating the actual objects and put them in a wall coordinate system and give all the
transformation so you guys can play around with it how you like so just to
show that so I can because everything is ready so I can now take the light or sweep and I can just project them into
the image images at the same time so here I'm showing just colored by distance so now you have some sort of
sparse density measurement on the images a distance measurement sorry so so
that's all I want there let's talk about thank you hi I was really really
Q&A
interested in your discussion around validation and particularly continuous development that sort of thing and so my
question was basically is is this new scenes data set is this enough to to guarantee that your model is going to
generalize to unseen data and you know not hit pedestrians in that stuff or do you have other validation that you need
to do no no I mean so the new sensor for this is it's purely an academic efforts so we want to share our data with
academic community to drive the car to feel forward we're not making any claims that this is somehow a sufficient data
set for trying to save the case it's a small subset of our our data yeah I
would say you know obviously my background is in the academic world one
of the hardest things was always collecting data because it's difficult and expensive and so having access to a
data set like that which was expensive to to collect and annotate but which we thought we would make available because
well we hoped that it would spark academic interests and smart people like
the people in this room coming up with new and better algorithms which could benefit the whole community and then maybe something
even want to come work with us adaptive so not totally a little bit of self interest there wasn't intended to be for
validation was more for research to give you a sense than the scale of validation there was one quote there and you know
saying you got to drive 275 million miles or more depending on your certainty you want to impose but to date
is an industry we've driven about like twelve million miles to twelve to fourteen million miles in some all
participants in autonomous mode under hundreds of over hundreds of different Bills of code and many different
environments so this would now be saying you're supposed to drive hundreds of millions of miles in a particular
environment on a single build of code a single platform now obviously we're probably not going to do that what we'll
end up doing is supplementing the driving with quite a lot of simulation and then other methodologies to convince
ourselves that we have we can make a statistical ultimately a statistical argument for safety so there'll be use
of data sets like this you know we'll be doing lots of regression testing on supersize version of data set
either kind of morally equivalent versions to test different parts of the systems now I'm not just classification but different aspects of the system are
motion planning decision-making localization all aspects of the system
and then augment that with on-road driving and augment that with simulation
so the safety case is really quite a bit broader unfortunately then any single data set would allow you to to kind of
speak to from an industrial perspective what do you think can 5g offer for
autonomous vehicles 5g yeah it's an interesting one well these vehicles are
connected you know that's that's a that's a requirement certainly when you think about operating
them as a fleet when the day comes when you have an autonomous vehicle that is personally owned and that they will come
in some point in the future it may or may not be connected it will almost certainly then be too but when you have
a fleet of vehicles and you want to coordinate the activity that fleet and a way to you know maximize the efficiency
of that network that transportation network they're certainly connected the requirements of that kind of tivity is
fairly relaxed if you're talking about just passing back and forth the position of the car and maybe some status indicators you know are you know
autonomous mode manual mode are all systems go where you have a fault code and what is it now there's some
interesting requirements that become a little bit more stringent if you think about what we call teleoperation and remote operation of the car the case
where if the car encounters a situation it doesn't recognize can't figure out gets stuck or confused you may kind of
phone a human operator who's sitting remotely to intervene and in that case you know that human operator will want
to have some situational awareness there may be a demand of high-bandwidth low-latency
high reliability the sort that maybe 5g is better suited to than 4G or LTE or
whatever you've got broadly speaking we see it as very nice to have but like any
infrastructure we understand that it's gonna arrive on a time line of its own and be maintained by someone who's not
us so it's very much outside our control and so for that reason we design a system such that we don't rely on kind
of the coming 5g way but we'll certainly welcome it when it arrives so you said you have presence in 45
countries so did you observe any interesting patterns from that like your car your same your same
self-driving car model that is deployed in Vegas as well as Singapore was able to perform equally well in both Vegas
and Singapore the model was able to perform very well in Singapore compared to Vegas to speak to your question about
like country to country variation you know we touched on that for a moment in the validation discussion but obviously
driving in Singapore and driving in Vegas is pretty different I mean you're on the other side of the road for starters but different traffic rules and
it's sort of underappreciated people drive differently there's slightly different traffic norms so one of the things that well if anyone
was in this class last year my co-founder Emilio gave a talk about something we call rule books which is a
structure that we've designed around that what we call the driving policy or the decision-making engine which tries to admit in a general and fairly
flexible way the ability to reprioritize rules reassign rules change weights on
rules to enable us to drive in one community and then another in a fairly seamless manner so they give you an
example when we when you want to get on the road in Singapore if you can imagine you've got a so you're let's say you're
a autonomy engineer who was tasked with writing the decision-making engine you decided I'm gonna do a finite-state architecture I'm gonna write down some
transition rules I'm gonna do them by hand it's gonna be great and then you did that for the right-hand driving and
your boss came in and said oh yeah next Monday we're gonna be the left-hand driving so you flip all that and get it
ready to go that could be a huge pain pain to do because it's generally speaking you're doing it manually and
then a very difficult to validate to ensure that that the outputs are correct across the entire spectrum possibilities
so we wanted to avoid that and so the long story short we actually quite
carefully designed the system such that we can scale to different cities and
countries and one of the ways you do that is by thinking carefully around the architectural design of the
decision-making engine but it's it's it's you know quite different this for cities I mentioned which are primary
sites Boston Pittsburgh Vegas and Singapore spans a wide spectrum of driving conditions I mean everybody
knows Boston which is pretty bad Vegas is warm weather mid density urban
but it's Vegas so I mean all kinds of stuff and then Singapore is interesting
perfect infrastructure of good weather flat people generally speaking obey the rules so it's kind of close to the ideal
case so you that exposure to this different spectrum of data I think I'll
speak for Oscar maybe it's pretty valuable I know for other parts of the development team quite valuable Singapore is ideal except they're the
constant construction zones so every time you drive out there's a new construction zone so we focus to have a lot of work in construction zone
detection Singapore and the torrential rain yeah in the jaywalkers right they
do a walk people don't break the radio AJ so other than that is perfect so
which country is fully equipped it's a really good question yeah well it's interesting because
there's other dimensions so when we look at which countries are interesting to us to be in as a market there's there's the
infrastructure conditions there's the driving patterns and properties the density you know is it Times Square at rush hour or is it
Dubuque Iowa there is the regulatory environment which is incredibly important you may have a perfectly
well-suited city from a technical perspective and they may not allow you to drive there so it's really all of
these things put together and so we you know we kind of have a matrix we analyze which cities check these boxes and and
assign them scores and then try to understand then also the economics of that market is that city check all these
boxes but there's no one taking using mobility services there there's no opportunity to actually generate revenue
from the service so we can you know you factor in all of those things yeah and I
think I mean one thing to keep in mind that is always the first first thing I thought candidates when I interview them
there's a huge difference in the advantage to the business more we're proposing right that's right right having service so we can choose even if
we commit to some city we can solve something you know select the routes that we feel comfortable and we can roll
it out sort of piece by piece when you say okay we we don't feel comfortable when drive at night in the city yet so
we just won't accept any rights right so that there's like that that decision space as well
hi thank you very much for coming and giving us this talk today was very very interesting I have a question which
might reveal more about how naive I am than anything else I was comparing your your point pillar approach to the
earlier approach where you were which is this the voxel based approach to
interpreting the lidar results and in the voxels you had a four dimensional
tensor that you were starting with and you your point Miller you only have three dimensions you're throwing away the Z as
I understood it so when you do that are you concerned that you're losing information about potential occlusions
or transparencies or semi occlusions is this a concern I think so so I may have
you know I've been a little bit sloppy there so we're certainly not throwing away the see what we're saying is that
we're learning the embedding of in the C dimension jointly with with everything else so Volk sonnet if you want sort of
felt that when I first signed that paper that I felt the need to like spoon-feeding Network a little bit and
say let's learn everything you know stratified in this in this high
dimension and then we'll have a second step where we learn to consolidate that
into a single vector we just said why don't just learn those things together so yeah thanks for a talk I have a
question for Carl you mentioned that like if people make change to the code do we need another validation or not so
I work in the industry of nuclear power so we do nuclear power simulations so
when we like make any change to our simulation code and to make it
commercialize we need to submit a request for NRC which is the nuclear
Regulation Committee so in your opinion do you think for self-driving we need
another third-party validation community or not or like should that be a third
party or it's just self check yeah that's a really good question
so I don't know the answer I would be surprised let me put it this way I would not be surprised either way if the automotive
industry ended up with with third party regulatory or oversight or it didn't and
I'll tell you why there's there's great precedents for what you just described nuclear aerospace there's external
bodies who have deep technical competence who can come in they can do investigations they can impose strict
regulation or or advise regulation and they can they can partner or
our define requirements for certification of various types the
automotive industry has largely been self-certifying there's an argument which is which is
certainly not unreasonable that you have a you know a real alignment of incentive within the industry and with the public
to be as safe as possible simply put the cost of a crashes is enormous
you know economically socially everything else but whether it continues along that path I couldn't tell you it's
an interesting space because it's one where the federal government is actually
moving very very quickly I mean I would say carefully to not overstepping and not trying to impose too much regulation
around an industry that has never generated a dollar of revenue is still quite NASA but if you would have told me
a few years ago that there would have been very thoughtfully defined draft regulatory guidelines or advice I mean
let's say it's not firm regulation around this industry I probably wouldn't believe you but in fact that exists
there's a third version that was released this summer by the Department of Transportation so there's intense
interest on the regulatory side in terms of how far you know the process goes in
terms of formation of an external body I think really remains to be seen I don't know the answer thanks for your
insightful talk looking at this slide I'm wondering how easy and effective your train models are to transfer across
different letters and whether you need for example if it is snowing do we need specific trainings for specifically for
your light hours to work effectively or you don't see any issues in that regard
no I mean I think the same rules apply to this method us as any other machine learning based method you want to have
support in your training data for the situation want to deploy in so if we have no snow you know train that I
wouldn't go and deploy this in snow I do like one thing I like after having
worked so much with mission though is that light the lighter point cloud is really easy to augment and play around
with so for example it's you know if you wanna say you want to be robust some
really rare events right so let's say there's a piano on the road I really want to detect that but it's hard
because I have very few examples of pianos on the road right now if you think about augmenting your visual data
set with that data it's actually quite tricky so that easy to have a photorealistic piano in your training
data but it is quite easy to do that in your lighter alright so you have a 3d model of your obvious piano you have
your your the model for your lidar and you can get a pretty accurate fairly realistic point cloud return from that
right so I like that part about working with lighter you can you can augment you can play around with it in fact one of
the things we do when we train this model is that we we copy and paste samples from from or like objects from
different samples you can take a car that I saw yesterday take that point the points the point difference on that car
you can just paste it into your current light or sweep you have to be a little bit careful right and I'm and this was
actually proposed by another very previous paper and we found that that was really useful they don't it sounds
absurd but it actually works and it speaks to the ability to do that with
leather punk rock okay great please give Carl and Oscar up again thank you so much
you

----------

-----
--61--

-----
Date: 2019.02.18
Link: [# Oliver Cameron (CEO, Voyage) - MIT Self-Driving Cars](https://www.youtube.com/watch?v=-j0tc0Y1CIE)
Transcription:

Lex introducing Oliver
all right welcome back to 6 s0 9 for deep learning for self-driving cars today we have Oliver Cameron is the
co-founder and the CEO of voyage before that he was the lead of the Udacity
self-driving car program that made ideas an autonomous vehicle research and development accessible to the entire
world he has a passion for the topic and a genuine open nature that makes him one
of my favorite people in general and one of my favorite people working in this space and I think thousands of people
agree with that so please give Oliver warm welcome thank you very much Lex and
Oliver background
thank you all for having me here today super excited to speak all about voyage
but in reality the the kind of thing I want to share today is kind of like this
title says how to start a self-driving car startup rarely do you kind of get an
inside scoop of how a startup is formed you kind of hear all the the PR all the
kind of very lovey-dovey press releases out there I want to share kind of the
inside of how at least voyage came to be which was a little unconventional compared to your average self-driving
car startup they always tell you that the path to a startup getting to the goal you want is kind of a zigzag oz was
kind of a insane zigzag as well we'll go through all of that stuff let's talk
about my background also a little unconventional I'm not very good at
learning in a classroom for me I found learning by doing by building has always
been the thing that's that's worked best for me so going all the way back to when I was a teenager software just in
general was my passion this idea that you can make something out of absolutely nothing and then all of a sudden
millions and in Facebook's case billions of people can be using that thing and
after building lots of crazy stuff and perhaps not being too popular in high school because that's all I did I
started a company offer I won't bore you with all the details but learned a lot during the experience and joined
went through Y Combinator J believe started right here in Cambridge she's very cool and then this very pivotal
moment happened to me I heard about this online class which was generating a
whole bunch of scandal and and lots of controversy and it was from this guy
called Sebastian Thrun he'd taken this Stamper class he taught in artificial
intelligence and just said screw it we're gonna put the whole thing online and back then and this was a around 2011
this was a very controversial thing to do today MIT and many others do this all
the time but back then there was a hell of a lot of controversy around and doing something like this but this learning
format really just appealed to me being able to sit in my in front of my laptop learn at my own pace build build build
was something that really resonated with me and I took this class in 2013
artificial intelligence for robotics and this again was just this pivotal moment my head exploded all the enthusiasm I'd
had the software kind of transferred to artificial intelligence and and robotics
and just became addicted to the format of what are now called MOOCs massively open online courses and I love them so
much I decided hey I want to go do this and help others learn this stuff so hey
let's go join Udacity and and build more classes like this so I did that for four
years let our machine learning robotics and eventually our self driving car curriculum which was a lot of fun and I
got to learn directly from two great company builders like truly great company builders one was Vishal Mackey
Jonny he was the operator extraordinary Udacity understood how to build a
company how to build a culture how to incentivize and how to do all those those things that we don't often talk
about and Sebastian Thrun he of course founded the Google self-driving car
project and it's early days and right now I believe he's building flying cars
just in general I learned so much from him but this idea that you are literally
in control of your destiny you can build absolutely anything if you if you put your mind - it was was always pretty inspirational
today of course I Drive in cars at voyage and we'll talk more about what
makes us special compared to the other self-driving car companies you may have heard of in this class and beyond let's
Udacity self-driving car engineer nanodegree program
talk about Udacity you raise your hand if you've heard of Udacity very curious there you go that's most of the room
Udacity like I said was founded by Sebastian Thrun he took this class online and all just exploded and he
built a company around it you'd ask these real focuses on increasing the world's GDP this idea that talent is
everywhere that it isn't now just constrained to the best schools in the
world that because of this proliferation of content there are talented students all over the world and all they need is
the content in which to be able to build crazy cool world-changing things and
what I see is my job today is to go out into the world and find these
ridiculously talented people and then put them to work on the hardest problems that exist and Udacity to me felt like
the perfect place to do this as a kind of prelude to this about three years
into Udacity we had had this real focus like I said on machine learning and
robotics but we really want to take it to the next step and we came up with this kind of concept internally that we
called only at Udacity what if we taught the things that other places weren't teaching what if people all around the
world could come lay learn from what may appear to be niche topics but were just
being taught at the right time because that industry is about to blow up and
the first one we did of this and we've done some after including flying cars a
much more in-depth curriculum on artificial intelligence with self-driving cars so this is a quick
video that introduces it and this is of course Sebastian's run robotics legend see this place
if you can build the same apartment will save you always but on top of its
transformations just imagine instead of owning a car you have a default in stock apartment and B
Hawkins link is phenomenal and it's eco Samara how many don't mean in work it
disappears there is an enormous market for surviving managed genius lots and lots of companies that you
wouldn't suspect have entered that feeling a nasty - I challenge everybody
did we pass the Largey university in the middle of South Africa so that everyone in the world can become
a self-taught engineer and why did we
want to do this was our goal it was to accelerate the deployment of
self-driving cars like Sebastian says in that video there's a number of reasons why self-driving cars a transformational
and at the time this was around 2016 it felt like self-driving cars were just
taking a little bit too long we rewind to that particular spot in time Google
was the really the only main effort going on and what we believed is that it
needed to happen faster and that one of the reasons it wasn't happening fast enough is because there wasn't enough talent in the space so what we decided
to do is like I said build something quite special in want to pair up a world-class curriculum an actual
self-driving car which we'll talk about more and what we called our open-source challenges and all of that would come
together to build this this quite special curriculum so let's start with
the curriculum one of our beliefs was that partnering with industry was the
right way to go that was because it felt and I believe this that the knowledge of
how to build a self-driving car was not necessary trapped in academia it was trapped in industry so we had to
go straight to industry work with engineers that were already you know challenging themselves with these
problems and get them on camera have them teach the concepts that they know and build day in day out
and have that be transplanted to thousands of mines around the world so these are just some of those partners there was many many more but we had a
real focus on finding these engineers wherever they may be and getting those folks on on-camera we also built an
incredibly talented team this is just a small snippet of the curriculum team but of course Sebastian Thrun was was a big
part of this curriculum when I told folks that I'd gotten the chance to work
with him on specifically self-driving cars he likened it to getting basketball lessons from Michael Jordan which I
thought was pretty fun and they were probably just as entertaining but some really truly great folks working on this curriculum and
still doing that to this day who deserve all of the credit frankly here's a quick photo of first lecture recordings with
eventual voyage co-founders Eric and Mac Eric who's on the left he hates this
picture and here's why there you go he still isn't at max height but we had to
he still has that box on his desk and we built a whole 12-month curriculum to
take an intermediate software engineer who may be in consumer software or just some other part of the software world
and take them into self-driving cars we wanted to cover perception prediction
planning localization controls even just the whole breadth of of the industry and
the reason we want to do that is because we saw the best fit for Udacity student not necessarily being a specialist in a
niche for example you know just perception although there's been a whole
bunch of folks doing that as well but that the skills of a Udacity student tend to pair themselves well with being
a generalist someone that can contribute all across the stack so we tried to give these folks that breadth of knowledge
the curriculum that we built with some
you're also welcome project to detective just like real economist people's have
to do in term two you'll learn about sensor fusion localization in control
this is harmful robotics that every self-driving car interior needs to know in order to actually move the vehicle to
space if the localization module you'll build a kidnapped vehicle project which takes
a vehicle that's lost and figures out where it is in the world with the help of sensor readings in a minute
this is exactly what real self-driving cars have to do every time they turn on in order to be on where they are in the
world in the control module you'll build a model predictive controller which is a
really advanced type of controller that's actually combos no credit cards move through the world and use the
steering wheel throttle and brake to follow the set of waypoints or trajectory to get from one point X in
turn three you'll learn about pathway and electives month and you'll learn
about system integration path blending is really the brains of a self-driving car it's how the perfect here's how kind of
it from one point to another as well as obstacles intimacy I'm gonna give you a
sneak preview how it works and this is something that nobody's ever seen before so get ready patenting involves three
parts there's prediction which is figuring out what the other vehicles are going to do
around us this goes up for a while so
it'll posit that the impact of this curriculum was was bigger than we
thought it would be when we pitched as a small team this idea to Sebastian to
viche at Udacity there was a lot of skepticism that something like this was
was going to be successful and the reason that you know there was that skepticism is that one of the kind of
formulas that Udacity looked at to determine the impact of building a certain type of content was the number of open jobs available if there was you
know for example in web development mobile development told that good stuff there was millions of jobs open so it
felt like there was a massive opportunity to impact the area but if you were to in 2016 search for you know
self-driving car engineers or the different disciplines that exist within it was it was kind of just Google so it
was very interesting just to see the instantaneous reaction that we had to launching this curriculum today over
14,000 successful students from all around the world as you can see where the most exciting thing is to see what
students have done with this so a curriculum for example I learned recently that a set of our students here
are building a self-driving truck stopped in India another set of students
in South Korea are building a perception engine for self-driving cars just a
whole bunch of folks are building truly amazing things and only that they've gotten jobs at cruise zukes way mo agro
all the big names and actively impacting those companies today now for the fun
Autonomous trip from Mountain View to San Francisco
stuff so we also decided to make a curriculum extra special and we decided
to do that by building an actual self-driving car and whenever I talked about this internally Udacity people asked me why
why do we need to do this right isn't the curriculum just enough why go to the
you know the length of building an actual self-driving car and selfishly some of it was just a personal want to
you know build a self-driving car but the the reasoning that I use is that what better way to prove to these
students that putting their faith in us that we know what we're doing than to build our own self-driving car and also
what better way to collaborate with these students on an area that is really infantile then again by having this
platform that students could actually run code on a car so we decide to buy a
car and we'll talk more about that in a second but we set ourselves a milestone for our self-driving car it was to drive
from Mountain View to San Francisco 32 miles of driving with zero dis engagements it should be repeatable it
won't be zero disengagement so every single time because otherwise we've got an actual self-driving car but in a
short period of time how much progress can we make towards this this stated goal raise your hand if you've been on
El Camino Rail in in that sort of region okay so you pray understand it's got a
lot of traffic lights in fact on our route about 130 traffic lights it's
multi Lane three lanes speed limit of about 4045 something like that so it's
you know fairly complex but it's also got some constraining factors which is what we're looking for - so focused our
tech efforts this is the car we bought you're probably very familiar if you follow self-driving cars with the
Lincoln MKZ of the world they're everywhere and there's a reason for that in terms of the drive-by-wire nature of
the vehicle and other stuff and we outfitted a whole bunch of sensors some cameras some lighters all that good
stuff we also try to build our own mount we affectionately call this the periscope I don't know why it's in slow
motion but this was not our final design build all this from parts at Home Depot
Trulia MVP and then we got to work the
goal was to accomplish that milestone within six months so we've course had to work fast assembled a dream team of
folks that I worked with on different projects at Udacity they also wanted to - come dabble in this folks that worked
on the machine learning curriculum robotics curriculum etc so this was one of our first days testing and we did
this at the shoreline amphitheater parking lot Jessie now is a very popular place to test self-driving cars in the
Bay Area because Google used to do it in the past we saw a lot of weird stuff for example you'll see here we saw what I
believe to be a motorcycle gang and we
made progress we kept iterating kept building and it started to come together in fact some stuff that we thought
wouldn't work surprisingly just start to work this is on El Camino Real
I'm in the backseat here so Mack
discovered that we shouldn't have stopped at that traffic light but we did we resolve the mystery later let's go to
the next video and of course we learned a lot by going in this route the different behaviors of drivers one of
the things that we were worried about is vehicles cutting us off and when we say cutting us off it means a vehicle
pulling out in front of us even a few hundred feet in front you'll see here
we drove a little slow 25 [Music]
[Music] said that was fine and pretty soon it
got quite boring car was doing very well driving itself we built some cool
algorithms to change lanes when necessary similar to you see with Tesla
autopilot these days
we collaborate with some students on a traffic light classifier which was integrated into Ross there and yep
pretty boring stuff so you can tell Eric was surprised that it was just fine and
we also had a penchant for building of recording themed videos like you saw
maybe from Elon Musk and the Tesla team with painted black we've got our own version of that eventually we became
pretty confident but we always you know wanted to test most of the day just to get the most learnings out of everything
this video was made at 2:30 a.m. driving from Mountain View to San Francisco all
32 miles cost as a backing track
[Music]
[Music]
[Music] maybe want to tow it down so it's easier
because there's less traffic right this is kind of cheating and didn't count as the milestone just to be clear you'll
see that we eventually hit the 32 miles and machers in the driver seat is pretty excited about that
[Music]
[Music]
and they hit it but of course that
didn't count because it's in the middle of the night and that's not gonna be a very useful route but it was awesome
accomplishment just to even make it 32 miles with no dis engagements when this traffic lights lane changes all that
good stuff but after four months this is in the daytime this began I believe it like six sorry 7
a.m. we accomplished it that small team had come together and build something
pretty cool they could handle again multi Lane roadways varying speed limits
traffic lights objects all that good stuff and the thing that really brought
this home to me is that the industry was now ready right it felt like this feeling I had in
software where someone in their bedroom can go and build something and launch it you know almost feeling overnight could
now not quite the same but close to the same happen in self-driving cars but
well we'll talk more about what this led to in a little bit let's talk about open source challenges we also got the same
Open source challenges
question why do this and it was clear to me that for something like self-driving
cars which was so you know formative we had to collaborate with students to
figure out the best stuff because you know even the folks that were Udacity were not necessarily the world's leading experts in these topics who want to use
this hivemind of activity from around the world to teach the best stuff so
just through a period of a year these are all the different challenges we launched there was prizes and leaders
leaderboards and all this sort of fun stuff the one that I'll focus most on today is using deep learning to predict
steering angles and the challenge was
clear it was that given a single camera frame you have to predict the
appropriate steering angle of the vehicle if anyone had read in videos and and papers in 2016 this stuff was all
the rage and it felt like one of those areas that was just begging for more exploration
again let's use this all these students from around the world to do it and we
did have students from all around the world there was over a hundred teams people self organized into these little groups to go and build this and over the
course of about four months we had a whole bunch of submissions all taking
incredibly different approaches to the problem we released a two sets validation sets all that good stuff here
you'll see are the winning model and I later found out that the author of this
model actually went on to lead the self-driving car team at Yandex which if
you've been following CSS is doing some pretty cool stuff and self-driving cars today but you'll see this is on a route
from the Bay Area to Half Moon Bay a very windy road and you'll see that the
prediction matches pretty closely to the actual which is nice and if you read his
description of his solution it's a pretty cool solution and it was I think the most exciting thing was just the
number of different approaches to the problem all resulting in some some
awesome stuff and again in true voyage fashion we recorded a video of what this model perform like on our car
it wasn't perfect as any first model and just that the general approach of camera
only you know driving had it's had its faults one of the main ones that you
know we realized after trying all this stuff out is that of course a car when
steered by such an input performs differently in a car than it does you
know on your desk in a you know simulator through pre-recorded camera frames so adjusting for those
Corrections that might need to be made is something that students after the fact added which was pretty cool so
after all of these things building that curriculum building a self-driving car launching these challenges it felt like
it was time for something new it was awesome to go and collaborate with all these students and it felt like
you know I had to go build something so gathered that same team that had built this curriculum and we said we're gonna
go build a self-driving car this is from my pitch at Khosla Ventures you can kind
Birth of Voyage
of see the pitch deck they're a little bit voyage is a new kind of taxi service our pitch has changed somewhat through
time but that's still pretty accurate and we started what is now called voyage
and our goal really was that we wanted to again build a self-driving car but we
wanted to do it differently we didn't want to follow the same formula that we felt we'd seen from some of the other
folks in the field and the reason is that those folks have real advantages right when you think of it about Google's project of which I'm a big fan
they have this massive engineering pipeline of folks that want to go build a self-driving car at today way mo but
they also have a cash bank balance of billions of dollars that is hard to
match they also have the brand recognition of getting to work with Google and all that good stuff so we just knew we had to think about this
problem quite differently and what motivated me is that today as we all
know we have this incredibly broken transportation system you step outside onto the roads today and I don't know
about you guys but I don't feel particularly safe when I jump into my car over we all know the stats over 1
million people have sefa fatalities on the roads today doesn't include folks that break necks
that inja break bones all that horrific stuff it's also incredibly inefficient
we've again all observe this as we go about our day just the number of lanes that exist on a road today to account
for peak traffic the number of vehicles which have enough room for eight people
have usually one person in that front seat I read a stat recently that only 7%
of the average vehicles energy usage is going towards moving the things that are actually in the car
the rest is waste so an incredibly inefficient system it's also expensive
the reason you know we see a lot of old cars on the road today is because that's at least today the most optimal and
affordable way to lots of folks to get around and inaccessible and you'll see
why this matters to us in particular our goal is to introduce a new way to explore our communities this is a video
of one of our cars at a particularly cool place which we'll talk more about and this is kind of our mission and why
now why is it possible to build a self-driving car now a number of factors
that we learned during that you'd ask the experience but some new as well it feels from everything we see that
sensors are now in this position which these sensors are now capable of level
for self-driving cars the resolution the range the reliability all those things that were necessary for an elf or sub
revving car are today ready that didn't used to be the case if you rewind you know to 2007 and look at the cars that
were participating in the DARPA challenges you'll see a lot of single channel lasers you'll see the relic of
the valid Iron Age TL 64 the the spinning bucket as it's called today and
no one would have claimed those sensors already but today you've got this enormous breadth of sensors that can
take you that way compute is there when we you know think about the recent rise in in GPUs and
whatnot finally you know being able to have enough performance in the back of a
car with the power constraints that you have it's it's there and talent
you know again this is not just Google today you've got all of these great minds from all around the world building
this technology so you're able to recruit those folks put them to work on on the problems they've solved in many
cases beforehand the reason I have yellow for computer vision which is not a knock against computer vision is
because it's not quite there yet for self a fully driverless self-driving car
if you again rewound you know three four five years this would have been a red
but today with all the community and whatnot around computer vision this is
steadily getting to a green state so pretty soon there'll be green and of course then you'll have that perfect
formula for level for driving what we run after is ride-sharing we believe
that the optimal way for people to move around is to be able to summon a car but
the thing that's suboptimal today is that you have to have a human driving you whenever you want to move around
prevents the cost from being lower prevents some safety issues prevent some quality issues we think solving that
will will mean these next-generation way of moving around will will come to
fruition but what we also see is that if you let's say we never remove the driver from the car that a ride hailing network
always had a human driver you are inherently limited by the number of miles you can drive which means that it
will never replace personal car ownership will never fix that fatality
number I talked about all of those those things we must solve so we think by having a self-driving car that these
next-generation transportation networks will come to fruition a lead VC is a guy
Retirement communities
called Vinod Khosla a the founder of Khosla Ventures an awesome guy who's done some truly world-changing things he
has this quote which I'm a big fan of your market entry strategy is often different from your market disruption
start where you find a gap in the market and push your way through and this better communicated what I mentioned at
the very beginning which is that we should build a self-driving car but do it in a different way because if we
don't do that we're gonna fall into the same traps as many of the others that have died along the way we have to find a way to do something
different that we own and that we are really really good at and for us that
was retirement communities hands up if you've ever visited a retirement community and see way less there you go
surprise Lex you've got to get you out to one but these are just amazing places
and the reasons we choose retirement communities first to deploy our
self-driving technology and is for these four reasons they are slower the speed
limits in these communities tend to be far slower than you'd see on public road much calmer roadway when you visit these
locations I liken it to listening to a podcast at 0.75 X just very constrained
very slow and a little boring from time to time but you've also got these HUD
felt transportation challenges we hear from these residents all the time about
how transportation is a pain point and that their only option is a personally owned vehicle these folks know in many
cases they shouldn't be driving but because they don't have an alternative they still drive we hear from folks that
put off much-needed surgeries hip replacements things like that because they don't have a friend in town who's
gonna be able to move them around we hear from folks with vision degeneration
that they just don't see a way that they'll be able to move around and keep that quality of life that they've been
able to have folks gripping steering wheels for extended period of times all these challenges that felt like the best
first place for a self-driving car to begin and a clear path to customers we see that on you know the roads today
ride-sharing on you know Public Citizen mantra is a particularly brutal battle a race to the bottom in terms of cost if
we owned every retirement community in the country meaning the transportation networks there that would in and itself
be a very valuable very valuable business one of my favorite passengers
is on ahed she came to visit as recently and gave this quick speech about why
self-driving cars matter to her in her community
let's talk about our first community this is the villages whenever I show
this slide people are astounded by the number of residents in a community like this over 125,000 and growing over 750
miles of road and what we have in this location is an exclusive license to operate an autonomous vehicle service
this is one of our other beliefs which is that by partnering very deeply with
the community it means that we're able to deliver a better service and that we're able to grow a more reliable
business we won't have you know entrance and competitors from all of the other self-driving car companies in our
communities what we actually do in exchange for that exclusive license is grant these communities equity because
if we win it's probably in fact highly likely as a result of those communities and the addressable market
transportation in these regions is massive these residents tend to be as a
lot of seniors tend to be quite affluent which means that they have some disposable income when it comes to being
able to pay for ride-sharing services and other things like that so we find
that that recipies is absolutely perfect here and we're launching and have
launched passenger services to these these residents I've got a love awesome feedback learned a lot about the needs
of providing ride-sharing for senior citizens just some quick stats this is
from my series x fundraising dec just
about the size of the senior market again this is the first place we go but you can get a feel for just how large
this transportation market is today there are 4 to 7 million seniors that's growing by 2060 to over a hundred
million seniors in the US the total addressable market for just seniors is
incredibly large 2,500 plus communities all that good stuff and this is how we
see the world the landscape of potential deployments you've kind of got a lot of the big guys
focusing on that bottom left quadrant they're focusing on large cities and it makes sense because it's playing to
their unique strengths it's playing to their ability to deploy thousands of cars tens of thousands of cars it plays
the strengths that they have at least some patience or ability to have more extended time lines when it comes to
building this technology but first up like us that you know fights for survival every single day it means that
we have to do things differently so we focus on that top right quadrant there what we've kind of coined is
self-contained communities these places are simplest slower but they also have
this ability for us to have that exclusivity that I talked about and
there's some others of course that we play in whether it's a senior market or maybe even small citizen and things like
that let's talk about autonomous technology so just to reiterate why do
we deploy in retirement communities slower speeds simpler roadway there is a central authority these places tend to
be run by private companies which makes for a quite unique relationship in a
very positive way means we can deploy faster it means we have the potential to have more impact in these regions I also
turns out that retirement communities tend to be located by this ideal weather for self-driving cars think about
Arizona Florida etc we have a world-class team building this a voyage
from all the major programs out there and that makes our lives infinitely
easier one thing that also makes our lives easier is the sensor configuration of our car we've intentionally made this
Sensor and technology stack
decision that we're not going to focus on optimizing for costs today but to optimize for performance we want to get
to truly drive us sooner than most and one of the easiest ways you can again make your life easier is by optimizing
for high resolution sensors at the very top of the vehicle we have the VLS 128
which is a 128 channel lidar that's capable of seeing in three hundred three hundred meters in 360 degrees many other
different light hours on the vehicle to cover different certain blind spots all together we says twelve point six million points per
second and then just looks incredibly high-resolution you'll see our car at
the bottom there and that's the the raw point cloud output that we see in the
world we run towards level four and for us what that means is that if you're
building a demo self-driving car kind of like we did at the Udacity project you may focus on just the top four items
that top row you may focus on perception prediction planning and controls and it turns out you can build a very
impressive demo quite quickly by just focusing on those things but of course those things fall apart whenever edge
cases are introduced which happen all the time so we've spent a ton of time on
all the items here because again our goal is to build not a demo but a truly driverless vehicle we also have a
emphasis on partnerships because what we've noticed in the self-driving
ecosystem is that there's not just more self-driving car companies building the full stack there's now folks going into
simulation to mapping to middlewares to tell the operations to routing to senses of course and and ton more so we make
our lives again easier by partnering with companies like this so that we don't have to spin up a simulation team
or we don't have to spin up an Operations team to go map the world we can just work with these these very cool companies let's talk about one unsolved
problem which fascinates me it's to do with perception and you probably won't be able to notice this unsolved problem
Example challenge for perception (foliage)
from just this picture but maybe if I add some annotations you might foliage
trees bushes whatever you want to call them you may have seen some quotes in
the media about some popular AV programs struggling with such such foliage for
example cruise cars sometimes slow down or stop if they see a bush on the side of a street or a lane dividing pole that
was in the information wrong way this one boobers self-driving car software
has routinely been fooled by the shadows of tree brain which it would sometimes mistake for real objects insiders say that's
Business Insider and even voyage there's only one hard stuff on the way the
culprit is a bush two feet high that protrudes into a lane from a street median which voyage considers possible
threat voyage mate remit and we did but we don't think that's scalable and well
maybe it is I don't know but we at the beginning of 2018 decide to solve this
problem so of course all of this resides in the world of perception area of
Survey of recent perception research
particular fascination for me we're sharing these slides but these are just
some of the the papers and research that we see going on that intends to solve
those sorts of issues one of the reasons you've seen those programs including ours be particularly sensitive to
foliage is because from a perception perspective one of the most well known
way to detect objects is to utilize the map if you have this map and you
effectively simplifying to a certain extent but subtract objects that aren't
in the map and then use that as a way to you know understand what's in and around
you that's dynamic then of course you'll end up with you know decent representations of cars and pedestrians and whatnot but if you know foliage
grows which it does trees then that's gonna you know extend out from the map and mean that that particular bush is
now an object in your path these networks here which these all neural
networks don't use that same technique they don't use the map as a prior instead what they do is take of course
this 3d scan of the world and then take em all learned approach to the problem you'll have you know tens of thousands
hundreds of thousands of labels of cars humans etc and then these next networks
will be able to pick these ones out were particularly fascinated by pixel which came from some great researchers at
Wilbur ATG voxel net came from Apple SPG I've heard our engineers talking a lot
about fast and furious recently which merges together perception and prediction and tracking into a
single network which is pretty cool and point pellets which I think came from the new tana me team recently I think
Kyle is speaking soon right so just in general we see a whole bunch of work
going out there to solve these issues the other one that this these sorts of networks solve which I also find
particularly fascinating is that if you use traditional clustering algorithms what you might see is that if two people
have stood next to each other traditional algorithm will clusters as one object which when you're trying to
you know move away from those edge cases and build a truly self-driving car that's a non-starter
right because pedestrians are the most important thing you can probably detect and detecting two things as one thing is
it's not going to cut it and of course it does that because it's it's a dumb algorithm it's not trained on any sort
of information but these networks again are very very good at understanding the
features and perspectives of humans even if they are in crowds and and whatnot and that then helps all your stack
downstream because if you have accurate perception information about objects in and around you your predictions are much
better your tracking is much better and ultimately how you navigate the world is much safer I'm also particularly
fascinated by reinforcement learning which I know Alexis as well if you've read our way most recent work on
imitation learning I think that's particularly cool another company we track quite closely just because they do
amazing stuff is wave trying to build an entirely self-driving a self-driving car powered by reinforcement learning
I think about disengagement saz rewards and things like that tool to to to net
to better performance also just errors of learned behavior planning ultimately
fusing rules of the road with more learned behaviors the ecosystem I think it's this area that is thriving today
seeing just how many folks are diving into not just the full stack but building tools and building other really
important parts of the the stack the maturation of sensors not just higher
resolution lidar but things like 3d radar we get pitched all the time from from these companies and it's clear to
see there's been a rise in volume from from all these these great great efforts lessons learned now that
Lessons learned
I've been building voyage for two years and prior to that four years that you asked me what things have I personally learned they're not technical in nature
so many things so these all may look like cliches but I promise you they'll
came from lessons which were really really painful in the moment don't be intimidated so the thing that I feel you
know happens a lot in self-driving cars is that because it started in this very
academic sense meaning you know Stanford Carnegie Mellon and and whatnot that it
felt like to break into the industry you had to also go through that same path you had to get a PhD in something and
and really go that the path that was you know well trodden but I think that you
know only takes the industry so far I think it's really important that we get folks from all different backgrounds all
different industries to come contribute to this field because if we don't that there is no driverless it can't happen
in that isolated bubble it needs to be extended out so don't be intimidated by those things understand your limitations
this is perhaps more of a kind of CEO lesson for myself but I think when
you're building out a company from you know one person or five people to today with forty four folks you cannot do
everything and it's really important you build a team around you that is able to do what you used to do but do it 10
times better I pray didn't spend enough time building out that team until we had some challenges our way when it comes to that
stuff be proactive versus reactive I think it's really crucial again when you're
building a company to try and predict what's gonna happen next because if your reactive you're constantly you know two
steps behind what other folks are doing gay love the way I think a lot of folks
again perhaps overstay their welcome in certain areas of the company when they should just say okay I've got experts
now I can just step aside and let those folks do what they do best and speaking
of which hire the best it's really easy when all this pressures on when you're building a company to kind of sacrifice
when it comes to your culture when it comes to high it's really crucial that you find folks that are not just the best in their
field but are the best match for your company and always be curious I think it's always one of the the things we
believe in a voyage is that it's important that knowledge is not isolated
just one person that that knowledge should be spread throughout the company because even though it may feel like
over sharing or over communicating what that knowledge may mean for someone that
has a particularly unique background is they may do something incredibly cool with it they may build something that totally transforms our company that's
about it can jump to questions if that's helpful that was great please give a big hand
[Applause] how did you identify retired communities as the target market to prioritize yes
Q&A
so retirement communities for us was actually there's a really long story about I'll turn me down a little bit so
when we were starting voyage sebastien theorem was very helpful in starting helping us start this company
and of course as kind of naive you know founders of a company we're like well
let's just take this El Camino thing and like put it on everywhere else it looks like El Camino and just do that over and over again but he cautioned against that
and very wisely so because again you're nothing special compared to the other self-driving car companies out there by
doing so and in 2009 he had really
advocated to Google you know leadership etc Larry Page that retirement
communities for self-driving cars might just be the best way for Google to go about deploying their self-driving cars
but and I can understand why I think the Google folks were you know what Google right well we're not just about
retirement communities were about the world like level-5 or nothing right so he got some pushback but he did some
research in that process met some folks so when you know we were starting he's like you got to check out these retirement communities so we did we went
to visit and eventually we got there so we want to got to that point without sebastian pushing for that follow-up on
the quest from the retirement communities the question is do you ever think about the other collateral issues
especially the retirement community would have to get into a car yep and how
exactly would they interface like somebody wants make a call to have a car
come to their wherever they are and they have to move from a point A to point B so how did you ever think about all
these issues that are very germane it's
not just a vehicle moving on its own yep but these are all collateral issues how
do you plan to address this it's good question so the way we think about this is that today we've intentionally
focused it on a segment of the market which is called ad the active adult communities these folks tend to be able
to you know go into their own cars or into a taxi open the door sit down
without the need for any you know assistance when it comes to that but they may have vision issues they may
have other issues that prevent them from driving perhaps for example we hear a lot that folks feel really uncomfortable
driving in the evenings they feel comfortable driving in the daytime because their vision supports it but when it comes to evening time they have
this mad rush to get home but there is that other market which you're talking about right which is folks that just need that helping hand towards getting
to the car and one of our beliefs as a company is that the senior market like I
had in that slide is surprisingly large and what that means to us is that we think we can own it we think we can be
that company that any senior citizen in that situation thinks oh I should call voyage because I need to get you know
from point A to point B instead of thinking I should call way mo or cruise
or any of the folks that gonna go after the general big market they'll think about voyage and the reason they'll think about is is because we'll deliver a product to them that is meant for
those folks that's designed for their use cases it may be that actually you know if they're going on a long trip let's say they're traveling 50 miles the
first mile of that trip and the last mile of that trip may involve a human like you know helping them into the car and then dropping that human off
somewhere else to go do that all over again it may involve crazy robots that help people from their cars we've heard
from you know folk folks at Toyota they're building these back carrying robots and other things that may assist
seniors from getting to the and whatnot so I think that's why that
market fries is particularly exciting because it feels like you can deliver these tailored products that would enable us to be the the market leader
but today we focus on active adult but who knows where you go next can you talk
a little bit about how you determined your final sensor sweet hmm yeah so that
the truth is is never final so we think about generations of vehicles so we have a first generation vehicle which was a
Ford Fusion had a single valid eye naitch TL 64 and a bunch of cameras
radar and we you know set some milestones based on that vehicle and we
accomplished those milestones and then once we reached kind of that the max in
which were able to take that vehicle we then say oh we need you know to bring on a g2 vehicle a second-generation vehicle
so we did that and we said okay we have these certain goals in mind which are pretty lofty and pretty ambitious
we need incredible range incredible resolution for these things and actually what we've discovered is that in our
particular communities going at the speeds that we're going at radar isn't particularly useful so we don't have
radar on our second generation vehicle for example but I'm sure that when we go to that third generation vehicle there'll be other driving factors that
you know we work backwards from the milestone to say what do we need on this vehicle maybe cost in the third
generation vehicle right we may say that hey we need a more affordable sensor suite than what exists in our second
generation vehicle but they're driven by technical requirements and that means that you know we are able to really
marry the two with the vehicle I was curious when you showed the student LED content or when you showed
one of the students in your first practice car had developed a traffic
light sensor and then you showed later on that you know you were getting student input for deep learning models
for steering wheel turns I was wondering how what your system
architecture kind of looks like in terms of the kinds of perception that you take in I have modular it is and to what
extent deep learning algorithms have played a part in those different parts of that system yeah it's a good question
so I really encourage folks to get familiar with Ross so Ross has always been this kind of
playground for robot assists of all different types of robots to be able to try things out on robots and Ross one is
particularly notorious for kind of hockey and hobbyist types of projects but it's not meant for production Ross -
though which is in kind of an alpha release state is definitely meant for more production oriented things and the
reason I mentioned Ross is because it has this awesome architecture which lets you plug and play what they call nodes
and be able to experiment with different approaches to the problem so for example
what you know is running that deep learning model predicting steering angles effectively replaced are more
rules based planner and perception engine and we just plug the output of
that to of the steering angle straight to our controller to just actuate the
vehicle and Ross is particularly good at those sorts of architectures and it's
all open source so you can do some cool stuff with it can you tell like how you handle the liability insurance rear for
passengers for your vehicles also how we handle insurance that question so we
have a pretty cool deal with a company called intact insurance and the idea is
that insurance in the autonomous age is gonna be very different than insurance
you know today right for human drivers because there's different risk assessments and whatnot and one of the
ways that we're able to prove to these insurers that you know we're good at
what we do is actually sending them data right we send them data from our cars as we drive showing that as we move through
the world we accurately detected things and planned around things and all that good stuff and then they use that data to inform our rates of insurance I think
that the future achieve insurance will be on a similar lines but perhaps more extreme where for example the rates will
change depending on the complexity of the environment if we're just driving down a straight road completely straight
and a zero vehicles around us our insurance rate should be super low right but if we enter a city center and as
thousands of people and cars and all that crazy stuff our insurance rates should just rise almost instantaneously
so what pond would someone today that insures the passenger the car senses all
that stuff but I think there's a lot of room for innovation there too did you have any problems like onboarding the people initially
when they were like you know skeptical scared and then the other question is what are the like major missing pieces
you computer vision to achieve out for what was that last maze it missing
pieces between command in computer vision to achieve my level four self-driving gotcha so one of the more
interesting insights I think we had about retirees is that again in my kind of naive state back in 2016 my general
feeling was retirement communities might not be the first to adopt this technology right because they may be slower to adopt new technology might be
scared of the technology all those sorts of things and to kind of validate that I
went to talk to some senior citizens because I talked to my own grandma she hates self-driving cars sounds like that's not a good sign but when to talk
to these folks in these sorts of locations and the really interesting thing we learned is that traditional consumer software or devices yes there
is definitely a lag in adoption with senior citizens and that's proven in many studies many stats that senior citizens are slower to adopt the
Facebook's of the world or the instagrams or the whatsapp's all those sorts of things cryptocurrency had Anna
but that's because they have these very well-defined processes that they've had for most of
their lives right instead of using facebook they call someone up and they have a chat you know a conversation with
someone about their day or all the stuff that's going on or they you know don't
share a picture on Instagram they physically mail a picture or something like that so to change that behavior is
tough right because that's a behavior that is fundamentally different than what they used to they have to log on to
a computer go to this weird Facebook thing and like share pictures with thousands of people that's weird but the
difference between that and a self-driving car is that our experience is no different than the car they used
to it just turns out it's being driven differently right like they see a car it's the same you know similar form factor to what
they used to they open it all they sit in the back seat okay there's a button I have to press to say go but it's pretty
similar to what I'm used to in my past I want to learn a new behavior I have to change something that I'm used to so
that was our first learning and then also they actually really don't care too much that it's autonomous they have very
when I'm in the car quite curious and enthusiastic about the technology and want to tell them about I don't know
lidar and deep learning and perception and that they you know don't want to hear any of that stuff and it kind of
dawned on me that the reason that is is because what they senior citizens have witness over their lifetimes it's far
more dramatic than I have right like we've oldest passenger was 93 and she told me a story about how when she was
very young she remembers literally moving on an almost daily basis in a horse and cart so when you talk about
like self-driving cars to those folks like they just you know that they couldn't care less because between that
period and today they've seen the birth of like flight planes everywhere they've seen car proliferation they've seen
scooters now they've seen like all of this crazy subway systems so a
self-driving car to them is like oh that's cool what I just wanted to move me that's our biggest learning bet the
question was computer vision what needs to happen between now and level-4 yeah so I think the the Holy Grail right so
if you had perfect perception self-driving cars are solved if we knew every object that was on the road in and
around is within a reasonable distance self-driving cars are solved false positives are accepted today which i
think is good but you really want to minimize false negatives right you want to zero false negatives in the world and
I think that's why we still have a tiny bit of work to do because when you think about the reason for a test driver being
in the vehicle well perception feeds everything downstream right so if you miss an
object miss identifying object any of that sort of stuff then that effect causes the whole stack downstream to to
become quite chaotic that's why I'm excited about all those networks I talked about one of the other things we
believe that helps us minimize false negatives to non-existent kind of state
as for us is that we band together multiple networks so we don't just rely on a single layer of perception we say
different networks have different strengths for example voxel net is particularly good at pedestrians but
Pixar is not so great as pedestrians because it's from a bird's eye view where pedestrians are quite thin and
whatnot so let's ban those two networks together and let's also band together some more traditional computer vision
algorithms that may not be processed on the entire you know 360 scan but may be processed on a small sample maybe at the
front of the vehicle for example so there's just lots of little bits and pieces like that to go through to
minimize the worst case scenario which is a false negative but it's clear when you see you know way mo and whatnot that
they feel very very very close to that so state you mentioned that weather was
one of the main reasons this was a great place to start can you talk about hurricanes yes it was funny I got a
question recently from Alex Roy I mean Lex is just talking about about okay in
the event of a hurricane right let's not talk about the technology second but in the event of a hurricane like we've all seen those pictures of people you know
getting on the freeways and trying to get out of the path of the hurricane right how is that going to work in a world where self-driving cars are
everywhere and personally driven vehicles there may be more of the the smaller set the smaller size I don't
quite have an answer to that yet but I think it's an interesting kind of thought problem from a technology perspective the really important part
the really important part of whether fuzz is remote operation so inside
everyone about sorry all of our vehicles have a cellular connection right and
each of those vehicles is connected to a remote operator that sat in somewhat
close proximity to that vehicle and that remote operator has a few jobs one is to just ensure the safe operation of the
vehicle make sure that vehicle is doing as it's intended to do all those good things but another is to make sure that
the operational domain that we are currently operating in is the one that's designed for so all these different
camera feeds are being you know live stream to this remote operator and if there is sudden downpour of rain that
remote operator has the ability to bring that vehicle to safe stop until that you know rain
shower disappears or whatever or hurric el hurricane whatever it may be but
there are companies I was pitch rescind by companies building weather forecasting on a scale that is not
really used today but really microclimates so thinking about just like this small subsection of the
villages predicting and understanding exact weather within those regions and then having web hooks to tell you or as
voyage that that's about to happen so there's a lot of cool stuff happening there but remote operates is currently kind of the eyes and ears of all cows to
prevent that sort of issue so please give all or a big hand thank you guys
you

----------

-----

--60--

-----
Date: 2019.02.12
Link: [# Drago Anguelov (Waymo) - MIT Self-Driving Cars](https://www.youtube.com/watch?v=Q0nGo2-y0xY)
Transcription:

all right welcome back to 6sz ro9 for deep learning for self-driving cars today we have Drago and glial of
principal scientists at way mo aside from having the coolest name in
autonomous driving Drago has done a lot of excellent work in developing applying machine learning methods to autonomous
vehicle perception and more generally in computer vision and robotics he's not helping way mo lead the world in
autonomous driving 10 plus million miles achieved autonomously to date which is
an incredible accomplishment so it's exciting to have Drago here with us to speak please give him a big hand
[Applause] hi thanks for having me I will tell you
Background
a bit about our work and the the exciting nature of self-driving and the problem and our solutions so my talk is
called taming the long tail of autonomous driving challenges my background is in perception in robotics
so I did PhD at Stanford with Daphne Koller and worked closely with one of
the pioneers in the space professor Sebastian Thrun I spent eight years at Google doing research on perception also
work on Street View developing deep models for detection neural net architectures I was briefly zooks I was
heading the 3d perception gaming jokes were built another perception system for
autonomous driving and I've been leading the research team at way more in most
recently so I want to tell you a little bit about Weimar when we start way more actually
Waymo story (2009 to today)
this month has its 10-year anniversary it started with Sebastian throng
convinced the Google leadership to try an exciting new moonshot
and the goal that they set for themselves was to drive 10 different segments that were 100 miles long and
later that year they succeeded and drove an order of magnitude more than anyone has ever driven
in 2015 we brought this car to the road it was built ground up as a study in
what fully driverless mobility would be like in 2015 we put this vehicle in
Austin and it completed the world's first fully autonomous ride on public
roads and the person inside this car is a fan of the project that he is blind so
we did not want this to be just a demo fully driverless experience we worked hard and in 2017 we launched a fleet of
fully self-driving vehicles on the streets of in Phoenix metro area
and we have been doing driverless fully driverless operations ever since
so I wanted to give you a feel for what fully driverless experience is like
[Music]
[Music]
[Music]
[Music]
and so we continued last year we launched our first commercial service in
the metro area of Phoenix there people can call a web on their phone it can
come pick them up and help them with errands or go to school and we've been already learning a lot from these
customers and we're looking to grow and expand the service and bring it to more people so in the process of drawing the
service we have driven 10 million miles on public road is like said and
driverless lis in Enmore also with with
human drivers to collect data and we've driven all kinds of scenarios cities
capturing a diverse set of conditions and a diverse set of situations in which we develop our systems
I want to tell you I mean about the long tail of events this is all the things we need to handle to enable truly sub
Long tail of events
driver this future and I guess all the problems that come with this and offer some solutions and show you how has been
thinking about these issues so as we drove 10 million miles of course we
still find scenarios new ones that we have not seen before we still keep collecting them right and so when you
think about self-driving vehicles they need to have the following properties first a vehicle needs to be capable it
needs to be able to handle the entire task of driving so you cannot just a subset and remove the human operator
from the vehicle and also all of these tasks obviously need to do well and safely and that is the requirement to
achieving so driving at scale and when you think about this now the question is
well how many of these capabilities and how many scenarios do you really need to handle well it turns out well the world
is quite diverse and complicated and
there is a lot of rare situations and all of them need to be handled well right and they call this the long tail
the long tail of situations you it's it's it's one type of effort to get
yourself driving for the common cases and then it's another effort to tame this the rest and they really really
matter and so I'll show you some for example
this is us driving in the street and let's see if you can tell what is unusual in this video you see so this I
can play it one more time so there's a
bicyclist and he is carrying a stop sign and I don't know where he picked it up
but it's certainly not a stop sign we need to stop for unlike others right and
so you need to understand that let me show you another scenario this is another case where we are happily
staying there and then the vehicle stops and a big pile of poles comes our way
right and you need to potentially understand that and learn to avoid it generally well different types of
objects can fall on the road it's not just pose here's another interesting scenario this is happens a lot it's
called construction and there's various aspects of it one of them is someone changed clothes Delaine put a bunch of
cones and we learn and this is our vehicle correctly identifying where it's
supposed to be driving between all of these cones and and successfully executing it so yeah we drive for a
while and this is this is something that is happens fairly often if you drive a lot another case is this
one I think you can you can understand what happened here and you can notice
actually so we hear the siren so we we have the ability to understand sirens to
special vehicles and you can see we hear it and stop and some guys are much later than us breaking at the last moment
letting the emergency vehicle pass and
here's another scenario potentially I want to show you let's see if you can understand what happened
so let me play one more time did you
guys see so we stopped at there's a green light we're about to go and someone goes at
high speed running a red light without any remorse right and we successfully stop and prevent issues right and so
sometimes you have the rules of the way and you have your road and people don't always abide by them and that's
something that you know I don't want to just directly go in front of that person even if they're breaking the law so
hopefully with this I convince you that the situations that can occur a diverse and challenging and there's quite a few
of them and I want to take a little bit on a tour of what makes this challenging and then tell you some ways in which we
think about it and how we're handling it and so to do this we're going to delve a
little bit more into the main tasks for sub driving which is perception prediction and planning so I'll tell you
Perception, prediction, and planning
a little bit about those right and perception these are the core AI aspects
of the car usually this task there's others we can talk about others as well in a little bit but that let's focus on this person so perception is mapping
from sensory inputs in potentially prior knowledge of the environment to seen representation and that same
presentation can contain objects it contains in semantics potentially you can construct the map you can learn
about objects or relationships and so on and perception the space of things you
need to handle in perception is fairly hard it's a complex mapping right so you have sensors the pixels come later
points come or radar scans come and you have multiple axis of variability in the
environment so obviously there's a lot of objects they have different types appearance pose is I don't know if you
see this well they're a bunch of people dressed as dinosaurs in this case people generally are fairly creative in how
they dress vehicles can also be different types people come in different
poses and we have seen it all right so that's one of prospects
there's different environments that these objects appear in so there are times of day seasons day night different
for example highway environment suburban street and so on and then there's a
different variability axis and this is a little more slightly more abstract that different objects can come in these
environments in different configurations and can have different relationships and so things like occlusion there's a guy
carrying a big board there is reflections there is smell people riding
on horses and so on and so what am i showing this because I just want to show
you the space right so in most cases you care about most objects in most
environments in most reasonable configurations and that's a space that you need to map from from the sensor
inputs to a representation that makes sense and you need if you need to learn this mapping function or represent it
somehow right and so let's go to the next step which is prediction so apart from just understanding what's happening
in the world you need to be able to anticipate and predict what some of the actors in the world are going to do the
actors being mostly people and people is honestly what makes driving quite
challenging this is one of the aspects that do so it's you know vehicle needs to be out there and be a full-fledged
traffic scene participant and this anticipation of agent behavior sometime
needs to be fairly long-term so sometimes when you want to make a decision you want to validate or convince yourself it does not interfere
what what anyone else is going to do and it can go from one second to maybe ten seconds or more you need to anticipate
the future so what goes into anticipating the future well you can
watch it past behavior some ones I'm going this way maybe I will continue I'm going there maybe I'm very aggressively
walking and maybe I'm more likely to do aggressive motions in the future high
levels in semantics well I'm in a presentation room I'm sitting here at the front giving a talk I'll probably
stay here and continue even though stranger things have happened
and of course there's subtle appearance skills so for example if a person's
watching our vehicle and moving towards them we can be fairly confident they're paying attention and not going to do
anything particularly dangerous if someone's not paying attention or being
distracted or you know there is a person in the car waving at us various gesture
skills the blinkers from the vehicles these are all signals and and subtle signals that we need to understand in it
in order to be able to behave well and last but not least even when you predict how other agents behave agents also
affected by the other agents in the environment as well so everyone can affect everyone else and you need to be
mindful of this so I'll give you an example of this I think this is one of the issues that really needs to be
thought about we are all interacting with each other so here's the case our way move vehicle is driving and there is
two bicyclists in red going around a parked car and what happens is we
correctly anticipate that as day bike they will go around the car and we slow down and let them pass right so we
reasoning that they will interact with the parked car this is the this is the prediction our most likely prediction
for the rear bicyclists we anticipate that they will do this and we correctly handle this okay so this illustrates
prediction and here planning this is our decision-making machine it produces
vehicle behavior typically ends up in control commands to the vehicle accelerate slow down steer the wheel any
to generate behavior that ultimately has several properties to and it's important to think of them which is safe safety
comes first comfortable for the passengers and also sends the right
signals to the other traffic participants you because they can interact with you and they will react to
your actions you need to be mindful and you need to of course make progress you
need to deliver your passengers so you need to trade all of these in a reasonable way right and it and it can
be fairly sophisticated reasoning and complex environments I'll show you just one scene this is this is the complex I
think school gathering there's bicyclist trailing us vehicles really close the hand within as a bunch of pedestrians
and we need to make progress and here is us we're driving and reasonably well in
crowded scenes and that is part of the prerequisite of bringing this technology
to in all the deaths urban environments being able to do so how are we going to do it well I gave it up I'm a machine
Machine learning at scale
learning person I think when you have this complicated models and systems machine learning is a really great tool
to model complex actions complex mapping functions features right and so we're
going to learn our system and we've been doing this I mean we're not the only one so obviously this this is now a machine
learning revolution and machine learning is permeating all parts of the way imma
stack all of these systems that I'm talking about it helps us perceive the world it helps us making decisions about
what others are going to do it helps us make our own decisions and machine
learning is a tool to handle the long tail right and now tell you a little more on this how so I have this allegory
about machine learning that I like to think about so there is a classical system and there is a machine learning system and to me a classical system and
I've been there I've done well early machine learning also systems also can be a bit classical you're the artisan
you're the expert you have your tools and you need to build this product and you have your craft and you go and take
your tools and build it right and it can fairly quickly get something reasonable but then it's harder to change it's
harder to evolve if if you learn new things now I need to go back and maybe the tools don't quite fit and you need
to essentially keep keep tweaking it and starts becoming the more complicated the product becomes the harder it is to do
and machine learning modern machine learning is like a factory right so
machine learning you build the factory which is the machine learning infrastructure and then you feed data in
this Factory and get nice models to solve your problems right and so kind of
infrastructure is at the heart of this new paradigm you need to build the factory all right once you do it now you
can iterate it's scalable right just keep the right data keep feeding the machine keeps giving you good models so
what is the ml factory for self-driving models well roughly it goes
this we have a software release we put it on the vehicle we're able to drive we
drive we collect data we collect it and we store it and then we select some some
parts of this data and we send it to labelers and the label is labeled parts of the data that we find interesting and
that's the knowledge that we want to extract from the data these are the labels they are notations the results we
want for our models right there is and
then what we're going to do is we're gonna train machine learning models on this data after we have the models we
will do testing and validation validate that they're good to put on our vehicles once they're good to put on our vehicles
we go and collect more data and then the process starts going again and again right so you collect more data now you
select new data that you have not selected before right you add it to your data set you keep training the model and
iterate iterate iterate it's a nice scalable set up of course this needs to be automated it needs to
be scalable itself it's a game of infrastructure right and at Weimer we
have the beautiful advantage to be really well set up with regards to the machine learning infrastructure and I'll
tell you a bit about its ingredients and how we how we go about it so ingredient
one is computing software infrastructure and we're part of alphabet Google and we are able to first of all leverage
tensorflow the deep learning framework we have access to the experts the throat pans the flow and know it in-depth we
have data centers to run large-scale parallel compute and also train models we have specialized hardware for
training models which you know make it cheaper and more affordable and faster so you can iterate better ingredient to
high quality label data we have the scale to collect and store hundreds and
thousands and more miles to millions of miles and just collecting a store and
convenience miles is not necessarily the best thing you can do right because
there is a decreasing utility to the data so most of the data comes from common scenarios you may be already good
at them and that's where the long tail comes right so so it's really important how you select the data and so this is
important part of this pipeline so while you're running release on the vehicle we have a bunch of models we have a bunch
of understanding about the world and you can we annotate the data as we go and you can use this knowledge to decide
what data is interesting how to store it which data we can potentially even ignore so then once we do that again we
need to be very careful how to select data we want to select data for examples that are interesting in some way and complement capture these long tail cases
that we potentially may not be doing so well on and so you know for this there
is we have active learning and data mining pipelines given exemplars find
the rare examples look for parts of your system which are uncertain or you know
inconsistent over time and and go and label those cases last but not least we
also produce auto labels so how can you do that well when you collect data you also see the future for many of the
objects what they did and so because of that now knowing the past and the future you can annotate your data better and
then go back to your model that does not know the future and try to replicate that with that model right and so you
need to do all of this is part of the system ingredient number three high quality models we're part of larger
alphabet and Google and deepmind and generally alphabet is the leader in AI
when I was at Google we were very early on the deep learning revolution I happen
to have the chance to be there at the time it was 20 2013 when I got on to do
deep learning and a lot of things were not understood and we were there working on it earlier than most people and so
through that we had the opportunity and the chance to develop some of the in my time the team I managed to invented
neural net architecture like Inception which became popular later we invented
at the time the state of the art object detection fast object detector called SSD and we want imagenet 2014 and now if you
go to the conference is Google and deep mine the leaders in perception and reinforcement learning and smart agents and you know there is like state of the
art say semantic segmentation networks pose estimation and so on the object detection of course goes without saying
and so we collaborate with Google in deep mountain projects improving our models and so this is my factory for
self-driving models and I want to tell you something that kind of captures all
of these ideas infrastructure data and models in one this is a project we did
recently and today we put online in our blog about automatic machine learning
for tuning and adjusting architectures of neural networks so so what what did
we do so there is a team at Google working on auto ml automatic machine
learning and usually networks themselves a complex architecture they're crafted by practitioners - artisans of networks
in some way and sometimes you know we have very high latency constraints in the models we have some compute
constraints the network's is specialized it takes often people months to find the right
architecture that's most performant low latency and so on and so there's a way to offload this work to the machines you
can have machines themselves once you suppose the problem go and find your
good network architecture that's both low latency and high performance right and so that's what we do and we drive in
a lot of scenarios and we as we keep collecting data and finding your cities or new examples the architectures may
change and we want to recently find that and keep evolving that without too much effort right so so we worked with the
Google researchers and they had a strong work where they invented well they
developed a system that searched the space of architectures and found a set
of components of neural networks it's a small sub Network called mast cell and
this is a diagram of a nerve cell it's a such set of layers put together that you can then replicate in the network to
build a larger Network and they discovered in a small vision dataset it was called C 410 it has its it's from
the early days of deep learning it was a very popular date set and you can quickly trade models and and explore
the large search space so the first thing we did is it took some problems in
that we have for our stack one of them being lighter segmentation so you have a map representation and some lighter
points and you essentially Sigma and the lighter points you say this is this
point is part of a vehicle that point is part of vegetation and so on this is a standard problem so what we first did it
way mo is we explored several hundred
mast cell combinations to see what performs better on this task and we
thought one of two things happened for the various versions that we found one of them is we can find models with
similar quality but much lower latency and less compute and then there is
models of a bit higher quality at the same latency it's essentially we found better models than the human engineers
did and similar results were obtained for added problems Lane detection as
well with this transfer learning approach of course you can also do entrant architecture search so there's
no reason why what was found on C 410 is best suited for our more specialized
problems and so we went about this more from the ground up so let's find exactly
deeper search much much larger space not limited to the nest cells themselves
and so the way to do this is because our networks are trained on quite a lot of data and take quite a while to converge
and it takes some compute we went to define the proxy task this is a smaller task simplified but correlates with the
larger task and we do this by some experimentation of what would be a proxy task and once we establish a proxy task
now we execute the search algorithms developed by the Google researchers and so we train up to 10,000 architectures
with different topology and capacity and once we find the top hundred models now
we train the large networks on those models all the way and pick the best ones right and so this way we can
explore much larger space of network architectures so what happened so on the
Left this is 4,000 different models spanning the scale and latency and quality and in red was the transfer
model so act after the first round of search we actually did not produce the better model than the transfer which
already leveraged their insight so then we took the learnings and the best models from this search and did the
second round the search which was in yellow which allowed us to beat it in third is we also executed reinforcement
learning algorithm developed by their researchers on 6,000 different architectures and that one was able to
significantly improve on the red dot which also significantly improves on the
in-house algorithm so that's one example where infrastructure data and models combine
and shows how you can keep automating the factory that is all good but we keep
Addressing the limits of machine learning
finding new examples in the world and for some situations we have fairly few examples as well right and so there are
cases where the models are uncertain or potentially can make mistakes and you
need to be robust to those I mean you cannot put the product and say well our network just don't handle some case and
it's so so we have designed a system to be robust even when ml is not
particularly confident and how do you do this so one part is of course you want redundant in complementary sensors so we
have given 360-degree field of view on our vehicles both in camera lighter and radar and they're complementary
modalities first of all you know an object is seen in all of them second of all they all have different strengths
and different modes of failure and so whenever one of them tends to fail the others usually work fine and so that
that helps a lot make sure we do not miss anything also we design our system to be a hybrid
system and this is the point I want to make right so I mean some of these mapping problems or you know problems
with nutria player models are very complicated they're high dimensional the image has a lot of pixels lighter has a
lot of lighter points right the networks can end up pretty big and it may not be
so easy to train with very few examples with the current state of the art and so the state of the art keeps improving of
course so this is their zero short and one-shot learning but we can also well
the state of the art is improving in the models we can also leverage expert domain knowledge and so what does that
do so humans can help develop the right input representations they can put an
expert bias that constrains the representation to fewer parameters that already describe the task and then with
that bias it is easier to learn models with fewer examples and there is also of
course experts can put in their knowledge in terms of designing the algorithm which incorporates it as well
right and so our system is this hybrid it's an example of what that looks for
perception is well with no matter if the there's cases where the machine learning
system may be not confident we still have tracks and obstacles from leather and radar scans and we make sure that we
we drive relative to those safely and in prediction and planning if we're not confident in our predictions we can
drive more conservatively and over time as the factory is running and our models become more powerful of course improve
and we get more data of all the cases the scope of ml grows right and the
sister the the set of cases that you can handle with it increases and so there's
two ways to attract attack the tail you both protect against it but you also keep growing ml and making a system more
performant I'm going to tell you now how we deal with large-scale testing which
Large-scale testing
is another key problem it's very important in in the pipeline and also in getting the vehicles on the road so how
do you normally develop a self-driving algorithm well the ideal thing you're gonna do is you make your algorithm
change and you would put it on the vehicle and drive a bunch and say now it looks in great alright let's make the
next one the problem is I mean we have a big fleet we have a lot of data but some
of the conditions and situations occur very very rarely and so if you do this you're gonna wait a long time
furthermore you don't just want to take your code and put it on a vehicle you need to test it even before that you
don't want to like you want very strongly tested code in public streets so you can do structured testing we have
a 90 acres air force base place where we can test very important situations and
situations that occur rarely it's an example of such a situation and so you
can do this as well so you can select and deliberately staged safely conditions occur but now again you
cannot do spore all situations so what do you do a simulator right and so how
much we need to simulate well we simulate a lot so we simulate the equivalent of 25,000 cars virtual cars
driving ten million miles a day and
seven over seven billion miles simulated it's a key part of our release process
so why do you need to simulate this much right well I hopefully I convinced you
there is a variety of cases to worry about and that you need to test right
through so far and furthermore it goes
all the way bottom-up so as a change perception for example slightly different segmentation or detection the
changes can go through the system and you know the results can change
significantly and you need to be robust to this you need to test all the way so
what to simulate one thing you can do is
Teaneck scenarios from scratch working with safety experts Nitsa and analyzing water conditions in which typically lead
to accidents so you can do that of course you can do it manually you can create them what else could you do well
you want to leverage your driving data you have all your logs you have a bunch
of situations there right so you can pick interesting situations from your logs and furthermore what you can do is
to take all these situations and you any create variations of this situation so you get even more scenarios so here's an
example of a log simulation I'll play Twice first time look at the image this
is what happened in the real world the first time so in the real world we mostly stayed in the middle lane and
stopped if you see what's happened in simulation simulation our algorithm
decided this time to merge to the left lane and stopped and everything was fine
things were safe things were happy what can go wrong in simulation from logs
well let's say this is another scenario slightly different visualization our
vehicle when it drove the real world was where the green vehicle is now in
simulation we drop differently and we have the blue vehicle right and so we're
driving BAM what happened well there is
a purple they're pasty purple agent who in the real world saw that we passed them safely and so it was safe for them to go
but it's no longer safe because we changed what we did so the insight is in simulation our actions affect the
environment and it need to be accounted for so what does that mean if you want
to have effective simulations on a large scale you need to simulate realistic driver and pedestrian behavior so you
know you could think of a simple model well how do you do oxy or what's a good
approximation of a realistic behavior well you can do a break and swerve model so you just say well there is some
normal way reactions happen you know I have a reaction time and braking profile
it may be swerving profile so if an agency someone in front of them maybe they just apply it is an algorithm all
right hopefully I convinced you that behavior can be fairly complicated in this will not always produce a
believable reaction especially is complex interactive cases such as merges
lane changes intersections and so on right so what could you do
you could learn an agent from real demonstrations well you went and
collected all this data in the world you have a bunch of it information of how vehicles pedestrians behave you can
learn the model and use that okay so what is an agent let's look a little bit
an agent receives sends the information maybe context about the environment and
it develops a policy it develops a reaction that's the driver agent in
applies acceleration is steering then gets new sensor information new map
information place in the map and it continues and if it's our own vehicle then you also have a router that's in
explicit intent generator which says well the passenger wants you to go over there why don't we try to make a right
turn now so you also get an intent and this is an agent you know it could be in
simulation it could be in the real world roughly this is the picture and this is an end-to-end agent end to end learning is popular right to its best
approximation if you learn a good policy this way you can apply it and have very believable agent reactions
right and so I'm going to tell you a little bit about work we did in this direction so we put a paper on archive
about a month ago I believe on we took 60 hours of footage of driving and we
try to see how well we can imitate it using a deep neural network all right
and so one option is to do exactly the same to antigen policy but we wanted to make a task easier how well we have a
good perception system at Weymouth so why don't we use its products for that agent also can simplify the input
representation a bit that is good if bigdhaas becomes easier controllers are well understood we can use an existing
controller so no need to worry about acceleration and arcs we can generate trajectories now if you want to see in a
little more detail to understand the representation is so we have this is our our agent vehicle which is sub driving
vehicle in this case but could be a simulation agent and we render an image with it at the center and potentially we
augment it with some we can we can generate a little bit of rotation to the image just so we don't over bias
the orientation a specific way all right and it's an 80 by 80 box so we roughly
see about 60 meters in front of us and 40 meters to the side in the center and
now we render a road map in this box which is the map like which lanes you're
allowed to drive on these traffic lights and generally at intersections we render what lanes are allowed to go and what
lanes and how the traffic lights permitted or do not permit it then you can render speed limits the objects
result of your perception system you render your current vehicle where it
believes it is and you render the post history so you you give an image of
where the agents been in the last for a few steps and so you want and last but
not least you render the intent so the intent is where you want to go so the conditions on this intent and this input
you want to predict the future waypoints for this vehicle right so that's the task and you can praise it as a supervised
learning problem man just learn to learn a policy with this network that
approximates what you've seen in the world with 60 hours of date course
learning agents there is a well-known problem it's identified it's called
paper dagger by Stephane Ross who is actually way more now and Andrew Pannell
so it's easy to make small errors over time so even though in each step if you do if you could do a relatively good
estimate if it strings 10 steps together you can end up very different from where agents have been before right and there
is techniques to handle this right one thing we did is synthesize perturbations so you have a trajectory and we
synthesize the form the trajectory and force the vehicle to learn to come back to the middle of the way so that's
something you can do that's reasonable now you know if you just have direct
imitation based in supervision we are trying to pass the vehicle in the street and it's stopping and never continuing
so now we did perturbations and well it
kind of ran through the vehicle right so that's not enough so we need more right
it's not actually an easy problem so in addition to having this agent RNN which essentially takes the
past and keeps creates memory of its past decisions and keeps iterating
predicting multiple points in the future so it predicts the trajectory piecemeal in the future
how about we also learn about collisions and staying on the road and so on so
we've meant the network and now the network starts also produce predicting a mask for the road and now we have a loss
here I don't know if I can point so here you have a road mask loss you say hey if
you driver generate motions that take outside the road that's probably not good hey if you ever cause collisions
where your perception network which takes takes the other objects and predicts their motions to predict here
our motion where the road is in the other agents motion in the future and
they're trying to make sure there's no collisions in that we stay on the road so you add this structural that adds a lot more constraints to the
to the system as it trains so it's not just limited but what's it with what it's explicitly seeing it allows it to
reason about things it has not explicitly seen as well and so now here's an example of us driving with
this network and it can now it can you can see that we're predicting the future it with the yellow boxes and we're
driving safely to intersections and complex scenarios actually handles a lot of scenarios very well I if you
interested I welcome you to go read the paper it handles most of the simple situations fine so now we have our past
two approaches the passing a parked car one of them stops in every starts the other one hits the car now it actually
handles it fine and beyond that afterwards we can stop
at a stop sign happily which is the red line over there and it does all of these operations and what we did beyond this
is we took the system has learned to an imitation data and we actually draw our real bueno car with it so we took it to
castle their force base staging grounds and this is it driving a road it's never seen before and stopping at stop signs
and so so that's all great we could use it as an agent simulation world and we could drive a car with it but it has
some issues so let's look on the left so here it is driving and then it was
driving too fast so because our range is limited it didn't know it had to make a turn in it over and the third so it just
drove off the road that's one thing that can happen so you know when one area of
improvement more range hears it is another time so yellow is by the way
what we did in the real world and green is what we do in the simulation in that example and here we're trying to execute
a complex maneuver a u-turn we're sitting there and we don't try to do it and we almost do it but not quite and at
least we end up in the driveway and there is that the interactive situations
when they get really complex this network also does not do too well right and so what does that tell us well long
tale came again in testing right there's again you can learn the policy for a lot of the common
situations but actually in testing some of the things you really care about is the long tail you want to test to the
corner cases you want to test in the scenarios where someone is obnoxious and adversarial and there's something not
too kosher right so one way to think of
it is this right this is the distribution of human behavior and of course it goes in multiple axis it could
be you know aggressive and conservative right and then somewhere in between you
could be super expert driver is super inexperienced and somewhere in between and so on so like our end-to-end model
it's fairly it's an ambassador's Entei
ssin meaning it could in theory learn any policy right I mean if you see everything you want to know about the environment by and large but it's
complex and this is similar a bit to the models as well some of the models we talked about before you can end up with
complex model if you have complex input this is images that are 80 by 80 with multiple channels it's a large input
space the model can have tens of millions of parameters now if you have an example if you have a case where you
have two or three examples in your whole 60 hours of driving there's no guarantee that your 10 million parameter model
will learn it well right and so it's really good when you have a lot of examples it's really trying to do well
in those and then you have the long tail so what do you do well we can improve
the representation you know we can improve our model this is you know there is a lot of room to to keep evolving
this and then this area will keep expanding right and that's one good direction there is a lot of interesting
questions how to do that and we're working on a lot of them is actually some exciting work hopefully I get to share with you another time something
else you can do if you remember from my slide about the hybrid system when you go to the longtail you can you can do
essentially a similar thing which is simpler biased expert design input distribution that is much easier to
learn with few examples you can also of course use expert design models
and so in this case you still will produce something reasonable by inputting this human knowledge and you
could have many models I mean there's not one you could just tune to various aspects of this distribution you can
have little models for all the aspects you care about you can mix and match it so that's another way to do it so let me
tell you about one such a model so the trajectory optimization agent so we take
inspiration from a motion control theory and we want to plan a good trajectory
for the vehicle the agent vehicle and that satisfies a bunch of constraints
and preferences and so one insight to
this is that we already know what the agent did in the environment last time so you have fairly strong idea about the
intent and that helps you when you specify the preferences because you can say okay well I have give me a
trajectory that minimizes some set of costs which are preferences on the trajectory typically called potentials
what is the potential well at different parts of the trajectory you can add this attractor potential saying well try to
go where you used to be before for example and that's the benefit of in simulation you have observed what was
done so this is a bit simpler and of course you can have repeller potential
don't hit things don't run into be a cause right so to first approximation that's what the roughly looks like and
so now where is the learning right well it's still machine learning model there is a presentation these potentials have
parameters it's the steepness of this of this curve there is sometimes they are
multi-dimensional right there's there's a few parameters typically we're talking a few dozen parameters or less all right
and you can learn them too so there is a technique called inverse reinforcement learning
want to learn these parameters that produce trajectories that come close to the trajectories you've observed in the real world so it see if you pick a bunch
of trajectories that represent certain type of behavior you want to model the tunia parameters to behave like it then
you want to generate reasonable trajectories continuous in all feasible that satisfy this right and this is part
of this optimization you can solve this actually and so then you can tune this agents so here's some agents I want to
show you so this is a complex interactive scenario to be a course but you can see on the left is on the right
is the aggressive guy blue is the agent red is our vehicle we're testing in simulation and so let me play one more
time once the sense essentially on the on the left is the conservative driver on the right is the aggressive driver
and they pass us and then use very
different reactions in our vehicle so the aggressive guy went in pastas and pushed us further into that Lane and we
much much later in the other case when you have a conservative driver we are in front of them and they're not bugging us
and we execute with much cheerier can switch into the right lane where we want to go all right so this is agents that
can test your system well now you have different scenarios in this case
depending what agent you put in and I'll show you a little more scenarios so it's
not just a - agent game I mean we can do things like merging from one side of the
highway to the next and this type of agent can generate fairly reasonable
behaviors it slow slowed down for knowing slow vehicle in front let the vehicles on this side pass you and still completes the mission and you can
generate multiple futures with this agent so here's an example again on the
right will be an aggressive guy right and on the left was the more
conservative person the aggressive guy I found a gap between the two vehicles and just went for it right and you can test
your stock this way and one more I wanted to show you is is an aggressive motorcycle driving so you can have an
agent that tests you can test the reaction to motorcycle that they're weaving in the lane right
so I guess what's my takeaway from this story about testing in the longtail you
need the Ministry of agents at the moment right so if you think of it right
and learning from demonstration is key you can encode some simple models by hand but ultimately it's much better the
task of modeling agent behavior is complex and it's much better learned and so here's the space the models so you
can have not learned you can just replay the log like a show then you can you can have design trajectories for agents -
for this reaction do this for that reaction do that then you can have the break and swirl model that mostly
there's someone in front of an agent just does it deterministic break trajectory optimization which I just
showed now our mid to mid model and potentially and to end top-down model top-down meaning you have like a top
view of the environment there's many other representations possible this is a very interesting space ultimately I
wanted to show you there's many possible agents and they have different utility and they have different number of
examples you need to train them with and so one other takeaway I wanted to tell you is smart agents are critical photon
and it's scale this is something I truly believe working in the space and this
line of direction is exciting and ultimately one of the exciting problems that there's still a lot of interesting
progress to be made and why well you have accurate models of human behavior
of drivers and pedestrians and they help achieve several things first you will do better decisions when you drive yourself
you'll be able to anticipate what others will do better and that will be helpful second you can develop a robust
simulation environment with those insights also very important third well our vehicle is also one more
agent in the environment it's an agent we have more control than the others but a lot of this inside supply and so this
is very exciting and interesting so I wanted to finish the talk just maybe as
Scaling to dozens and hundreds of cities
a mental exercise right when you think of a system that is tackling a complex
AI challenge like self-driving what is the good properties of the system to have and how do you think
a scalable system and to me there's this mental test right we want to grow and
handle and you know bring our service to more and more environments more and more cities how do you scale to dozens or
hundreds of cities so as we talked about the longtail each new environment can
bring new challenges and they can be complex intersections and cities like Paris
there's our Lombard Street in San Francisco and from there there's narrow streets in European towns there's all
kinds as the long tails keep keeps coming as you keep driving your environments in Pittsburgh people drive
the famous Pittsburgh left they take different precedence than usual the
local customs of driving of behaving all of this needs to be accounted for as you expand and this makes the system
potentially more complex or easier harder to turn to all environments right but it's important because ultimately
that's the only way you can scale so how do you what should the scalable process do so in my mind you let's say have a
very good sobriety system I mean this very much parallels the factory analogy
I'm just going to repeat it one more time you take your vehicles we put a bunch of women cars and we drive a long
time in that environment with drivers maybe 30 days maybe more at least that long
and you collect all the data right and then your system should be able to
improve a lot on the data have collected right so drive a bunch obviously don't
wanna don't want to chain the system too much in the real world while it's driving but you want train it active
you've collected in data about the environment so it needs to be trainable and collected data it's very important
for a system to be able to quantify or have a notion to elicit from it whether
it's incorrect or not confident right because then you can take action and
this is the important property that I think people should think of when they design systems how they listed this then
you can take an action you can ask questions to raters that's fairly legit typical active learning is a bit like
this right so and it's usually based in some amount of low confidence or surprise
that's the examples you want to to send and even better
the system could potentially directly update itself and this is an interesting question how those systems update
themselves in light of new knowledge and we have a system that clearly does this right and typically do it with reasoning
and what is reasoning right so I have an
answer it is one answer there's possibly others right but one way is you can
check and enforce consistency of view beliefs and you can look for explanations of the world that are consistent and see if you have a
mechanism in the system that can do this this allows the system to improve itself without necessarily being fed purely
labeled data it can improve yourself from just collected data and I think it's interesting to think of systems
where you can do reasoning and representations that these models need to have right and last but not least we
need scalable training and testing infrastructure right this is part of the factory I was talking about I'm very
lucky to a mode to have wonderful infrastructure and you know it allows this virtuous
cycle to happen thank you appearance trouble thank you
Q&A
so much for the talk really appreciate it so if you were to train off of image and lidar data a synthetic imaging lidar
data is there would you wait the synthetic data differently than real
word real-world data when training your models so there's actually a lot of interesting research in the field there
are people trained on simulator but also trained adaptation models that make
simulator data look like real data right so you're essentially you're trying to
build consistency or it leads to training on simulator scenarios but if you learn a mapping from simulator
scenes to real scenes right you could potentially train on the transformed simulator data already that's
transforming with other models there's many ways to do this ultimately right so achieving realism in simulator is an
open research problem right I assume no there is a lot of rules that you have to
put into a system to mate to be able to trust it you know and so how you find
the balance between this automatic models that you don't get work when you're not quite sure what does I would
do and rules were your shows it was but it's not scalable I mean through lots
and lots of testing and analysis right so you keep you keep keeping track of
the performance of your models and you see where they come short right and then those are the areas you most need expert
computing to compliment right but the balance can change over time right and it's a natural process of evolution
right so evolving your system as you go I mean generally you know the MLP growls
is the capabilities in the data sets girl right so you stressed at the end of
both the first half and the second half of your talk the importance of quantifying uncertainty and the
predictions that your models are making so have you developed techniques for doing
that with neural nets or are you using some probabilistic graphical models or something so a lot of the models and
neural nets there's many ways to capture this actually I'm just going to give a
general answer and not commenting on specifically what way I'll be doing I think first of all there's techniques in
neural nets that can predict whether they can predict their own uncertainty fairly well right either directly
regress its uncertainty for certain products or using samples of networks or dropout or techniques like this that
also provide the measure of uncertainty another way of doing uncertainty is to
leverage constraints in the environment so if you have temporal sequences right
you don't want for example objects to appear or disappear or generally
unreasonable changes and in the environment or inconsistent prediction in your models a good areas to look I'm
just wondering do you guys train and deploy different models depending on where the car is driving like what city
or do you train and deploy a single model that adapts to most scenarios well
ideally you would have a lot of the adapts to most scenarios then you know a complement is needed yeah so first off
thanks for your talk I find the simulator work really really exciting and I was wondering if you could either
talk about talk more about or maybe provide some insights into simulating
pedestrians because as a pedestrian myself I feel like my behaviors a lot less constrained than a vehicle right
and I imagine you I mean there's an advantage in that you're sensing from a vehicle and you kind of know your
sensors are like the first person from a vehicle but not from a pedestrian and that's correct I mean so if you want to
simulate pedestrians far away in an environment right and you want to simulate them as very high-resolution
writing you've collected log data you may not have the detailed data on that pedestrian right at the same time the
subtle cues for that pedestrian matter less at that distance as well because it's not like you observed them or
reacted to them in the first place so there is an interesting question at what fidelity need to simulate things right and there
is levels of realism in simulation that at some level need to parallel what your
models are paying attention thank you for the talk it was very interesting since you you know titled and talked
about it long tail it makes me wonder is the bulk of the problem solved
do you think well we're gonna have this figured out and within the next couple
of years there can be self-driving cars everywhere or do you think it's closer to you know actually there could be
decades before we've really worked out everything necessary what are your
thoughts about the future it's a bit hard to that's a good question it's a bit hard to give this prognosis I think
I mean I'm not completely sure I think one thing I would say is it will take a
while for self-driving cars to roll out at scale right so this is not a
technology that just determine a crank and appears everywhere right there's logistics and algorithms and all this
tuning and testing needed to make sure it's really safe in the various environments so it will take some time
when you were talking about prediction you mentioned looking at a context and saying if a person or if someone is
looking at us we can assume that they will behave differently than if they're not paying attention to what we're doing potentially is that's something you're
actively doing do you take into consideration as pedestrians or other participants in traffic are paying
attention to your vehicles so I can't comment on our model designs too much
but I think this is generally cues one needs to pay attention to they're very significant I mean you know even when
people drive for example there's someone sitting in the vehicle next to you waving keep going right in these natural
interactions in the environment that you know is something you need to think
about in one of you first of all thank you it's really cool talk in one of your
last slides you talked about resolving certain uncertainties by the means of
establishing a set of beliefs and checking to see if they were consist ready that's my own theory by the way
right but I feel that the concept of reasoning is under explored in deep
learning and what it means right so if you read for sky Kahneman type 1 type 2
reasoning we're really good at the instinctive mapping type of tasks right
so likely some law to meet to maybe high
level perception of the point but the reasoning part with neural networks right and generally with models that's a
bit less explored I think it's long term it's fruitful that's my personal opinion
right I guess the question is going to ask is if you could elaborate on that
concept in connection with the models you guys are working with I guess that's so they'll to give an example from
current work right and there's a lot of work on weekly supervised learning sure
and that's kind of been a big topic in 2018 and there were a lot of really strong papers including by Google brain
and nearly angular and crew team and so on and essentially if you used to read
the books about 3d reconstruction in geometry and so on alright there's a
bunch of rules you can encode geometric expectations about the world so when you have video and when you have 3d outputs
in your models there is certain amount of consistency one example is ego motion versus depth estimation there is a very
strong constraint that if you predict the depth and you predict the gue motion correctly then you can reproject certain
things and they will look good right and that's a very strong constraint that's a consistency and notice about the
environment the expected this can help train your model right and so more of this type of reasoning may be
interesting you mentioned expert design algorithms and I was wondering from your
perspective almost from Wayne was perspective how important are those say
non machine learning type algorithms or non machine learning type approaches to tackling the challenges of autonomous
driving could you could you say how important is which aspect of them of expert design algorithms every now and
then you just you sprinkle it in like here we can try expert design algorithms because we actually understand some
parts of the problem and I was wondering like what is really important like for the challenges in autonomous driving
outside of the field of machine learning I mean generally you want the problem is
you want to be safe in the environment that makes that makes it such that you don't want to make errors in perception
prediction and planning right and the state of machine learning is not at the
point where it never makes errors provided the scope that we're currently
addressing and so throughout your start with the current state of machine learning it needs to be complemented
right and so we've carefully done it and I think machine learning as it improves
I think they'll be less and less need to do it it's somewhat effort intensive
bringing especially in an evolving system to do that to have a hybrid system but right now I think this is the
main thing that keeps you able to do complex behaviors in some cases for
which is very hard to collect data and you still need to handle then it's then it's the right thing to do
right so the way I view a time machine learning personal like I like to doing better and better that's it we're not
religious it should not be we just need to solve the problem and right now the right mix is a hybrid system is my
belief we're really excited to see what Wei MO has in store for us in 19 so
please give drugged-up again [Applause] you
[Applause]
you

----------

-----

--59--

-----
Date: 2019.02.07
Link: [# Kyle Vogt: Cruise Automation | Lex Fridman Podcast #14](https://www.youtube.com/watch?v=YUYagvESisE)
Transcription:

the following is a conversation with convoked he is the president and the CTO of Cruz Automation leading an effort to
solve one of the biggest robotics challenges of our time vehicle automation he's a co-founder of two
successful companies twitch and crews that have each sold for a billion dollars and he's a great example of the
innovative spirit that flourishes in Silicon Valley and now is facing an
interesting and exciting challenge of matching that spirit with the mass
production and the safety centric culture of a major automaker like General Motors this conversation is part
of the MIT artificial general intelligence series and the artificial intelligence podcast if you enjoy it
please subscribe on youtube itunes or simply connect with me on twitter at Lex
Friedman spelled Fri D and now here's my conversation with Kyle vote
grew up in Kansas right yeah and I just saw that picture you had you know there's them a little bit a little bit worried about that yeah so in high
High School Robotics
school in Kansas City you joined Shawnee Mission North High School Robotics team
yeah now that wasn't your high school that's right that was that was the only high school in the area that had a like
a teacher who was willing to sponsor a FIRST Robotics team I was gonna troll you a little bit jog your mess
trying to look super cool and intense because you know this was BattleBots it's a serious business so we're standing there with a welded
steel frame and looking tough so go back there what is that jury to robotics well
I think I've been trying to figure this out for a while but I've always liked building things with Legos and when I was really really young I wanted the
Legos I had motors and other things and then you know Lego Mindstorms came out and for the first time you could program
Lego contraptions and I think things just sort of snowballed from that but I
remember seeing you know the battle bots TV show on Comedy Central and thinking
that is the coolest thing in the world I want to be a part of that and not knowing a whole lot about how to build
these 200-pound fighting robots so I sort of obsessively pored over the
internet forums where all the creator's for battle bots would sort of hang out and talk about you know document their
build progress and everything and I think I read I must have read like you
know tens of thousands of forum posts from from basically everything that was out there on what these people were
doing and eventually like sort of triangulated how to how to put some of these things together and and ended up
doing battle bots which was you know I was like 13 or 14 which is pretty awesome I'm not sure if the show is still running but the battle bots is
Battle Bots
there's not an artificial intelligence component it's remotely controlled and yeah it's an almost like a mechanical
generic challenge yeah I think things that can be broken they're radio-controlled so and I think that
they allowed some limited form of autonomy but you know in a two-minute match you're in and the way these things
ran you're really doing yourself a disservice by trying to automate it versus just you know do the practical thing which is drive it yourself
the entertainment aspect just going on YouTube there's like and some of them wield an axe some of them I mean there's
that fun so what drew you to that aspect it wasn't the mechanical engineering was it the dream to create like Frankenstein
and sentient being I was just like the Lego you like tinkering with stuff I mean that that was just building
something I think the the idea of you know this this radio-controlled machine that that can do various things if it
has like a weapon or something was pretty interesting I agree it doesn't have the same appeal as you know
autonomous robots which I which I you know sort of gravitated towards later on but it was definitely an engineering challenge because everything you did in
in that competition was pushing components to their limits so we would
buy like these $40 DC motors that came out of a winch like on the front of a
pickup truck or something and we'd power the car with those and we'd run them at like double or triple their rated
voltage so they immediately start overheating but for that 2-minute match you can get you know a significant
increase in the power output of those motors before they burn out and so you're doing the same thing for your battery packs all the materials in the
system and I think there was something something intrinsically interesting about just seeing like where things
break and did you all fly and see where they break did you take it to the
Wedges
testing point like how did you know two minutes or was there a reckless let's just go with it and see we weren't very
good at BattleBots we lost all of our matches that woody first round like the one I built first both of them were
these wedge-shaped robots because a wedge even though it's sort of boring to look at is extremely effective you drive towards another robot and the front edge
of it gets under him and then they sort of flip over kind of like a door stopper and the first one had a pneumatic
polished stainless steel spike on the front that would shoot out about eight inches the purpose of which is what
pretty pretty ineffective actually but it looks cool and was it helpful to lift no it was it was just to try to poke
holes in the other robot and then the second time I did it which is the following I think maybe 18 months later
we had well a titanium axe with a with a hardened steel tip on it that was
powered by a hydraulic cylinder which we were activating with liquid co2 which was had
Software
its own set of problems so great so that's kind of on the hardware side I mean at a certain point there must have
been born a fascination on the software side so what was the first piece of coal
you've written go back there see what language was it what what was that was a
Emacs vim was it a more respectable modern ID do you remember any of this
yeah well I remember I think maybe when I was in third or fourth grade school I
was at elementary school had a bunch of Apple 2 computers and we'd play games on those and I remember every once in a
while something mood would would crash it wouldn't start up correctly and it would dump you out to what I later
learned was like sort of a command prompt and my teacher would come over and type actually remember this to this
day for some reason like PR number six or PR pound six which is peripheral 6 which is the disk drive which would fire
up the disk and load the program and I just remember thinking wow she's like a hacker like teach me these these codes
these error codes what I called him at the time but she had no interest in that so it wasn't until I think about fifth
grade that I had a school where you could actually go on these Apple twos and learn to program and so it's all in
basic you know where every line you know the line numbers are all number that every line is numbered and you have to
like leave enough space between the numbers so that if you want to tweak your code you go back and the first line
was 10 and the second line is 20 now you have to go back and insert and 15 and if you need to add code in front of that
you know 11 or 12 and you hope you don't run out of line numbers and have to redo the whole thing there's go-to statements yeah go to and
it's very basic maybe it's a name but a lot of fun and that was like that was
you know it's fun that's when you know when your first program you see the magic of it it's like it just just like this world opens up with you know
endless possibilities for the things you could build or or accomplish with that computer so you got the bug then so even
Programming
starting with basic and then what C++ throughout what did you it was a computer program in computer science
classes in high school not not where I went so it was a self-taught but I did a lot of programming the thing that
you know sort of pushed me in the path of eventually working on self-driving cars is actually one of these really
long trips driving from my house in Kansas to I think Las Vegas where we did
the Battle Watts competition and I had just gotten my I think my learner's permit or early driver's permit and so I
was driving this you know 10 hour stretch across western Kansas where it's just you're going straight on a highway
and it is mind-numbing ly boring and I remember thinking even then with my sort of mediocre programming background that
this is something that a computer can do right let's take a picture of the road let's find the yellow lane markers and you know steer the wheel and you know
later I've come to realize this had been done you know since since the 80s or the 70s or even earlier but I still wanted to do
it and sort of immediately after that trip switched from sort of BattleBots which is more radio-controlled machines to thinking about building you
know autonomous vehicles of some scale start off with really small electric ones and then you know progress to what
Artificial Intelligence
we're doing now so what was your view of artificial intelligence at that point what did you think so this is uh before
there's been ways in artificial intelligence right the the current wave with deep learning makes people believe
that you can solve in a really rich deep way the computer vision perception problem but like in before the deep
learning craze you know how do you think about how would you even go about building a thing that perceives itself
in the world local as itself in the world moves around the world like when you were younger and yeah as what was your thinking about it well prior to
deep neural networks our convolutional neural as these modern techniques we have or at least ones that are in use
today it was all heuristic space and so like old-school image processing and I think extracting you know yellow lane
markers out of an image of a road is one of the problems that lends itself
reasonably well to those heuristic based methods you know like just do a threshold on the color yellow and then
try to fit some lines to that using a Hough transform or something and then go from there
traffic like detection and then stop signs detection red yellow green and I think you can you could I mean if you
wanted to do a full I was just trying to make thing that would stay in between the lanes on a highway but if you wanted to
do the full the full you know set of capabilities needed for a driverless car
I think you could and we done this at cruise you know in the very first days you can start off with a really simple
you know human written heuristic just to get the scaffolding in place for your system traffic light detection probably
a really simple you know color threshold injustice system up and running before you migrate to you know a deep learning
based technique or something else and you know back in when I was doing this my first one it was on Pentium 203 233
megahertz computer in it and I I think I wrote the first version in basic which is like an interpreted language it's
extremely slow because that's the thing I knew at the time and so there was no no chance at all of using there was no
computational power to do any sort of reasonable deep nets like you have today
so I don't know what kids these days are doing our kids these days you know at age 13 using neural networks in their
garage I mean I also I get emails all the time from you know like 11 12 year
Deep Learning
old saying I'm having you know I'm trying to follow this tensorflow tutorial and I'm having this problem
and their general approach in the deep learning community is of extreme
optimism of as opposed to you mentioned like heuristics you can you can separate
the autonomous driving problem into modules and try to solve it sort of rigorously or you just do it end to end and most people just kind of love the
idea that you know us humans do a tenth and we just perceive and act we should be able to use that do the same kind of
thing when you're on that's and that that kind of thinking you don't want to criticize that kind of thinking because
eventually they will be right yeah and so it's exciting and especially when they're younger to explore that is a
really exciting approach but yeah it's it's changed the the language the kind
of stuff you turned green with it it's kind of exciting to see when they seniors grow up yeah I can only imagine
if you if your starting point is you know Python and tensorflow at age 13 where you end up you know after 10 or 15
years of that that's that's pretty cool because of github because this they're tools for solving most of the
Entrepreneurship
major problems and artificial intelligence are within a few lines of code for most kids and that's incredible
to think about also on the entrepreneurial side and and and at that point was there any thought about
entrepreneurship before you came to college is sort of doing your building
this into a thing that impacts the world on the large scale yeah I've always wanted to start a company I think that's
you know just a cool concept of creating something and exchanging it for value or
creating value I guess so in high school I was I was so trying to build like you
know a servo motor drivers little circuit boards and sell them online or other other things like that and
certainly knew at some point I wanted to do a startup but it wasn't really I'd say until college until I felt like I
had the I guess the right combination of the environment the smart people around you
and some free time and a lot of free time at MIT so you came to MIT as an
DARPA Grand Challenge
undergrad 2004 that's right and that's when the first DARPA Grand Challenge was
happening yeah the the timing of that is beautifully poetic so how did you get yourself involved in that one originally
there wasn't a official entry yeah faculty sponsored thing and so a bunch of undergrads myself included I started
meeting and got together and tried to haggle together some sponsorships we got a vehicle donated a bunch of sensors and
tried to put something together and so we had our team was probably mostly freshmen and sophomores you know which
was not really a fair fair fight against maybe the you know postdoc and
faculty-led teams from other schools but we we got something up and running we had our vehicle drive by a wire and you
know very very basic control and things but on the day of the qualifying for pre
qualifying round the one and only steering motor that we had purchased the
thing that we had you know retrofitted to turn the steering wheel on the truck died and so our vehicle was just dead in
the water couldn't steer so we didn't make it very far on the hardware side so was there a software component was there
AI in Autonomous Vehicles
like how did your view of autonomous vehicles in terms of artificial intelligence evolve in this moment I
mean you know like you said from the 80s has been autonomous vehicles but really that was the birth of the modern wave
the the thing that captivated everyone's imagination that we can actually do this so what how were you captivated in that
way so how did your view of autonomous vehicles change at that point I'd say at that point in time it was it was a
the curiosity as in like is this really possible and I think that was generally
the spirit and the the purpose of that original DARPA Grand Challenge which was
to just get a whole bunch of really brilliant people exploring the space and
pushing the limits and and I think like to this day that DARPA challenge with its you know million dollar prize pool
was probably one of the most effective you know uses of taxpayer money dollar
for dollar that I've seen you know because that that small sort of
initiative that DARPA put put out sort of in my view was the catalyst or the
tipping point for this this whole next wave of autonomous vehicle development so that was pretty cool so let me jump
DARPA Challenges
around a little bit on that point they also did the urban challenge where I was in the city but it was very artificial
and there's no pedestrians and there's very little human involvement except a few professional drivers yeah do you
think there's room and then there was the Robotics Challenge with humanoid robots right so in your now role is
looking at this you're trying to solve one of the you know autonomous driving one of the harder more difficult places
of San Francisco is there a role for DARPA to step in to also kind of help out they challenge with new ideas
specifically a pedestrians and so on all these kinds of interesting things well I haven't I haven't thought about it from
that perspective is there anything DARPA could do today to further accelerate things and I would say my instinct is
that that's maybe not the highest and best use of their resources in time because like kick starting and spinning
up the flywheel is I think what what they did in this case for a very very little money but today this has become
this has become like commercially interesting to very large companies and the amount of money going into it and
the amount of people like going through your class and learning about these things and developing these skills is
just you know orders of magnitude more than it was back then and so there's enough momentum and inertia and energy
and investment dollars into this space right now that I don't I don't I think they're I think they're they can just
say mission accomplished and move on to the next area of technology that that needs help so then stepping back to MIT you left on
Leaving MIT
my teaching a junior year what was that decision like as I said I always wanted to do a company in or start a company
and this opportunity landed in my lap which was a couple guys from Yale we're
starting a new company and I googled them and found that they had started a company previously and sold it actually
on eBay for about a quarter million bucks which was a pretty interesting story but so I thought to myself these
guys are you know rock star entrepreneurs they've done this before they must be driving around in Ferraris
because they sold their company and you know I thought I could learn a lot from
them so I teamed up with those guys and you know went out during went out to
California during IIP which is my tease month off on one on one way ticket and
basically never went back we were having so much fun we felt like we were building something and creating something and it was going to be
interesting that you know I was just all in and got completely hooked and that that business was justin.tv which is
originally a reality show about a guy named Justin which morphed into a live video
streaming platform which then morphed into what is twitch today so that was
that was quite a an unexpected journey so no regrets no looking back it was
No regrets
just an obvious I mean one-way ticket I mean if we just pause on that for a second there was no how did you know these were
the right guys this is the right decision you didn't think it was just follow the heart kind of thing well I
didn't know but you know just trying something for a month during IEP he seems pretty little risk right right and
then you know well maybe I'll take a semester off and my teas pretty flexible about that you can always go back right
and then after two or three cycles of that I eventually threw in the towel but you know I think it's
I guess in that case I felt like I could always hit the undo button if I had to right but it never lasts from from when
Brave decision
you look in retrospect I mean it seems like a brave decision that you know it's difficult it would be difficult for a
lot of people to make it wasn't as popular I'd say that the general you know flux of people out of MIT at the
time was mostly into you know financier consulting jobs in Boston or New York and very few people were going to
California to start companies but today I'd say that's it's probably inverted which is just a sign of a sign of the
times I guess yeah so there's a story about midnight of March 18 2007 where whether we're
Failure
TechCrunch I guess and I was just in TV earlier than was supposed to a few hours
the site didn't work I don't know if any of this is true you can tell me and I you and one of the folks adjusted to e
I'm a shear coated through the night can you take me through that experience so
let me let me say a few nice things that the article I read quoted Justin Kahn
said that you were known for mural coding through problems and being a creative quote creative genius so on
that night what was going through your head or maybe I put another way how do
you solve these problems what's your approach to solving these kinds of problems were the line between success
and failure seems to be pretty thin that's a good question well first of all that's that's a nice of Justin to say
that I think you know I would have been maybe twenty-one years old then and not very experienced at programming but as
with with everything in a start-up you're sort of racing against the clock
and so our plan was the second we had this live streaming camera backpack up
and running where Justin could wear it and no matter where he went in a city it would be streaming live video and this is even before the iPhones this is like
hard to do back then we would launch and so we thought we were there and and the
backpack was working and then we sent out all the emails to launch the launch the company and do the press thing and
then you know we weren't quite actually there and then we thought oh well you
know they're not going to announce it until maybe 10 a.m. the next morning and it's I don't know it's 5 p.m. now so how
many hours do we have left what is that like you have 17 hours to go and and and
that was that was gonna be fine was the problem obvious did you understand what could possibly like how complicated was
the system at that point it was it was pretty messy so to get a live video feed
that looked decent working from anywhere in San Francisco I put together the
system where we had like three or four cell phone data modems and they were like we take the video stream and you
know sort of spray it across these three or four modems and then try to catch all the packets on the other side you know
with unreliable cell phone networks pretty low level networking yeah and and putting his like you know sort of
protocols on top of all that to reassemble and reorder the packets and have time buffers and error correction
and all that kind of stuff and the night before it was just staticky every once
in while the image would would go staticky and there would be this horrible like screeching audio noise
because the audio was also corrupted and this would happen like every five to ten minutes or so and it was a really you
know off-putting to the viewers how do you tackle that problem what was the just freaking out behind a computer
there's the word are there other other folks working on this problem like we behind a whiteboard were you doing uh
yes a little hair coding it has a little only because there's four of us working
on the company and only two people really wrote code and Emmett wrote the website in the chat system and I wrote
the software for this video streaming device and video server and so I you
know it's my sole responsibility to figure that out yeah and I think I think it's those you know setting setting
deadlines trying to move quickly and everything where you're in that moment of intense pressure that sometimes people do their best and most
interesting work and so even though that was a terrible moment I look back on it fondly because that's like you know that's one of those character defining
moments I think so in 2013 October you founded cruise
Cruise Automation
automation yeah so progressing forward another exception successful company was
acquired by GM in 16 for 1 billion dollars but in October 2013 what was on
your mind what was the plan how does one seriously start to tackle one of the
hardest robotics most important impact for robotics problems of our age after going through
twitch twitch was was and it is today pretty successful but the the work was
the result was entertainment mostly like the the better the product was the more we would entertain people and then you
know make money on them ad revenues and other things and that was that was a good thing it felt felt good to entertain people but I figured like you
know what is really the point of becoming a really good engineer and developing these skills other than you
know my own enjoyment and I realized I wanted something that scratched more of an existential itch like something that that truly matters and so I basically
made this list of requirements for a new if I was going to do another company and
the one thing I knew in the back of my head that twitch took like eight years to become successful and so whatever I
do I better be willing to commit you know at least ten years to something and when you think about things from that
perspective you certainly I think raised the bar on weight you choose to work on so for me
the three things where it had to be something where the technology itself determines the success of the product
like hard really juicy technology problems because that's what motivates me and then it had to have a direct and
positive impact on society in some way so an example would be like you know healthcare self-driving cars because
they save lives other things where there's a clear connection to somehow improving other people's lives and the last one is it had to be a big business
because for the positive impact to matter it's got to be a large scale scale yeah and I was thinking about that
for a while and I made like I tried writing a gmail clone and looked at some other ideas and then it just sort of
light bulb went off like self-driving cars like that was the most fun I had ever had in college working on that and
like well what's the state of the technology has been ten years maybe maybe times have changed and maybe now
is the time to make this work and I poked around and looked at the only other thing out there really at the time
was the Google self-driving car project and I thought surely there's a way to you know have an entrepreneur mindset
and sort of solve the Minimum Viable Product here and so I just took the plunge right then in there and said this this is something I know I can commit
ten years to it's the probably the greatest applied AI problem of our generation it's right and if it works
it's going to be both a huge business and therefore like probably the most positive impact I can possibly have on
the world so after that light bulb went off I went all in on crews immediately
and got to work did you have an idea how to solve this problem which aspect of the problem to solve you know slow like
How to solve the problem
what we just had Oliver for voyage here slow-moving retirement communities urban driving highway driving did you have
like did you have a vision of the city of the future or you know the
transportation is largely automated that kind of thing or was it sort of more
fuzzy and gray area than that my analysis of the situation is that Google
is putting a lot it had been putting a lot of money into that project that a lot more resources and so
and they still hadn't cracked the fully driverless car you know this is 20 2013
I guess so I thought what what can I do to sort of go from zero to you know
significant scale so I can actually solve the real problem which is the driverless cars and I thought here's the
strategy we'll start by doing a really simple problem or solving a really simple problem that creates value for
people so eventually ended up deciding on automating highway driving which is relatively more straightforward as long
as there's a backup driver there and I'll you know the go-to-market will be able retrofit people's cars and just
sell these products directly and the idea was we'll take all the revenue and profits from that and use it to do the
social reinvest that in research for doing fully fabulous cars and that was
the plan the only thing that really changed along the way between then and now is we never really launched the first product we had
enough interest from investors in enough of a signal that this was something that we should be working on that after about
a year of working on the highway autopilot we had it working you know on a prototype stage but we just completely
abandoned that and said we're gonna go all in on driverless cars now is the time can't think of anything that's more
exciting and if it works more impactful so we're just gonna go for it the idea of retrofit is kind of interesting yeah
Retrofit
being able to it's how you achieve scale it's a really interesting idea is it's something that's still in the in the
back of your mind as a possibility not at all I've come full circle on that one
trying to build a retrofit product and I'll touch on some of the complexities of that and then also having been inside
in OEM and seeing how things work and how a vehicle is developed and validated when it comes to something that has
safety critical implications like controlling the steering and the other control inputs on your car it's pretty
hard to get there with with a retrofit or if you did even if you did it it
creates a whole bunch of new complications around liability or how did you truly validate that or you know
something in the base vehicle fails and causes your system to fail whose fault is it
or if the cars anti-lock brake systems or other things kick in or the software has been it's different in one version
of the car you retrofit versus another and you don't know because the manufacturer has updated it behind the scenes there's basically an infinite
list of longtail issues that can get you and if you're dealing with a safety critical product that's not really acceptable that's a really convincing
summary of why it's really challenging but I didn't at the time so we tried it anyway but it's a pitch also at the time
it's a really strong one yes that's how you achieve scale and that's how you beat the current the the leader at the
time of Google or the only one in the market the other big problem we ran into which is perhaps the biggest problem
from a business model perspective is we had kind of assumed that we'd we started
with an Audi s4 as the vehicle we retrofitted with his highway driving capability and we had kind of assumed
that if we just knock out like three make and models of vehicle that'll cover like eighty percent of a San Francisco
market doesn't everyone there drive I don't know a BMW or a Honda Civic or one of these three cars and then we surveyed
our users we found out that it's all over the place we would to get even a decent number of units sold we'd have to
support like you know 20 or 50 different models and each one is a little butterfly that takes time and effort to
maintain you know that retrofit integration and custom hardware and all this so is it there's a tough business
so GM manufactures and sells over nine million cars a year and what you with
Detroit vs Silicon Valley
crews are trying to do some of the most cutting-edge innovation in terms of
applying AI and so hot out of those you've talked about a little bit before but it's also just fascinating to me
we'll work a lot of automakers you know the difference between the gap between Detroit and Silicon Valley
let's say just to be sort of poetic about it I guess what how do you close that gap how do you take GM into the
future where a large part of the fleet would be autonomous perhaps I want to start by acknowledging that that GM is
made up of you know tens of thousands of really brilliant motivated people who want to be a part of the future and so
it's pretty fun to work within the attitude inside a car company like that is you know embracing this this
transformation and change rather than fearing it and I think that's a testament to the leadership at GM and that's flown all
the way through to to everyone you talk to even the people in this in blue plants working on these cars so that's
really great so that starting from that position makes a lot easier so then when
the the people in San Francisco at Cruz interact with the people at GM at least we have this common set of values which
is that we really want this stuff to work because we think it's important and we think it's the future
not to say you know those two cultures don't clash they absolutely do there's different different sort of value
systems like in a car company the thing that gets you promoted and so the reward system is following the processes
delivering the the program on-time and on-budget so any sort of risk-taking is
discouraged in many ways because if a program is late or if you shut down the
plant for a day it's you know you can count the millions of dollars that burn by pretty quickly whereas I think you
know most Silicon Valley companies and crews in the methodology we were
employing especially around the time of the acquisition the reward structure is about trying to solve these complex
problems in any way shape or form or coming up with crazy ideas that you know 90% of them won't work and and so so
meshing that culture of sort of continuous improvement and experimentation with one where everything needs to be you know
rigorously defined upfront so that you never slip a deadline or miss a budget was a pretty big challenge and that
we're over three years in now after the acquisition and I'd say like you know
the investment we made in figuring out how to work together successfully and who should do what and how we bridge the
gaps between these very different systems and way of doing engineering work is now one of our greatest assets because I think we have this really
powerful thing but for a while it was both both GM and crews were very steep on the learning curve yes I'm sure it
The culture gap
was very stressful it's really important work because that's that's how to revolutionize the transportation it
really to revolutionize any system you know you look at the healthcare system or you look at the legal system I have
people like lawyers come up to me all the time like everything they're working on can easily be automated but then
that's not a good feeling yeah that was it's not a good feeling but also there's no way to automate because the the the
entire infrastructure is really you know based is older and it moves very slowly
and so how do you close the gap between I haven't how can I replace of course
lawyers don't wanna be replaced with an app but you could replace a lot of aspect when most of the data is still on
paper and so the same thing was with automotive I mean it's fundamentally
software so it's is basically hiring software engineers it's thinking a software world I mean I'm pretty sure
nobody in Silicon Valley's ever hit a deadline so and then it's probably true
yeah and GSI is probably the opposite yeah so that's that culture gap is really fascinating so you're optimistic
about the future of that yeah I mean from what I've seen it's impressive and I think like especially in Silicon
Valley it's easy to write off building cars because you know people have been doing that for over a hundred years now
in this country and so it seems like that's a solved problem but that doesn't mean it's an easy problem and I think it
would be easy to sort of overlook that and think that you know we're Silicon
Valley engineers we can solve any problem you know building a car it's been done therefore it's you know it's
it's it's not it's not a real engineering challenge but after having seen just the sheer scale and magnitude
and industrialization that occurs inside of an automotive assembly plant that is
a lot of work that I am very glad that we don't have to reinvent to make self-driving cars work and so to have
you know partners who have done that for a hundred years now these great processes and this huge infrastructure and supply base that we can tap into is
just remarkable because the scope in surface area of the problem of deploying
fleets of self-driving cars is so large that we're constantly looking for ways to do less so we can focus on the things
that really matter more and if we had to figure out how to build an assemble in
you know test and build the cars themselves I mean we work closely with Jim on that but if we had to develop all
that capability in-house as well you know that that would just make make the
problem really intractable I think mmm so yeah just like your first entry mit
The biggest opportunity to make money
DARPA challenge when there was what the motor that failed and somebody that knows what they're doing with the motor did it that would have been nice if you
focus on the software and not the hardware platform yeah right so from your perspective now you know there's so
many ways that autonomous vehicles can impact Society in the next year five years ten years what do you think is the
biggest opportunity to make money in autonomous driving sort of make it a
financially viable thing in the near-term what do you think would be the biggest impact there well the things
that that drive the economics for fleets of self-driving cars or they're sort of a handful of variables one is you know
the cost to build the vehicle itself so the material cost how many you know what's the cost of all your sensors plus
the cost of the vehicle and every all the other components on it another one is the lifetime of the vehicle it's very
different if your vehicle drives one hundred thousand miles and then it falls apart versus you know two million
and then you know if you have a fleet it's kind of like an airplane where or
airline where once you produce the vehicle you want it to be in operation
as many hours a day as possible producing revenue and then a you know the other piece of that is how are you
generating revenue I think that's kind what you're asking and I think the obvious things today are you know the ride-sharing business because that's
pretty clear that there's demand for that there's existing markets you can tap into and larger urban areas that
kind of thing yeah yeah and and and I think that there are some real benefits to having cars without drivers compared
to through the status quo for people who use ride share services today you know you get privacy consistency
hopefully significant improve safety all these benefits versus the current product but it's it's a crowded market
and then other opportunities which you've seen a lot of activity in the last really in last six to twelve months is you know delivery whether that's
parcels and packages food or or groceries those are all sort of I think
opportunities that are that are pretty ripe for these you know once you have this core technology which is the fleet
of autonomous vehicles there's all sorts of different business opportunities you can build on top of that but I think the
important thing of course is that there's zero monetization opportunity until you actually have that fleet of
very capable driverless cars that are that are as good or better than humans and that's sort of where the entire
industry is sort of in this holding pattern right now yeah the trend achieved that baseline so but you said sort of rely not reliability consistency
Personality of the car
it's kind of interesting I think I heard you say somewhere I'm not sure if that's what you meant but you know I can
imagine a situation where you would get an autonomous vehicle and you know when
you get into an uber or lyft you don't get to choose the driver in a sense that you don't get to choose the personality of the driving do you think
there's a there's room to define the personality of the car the way drives
you in terms of aggressiveness for example in terms of sort of pushing the
bomb the one of the biggest challenges in Toms driving is the is a trade-off between sort of safety and
and do you think there's any room for the human to take a role in that
decision to accept the liability I guess we III wouldn't it no I'd say within
reasonable bounds as in we're not gonna I think it'd be highly unlikely we did expose any nob that would let you you
know significantly increase safety risk I think that's that's just not something
we'd be willing to do but I think driving style or like you know are you
gonna relax the comfort constraints slightly or things like that all of those things make sense and are plausible I see all those is you know
nice optimizations once again we get the core problem solved and these fleets out there but the other thing we've sort of
observed is that you have this intuition that if you sort of slam your foot on
the gas right after the light turns green and aggressively accelerate you're gonna get there faster but the actual
impact of doing that is pretty small you feel like you're getting there faster but so that so the same would be true
for ABS even if they don't slam there you know the pedal to the floor when the light turns green they're gonna get you
they're within you know if it's a 15-minute trip within 30 seconds of what you would have done otherwise if you were going really aggressively so I
think there's this sort of self-deception that that my aggressive driving style is getting me there faster
well so that's you know some of the things I study some things I'm fascinated by the psychology of that I don't think it matters that it doesn't
Emotional release
get you there faster it's it's the emotional release driving is is a place
being inside or a car somebody said it's like the real world version of being a troll so you have this protection this
mental protection you're able to sort of yell at the world like release your anger whatever is but so there's an element of that that I think autonomous
vehicles would also have to you know have giving an outlet to people but it doesn't have to be through through
through driving or honking or so on there might be other outlets but I think to just sort of even just put that aside
the baseline is really you know that's the focus that's the thing you need to solve and then the fun human things can
be solved after but so from the baseline of just solving autonomous driving and
you're working in San Francisco one of the more difficult cities to operate in what what is what is the any of you currently
the hardest aspect of autonomous driving and negotiated with pedestrians is that
edge cases of perception is it planning is there a mechanical engineering is it
data fleet stuff like what are your thoughts on the challenge the more challenging
aspects there that's a good that's a good question I think before before we go to that though I just wanted I like what you said about the psychology
aspect of this because I think one observation I made is I think I read somewhere that I think it's maybe
Americans on average spend you know over an hour a day on social media like staring at Facebook and so that's just
you know 60 minutes of your life you're not getting back and it's probably not super productive and so that's 3,600
seconds right and that's that's time you know it's a lot of time you're giving up
and if you compare that to people being on the road if another vehicle whether
it's a human driver or autonomous vehicle delays them by even three seconds they're laying in on the horn
you know even though that's that's you know one one thousandth of the time they waste looking at Facebook every day so
there's there's definitely some you know psychology aspects of this I think that are pre interesting road rage in general
and then the question of course is if everyone is in self-driving cars do they even notice these three-second delays
anymore because they're doing other things or reading or working or just talking to each other so it'll be
interesting to see where that goes in a certain aspect people people need to be distracted by something entertaining something useful inside the
car so they don't pay attention to the external world and then and then and it can take whatever psychology and bring
it back to Twitter and then focus on that as opposed to sort of interacting
sort of putting the emotion out there into the world so it's a it's an interesting problem but baseline
autonomy I guess you could say self-driving cars you know at scale will lower the collective blood pressure of
society probably by a couple points yeah without all that road rage and stress so that's a good good externality so back
to your question about the technology in the the I guess the biggest problems and
I have a hard time answering that question because you know we've been at this like specifically focusing on driverless
cars and all the technology needed to enable that for a little over four and a half years now and even a year or two in
I felt like we had completed the functionality needed to
get someone from point A to point B as in if we need to do a left turn maneuver or if we need to drive around a you know
a double parked vehicle into oncoming traffic or navigate through construction zones the the scaffolding and the building
blocks where it was there pretty early on and so the challenge is not any one scenario or situation for which you know
we fail at 100% of those it's more you know we're benchmarking against a pretty
good or pretty high standard which is human driving all things considered humans are excellent at handling the
edge cases and unexpected scenarios whereas computers the opposite and so beating that that baseline set by humans
is the challenge and so what we've been doing for quite some time now is basically
it's this continuous improvement process where we find sort of the the most you know uncomfortable or the things that
that could lead to a safety issue other things all these events and then we sort
of categorize them and rework parts of our system to make incremental improvements and do that over and over
and over again and we just see sort of the overall performance of the system you know actually increasing in a pretty
steady clip but there's no one thing there's actually like thousands of little things and just like polishing
functionality and making sure that it handles you know every version impossible permutation of a situation by
either applying more deep learning systems or just by you know adding more
tests coverage or new scenarios that that we develop against and just grinding on that it's we're sort of in
the the unsexy phase of development right now which is doing the real engineering work that it takes to go
from prototype to production you're basically scaling the the grinding so has sort of taking seriously
that the process of all those edge cases both with human experts and machine
learning methods to cover to cover all those situations yeah and the exciting
thing for me is I don't think that grinding ever stops right because there's a moment in time where you you
cross that threshold of human performance and become superhuman but
there's no reason there's no first principles reason that AV capability will tap out anywhere near humans like
there's no reason it couldn't be 20 times better whether that's you know just better driving or safer driving a
more comfortable driving or even a thousand times better given enough time and we intend to basically chase that
you know forever to build the best possible product better and better and better and always new educators come up
Autonomous Vehicles
and you experiences so and you want to automate that process as much as possible mhm so what do you think in
general in society when do you think we may have hundreds of thousands of fully autonomous vehicles driving around so
first of all predictions nobody knows the future you're a part of the leading people trying to define that future but
even then you still don't know but if you think about a hundreds of thousands of heat
so a significant fraction of vehicles in major cities are autonomous do you think
I would Rodney Brooks who is 2050 and beyond are you more with Elon Musk who
is we should have had that two years ago well I mean I don't want me to have it
two years ago but we're not there yet so I guess the the way I would think about that is let's let's flip that question
around so what would prevent you to reach hundreds of thousands of vehicles and that's a goodness a good rephrasing
yeah so the I'd say the it seems the consensus
among the people developing self-driving cars today is to sort of start with some form
of an easier environment whether it means you know lacking inclement weather or you know mostly sunny or whatever it
is and then add add capability for more complex situations over time and so if
you're only able to deploy in areas that that meet sort of your criteria or that
the current domain you know operating domain of the software you developed that may put a cap on how many cities you could deploy in
but then as those restrictions start to fall away like maybe you add you know capability to drive really well and and
safely in heavy rain or snow you know that that probably opens up the market by - two or three fold in terms of the
cities you can expand into and so on and so the real question is you know I I know today if we wanted to we could
produce that that many autonomous vehicles but we wouldn't be able to make use of all of them yet because we would
sort of saturate the demand in the cities in which we would want to operate initially so if I were to guess like
what the timeline is for those things falling away and reaching hundreds of thousands of vehicles maybe a range is
but I would I would say less than five years that's in five years yeah and of course you're working hard to make that
Building a Successful Startup
happen so you started two companies that were eventually acquired for each for a
billion dollars so you're pretty good person to ask what does it take to build a successful startup mmm-hmm I think
there's there sort of survivor bias here a little bit but I can try to find some common threads for the the things that
worked for me which is you know in in both of these companies
it was really passionate about the core technology I actually like you know lay awake at night thinking about these problems and how to solve them and I
think that's helpful because when you start a business there are like to this day they're they're these crazy ups and
downs like one day you think the business is just on you're just on top of the world and unstoppable and the next day you think okay this is all
gonna and you know it's it's just it's just going south and it's gonna be over tomorrow and and so I think like having
a true passion that you can fall back on and knowing that you would be doing it even if you weren't getting paid for it helps you whether those those tough
times so that's one thing I think the other one is really good people so I've always been
surrounded by really good co-founders that are logical thinkers are always pushing their limits and have very high
levels of integrity so that's Dan Khan in my current company and actually his brother and a couple other guys for
Justin TV and twitch and then I think the last thing is just uh I guess persistence or
perseverance like and and that that can apply to sticking to sort of a or having
conviction around the original premise of your idea and and sticking around to do all the you know the unsexy work to
actually make it come to fruition including dealing with you know whatever
it is that that you're not passionate about whether that's finance or or HR or or operations or those things as long as
you are grinding away in working towards you know that North Star for your business whatever it is and you don't
give up and you're making progress every day it seems like eventually you'll end up in a good place and the only things
that can slow you down are you know running out of money or I suppose your competitors destroying you but I think most of the time it's people giving up
or or somehow destroying things themselves rather than being beaten by their competition or running out of money yeah if you never quit eventually
Y Combinator vs VC Route
you'll arrive so working size version of what I was trying to say yeah so you want the Y
Combinator out twice yeah what do you think in a quick question do you think is the best way to raise funds in the
early days or not just funds but just community develop your idea and so on
can you do it solo or maybe with a co-founder with like self-funded do you
think Y Combinator is good it's good to do VC route is there no right answer was there for the Y Combinator experience
something that you could take away that that was the right path to take there's no one-size-fits-all answer but if your
ambition I think is to you know see how big you can make something or or or
rapidly expand and capture market or solve a problem or whatever it is then
then you know going to venture back route is probably a good approach so that so that capital doesn't become your
primary constraint Y Combinator I love because it puts you in this sort of
competitive environment while you're where you're surrounded by you know the top maybe one percent of other really
highly motivated you know peers who are in the same same place and that that
environment I think just breeds breed success right if you're surrounded by really brilliant hard-working people
you're gonna feel you know sort of compelled or inspired to try to emulate them and/or beat them and so even though
I had done it once before and I felt like yeah I'm pretty self-motivated I thought like I look this is gonna be a
hard problem I can use all the help I can get so surrounding myself with other entrepreneurs is gonna make me work a
little bit harder or push a little harder than it's worth it when Saba white why I did it you know for example
a second time let's let's go philosophical existential if you'd go back and do something differently in
Philosophical existential
your life starting in high school than MIT leaving MIT you could have gone the
PG route doing startup I'm gonna see about a start-up in California and youth
or maybe some aspects of fundraising is there something you'll regret something you need not necessarily grab
but if you go back it could do differently I think I've made a lot of mistakes like you know pretty much
everything you can screw up I think I've screwed up at least once but I you know I don't regret those things I think it's
hard to hard to look back on things even if they didn't go well and call it a regret because hopefully took away some
new knowledge or learning from that so
I would say there was a period yeah the closest I can I can come to us is there's a period in in justin.tv I think
after seven years where that the company was going one direction
which is sorts twitch in video gaming and I'm not a video gamer I don't really even use twitch at all and I was still
working on the core technology there but my heart was no longer in it because the business that we were creating was not
something that I was personally passionate about it didn't meet your bar of existential impact yeah and I'd say
III probably spent an extra year or two working on that and and I'd say like I
would have just tried to do something different sooner because those are those were two years where I felt like
you know from this philosophical or existential thing I I just I just felt something was missing and so I would
have I would have if I could look back now and tell myself it's like I would have said exactly that like you're not getting any meaning out of your work
personally right now you should you should find a way to change that and that's part of the pitch I use to
basically everyone who joins crews today it's like hey you've got that now by coming here well maybe you needed the two years of
What does 2019 hold for Crew
that existential dread to develop the feeling that ultimately was the fire that created crews so you never know you
can be good theory yeah so last question what does 2019 hold for crews after this
I guess we're gonna go and I'll talk to your class but one of the big things is going from prototype to production for
autonomous cars and what does that mean once that look like in 2019 for us is the year that we try to cross over that
threshold and reach you know superhuman level of performance to some degree with the software and have all the other of the thousands of
little building blocks in place to launch you know our first commercial
product so that's that's what's in score for us are in store for us and we've got a lot of work to do we've got a lot of
brilliant people working on it so it's it's all up to us now yeah from Charlie
Miller and Chris fells like the people I have crossed paths with if you know it sounds like you have an amazing team so
I'm like I said it's one of the most I think one of the most important problems in artificial intelligence of the
century you'll be one of the most defining the super exciting that you work on it and the best of luck in 2019
I'm really excited to see what Cruz comes up with thank you thanks for having me today nice call
you

----------

-----

--58--

-----
Date: 2019.02.01
Link: [# Self-Driving Cars: State of the Art (2019)](https://www.youtube.com/watch?v=sRxaMDDMWQQ)
Transcription:


Introduction
- Today I'd like to talk about the state of the art of autonomous vehicles, how I see the landscape, how others see the landscape,
what we're all excited about, ways to solve the problem and what to look forward to in 2019
as we also get to hear from the different perspectives and the various leaders in industry and autonomous vehicles
in the next few, next couple of weeks and next few days. So the problem, the mission, the dream,
the thing that we're trying to solve for many it may be about entrepreneurial possibilities
of making money and so on. But really it's about improving access to mobility,
moving people around in the world that don't have that ability, whether it has to do with age
or purely access of where you live. We want to increase the efficiency of how people move about.
The ability to be productive in the time we spend in traffic and transportation.
One of the most hated things in terms of stress, emotion, the thing in our lives that if we could just
with a snap of a finger remove is traffic. So the ability to convert that into efficiency,
into a productive aspect, into a positive aspect of life and really the most important thing at least for me
and for many of us working in the space, is to save lives, prevent crashes that lead to injuries,
prevent crash that will lead to fatalities. Here's a counter. Every 23 seconds somebody in the world dies
in a car, auto crash. It should be a sobering, it is for me,
thing that I think about every single day. You go to bed, you wake up, you work on all the deep learning levels,
all the different papers are publishing, everything we're trying to push forward is really to save lives at the beginning and at the end
that is the main goal. So with that groundwork, with that idea, with that base,
2018 in review
the mission that we're all working towards from the different ideas and different perspectives,
I would like to review what happened in 2018. So first, Waymo has done incredible work
in deploying and testing their vehicles in various domains and having October reached the mark
of 10 million miles, German autonomously which is an incredible accomplishment. It's truly a big step for fully autonomous vehicles
in terms of deployment and obviously is growing and growing by day.
And we'll have Drago here from Waymo to talk about their work there. Then on the L2 on the semi-autonomous side,
that's the pair, that's the mirror side of this equation. The other incredible number,
that's perhaps less talked about, is the one billion mile mark reached by Tesla
in the semi autonomous driving of autopilot. Now autopilot is a system that's able to control
its position in the lane, center itself in the lane, it's able to control the longitudinal movement so not follow a vehicle
when there's a vehicle in front and so on. But the degree of its ability to do so is the critical thing here,
is the ability to do so for many minutes at a time even hours at a time especially on highway driving.
That's the critical thing. And the fact that they've reached one billion with a B miles is an incredible accomplishment.
All of that from the machine learning perspective is data. That's data. And all of the autopilot models are driven
with the primary sensor being a camera, that's computer vision.
Now how does computer vision work in modern day, especially with the second iteration of auto pilot hardware
there's a neural network. There's a set of neural networks behind it. That's super exciting. That is probably the largest deployment
of neural networks in the world that has a direct impact
on a human life, that's able to decide, that's able to make life critical decisions
many times a second over and over. That's incredible. You go from the step of image classification on ImageNet
and you sit there with a tensor flow and you're very happy there. You were able to achieve a 99.3 accuracy
with a state of the art algorithm. You take from that a step towards there's a human life,
your parents driving, your grandparents driving this,
your children driving the system and there's a neural network making the decision of whether they'll live.
So that one billion mark is an incredible accomplishment. And on the sobering side and from various perspectives,
Fatalities
the fatalities, there's been two fatalities that happened in March of 2018. One in the fully autonomous side of things
with Uber in Tempe, Arizona, hitting a pedestrian
and leading to a pedestrian fatality. And on the semi-autonomous side with Tesla Autopilot,
the third fatality that Tesla Autopilot led to and the one in 2018 is in Mountain View, California
when Tesla slammed into a divider killing his driver.
Now the two aspects here that are sobering and really important to think about as we talk about the progression of autonomous vehicles,
proliferation in our world is our response as a public, is from the general public to the engineers
to the media and so on, how we think about these fatalities. And obviously there's a disproportionate amount
of attention given to these fatalities. And that's something as engineers you have to also think about,
that the bar is much higher on every level in terms of performance. So in order to success, as I'll argue,
in order to design successful autonomous vehicles those vehicles will have to take risks.
And when the risks don't pan out, the public, if the public doesn't understand,
the general problem that we're tackling, the goal of the mission, that those risks when they don't,
the risks that are taken can have significant detrimental effect
to the progress in this autonomous vehicle space. So that's something we really have to think about. That's our role as engineers and so on.
Question, yeah. So the question was, do we know the the rate of fatalities per mile of vehicle driven
which is at the crudest level how people think about safety. So there's about 80, 90, 100 million miles driven
in manually controlled cars at every fatality. So one fatality per, depending on which numbers you look at,
it's 80 to 100 million miles. In the Tesla vehicle, for example,
the fatality is well we could just take the one billion and divided it by three.
Now this, it's apples and oranges in comparison and that's something actually that we're working on to make sure
that we compare it correctly. Compare the aspects of manual miles
that directly are comparable to the autopilot miles. So Autopilot is a modern vehicle that's much safer.
Tesla is a modern vehicle that's much safer than the general population of manually driven vehicles.
Autopilot is driven on only a particular kinds of roads on the highway primarily, most of the miles.
The kinds of people that drive Autopilot, all these kinds of factors need to be considered when you compare the two.
But when you just look at the numbers, Tesla Autopilot's three times safer than manually driven vehicles.
But that's not the right way to look at it. And for anyone that's ever taken a statistics class,
three fatalities is not, does not, it's not a large number
by which to make any significant conclusions.
Nevertheless, that doesn't stop the media, the New York Times and everybody from responding to a single fatality,
which PR and marketing aspects of these different companies are very sensitive to,
which is of course troubling and concerning for an engineer that wants to save lives. But it's something that we have to think about.
Okay, 2018 in review continued. There's been a lot of announcements
Taxi services
or rather actual launches of public testing of autonomous taxi services.
So companies that on public roads have been delivering
real people from one location to another. Now there's a lot of caveats. In many of these cases it's very small scale,
just a few vehicles, in most cases it's very low speed, in a constrained environment,
in a constrained community and almost always, really always, with a safety driver.
There's a few exceptions for demonstration purposes but there's always an actual driver in the seat.
Some of the brilliant folks representing these companies will speak in this course is Voyage doing it in an isolated community,
awesome work they're doing in villages in Florida, Optimus Ride here in Boston doing
and the community in Union Point, Drive.ai in Texas, May Mobility expanding beyond Detroit
but really most operation's in Detroit, Waymo has launched its service. Waymo one that's gotten some publicity in Phoenix, Arizona.
That Nuro doing zero occupancy deliveries of groceries autonomously.
So we didn't say has to be delivering humans, it's delivering groceries autonomously. Uber is quietly, or not so quietly,
resumed its autonomous vehicle taxi service testing in Pittsburgh in a very careful constrained way.
Aptiv, after acquiring Carl Iagnemma and nuTonomy,
has been doing extensive large-scaled taxi service testing
everywhere from Vegas to Boston here to Pittsburgh and in Singapore of course.
Aurora that spoke here last time,
the head of Tesla Autopilot launched Aurora and the Chris Urmson behind this young upstart company
is doing testing in San Francisco and Pittsburgh and then Cruise, Kyle will be here to talk from GM,
is doing testing in San Francisco, Arizona and Michigan. So when we talk about predictions,
Predictions
I'll talk about a few people predicting when we're going to have autonomous vehicles
and when you yourself think about what it means when will they be here?
When will autonomous vehicles arise such that that Uber that you call will be autonomous and not with a populated by a driver.
So the thing we have to think about is what we think about what, how we define autonomous,
what that experience looks like. And most importantly in these discussions, we have to think about scale.
So we here at MIT our group MIT Human Centered Autonomous Vehicle, we have a fully autonomous vehicle that people can get in
if you would like and it will give you a ride in a particular location. But that's one vehicle, it's not a service
and it only works on particular roads. It's extremely constrained. In some ways it's not much different
than most of the companies that we were talking about today. Now scale here, there's a magic number,
I'm not sure what it is but for this, the purpose of this conversation let's say it's 10,000, where there's a meaningful deployment,
when it's truly going beyond that prototype demo mode to where everything is under control,
to where it's really touching the general population in a fundamental way. Scale is everything here and it starts,
let's say at 10,000. Just to give you for reference, there's 46,000 active Uber drivers in New York City.
So that's what 10,000 feels like some, you know 25, 30 % of the Uber drivers in New York City
all of a sudden are become passengers.
So the predictions, I'm not a marketing PR person, so I don't understand what everybody has
to have make a prediction but they all seem to. Although major automakers have made a prediction
of when they'll have a deploy, when they will be able to deploy autonomous vehicles.
Tesla has made in early 2017,
a prediction that it will have autonomous vehicles 2018. In 2018 they've now adjusted the prediction to 2019.
Nissan, Honda, Toyota have made prediction for 2020
under certain constraints in highway urban. Hyundai and Volvo has in 2021.
BMW and Ford, Ford saying at scale, so a large scale deployment 2021.
And Chrysler in '21 and Daimler saying in the early '20s. So there is the the predictions
that are extremely optimistic that are perhaps driven
by the instinct that the company has to declare that they're at the cutting edge of innovation.
And then there is many of the leading engineers behind the leading these teams including Carl Iagnemma
and Gill Pratt from MIT who in injects a little bit
of caution and grounded
ideas about how difficult it is to remove the human from the loop of automation. So Carl says that basically teleoperation,
kind of gives this analogy of an elevator and the elevators fully autonomous but there is still a button to call for help
if something happens. And that's how he thinks about autonomous vehicles. Even with greater and greater degree of automation,
they're still going to have to be a human in the loop, they're still going to be a way to contact a human to get help.
And Gill Pratt and Toyota and they're making some announcements at CES,
basically saying that the human in the loop is the fundamental aspect that we need to approach this problem and removing the human
from consideration is really, really far away.
And Gill, who's historically and currently is one of the sort of the great roboticists in the world
that defined a lot of the DARPA challenges and a lot of our progress historically speaking
up to this point. So they're really the full spectrum, we can think of it as the Elon Rodney spectrum
of optimism versus pessimism. Elon Musk, who's extremely bold and optimistic
about his predictions. I often connect with this kind of thinking
because sometimes you have to believe the impossible is possible in order to make it happen. And then there is Rodney,
also one of the great roboticists, the former head of the of CSAIL, the AI laboratory here,
is a little bit on the pessimistic side. So for Elon, now fully autonomous vehicle will be here in 2019
for Rodney the vehicles are really, fully autonomous are beyond 2050.
But there, he believes in the '30s there will be a significant, a major city will be able
to allocate a significant region of that city where manual driving is fully banned.
Which is the way he believes those vehicles could, autonomous vehicle really proliferate when you ban manually driven vehicles in certain parts.
And then in the '40s, 2045 or beyond, majority of U.S cities will ban manually driven vehicles.
Of course the quote from Elon Musk in 2017 is that,
my guess is that in probably 10 years it will be very unusual for cars to be built
that are not fully autonomous. So we also have to think about the long tail of the fact
that many people drive cars that are 10 years old, 20 years old. So even when you have every car's built as fully autonomous,
it's still gonna take time for that dissipation of vehicles to happen. And so my own view beyond predictions,
to take a little pause into the ridiculous and the fun to explain the view.
Human-centered autonomy
Yes that is me playing guitar in our autonomous vehicle. Now the point of this ridiculous video and embarrassing,
I should've never played it. Yeah, okay, I think it's gonna be over soon.
Now for those of you born in the '90s that's classic rock. (audience laughing)
So the point I'm trying to make beyond predictions is that autonomous vehicles will not be adopted by human beings
in the near term, in the next 10-15 years, because they're safer. Safety is not going to, they may be safer but that is,
they're not going to be so much safer that that's going to be the reason you adopt.
It's not gonna be because they get you to the location faster. Everything we see with autonomy is they're going to be slower
until majority of the fleet is autonomous. They're cautious and therefore slower
and therefore more annoying in the way we think about actually how we navigate this world. We take risk, we drive assertively with speed
over the speed limit all the time. That is not how autonomous vehicles today operate. So they're not gonna get us there faster
and for every promise, every hope that they're going to be cheaper really there's still significant investment going into them
and there is not good economics in the near term of how to make them obviously significantly cheaper.
What I think Uber and Lyft has taken over the taxi service
because of the human experience. In the same way autonomy will only take over if,
not take over but be adopted by human beings if it creates a better human experience. If there's something about the experience
that you enjoy the heck out of. This video and many others that we're putting out,
shows that in the natural language communication, the interaction with the car, the ability of the car to sense everything you're doing
from the activity of the driver to the driver's attention and being able to transfer control back and forth
in a playful way but really in a serious way also that's personalized to you.
That's really the human experience, the efficiency of the human experience, the richness of the human experience,
that is what we need to also solve. That's something you have to think about because many of the people,
that'll be speaking at this class and many of the people that are working on this problem are not focused on the human experience.
It's a kind of afterthought that once we solve the autonomous vehicle problem it'll be fun as hell to be in that car.
I believe you first have to make it fun as hell to be in the car and then solve the autonomous vehicle problem jointly.
So in the language that we're talking about here there are several levels of autonomy that are defined
Levels of autonomy and proliferation strategies
from level zero to level four. Level zero no automation, four and five, level three, four and five increasing automation.
So level two is when the driver is still responsible, level three, four, five is when there's less and less responsibility.
But really in three, four, five, there's parts of the driving where the liability's on the car.
So there's only really two, as far as I'm concerned, levels, human center autonomy and full autonomy.
Human centered means the human is responsible. Full autonomy means the car is responsible
both on the legal side, the experience side and the algorithm side.
That means full autonomy does not allow for teleoperation.
So it doesn't allow for the human to step in and remotely control the vehicle because that means the human is still in the loop.
It doesn't allow for the 10 second rule that it's gonna be fully autonomous
but once it starts warning you, you have 10 seconds to take over. No, it's not fully autonomous if it cannot guarantee safety in any situation.
It has to be able to, if the driver doesn't respond in 10 seconds it has to be able to find safe harbor. It has to be able to pull off to the side of the road
without hurting anybody else to find safety. So that's the fully autonomous challenge.
And so how do we envision these two levels of automation proliferating society,
getting deployed at a mass scale? The 10,000, 10 million beyond.
On the fully autonomous side, the way to think about it with the predictions
that we're talking about here, is there's several different possibilities of how to deploy these vehicles.
One is last mile delivery of goods and services
like the groceries. These are zero occupancy vehicles delivering groceries or delivering human beings at the last mile.
What the last mile means is it's slow-moving transport to the destination where most of the tricky driving
along the way is done manually and then the last mile delivery in the city in the urban environment is done
by zero occupancy autonomous vehicles. Trucking on the highway, possibly with platooning,
where a sequence of trucks follow each other. So in this what people think about it as a pretty well-defined problem of highway driving
with lanes well marked, well mapped routes throughout the United States and globally
on the highway driving is automatable. The specific urban routes kind of like what a lot of the these companies are working on,
defining this taxi service and personalized public transport.
There's certain pickup locations you're allowed to go to, there are certain drop-off locations and that's it.
It's kind of like taking the train here but as opposed to getting on the train with 100 other people you're getting or bus,
you're getting on the car with, when you're alone or with one other person.
The closed communities, something Oliver Cameron with Voyage is working on defining and Optimus Ride,
defining a particular community that you now have a monopoly over
that you define the constraints, you define the customer base and then you just deliver the vehicles. You map the entire road, you have slow-moving transport
that gets people from A to B anywhere in that community.
And then there's the world of zero occupancy ride-sharing delivery.
So the Uber that comes to you as opposed to having you drive it yourself and it comes to you autonomously with nobody in there
and then you get in and drive it. So imagine a world where we have empty vehicles driving around,
delivering themselves to you. Semi-autonomous side is thinking about a world
where teleoperation plays a really crucial role where it's fully autonomous under certain constraints on the highway but a human can always step in.
High autonomy on the highway kind of like what Tesla is working towards most recently,
it's on-ramp to off-ramp. Now the driver is still responsible, liability wise
and in terms of just observing the vehicle and algorithmically speaking but the autonomy is pretty high level
to a point where much of the highway driving could be done fully autonomously. And low autonomy unrestricted travel
as an advanced driver assistance system, meaning that the car kind of like the Tesla,
the Volvo S90s or the Super Cruise and the Cadillacs all these kinds of L2 systems that are able
to keep you in the lane, you know 10 to 30% of the miles that you drive and some fraction of the time take some
of the stress of driving off. And then there is some out there ideas, right.
Out-of-the-box ideas
The idea of connected vehicles, vehicle to vehicle communication and vehicle to infrastructure communication enabling us
to navigate, for example, intersection efficiently without stopping, removing all traffic lights.
So here shown on the bottom is our conventional approach of there's a queuing system that forms
because of traffic lights that turn red, green, yellow and without traffic lights and with communication
to the infrastructure in between the vehicles you can actually optimize that to significantly increase the traffic load through a city.
Of course there's the boring solution
of tunnels under cities, layers of tunnels under cities.
Tunnels all the way down. Autonomous vehicles basically
by the design of the tunnel, constraining the problem to such a degree that an, I mean the idea of autonomy
just is completely transformed. That you're basically, a car is able to transform itself
into a mini train, into a mini public transit entity, for a particular period of time.
So you get into that tunnel, you drive at 200 miles an hour and or not necessarily drive, be driven 200 miles an hour
and then you get out of the tunnel. Of course there's the flying cars, personalized flying car vehicles.
I will not, I mean,
Rodney as I mentioned before, does believe that we'll have them in 2050. There's a lot of people that are seriously actually thinking
about this problem is there's a level of autonomy obviously that's required here for a regular person.
I don't know somebody without a pilot's license, for example, to be able to take off and land.
Making that experience accessible to regular people means that there's going to be a significant amount
of autonomy involved. One of the people really, one of the companies really seriously working on this,
is Uber with the Uber Elevate, Uber Air I think it's called
and the idea is that you would meet your vehicle not on the street but at a roof,
you take it elevator, you meet them at the roof of a building. This video's from Uber.
They're seriously addressing this problem. Many of the great solutions
to the world's problems have been laughed at at some point. So let's not laugh too loud at these possibilities.
Who will be first?
Back in my day we used to drive in the street. Okay so aha, 10,000 vehicles,
if that's the bar. I sort of out of curiosity asked, did a little public poll.
3,000 people responded. Asked who will be first to deploy 10,000 fully autonomous cars operating
on public roads without a safety driver. And several options percolated with Tesla getting 57%
of the vote and Waymo gaining 21% of the vote and 14% someone else and 8% the curmudgeons
and the engineers saying no one in the next 50 years will do it.
And again in 1998 when Google came along, the leaders of the space were Ask Jeeves
and Infoseek and Excite, all services I've used and probably some people in this room have used,
Lycos, Yahoo, obviously they were the leaders in the space and Google disrupted that space completely.
So this poll shows the current leaders but it's wide open to ideas and that's why there's a lot
of autonomous vehicle companies. Some companies are taking advantage of the hype
and the fact that there's a lot of investment in the space but some companies, like some of the speakers visiting
in this course are really trying to solve this problem. They want to be the next Google, the next billion, multi-billion,
next trillion dollar company by solving the problem. So it's wide open. But currently Tesla with a human,
with the semi-autonomous vehicle approach working towards trying to become fully autonomous.
And Waymo starting with the fully autonomous working towards achieving scale at the fully autonomous are the leaders in the space.
Given that, ranking in 2019,
Historical context
let's take a quick step back to 2005 with the DARPA challenge when the story began.
The race to the desert when Stanley from Stanford won a race through the desert
that really captivated people's imagination about what's possible. And a lot of people have said that the autonomous vehicle problem is solved in 2005.
They really said you know the idea was especially because in 2004 nobody finished that race,
2005 four cars finished the race, it was like well we cracked it. This is it.
And then you know some critics said that urban driving is really nothing comparable
to desert driving, desert is very simple there's no obstacles and so on. It's really a mechanical engineering problem
it's not a software problem. It's not a fundamentally, it's not really an autonomous driving problem as it would be delivered to consumers
and of course in 2007, DARPA put together Urban Grand Challenge and several people finished that with CMU's boss winning.
And so the thought was at that point, that's it, we're done. As Ernest Rutherford, a physicist, said,
that physics is the only real science, the rest is just stamp collecting, all the biology, chemistry. Certainly, oh boy, I wouldn't want to know
what he thinks about computer science. It's just all this stupid silly details Physics is the fundamentals.
And that was the idea with the DARPA Grand Challenge and solving that that we solved the fundamental problem of autonomy.
And the rest is just for industry to figure out some of the details of how to make an app
and make a business out of it. So that could be true. And the underlying beliefs there is
Underlying beliefs of the industry and public
that driving is an easy task, that it's solvable. The thing that we do as human beings
that it's pretty formalizable it's pretty easy to solve with autonomy
that the other idea is that humans are bad at driving. This is a common belief. Not me, not you but everybody else,
nobody in this room but everybody else is a terrible driver. The kind of intuition that we have about our experience of traffic leads us to believe
that humans are just really bad at driving. And from the human factors, psychology side,
there's been over 70 years
of research showing that humans are not able
to monitor, maintain vigilance, monitoring a system. So when you put a human in a room with a robot
and say watch that robot, they start texting like 15 seconds in.
So that's the fundamental psychology. There's thousands of papers on this. People are, they tune out, they over trust the system,
they misinterpret the system and they lose vigilance. Those are the three underlying beliefs.
It very well could be true but what if it is not? So we have to consider that it is not.
The driving task is easy because if you think the driving task is easy and formalizable and solvable by autonomous vehicles,
Driving is hard
you have to solve this problem. The subtle vehicle-to-vehicle, vehicles-to-pedestrian nonverbal communication
that happens here in a dramatic sense but really happens in the subtle sense
millions of times every single day in Boston. Subtle nonverbal communication between vehicles,
you go, no, you go. You have to solve all the crazy road conditions
where in a split seconds you have to make a decision about, so in snowy, icy weather, rain,
limited visibility conditions, you have 100, 200 milliseconds to make a decision.
Your algorithm based on the perception has to make a control decision.
And then you have to deal with a nonverbal communication with pedestrians, these unreasonable irrational creatures, us human beings.
You have to not only understand what the intent of the movement that's anticipated.
So anticipating the trajectory of the pedestrian you also have to assert yourself in a game theoretic way
as crazy as it might sound, you have to threaten yourself, you have to take a risk. You have to take a risk that
if I don't slow down like that ambulance didn't slow down that the pedestrian will slow down.
Algorithmically we're afraid to do that. The idea that a pedestrian that's moving,
we anticipate their trajectory based on the simple physics of the current velocity of the momentum, they're gonna keep going with some probability.
The fact that by us accelerating we might make that pedestrian stop,
it's something that we have to incorporate into algorithms and we don't today. And we don't know how to really.
So if driving is easy we have to solve that too. And of course the thing I showed yesterday with the coast runners and the boat going around
and all the ethical dilemmas from the moral machine
to the more serious engineering aspects that from the unintended consequences
that arise from having to formalize the objective function
under which a planning algorithm operates. If there's any learning that, as I showed yesterday,
a boat on the left run by a human wants to finish the race, the boat on the right figures out that it doesn't have to finish the race,
it can pick up turbos along the way and gets much more reward. So if the objective function is to maximize the reward,
you can slam into the wall over and over and over again and that's actually the way to optimize the reward.
And those are the unintended consequences of an algorithm that has to be formalizable to the objective function
without a human in the loop. Humans are bad at driving. As I showed yesterday,
humans if they're bad at anything it's about having a good intuition about what's hard and what's easy.
Humans are amazing
The fact that we have 540 million years worth of data on our visual perception system means we don't understand how damn impressive it is
to be able to perceive and understand the scene in a split second, maintain context,
maintain an understanding of performing all the visual localization tasks
about anticipating the physics of the scene and so on. And then there's a control side.
The humans don't give enough credit to ourselves. We're incredible, state-of-the-art soccer player on the left
(audience laughing) and the state-of-the-art robot on the right.
I think there's like four or five times he scores, (audience laughing) all right.
And this is all the movement and so on involved with that, of course here that's the human robot,
that's a really incredible work that's done for the DARPA Robotics Challenge with the humanoid robots on the right and incredible work
by the human people doing the same kind of tasks
much more impressive task I would say. So that's where we stand. And the ones on the right are actually not fully autonomous,
there's still some human in the loop. There's just noisy broken communication. So that, humans are incredible
in terms of our ability to understand the world and in terms of our ability to act in that world.
Humans and automation don't mix well?
And the fact that humans, the idea, the view, the popular view grounded in the psychology that humans
and automations don't mix well, over trust, misunderstanding, loss of vigilance, the command and so on,
that's not an obvious fact. It happens a lot in the lab. Most of the experiments are actually in the lab.
This is the difference. You put, many of you, you put a undergrad, grad student
in a lab and say here watch this screen and wait for the dot to appear.
They'll tune out immediately but when it's your life and you're on the road, it's just you in the car,
it's a different experience. It's not completely obvious that vigilance will be lost and it's not a complete, when it's just you and the robot,
it's not completely obvious what the psychology, what the attentional mechanism, with the vigilance that it looks like.
So one of the things we did, is we instrumented here 22 Tesla's and observed people now over a period of two years of what they actually do
when they're driving autopilot, driving these systems. In red shown manually controlled vehicles and cyan showed vehicle control autopilot.
Now there's a lot of details here and we have a lot of presentations on this but really, the fundamentals are, is that they drive 34%,
large percentage of the miles in autopilot and in 26,000 moments of transfer of control
they are always vigilant. There's not a moment once in this data set
where they respond too late to a critical situation,
to a challenging role situation. Now the data set, 22 vehicles, that's a 0.1% or less than the full Tesla fleet
that has autopilot. But it's still an inkling. It's not obvious that it's not possible to build a system
that works together with a human being and that system essentially looks like this.
Some percentage, 90%, maybe less, maybe more, when it can solve the problem of autonomous driving
it solves it and when he needs human help it asks for help. That's the trade-off, that's the balance.
On the fully autonomous side, on the right it has to solve here with citations
and there's references always on the bottom. All the problems have to be solved exceptionally, perfectly,
from mapping localization to the scene perception to control to planning to being able to find safe harbor
at any moment to also being able to do external HMI communication with the other pedestrians, the vehicles in the scene
and then there's teleoperation, vehicle-to-vehicle, vehicle-to-AI. You have to solve those perfectly if you want to solve the fully autonomous problem,
as I said including all the crazy things that happen in driving. And if you approach the shared autonomy side,
the semi-autonomous where you're only responsible for a large percentage but not 100% of the driving
then you have to solve the human side, the human interaction, the sensing what the driver is doing,
the collaborating communicating with the driver and the personalization aspect that learns with the driver.
As I said you can go online, we have a lot of demonstrations of these kinds of ideas. But the natural language, the communication,
I think is critical for all of us as we're tweeting as all of us do.
(people chattering) So it's as simple as, so this is just demonstration of Eco taking control
when the attention over time, that the driver is being,
okay, we got it thank you.
Okay so basically a smartphone use which has gone up year by year and we're doing a lot of analysis on that,
it's really what people do in the car is they use their phone, whether it's manual or autonomous driving
or semi-autonomous driving. So being able to manage that, to communicate with the driver
about when they should be paying attention which may not be always. You're sort of balancing the time when it's a critical time
to pay attention when it's not and communicating effectively, learning with the driver, that problem is a fundamental machine learning problem.
There's a lot of data visible light, everything about the driver and it's a psychology problem.
So we have data, we have complicated human beings and it's a human robot interaction problem
that deserves solving. But as you'll hear on the beyond the human side looking out
Two approaches: Lidar vs Vision
into the world, people that are trying to solve the fully autonomous vehicle it's really a two approach consideration.
One approach is vision, cameras and deep learning, right.
Collect a huge amount of data. So cameras have this aspect
that they're the highest resolution of information available. It's rich texture information
and there's a lot of it which is exactly what you know networks love right. So to be able to cover all the crazy edge cases,
the vision data, camera data, visible light data, is exactly the kind of data you need
to collect a huge amount of, to be able to generalize over all the crazy countless edge cases that happen.
It's also feasible, all the major data sets, all the, in terms of cost, interest, scale,
all the major data sets of visible light cameras. That's another pro and they're cheap
and the world as it happens, whoever designed the simulation that we're all living in,
made it such that our world, our roads and our world,
is designed for human eyes. Eyes is the way we perceive the world
and so the lane mark is also on is visual, most of the road textures that you use
to navigate, to drive are visible, are made for human eyes.
The cons are that without a ton of data and we don't know how much, they're not accurate.
You make errors because driving is ultimately about 99.99999% accuracy and so that's what I mean
by not accurate. It's really difficult to reach that level.
And then the second approach is LIDAR, taking a very particular constrained set of roads,
mapping the heck out of them, understanding them fully under different weather conditions and so on
and then using the most accurate sensors available. A suite one sensors but really LIDAR at the forefront.
Being able to localize yourself effectively. The pros there that it's consistent, especially when machine learning is not involved,
it's consistent and reliable and it's explainable. If it fails, you can understand why,
you can account for those situations. It's not so much true for machine learning methods. It's not so much explainable why it failed
in a particular situation. The accuracy is higher as we'll talk about. The cons of LIDAR is that it's expensive
and most of the approaches in perceiving the world using LIDAR primarily
are not deep learning based and therefore they're not learning over time. And if they were deep learning based,
there's a reason they're not, it's 'cause you need a lot of car, you gonna need a lot of LIDAR data.
And there's only a tiny percentage of cars in the world quite obviously are equipped with LIDAR
in order to collect that data. So quickly running through the sensors.
Radar is, it's kind of like the offensive line of football.
They're actually the ones that do all the work and they never get the credit. So radar is that.
It's always behind to catch, to actually do the detection in terms of obstacle,
the most critical safety critical obstacle avoidance. It's cheap, it does extremely well
and it does well in extreme weather but it's low resolution so it cannot stand on its own
to achieve any kind of degree of high autonomy. Now on the LIDAR side it's expensive,
it's extremely accurate depth information, 3D cloud, point cloud information. Its resolution is much higher than radar
but still lower than visible light and there is depending on the sensor, a 360 degree visibility that's built in.
So there's a difference in resolution here, visualized LIDAR on the right, radar on the left.
The resolution is just much higher and is improving and the cost is going down and so on. Now on the camera side, it's cheap, everybody got one,
the resolution is extremely high in terms of the amount of information transferred per frame
and everybody you know really the scale of the number of vehicles
that have this equipped is humongous. So it's ripe for application of deep learning.
And the challenge is it's noisy, it's bad at depth estimation
and it's not good in extreme weather.
So if we kind use this plot to look, to compare these sensors, to compare these different approaches.
So LIDAR works in the dark, variable lighting conditions, has pretty good resolution,
has pretty good range but it's expensive,
it's huge, and it doesn't provide rich textural contrast information
and it's also sensitive to fog and rain conditions. Now ultrasonic sensors catch a lot of those problems.
They're better at detecting proximity, they're high resolution in objects that are close
which is why they're often used for parking but they can still also be integrated in the sensor fusion package
for an autonomous vehicle. They really catch a lot of the problems that radar has.
They complement each other well and radar, cheap, tiny, detect speed
and has pretty good range but has terrible resolution.
There's very little information being provided. And then cameras a lot of rich information,
they're are cheap, their small range is great, the best range actually of all the sensors
and works in bright conditions but doesn't work in the dark, in extreme conditions
and it's just susceptible to all these kinds of problems and doesn't detect speed unless you do some tricky structure
from motion kind of things. So here's where sense of fusion steps in and you, everybody works together
to build an entire picture. That's how this plot works. You can stack it on top of each other.
So if you look at a suite that for example Tesla is using which is ultrasonic radar and camera and you compare it to just LIDAR
and see how these paths compare that actually the suite of camera, radar
and ultrasonic are comparable to LIDAR. So that those are the two comparisons that we have.
You have the costly non machine-learning way of LIDAR and you have the cheap
but needs a lot of data and is not explainable and reliable in the near-term vision based approach.
And those are the two competing approaches. Now of course huevos will talk about they're trying to use both but ultimately the question is
who catches, who is the fail safe?
In the semi-autonomous way when there's a camera based method, the human is the fail safe.
When you say, oh crap I don't know what to do, the human catches. In the fully autonomous mode,
so what Waymo's working on and others, the fail safe is LIDAR,
the fail safe is maps that you can't rely on the human. But you know this road so well
that if the camera is freaked out if there's any of the sensors freaked out that you're able to, you have such good maps,
you have such good accurate sensors, that the fundamental problem of obstacle avoidance which is what safety is about, can be solved.
The question is what kind of experience that creates. In the meantime as the people debate, try to make money, start companies,
In the meantime… data
there's just lots of data. Ford F-150 still the most popular car in America.
Manually driven cars are still happening. So there's a lot of data happening. Semi-autonomous cars, every company is now releasing
more and more semi-autonomous technology. So that's all data.
And what that boils down to is the two paths they're walking towards is vision versus LIDAR,
L2 versus L4, semi-autonomous versus fully autonomous. Tesla on the semi-autonomous front has reached
one billion miles. Waymo the leader on the autonomous front has reached 10 million miles.
The pros and cons as I've outlined them. One, division one, the one I'm obviously very excited about
and machine learning researchers excited are about which fundamentally relies on huge data and deep learning.
The neural networks that are running inside the Tesla and with their new as they,
it's kind of the same kind of path as Google was taking from the GPU to the TPU, Tesla's taking from Nvidia Drive PX2 system,
sort of more general GPU based system to creating their own ASIC and having a ton of awesome neural networks running
on their car. That kind of path, that others are beginning to embrace, is really interesting to think about
for machine learning engineers. And then people that are maybe more grounded
and actually wanna, are really, value, safety, reliability
and sort of from the automotive world, are thinking well we need machine learning is not explainable
it's difficult to work with, it's not reliable and so in that sense we have to have a sensor suite
that are extremely reliable. Those are the two paths. Yep, question.
The question is there's all kinds of things you need to perceive, stop signs and traffic lights,
pedestrians and so on. Some of them, if you hit them it's a problem, some of them are a bag flying through the air
and all have different visual characteristics all have different characteristics for all the different sensors.
So LIDAR can detect of solid-body objects,
camera is better at detecting, as last year Sasha Arnu talked about,
I think fog or smoke. These are interesting things. They might look like an object
to certain sensors and not to others, But the traffic light detection problem luckily is
with cameras is, it's pretty solved at this point. So that's luckily the easy part.
The hard part is when you have a green light and there's a drunk, drugged, drowsy or distracted,
the four Ds that hits an online pedestrian trying to cross what to do.
That's the hard part. So the road ahead for us as engineers, the science is the thing I'm super excited
The road ahead
about the possibility of artificial intelligence having a huge impact, is taking the step from having these
even if they're large, toy datasets, toy problems, toy benchmarks of ImageNet classification
in cocoa, all the exciting deep RL stuff that we'll talk about in the future weeks,
really are toy examples, the game of go and chess and so on. But taking those algorithms and putting them in cars
where they can save people's lives and they actually directly touch and impact our entire civilization
that's actually the defining problem for artificial intelligence in the 21st century is AI
that touches people in a real way and I think cars, autonomous vehicles, is one of the big ways that that happens.
We get to deal with the psychology, the philosophy, the sociology aspects of it, how we associate,
think about it, to the robotics problem, to the perception problem. It's a fascinating space to explore
and we have many guest speakers exploring that different ways and that's really exciting to see
how these people are trying to change the world. So with that I'd like to thank you very much,
go to deeplearning.mit.edu and the code is always available online.
(people clapping)

----------

-----

--57--

-----
Date: 2019.01.24
Link: [# MIT 6.S091: Introduction to Deep Reinforcement Learning (Deep RL)](https://www.youtube.com/watch?v=zR11FLZ-O9M)
Transcription:

Introduction
today I'd like to overview the exciting field of deep reinforcement learning introduced overview and provide you some
of the basics I think it's one of the most exciting fields in artificial
intelligence it's marrying the power and the ability of deep neural networks to
represent and comprehend the world with the ability to act on that understanding
on that representation taking as a whole that's really what the creation of
intelligent beings is understand the world and act and the exciting
breakthroughs that recently have happened captivate our imagination about what's possible and that's why this is
my favorite area of deep learning and artificial intelligence in general and I hope you feel the same so what is deep
reinforcement learning we've talked about deep learning which is taking
samples of data being able to in a supervised way compress encode the
representation that data in the way that you can reason about it I would take that power and apply it to the world
where sequential decisions are to be made so it's looking at problems and
formulations of tasks where an agent an intelligent system has to make a
sequence of decisions and the decisions that are made have an effect on the
world around the agent how how do all of us any intelligent being that it's
tasked with operating in the world how did he learn anything especially when you know very little in the beginning
it's trial and error is the fundamental process by which reinforcement learning
agents learn and the deep part of deep
reinforcement learning is neural networks as using the frameworks and reinforcement learning where the neural
network is doing the representation of the world based on which the actions are
made and we have to take a step back when we look at the types of learning sometimes
Types of learning
the terminology itself can confuse us to the fundamentals there are supervised
learning there semi-supervised learning there's unsupervised learning there's reinforcement learning and there's this
feeling that supervised learning is really the only one where you have to perform the manual annotation where you
have to do the large-scale supervision that's not the case every type of
machine learning is supervised learning it's supervised by a loss function or a
function that tells you what's good and what's bad you know even looking at our
own existence is how we humans figure out what's good and bad there's all
kinds of sources direct and indirect by which our morals and ethics we figure out what's good and bad the difference
we supervised and unsupervised and reinforcement learning is the source of that supervision what's implied when you
say unsupervised is that the cost of human labor required to attain the
supervision is low but it's never Turtles all the way down it's Turtles
and then there's a human at the bottom there at some point there needs to be
human intervention human input to provide what's good and what's bad and
this will arise in reinforcement learning as well I have to remember that because the challenges and the exciting
opportunities of reinforcement learning lie in the fact of how do we get that
supervision in the most efficient way possible but supervision nevertheless is required for any system that has an
input and an output that's trying to learn like a neural network does to
provide an output that's good he needs somebody to say what's good and what's bad for you curious about that there's
been a few books a couple written throughout the last few centuries from Socrates to Nietzsche I recommend the
latter especially so let's look at supervised learning and reinforcement learning let like to propose a way to
think about the difference that is illustrative and useful when we
start talking about the techniques so supervised learning is taking a bunch of examples of data and learning from those
examples where a ground truth provides you the compressed semantic meaning of
what's in that data and from those examples one by one whether it's sequences or single samples we learn
what how to then few take future such samples and interpret them reinforcement
learning is teaching what we teach an agent through experience not by showing
a singular sample of a data set but by putting them out into the world the
distinction there the essential element of reinforcement learning then for us now we'll talk about a bunch of
algorithms but the essential design step
is to provide the world in which to experience the agent learns from the
world the from the world it gets the dynamics of that world the physics of
the world from that world that gets the rewards what's good and bad and us as designers of that agent do not just have
to do the algorithm we have to do design the the world in which that agent is
trying to solve a task the design of the world is the process of reinforcement
learning the design of examples the annotation of examples is the world of supervised learning and the essential
perhaps the most difficult element of reinforcement learning is the reward the good versus bad here a baby starts
walking across the room we want to define success as a baby walking across
the room and reaching the destination that's success and failure is the
inability to reach that destination simple and reinforcement learning in humans
Reinforcement learning in humans
the way we learn from these very few examples appear to learn from very few
examples of trial and error is a mystery a beautiful mystery full of open questions it could be from the huge
amount of data 230 million years worth of bipedal data there who've been walking what mammals walking ability to
walk or 500 million years the ability to see having eyes so that's the the
hardware side somehow genetically encoded in us is the ability to comprehend this world extremely
efficiently it could be through not the hardware not the five hundred million
years but the the few minutes hours days months maybe even years in the very
beginning were born the ability to learn really quickly through observation to
aggregate that information filter all the junk that you don't need and be able to learn really quickly through
imitation learning through observation the way for walking that might mean observing others talk the idea there is
if there was no other around we would never be able to learn this the
fundamentals of this walking or as efficiently it's through observation and
then it could be the algorithm totally not understood is the algorithm that our
brain uses to learn the backpropagation that's an artificial neural networks the
same kind of processes not understood in the brain that could be the key so I
want you to think about that as we talk about the very trivial by comparison
accomplishments and reinforcement learning and how do we take the next steps but it nevertheless is exciting to
What can be learned from data?
have machines that learn how to act in the world the process of learning for
those who have fallen in love with artificial intelligence the process of
learning is thought of as intelligence it's the ability to know very little and through experience examples interaction
with the world in whatever medium whether it's data or simulation so on be able to form much richer and
interesting representations of that world be able to act in that world that's that's the dream so let's look at this stack of what an
age what it means to be an agent in this world from top the input to the bottom
the output is the there's an environment we have to sense that environment we
have just a few tools as humans have several sensory systems on cars you can
have lidar camera stereo vision audio microphone networking GPS IMU sensor so on whatever
robot you can think about there's a way to sense that world and you have this raw sensory data and then once you have
the raw sensory data you're tasked with representing that data in such a way that you can make sense of it as opposed
to all the the raw sensors and the I the cones and so on that taking just giant
stream of high bandwidth information we have to be able to form higher
abstractions of features based on which we can reason from edges to corners to faces and so on that's exactly what deep
learning neural networks have stepped in to be able to in an automated fashion with as little human input as possible
be able to form higher-order representations of that information then
there is the the learning aspect building on top of the greater abstractions form through the
representations be able to accomplish something useful well--there's discriminative tasks a generative task
and so on based on the representation be able to make sense of the data be able to generate new data and so on from
sequence the sequence to sequence the sample from Sam of the sequence and so on and so forth to actions as we'll talk
about and then there is the ability to
aggregate all the information has been received in the past to the useful
information that's pertinent to the task at hand it's the thing the old it looks
like a duck quacks like a duck swims like a duck three different data sets I'm sure there's state-of-the-art
algorithms for the three image class education audio recognition video
classification - activity recognition so on aggregating those three together is
still an open problem and that could be the last piece again I want you to think about as we think about reinforcement
learning agents how do we play how do we transfer from the game of Atari to the game of go to the game of dota to the
game of a robot navigating an uncertain environment in the real world and once
you have that once you sense the raw world once you have a representation of that world then we need to act which is
provide actions within the constraints of the world in such a way that we believe can get us towards success the
promise excitement of deep learning is is the part of the stack that converts
raw data into meaningful representations the promise the dream of deeper enforcement learning is going beyond and
building an agent that uses that representation and acts achieve success
in the world that's super exciting the framework and the formulation
Reinforcement learning framework
reinforcement learning at its simplest is that there's an environment and
there's an agent that acts in that environment the agent senses the environment by a by some observation
well there's partial or complete observation of the environment and it
gives the environment and action it acts in that environment and through the action the environment changes in some
way and then a new observation occurs and then also as you provide they
actually make the observations you receive a reward in most formulations of this of this framework this entire
system has no memory that the the only
thing you two could be concerned about as a state you came from the state you arrived in and the reward received the
open question here is what can't be modeled in this kind of way can we model all of it
from from human life to the game of go can all this be model in this way and
what are is this a good way to formulate the learning problem of robotic systems
in the real world in simulated world those are the open questions the
environment could be fully observable or partially observable like in poker
it could be single agent or multi agent Atari versus driving like deep traffic
deterministic or stochastic static versus dynamic static is in chess
dynamic again and driving in most real-world applications the screen versus continuous like games chess or
continuous and carpal balancing a polo on a cart the challenge for RL in real world
Challenge for RL in real-world applications
applications is that as a reminder
supervised learning is teaching by example learning by example teaching
from our perspective reinforcement learning is teaching by experience and the way we provide experience the
reinforcement learning agents currently for the most part is through simulation or through highly constrained real-world
scenarios so the challenge is in the fact that most of the successes is with
systems environments that are simulated so there's two ways to then close this
gap to directions of research and work one is to improve the algorithms improve
the ability of the algorithm student to form policies that are transferable across all kinds of domains including
the real world including especially in the real world so train and simulation transfer to the real world
or is we improve the simulation in such a way that the fidelity of the
simulation increased increases to the point where the gap between reality and simulation is is minimal to a degree
that things learn the simulation are directly trivially transferable to the
to the real world okay the major components of an RL agent
Component of an RL agent
an agent operates based on a strategy
called the policy it sees the world it makes a decision that's a policy makes a
decision how to act sees the reward sees a new state acts sees a reward
she's new States and acts and this repeats forever until a terminal state
the value function is the estimate of
how good a state is or how good a state action pair is meaning taking an action
in a particular state how good is that ability to evaluate that and then the
model different from the environment from the perspective the agent so the environment has a model based on which
it operates and then the agent has a representation best understanding of that model so the purpose for an RL
agent in this simply formulated framework is to maximize reward the way
that the reward mathematically and practically is talked about is with a
discounted framework so we discount further and further future award so the
reward that's farther into the future is means less to us in terms of maximization than reward that's in the
near term and so why do we discount it so first a lot of it is a math trick to
be able to prove certain aspects analyze certain aspects of convergence and in general on a more philosophical sense
because environments either are or can be thought of a stochastic random it's
very difficult to there's a degree of uncertainty which makes it difficult to really
estimate the the the reward they'll be in the future because of the ripple
effect of the uncertainty let's look at an example a simple one helps us
Example: robot in a room
understand policy's rewards actions there's a robot in the room there's 12
cells in which you can step it starts in the bottom left it tries to get rewards
on the on the top right there's a plus one it's a really good thing at the top right wants to get there by walking
around there's a negative 1 which is really bad you wants to avoid that Square and the choice of action is this
up-down left-right for actions so you could think of there being a negative
reward of point 0 4 for each step so there's a cost to each step and there's a stochastic nature to this world
potentially we'll talk about both deterministic stochastic so in the in the stochastic case when you choose the
action up with an 80% probability with an 80% chance you move up but with 10%
chance to move left another 10 move right so that's the Catholic nature even though you try to go up you might end up
in a blocks to the left into the right so for a deterministic world the optimal
policy here given that we always start in the bottom left is really shortest path is you know you can't ever because
there's no stochasticity you're never gonna screw up and just fall into the hole negative 1 hole that you just
compute the shortest path and walk along that shortest path why shortest path
because every single step hurts there's a negative a reward to it point 0 4
so shortest path is the thing that minimizes the reward shortest path to the to the plus 1 block ok let's look at
it stochastic world like I mentioned the 80% up and then split to 20 10 % to left
and right how does the policy change well first of all we need to have we
need to have a plan for every single block in the area because you might end up there due to this the castus 'ti of
the world ok the the basic addition there is that we're trying to
go avoid up the closer you get to the negative one hole so just try to avoid
up because up the stochastic nature of up means that you might fall into the
hole with a 10% chance and given the point zero for step reward you're
willing to take the long way home in some cases in order to avoid that possibility the negative one possibility
now let's look at a reward for each step if it decreases to negative two it really hurts to take every step then
again we go to the shortest path despite the fact that there's a stochastic
nature in fact you don't really care that you step into the negative one hole because every step really hurts you just
want to get home and then you can play with this reward structure right yes
instead of negative 2 or negative point 0 4 you can look at negative 0.1 and you
can see immediately that the structure of the policy it changes so with a
higher value the higher negative reward free step immediately the urgency of the
agent increases versus the less urgency the lower the negative reward and when
the reward flips so it's positive the
every step is a positive so the entire system which is actually quite common in
reinforcement learning the entire system is full of positive rewards and so that then the optimal policy becomes the
longest path is grad school taking as
long as possible never reaching the destination so what lessons do we draw
from robot in the room two things the environment model the dynamics is just
there in the trivial example the stochastic nature the difference between 80 percent 100 percent and 50 percent
the model of the world the environment has a big impact on what the optimal policy is
and the reward structure most importantly the thing we can often
control more in our constructs of the
task we try to solve them enforcement is the what is good and what is bad and how
bad is it and how good is it the reward structure is a big impact and that has a complete change like like
Robert Frost say the complete change on the policy the choices the agent makes
so at when you formulate a reinforcement learning framework as researchers as
students what you often do is you design the environment you design the world in
which the system learns even when your ultimate goal is the physical robot it
does still there's a lot of work still done simulation so you design the world the parameters of that world and you
also design the reward structure and it can have a transformative results slight
variations in those parameters going to huge results on huge differences on the policy that's arrived and of course the
AI safety and unintended consequences
example I've shown before I really love is the impact of the the changing reward
structure might have unintended consequences and those consequences for
real-world system can have obviously highly detrimental costs that are more
than just a failed game of Atari so here is a human performing the task gate
playing the game of coast runners racing around the track and so it's when you
finish first and you finish fast you get a lot of points and so it's natural to
then okay let's do an RL agent and then optimize this for those points and will you find out in the game is that you
also get points by picking up the little green turbo things and with agent
figures out is that you can actually get a lot more points even by simply focusing on the green turbos
focusing on the green turbos just rotating over and over slamming into the wall fire and everything just picking it
up especially because ability to pick up those turbos can avoid the terminal
state at the end of finishing the race in fact finishing the race means you stop collecting positive reward so you
never want to finish collected turbos and though that's a trivial example it's
not actually easy to find such examples but they're out there of unintended consequences that can have highly
negative detrimental effects when put in the real world we'll talk about a little bit of robotics when you put robots for
wheeled ones like autonomous vehicles into the real world and you have objective functions that have to
navigate difficult intersections full of pedestrians you have to form intent models those pedestrians here you see
cars asserting themselves through dense intersections taking risks and within
those risks that are taking by us humans will drive vehicles we have to then encode that ability to take subtle risk
into into AI based control algorithms
perception then you have to think about at the end of the day there's an
objective function and if that objective function does not anticipate the green
turbos that are to be collected and then result in some understand the consequences could have very negative
effects especially in situations that involve human life that's the field of
AI safety and some of the folks will talk about deep mind and open AI that are doing incredible work in RL also
have groups that are working on a AI safety for a very good reason this is a
problem that I believe that artificial intelligent will define some of the most
impactful positive things in the 21st century but I also believe we are nowhere close
to solving some of the fundamental problems of AI safety that we also need
to address as we those algorithms okay examples and reinforcement learning systems all of it
Examples of RL systems
has to do with formulation or rewards formulation of states and actions you have the traditional the often used
benchmark of a cart balancing a poll continuous so the action is the
horizontal force to the cart the goal is to balance the poll so stays top and the moving cart and the reward is one in
each time step if the poll is upright in the state measured by the cart by the
agent is the pole angle angular speed and of course self sensing of the cart
position and the horizontal velocity another example here didn't want to
include the video because it's really disturbing but I do want to include the slide because it's really important to
think about is by sensing the the raw pixels learning and teaching an agent to
play a game of doom so the goal there is to eliminate all opponents the state is
the raw game pixels the action is up/down shoot reload and so on and the
positive reward is when an opponent is eliminated and negative one the agent is
eliminated simple I added it here because again on the topic of AI safety
we have to think about objective functions and how that translate into
the world of not just autonomous vehicles but things that even more
directly have harm like autonomous weapon systems and we have a lecture on this in the AGI series and on the
robotics platform the manipulate object manipulation and grasping objects there's a few benchmarks there's a few
interesting applications learning the problem of grabbing objects moving
objects manipulating objects rotating and so on especially when those objects
don't have have complicated shapes and so the goal is to pick up an object in
the purely in the grasping objects allenge the state is the visual racial slurs visual visual base the raw
pixels of the objects the actions is to move the arm grasp the object pick it up
and obviously it's positive when the pickup is successful the reason I'm
personally excited by this is because it'll finally allow us to solve the
problem of the claw which has been torturing me for many years
I don't know that's not at all why I'm excited by it okay and then we have to
think about as we get greater and greater degree of application in the real world with robotics
like cars the the main focus of my passion in terms of robotics is how do
we encode some of the things that us humans encode how do we you know we have to think about our own objective
function our own reward structure our own model of the environment about which we perceive and reasonable in order to
then encode machines that are doing the same and I believe autonomous driving is in that category but to ask questions of
ethics we have to ask questions of of risk value of human life value of
efficiency money and so on all these in front of ethical questions that an autonomous vehicle unfortunately has to
solve before it becomes fully autonomous so here are the key takeaways of the
Takeaways for real-world impact
real-world impact of reinforcement learning agents on the deep learning
side okay these neural networks that form high representation the fun part is the algorithms all the different
architectures the different encoder/decoder structures all the attentions self attention recurrent
Sallust Engr use all the fun architectures and the data so that and
the ability to leverage different data sets in order to discriminate better
than perform this Crematory tasks better than you know MIT does better than stand
for that kind of thing that's the fun part the hard part is asking good questions and collecting huge amounts of
data that's representative over the task that's for real world impact not cvpr publication real-world impact
a huge amount of data on a deeper enforcement learning side the key challenge the fun part again is the
algorithms how do we learn from data some of the stuff I'll talk about today the hard part is defining the
environment defining the acts of space and the reward structure as I mentioned this is the big challenge and the
hardest part is how to crack the gap between simulation in the real world the leaping lizard that's the hardest part
we don't even know how to solve that transfer learning problem yet for the real world in fact the three types of
reinforcement learning there's countless
3 types of RL: model-based, value-based, policy-based
algorithms and there's a lot of ways to economize them but at the highest level there's model-based and there's model
free model based algorithms learn the model of the world so as you interact
with the world you construct your estimate of how you believe the dynamics
of that world operates the nice thing about doing that is once you have a
model or an estimate of a model you're able to anticipate you're able to plan
into the future you're able to use the model to in a branching way predict how
your actions will change the world so you can plan far into the future this is the mechanism by which you can you
can do chess in the simplest form because in chess you don't even need to
learn the model the models learnt is given to you chess go and so on the most important way in which they're
different I think is the sample efficiency is how many examples of data
are needed to be able to successfully operate in the world and so model based methods because they're constructing a
model if they can are extremely simple efficient because once you have a model
you can do all kinds of reasoning that doesn't require experiencing every possibility of that model you can unroll
the model to see how the world changes based on your actions value based
methods are ones that look to estimate the quality of states the quality of
taking a certain action in the certain state so they're called off policy
versus the last category that's on policy what does it mean to be off policy it means that they constantly
value based agents constantly update how good is taken action in a state and they
have this model of that goodness of taking action in a state and they use
that to pick them optimal action they don't directly learn a policy a strategy
of how to act they learn how good it is to be in a state and use that goodness
information to then pick the best one and then every once in a while flip a
coin in order to explore and then policy based methods our ones that directly
learn a policy function so they take as input the the world representation of
that world neural networks and this output a action where the action is
stochastic so okay that's the range of model-based value based and policy based
here's an image from open AI that I really like I encourage you to as we
further explore here to look up spinning up in deeper enforcement learning from open AI here's an image that texana
mises in the way that I described some of the recent developments in RL so at
the very top the distinction between model free RL and model-based RL in
model free RL which is what we'll focus on today there is a distinction between
policy optimization so on policy methods and q-learning
which is all policy methods pause optimizations methods that directly optimize the policy they'll directly
learn the policy in some way and then q-learning off policy methods learn like
I mentioned the value of taking a certain action in the state and from that learned that learned Q value be
able to choose how to act in the world so let's look at a few sample representative
approaches in this space let's start with the with the one that really was
Q-learning
one of the first great breakthroughs from google deepmind on the deep IRL side and solving atari games dqn deep
queue learning networks deep queue networks and let's take a step back and
think about what cue learning is q-learning looks at the state action value function queue that estimates
based on a particular policy or based on an optimal policy how good is it to take an action in this state the estimated
reward if I take an action in this state and continue operating under an optimal
optimal policy it gives you directly a way to say amongst all the actions I
have which action should that take to maximize the reward now in the beginning you know nothing you know you don't have
this value estimation you don't have this cue function so you have to learn it and you learn it with a bellman
equation of updating it you take your current estimate and update it with the reward you seed received after you take
an action here it's off policy and model
free you don't have to have any estimate or knowledge of the world you don't have to have any policy whatsoever all you're
doing is roaming about the world collecting data when you took a certain action here award you received and
you're updating gradually this table where the table has state states on the
y-axis and actions on the x-axis and the
key part there is because you always have an estimate of what of to take an
action of the value of taking that action so you can always take the optimal one but because you know very
little in the beginning that optimal is going to you have no way of knowing
that's good or not so there's some degree of expiration the fundamental aspect of value based methods or ami are
all methods like I said it's trial and error is exploration so for value based
methods that q-learning the way that's done is with the flip of a coin epsilon greedy with a flip of a
coin you can choose to just take a random action and you slowly decrease epsilon
to zero as your agent learns more and more and more so in the beginning you explore a lot with epsilon 1 and epsilon
of zero in the end when you're just acting greedy based on the your
understanding of the world as represented by the q-value function for non neural network approaches this is
simply a table the Q this Q function is a table like I said on the Y State X
actions and in each cell you have a reward that's at this counter reward
that you estimated to be received there and as you walk around with this bellami equation you can update that table but
it's a table nevertheless number of states times number of actions now if
you look at any practical real-world problem and an arcade game with raw
Deep Q-Networks (DQN)
sensory input is a very crude first step towards the real world so raw sensor
information this kind of value iteration and updating a table is impractical
because here's for a game of break out if we look at four consecutive frames of a game of breakout size of the of the
raw sensory input is 84 by 84 pixels grayscale every pixel has 256 values
that's 256 to the power of whatever 84
times 84 times 4 is whatever it is it's significantly larger the number of atoms
in the universe so the size of this cue table if we use the traditional approach
is intractable
you'll know it's to the rescue deep RL is rl+ neural networks where the neural
networks is tasked with taking this in Valley based methods taking this cue
table and learning a compress representation of it learning an approximator for the function from state
action to the value that's what previously talked about the ability the
powerful ability of neural networks to form representations from extremely high
dimensional complex raw sensory information so it's simple the framework
remains for the most part the same in reinforcement learning it's just that this cue function for
value based methods becomes a neural network and becomes an approximator where the hope is as you navigate the
world and you pick up new knowledge through the back propagating the gradient and the loss function that
you're able to form a good representation of the optimal q function so using your networks with you'll know
it's a good at which is function approximator x' and that's DQ 1 deep Q Network was used to have the initial
incredible nice results on our K games where the input is the raw sensory
pixels with a few convolutional layers for the connected layers and the output is a set of actions you know probability
of taking that action and then you sample that and you choose the best action and so this simple agent whether
the neural network that estimates that Q function very simple network is able to
achieve superhuman performance on many of these arcade games that excited the
world because it's taking raw sensory information with a pretty simple network
that doesn't in the beginning understand any of the physics of the world any of the dynamics of the environment and
through that intractable space the intractable state space is able to learn
how to actually do pretty well the loss function for DQ n has to Q functions one
is the expected the predicted Q value of
a taking an action in a particular state and the other is the target against
which the loss function is calculated which is what is the value that you got
once you actually take in that action and once you've taken that action the
way you calculate the value is by looking at the next step and choosing the max to Singh if you take the best
action in the next state what is going to be the Q function so there's two estimators going on with in terms of
neural networks those two forward passes here there's two Q's in this equation so in traditional DQ n that's just that's
done by a single neural network with a few tricks and double DQ n that's done
by two neural networks and I mentioned tricks because with this and with most
of RL tricks tell a lot of the story a lot of what makes
systems work is the details in in games and robotic systems in these cases the
two biggest tricks for DQ n that will reappear and a lot of value based methods is experience replay so think of
an agent that plays through these games as also collecting memories you collect
this bank of memories that can then be replayed the power of that one of the
central elements of what makes value based methods attractive is that because
you're not directly estimating the policy but are learning the quality of taking an action in a particular state
the you're able to then jump around through your memory and and play
different aspects of that memory so learn train the network through the
historical data and then the other trick simple is like I said that there is so
the loss function has two queues so you're it's it's a dragon chasing its
own tail it's easy for the loss function to become unstable so the training does
not converge so the trick of fixing a target Network is taking one of the queues and only updating in every X
steps every thousand steps and so on and taking the same kind of network it's just fixing it so for the target
network that defines the loss function just keeping it fixed and only updating any regulator so you're chasing a fixed
target with a loss function as opposed to a dynamic one so you can solve a lot
of the Atari games with minimal effort come up with some creative solutions here break out here after 10 minutes of
training on the left after a to have 2 hours of training on the right is coming up with some creative solutions again
it's pretty cool because this is raw pixels right we're now like there's been
a few years since this breakthrough so kind of take it for granted but I still
for the most part captivated by just how beautiful it is that from the raw
sensory information neural networks are able to learn to act
in a way that actually supersedes humans in terms of creativity in terms of in terms of actual raw performance it's
really exciting and games of simple form is the cleanest way to demonstrate that and you the the same kind of DQ and
network is able to achieve superhuman performance and a bunch of different games there's improvements to this like dual
DQ one again the q function can be decomposed which is useful in to the
value estimate of being in that state and what's called and in future slides
that we called advantage so the advantage of taking action in that state the nice thing of the
advantage as a measure is that it's a measure of the action quality relative
to the average action that could be taken there so if it's very useful
advantage versus sort of raw reward is that if all the actions you have to take are pretty good you want to know well
how much better it is in terms of optimism that's a better measure for choosing
actions in a value-based sense so when you have these two estimates you have
these two streams for neural networking the dueling DQ n DG QM where one
estimates the value the other the advantage and that's again that dueling
nature is useful for also on the there are many states in which the action is
decoupled the quality of the actions is decouple from the state so many states
it doesn't matter which action you take so you don't need to learn all the
different complexities all the topology of different actions when you in a particular state and another one is
prioritize experience for play like I said experience replay is really key to these algorithms and the thing that
sinks some of the policy optimization methods and experiments replay is collecting different memories but if you
just sample randomly in those memories you're now affected the sampled
experiences are really affected by the frequency of those experience occurred not their importance so prioritize
experience replay assigns a priority a value based on the magnitude of the
temporal difference learned error so the the stuff you have learned the most from
is given a higher priority and therefore you get to see through the experience
replay process that that particular experience more often okay moving on to
Policy Gradient (PG)
policy gradients this is on policy versus q-learning off policy policy
gradient is directly optimizing the policy where
the input is the raw pixels and the policy network represents the forms of
representations of that environment space and as output produces a stochastic estimate a probability of the
different actions here in the pong the pixels a single output that produces the
probability of moving the paddle up so how do pause gradients vanilla policy grading the very basic works is you
unroll the environment you play through the environment here pong moving the
paddle up and down and so on collecting no rewards and only collecting reward at
the very end based on whether you win or lose every single action you're taking
along the way gets either punished or rewarded based on whether it led to victory or defeat this also is
remarkable that this works at all because the credit assignment there's a is I mean every single thing you did
along the way is averaged out it's like muddied it's the reason that policy
gradient methods are more inefficient but it's still very surprising that it works at all so the pros versus DQ one
the value based methods is that if the world is so messy that you can't learn a q function the nice thing about policy
gradient because it's learning the policy directly that it will at least learn a pretty good policy usually in
many cases faster convergence it's able to deal with stochastic policies so value based methods can out learners the
gassing policies and it's much more naturally able to deal with continuous actions the cons is it's inefficient
versus dqn it's it can become highly
unstable as we'll talk about some solutions to this during the training process and the credit assignment so if
we look at the chain of actions that lead to a positive reward some might be
awesome action some may be good action some might be terrible actions but that doesn't matter as long as the death
the nation was good and that's then every single action along the way gets a positive reinforcement that's the
downside and there's now improvements to that advantage actor critic methods a to see combining the best of value based
Advantage Actor-Critic (A2C & A3C)
methods and policy base methods so
having an actor two networks an actor which is policy based and that's the one
that's takes the actions samples the actions from the policy Network and the critic that measures how good those
actions are and the critic is value based all right so as opposed to in the
policy update the first equation there the reward coming from the destination the that our war being from whether you
won the game or not every single step along the way you now learn a Q value
function Q s a state and action using the critic Network so you're able to now
learn about the environment about evaluating your own actions at every step so you're much more sample
efficient there's a synchronous from deep mind and synchronous from open AI
variants of this but of the actor advantage actor critic framework but
both are highly parallelizable the difference with a three C the
asynchronous one is that every single agency just throw these agents operating
in the environment and they're learning they're rolling out the games and getting the reward they're updating the
original Network asynchronously the global network parameters asynchronously
and as a result they're also operating constantly an outdated versions of that
network the open AI approach that fixes this is that there's a coordinator that
there's these rounds where everybody all the agents in parallel are rolling out
the episode but then the coordinator waits for everybody to finish in order to make the update to the global network
and then distributes all the same parameter to all the agents and so that means that
every iteration starts with the same global parameters and that has really nice properties in terms of conversions
and stability of the training process okay from google deepmind the deep
Deep Deterministic Policy Gradient (DDPG)
deterministic policy gradient is combining the ideas of dqn but dealing
with continuous action spaces so taking a policy network but instead of the
actor actor critic framework but instead of picking a stochastic policy having
the actor operator on the since the casting nature is picking the best picking a deterministic policy so it's
always choosing the best action but ok with that the problem quite naturally is
that when the policy is now deterministic it's able to do continuous action space but because it's termina
stick it's never exploring so the way we inject exploration into the system is by adding noise either adding noise into
the action space on the output or adding noise into the parameters of the network that have then that create perturbations
and the actions such that the final result is that you try different kinds of things and the the scale of the noise
just like well the epsilon greedy in the exploration for DQ on the scale of the noise decreases as you learn more and
more so on the policy optimization side from open ai and others
Policy Optimization (TRPO and PPO)
we'll do a lecture just on this there's been a lot of exciting work here the
basic idea of optimization on policy optimization with PPO and TRP au is
first of all we want to formulate reinforcement learning as purely an
optimization problem and second of all if policy optimization the actions you
take influences the rest of your the optimization process you have to be very
careful about the actions you take in particular you have to avoid taking
really bad actions when you're convergence the the training performance in general collapses so how do we do
that there's the line search methods which is where gradient descent or gradient descent falls under which which is the
how we train deep neural networks is you first pick a direction of the gradient
and then pick the step size the problem with that is that can get you into
trouble here there's a nice visualization walking along a ridge is
it can it can result in you stepping off that Ridge again the collapsing of the
training process the performance the trust region is is the underlying idea
here for the for the policy optimization methods that first pick the step size so
that constrain in various kinds of ways the the magnitude of the difference to
the weights that's applied and then the direction so it placing a much higher
priority not choosing bad actions that can throw you off the optimization path should actually we should take to that
path and finally the on the model-based methods and we'll also talk about them
AlphaZero
in the robotics side there's a lot of interesting approaches now where deep
learning is starting to be used for a model-based methods when the model has to be learned but of course when the
model doesn't have to be learned it's given inherent to the game you know the model like Ingo and chess and so on out
zero has really done incredible stuff so what's wise what is the model here so
the way that a lot of these games are approached you know game of Go it's turn-based one person goes and then
another person goes and there's this game tree at every point as a set of actions that could be taken and quickly
if you look at that game tree it's it becomes you know a girl's exponentially so it becomes huge a game of go is the
hugest of all in terms of because the number of choices you have is the largest and there's chess and then you
know it gets the checkers and then tic-tac-toe and it's just the the degree at every step increases decreased based
on the game structure and so the task for a neural network there is to learn the quality of the board it's that it's
to learn which boards which game positions are most likely to result in a
are most useful to explore and a result in a highly successful state so that
choice of what's good to explore what's what branch is good to go down is where
we can have neural network step in and without phago it was pre trained the
first success that beat the world champion was pre trained on expert games then with alphago zero
it was no pre training on expert systems
so no imitation learning is just purely through self play through suggesting
through playing itself new board positions many of these systems use Monte Carlo tree search and during the
search balancing exploitation exploration so going deep on promising positions based on the estimation then
you'll network or with a flip of a coin playing under play positions and so this
kind of here you can think of as an intuition of looking at a board and estimating how good that board is and
also estimating how good that board is likely to lead to victory down the end
so as to mean just general quality and probability of leading to victory then
the next step forward is alpha zero using the same similar architecture with
MCTS what do you call it research but applying it to different games and
applying it and competing against other engines state-of-the-art engines and go
and shogi in chess and outperforming them with very few very few steps so
here's this model-based approaches which are really extremely simple efficient if
you can construct us such a model and in in the robotics if you can learn such a model I can be exceptionally powerful
here beating the the engines which are
far superior to humans already stockfish can destroy most humans on earth at the
game of chess the ability through learning through through estimating the quality of a board to be able to defeat
these engines is incredible and the the exciting aspect here versus engines that
don't use neural networks is that the number its it really has to do with
based on the neural network you explore certain positions you explore certain
parts of the tree and if you look at grandmasters human players in chess they
seem to explore very few moves they have a really good neural network at estimating which are the likely branches
which would provide value to explore and on the other side stock fish and so on
are much more brute force in their estimation for the MCTS and then alpha
zero is a step towards the Grandmaster is the number of branches need to be explored as much much fewer a lot of the
work is done in the representation form by the neural network it's just super exciting and then it's able to uh
perform stockfish in chess it's able to outperform Elmo and shogi and it's
itself in go or the previous iterations of alphago zero and so on now the
Deep RL in real-world applications
challenge here the sobering truth is that majority of real world application
of agents that have to act in this world perceive the world and act in this world are for the most part not based have no
RL involved so the action is not learned use neural networks to perceive certain
aspects of the world but ultimately the action is not is not learned from data
that's true for all most of the autonomous vehicle companies are all of the autonomous vehicle companies
operating today and it's true for robotic manipulation in the industrial
robotics and any of the humanoid robots have to navigate in this world under uncertain conditions all the work from
Boston Dynamics doesn't involve any machine learning as far as we know now
that's beginning to change here with animal the the recent development where
the certain aspects of the control a robotic could be learned
you're trying to learn more efficient movement you're trying to learn more robust movement on top of the other
controllers so it's quite exciting through RL to be able to learn some of
the control dynamics here that's able to teach this particular robot to be able
to get up from arbitrary positions so it's less hard coding in order to be able to deal with unexpected nishal
conditions and unexpected perturbations so that's exciting there in terms of
learning the control dynamics and some of the driving policy so maybe behavioral driving behavior
decisions changing lanes turning and so on that if you if you were here last week heard
from way moe they they're starting to use some RL in terms of the driving policy in order to especially predict the future they're
trying to anticipate intent modeling predict what the pedestrians the cars are going to be based on environment that are trying to
unroll what's happened recently into the future and beginning to move beyond sort
of pure end to end on NVIDIA and to end learning approach of the control decisions are actually moving to
RL and making long-term planning decisions but again the challenge is the
Closing the RL simulation gap
the gap the leap needed to go from simulation to real-world all most the
work is done from the design of the environment and the design and the reward structure and because most of
that work now is in simulation we need to either develop better algorithms for transfer learning or close the distance
between simulation in the real world and also we could think outside the box a
little bit at the conversation with Peter bill recently one of the leading researchers in deep RL it kind of on the
side quickly mentioned the the idea is that we don't need to make simulation
more realistic what we could do is just create an infinite number of simulations
or very large number of simulations and the naturally the regularization aspect
of having all those simulations will make it so that our our reality is just another sample from those simulations
and so maybe the solution isn't to create higher fidelity simulation or to create transfer learning algorithms
maybe it's to build a arbitrary number
of simulations so then that step towards creating a agent that work that works in
the real world is a trivial one and maybe that's exactly whoever created the
simulation we're living in and the multiverse that we're living in did next
Next step in Deep RL
steps the lecture videos will have several in RL will be made all available
on deep learning that MIT ID you will have several tutorials in RL on github
the link is there and I really like the essay from open AI on spinning up as a
deep our researcher you know if you're interested in getting into research in RL what are the steps need to take from
the background of developing the mathematical background prop stat and multivariate calculus to some of the
basics like it's covered last week on deep learning some the basics ideas in RL just terminology
and so on some basic concepts then picking a framework tends to flow our PI torch and learn by doing i implemented
guram as i mentioned today those are the core RL algorithms so implement all isms
from scratch it should only take about two hundred three hundred lines of code there actually when you put it down on
paper quite simple intuitive algorithms and then read papers about those
algorithms that follow after looking not for the big waving performance the hand
waving performance but for the tricks that were used to change these algorithms the tricks tell a lot of the
story and that's the useful parts that they need to learn and iterate fast on
simple benchmark environments so open the I Jim has provided a lot of easy to use environments that you can play with
that you can train an agent in minutes hours as opposed to days and weeks and
so iterating fast is the best way to learn these algorithms and then on the research side there's three ways to get
a best paper award right two to publish and to contribute and have an impact in
the research community in in RL one is improving existing approach given us a
particular benchmarks there's a few benchmark datasets environments that are emerging so you want to improve on the
existing approach some aspect of the convergence in the performance you can focus on an unsolved task there's
certain games that just haven't been solved through their RL formulation or
you can come up with a totally new problem that hasn't been addressed by RL before so with that I'd like to thank
you very much tomorrow I'll hope to see you here for deep traffic Thanks

----------

-----

--56--

-----
Date: 2019.01.19
Link: [# Tomaso Poggio: Brains, Minds, and Machines | Lex Fridman Podcast #13](https://www.youtube.com/watch?v=aSyZvBrPAyk)
Transcription:

the following is a conversation with Tommaso poggio he's the professor at MIT and as a director of the Center for
brains minds and machines sited over 100,000 times his work has had a
profound impact on our understanding of the nature of intelligence in both biological and artificial neural
networks he has been an advisor to many highly impactful researchers and entrepreneurs
in AI including demis hassabis of deep mind I'm nacho of mobile eye and
Christof Koch of the Allen Institute for brain science this conversation is part
of the MIT course on artificial general intelligence and the artificial intelligence podcast if you enjoy it
subscribe on youtube itunes or simply connect with me on twitter at Lex Friedman spelled Fri D and now here's my
conversation with Tommaso poggio you've mentioned that in your childhood you've
developed a fascination with physics especially the theory of relativity and that Einstein was also a childhood hero
to you what aspect of Einstein's genius the nature was genius do you think was
essential for discovering the theory of relativity you know Einstein was a hero
to me and I'm sure to many people because he was able to make of course a
major major contribution to physics with
simplifying a bit just a Gedanken experiment a fourth experiment you know
imagining communication with Lights between a stationary observer and
somebody on a train and I thought you know the the fact that just with the
force of his fault of his thinking of his mind he could guide to some
something so deep in terms of physical reality how time depend on space and
speed it was something absolutely fascinating was the power of
intelligence the power of the mind do you think the ability to imagine to
visualize as he did as a lot of great forces sister do you think that's in all of us
human beings or is there something special to that one particular human being I think you know all of us can
learn and have in principle similar
breakthroughs there are lesson to be learned from Einstein he was one of five PhD students
at ETA and the ID Canarsie technician actua in Zurich in physics and he was
the worse of the five but the only one who did not get an academic position
when he graduated well finished his PhD and he went to work as everybody knows
for the Patent Office and so it's not so much the work for the Patent Office but
the fact that obviously it was marked but he was not the top student obviously
was the anti conformist I was not thinking in the traditional way that
probably stitches and the other students were doing so there is a lot to be said
about you know trying to be to do the opposite or something quite different
from what other people are doing that's actually true for the stock market never never buy for very bodies by and
also true for science yes so you've also mentioned staying on a theme of physics
that you were excited and a young age by the mysteries of the universe that
physics could uncover such as I saw mentioned the possibility of time travel
so the most out-of-the-box question I think I'll get to ask today do you think time travel is possible well it would be
nice if it were possible right now you know you in science you never say no
but your understanding of the nature of time yeah it's very likely that it's not
possible to travel in time you may be able to travel forward in time
if we can for instance freeze ourselves or you know go on some spacecraft
traveling close to the speed of light but in terms of activity traveling for
instance back in time I find probably very unlikely so do you still hold the
underlying dream of the engineering intelligence that will build systems
that are able to do such huge leaps like discovering the kind of mechanism that
would be required to travel through time do you still hold that dream or are echoes of it from your childhood yeah I
you know I don't think whether there are certain problems that probably cannot be
solved depending what what you believe about the physical reality like you know
maybe totally impossible to create energy from nothing or to travel back in
time but about making machines that can
think as well as we do or better or more likely especially in the short and
midterm helped us think better which is in a sense is happening already with the
computers we have and it will happen more and more but that I certainly believe and I don't see in principle why
computers at some point could not become more intelligent than we are although
the word intelligence it's a tricky one and one who should discuss which I mean
with that in intelligence consciousness yeah words like love is all these are
very you know you need to be disentangled so you've mentioned also that you believe the problem of
intelligence is the greatest problem in science greater than the origin of life and the origin the universe you've also
in the talk I've listened to said that you're open to arguments against against
you so what do you think is the most captivating aspect of this problem of
understanding the nature of intelligence why does it captivate you as it does
well originally I think one of the motivation that I had as I guess a
teenager when I was infatuated with theory of relativity was really that I I
found that there was the problem of time and space and general relativity but
there were so many other problems of the same level of difficulty and importance
that I could even if I were I stein it was difficult to hope to solve all of
them so what about solving a problem whose solution allowed me to solve all
the problems and this was what if we could find the key to an intelligence
you know ten times better or faster than Einstein so that's sort of seeing
artificial intelligence as a tool to expand our capabilities but is there
just an inherent curiosity in you and just understanding what is in our in
here that makes it all all work yes absolutely all right so I was starting I
started saying this was the motivation when I was a teenager but you know soon
after I think the problem of human intelligence became a real focus of you
know of my sent my science and my research because I think he's for me the
most interesting problem is really asking oh we we are right is asking not
only a question about science but even about the very tool we are using to do
science which is our brain how does our brain work from where does it come from
after its limitation can we make it better and that in many ways is the ultimate
question that underlies this whole effort of science so you've made
significant contributions in both the science of intelligence and the engineering event
in a hypothetical way let me ask how far do you think we can get in creating
intelligent systems without understanding the biological the
understanding how the human brain creates intelligence put another way do you think we can build a strong-ass system without really
getting at the core the functionally understanding the functional nature of the brain well this is a real difficult
question you know we did solve problems
like flying without really using too
much our knowledge about how birds fly it was important I guess to know that
you could have things heavier than than air being able to fly like like birds
but beyond that probably we did not learn very much you know some you know
the brothers right did learn a lot of observation about birds and designing
their their aircraft but you know you can argue we did not use much of biology
in that particular case now in the case of intelligence I think that it's it's a
bit of a bet right now if you are if you ask okay we we all
agree we'll get at some point maybe soon maybe later to a machine that is
indistinguishable from my secretary say in terms of what I can ask the machine
to do I think we get there and now the question is and you can ask people do
you think we'll get there without any knowledge about you know the human brain or that is the best way to get there is
to understand better the human brain yeah okay this is I think an educated
bet that different people with different background will decide in different ways
the recent history of the progress in AI in the last out say five years or ten
years is has been that the main breakthroughs
the main recent breakthroughs I really start from neuroscience
mention reinforcement learning as one is one of the algorithms at the core of
alphago which is the system that beat the kind of an official world champion
of go lee sedol and two three years ago in seoul that's one and that started
related with the work of Pavlov and I'll or hundred Marvin Minsky in the sixties
many other neuroscientists later on and deep learning started which is the core
again of alphago and systems like autonomous driving systems for cars like
the systems that mobile I which is a company started by one of my exposed or
Colonel Joshua did so that is a core of those things and deep learning really
the initial ideas in terms of the architecture of this layered ARCIC on networks started with work of Torsten
Wiesel and David Hubel at Harvard up the river in the 60s so recent history
suggests the neuroscience played a big role in these breakthroughs my personal
bet is that there is a good chance they continue to play a big role maybe not in
all the future breakthroughs but in some of them at least in inspiration so at least in a new spirit absolutely yes so
you see you studied both artificial and biological neural networks you said these mechanisms that underlie deep
learning deeper and reinforcement learning but there is nevertheless
significant differences between biological and artificial neural networks as they stand now so between
the two what he finds the most interesting mysterious maybe even
beautiful difference as it currently stands in our understanding I must
confess that until recently I found that the artificial networks
too simplistic relative to real neural networks but you know recently I've been
started to think that yes there are a very big simplification of what you find
in the brain but on the other hand there are much closer in terms of the
architecture to the brain than other models that we had that computer science
used as model of thinking which were mathematical logics you know Lisp Prolog
and those kind of things yeah so in comparison to those they're much closer
to the brain you have networks of neurons which is what the brain is about
and the artificial neurons in the models are as I said caricature of the
biological neurons but they're still neurons single units communicating with other units something that is absent in
you know the traditional computer type models of mathematics reasoning and so
on so what aspect is would you like to see in artificial neural networks added
over time as we try to figure out ways to improve them so one of the main
differences and you know problems in
terms of deep learning today and it's not only deep learning and the brain is
the need for deep learning techniques to have a lot of labeled examples you know
for Easter for imagenet you have like a training site which is 1 million images each one labeled by some human in terms
of which object is there and it's it's clear that in biology a baby may be able
to see million of images in the first years of life but will not have million
of labels given to him or her by parents or take
take care takers so how do you solve that you know I think there is this
interesting challenge that today deep learning and related techniques are all
about big data big data meaning a lot of examples labeled by humans
whereas in nature you have so that this
big data is n going to infinity that's the best you know and meaning labeled
data but I think the biological world is more n going to one Hey a child can
learn the beautiful wrote a very small number of you know labeled examples like
you tell a child this is a car you don't need to say like imagenet you know this
is a car this is a car this is not a car this is not a cat 1 million times so and
of course with alphago and or at least alpha 0 variants there's because of the
because the world of go is so simplistic that you can actually learn by yourself
through self play you could play against each other and the real world i meet the visual system that you've studied
extensively is a lot more complicated than the game of go so under comment
about children which are fascinatingly good at learning new stuff how much of
it do you think is hardware how much of it is software you know that's a good deep question is in a sense is the old
question of nurture and nature how much isn't in the gene and how much is in the
experience of an individual obviously it's both that play a role and i believe
that the way evolution gives put prior information so
to speak hard while it's not really hard while but that's essentially an
hypothesis I think what's going on is that evolution as you know almost
necessarily if you believe in Darwin is very opportunistic and and think about
our DNA and the DNA of Drosophila our
DNA does not have many more genes than resolve around the fly the fly the fruit
fly now we know that the fruit fly does not learn very much during its
individual existence it looks like one of this machinery that it's really
mostly not hundred percent but you know 95 percent hard coded by the genes
but since we don't have many more genes than Drosophila as evolution could
encoding as a kind of general learning machinery and then had to give very weak
priors like for instance let me take
give a specific example which is recent to work by a member of our Center for
brains minds and machines we know because of work of other people in our
group and other groups that there are cells in a part of our brain neurons that are tuned to phases they seems to
be involved in face recognition now this face area exists seems to be present in
young children and adults and one
question is is there from the beginning is hardwired by evolution or you know
somehow is learned very quickly so what's your by the way a lot of the questions I'm asking with the answer is
we don't really know but as a person who has contributed some profound ideas in
these fields you're a good person to guess at some of these so of course there's a caveat before a lot of the
stuff we talk about but what is your hunch is the face the part of the brain
that that seems to be concentrated on face recognition are you born with that or you just is designed to learn that
quickly like the face of the mother and I my hand shimmer by bias was the second
one learned very quickly and it turns out that Marge Livingstone at Harvard
has done some amazing experiments in which she raised baby monkeys depriving
them of faces during the first weeks of life so they see technicians but the
technician have a mask yes and and so
when they looked at the area in the brain of this monkeys
that were usually find faces they found no face preference so my guess is that
what evolution does in this case is there is a plastic Canaria which is
plastic which is kind of predetermined to be imprinted very easily but the
command from the gene is not detailed circuitry for a face template could be
but this will require probably a lot of bits you had to specify a lot of connection of a lot of neurons instead
that the command that commands from the gene is something like imprint memorized
what you see most often in the first two weeks of life especially in connection
with food and maybe nipples I don't write well source of food and so in then
that area is very plastic at first and in the otherwise I'd be interesting if a variant of that experiment would show a
different kind of pattern associated with food than a face pattern well whether that quite stick there are
indications that during that experiment what the monkey saw quite often where
the blue gloves of the technicians that were giving to the baby monkeys the milk
and some of the cells see instead of being face sensitive in that area or a
hand sensitive that's fascinating can you talk about what are the
different parts of the brain and in your view sort of loosely and how do they
contribute to intelligence do you see the brain as a bunch of different modules and they together come in the
human brain to create intelligence or is it all one mush of the same kind of
fundamental architecture yeah that's you
know that's an important question and there was a phase in neuroscience by
in the 1950 or so in which it was believed for a while that the brain was
equipotential this was the term you could cut out a piece and nothing
special happened apart a little bit less performance there was a a surgeon
Lashley did a lot of experiments of this type with mice and rats and concluded
that every part of the brain was essentially equivalent to any other one
it turns out that that's that's really not true it's there are very specific
modules in the brain as you said and you know people may lose the ability to
speak if you have a stroke in a certain region or may lose control of their legs
in another region or so they're very specific the brain is also quite
flexible and redundant so often it can correct things and you know the kind of
takeover functions from one part of the brain to the other but but but really
there are specific modules of the answer that we know from this old work which
was basically on based on lesions either on animals or very often there were a
mine of well it there was a mine a very interesting data coming from from the
war from different types of injuries injuries that soldiers had in the brain
and more recently functional MRI which
allow you to to check which part of the brain are active when you are doing
different tasks as you know can replace
some of this you can see that certain parts of the brain are involved or
active in this language yeah yeah that's right but sort of taking a step back to that
part of the brain that discovers that specializes in the face and how that might be learned what's your intuition
behind you you know is it possible that the sort of from a physicists
perspective when you get lower and lower that it's all the same stuff and it just when you're born it's plastic and it
quickly figures out this part is going to be about vision this is gonna be about language this is about common
sense reasoning do you have an intuition that that kind of learning is going on really quickly or is it really kind of
solidified in hardware that's a great question so there are parts of the brain
like the cerebellum or they put campus that are quite different from each other
they clearly have different Anatomy different connectivity that then there
is the cortex which is the most
developed part of the brain in humans and in the cortex you have different
regions of the cortex that are responsible for vision for audition for
motor control for language now one of the big puzzles of of this is that in
the cortex is the cortex is the cortex it looks like it is the same in terms of
hardware in terms of type of neurons and connectivity across these different
modalities so for the cortex letting
aside these other parts of the brain like spinal cord upon campus or bedroom and so on for the cortex I think your
question about hardware and software and learning and so on it's it I think is
rather open and you know it I find very
interesting for easy to think about an architecture computer architecture that
is good for vision and the symptom is good for language seems to be you know
so different problem areas that you have
to solve but the underlying mechanism might be the same that's really instructive for it maybe artificial
neural networks so you've done a lot of great work in vision and human vision
computer vision and you mentioned the problem of human vision is really as
difficult as the problem of general intelligence and maybe that connects to the cortex discussion can you describe
the human visual cortex and how the humans begin to understand
the world through the raw sensory information the woods for folks enough
familiar especially in on the computer vision side we don't often actually take
a step back except saying what the sentence or two that one is inspired by the other well what is it that we know
about the human visual cortex that's interest so we know quite a bit at the same time we don't know a lot but the
the bit we know you know in a sense we know a lot of the details and Men we
don't know and we know a lot of the top level the answer the top level question
but we don't know some basic ones even in terms of general neuroscience forgetting vision you know why do we
sleep it's such a basic question and we
really don't have an answer to that do you think so taking a step back on that so sleep for examples fascinating do you
think that's a neuroscience question or if we talk about abstractions what do
you think is an interesting way to study intelligence or are most effective on the levels of abstractions the chemicals
the biological is electro physical mathematical as you've done a lot of excellent work on that side which
psychology is sort of like at which level of abstraction do you think well in terms of levels of abstraction I
think we need all of them all hits when you know it's like if you ask me what
does it mean to understand the computer right that's much simpler but in a computer I could say well I understand
how to use PowerPoint that's my level of understanding a computer it's it has
reasonable you know give me some power to produce lights and beautiful slides and now the class on body exercise well
I I know how the transistor work that are inside the computer I can write the equation for you know transistor and
diodes and circuits logical circuits and I can ask this guy do you know how
to operate PowerPoint no idea so do you think if we discovered computers walking
amongst us full of these transistors that are also operating under windows
and have PowerPoint do you think it's digging in a little bit more how useful
is it to understand the transistor in order to be able to understand
PowerPoint and these higher-level very good intelligence I see so I think in the case of computers because they were
made by engineers by us this different level of understanding are rather
separate on purpose you know you there are separate modules so that the
engineer that designed the circuit for the chips does not need to know what power is inside PowerPoint and somebody
you can write the software translating from one to the end to the other and so
in that case I don't think understanding the transistor help you understand
PowerPoint or very little if you want to understand the computer this question
you know I would say you have to understanding a different levels if you really want to build one right but but
for the brain I think these levels of understanding so the algorithms which
kind of computation you know the equivalent of PowerPoint and the circuits you know the transistors I
think they are more much more intertwined with each other there is not you know in Italy level of the software
separate from the hardware and so that's why I think in the case of the brain a
problem is more difficult or more than four computers requires the interaction
the collaboration between different types of expertise that's a big the brain is a big mess
you can't just on disentangle a level I think you can but is is much more
difficult and it's not you know it's not completely obvious and and I said I think he's one of the
person everything is the greatest problem in science so yeah you know I think he's it's fair that it's difficult
one that said you do talk about compositionality and why I might be
useful and when you discuss what why these neural networks in artificial or biological sense learn anything you talk
about compositionality see there's a sense that nature can be disentangled
our purpura well all aspects of our cognition could
be disentangled a little to some degree so why do you think what first of all
how do you see compositionality and why do you think it exists at all in nature
it spoke about I use the the term
compositionality when we looked at deep neural networks
multi-layers and trying to understand when and why they are more powerful than
more classical one layer network like linear classifier kernel machines
so-called and what we found is that in
terms of approximating or learning or representing a function a mapping from
an input to an output like from an image to the label in the image if this
function as a particular structure then deep networks are much more powerful
than shallow networks to approximate the underlying function and the particular
structure is a structure of compositionality if the function is made
up of functions of function so that you need to look on when you are
interpreting an image classifying an image you don't need to look at all
pixels at once but you can compute something from small groups of pixels
and then you can compute something on the output of this local computation and
so on that is similar to what you do when you read the sentence you don't need to read the first and the last
letter but you can read syllables combine them in words combine the words
in sentences so this is this kind of structure so that's as part of the
discussion of why deep neural networks may be more effective than the shallow methods and is your sense for most
things we can use neural networks for those problems are going to be
compositional in nature like like language like vision how far can we get
in this kind of right so here is almost philosophy well you
know there yeah let's go there so a friend of mine max tegmark who is a
physicist at MIT I've talked to him on this thing yeah and he disagrees with you right yeah but we you know we agree
most but the conclusion is a bit differently he is conclusion is that for images for
instance the compositional structure of this function that we have to learn or
to solve these problems comes from physics comes from the fact that you
have local interactions in physics between atoms and other atoms between
particle of matter and other particles between planets and other planets
between stars that it's all local and
that's true but you could push this argument a bit further not this argument
actually you could argue that you know maybe that's part of the true but maybe
what happens is kind of the opposite is that our brain is wired up as a deep
network so it can learn understand solve
problems that I have this compositional structure and I cannot do they cannot
solve problems that don't have this compositional stretch so the problem is we are accustomed to we think about we
test our algorithms on our this compositional structure because our
brain is made up in that's in a sense an evolutionary perspective as we've so the
ones that didn't have the they weren't dealing with a compositional nature of reality died off yes it also could be
may be the reason why we have this local connectivity in
the brain like simple cells in cortex looking only the small part of the B
image each one of them and another says looking at it small number of these simple cells and so on the reason for
this may be purely that was difficult to grow longer range connectivity so
suppose it's you know for biology it's possible to grow short range
connectivity but not longer and also because there is a limited number of long range the Duke and so you have at
this this limitation from the biology and this means you build a deep
convolutional neck this would be something like deep convolutional network and this is great for solving
certain class of problem these are the ones we are we find easy and important
for our life and yes they were enough for us to survive and and you can start
a successful business on solving those problems right mobile a driving is a
compositional problem right so on the unlearning task i mean we don't know
much about how the brain learns in terms of optimization but so the thing that's
stochastic gradient descent is what artificial neural networks used for the
most part to adjust the parameters in such a way that it's able to deal based
on the label data it's able to solve the problem yeah so what's your intuition
about why it works at all a heart of a
problem it is to optimize in your own network artificial neural network is
there other alternatives you're just in general your intuition is
behind this very simplistic algorithm that seems to do pretty good surprising yes yes so I find near of science the
the architecture of cortex it's a really similar to the architecture of deep networks so that
there is a nice correspondence there between the biology and this kind of
local connectivity hierarchical architecture the stochastic gradient
descent as you said is is a very simple technique
it seems pretty unlikely that biology
could do that from from what we know right now about you know cortex and neurons and synapses
so it's a big question open whether there are other optimization learning
algorithms that can replace stochastic gradient descent and my my guess is yes
but nobody has found yet a real answer I
mean people are trying still trying and there are some interesting ideas the
fact that stochastic gradient descent is so successful this has become clear is
not so mysterious and the reason is that it's an interesting fact you know it's a
change in a sense in how people think about statistics and and this is the
following is that typically when you had
data and you had say a model with parameters you are trying to fit the
model to the data you know to fit the parameter typically the kind of kind of
crowd wisdom type idea was you should
have at least you know twice the number of data than the number of parameters
you maybe 10 times is better now the way
you train neural net or this disease that I have they have 10 or 100 times
more parameters than did exactly the opposite and which you know it is it has
been one of the puzzles about neural networks how can you get something that really works when you have so much
freedom in its in from that Laura Derek in general right somehow right exactly
do you think this the stochastic nature is essential to randomness so I think we have some initial understanding why this
happens but one nice side effect of
having this over parameterization more parameters than data is that when you
look for the minima of a loss function like stochastic gradient descent is doing in find I I made some calculations
based on some old basic theorem of algebra called
bazoo theorem and that gives you an estimate of the number of solution of a
system of polynomial equation anyway the bottom line is that there are probably
more minima for a typical deep networks
than atoms in the universe just to say there are lost because of the over
parametrization a more global minimum zero meaning good
meaning so it's not just local minima yeah a lot of them so you have a lot of
solutions so it's not so surprising that you can find them relatively easily and
this is why this is because of the overall parameterization the organization sprinkles an entire space
for solutions pretty good and so not so surprising right is like you know if you
have a system of linear equation and you have more unknowns than equations then
you have we know you have an infinite number of solutions and the question is
to pick one that's another story but you have an infinite number of solutions so there are a lot of value of your
unknowns that satisfy the equations but it's possible that there's a lot of
those solutions that aren't very good what's surprising so that's a good question why can you pick one the
generalizes one yeah that's a separate question with separate answers one one
theorem that people like to talk about that kind of inspires imagination of the
power in your networks is the universality a universal approximation theorem you can approximate any
computable function with just a finite number of neurons and a single hidden layer see you find this theorem one
surprising you find it useful interesting inspiring now this one you
know I never found it very surprising it's was known since the 80s
since I entered the field because it's basically the same as biased as the
which says that I can approximate any continuous function with a polynomial of
sufficiently with a sufficient number of terms monomials so basically the same
and the proves very similar so your intuition was there's never any doubt in
your networks in theory could the right be very strong approximate nicely the the question the interesting question is
that if this theorem
it says you can approximate fine but when you ask how many neurons for
instance or in the case of polynomial how many monomials I need to get a good
approximation then it turns out that
that depends on the dimensionality of your function how many variables you
have but it depends on the dimensionality of your function in a bad way it's for instance suppose you want
an error which is no worse than 10% in
your approximation you come up with a net of the approximate your function
within 10% then turns out that the
number of units you need are in the order of 10 to the dimensionality D how
many variables so if you have you know two variables is these 2 would you have
hundred units and okay but if you have say 200 by 200 pixel images now this is
you know 240 thousand whatever and we can go to the sizing universe pretty
quickly there are exactly 10 to the 40,000 and so this is called the curse
of dimensionality not you know quite appropriate and the hope is with the
extra layers you can remove the curse what we proved is that if you have deep
layers or a rocky core architecture that with the local connectivity of the type
of convolutional deep learning and if you are dealing with a function that has
this kind of hierarchical architecture then you avoid completely the curves
you've spoken a lot about supervised deep learning yeah what are your
thoughts hopes views on the challenges of unsupervised learning with the
with Ganz with the generator valor surround networks do you see those is
distinct that the power of Ganz does is distinct from supervised methods in your
networks are they really all in the same representation ballpark gains is one way
to get estimation of probability
densities which is somewhat new way but people have not done before I I don't
know whether this will really play an important role in you know in
intelligence or it's it's interesting I'm I'm less enthusiastic about it too
many people in the field I have the feeling that many people in the field are really impressed by the ability to
of producing realistic looking images in
this generative way which describes the popularity of the methods but you're saying that while that's exciting and
cool to look at it may not be the tool that's useful for yeah for so you
describe it kind of beautifully current supervised methods go and to infinity in terms of number of labelled points and
we really have to figure out how to go to and to one yeah and you're thinking ganz might help but they might not be
the right I don't think you for that problem which I really think is important I think they may help they
certainly have applications for instance in computer graphics and you know we I
did work long ago which was a little bit similar in terms of saying okay 11 network and I present
images and I can so input its images and
output is for instead the pose of the image you know a face how much is miling is rotated 45 degrees or not what about
having a network that I trained with the same dataset but now I invert input and
output now the input is the pose or the expression number certain numbers and
the output is the image and I train it and we did pretty good interesting results in terms of producing very
realistic looking images was you know less sophisticated mechanism but the
output was pretty less than gains but the output was pretty much of the same
quality so I think for computer graphics type application yeah definitely gains
can be quite useful and not only for that--for but for you know helping for
instance on this problem of unsupervised example of reducing the number of
labeled examples I think people it's
like they think they can get out more than they put in you know it there's no
free lunches Yeah right that's what do you think what's your intuition how can we slow the growth of
n to infinity in supervised and to infinity in supervised learning so for
example mobile I has very successfully I mean essentially annotated large amounts
of data to be able to drive a car now one thought is so we're trying to teach machines of AI and we're trying to so
how can we become better teachers maybe that's one one way now I got your you know what I like that because one
again one caricature of the history of computer sites you could say is with the
gains with programmers expensive yeah continuously labelers cheap yeah and the
future would be schools like we have for kids yeah currently the labeling methods were
not selective about which examples we we
teach networks with so I think the focus of making one-shot networks that learn
much faster is often on the architecture side but how can we pick better examples
with wish to learn do you have intuitions about that well that's part of the quarter program but the other one
is you know if we look at biology
reasonable assumption I think is in the
same spirit II that I said evolution is opportunistic and has weak priors you
know the way I think the intelligence of child the baby may develop is by
bootstrapping weak priors from evolution for instance in you can assume that you
are having most organisms including human babies built in some basic
machinery to detect motion and relative motion and in fact there is you know we
know all insects from fruit flies other animals they have this
even in the readiness of in the very peripheral part it's very conserved across species something that evolution
discovered early it may be the reason why babies tend to look in the first few
days to moving objects and not to not moving out now moving objects means okay
they are attracted by motion but motion also means that motion gives automatic
segmentation from the background so because of motion boundaries you know
either the object is moving or the eye of the baby is tracking the moving
object and the background is moving right yeah so just purely on the visual characteristics of the scene as seems to
be the most useful right so it's like looking at an object without background
it's ideal for learning the object otherwise it's really difficult because
you have so much stuff so suppose you do this at the beginning first weeks then
after that you can recognize the object now they're imprinted a number of even
in the background even without motion so that's at the by the way I just want to
ask an object recognition problem so there is this being responsive to movement and edge detection essentially
what's the gap between being effectively effective at visually recognizing stuff
detecting word that is and understanding the scene there is this a huge gap in
many layers or is it as a close no I think that's a huge gap
I think present algorithm with all the success that we have and the fact that
are a lot of very useful it's I think we are we are in a golden age for applications of low level vision and low
level speech recognition and so on you know Alexa and so there are many more things of similar
level to be done including medical diagnosis and so on but we are far from what we call understanding of a scene of
language of actions of people that is
despite the claims that's I think very far or a little bit off so in popular
culture and among many researchers some of which I've spoken with the sue Russell and you know a mask in and out
of the AAI field there's a concern about the existential threat of AI yeah and
how do you think about this concern in and is it valuable to think about
large-scale long-term unintended consequences of intelligent systems we
try to build I always think is better to worry first you know early rather than
late so some worry is good yeah I'm not against worry at all
personally I think that you know it will
take a long time before there is real reason to be worried but as I said I
think it is good to put in place and think about possible safety against what
I find a bit misleading are things like that I've been said by people I know
like Elon Musk and what is boström important notice first name a neck panic
poster right you know and a couple of other people that for instance a eyes
more dangerous the nuclear weapons right yeah I think that's really project that
can be it's misleading because in terms of priority which should still be more
worried about nuclear weapons and you know what people are doing about it and
some then a and he's spoken about them as obvious
and yourself saying that you think you'll be about a hundred years out
before we have a general intelligence system that's on par with the human being you have any updates for those
predictions what I think he said he's at 28 he said it went all right this was a couple of years ago I have not asked him
again so I should have your own prediction what's your prediction about
when you'll be truly surprised and what's the confidence interval or not you know it's so difficult to
predict the future and even the presence of it's nothing it's pretty hard to predict a bit I'll be but as I said this
is completely it would be more like rod Brooks I think he's about 200 years when
we have this kind of a GI system artificial general intelligence system you're sitting in a room with her him it
do you think it will be the underlying design of such a system is something
we'll be able to understand it will be simple do you think you'll be explainable understandable by us your
intuition again we're in the realm of philosophy a little bit but probably no
but it again it depends would you really mean for understanding
so I think you know we don't understand what how
deep networks work I think we're beginning to have a theory now but in
the case of deep networks or even in the case of the simple simpler kernel
machines or linear classifier we really don't understand the individual units
also we but we understand you know what the computation and the limitations and
the properties of it are it's similar to many things you know we what does it
mean to understand how a fusion bomb works how many of us you know many of us
understand the basic principle and some of us may understand deeper details in
that sense understanding is as a community as a civilization can we build another copy of it okay and in that
sense you think there'll be there will need to be some evolutionary component
where it runs away from our understanding or do you think it could be engineered from the ground up the
same way you go from the transistor to our point all right so many years ago this was
actually 40 41 years ago I wrote a paper with David Marr who was one of the
founding father of computer vision of computational dish I wrote a paper about
levels of understanding which is related to the question I discussed earlier about understanding power point
understanding transistors and so on and you know in that kind of framework we
had the level of the hardware and the top level of the algorithms we did not
have learning recently I updated adding levels and one level I added to those
free was learning so and you can imagine
you could have a good understanding of how you construct learning machine
like we do but being unable to describe
in detail what the learning machines will discover right now that would be
still a powerful understanding if I can build the learning machine even if I
don't understand in detail every time made it learn something just like our
children if they're if they start listening to a certain type of music I don't know Miley Cyrus or something you
don't understand why they came after that particular preference but you understand the learning process that I'm
very interesting yeah yeah so unlearning
for systems to be part of our world it has a certain one of the challenging
things that you've spoken about is learning ethics learning yeah morals and
what how hard do you think is the problem of first of all humans
understanding our ethics what is the origin and the neural a low level of ethics what is it at a higher level is
it something that's learner before machines in your intuition I think yeah
ethics is learnable very likely I I think I is one of these problems were
think understanding the neuroscience of
ethics you know people discuss there is an ethics of neuroscience yes you know
how a neuroscientist should or should not behave can you think of a neurosurgeon and the ethics are you Rory
has to behavior he she has to be but I'm more interested on the neuroscience of
you blow my mind right now the neuroscience of ethics is very matter yeah and you know I think that would be
important to understand also for being able to to design machines that have
that are ethical machines in our sense of ethics and you think there
is something in your science there's patterns tools in your science that can
help us shed some light on ethics or yeah mostly on the psychology sociology
much higher level no there is a culture but there is also in the meantime there are there is evidence fMRI of specific
areas of the brain that are involved in certain ethical judgment and not only
this you can stimulate those area with magnetic fields and change the ethical
decisions yeah Wow so that's work by a
colleague of mine Rebecca Saxe and there is a other researchers doing similar
work and I think you know this is the beginning but ideally at some point
we'll have an understanding of how this works and white of all right the big y
question yeah it must have some some purpose yeah obviously test you know
some social purpose is is probably if
neuroscience holds the key to at least eliminate some aspect of ethics that means it could be a learn about problem
yeah exactly and as we're getting into harder and harder questions let's go to the hard
problem of consciousness yeah is this an important problem for us to think about
and solve on the engineering of intelligence side of your work of our dream you know it's unclear so you know
again this is a deep problem part because it's very difficult to define
consciousness and and there is the debate among
neuroscientist and about whether
consciousness and philosophers of course whether consciousness is something that
requires flesh and blood so to speak yes
or could be you know that we could have
silicon devices that are conscious or up
to statement like everything has some degree of consciousness and some more
than others this is like Giulio Tononi and she would just recently talk to
Christophe Koch okay so he a crystal force my first graduate student yeah do
you think it's important to illuminate aspects of consciousness in order to
engineer intelligence systems do you think an intelligent system would ultimately have consciousness are they
to the interlinked you know most of the
people working in artificial intelligence I think who'd answer we don't strictly need the consciousness
to have an intelligent system that's sort of the easier question because yeah
because it's it's a very engineering answer to the question yes that's the Turing test will run in consciousness
but if you were to go do you think it's possible that we need to have so that
kind of self-awareness we may yes so for instance I I personally think that when
test a machine or a person in a Turing test in an extended to interesting I
think consciousness is part of what we
require in that test you know in priestly to say that this is intelligent
Christophe disagrees so as he does yeah it despite many other romantic notions
he who he disagrees with that one yes that's right so you know we would see do you think as
a quick question Ernest Becker fear of death
do you think mortality and those kinds of things are important for well for
consciousness and for intelligence the finiteness of life finiteness of
existence or is that just the side effect of evolutionary side effect is
useful to a for natural selection do you think this kind of thing that we're
gonna this interview is gonna run out of time soon our life will run out of time soon do you think that's needed to make
this conversation good and in life good you know I never thought about it is it a very interesting question I think
Steve Jobs in his commencement speech at Stanford argued that you know having a
finite life was important for for stimulating achievement so I was a different yeah I live every day like
it's your last right yeah yeah so I rationally I don't think strictly you
need mortality for consciousness but oh no they seem to go together in our
biological system yeah you've mentioned before and students are associated with
alpha go immobilize the big recent success stories in the eye and I think it's captivated the entire world of what
I can do so what do you think will be the next breakthrough and what's your
intuition about the next breakthrough of course I don't know where the next breakthroughs is I think that there is a
good chance as I said before that the next breakthrough would also be inspired by you know neuroscience
but which one I don't know and there's so MIT has this quest for
intelligence you know and there's a few moon shots which in that spirit which ones are you excited about what which
projects kind of well of course I'm excited about one of the moon shots with
it which is our Center for brains minds and machines history the one which is
filip fully funded by NSF and it's a it
is about visual intelligence it's an area that one has a particularly about
understanding visual intelligence or visual cortex and and visual
intelligence in the sense of how we look around ourselves and understand the word
around ourselves you know meaning what what is going on how we could go from
here to there without hitting obstacles you know whether there are other agents
people in the market these are all things that we perceive very quickly and
and it's something actually quite close to being conscious not quite but now
there is this interesting experiment that was run at Google X which is in a
sense is just a virtual reality experiment but in which they had subject
sitting in a chair with goggles like oculus and so on
earphones and they were seeing through the eyes of a robot nearby two cameras
microphones for a/c mossad their sensory system was there and the impression of
all the subject very strong they could not shake it off was that they were
where the robot was they could look at themselves from the robot and still feel
they were they were where the robot is they were looking their body their self
were had moved so some aspect of scene understanding has to have ability to
place yourself have a self-awareness about your position in the world and
what the world is right so yeah so we may have to solve the hard problem of
consciousness on their way yes but it's quite quite quite a moonshot eyes so if you've been an adviser to some
incredible minds including demis hassabis Christophe Co I'm not sure like
you said all went on to become seminal figures in their respective fields from
your own success as a researcher and from perspective as a mentor of these
researchers having guided them Madhvi so
what does it take to be successful in science and engineering careers whether
you're talking to somebody in their teens 20s and 30s what does that path
look like it's curiosity and having fun
and I think is important also having fun
with other curious minds it's the the
people you surround with - so yeah fun and curiosity is there mentioned Steve
Jobs is there also an underlying ambition that's unique that you saw or
is it really does boil down to insatiable curiosity and fun well of course you know it's been cured
using active and ambitious way yes
definitely but I think sometime in in science there are friends of mine who
are like this you know there are some of the scientists like to work by
themselves and kind of communicate only
when they complete their work or discover something I think I always
found the the actual process of you know
discovering something is more fun if it's together with other intelligent and
curious and fun people so if you see the fun in that process of the side effect of that process will be the election of
discovering something yes so as you've led many incredible efforts here what's
the secret to being a good advisor mentor leader in a research setting is that similar spirit or yeah what what
advice could you give to people young faculty and so on it's partly repeating
what I said about an environment that should be friendly and fun and ambitious
and you know I think I learned a lot from some of my advisers and friends and
some of our physicists and there was reason this behavior that was encouraged
of when somebody comes with a new idea in the group you're unless is really
stupid but you are always enthusiastic and then and the other two just for a
few minutes for a few hours then you start you know asking critically a few
questions testing but you know this is a process that is I think it's very very
good this you have to be enthusiasm time people are very critical from
beginning that's that's that's not yes you have to give it a chance yes let's
see to grow that said with some of your ideas which are quite revolutionary so there's a witness especially in the
human vision side and neuroscience side there could be some pretty heated arguments do you enjoy these dessert a
part of science and I could academic pursue see you enjoy yeah is it is that
something that happens in your group as well yeah absolutely I also spent some
time in Germany again that is this tradition in which people are more
forthright less kind than here so you
know in the u.s. you when you write a bad letter you still say this guy's nice
yes so yet here in America its degrees
of nice yes it's all just degrees of Nicaea right right so as long as this
does not become personal and it's really like you know a football game with these
rules that's great so if you somehow
found yourself in a position to ask one question of an Oracle like a genie maybe
a god whoa and you're guaranteed to get a clear answer what kind of question
would you ask what what would be the question you would ask in the spirit of
our discussion it could be how could be how could I become ten times more intelligent and so but see you only get
a clear short answer so do you think there's a clear short answer to that no
and that's the answer you'll get yeah okay so you've mentioned flowers of
Algren odd oh yeah this is a story that inspires you in your childhood as this
story of a mouse and human achieving genius-level intelligence and then
understanding what was happening while slowly becoming not intelligent again in this tragedy of
intelligence and losing intelligence do you think in that spirit and that story
do you think intelligence is a gift or curse from the perspective of happiness
and meaning of life you try to create intelligence system that understands the
universe but at an individual level the meaning of life do you think intelligence is a gift it's a good
question I don't know as one of this as one
people consider the smartest people in the world in some in some dimension at
the very least what do you think no no it may be invariant to intelligence
likely of happiness would be nice if it were that's the hope
yeah you could be smart and happy and clueless unhappy yeah as always on the
discussion of the meaning of life it's probably a good place to end Tommaso thank you so much for talking today
thank you this was great
you

----------

-----
--55-- 

-----
Date: 2019.01.17
Link: [# Deep Learning State of the Art (2019) - MIT](https://www.youtube.com/watch?v=53YvP6gdD7U)
Transcription:

The thing I would very much like to talk about today is the state of the art in deep learning.
Here we stand in 2019 really at the height of some of the great accomplishments
that have happened. But also stand at the beginning. And it's up to us to define where this incredible
data-driven technology takes us. And so I'd like to talk a little bit about the breakthroughs that happened in 2017 and 2018
that take us to this point. So this lecture is not on the state of the art results on
main machine learning benchmarks. So the various image classification and object detection
or the NLP benchmarks or the GAN benchmarks. This isn't about the cutting edge algorithm
that's available on github that performs best on a particular benchmark. This is about ideas
ideas and developments that are at the cutting edge of what defines this exciting field of deep learning.
And so I'd like to go through a bunch of different areas that I think they're really exciting.
Of course this is also not a lecture that's complete There's other things that may be totally missing that happened
in 2017-18 that are particularly exciting to people here and people beyond.
For example medical applications of deep learning is something I totally don't touch on.
And protein folding and all kinds of applications that there has been some exciting developments
from deep mind and so on that don't touch on. So forgive me if your favorite developments are missing
but hopefully this encompasses some of the really fundamental things that have happened
both on the theory side and the application side and then the community side of all of us being able to work
together on this and these kinds of technologies. I think 2018 in terms of deep learning is the year of
BERT and Natural Language Processing
natural language processing. Many have described this year as the ImageNet moment.
In 2012 for computer vision when AlexNet was the first neural network that really gave that big jump in performance.
And computer vision it started to inspire people what's possible with deep learning with purely learning based methods.
In the same way there's been a series of developments from 2016-17 led up to 18 with a development of BERT
that has made on benchmarks and in our ability to
apply NLP to solve various NLP tasks, natural language processing tasks a total leap.
So let's tell the story of what takes us there. There's a few developments. I've mentioned a little bit on Monday
about the encoder decoder or recurrent neural networks. So this idea of recurrent neural networks encode sequences of data
and output something, output either a single prediction or another sequence.
When the input sequence and the output sequence are not the same, necessarily the same size,
they're like in machine translation we have to translate from one language to another the encoder decoder architecture takes the following process.
It takes in the sequence of words or the sequence of samples as the input
and uses the recurrent units whether LSTM, GRU and beyond
and encodes that sentence into a single vector. So forms an embedding of that sentence of what it
represent, representation of that sentence. And then feeds that representation in the decoder
recurrent neural network that then generates the sequence of words that form
the sentence in the language that's being translated to. So first you encode by taking the sequence and
mapping it to a fixed size vector representation. And then you decode by taking that fixed size vector representation
and unrolling it into the sentence that can be of different length than the input sentence. Okay that's the encoder-decoder structure for recurrent neural networks
has been very effective for machine translation and dealing with arbitrary length input sequences,
arbitrary length output sequences. Next step attention.
What is attention? Well it's the next step beyond it's an improvement on the
the encoder-decoder architecture.
It allows the, it provides a mechanism that allows to look back at the input sequence.
So suppose to saying that you have a sequence that's the input sentence
and that all gets collapsed into a single vector representation. You're allowed to look back at the particular samples from the input sequence
as part of the decoding process. That's attention and you can also learn which aspects
are important for which aspects of the decoding process, which aspects the input sequence
are important to the output sequence. Visualize in another way
and there's a few visualizations here. They're quite incredible that are done by Jay Alammar.
I highly recommend you follow the links and look at the
further details of these visualizations of attention. So if we look at neural machine translation
the encoder RNN takes a sequence of words and throughout, after every sequence forms a set of
hidden representations, hidden state that captures the representation of the worlds that followed.
And those sets of hidden representations as opposed to being collapsed to a single fixed size vector, are then
all pushed forward to the decoder. That are then used by the decoder to translate
but in a selective way. Where the decoder here visualized on the y-axis
the input language and on the X the output language the decoder weighs the different parts of the input sequence differently
in order to determine how to best translate generate the word that forms a translation in the full output sentence.
Okay that's attention, allowing expanding the encoder-decoder architecture
to allow for selective attention to the input sequence
as opposed to collapsing everything down into fixed representation. Okay next step self-attention.
In the encoding process allowing the encoder to also
selectively look informing the hidden representations
at other parts of the input sequence in order to form those representations.
It allows you to determine for certain words.
What are the important relevant aspects of the input sequence that can help you encode that word the best?
So it improves the encoder process by allowing it to look at the entirety of the context. That's self-attention.
Building a transformer. It's using the self attention mechanism in the encoder
to form these sets of representations on the input sequence. And then as part of the decoding process follow the same
but in reverse with a bunch of self-attention that's able to look back again.
So it's self attention on the encoder attention on the decoder and that's where the magic, that's where the entirety magic is.
That's able to capture the rich context of the input sequence in order to generate
in the contextual way the output sequence. So let's take a step back then and look at what is critical to natural language
in order to be able to reason about words, construct a language model
and be able to reason about the words in order to classify a sentence or translate a sentence
or compare two sentences and so on. There the sentences are collections of words or characters
and those characters and words have to have an efficient representation that's meaningful for that kind of understanding.
And that's what the process of embedding is. We talked a little bit about it on Monday. And so the traditional Word2Vec  process of
embedding is you use some kind of trick in an unsupervised way to map words into
into a compressed representation. So language modeling is the process of determining
which words follow each other usually. So one way you can use it as in a skip gram model
taking a huge datasets of words you know, there's writing all over the place taking those datasets
and feeding a neural network that in a supervised way looks
at which words are usually follow the input. So the input is a word the output is which word are
statistically likely to follow that word. And the same with the preceding word. And doing this kind of unsupervised learning
if you throw away the output and the input and just taking the hidden representation form in the middle
that's how you form this compressed embedding a meaningful representation that when
two words are related in a language modeling sense, two words that are related they're going to be in that representation close to each other.
And when they're totally unrelated have nothing to do with each other they're far away ELMo is the approach of using bi-directional L STMs
to learn that representation. And what bi-directional, bi-directionally? So looking not just the sequence that let up to the word but in both directions the sequence that
following, the sequence that before. And that allows you to learn the rich full context of the word.
In learning the rich full context of the word you're forming representations that are much better able to represent the statistical language model
behind the kind of corpus of language that you're you're looking at. And this has taken a big leap in ability to then
that for further algorithms then with the language model a reasoning about doing things like
sentence classification, sentence comparison, so on. Translation that representation is much more effective
for working with language. The idea of the OpenAI transformer
is the next step forward is taking the the same transformer that I mentioned previously.
The encoder with self-attention decoder with attention looking back at the input sequence.
And using, taking the language learned by the decoder
and using that as a language model and then chopping off layers and training in a specific on a specific language tasks like sentence classification.
Now BERT is the thing that did the big leap in performance.
With the transformer formulation there is always there's no bi-directional element.
There is, it's always moving forward. So the encoding step and the decoding step with BERT is
it's richly bi-directional it takes in the full sequence of the sentence
and masks out some percentage of the words, 15% of the words.
15% of the samples of tokens from the sequence. And tasks the entire encoding
self-attention mechanism to predict the words that are missing.
That construct and then you stack a ton of them together. A ton of those encoders self-attention feed-forward network,
self attention feed forward network together. And that allows you to learn the rich context of the language to then at the end perform all kinds of tasks.
You can create first of all, like Elmo and like Word2Vec, create rich contextual embeddings.
Take a set of words and represent them in the space that's very efficient to reason with.
You can do language classification, you can do settings pair classification,
you can do the similarity of two sentences, multiple choice question answering, general question answering,
tagging of sentences. okay I'll link it on that one a little bit too long.
but it is also the one I'm really excited about and really if there's a breakthrough this year
is been it's thanks to BERT. The other thing I'm very excited about is totally
jumping away from the new rips,
Tesla Autopilot Hardware v2+: Neural Networks at Scale
the theory, those kind of academic developments and deep learning and into the world of applied deep learning.
So Tesla has a system called Autopilot
where the hardware version 2 of that system
is a newer  implementation of the NVIDIA Drive PX 2 system
which runs a ton of neural networks. There's 8 cameras on the car and
a variant of the inception network is now taking in all a cameras
at different resolutions as input and performing various tasks,
like drivable area segmentation, like object detection and some basic localization tasks.
So you have now a huge fleet of vehicles where it's not engineers
some I'm sure engineers but it's really regular consumers, people that have purchased the car have no understanding
in many cases of what neural networks limitations the capabilities are so on. Now it has a neural network is controlling the well being
has its decisions, its perceptions and the control decisions based on those perceptions
are controlling the life of a human being. And that to me is one of the great breakthroughs of 17 and 18.
In terms of the development of what AI can do in a practical sense in impacting the world.
And so one billion miles over 1 billion miles have been driven in Autopilot.
Now there's two types of systems in currently operating in Tesla's. .There's hardware version 1, hardware version 2.
Hardware version 1 was Intel Mobileye monocular camera perception system.
As far as we know that was not using a neural network. And it was a fix system. That wasn't learning, at least online learning in the Tesla's.
The other is hardware version 2 and it's about half and half now in terms of the miles driven.
The hardware version 2 has a neural network that's always learning. There's weekly updates. It's always improving the model shipping new weights and so on.
That's the exciting set of breakthroughs in terms of AutoML, the dream of automating some aspects or
AdaNet: AutoML with Ensembles
all aspects or many aspects as possible of the machine learning process where you can just drop in a dataset that you're working on
and the system will automatically determine all the parameters
from the details of the architectures, the size are the architecture, the different modules and then architecture
the hyper parameters use for training the architecture running that they're doing the inference everything.
All is done for you. All you just feed it is data So that's been the success of the neural architecture search in 16 and 17.
And there's been a few ideas with Google AutoML that's really trying to almost create an API we just drop in data set.
And it's using reinforcement learning and recurrent neural networks to given a few modules,
stitch them together in such a way where the objective function is optimizing the performance of the overall system.
And they've showed a lot of exciting results. Google showed and others that outperform state of art systems
both in terms of efficiency and in terms of accuracy. Now in 18 there've been a few improvements on
this direction and one of them is a AdaNet where it's now using the same reinforcement
learning AutoML formulation to build ensembles on your network. So in many cases state-of-the-art performance can be achieved
by as opposed to taking a single architecture, is building up a multitude and ensemble a collection of architectures.
And that's what is doing here is given candidate architectures,
stitching them together to form an ensemble to get state-of-the-art performance. Now that state of the art performance is not a leap
a breakthrough leap forward but it's nevertheless a step forward. And it's a very exciting field that's going to be
receiving more and more attention. There's an area of machine learning that's heavily under studied
AutoAugment: Deep RL Data Augmentation
and I think it's extremely exciting area. And if you look at 2012 with AlexNet achieving
the breakthrough performance of showing what deep learning networks are capable of.
From that point, from 2012 to today there's been non-stop
extremely active developments of different architectures that even on just ImageNet alone on doing the image classification task
have improved performance over and over and over with totally new ideas.
Now on the other side on the data side there's been very few ideas about how to do data augmentation.
So data augmentation is the process of, you know, it's what
kids always do when you learn about an object right? You look at an object and you kind of like twist it around is
is taking the raw data and messing it in such a way
that it can give you much richer representation of what this can this data can look like in other forms
in other contexts in the real world. There's been very few developments I think still
and there's this AutoAugment is just a step a tiny step into that direction that I hope that
we as a community invest a lot of effort in. So what AutoAugment does? As it says, ok, so there's these data augmentation methods
like translating the image, sharing the image, doing color manipulation like color inversion.
Let's take those as basic actions you can take and then use reinforcement learning and an RNN again construct to stitch those actions
together in such a way that can augment data like an ImageNet, you train on the data, it gets state-of-the-art performance.
So mess with the data in a way that optimizes the way you mess with the data. So.
And then they've also showed that given that the
set of data augmentation policies that are learned to optimize for example for ImageNet
given the some kind of architecture you can take that learn the set of policies for data augmentation and apply it to a totally different dataset.
So there's the process of transfer learning. So what is transfer learning?
We talked about transfer learning, you have a neural network that learns to do cat versus dog
or no learns to do a thousand class classification problem on image. And then you transfer, you chop off few layers and you transfer on the task of
your own dataset of cat versus dog. What you're transferring is the weights
that are learned on the ImageNet classification task. And now you're then fine-tuning those weights on the
specific, personal cat vs. dog dataset you have.
Now you can do the same thing here. You can transfer as part of the transfer learning process,
take the data augmentation policies learned on ImageNet,
and transfer those. You can transfer both the weights and the policies. That's a really super exciting idea I think.
It wasn't quite demonstrated extremely well here in terms of performance,
so it got an improvement in performance and so on, but any kind of inspired an idea that's something
that we need to really think about. How to augment data in an interesting way such that given just a few samples of data?
We can generate huge data sets in a way that you can then form meaningful complex rich representations from.
I think that's really exciting in one of the ways that you break open the problem of how do we learn a lot from a little.
Training deep neural networks with synthetic data. This also really an exciting topic
Training Deep Networks with Synthetic Data
that a few groups but especially NVIDIA invested a lot in. Here's a from a CVPR2018 probably my favorite work on this topic
is they really went crazy and said ok let's mess
with synthetic data in every way we could possibly can. So on the left there're shown a set of backgrounds
then there's also a set of artificial objects and you have a car or some kind of object that you're trying to classify.
So let's take that car and mess with it with every way possible. Apply lighting variation to whatever way possible,
rotate everything that is crazy so what NVIDIA is really good at is creating realistic scenes.
And they said okay let's create realistic scenes but let's also go away aboveboard and not do realistic at all.
Do things that can't possibly happen in reality. And so generally these huge datasets I want
to train and again achieve quite interesting quite a quite good performance
on image classification. Of course they're trying to apply  to ImageNet and so on these kinds of tasks,
you're not going to outperform networks that were trained on ImageNet. But they show that with just a small sample from from those real images
they can fine tune this network train on synthetic images, totally fake images to achieve state of the art performance.
Again another way to generate, to get, to learn a lot for very little
by generating fake worlds synthetically.
Segmentation Annotation with Polygon-RNN
The process of annotation which for supervised learning is what you need to do in order to
train the network, you need to be able to provide ground truth, you need to be able to label whatever the entity that is being learned.
And so for image classification that's saying what is going on in the image. And part of that was done on ImageNet by
doing a Google search for creating candidates. Now saying what's going on in the image is a pretty easy tasks.
Then there is the object detection task of detecting the boundary box.
And so saying drawing the actual boundary box is a little bit more difficult but it's a couple of clicks and so on.
Then if we take the finals the probably one of the higher complexity tasks of perception
of image understanding is segmentation. It's actually drawing either pixel level or polygons
the outline of particular object. Now if you have to annotate that that's extremely costly.
So the work with Polygon-RNN is to use recurrent neural networks to make suggestions for polygons.
It's really interesting. There's a few tricks to form these high-resolution polygons.
So the idea is it drops in a single point you draw a boundary box around an object.
You use convolutional neural networks to drop the first point. And then use recurrent neural networks to draw around it.
And the performance is really good There's a few tricks and this tool is available online.
It's a really interesting idea again the dream with AutoML is to remove
the human from the picture as much as possible. With data augmentation remove the human from the
picture as much as possible for a menial data. Automate the boring stuff and in this case
the act of drawing a polygon tried to automated as much as possible. The interesting other dimension along which
DAWNBench: Training Fast and Cheap
deep learning is recently being trying to be optimized is how do we make deep learning accessible.
Fast, cheap, accessible. So the DAWNBench from Stanford the benchmark
the DAWNBench benchmark from Stanford asked formulated an interesting competition,
which got a lot of attention and a lot of progress. It's saying if we want to achieve 93% accuracy
on ImageNet and 94% on CIFAR10, let's now compete, that's like the requirement,
let's now compete how you can do it in the least amount of time and for the least amount of dollars.
Do the training in the least amount of time and the training in the least amount of dollars like literally dollars you are allowed to spend to do this.
And fast AI you know it's a renegade awesome renegade group of deep learning researchers
have been able to train on ImageNet in 3 hours. So this is for training process for 25 bucks.
So training a network that achieves 93% accuracy for 25 bucks,
and 94% accuracy for 26 cents on CIFAR10.
So the key idea that they were playing with is quite simple. But really boils down to messing with the learning rate
throughout the process of training. So the learning rate is how much you based on the loss function
based on the error the neural network observes, how much do you adjust the weights. So they found that if they crank up the learning rate
while decreasing the momentum, which is a parameter of the optimization process,
and they do it that jointly they're able to make the network learn really fast. That's really exciting and the benchmark itself is also really exciting
because that's exactly for people sitting in this room that opens up the door to doing all kinds of fundamental deep learning
problems without the resources of Google DeepMind or OpenAI or Facebook or so on, without computational resources.
That's important for academia that's important for independent researchers and so on. So GANs. There's been a lot of work on
BigGAN: State of the Art in Image Synthesis
generative adversarial neural networks. And in some ways there has not been breakthrough
ideas in GANs for quite a bit.
And I think began from Google DeepMind an ability to generate
incredibly high-resolution images. And it's the same GAN technique,
so in terms of breakthroughs and innovations but scaled. So the increase the model capacity and increase the the batch size
the number of images that are fed that are fed to the network. It produces incredible images
I encourage you to go online and and look at them It's hard to believe that they're generated.
So that was 2018 for GANs was a year of scaling and parameter tuning
as opposed to breakthrough new ideas. Video-to-Video Synthesis. This work is from NVIDIA
Video-to-Video Synthesis
is looking at the problem so there's been a lot of work on general going from image to image.
So from a particular image generating another image. So whether it's colorizing an image or just to traditionally define GANs.
The idea with video to video synthesis that a few people have been working on but NVIDIA took a good step forward is to make the video
to make the temporal consistency the temporal dynamics part of the optimization process. So make it look not jumpy.
So if you look here at the comparison the for this particular.
So the input is the labels on the top left and the output of the of the NVIDIA approach is on the bottom right.
See it's temper it's very temporarily consistent. If you look at the image to image mapping that's
that state the pix2pixHD. It's very jumpy, it's not temporally consistent at all.
And there's some naive approaches for trying to maintain temporal consistency.
That's in the bottom left. So you can apply this to all kinds of tasks all kinds of video to video mapping.
Here is mapping it to face edges. Edge detection on faces mapping it to faces.
Generating faces from just edges. You can look at body pose to actual images.
As an input to the network you can take the pose of the person and generate the  video of the person.
Okay semantic segmentation. The problem of perception, so if began with AlexNet and ImageNet
Semantic Segmentation
has been further and further developments where the input, the problem is of basic image classification,
where the input is an image and the output is a classification was going on in that image and the fundamental architecture can be reused
for more complex tasks like detection like segmentation and so on, interpreting what's going on in the image.
So these large networks from VGGNet, GoogLeNet, ResNet, SENet, DenseNet
all these networks are forming rich representations that can then be used for all kinds of tasks whether that task is object detection.
This here shown is the region based methods where the neural network is tasked the
convolutional layers make region proposals. So much of candidates to be considered.
And then there's a step that's determining what's in those different regions and forming boundary boxes around them in a for-loop way.
And then there is the one-shot method single-shot method where in a single pass
all of the boundary boxes in their classes generated. And there has been a tremendous amount of work
in the space of object detection. Some are single shot method, some are region based methods.
And there's been a lot of exciting work but not more not I would say breakthrough ideas.
And then we take it to the highest level of perception which is semantic segmentation.
There's also been a lot of work there the state of the art performance
is at least for the open source systems is DeepLabv3+ on the PASCAL VOC challenge.
So semantic segmentation and catch it all up started 2014 with fully convolution neural networks.
Chopping off the fully connected layers and then outputting the heatmap very grainy very low resolution.
Then improving that was SegNet performing maxpooling with a breakthrough idea that's reused in a lot of cases is
Dilated Convolution, Atrous convolutions having some spacing which increases the
field of view of the convolutional filter. The key idea behind DeepLabv3 that
is the state of the art is the multi-scale processing.
Without increasing the parameters the multi scale is achieved by the "atrous rate"
So taking those atrous convolutions and increasing the spacing. And you can think of the increasing that spacing
by enlarging the model's field of view. And so you can consider all these different scales of processing and looking at the
at the layers of features. So allowing you to be able to grasp the greater context
as part of the upsampling deconvolutional step. And that's what's produced in the state of art performances
and that's where we have the tutorial on github showing this DeepLab
architecture trained on CityScapes. CityScapes is a driving segmentation data set
that is one of the most commonly used for the task of driving scene segmentation.
Okay on the deep reinforcement learning for.
AlphaZero & OpenAI Five
So this is touching a bit a bit on the 2017. But i think the excitement really settled in 2018
as the work from Google and from OpenAI, DeepMind. So it started in DQN paper from Google DeepMind where they beat a bunch of
a bunch of Atari games achieving superhuman performance with deep reinforcement learning methods.
That are taking in just the raw pixels of the game, so the same kind of architecture is able to learn how to beat these,
how to beat these games. Super exciting idea that kind of has echoes
of what general intelligence is. Taking in the raw raw information and being able to understand
the game, the sort of physics of the game sufficient to be able to beat it. Then in 2016 AlphaGo with some supervision and some playing against itself,
self play, some supervised learning on expert world champ players
and some self play where it plays against itself was able to beat the top of the world champion at Go.
And then 2017 AlphaGo Zero a specialized version of Alpha Zero
was able to beat the AlphaGo with just a few days of training.
and zero supervision from expert games. So through the process of self play again this is kind of
getting the human out of the picture more and more and more
which is why Alpha Zero is probably or this AlphaGo Zero was the demonstration of
the cleanest demonstration of all the nice progress in deep reinforcement learning. I think if we look at the history of AI
when you're sitting on a porch hundred years from now sort of reminiscing back Alpha Zero will be a thing that people will
remember as an interesting moment in time, as a key moment in time.
And Alpha Zero was applied in 2017 to beat.
Alpha Zero paper was in 2017 and it was this year played StockFish in chess which is the best engine, chess playing engines
is able to beat it with just four hours of training of course the four hours this caveat.
Because four hours for Google DeepMind is highly distributed training. So it's not four hours for an undergraduate student sitting in their dorm room.
But meaning it was able to self play to very quickly learn to beat the state of the art chess engine.
And learned to beat the state of the art Shogi engine Elmo.
And the interesting thing here is you know with perfect information games like chess
you have a tree and you have all the decisions you could possibly make and so the farther along you look at along that tree presumably the better you do.
That's how DeepBlue beat Kasparov in the 90s is you just look as far as possible in a down the tree
to determine which is the action is the most optimal. If you look at the way human grandmasters think
it certainly doesn't feel like they're like looking down a tree. There's something like creative intuition there's something like
you can see the patterns in the board, you can do a few calculations but really it's an order of hundreds.
It's not on the order of millions or billions which is kind of the
the StockFish the state of the art chess engine approach.
And Alpha Zero is moving closer and closer closer towards the human grandmaster concerning very few future moves.
It's able through the neural network estimator that's estimating the quality of the move and the quality of the different, the current quality of the board and
and the quality of the moves that follow. It's able to do much much less look ahead.
So the neural network learns the fundamental information just like when a grandmaster looks
at a board they can tell how good that is. So that's again interesting, it's a step towards
at least echoes of what human intelligence is in this very structured formal constrained world of chess
and go and shogi. And then there's the other side of the world that's messy.
It's still games. It's still constrained in that way but OpenAI has taken on the challenge of playing games
that are much messier to have this resemblance
of the real world and the fact that you have to do teamwork, you have to look at long time horizons
with huge amounts of imperfect information, hidden information, uncertainty.
So within that world they've taken on the challenge of a popular game Dota 2.
On the human side of that
there's the competition the international hosted every year where you know in 2018 the winning team gets 11 million dollars. So it's a very popular very active competition has been
going on for a few years. They've been improving and it achieved a lot of interesting milestones in 2017.
Their 1v1 bot beat the top professional Dota 2 player. The way you achieve great things is as you try.
And in 2018 they tried to go 5v5. The OpenAI team lost two games
a go against the top Dota 2 players at the 2018 international.
And of course their ranking here the MMR ranking in Dota 2
has been increasing over and over but there's a lot of challenges here that make it extremely difficult.
To beat the human players and this is, you know, in every story rocky
or whatever you think about losing is essential element of a story that leads to then
a movie in a book and the greatness. So you better believe that they're coming back next year.
And there's going to be a lot of exciting developments there. It also, Dota 2 and this particular video game makes it currently
this really two games that have the public eye in terms of AI taking on his benchmarks.
So we saw go incredible accomplishment What's next? So last year the associate were the best paper in Europe's.
There was the heads up Texas No Limit Hold'em AI was able to beat the top level players was completely current
well not completely but currently out of reach is the general not heads up one versus one but the general team
Texas No Limit Hold'em here you go. And on the gaming side this dream of Dota 2 now
that's the benchmark that everybody's targeting. And it's actually incredibly difficult one and some people think would be a long time before we can win.
And on the more practical side of things the
2018, start in 2017 has been a year of
Deep Learning Frameworks
of the frameworks growing up of maturing
and creating ecosystems around them. With TensorFlow with the history there dating back a few years
has really with TensorFlow 1.0 as come
to be sort of a mature framework PyTorch 1.0 came out 2018 is matured as well.
And now the really exciting developments in the TensorFlow with the eager execution and beyond
that's coming out TensorFlow 2.0 in in 2019. So really those two players have made incredible leaps in standardizing deep learning.
In the fact that a lot of the ideas I talked about today and Monday and we'll keep talking about
are all have a github repository with implementations in TensorFlow and PyTorch.
Making extremely accessible and that's really exciting. it's probably best to quote Geoff Hinton the "Godfather" of deep learning,
2019 and beyond
one of the key people behind backpropagation said recently on backpropagation is "My view is throw it all away and start again"
His believes backpropagation is totally broken and an idea that has ancient
and it needs to be completely revolutionized and the practical protocol for doing that is he said the future
depends on some graduate student who's deeply suspicious of everything I've said that's probably a good way to end
the discussion about what the state of the art in deep learning holds because everything we're doing is fundamentally based on
ideas from the 60s and the 80s and really in terms of
new ideas, there has not been many new ideas especially the state of the art results that I've mentioned
are all based on fundamentally, on stochastic gradient descent and backpropagation.
It's ripe for totally new ideas. So it's up to us to define
the real breakthroughs and the real state of the art 2019 and beyond. So that I'd like to thank you and
the stuff is on the website deeplearning.mit.edu.

----------

-----
--54--

-----
Date: 2019.01.11
Link: [# Deep Learning Basics: Introduction and Overview](https://www.youtube.com/watch?v=O5xeyoRL95U)
Transcription:

Welcome everyone to 2019. It's really good to see everybody here
make it in the cold. This is 6.S094 Deep Learning for Self-Driving Cars.
It is part of a series of courses on deep learning that we're running throughout this month.
The website that you can get all the content of videos, the lectures and the code is deeplearning.mit.edu.
The videos and slides will be made available there along with a github repository
that's accompanying the course. Assignments for registered students will be emailed later on in the week.
And you can always contact us with questions, concerns, comments at hcai, human centered AI, at mit.edu.
So let's start through the basics, the fundamentals. To summarize in one slide,
Deep learning in one slide
what is deep learning? It is a way to extract useful patterns from data
in an automated way with as little human effort involved
as possible hence to automate it. How? The fundamental aspect that we'll talk about
a lot is the optimization of neural networks. The practical nature that we'll provide the code
and so on is that there's libraries that make it accessible
and easy to do some of the most powerful things in deep learning using Python, TensorFlow & friends.
The hard part always with machine learning artificial intelligence in general
is asking good questions and getting good data. A lot of times the exciting aspects of what's the news covers
and a lot of the exciting aspects of what is published and that the prestigious conferences in an archive,
in a blog post is the methodology. The hard part is applying the
methodology to solve real world problems, to solve fascinating interesting problems. And that requires data,
that requires asking the right questions of that data, organizing that data
and labeling selecting aspects of that data that can reveal the answers to the questions you ask.
So why has this breakthrough over the past decade
of the application of neural networks, the ideas in neural networks? What has happened? What has changed?
They've been around since the 1940s. And ideas were percolating even before.
The digitization of information, data. The ability to access data easily in a distributed fashion across the world.
All kinds of problems have now a digital form. They can be accessed by learning algorithms.
Hardware; compute, both the Moore's Law of CPU and GPU
and ASICs, Google's TPU systems, hardware that enables the efficient
effective large-scale execution of these algorithms.
Community; people here, people all over the world are being able to work together, to talk to each other,
to feed the fire of excitement behind machine learning. github and beyond.
The tooling;  we'll talk about TensorFlow PyTorch and everything in between
that enables a person with an idea
to reach a solution in less and less and less time. Higher and higher levels of abstraction
empower people to solve problems in less and less time with less and less knowledge,
where the idea and the data become the central point, not the effort, that takes you from an idea to the solution.
And there's been a lot of exciting progress. Some of which we'll talk about from face recognition to
the general problem of scene understanding, image classification, the speech, text, natural language processing, transcription,
translation in medical applications and medical diagnosis. And cars
being able to solve many aspects of perception in autonomous vehicles with drivable area, lane detection,
object detection, digital assistance, ones on your phone and beyond the ones in your home.
Ads, recommender systems from Netflix to search to social, Facebook.
And of course deep reinforcement learning successes in the playing of games,
from board games to StarCraft and Dota.
History of ideas and tools
Let's take a step back. Deep learning is more than a set of tools
to solve practical problems. Pamela McCorduck said in 79
"AI began with the ancient wish to forge the gods." Throughout our history, throughout our civilization, human civilization
we've dreamed about creating echoes of whatever is in this mind of ours in the machine.
And creating living organisms from the popular culture in the 1800s
with Frankenstein to Ex Machina this vision is dream of understanding intelligence and creating intelligence has captivated all of us.
And deep learning is at the core of that. Because there's aspects of, the learning aspects
that captivate our imagination about what is possible. Given data and methodology what learning
learning to learn and beyond how far that can take us.
And here visualized is just 3% of the neurons and one millionth of the synapses in our own brain.
This incredible structure that's in our mind and there's only echoes of it. Small shadows of it in our artificial neural networks that we're able to create.
But nevertheless those echoes are inspiring to us.
The history of neural networks on this pale blue dot of ours
started quite a while ago with summers and winters,
with excitements and periods of pessimism. Starting in the 40s with neural networks and
the implementation of those neural networks is a perceptron in the 50s; with ideas of backpropagation,
restricted Boltzmann machine, recurrent neural networks in the 70s and 80s; with convolutional neural networks
and the MNIST data set with data sets beginning to percolate LSTM, bi-directional RNNs in the 90s;
and the rebranding and the rebirth of neural networks under the flag of Deep Learning
and Deep Belief Nets in 2006; the birth of ImageNet, the data set that on which
the possibilities of a deep learning can bring to the world
has been first illustrated in the recent years in 2009. And AlexNet the network that an ImageNet performed exactly that
with a few ideas like dropout and improved neural networks over time every year by year
improving the performance of neural networks. In 2014 the idea of GANs, the Yann LeCun called
the most exciting idea of the last 20 years, the Generative Adversarial Networks, the ability to with very little supervision
generate data, to generate ideas after forming representation of those. From the understanding from the high-level
abstractions of what is extracted in the data be able to generate new samples. Create, the idea of being able to create
as opposed to memorize is really exciting. And on the applied side in 2014 with DeepFace
the ability to do face recognition. There's been a lot of breakthroughs on the computer vision front
that being one of them. The world was inspired, captivated in 2016
with AlphaGo, and in 17 with AlphaZero beating with less and less and less effort
the best players in the in the world at Go. The problem that for mostly the history of
artificial intelligence thought to be unsolvable. And new ideas with capsule networks and in this year, the year 2018
was the year of natural language processing. A lot of interesting breakthroughs of Google's Bert and others that we'll talk about
breakthroughs on ability to understand language, understand speech
and everything including generation that's built all around that.
And there's a parallel history of tooling starting in the 60s with the perceptron and the wiring diagrams.
They're ending with this year with PyTorch 1.0 and TensorFlow 2.0.
These really solidified, exciting, powerful ecosystems of tools
that enable you to do very, to do a lot with very little effort.
The sky is the limit, thanks to the tooling.
Simple example in TensorFlow
So let's then from the big picture taken to the smallest. Everything should be made as simple as possible.
So let's start simple with a little piece of code before we jump into the details
and a big run through everything that is possible in deep learning. At the very basic level with just a few lines of code
really six here, six little pieces of code, you can train a neural network that understand
what's going on in an image. The classic, that I will always love MNIST data set,
the handwritten digits where the input to a neural network or machine learning system is a picture of a handwritten digit
and the output is the number that's in that digit.
It's as simple as in the 1st Step: import a library TensorFlow.
2nd step: import the data set MNIST. 3rd step, like Lego bricks, stack on top of each other
the neural network layer by layer, with a hidden layer, an input layer and output layer.
Step 4 train the model as simple as a single line: model fit. Evaluate the model in Step 5 on the testing data set.
And that's it. In Step 6 you're ready to deploy. You're ready to predict what's in the image.
It's simple as that. And much of this code obviously much more complicated or
much more elaborate and rich and interesting and complex we'll be making available on
github on our repository that accompanies these courses. Today we'll release the first tutorial on driver scene segmentation.
I encourage everybody to go through it. And then on the tooling side in one slide,
TensorFlow in one slide
before we dive into the neural networks and deep learning. The tooling side amongst many other things
TensorFlow is a deep learning library, an open source library from Google. The most popular one today.
The most active with a large ecosystem. It's not just something you import in Python
and to solve some basic problems. There's an entire ecosystem of tooling. There's different levels of APIs.
Much of what we'll do in this course will be the highest level API with Keras. But there's also the ability to run in the browser with TensorFlow.js,
on the phone with TensorFlow Lite. In the cloud without any need to have a computer hardware,
anything any of the libraries set up on your own machine, you can run all the code that we're providing in the cloud
with Google Colab, Colaboratory. And the optimized ASICs hardware that Google is
optimized for TensorFlow with their TPU-Tensor Processing Unit ability to visualize tensorboard models that provide TensorFlow Hub.
And there's just, this is an entire ecosystem including most importantly I think documentation of blogs
that make it extremely accessible to understand the fundamentals of the tooling
that allow you to solve the problems from natural language processing to computer vision to GANs-Generative Adversarial Networks and
everything in between with deeper enforcement learning and so on. So  that's why we were excited to work both in theory in this course,
in this series of lectures, and in the tooling, in the applied side of TensorFlow.
It really makes it exceptionally these ideas exceptionally accessible. So deep learning at the core is the ability to form
Deep learning is representation learning
higher and higher level of abstractions of representations in data and raw patterns.
Higher and higher levels of understanding of patterns.
And those representations are extremely important
and effective for being able to interpret data.
Under certain representations data is trivial to understand, cat versus dog,
blue dot versus green triangle. Under others it's much more difficult.
In this task drawing a line under polar coordinates is trivial,
under Cartesian coordinates is very difficult, well impossible to do accurately.
And that's a trivial example of a representation. So our task with deep learning, with machine learning in general
is forming representations that map the topology. This, the whatever the topology, the rich space of the problem
that you're trying to deal with of the raw inputs, map it in such a way
that the final representation is trivial to work with,
trivial to classify, trivial to perform regression,
trivial to generate new samples of that data. And that representation of higher and higher levels of representation
is really the dream of artificial intelligence.
That is what understanding is, making the complex simple, like
like Einstein back in a few slides ago said. And that with Juergen Schmidhuber and whoever else said it, I don't know,
that's been the dream of all of science in general.
Of the history of science is the history of compression progress, of forming simpler
and simpler representations of ideas.
The models of the universe of our solar system
with the earth at the center of it is much more complex to perform to do physics on
then a model where the Sun is at the center. Those higher and higher levels of simple representations
enable us to do extremely powerful things. That has been the dream of science and the dream of artificial intelligence.
Why deep learning (and why not)
And why deep learning? What is so special about deep learning in the grander
world of machine learning and artificial intelligence? It's the ability to more and more remove the input of human experts,
remove the human from the picture, the human costly inefficient effort of human beings in the picture.
Deep learning automates much of the extraction from the raw
gets us closer and closer to the raw data without the need of human involvement, human expert involvement.
Ability to form representations from the raw data as opposed to having a human being need to extract features
as was done in the 80s and 90s in the early aughts to extract features
with which then the machine learning algorithms can work with. The automated extraction of features enables us to work with large and larger datasets
removing the human completely except from the supervision labeling step at the very end.
It doesn't require the human expert. But at the same time
there is limits to our technologies. There's always a balance between excitement and disillusionment.
The Gartner hype cycle, as much as we don't like to think about it,
applies to almost every single technology. Of course the magnitude of the peaks and the troughs is different.
But I would say we are at the peak of inflated expectation with deep learning.
And that's something we have to think about as we talk about some of the ideas and exciting possibilities of the future.
And with self driving cars that we'll talk about in future lectures in this course we're at the same. In fact we're little bit beyond the peak.
And so it's up to us. This is MIT and engineers and the people working on this in the world
to carry us through the trough, to carry us through the future as the ups and downs
of the excitement progresses forward
into the plateau of productivity. Why else not deep learning?
If we look at real world applications especially with humanoid robotics, robotics manipulation
and even yes autonomous vehicles, majority aspects of the autonomous vehicles
do not involve to an extensive amount machine learning today.
The problems are not formulated as data driven learning, instead they're model-based optimization methods
that don't learn from data over time. And then from the speakers that these couple of weeks
we'll get to see how much machine learning starting to creep in. But the examples shown here with the Boston
with amazing humanoid robotics in Boston Dynamics to date almost no machine learning has been used
except for trivial perception. The same with autonomous vehicles. Almost no machine learning and deep learning has been used
except with perception. Some aspect of enhanced perception from the visual texture information.
Plus what's becoming, what's starting to be used a little bit more is the use of recurrent neural networks
to predict the future, to predict the intent of the different players in the scene
in order to anticipate what the future is. But these are very early steps. Most of the success of EC today the 10 million miles away Moses achieved
has been attributed mostly to non machine learning methods.
Why else not deep learning? Here's a really clean example of unintended consequences
of ethical issues. We have to really think about. When an algorithm learns from data
based on an objective function, a loss function, the power, the consequences of an algorithm that
optimizes that function is not always obvious. Here's an example of a human player playing the game
of coast runners with a, it's a boat racing game where the task is to go
around the racetrack and try to win the race. And the objective is to get as many points as possible.
There are three ways to get points. The finishing time, how long it took you to finish. The finishing position, where you were in ranking.
And picking up cone called turbos those little green things along the way.
They give you points. Okay simple enough. So we designed an agent in this case an RL Agent
that optimizes for the rewards. And what we find on the right here,
the optimal the agent discovers that the optimal actually has nothing to do with finishing the race or the ranking.
They can get much more points by just focusing on the turbos and collecting those
those little green dots because they regenerate. So if you go in circles over and over and over slamming into the wall
collecting the green turbos. And that's a very clear example of
a well-reasoned, formulated objective function
that has totally unexpected consequences. At least without sort of considering
considering those consequences ahead of time. And so that shows the need for AI safety
for a human in the loop of machine learning. That's why not deep learning exclusively.
Challenges for supervised learning
The challenge of deep learning algorithms, of deep learning applied
is to ask the right question and understand what the answers mean.
You have to take a step back and look at the difference,
the distinction, the levels, degrees of what the algorithm is accomplishing.
For example image classification is not necessarily scene understanding. In fact it's very far from scene understanding.
Classification may be very far from understanding. And the datasets can vary drastically
across the different benchmarks in the datasets used. The professionally done photographs versus
synthetically generated images versus real world data. And the real world data is where the big impact is.
So often times the one doesn't transfer to the other. That's the challenge of deep learning.
Solving all of these problems of different lighting variations, impose variation, inter class variation
all the things that we take for granted human beings with our incredible perception system. All have to be solved in order to gain
greater and greater understanding of a scene. And all the other things we have to close the gap
on that we're not even close to yet. Here's an image from Andrej Karpathy blog from a few years ago
of former President Obama's stepping on a scale. We can classify, we can do semantic segmentation
of the scene, we can do object detection, we can do a little bit of 3d reconstruction from a video version of the scene.
But we can't do well is all the things we take for granted. We can't tell the images in the mirrors versus in reality as different.
We can't deal with the sparsity of information. Just a few pixels on President Obama's face
we can still identify Mr.President. The 3D structure of the scene
that there's a foot on top of a scale that there's human beings behind
with from a single image. Things we can trivially do using all the common-sense semantic knowledge that we have
cannot do the physics of the scene that there's gravity. And the biggest thing,
the hardest thing is what some people's minds. And what some people's minds about what's on other people's minds and so on.
Mental models of the world being able to infer what people are thinking about. Be able to infer there's been a lot of exciting work here at MIT about
what people are looking at. But we're not even close to solving that problem either. But what they're thinking about we're not even
we haven't even begun to really think about that problem. And we do trivially as human beings.
And I think at the core of that I think I'm harboring on the visual perception problem.
Because it's one we take really for granted as human beings especially when trying to solve real world problems,
especially when trying to solve autonomous driving is we've have 540 million years of data for visual perception
so we take it for granted. We don't realize how difficult it is. And we can't focus all our attention on this recent development
of a hundred thousand years of abstract thought being able to play chess being able to reason.
But the visual perception is nevertheless extremely difficult. At every single layer of what's required to perceive, interpret
and understand the fundamentals of a scene. In a trivial way to show that is just all the ways you can mess
with these image classification systems by adding a little bit of noise. The last few years there's been a lot of papers a lot of work
to show that you can mess with these systems by adding noise. Here with 99% accuracy predicted dog
add a little bit of distortion you immediately the system predicts with 99% accuracy that's an ostrich.
And you can do that kind of manipulation with just a single pixel. So that's just a clean way to show the gap between image classification
on an artificial data cell like ImageNet and real world perception that has to be solved,
especially for life critical situations like autonomous driving.
I really like this Max Tegmark's visualization of this rising sea
of the landscape of human competence from Hans Moravec.
And this is the difference as we progress forward.
And we discussed some of these machine learning methods is there is the human intelligence, the general human intelligence.
Let's call Einstein here. That's able to generalize over all kinds of problems
over all kinds of from the common sense to the incredibly complex. And then there is the way we've been doing
especially data-driven machine learning, which is Savant, which is specialized intelligence.
Extremely smart at a particular task but not being able to transfer except in the very narrow
neighborhood on this landscape of different of art, cinematography, book writing at the peaks
and chess, arithmetic and theorem proving and vision at the at the bottom in the lake.
And there's this rising sea as we saw a problem after problem the question can the methodology in and the approach of
deep learning of everything we're doing now keep the sea rising or do fundamental breakthroughs
have to happen in order to generalize and solve these problems. And so from the specialized where the successes are
the systems are essentially boiled down to given  the dataset
and given the ground truth for that data set, here's the apartment cost in the Boston area
be able to input several parameters and based on those parameters predict the apartment cost.
That's the basic premise approach behind the  successful
supervised deep learning systems today. If you have good enough data, that's good enough ground truth
that can be formalized, we can solve it. Some of the recent promise that we will do an entire series of lectures
in the third week on deep reinforcement learning show that from raw sensory information with very little annotation
to self play whether systems learn without human supervision
are able to perform extremely well in these constrained context. The question of a video game.
Here pong to pixels being able to perceive the raw pixels of this pong game as raw input
and learn the fundamental quote unquote physics of this game. Understand how it is this game behaves
and how to be able to win this game. That's kind of a step toward general purpose artificial intelligence.
But it is a very small step because it's in a simulated very trivial situation.
That's the challenge, that's before us with less and less human supervision be able to solve huge real-world problems.
From the top supervised learning where majority of the teaching
is done by human beings throughout the annotation process, through labeling all the data, by showing different examples
and further and further down to semi-supervised learning, reinforcement learning and supervised learning
removing the teacher from the picture. And making that teacher extremely efficient when is needed.
Of course data augmentation is one way we'll talk about.
So taking a small number of examples and messing with that set of examples, augmenting that set of examples,
through trivial and through complex methods of cropping, stretching, shifting and so on.
Including to generative networks modifying those images to grow a small data set into a large one
to minimize, to decrease further and further the input that's a human is
the input of the human teacher. But still that's quite far away from the incredibly efficient
both teaching and learning that humans do. This is a video and there's many of them online for the first time a human baby walking.
We learn to do this you know, it's one shot learning.
One day you're on four, all fours, and the next day your two hands up
and then you figure out the rest. One shot. Well you can kind of ish, you can kind of play around with it.
But the point is you extremely efficient. With only a few examples we are able to learn the fundamental aspect of
how to solve a particular problem. Machines in most cases need thousands, millions
and sometimes more examples depending on the life critical nature of the application.
The data flow of supervised learning systems is there's input data,
there's a learning system and there is output. Now in the training stage for the output we have the ground truth.
And so we use that ground truth to teach the system. In the testing stage when it goes out into the wild there's new input data over
which we have to generalize with the learning system, we have to make our best guess. In the training stage that the processes with neural networks is, given
the input data for which we have the ground truth, pass it through the model, get the prediction. And given that we have the ground truth
we can compare the prediction to the ground truth, look at the error. And based on that error adjust the weights.
The types of predictions we can make is regression and classification. Regression is continuous and classification is categorical.
Here if we look at whether the regression problem says
what is the temperature going to be tomorrow. And the classification formulation of that problem says is it going to be hot or cold
or some threshold definition of what hot or cold is. That's regression and classification.
And the classification front it can be multi class which is the the standard formulation. We are tasked with saying,
what is, there's only a particular entity can be only be one thing,
and then there's multi-label or a particular entity can be multiple things. And overall the input to the system can be not just a single
sample of the particular dataset and the output doesn't have to be a particular sample of the ground truth dataset.
They can be a sequence, sequence to sequence, a single sample to a sequence, a sequence to the sample
and so on. From video captioning or it's video captioning to translation to
natural language generation to of course the one-to-one computing to general computer vision.
Okay that's the bigger picture. Let's step back from the big to the small to a single neuron inspired by our own brain,
the biological neural networks in our brain, in the computational block that is behind a lot of the intelligence in our mind.
The artificial neuron has inputs with weights on them plus a bias and activation function
and an output. It's inspired by this thing as I showed it before. Here visualizes the Thalamocortial system
with three million neurons and 476 million synapses. The full brain has a hundred billion billion neurons
and a thousand trillion synapses.
ResNet and some of the other state-of-the-art networks have tens hundreds of millions
of edges of synapses. The human brain has ten million times more synapses
than artificial neural neural networks and there's other differences. The topology is asynchronous
and not constructed in layers. The learning algorithm for artificial neural networks is backpropagation
for our biological networks we don't know.
That's one of the mysteries of the human brain. There's ideas but we really don't know. A power consumption human brains are much more efficient
than you know networks that's one of the problems that we're trying to solve and ASICs are starting to begin to solve some of these problems.
And the stages of learning in the biological neural networks you really never stop learning.
You're always learning, always changing both on the hardware and a software. In artificial neural networks often times there's a training stage,
there's a distinct training stage and there's a distinct testing stage when you release the thing in the wild. Online learning is an exceptionally difficult thing
that we're still in the very early stages of.
This neuron takes a few inputs, the fundamental computational block behind neural networks,
takes a few inputs, applies weights which are the parameters that are learned, sums them up, puts it into a nonlinear activation function after adding the bias,
also learned parameter and gives an output. And the task of this neuron is to get excited
based on certain aspects of the layers, features inputs that follow before.
And in that ability to discriminate get excited by certain things
and get not excited about other things hold a little piece of information of whatever level of abstraction it is.
So when you combine many of them together you have knowledge.
Different levels of abstractions form a knowledge base that's able to represent, understand or even act on a particular set of raw inputs.
And you stack these neurons together in layers both in width and depth increasing further on.
And there's a lot of different architectural variants. But they begin at this basic fact that with just a single hidden layer of a neural network.
The possibilities are endless. You can approximate an any arbitrary function.
A neural network with a single hidden layer can approximate any function. That means any other neural network with multiple layers and so on
is just interesting optimizations of how we can discover those functions.
The possibilities are endless. And the other aspect here is the mathematical underpinnings
of neural networks with the weights and the differentiable activation functions
are such that in a few steps from the inputs to the outputs
are deeply parallelizable. And that's why the other aspect on the compute
the parallelizability of neural networks is what enables some of the exciting
advancements on the graphical processing unit the GPUs
and with ASICs TPUs. The ability to run across, across machines,
across GPU units in the very large distributed scale
to be able to train and perform inference on neural networks. Activation functions.
Key low-level concepts
These activation functions put together are tasked with optimizing a loss function.
For regression that loss function is mean squared error usually, there's a lot of variance.
And for classifications cross entropy loss. In the cross entropy loss the ground truth is 0,1. In the mean squared error it's a real number.
And so with the loss function and the weights and the bias and the activation functions propagating forward to the network from the input to the output.
Using the loss function we use the algorithm of backpropagation, which I did an entire lecture last time,
to adjust the weights. To have the air flow backwards to the network
and adjust the weights such that once again the weights that were responsible for
producing the correct output are increased in the weights that were responsible for
producing the incorrect output are decreased The forward pass gives you the error.
The backward pass computes the gradients and based on the gradients the optimization algorithm combine a learning rate adjust the weights.
The learning rate is how fast the network learns. And all of this is possible on the numerical computation
side with automatic differentiation. The optimization problem given those gradients
that are computed and enough backward flow to the network of the gradients is Stochastic Gradient Descent.
There's a lot of variants of this optimization algorithms that solve various problems from Dying ReLUs to Vanishing Gradients.
There's a lot of different parameters and momentum and so on.
That's really just boil down to all the different problems that are It is part of a series of courses This is 6.S094 deep learning for self-driving cars. making in the cold. It's really good to see everybody here solved with non linear optimization.
Mini-batch size. What is the right size of a batch? Or really it's called mini batch when it's not the entire dataset
to you based on which to compute the gradients to adjust the learning. Do you do it over a very large amount?
Or do you do it with stochastic gradient descent for every single sample of the data?
If you listen to Yann LeCun and a lot of recent literature is small minibatch sizes are good.
He says "Training with large minibatches is bad for your health. More importantly, it's bad for your test error.
Friends don't let friends use minibatches larger than 32" Larger batch size means more computational speed
because you don't have to update the weights often. But smaller batch size empirically produces better generalization.
The problem we're often on the broader scale of learning trying to solve is overfitting.
And the way we solve it is the regularization. We want to train on a dataset without memorizing to an extent
that you only do well in that trained dataset. So you want it to be generalizable into future
into into into the future things that you haven't seen yet. So obviously this is a problem for small datasets
and also for sets of parameters that you choose. Here shown an example of a sine curve trying to fit
particular data versus a 9-degree polynomial, trying to fit a particular set of data with the blue dots.
The 9-degree polynomial is overfitting. It does very well for that particular set of samples
but does not generalize well in the general case And the trade-off here is, as you train further and further
at a certain point there's a deviation between the
the error being decreased to 0 on the training set
and going to 1 on the test set. And that's the balance we have to strike.
That's done with the validation set. So you take a piece of the training set for which you have the ground truth
and you call it the validation set in set inside and you evaluate the performance of your system on that validation set.
And after you notice that your training network is performing poorly
on the validation set for prolonged period of time, that's when you stop. That's early stoppage.
Basically it's getting better and better and better and then there's some period of time, there's always noise of course, and after some period of time is definitely getting worse.
That's we need to stop there. So that provides an automated way to discovering when need to stop.
And there's a lot of other regularization methodologies. Of course as I mentioned dropout is very interesting approach for.
And it's variance of simply with a certain kind of probability
randomly remove nodes in the network, both the incoming and outgoing edges,
randomly throughout the training process. And there's normalization.
Normalization is obviously always applied at the input.
So whenever you have dataset as different lighting conditions different variations
they get different sources and so on, you have to all kind of put on the same level ground.
So that we're learning the fundamental aspects of the input data as opposed to the some less relevant semantic information
like lighting variation and so on. So we usually always normalize. For example if it's a computer vision with pixels from 0 to 255,
you always normalize to 0 to 1 or -1 to 1 or normalize based on the mean and the standard deviation.
That's something you should almost always do. The thing that enabled a lot of breakthrough performances
in the past few years is batch normalization. It's performing its kind of same normalization later on in the network,
looking at the inputs to the hidden layers.
And normalizing based on the batch of data which on which  yo're training normalized based on mean and the standard deviation.
As batch normalization with batch renormalization fixes a few of the challenges
which is given that you're normalizing during the training
on the minibatches in the training data set, that doesn't directly map to the inference station the testing.
And so it allows, by keeping a running average, it, across both training and testing,
you're able to asymptotically approach a global normalization. So this idea across all the weights
not just the inputs across all the weights you normalize the world in the all the levels of abstractions you forming.
And batch renorm solves a lot of these problems doing inference. And there's a lot of other ideas from layer to weight to
instance normalization to group normalization. And you can play with a lot of these ideas in the TensorFlow playground.
On playground.tensorflow.org that I highly recommend. So now let's run through a bunch of different ideas
Higher-level methods
some of which we'll cover in future lectures. And what is all of this in this world of deep learning
from computer vision to deep reinforcement learning to the different small level techniques to the large natural language processing?
So convolutional neural networks, the thing that enables image classification. So these convolution of filters slide over the image and
able to take advantage of the the spatial invariance of visual information that a cat in the top-left corner is the same as features associated with cats in the top right corner and so on.
Images are just a set of numbers and our task is to take that image and produce a classification
and use the spatial in the spatial variance of visual information to make that
to slide a convolution filter across the image. And learn that filter as opposed to
as opposed to assigning equal value to features that are present in various
at various regions of the image. And stacked on top feature these convolution filters can form
high-level abstractions of visual information and images with AlexNet, as I've mentioned, and the ImageNet data set and challenge
captivating the world of what is possible with neural networks have been further and further improved
superseding human performance with of special note
GoogLeNet with the inception module. There's different ideas that came along ResNet with the residual blocks.
And SENet most recently. So the object detection problem is a step the next step
in the visual recognition. So the image classification is just taking the entire image saying what's in the image.
Object detection localization is saying find all the objects of interest
in the scene and classify them. The region based methods like shown here Faster R-CNN
takes the image, uses convolution neural network to extract features in that image
and generate region proposals. Here's a bunch of candidates that you should look at. And within those candidates, it classifies what they are
and generates a four parameters the bounding box
that thing that captures that thing. So object detection localization ultimately boils down to a bounding box,
a rectangle with a class. That's the most likely class that's in that bounding box.
And you can really summarize region based methods as you generate the region proposal
here little pseudocode and do a for loop over the over the region proposals
and perform detection on that for loop. The Single-Shot methods remove the for loop.
There's a single pass through, you had a bunch of, take a for example here shown SSD.
Take a pretrained neural network that's been trained to do image classification, stack a bunch of convolutional layers on top,
from each layer extract features that are then able to generate in a single pass
classes boundary boxes, boundary box predictions and the class associate of this boundary box.
The trade off here, this is where the popular yellow v123come from
the trade-off here oftentimes is in performance and accuracy.
So single-shot methods are often less performant
especially on in terms of accuracy on objects that really far away or rather objects that are small in the image or really large.
Then the next step up in visual perception, visual understanding is semantic segmentation.
That's where the tutorial that we presented here on github is covering. Semantic segmentation is the task of now as opposed to a boundary box
or the classify the entire image or detecting the object is a boundary box is assigning at a pixel level
the boundaries of what the object is. Every single, in full scene classic full scene segmentation classifying,
what every single pixel which class that pixel belongs to. And the fundamental aspect there's
we'll cover a little bit or a lot more on Wednesday is taking a image classification network,
chopping it off at some point. And then having which is performing the encoding step
of compressing a representation of the scene. And taking that a representation with a decoder
upsampling in a dense way.
So taking that representation upsampling the pixel level classification.
So that upsampling has a lot of tricks that we'll talk through. They are interesting but ultimately boils down to
the encoding step of forming a representation what's going on on the scene and then decoding step that upsamples
the pixel level annotation, classification of all the individual pixels. And as I mentioned here the underlying idea applied
most extensively most successfully in computer vision is transfer learning.
Most commonly applied way of transfer learning is taking a pre-trained your network
like ResNet and chopping it off at some point. It's chopping off the fully connected layers,
some aspects some parts of the layers and then taking a data set,
a new data set and retraining that network. So what is this useful for?
For every single application computer vision in industry. When you have a specific application
like you want to build a pedestrian detector. If you want to build a pedestrian detector and you have a pedestrian dataset,
it's useful to take ResNet trained on ImageNet or COCO
And taking that network, chopping off some of the layers trained in the general case of vision perception. and then retrain it on your specialized pedestrian dataset.
And depending on how large the dataset is the sum of the previous layers that from the pre-training network should be fixed,
frozen. And sometimes not depending on how large the data is. And this is extremely effective in computer vision
but also in audio speech and NLP.
And so as I mentioned with the pre-trained networks
they are ultimately forming representations of the database on which classifications the regression is made,
prediction is made. But a cleanest example of this is the auto encoder
of forming representations in an unsupervised way. The input is an image and the output is that exactly same image.
So why do we do that? Of you add a bottleneck in the network
where there is where the network is narrower at the
in the middle than it is on the inputs and the outputs. It's forced to compress the data down into meaningful representation.
That's what the auto encoder does. You're training it to reproduce the output
and reproduce it with a latent representation that is smaller than the original raw data.
That's a really powerful way to compress the data. It's used for removing noise and so on. But it's also just a effective way to demonstrate a concept.
It can also be used for embeddings. We have a huge amount of data and you want to
form a compressed efficient representation of that data.
Now in practice, this is completely unsupervised. In practice, if you want to form an efficient useful representation of the data,
you want to train it in a supervised way. You want to train it on a discriminative task
where you have labelled data. And the network is trained to identify cat versus dog.
Network that's trained in the discriminative way on an annotated supervised learning way
is able to form better representation. But nevertheless the concept stands. And one way to visualize these concepts is the
the tool that I really love projector.tensorflow.org, is a way to visualize these different representations
these different embeddings. You should definitely play with and you can insert your own data.
Okay going further and further in this direction of unsupervised and forming representations is
generative adversarial networks. From these representations being able to generate new data. And the fundamental methodology of GANs is to have two networks.
One is the generator, one is the discriminator and they compete against each other in order to, for the generator
to get better and better and better at generating realistic images.
The generator's tasks from noise to generate images based on a certain representation that are realistic.
And the discriminator is the critic that has to discriminate
between real images and those generated by the generator. And both get better together.
The generator gets better and better at generating real images to trick the discriminator
and the discriminator gets better and better at telling the difference in real and fake
until the generator is able to generate some incredible things.
So shown here in by the work with NVIDIA, mean the ability to generate realistic faces
as skyrocketed in the past 3 years. So these are samples of celebrities photos that have been able to generate.
Those are all generated by GAN. There's ability to generate temporally consistent video over time
with GANs. And then there's the ability shown at the bottom right and Nvidia I'm sure
I'm sure also we'll talk about the pixel level from semantic segmentation being. So from the semantic pixel segmentation on the right
be able to generate completely the scene on the left.
All the raw rich high-definition pixels on the left.
The natural language processing world same, forming representations, forming embeddings
with Word2Vec, ability to from words to form representation
that are efficiently able to then be used to reason about the words.
The whole idea of forming representation about the data is taking a huge, you know, vocabulary over a million words.
You want to be able to map it into a space
are in a Euclidean sense in Euclidean distance between words are
semantically far apart from each other as well. So things that are similar are together in that space.
And one way of doing that with skip grams for example is looking at a source text
and turning into a large body of text, into a supervised learning problem
by learning to map, predict from the words from a particular word to all its neighbors.
So training network on the connections that are commonly seen in natural language.
And based on those connections we're able to know which words are related to each other. Now the main thing here is.
Now I won't get into too many details but the the main thing here with the input vector representing the words
and the output vector representing the probability that those words are connected to each other.
The main thing both are thrown away in the end the main thing is the middle, the hidden layer
That representation gives you the embedding. That represent these words in such a way where in the Euclidean space
the ones that are close together semantically. Are semantically together in the ones that are not are semantically far apart.
And natural language and other sequence data,
text, speech, audio, video relies on recurrent neural networks.
Recurrent neural networks are able to learn temporal data, temporal dynamics in the data.
Sequence data and are able to generate sequence data. The challenge is that they're not able to learn long-term context.
Because when unrolling a neural network it's trained by unrolling and doing backpropagation
without any tricks the backpropagation of the gradient fades away very quickly. So you're not able to memorize the context
in a longer form of the sentences. Unless there's extensions here with LSTMs that are use long term dependency
is captured by allowing the network to forget information,
allow it to freely pass through information in time.
So what to forget what to remember and every time decide what to output.
And all of those aspects have gates that are all trainable with sigmoid and tanh functions.
Bi-directional real recurrent neural networks from the 90s is an extension often used for providing
context in both direction. So recurrent neural networks simply define is
learning representations what happened in the past. Now in many cases you're able, it's not real-time operation in that
you're able to also look into the future. You look into the data that falls out of the sequence. So benefits you do a forward pass to the network
beyond the current and then back.
The encoder-decoder architecture in recurrent neural networks used very much when the sequence on the input
and the sequence and the output are not relied to be of the same length. The task is to first with the encoder network encode everything
that's came, everything on the input sequence. So this is useful for machine translation for example.
So encoding all the information the input sequence in English and then in the language you translating to
given that representation, keep feeding it into the decoder recurrent neural network to generate the translation.
The input might be much smaller or much larger than the output. That's the encoder decoder architecture.
And then there's improvements. Attention is the improvement on this encoder-decoder architecture
that allows you to as opposed to taking the input sequence, forming a representation of it and that's it.
It allows you to actually look back at different parts of the input. So not just relying in the on the single vector representation
of all the entire input.
And a lot of excitement has been around the idea as I mentioned
some of the dream of artificial intelligence and machine learning in general has been to remove the human more and more and more from the picture.
Being able to automate some of the difficult tasks. So AutoML from Google and just the general concept of
neural architecture search, NasNet. The ability to automate the discovery of
parameters of a neural network. And the ability to discover the actual architecture
that produces the best result. So with neural architecture search you have basic
basic modules similar to the ResNet modules, and with a recurrent neural network
you keep assembling and network together. And assembling in such a way that it minimizes
the loss of the overall classification performance. And it's shown that you can then construct
a neural network that's much more efficient and much more accurate than state of the art
on classification tasks like ImageNet here shown with a plot erved at the very least competitive with the state of the art and SCnet.
It's super exciting that as opposed to like I said stacking lego pieces yourself, the final result is essentially you step back
and you say here's I have a data set with the with the labels with the ground truth
which is what Google the dream of Google AutoML is have the data set you tell me what kind of neural network
will do best on this data set. And that's it. so all you bring is the data It constructs the network through this neural architecture search
and it returns to you the model and that's it. It solves, it makes it possible to solve the exception
you know, solve many of the real world problems that essentially boil down to I have a few classes
I need to be very accurate on here's my data set. And then I convert the problem of a deep learning researcher
to the problem of maybe what's traditionally what's more commonly called the sort of a data science
engineer where the task is as I said focuses on what is the right question
and what is the right data to solve that question. And deep reinforcement learning taking further steps
along the path of decreasing human input. Deep reinforcement learning is the task of an agent
to act in the world based on the observations of the state and the rewards received in that state,
knowing very little about the world and learning from the very sparse nature of the reward.
Sometimes only when you in the gaming context when you win or lose. Or in the robotics contest when you successfully accomplish a task or not
with a very sparse award are able to learn how to behave in that world. Here with with cats learning how the Bell maps to the food
and a lot of the amazing work at open AI and deep mind about the robotics manipulation and navigation
through self play in simulated environments. And of course the best of our own deep reinforcement learning
competition with deep traffic that all of you can participate. And I encourage you to try to win that with no supervised knowledge.
No human supervision through sparse rewards from the simulation
or through self play constructs able to learn how to operate successfully in this world.
Toward artificial general intelligence
And those are the steps we're taking towards general towards artificial general intelligence.
This is the exciting from the breakthrough ideas
that we'll talk about on Wednesday natural language processing to generative adversarial networks.
They're able to generate arbitrary, data high resolution data, create data. Really from this understanding of the world
to deep reinforcement learning being able to learn how to act in the world, very little input from human supervision
is taking further and further steps and there's been a lot of exciting ideas going by different names. Sometimes misused,
sometimes overused, sometimes misinterpreted of transfer learning,
meta learning and the hyper parameter architecture search basically removing a human as much as possible
from the menial tasks and involving a human only on the fundamental side as I mentioned with the racing boat on the ethical side.
And the things that us humans at least pretend to be quite good at
which is understanding the fundamental big questions, understanding the data that empowers us to solve real world problems,
and understand the ethical balance that needs to be struck in order to solve those problems. Well on the bottom right I show that's our job here in this room
our job for all the engineers in the world to solve these problems and progress forward through the current summer
and through the winter, if it ever comes. So with that I'd like to thank you and you can get the videos, code and so on
online deeplearning.mit.edu. Thank you very much guys.

----------

-----
--53--

-----
Date: 2018.12.28
Link: [# Tuomas Sandholm: Poker and Game Theory | Lex Fridman Podcast #12](https://www.youtube.com/watch?v=b7bStIQovcY)
Transcription:

the following is a conversation with Thomas sent home he's a professor same you and co-creator of lebra's which is
the first AI system to be top human players in the game of heads-up No Limit Texas Hold'em he has published over 450
papers on game theory and machine learning including a best paper in 2017 at nips now renamed to new reps which is
where I caught up with him for this conversation his research and companies have had wide reaching impact in the
real world especially because he and his group not only proposed new ideas but
also build systems to prove that these ideas work in the real world this
conversation is part of the MIT course on artificial general intelligence and the artificial intelligence podcast if
you enjoy subscribe on youtube itunes or simply connect with me on Twitter at Lex
Friedman spelled Fri D and now here's my conversation with Thomas sent home can
you describe at the high level the game of poker Texas Hold'em heads-up Texas
Hold'em for people who might not be familiar at this card game yeah happy to
so heads up No Limit Texas Hold'em has really emerged in the AI community as a main benchmark for testing these
application independent algorithms for imperfect information game solving and
this is a game that's actually played by humans you don't see that much on TV or
casinos because well for obvious reasons but you do see it in some expert level
casinos and you see it in the best poker movies of all time it's actually an event in the World Series of Poker but
mostly it's played online and typically for pretty big sums of money and this is
a game that usually only experts play so if you recall to your home game on a
Friday night it probably is not gonna be hits up no Limit Texas Hold'em it might be no let me it takes us Hold'em in some
cases but typically for a big group and it's not as competitive well heads up
means it's two-player so it's really like me against you Am I you better much like chess or or or go
in that sense but an imperfect information game which makes it much harder because I have to deal with issues of you knowing things that I
don't know and I know things that you don't know instead of pieces being nicely laid on the board for both of us to see
so in Texas Hold'em there's a two cards that you only see the game on to you
yeah there is they gradually lay out some cards that add up overall to five cards that everybody can see yeah the
imperfect nature of the information is the two cards that you're holding on front yeah so as you said you know you
first get two cards in private each and then you this a betting round then you
get three clubs in public on the table then there's a betting round then you get the fourth card in public on the
table they're spitting around then you get the five fifth card on the table there's a bending drop so there's a total of four betting rounds and four
torrontés of information revelation if you will the only the first tranche is private and they omits public from there
and this is probably probably by far the
most popular game in AI and just the general public in terms of imperfect
information so it's probably the most popular spectator game to watch right so
which is why it's a super exciting game tackle so it sits on the order of chess
I would say in terms of popularity in terms of AI setting it as the bar of
what is intelligence so in 2017 labret does how do you
pronounce it Liberato lebra das lebra does beats little laughing they're a little bit Latin LeBron is beat a few
for expert human players can you describe that event what you learned
from it what was it like what was the process in general for people who have not read the papers and study yeah so
the event was that we invited four of the top 10 players with these are specialist players in heads-up no Limit
Texas Hold'em which is very important because this game is actually quite different than the the multiplayer
version we brought me in to Pittsburgh to play at the reverse casino for twenty days we wanted to get a
hundred and twenty thousand hands in because we wanted to get statistical significance so it's a lot of hands for
humans to play even for this top pros who play fairly quickly normally so we
couldn't just have one of them play so many hands twenty days they were playing basically morning to evening and he
raised two hundred thousand as a little incentive for them to play and the setting was so that they didn't all get
fifty thousand we actually paid them out based on how they did against the AI
each so they had an incentive to play as hard as they could whether they're way
ahead the way behind or right at the mark of beating the AI and you don't make any money unfortunately right no we
can't make any money so so originally a couple of years earlier I actually explored whether we could actually play
for money because that would be of course interesting as well to play against the top people for money but the
Pennsylvania Gaming Board said no so so if we couldn't so this is much like an exhibit like for a musician or a boxer
or something like that nevertheless you're keeping track of the money and brought us one close to two
million dollars I think so so if there if it was for real money if you were
able to earn money that was a quite impressive and inspiring achievement just a few details what what were the
players looking at I mean were they behind the computer what was the interface like yes there they were
playing much like they normally do these top players when they play this game they play mostly online so they used to
playing through what UI yes and they did the same thing here so there was this layout you could imagine there's a table
on the screen this the the human sitting there and then there's the AI sitting
there and the the screen source everything is happening the cards coming out and so the bets being made and we
also had the betting history for the human so if the human for what what had happened in the ham so far they could
actually reference back and and and so forth is there a reason they were given access to the betting
history for well we just uh it's a it didn't really matter that they wouldn't
have forgotten anyway these are top quality people but we just want to put out there so it's not a question for
human for getting and the AI somehow trying to get advantage of better memory so what was that like I mean that was an
incredible accomplishment so what did it feel like before the event did you have
doubt hope where was your confidence at yeah that's great so a great question so eighteen
months earlier I had organized the similar brains versus AI competition with our previous a I call clerical and
we couldn't beat the humans so this time around it was only eighteen months later
and I knew that this new AI Lovato's was way stronger but it's hard to say how
you'll do against the top humans before you try so I thought we had about a 50/50 shot and the international betting
sites put us a us as a four to one or five to one underdog so it's kind of
interesting that people really believe in people and I get over AI not just
people people don't just believe over believing themselves but they have overconfidence in other people as well compared to the performance of AI and
yeah so we were afford to 105 to 108 beating the humans in a row we were
still 50/50 on the international betting sites do you think there's something special and magical about poker and in
the way people think about it in a sense you have I mean even in chess there's no
Hollywood movies poker is this the star of many movies and there's this feeling
that certain human facial expressions and body language eye movement all these
tells are critical to poker you can look into somebody's soul understand their
betting strategy and so on there so that's probably why the possibly do you
think that is why people have a confidence that humans will outperform because AI systems cannot in
construct perceive these kinds of tells they're only looking at betting patterns and and nothing else the betting
patterns and and statistics so what's
more important to you if you step back and human players human versus human what's the role these tells of these
ideas that we romanticize yeah so I split it into two parts so one is why do
humans trust he much more than AI and all have overconfidence in humans yes I
think that's that's not really related to tell a question it's just that they've seen these top players how good
they are and they're really fantastic so it's just hard to believe therefore that
the Navy I could beat them yeah so I think that's where that comes from and and that's actually maybe a more general lesson about the AI that until you've
seen it over perform a human it's hard to believe it it could but then the tails a lot of these top players they're
so good at hiding tails that among the top players it's actually not really
worth it for them to invest a lot of effort trying to find tails in each other because there's a so good at
hiding them so yes at the kind of Friday evening game tells are gonna be a huge
thing you can read other people and if you're a good reader you you'll read them like an open book but at the top
levels of poker no details become a list of the much much smaller and smaller aspect of the game as you go to the top
levels the the amount of strategies the amount of possible actions is is very
large ten to the power of one hundred plus so there has to be some I've read a
few the papers related it has it has to form some abstractions of various hands
and actions so what kind of abstractions are effective for the game of poker yeah
so you're exactly right so when you go from a game tree that's ten to the 161
especially in an imperfect information game it's way too large to solve directly even with our fastest ik
finding algorithms so you wanna abstract it first and abstraction in games is
much trickier than abstraction in mdps or other single agent settings because
you have these abstraction pathologies that if I have a finer grained abstraction the strategy that I can get
from that for the real game might actually be worse than the strategy I can get from the coarse-grained abstraction if you have to be very
careful now the the kinds of abstractions just to zoom out we're talking about there's the hands
abstractions and then there's betting strategies yeah what I think actions yeah baiting access or so there's
information obstruction to talk about general games information abstraction which is the abstraction of what chance
does and this would be the cards in the case of poker and then there's action abstraction which is abstracting the
actions of the actual players which would be bits in the case of poker yourself and the other players yes
yourself and other players and for information abstraction we were
completely automated so these were these are algorithms but they do what we call
potential aware abstraction where we don't just look at the value of the hand but also how it might materialize in the
good or bad hands over time and it's a certain kind of bottom-up process with integer programming there and clustering
and various aspects how do you build build this abstraction and then in the
action abstraction there it's largely based on how humans other and other AIS
have played this game in the past but in the beginning we actually use an automated action abstraction technology
which is provably convergent that it finds the optimal combination of eight
sizes but it's not very scalable so we couldn't use it for the whole game but we used it for the first couple of
betting actions so what's more important the strength of the hand so the information retraction or the how you
play them the actions does you know the romanticized notion again
is that it doesn't matter what hands you have that the actions the betting may be
the way you win no matter what hands you have yeah so that's why you have to play a lot of hands so that the role of luck
gets smaller so you could otherwise get lucky and get some good hands and then
you're gonna win the match even with thousands of hands you can get lucky because there's so much variance in No
Limit Texas Hold'em because if we both go all-in it's a huge stack or variant
so there are these massive swings in No Limit Texas Hold'em so that's why you
have to play not just thousands but over a hundred thousand hands don't get statistical significance let me ask
another way this question if you didn't even look at your hands but they didn't
know that the your opponents didn't know that how well would you be able to do oh that's a good question there's actually
I heard this story that this is Norwegian female poker player goal and at uber stud who's actually won a
tournament by doing exactly that but that would be extremely rare so so I
cannot really play well the hands do
have some role to play oh yes so LeBron is does not use as far as I understand a
used learning methods deep learning is there room for learning in you know
there's no reason why lab artist doesn't you know combined with an alphago type approach for estimating the quality for
function estimator what are your thoughts on this maybe as compared to
another algorithm which I'm not that familiar with deep stack the the engine that does use deep learning that it's
unclear how well it does but nevertheless uses deep learning so what are your thoughts about learning methods
to aid in the way that teller Broadus plays the game of poker yeah so as you
said Lee barratto's did not use learning methods and played very well without them since then we have actually
actually here we have a couple of papers on things that do use learning technique
Saxon so and deep learning in particular and the sort of the way you're talking
about where it's learning an evaluation function but in imperfect information
games unlike let's say in Co or now now also in chess and shogi it's not some
sufficient to learn an evaluation for a state because the value of an
information set depends not only on the exact state but it also depends on both
players beliefs like if I have a bad hand I'm much better off if the opponent
thinks I'm have a good hand and vice versa if I have a good hand I'm much better off if the opponent believes I
have a bad hand so the value of a state is not just a function of the cards it
depends on if you will the path of play but only to the extent that is captured
in the belief distributions so so that's why it's not as simple as as it is
imperfect information games another one I'd say it's simple there either it's of course very complicated computationally
there too but at least conceptually it's very straightforward there's a state there's an evaluation function you can
try to learn it here you have to do something more and what we do is in one
of these papers we're looking at allowing where we allow with the opponent to actually take different
strategies at the leaf of the search tree as F if you will and and that is a
different way of doing it and it doesn't assume therefore a particular way that the opponent plays but it allows
opponent to choose from a set of different continuation strategies and
that forces us to not be too optimistic in our local head search and that's
that's one way you can do sound look ahead search in imperfect information games which is very different difficult
and in us you were asking about deep stack what they did it was very
different than what we do either in Lee brothers or in this new work they were gender and Umrah generating
various situations in the game then they were doing Luca head from there to the end of the game as if that was a start
of a different game and then they were using deep learning to learn those values of those states but the states
were not just the physical states they include the belief distributions when you talk about look ahead for deep stack
or with libertas does it mean considering every possibility that the game can involve is that we're talking
about extremely sort of like this exponentially growth of a tree yes so we're talking about exactly that
much like you do in Alpha Beta search or want to crawl to research but with
different techniques so there's a different search algorithm and then we have to deal with the leaves differently
so if you think about what Lee brothers did we didn't have to worry about this because we only did it at the end of the
game so we would always terminate into a real situation and we would know what to
payout this it didn't do this depth limited loka heads but now in this new paper which is called depth limited
I think it's called depth limited research for imperfect information games we can actually do sound depth limited
look at it so we can actually started with a look ahead from the beginning of the game on because that's too complicated to do for
this whole long game so in Lee brothers we were just doing it for the end so and then the other side
this belief distribution so is it explicitly modeled what kind of beliefs
that the opponent might have yeah yeah it is explicitly modeled but it's not
assumed the beliefs are actually output not input of course the starting beliefs
are input but they just fall from the rules of the game because we know that the dealer deals uniformly from the dick
so I know that every pair of cards that you might have is equally likely I know
that for a fact that's as follows from the rules of the game of course except the two cards that I have I know you don't have those yes
you have to take that into account that's called card removal and that's very important is the dealing always
coming from a single deck in the heads up so you can assume single deck know
that if some if if I have the ace of spades I know you don't have an ace of spades
okay so in the beginning your belief is basically the fact that it's a fair dealing of hands but how do you adjust
start to adjust that belief well that's a where this beauty of games here it
comes so nash equilibrium which john nash introduced in 1950 introduces what
rational play is when you have more than one player and these are pairs of
strategies where strategies are contingency plans one for each player so
neither player wants to deviate to a different strategy given that the other doesn't deviate but as a
side effect you get the beliefs from Bayes rule so Nash equilibrium really
isn't just deriving in these imperfect information games Nash equilibrium doesn't just define strategies it also
defines beliefs for both us and it defines beliefs for each state so at the
each state it's if they take all information sets at each information set
in the game there's a set of different states that we might be in but I don't
know which one we're in Nash equilibrium tells me exactly what is a probability distribution over those real world
states in my mind how does naturally give you that distribution so why I'll
do a simple example so you know the game rock-paper-scissors so we can draw it as
player 1 moves first and then player 2 moves but of course it's important that
player 2 doesn't know what player 1 moved otherwise player 2 would win every time so we can draw that as an
information set where player 1 makes one of three moves first and then there's an information set for player 2 so player 2
doesn't know which of those nodes the world is it but once we know the
strategy for player 1 Nash equilibrium will say that you play 1/3 Rock 1/3 paper 1/3 caesars from that I can derive
my beliefs of the information set that they wanted 1/3 wants it though so Bayes gives you that basis you but is that
specific to a particular player or is it is there something you quickly update with the game theory isn't really player
specific so that's what also why we don't need any data we don't need any history how these particular humans
played in the past or how any AI or even had played before it's all about rationality so we just think the AI just
thinks about what would a rational opponent do and what would I do if I were right I am rational and that that's
that's the idea of game theory so it's really a data free opponent free
approach sir comes from the design of the game as opposed to the design of the player exactly if there's no opponent
modeling per se I mean we've done some work on combining opponent modeling with game theory so you couldn't exploit weak
players even more but that's another strand and in the Lee brothers we didn't turn that on because I decided that
these players are too good and when you start to exploit an opponent you'll
typically open yourself up self up to exploitation and these guys have so few holes to exploit and they're world's
leading experts in counter exploitation so I decided that we're not gonna turn that stuff on actually I saw a few
papers exploiting opponents it sound very interesting to explore do you think
there's room for exploitation generally outside of LeBron us is is there subject
or people differences that could be exploited maybe not just in poker but in
general interactions negotiations all these other domains that yours considering yeah I definitely we've done
some work on that and I really like their work at hybridize is the two so you figure out what would a rational
opponent do and by the way that's safe in these zero-sum games two player zero-sum games because if the opponent
does something irrational yes it might show throw off my beliefs but the amount
that the player can gain by throwing off my belief is always less than they lose
by playing poorly so so it's safe but still if somebody's weak as a player you
might want to play differently to exploit them more so that you can think about it this way a game theoretic
strategies are unbeatable but it doesn't maximally beat the other opponent so the
winnings per hand might be better with a different strategy and the hybrid is that you start from a game theoretic
approach and then as you gain data from about the opponent in certain parts of
the game tree that in those parts of the game tree you start to tweak your strategy more and more towards
exploitation while still staying fairly close to the game theoretic strategy so as to not open yourself up to
exploitation too much how do you do that do you try to vary up
strategies make it unpredictable it's like what is it tit-for-tat strategies in prisoner's
dilemma or well it doesn't that that's a repeated game kind of prisoner's dilemma
repeats it games but but even there there's no proof that says that that's the best thing but experimentally it
actually does does does well so what kind of games are there first of all I don't know if this is something that you
could just summarize there's perfect information games or all the informations on the table there is
imperfect information games there's repeated games you play over and over
there's zero-sum games there's nonzero-sum games yeah and then there's
a really important distinction you're making two-player versus more players so
what are what other games out there and what's the difference for example with
this two-player game versus more players yeah what are the key differences right
here so let me start from the the basic so a repeated game is a game where the
same exact game is played over and over in these extensive form games where
think about three form maybe with these information says to represent incomplete information you can have kind of
repetitive interactions even repeated games are a special case of that by the way but if the game doesn't have to be
exactly the same selectively sourcing all trips yes we kind of see it the same supply base year to year but what I'm
buying is a little different every time and the supply base is a little different every time and so on so it's not really repeated so to find a purely
repeated game is actually very rare in the world so they're really a very coarse model of what's going on then if
you move up from repeat just repeated simple repeated matrix games not all the
way to extensive form games but in between they're stochastic games where you know
this these think about it like these little matrix games and when you take an action and your
home takes an action they determine not which next state I'm going to next game
I'm going to but the distribution over next games where I might be going to so
so that's the stochastic game but it's like matrix games repeated stochastic games extensive form games that is from
less to more general and and poker is an example of the last one so it's really
the most general setting extensive form games and that's kind of what the AI
community has been working on and being benched marked on with this heads-up No
Limit Texas Hold'em can you describe extensive form games what was the motto here yeah so if you
imagine with the tree form so it's really the tree form like in chess there's a search tree versus a matrix is
a matrix yeah and that's the new matrix is called the matrix form or by matrix form or normal form game and here you
have the tree form so you can actually do certain types of reasoning there that you'll lose the information when you go
to normal form there's a certain form of equivalence like if you go from three
form and you say it every possible contingency plan is the strategy then I
can actually go back to the normal form but I lose some information from the lack of sequentiality then the
multiplayer versus two-player distinction is an important one so two-player games in zero-sum are
conceptually easier and computationally easier there's still huge like this one
this one but they're conceptually easier and computationally easier in that
conceptually you don't have to worry about which equilibrium is the other guy going to play when there are multiple
because any equilibrium strategy is a best response to any other equilibrium strategy so I can play a different
equilibrium from you and we'll still get the right values of the game that falls apart even with two players when you
have general some games even without cooperation just even without cooperation so there's a big gap from
two player zero-sum to two-player general sum or even to three player zero-sum that's that's a big gap
at least in theory can you maybe not mathematically provide the intuition why
it all falls apart with three or more players it seems like you should still be able to have a Nash equilibrium that
yeah that's instructive that holds okay so it is true that all finite games have
a Nash equilibrium so this is what your Nash actually proved so they do have a
Nash equilibrium that's not a problem the problem is that there can be many and then there's a question of which
equilibrium to select so and if you select your strategy from a different equilibrium and I select mind then did
what does that mean I and in this non zero sum games we may lose some joint
benefits we hope by being just simply stupid we could actually both be better off if we did something else yes and in
three player you get other problems also like collusion that maybe you and I can get up on a third player and we can do
radically better by colluding so that there are lots of issues that come up there so no Brown student you workers on this
has mentioned I looked through the AMA and read it he mentioned that the
ability of poker players to collaborate will make the game he was asked the question of how would you make the game
of poker or both of you were asked the question how would you make the game of poker
beyond being solvable by current AI methods and he said that there's not
many ways of making poker more difficult but collaboration or cooperation between
players would make it extremely difficult so can you provide the intuition behind why that is if you
agree with that idea yeah so we've done a lot of work coalitional games and we
actually have a paper here with my other student cappella Farina and some other collaborators on after net nips on that
actually just came back from the poster session where we present life so when
you have a collusion it's a it's a different problem yes and it typically gets even harder then
even the game representations some of the game representations don't really allow go to computation so we actually
introduced a new game representation for for that is that kind of cooperation
part of the model is are you do you have do you have information about the fact
that other players are cooperating or is it just this chaos that where nothing is known so there's some something's
unknown can you give an example of a collusion type game or Z you select
breach that so think about bridge it's like when you and I are on a team our payoffs are the same the problem is
that we can't talk so so when I get my cards I can't whisper to you what my cards are that would not be allowed so
we have to somehow coordinate our strategies ahead of time and only ahead
of time and then there are certain signals we can talk about but they have to be such that the other team also
understands them so so that that's that's an example where the coordination is already built into the rules of the
game but in many other situations like auctions or negotiations or diplomatic
relationships poker it's not really built-in but it still can be very
helpful for the coders I've read you right somewhere the negotiations you
come to the table with prior like a strategy that like that you're willing
to do and not willing to do those kinds of things so how do you start to now
moving away from poker movie beyond poker into other applications like negotiations how do you start applying
this to other and to other domains yeah even real world domains that you've
worked on yeah I actually have two start-up companies doing exactly that one is called strategic machine and
that's for kind of build applications gaming sports all sorts of things like that any applications of this to
business and to sports and to gaming to various types of things for in finance
electricity markets and so on and the other is called strategy robot where we are taking this to military secure
the cyber security and intelligence applications I think you worked a little bit in how he put it advertisement sort
of suggesting ad kind of thing yeah auction that's another component optimized markets optimized but that's
much more about a combinatorial market and optimization based technology that's not using these game theoretic reasoning
technologies I think okay so what sort of high level do you think about our
ability to use game theoretic concepts to model human behavior do you think do
you think human behavior is amenable to this kind of modeling so outside of the poker games and where have you seen it
done successfully in your work I'm not sure the goal really is modeling humans
like for example if I'm playing a zero-sum game yes I don't really care that the opponent is actually following
my model of rational behavior because if they're not that's even better for me
right so so they see with the opponents and games there's a the prerequisite is
that you've formalized the interaction in some way that can be amenable to
analysis and you've done this amazing work with mechanism design designing
games that have certain outcomes but so
I'll tell you an example for my for my world of autonomous vehicles right we're studying pedestrians and pedestrians and
cars negotiating this nonverbal communication there's this weird and game dance of tension where pedestrians
are basically saying I trusted you won't kill me and so as a jaywalker I will step onto the road even though I'm
breaking the law and there's this tension and the question is we really don't know how to model that well in
trying to model intent and so people sometimes bring up ideas of game theory
and so on do you think that aspect of human behavior can use these kinds of
imperfect information approaches modeling how do we how do you start to attack a
problem like that when you don't even know how the game design the game to describe the situation in order to solve
it okay so I haven't really thought about jaywalking but one thing that I think could be a good application in an
autonomous vehicles is the following so let's say that you have fleets of autonomous cars operated by different
companies so maybe here's the way more fleet and here's the uber fleet if you
think about the rules of the road they define certain little rules but that still leaves a huge strategy space open
like as a simple example when cars merge you know how he must merge you know they slow down and look at each other and try
to I try to merge wouldn't it be better if these situations would all repeat pre-negotiated so we can actually merge
at full speed and we know that this is the situation this is how we do it and it's all gonna be faster but there are
way too many situations to negotiate manually so you could do use automated negotiation this is the idea at least
you could use automated negotiation to negotiate all of these situations or many of them in advance and of course it
might be that hey maybe you're not gonna always let me go first maybe you said okay well in these
situations all let you go first but in exchange you're gonna give me - how much you're gonna let me go first in this
situation yes so it's this huge combinatorial negotiation and do you think there's
room in that example of merging to model this whole situation is an imperfect information game or do you really want
to consider it to be a perfect no that's a good question yeah that's a good question I'm paid the price of assuming
that you don't know everything yeah I don't know it's certainly much easier games with perfect information are much
easier so if you can get away with it you should but if the real situation is
of imperfect information then you're going to have to deal with in for imperfect information great so what
lessons have you learned the annual computer poker competition an incredible
accomplishment of AI you know you look at the history of deep blue go these kind of moments when I stepped
up in an engineering effort and a scientific effort combined to beat the
best human players so what do you take away from this whole experience what have you learned about designing it has
systems that play these kinds of games and what does that mean for sort of AI
in general for the future of IAI development yeah so that's a good question so there's so much to say about
it I do like this type of performance oriented research although in my group
we go all the way from like idea to theory to experiments to big system fielding the commercialization so we
spend that spectrum but I think that in a lot of situations in AI you really
have to build the big systems and evaluate them at a scale before you know what works and doesn't and we've seen
that in the computational game theory community that there are a lot of techniques that look good in the small
but then they cease to look good in the large and we've also seen that there are a lot of techniques that look superior
in theory and I really mean in terms of convergence rates better like first-order methods better convergence
rates like the CFR based based algorithms yet the CFR pay based algorithms are the fastest in practice
so it really tells me that you have to test this in reality the theory isn't tight enough if you will to tell you
which algorithms are better than the others and you have to look at these
things that in the large because any sort of projections you do from the small and at least in this domain be
very misleading so that that's kind of from from a kind of science and engineering perspective from personal
perspective it's been just a wild experience in that with the first poker competition the first or first brains
versus AI man-machine poker competition that we organized there had been by the way for other poker games there had been
previous competitions but this was for heads up No Limit this was the first and I probably became the most hated person
in the world of Poker and I didn't mean to III size that they cracked in the
game for yeah it was a lot of people felt that it was a real threat to the whole game the whole
existence of the game if AI becomes better than humans people would be
scared to play poker because there are the superhuman AI is running around taking their money and you know all of
that so so I just it's just really aggressive just in the comments were super aggressive I got everything
it's just short of death threats do you think the same was true for chess
because right now they just completed the World Championships and chess and humans just started ignoring the fact
that there's AI systems now that I'll perform humans and they still enjoy the game is still a beautiful game that's
what I think yeah and I think the same thing happens in poker and so I didn't think of myself as somebody was gonna
kill the game and I don't think I did yeah I've really learned to love this game I wasn't a poker player before but
learn so many new ones is about it from these AIS and they've really changed how the game is played by the way so they
have these very Martian ways of playing poker and the top humans are now incorporating those types of strategies
into their own play so if anything to me our work has made poker a richer more
interesting game for humans to play not something that is gonna steer him as away from it entirely just a quick
comment and something you said which is if I may say so in academia is a little
bit rare sometimes it's pretty brave to put your ideas to the test in the way
you described saying that sometimes good ideas don't work when you actually try to apply them
at scale and so where does that come from I mean what if you could do a advice for people what what drives you
in that sense were you always this way I mean it takes a brave person I guess is what I'm saying to test their ideas and
to see if this thing actually works against human top human players and so on yeah I don't know about brave but it
takes a lot of work it takes a lot of work and a lot of time to organize do
make something big and to organize an event and stuff like that and what drives you in that effort because you
could still I would argue get a best paper award and nips as you did in 17
without doing this that's right yes and so so in general I believe it's very
important to do things in in the real world and at scale and that's really
where the the the pudding if you will proof is in the pudding that's what that's where it is in this particular
case it was kind of a competition between different groups and for many
years as to who can be the first one to beat the top humans that heads up No Limit Texas Hold'em so it became it
became kind of a like a competition who
can get there yeah so a little friendly competition could be I can do wonders for progress yes so the topic of
mechanism design which is really interesting also kind of new to me except as an observer if I don't know
politics and any I'm an observer of mechanisms but you write in your paper
an automated mechanism design that I quickly read so mechanism design is
designing the rules of the game so you get a certain desirable outcome and you
have this work on doing so in an automatic fashion as opposed to
fine-tuning it so what have you learned from those efforts if you look say I
don't know at complex it's like our political system can we design our
political system to have in an automated fashion to have outcomes that we want
can we design something like traffic lights to be smart where it gets
outcomes that we want so what are the lessons you draw from that work yeah so
I still very much believe in the automated mechanism design direction yes but it's not a panacea
there are impossibility results in mechanism design saying that there is no mechanism that accomplishes objective X
in Class C so so they it's not gonna there's no way using any mechanism
design tools manual or automated to do certain things in mechanism design he can't describe that again so meaning
there it's impossible to achieve that yeah yes it was likely impossible so so
so these are these are not statements about human ingenuity who might come up with something smart these are proofs
that if you wanna accomplish properties X in Class C that is not to oppose with
any mechanism the good thing about automated mechanism design is that we're not really designing for a class we're
designing for specific settings at the time so even if there's an impossibility
result for the whole class it just doesn't mean that all of the cases in
the class are impossible it just means that some of the cases are impossible so we can actually carve these islands of
possibility within these known impossible classes and we've actually done that so what one of the famous
results in mechanism design is a Meyer sham set its weight theorem for pi Roger Myerson and Mark Satterthwaite from 1983
so it's an impossibility of efficient trade under imperfect information we show that you can in many settings avoid
that and get the efficient trade anyway depending on how they design the game okay so depending how you design the
game and of course it's not it doesn't in any way any way contradict to
impossibility result or impossibility results is still there but it just finds spots within this impossible class where
in those spots you don't have time possibility sorry if I'm going a bit philosophical but what lessons you draw
towards like I mentioned politics or human interaction and designing mechanisms for outside of just these
kinds of trading or auctioning or purely
formal games our human interaction like a political system what how do you think it's applicable to yeah politics or to
business to negotiations these kinds of things
designing rules that have certain outcomes yeah yeah I do think so have
you seen success that successfully done yes and really oh you mean mechanism design or automated make automated
mechanism design but so so mechanism design itself has had fairly limited
success so far there are certain cases but most of the real-world situations are actually not sound from a mechanism
design perspective even in those cases where they've been designed by very knowledgeable mechanism design people
the people are typically just taking some insights from the theory and applying those insights into the real
world rather than applying the mechanisms directly so one famous example of is the FCC spectrum auctions
so I've also had a small role in that and very good economists have been where
excellent economists have been working on that with no game theory yet the rules that are designed in practice
they're they're such that bidding truthfully is not the best strategy usually mechanism design we try to make
things easy for the participants so telling the truth is the best strategy but but even in those very high stakes
auctions where you have tens of billions of dollars worth of expect from being auctioned truth-telling is not the best
strategy and by the way nobody knows even a single optimal bidding strategy
for those auctions what's the challenge of coming up with an optimum because there's a lot of players and there's a
lot of players but many items for sale and the these mechanisms are such that
even with just two items or one item bidding truthfully wouldn't be the best
strategy if you look at the history of AI it's marked by seminal events and
alphago being a world champion human go player I would put librettist winning
the heads of no-limit hold'em as one of such event thank you and what do you
think is the next such event whether it's in
your life or in the broadly AI community that you think might be out there that
would surprise the world so that's a great question and I don't really know the answer in terms of game solving hits
up No Limit Texas Hold'em really was the one remaining widely agreed-upon
benchmark so that was the big milestone now are there other things yes certainly
there are but there there is not one that the community has kind of focused on so what could be other things there
are groups working on StarCraft there are groups working on dota2 these are video games yes or you could have like
diplomacy or Hanavi you know things like that these are like recreational games
but none of them are really acknowledged that's kind of the main next challenge
problem like chess or go or heads-up No Limit Texas Hold'em was so I don't
really know in the game solving space what is or what will will be the next benchmark I hope kind of hope that there will be a
next benchmark because really the different groups working on the same problem really drove these application
independent techniques for put very quickly over ten years do you think there's an open problem that excites you
that you start moving away from games into real world games like say the stock
market trading yeah that's that's kind of how I am so I am probably not going
to work as hard on these recreational
benchmarks I'm doing to startups on game solving technology strategic machine and strategy robot and we're really
interested in pushing this stuff into practice what do you think would be
really you know a powerful result that
would be surprising that would be if you can say I mean you know five years ten
years from now something that statistically you would say is not very likely but if there's a breakthrough
what achieve yeah so I think that overall we're in a very different
situation in game theory than we are in let's say machine learning yes
so in machine learning it's a fairly mature technology and it's very broadly applied and proven success in the real
world in game solving there are almost no applications yet we have just become superhuman which
machine learning you could argue happened in the 90s if not earlier and at least some supervised learning at
certain complex supervised learning applications now I think a next challenge problem I
know you're not asking about this way you're you're asking about the technology breakthrough but I think the big big breakthrough is to be able to
show it hey maybe most of let's say military planning or most of business strategy will actually be done
strategically using computational game theory that that's what I would like to see as a next five or ten year goal
maybe you can explain to me again forgive me if this is an obvious question but you know machine learning
methods neural networks are suffer from not being transparent not being explainable a game theoretic methods you
know Nash equilibria do they generally when you see the different solutions are they when you talk about military
operations are they once you see the strategies do they make sense that they explainable or do they suffer from the
same problems as neural networks do so that's that's a good question I would say a little bit yes and no and what I
mean by that is that these games are ethic strategies let's say Nash equilibrium it has provable properties
so it's unlike let's say deep learning where you kind of cross your fingers hopefully it'll work and then after the
fact when you have the weights you're still crossing your fingers and I hope it will work here you know that the
solution quality is there this provable or Souls from quality guarantees now that doesn't necessarily mean that the
strategies are human understandable that's a whole other problem so that's also I think it deep learning and
computational game theory are in the same boat in that sense that both are difficult to understand but at least the
game theoretic techniques they have this guarantees of guarantee quality so did
you see business operations to achieve your corporations or even military in the future being at least the strong
candidates being proposed by automated systems do you see that yeah I do I do
but that's more of a really belief than a substantiated fact depending on where
you land and optimism or pessimism that's a relief to me that's an exciting future especially if they're provable
things in terms of optimality so looking into the future there's a a few folks worried
about the especially you look at the game of poker which is probably one of
the last benchmarks in terms of games being solved they they worry about the future and the existential threats of
artificial intelligence so the negative impact in whatever form on society is that something that concerns you as much
are you more optimistic about the positive impacts of AI oh I am much more
optimistic about the positive impacts so just in my own work what we've done so far we run the nationwide kidney
exchange hundreds of people are walking around alive today who would it be and it's increased employment you had you
have a lot of people now running kidney changes and at the transplant centers
interacting with the kidney exchange you have extra surgeons nurses
anesthesiologists hospitals all of that as so so employment is increasing from
that and the world is becoming a better place another example is combinatorial sourcing auctions we did 800 large-scale
combinatorial sourcing auctions from 2001 to 2010 in a previous startup of
mine called combine it and we increased the supply chain efficiency on that
sixty billion dollars of spend by twelve point six percent so that's over six
billion dollars of efficiency improvement in the world and this is also like shifting value from somebody
to somebody else just efficiency improvement like in trucking less empty driving so there's less waste less
carbon footprint and so on it's a huge positive impact in the near term but
sort of to stay in it for a little longer because I think game theory is a
role to play here well let me actually come back and tell you this is one thing I think Asia is also going to make the
world much safer so so so that's another aspect that often gets overlooked well
let me ask this question maybe you can speak to the the safer so I talked to max tegmark is do a Russell who are very
concerned about the resume yeah and often the concern is about value misalignment so AI systems
basically working operating towards goals that are not the same as human
civilization human beings so it seems like game theory has a role to play there to to make sure the values are
aligned with human beings I don't know if that's how you think about it if not how do you think AI might help with this
problem how do you think a i'ma make the world safer yeah I think this value
misalignment is a fairly theoretical worry and I haven't really seen it in it
because I do a lot of real applications I don't see it anywhere the closest I've seen it was the
following type of mental exercise really where I had this argument in the late 80s when we were building these
transportation optimization systems and somebody had heard that it's a good idea to have high utilization of assets so
they told me that hey why don't you put that as objective and we didn't even pull it as an objective because I just
showed him it you know if you had that as your objective the solution would be to load your trucks full and driving
circles nothing would ever get delivered you'd have a hundred percent utilization so yeah I know this phenomenon I've
known this for over 30 years in but I've never seen it actually be a problem reality in reality and yes if you have
the wrong objective the AI will optimize that to the hilt and it's gonna fit more than some human who's kind of trying to
so within a half-baked way with some human insight to but I just haven't seen
that materialize in practice there's this gap that you actually put your finger on very clearly just now between
theory and reality that's very difficult to put into words I think it's what you
can theoretically imagine the worst possible case or even yeah I mean bad
cases and what usually happens in reality so for example to me maybe it's
something you can comment on having grown up and I had grew up in the Soviet Union you know there's currently
10,000 nuclear weapons in the world and for many decades it's theoretically
surprising to me that the nuclear war is not broken out do you think about this
aspect from a game theoretic perspective in general why is that true why in
theory you could see how things would go terribly wrong and somehow yet they have not yeah how do you think so so I do
think that about that a lot I think the biggest two threats that we're facing as mankind one is climate change and the
other is nuclear war so I saw so those are my main two worries that they're worried about and I've tried to do
something about climate I thought about trying to do something for climate change twice actually before two of my
startups had actually commissioned studies of what we could do on those things and we didn't really find a sweet
spot but I'm still keeping an eye out on that if there's something where we could actually provide a market solution or
optimization solution or some other technology solution to problems right now
like for example pollution critic markets was what we were looking at then and it was much more the lack of
political will by those markets were not so successful rather than bad market
design so I could go in and make a better market design but that wouldn't really move the needle on the world very
much if there's no political will and in the u.s. you know the market at least the Chicago market was just shut down
and and so on so it and then it doesn't really help create your market design was there any nuclear side it's more so
global warming is more encroaching
problem you know nuclear weapons have been here it's an obvious problem has
just been sitting there so how do you think about what is the mechanism design there that just made everything seem
stable and are you still extremely worried I am still extremely worried so
you probably know the simple game theory of mad so solar so this was a mutually
assured destruction and it's like it doesn't require any computation with small matrices you can actually convince
yourself that the game is such that nobody wants to initiate yeah that's a very coarse-grained analysis and it
really works in a situation where you have two superpowers or small number of superpowers now things are very
different you have a smaller nuke so the threshold of initiating is smaller and
you have smaller countries and non non nation actors who make it Nokes and so
on so it's I think it's riskier now than it was maybe ever before and what idea
application by I you've talked about a little bit but what is the most exciting
to you right now I mean you you're here at nips europe's now you have a few excellent pieces of
work but what are you thinking into the future with several companies you're doing what's the most exciting thing or one of the exciting things the number
one thing but for me right now is coming up with these scalable techniques for
game solving and applying them into the real world they're still very interested
in market design as well and we're doing that in the optimized markets but I'm most interested if number one right now
is strategic machine strategy robots getting that technology out there and seeing as you were in the trenches doing
applications what needs to be actually filled what technology gap still need to be filled so it's so hard to just put
your feet on the table and imagine what needs to be done but when you're actually doing real applications the
applications tell you what needs to be done and I really enjoy that interaction is it a challenging process to apply
some of the stay the are techniques you're working on and and having the
the various players in industry or the military or people who could really
benefit from it actually use it what's that process like of you know in autonomous vehicles will work with
automotive companies and they're in in many ways they're a little bit old-fashioned it's difficult they really
want to use this technology there's clearly will have a significant benefit but the systems aren't quite in place to
easily have them integrated in terms of data in terms of compute in terms of all
these kinds of things so deuce is that one of the bigger challenges that you're facing and how do you tackle that
challenge yeah I think that's always a challenge that that's gonna slowness and inertia really of let's do things the
way we've always done it you just have to find the internal champions that the customer who understand that hey things
can't be the same way in the future otherwise bad things are going to happen and it's in order most vehicles it's
actually very interesting that the car makers are doing that then they're very traditional but at the same time you have tech companies who have nothing to
do with cars or transportation like Google and Baidu really pushing on
autonomous cars I find it fascinating clearly you're super excited about
actually these ideas having an impact in the world in terms of the technology in
terms of ideas and research their directions that you're also excited about whether that's on the some of the
approaches you talked about for the imperfect information games whether it's applying deep learning just some of these problems is there something that
you're excited in in the research side of things yeah yeah lots of different things in the game solving so solving
even bigger games games will you have more hidden action of the play your
actions as well poker is a game where really the chance actions are hidden or
some of them are hidden but the player actions are public the multiplayer games of various sorts
collusion opponent exploitation all and
even longer games some games that basically go forever but they're not repeated so seek extensive phone games
that go forever whoa what what would that even look like how do you represent that how do you solve that what's an
example of a game like that or is this some of the stochastic games the imagine let's say business strategy so it's and
not just modeling like a particular interaction but thinking about the business from here to eternity
or I think or let's let's say military
strategy so it's not like war is going to go away how do you think about military strategy that's going to go
forever how do you even model that how do you know whether a move was good that
you somebody made and and and so on so that that's kind of one direction I'm
also very interested in learning much more scalable techniques for integer
programming so we had a nice email paper this summer on that for the first automated algorithm configuration paper
that has theoretical generalization guarantees so if I see these many training examples and I told my
algorithm in this way it's going to have good performance on the real distribution which have not seen so
which is kind of interesting that you know algorithm configuration has been going on now for at least 17 years
seriously and there has not been any generalization theory before well this
is really exciting and it's been it's a huge honor to talk to you thank you so much to us thank you for bringing
livadas to the world and all the great work you're done well thank you very much it's been fun good questions
you

----------

-----
--52--

-----
Date: 2018.12.23
Link: [# Juergen Schmidhuber: Godel Machines, Meta-Learning, and LSTMs | Lex Fridman Podcast #11](https://www.youtube.com/watch?v=3FIo6evmweo)
Transcription:

the following is a conversation with jurgen schmidhuber he's the co-director of a CSA a lab and a co-creator of long
short term memory networks LS TMS are used in billions of devices today for
speech recognition translation and much more over 30 years he has proposed a lot
of interesting out-of-the-box ideas a meta learning adversarial networks computer vision and even a formal theory
of quote creativity curiosity and fun this conversation is part of the MIT
course and artificial general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or simply
connect with me on twitter at Lex Friedman spelled Fri D and now here's my
conversation with jurgen schmidhuber early on you dreamed of AI systems that
self-improve recursively when was that dream born when I was a baby
no it's not true I mean it was a teenager and what was the catalyst for
that birth what was the thing that first inspired you when I was a boy I'm I was
thinking about what to do in my life and then I thought the most exciting thing
is to solve the riddles of the universe and and that means you have to become a
physicist however then I realized that there's something even grander you can
try to build a machine that isn't really a machine any longer that learns to
become a much better physicist than I could ever hope to be and that's how I thought maybe I can multiply my tiny
little bit of creativity into infinity but ultimately that creativity will be
multiplied to understand the universe around us that's that's the the
curiosity for that mystery that that drove you yes so if you can build a
machine that learns to solve more and more complex problems and more and more
general problems older then you basically have solved all the problems
at least all the solvable problems so how do you think what is the mechanism
for that kind of general solver look like obviously we don't quite yet have
one or know how to build one who have ideas and you have had throughout your career several ideas about it so how do
you think about that mechanism so in the 80s I thought about how to build this
machine that learns to solve all these problems I cannot solve myself and I
thought it is clear that has to be a machine that not only learns to solve
this problem here and problem here but it also has to learn to improve the learning algorithm itself so
it has to have the learning algorithm in a representation that allows it to
inspect it and modify it such that it can come up with a better learning
algorithm so I call that meta learning learning to learn and recursive
self-improvement that is really the pinnacle of that why you then not only alarm how to improve on that problem and
on that but you also improve the way the machine improves and you also improve the way it improves the way it improves
itself and that was my 1987 diploma thesis which was all about that
hierarchy of metal or knows that I have
no computational limits except for the well known limits that Google identified
in 1931 and for the limits our physics in the recent years meta learning has
gained popularity in a in a specific kind of form you've talked about how
that's not really meta learning with Newall networks that's more basic
transfer learning can you talk about the difference between the big general meta learning and a more narrow sense of meta
learning the way it's used today the ways talked about today let's take the example of a deep neural networks that
has learnt to classify images and maybe you have trained that network on 100
different databases of images and now a new database comes along and you want to
quickly learn the new thing as well so one simple way of doing that as you take
the network which already knows 100 types of databases and then you would
just take the top layer of that and you retrain that using the new label data
that you have in the new image database and then it turns out that it really
really quickly can learn that to one shot basically because from the first
100 data sets it already has learned so much about about computer vision that it can reuse
that and that is then almost good enough to solve the new task except you need a
little bit of adjustment on the top so that is transfer learning and it has
been done in principle for many decades people have done similar things for decades meta-learning true mental
learning is about having the learning algorithm itself open to introspection
by the system that is using it and also
open to modification such that the learning system has an opportunity to modify any part of the learning
algorithm and then evaluate the consequences of that modification and
then learn from that to create a better learning algorithm and so on recursively
so that's a very different animal where you are opening the space of possible
learning algorithms to the learning system itself right so you've like in
this 2004 paper you described get all machines and programs that we write
themselves yeah right philosophically and even in your paper mathematically these are really compelling ideas but
practically do you see these self referential programs being successful in
the near term to having an impact where sort of a demonstrates to the world that
this direction is a is a good one to pursue in the near term yes we had these
two different types of fundamental research how to build a universal problem solver one basically exploiting
[Music] proof search and things like that that
you need to come up with asymptotic Liam optimal theoretically optimal
self-improvement and problems all of us however one has to admit that through
this proof search comes in an additive constant an overhead an additive
overhead that vanishes in comparison to
what you have to do to solve large problems however for many of the small
problems that we want to solve in our everyday life we cannot ignore this constant overhead and that's why we also
have been doing other things non universal things such as recurrent
neural networks which are trained by gradient descent and local search techniques which aren't universal at all
which aren't provably optimal at all like the other stuff that we did but which are much more practical as long as
we only want to solve the small problems that we are
typically trying to solve in this environment here yes so the universal
problem solvers like the girdle machine but also Markos who does fastest way of
solving all possible problems which he developed around 2012 - in my lab they
are associated with these constant overheads for proof search which guarantee is that the thing that you're
doing is optimal for example there is this fastest way of solving all problems
with a computable solution which is due to Marcus Marcus jota and to explain
what's going on there let's take traveling salesman problems with traveling salesman problems you have a
number of cities in cities and you try to find the shortest path through all
these cities without visiting any city twice and nobody know is the fastest way
of solving Traveling Salesman problems tsps but let's assume there is a method
of solving them within n to the 5 operations where n is the number of
cities then the universal method of
Marcus is going to solve the same trolley salesman problem
also within n to the 5 steps plus o of 1
plus a constant number of steps that you need for the proof searcher which you
need to show that this particular class of problems that Traveling Salesman
salesman problems can be solved within a certain time bound within order into the
five steps basically and this additive constant doesn't care for in which means
as n is getting larger and larger as you have more and more cities the constant
overhead pales in comparison and that means that almost all large problems
I solved in the best possible way our way today we already have a universal
problem solver like sound however it's not practical because the overhead the
constant overhead is so large that for the small kinds of problems that we want
to solve in this little biosphere by the way when you say small you're talking
about things that fall within the constraints of our computational systems thinking they can seem quite large to us
mere humans right that's right yeah so they seem large and even unsolvable in a
practical sense today but they are still small compared to almost all problems
because almost all problems are large problems which are much larger than any
constant do you find it useful as a person who is dreamed of creating a
general learning system has worked on creating one has done a lot of interesting ideas there to think about P
versus NP this formalization of how hard
problems are how they scale this kind of worst-case analysis type of thinking do
you find that useful or is it only just a mathematical it's a set of
mathematical techniques to give you intuition about what's good and bad mm-hmm so P versus NP that's super
interesting from a theoretical point of view and in fact as you are thinking about that problem you can also get
inspiration for better practical problems always on the other hand we
have to admit that at the moment as he best practical problem solvers for all
kinds of problems that we are now solving through what is called AI at the moment they are not of the kind that is
inspired by these questions you know there we are using general-purpose
computers such as recurrent neural networks but we have a search technique which is just local search gradient
descent to try to find a program that is running on these recurrent networks such
that it can or some interesting problems such as speech recognition
machine translation and something like that and there is very little theory
behind the best solutions that we have at the moment that can do that do you
think that needs to change you think that world change or can we go can we create a general intelligence systems
without ever really proving that that system is intelligent in some kind of mathematical way solving machine
translation perfectly or something like that within some kind of syntactic definition of a language or can we just be super
impressed by the thing working extremely well and that's sufficient there's an old saying and I don't know who brought
it up first which says there's nothing more practical than a good theory and um
yeah and a good theory of problem-solving under limited resources
like here in this universe or on this little planet has to take into account
these limited resources and so probably that is locking
a theory in which is related to what we already have sees a sim totally optimal
comes almost which which tells us what we need in addition to that to come up
with a practically optimal problem so long so I believe we will have something
like that and maybe just a few little tiny twists unnecessary to to change what we already
have to come up with that as well as long as we don't have that we mmm admit
that we are taking sub optimal ways and we can y'all not Verizon long shorter
memory for equipped with local search techniques and we are happy that it
works better than any competing method but that doesn't mean that we we think
we are done you've said that an AGI system will ultimately be a simple one a
general intelligent system will ultimately be a simple one maybe a pseudocode of a few lines to be able to
describe it can you talk through your intuition behind this idea why you feel that uh at
its core intelligence is a simple algorithm experience tells us that this
stuff that works best is really simple so see asymptotic team optimal ways of
solving problems if you look at them and just a few lines of code it's really true although they are these amazing
properties just a few lines of code then the most promising and most useful
practical things maybe don't have this proof of optimality associated with them
however they are so just a few lines of code the most successful mmm we can
neural networks you can write them down and five lines of pseudocode that's a
beautiful almost poetic idea but what you're describing there is this the
lines of pseudocode are sitting on top of layers and layers abstractions in a sense hmm so you're
saying at the very top mmm you'll be a beautifully written sort of algorithm
but do you think that there's many layers of abstractions we have to first learn to construct yeah of course we are
building on all these great abstractions that people have invented over the
millennia such as matrix multiplications and real numbers and basic arithmetic
and calculus and derivations of error
functions and derivatives of error functions and stuff like that so without that language that greatly
simplifies our way our thinking about these problems we couldn't do anything
so in that sense as always we are standing on the shoulders of the Giants who in the past simplified the problem
of problem solving so much that now we have a chance to do the final step the
final step will be a simple one oh if we if you take a step back through all of
human civilization in just the universe in check how do you think about evolution and
what if creating a universe is required to achieve this final step what if going
through the very painful and an inefficient process of evolution is needed to come up with this set of
abstractions that ultimately to intelligence do you think there's a shortcut or do you think we have to
create something like our universe in order to create something like human level intelligence hmm so far the only
example we have is this one this universe and you live you better maybe
not but we are part of this whole process right so apparently so it might
be the key is that the code that runs the universe as really really simple everything points
to that possibility because gravity and other basic forces are really simple
laws that can be easily described also in just a few lines of code basically and and then there are these other
events that the apparently random events in the history of the universe which as
far as we know at the moment don't have a compact code but who knows maybe somebody and the near future is going to
figure out the pseudo-random generator which is which is computing whether the
measurement of that spin up or down thing here is going to be positive or
negative underlying quantum mechanics yes so you ultimately think quantum mechanics is a pseudo-random number
generator monistic there's no randomness in our universe does God play dice so a
couple of years ago a famous physicist quantum physicist Anton Zeilinger he
wrote an essay in nature and it started more or less like that one of the
fundamental insights our theme of the 20th century was that the universe is
fundamentally random on the quantum level and that whenever you measure spin
up or down or something like that a new bit of information enters the history of the universe and while I was reading
that I was already typing the responds and they had to publish it because I was
right that there's no evidence no physical evidence for that so there's an
alternative explanation where everything that we consider random is actually
pseudo-random such as the decimal expansion of pi
supply is interesting because every three-digit sequence every sequence of
three digits appears roughly one in a thousand times and every five digit
sequence appears roughly one in ten thousand times what do you really would
expect if it was run random but there's a very short algorithm short program
that computes all of that so it's extremely compressible and who knows maybe tomorrow somebody some grad
student at CERN goes back over all these data points better decay and whatever
and figures out oh it's the second billion digits of pi or something like
that we don't have any fundamental reason at the moment to believe that
this is truly random and not just a deterministic video game if it was a
deterministic video game it would be much more beautiful because beauty is
simplicity and many of the basic laws of the universe like gravity and the other
basic forces are very simple so very short programs can explain what these are doing and and it would be awful and
ugly the universe would be ugly the history of the universe would be ugly if for the extra things the random the
seemingly random data points that we get all the time that we really need a huge
number of extra bits to destroy all these um these extra bits of information
so as long as we don't have evidence that there is no short program that
computes the entire history of the entire universe we are a scientists
compelled to look further for that Swiss program your intuition says there exists
a shortest a program that can backtrack to the to the creation of the universe
so the shortest path to the creation yes including all the
entanglement things and all the spin up-and-down measurements that have been
taken place since 13.8 billion years ago
and so yeah so we don't have a proof that it is random we don't have a proof
of that it is compressible to a short program but as long as we don't have
that proof we are obliged as scientists to keep looking for that simple explanation absolutely so you said
simplicity is beautiful or beauty is simple either one works but you also
work on curiosity discovery you know the romantic notion of
randomness of serendipity of being
surprised by things that are about you kind of in our poetic notion of reality
we think as humans require randomness so you don't find randomness beautiful you
use you find simple determinism beautiful yeah okay so why why because
the explanation becomes shorter a universe that is compressible to a short
program is much more elegant and much more beautiful than another one which
needs an almost infinite number of bits to be described as far as we know many
things that are happening in this universe are really simple in terms are from short programs that compute gravity
and the interaction between elementary particles and so on so all of that seems
to be very very simple every electron seems to reuse the same sub program all
the time as it is interacting with other elementary particles if we now require
an extra Oracle injecting new bits of information all the time for these extra
things which are currently no understood such as
better decay then the whole description
length our data that we can observe out of the history of the universe would
become much longer and therefore uglier
and uglier again the simplicity is elegant and beautiful all the history of science is
a history of compression progress yes so you've described sort of as we build up
abstractions and you've talked about the idea of compression how do you see this
the history of science the history of humanity our civilization and life on earth as some kind of path towards
greater and greater compression what do you mean by there how do you think of that indeed the history of science is a
history of compression progress what does that mean hundreds of years ago
there was an astronomer whose name was Keppler and he looked at the data points
that he got by watching planets move and then he had all these data points and
suddenly turnouts that he can greatly compress the data by predicting it
through an ellipse law so it turns out that all these data points are more or
less on ellipses around the Sun and another guy came along whose name was
Newton and before him hook and they said the same thing that is making these
planets move like that is what makes the apples fall down and it also holds form
stones and for all kinds of other objects and suddenly many many of these
compression of these observations became much more compressible because as long as you can predict the next thing given
what you have seen so far you can compress it you don't have to store that data extra this is called predict
coding and then there was still something wrong with that theory of the
universe and you had deviations from these predictions of the theory and 300
years later another guy came along whose name was Einstein and he he was able to
explain away all these deviations from the predictions of the old theory
through a new theory which was called the general theory of relativity which
at first glance looks a little bit more complicated and you have to warp space and time but you can't phrase it within
one single sentence which is no matter how fast you accelerate and how fast are
hard you decelerate and no matter what is the gravity in your local framework
Lightspeed always looks the same and from from that you can calculate all the
consequences so it's a very simple thing and it allows you to further compress
all the observations because suddenly there are hardly any deviations any
longer that you can measure from the predictions of this new theory so all of
science is a history of compression progress you never arrive immediately at
the shortest explanation of the data but you're making progress whenever you are
making progress you have an insight you see all first I needed so many bits of
information to describe the data to describe my falling apples my video are falling apples I need so many data so
many pixels have to be stored but then suddenly I realize no there is a very
simple way of predicting the third frame in the video from the first tool and and
maybe not every little detail can be predicted but more or less most of these orange blocks blobs that are coming down
they accelerate in the same way which means that I can greatly compress the video and the amount of compression
progress that is the depth of the insight that you have at that moment
that's the fun that you have the Scientific fun that fun in that discovery and we can build artificial
systems that do the same thing they measure the depth of their insights as they are looking at the data which is
coming in through their own experiments and we give them a reward an intrinsic
reward and proportion to this depth of insight and since they are trying to
maximize the rewards they get they are
suddenly motivated to come up with new action sequences with new experiments
that have the property that the data that is coming in as a consequence are these experiments has the property that
they can learn something about see a pattern in there which they hadn't seen
yet before so there's an idea of power play you've described a training general
problem solver in this kind of way of looking for the unsolved problems yeah can you describe that idea a little
further it's another very simple idea so normally what you do in computer science you have you have some guy who gives you
a problem and then there is a huge search space of potential solution
candidates and you somehow try them out and you have more less sophisticated
ways of moving around in that search space until you finally found a solution
which you consider satisfactory that's what most of computer science is about
power play just goes one little step further and says let's not only search
for solutions to a given problem but let's search two pairs of problems and
their solutions where the system itself has the opportunity to phrase its own
problem so we are looking suddenly at pairs of problems and their solutions or
modifications are the problems over that is supposed to generate a solution to that
new problem and and this additional
degree of freedom allows us to build Korea systems that are like scientists
in the sense that they not only try to solve and try to find answers to
existing questions no they are also free to impose their own questions so if you
want to build an artificial scientist we have to give it that freedom and power play is exactly doing that so that's
that's a dimension of freedom that's important to have but how do you are hardly you think that
how multi-dimensional and difficult the space of them coming up in your
questions is yeah so as as it's one of the things that as human beings we consider to be the thing that makes us
special the intelligence that makes us special is that brilliant insight yeah
that can create something totally new yes so now let's look at the extreme
case let's look at the set of all possible problems that you can formally
describe which is infinite which should be the next problem that a scientist or
power-play is going to solve well it should be the easiest problem that goes
beyond what you already know so it should be the simplest problem
that the current problems all of that you have which can already sold 100 problems that he cannot solve yet by
just generalizing so it has to be new so it has to require a modification of the
problem solver such that the new problem solver can solve this new thing but the old problem solver cannot do it
and in addition to that we have to make sure that the problem solver doesn't
forget any of the previous solutions right and so by definition power play is
now trying always to search and this pair of in in the set of pairs of
problems and problems over modifications for a combination that minimize the time
to achieve these criteria so as always trying to find the problem which is
easiest to add to the repertoire so just like grad students and academics and
researchers can spend the whole career in a local minima hmm stuck trying to come up with interesting
questions but ultimately doing very little do you think it's easy well in
this approach of looking for the simplest unsolvable problem to get stuck in a local minima is not never really
discovering new you know really jumping outside of the hundred problems the very
solved in a genuine creative way no because that's the nature of power play
that it's always trying to break its current generalization abilities by
coming up with a new problem which is beyond the current horizon just shifting the horizon of knowledge a
little bit out there breaking the existing rules search says the new thing becomes
solvable but wasn't solvable by the old thing so like adding a new axiom like
what Google did when he came up with these new sentences new theorems that
didn't have a proof in the phone system which means you can add them to the repertoire
hoping that that they are not going to damage the consistency of the whole
thing so in the paper with the amazing title formal theory of creativity fun in
intrinsic motivation you talk about discovery as intrinsic reward so if you
view humans as intelligent agents what do you think is the purpose and meaning
of life far as humans is you've talked about this discovery do you see humans
as an instance of power play agents yeah so humans are curious and
that means they behave like scientists not only the official scientists but
even the babies behave like scientists and they play around with toys to figure
out how the world works and how it is responding to their actions and that's
how they learn about gravity and everything and yeah in 1990 we had the
first systems like the hand would just try to to play around with the environment and come up with situations
that go beyond what they knew at that time and then get a reward for creating
these situations and then becoming more general problem solvers and being able to understand more of the world so yeah
I think in principle that that that
curiosity strategy or sophisticated
versions of whether chess is quiet they are what we have built-in as well because evolution discovered that's a
good way of exploring the unknown world and a guy who explores the unknown world has a higher chance of solving problems
that he needs to survive in this world on the other hand those guys who were
too curious they were weeded out as well so you have to find this trade-off evolution found a certain trade-off
apparently in our society there are as a certain percentage of extremely
exploitive guy and it doesn't matter if they die because many of the others are more
conservative and and and so yeah it would be surprising to me if if that
principle of artificial curiosity wouldn't be present and almost exactly
the same form here in our brains so you're a bit of a musician and an
artist so continuing on this topic of creativity what do you think is the role
of creativity and intelligence so you've kind of implied that it's essential for
intelligence if you think of intelligence as a problem-solving system
as ability to solve problems but do you think it's essential this idea of
creativity we never have a program a sub
program that is called creativity or something it's just a side effect of when our problem solvers do they are
searching a space of problems or a space of candidates of solution candidates
until they hopefully find a solution to have given from them but then there are these two types of creativity and both
of them are now present in our machines the first one has been around for a long time which is human gives problem to
machine machine tries to find a solution to that and this has been happening for
many decades and for many decades machines have found creative solutions to interesting problems where humans
were not aware of these particularly in creative solutions but then appreciated
that the machine found that the second is the pure creativity that I would call
what I just mentioned I would call the applied creativity like applied art
where somebody tells you now make a nice picture off of this Pope and you will
get money for that okay so here is the artist and he makes a convincing picture
of the Pope and the Pope likes it and gives him the money and then there is the pure creative
creativity which is more like the power play and the artificial curiosity thing where you have the freedom to select
your own problem like a scientist who defines his own question to study and so
that is the pure creativity of UL and opposed to the applied creativity which
serves another and in that distinction there's almost echoes of narrow AI
versus general AI so this kind of constrained painting of a pope seems
like the the approaches of what people are calling narrow AI and pure
creativity seems to be maybe I'm just biased as a human but it seems to be an
essential element of human level intelligence is that what you're
implying to a degree if you zoom back a little
bit and you just look at a general problem-solving machine which is trying to solve arbitrary problems then this
machine will figure out in the course of solving problems that it's good to be
curious so all of what I said just now about this prewired curiosity and this
will to invent new problems that the system doesn't know how to solve yet should be just a byproduct of the
general search however apparently evolution has built it into us because
it turned out to be so successful a pre-wiring a buyer's a very successful
exploratory buyers that that we are born with and you've also said that
consciousness in the same kind of way may be a byproduct of problem-solving
you know do you think do you find it's an interesting by-product you think it's a useful by-product what are your
thoughts on consciousness in general or is it simply a byproduct of greater and
greater capabilities of problem-solving that's that's similar to creativity in
that sense yeah we never have a procedure called consciousness in our
machines however we get as side effects of what these machines are doing things
that seem to be closely related to what people call consciousness so for example
in 1990 we had simple systems which were basically recurrent networks and
therefore universal computers trying to map incoming data into actions that lead
to success maximizing reward in a given environment always finding the charging station in
time whenever the battery's low and negative signals are coming from the battery always finds the charging
station in time without bumping against painful obstacles on the way so
complicated things but very easily motivated and then we give these little
a separate we can all network which is
just predicting what's happening if I do that in that what will happen as a consequence of these actions that I'm
executing and it's just trained on the long and long history of interactions with the world so it becomes a
predictive model loss of art basically and therefore also a compressor our
theme observations after what because whatever you can predict you don't have
to store extras or compression is a side effect of prediction and how does this
record Network impress well it's inventing little sub programs little sub Network networks that stand for
everything that frequently appears in the environment like bottles and microphones and faces maybe lots of
faces in my environment so I'm learning to create something like a prototype
face and a new face comes along and all I have to encode are the deviations from the prototype so it's compressing all
the time the stuff that frequently appears there's one thing that appears
all the time that is present all the time when the agent is interacting with
its environment which is the agent itself so just for data compression reasons it
is extremely natural for this we can network to come up with little sub
networks that stand for the properties of the agents the hand you know the the
other actuators and all the stuff that you need to better encode the data which
is influenced by the actions of the agent so they're just as a side effect of
data compression during problem-solving you have inter myself models now you can
use this model of the world to plan your future and that's what yours have done
since 1990 so the recurrent Network which is the controller which is trying
to maximize reward can use this model as a network of the what is this model network as a wild this predictive model
of the world to plan ahead and say let's not do this action sequence let's do this action sequence instead because it
leads to more predictor to rewards and whenever it's waking up these layers of
networks let's stand for itself and it's thinking about itself and it's thinking
about itself and it's exploring mentally the consequences of its own actions and
and now you tell me what is still missing missing the next the gap to
consciousness yeah hi there there isn't that's a really beautiful idea that you know if life is a collection of data and
in life is a process of compressing that data to act efficiently you in that data
you yourself appear very often so it's useful to form compressions of yourself
and it's a really beautiful formulation of what consciousness is a necessary side-effect it's actually quite
compelling to me you've described our nen's developed LST aims long short-term
memory networks the there type of recurrent neural networks they have
gotten a lot of success recently so these are networks that model the temporal aspects in the data temporal
patterns in the data and you've called them the deepest of the Newell networks right so what do you think is the value
of depth in the models that we use to learn since you mentioned the long
short-term memory and the lsdm I have to mention the names of the brilliant
students of course that's worse first of all and my first student ever set for writer who
had fundamental insights already in this diploma thesis then Felix Kias had
additional important contributions Alex gray is a guy from Scotland who is
mostly responsible for this CTC algorithm which is now often used to to train the Alice TM to do the speech
recognition on all the Google Android phones and whatever and Siri and so on
so these guys without these guys I would
be nothing it's a lot of incredible work what is now the depth what is the importance of depth well
most problems in the real world are deep in the sense that the current input
doesn't tell you all you need to know about the environment mm-hmm so instead
you have to have a memory of what happened in the past and often important
parts of that memory are dated they are pretty old and so when you're doing
speech recognition for example and somebody says eleven then that's about
half a second or something like that which means it's already fifty-eight time steps and another guy or the same
guy says seven so the ending is the same Evan but now the system has to see the
distinction between seven and eleven and the only way I can see the differences it has to store that fifty steps ago
there wasn't or a nerve eleven or seven so there you have already a problem of
depth fifty because for each time step you have something like a virtual a
layer and the expanded unrolled version of this Riccar network which is doing the speech recognition so these long
time lags they translate into problem depth and most problems and this world
Asajj that you really have to look far back in time to understand what is the problem and to
solvent but just like with our CMS you don't necessarily need to when you look
back in time remember every aspect you just need to remember the important aspects that's right the network has to
learn to put the important stuff in into memory and to ignore the unimportant
noise so but in that sense deeper and deeper is better or is there a
limitation is is there I mean LCM is one of the great examples of architectures that do something
beyond just deeper and deeper networks there's clever mechanisms for filtering
data for remembering and forgetting so do you think that that kind of thinking is necessary if you think about LCM is a
leap a big leap forward over traditional vanilla are nuns what do you think is
the next leap hmm it within this context so LCM is a very clever improvement but
LCM still don't have the same kind of ability to see far back in the future in
the in the past as us humans do the credit assignment problem across way
back not just 50 times steps or a hundred or a thousand but millions and
billions it's not clear what are the practical limits of the lsdm when it
comes to looking back already in 2006 I think we had examples where it not only
looked back tens of thousands of steps but really millions of steps and who won
Paris artists in my lab I think was the first author of a paper where we really
was a 2006 or something had examples word learn to look back for more than 10
million steps so for most problems of
speech recognition it's not necessary to look that far back but there are examples where it does now so looking
back thing [Music] that's rather easy because there is only one past but there are many possible
futures and so a reinforcement learning system which is trying to maximize its
future expected rewards and doesn't know yet which of these many possible future
should I select given this one single past it's facing problems that the LCN
by itself cannot solve so the other sim is good for coming up with a compact
representation of the history so far of the history and observations in action
so far but now how do you plan in an efficient and good way among all these
how do you select one of these many possible action sequences that a reinforcement learning system has to
consider to maximize reward in this unknown future so again it behaves this
basic setup where you have one week on network which gets in the video and the
speech and whatever and it's executing actions and is trying to maximize reward so there is no teacher who tells it what
to do at which point in time and then there's the other network which is
just predicting what's going to happen if I do that then and that could be an
LCM Network and it allows to look back all the way to make better predictions
of the next time step so essentially although it's men predicting only the next time step it is motivated to learn
to put into memory something that happened maybe a million steps ago because it's important to memorize that
if you want to predict that at the next time step the next event you know how
can a model of the world like that a predictive model of the world be used by
the first guy let's call it the controller and the model the controller and the model how can the model be used
by the controller to efficiently select among these many possible futures so
naive way we had about 30 years ago was let's just use the model of the world as
a stand-in as a simulation of the wall and millisecond by millisecond we planned the future and that means we
have to roll it out really in detail and it will work only as the model is really good and it will still be inefficient
because we have to look at all these possible futures and and there are so many of them so instead what we do now
since 2015 and our cm systems controller model systems we give the controller the
opportunity to learn by itself how to use the potentially relevant parts of
the M of the model network to solve new problems more quickly and if it wants to
it can learn to ignore the M and sometimes it's a good idea to ignore the the M because it's really bad it's a bad
predictor in this particular situation of life where the control is currently
trying to maximize r1 however it can also allow and to address and exploit
some of the sub programs that came about in the model network through compressing
the data by predicting it so it now has an opportunity to reuse that code the
ethnic information in the modern are trying to reduce its own search space
such that it can solve a new problem more quickly than without the model
compression so you're ultimately optimistic and excited about the power
of ära of reinforcement learning in the context of real systems absolutely yeah
so you see RL as a potential having a huge impact beyond just sort of the M
part is often develop on supervised learning methods
you see RL as a four problems of cell
traffic cars or any kind of applied cyber BOTS X that's the correct
interesting direction for research in your view I do think so we have a
company called Mason's Mason's which has applied to enforcement learning to
little Howdy's there are DS which learn to park without
a teacher the same principles were used of course so these little Audi's they
are small maybe like that so I'm much smaller than the real Howdy's but they
have all the sensors that you find the real howdy is you find the cameras that lead on sensors they go up to 120 20
kilometres an hour if you if they want to and and they are from pain sensors
basically and they don't want to bump against obstacles and other Howdy's and
so they must learn like little babies to a park take the wrong vision input and
translate that into actions that lead to successful packing behavior which is a
rewarding thing and yes they learn that they are salt we have examples like that and it's only in the beginning this is
just the tip of the iceberg and I believe the next wave of a line is going
to be all about that so at the moment the current wave of AI is about passive
pattern observation and prediction and and that's what you have on your
smartphone and what the major companies on the Pacific of em are using to sell you ads to do marketing that's the
current sort of profit in AI and that's only one or two percent of the world economy which is big enough to make
these company is pretty much the most valuable companies in the world but there's a much much bigger fraction of
the economy going to be affected by the next wave which is really about machines that shape the data through our own
actions and you think simulation is ultimately the biggest way that that
though those methods will be successful in the next 10 20 years we're not talking about a hundred years from now we're talking about sort of the
near-term impact of RL do you think really good simulation is required or is
there other techniques like imitation learning you know observing other humans
yeah operating in the real world where do you think this success will come from so at the moment we have a tendency of
using physics simulations to learn
behavior for machines that learn to solve problems that humans also do not
know how to solve however this is not the future because the future is and
what little babies do they don't use a physics engine to simulate the world
no they learn a predictive model of the world which maybe sometimes is wrong in
many ways but captures all kinds of important abstract high-level predictions which are really important
to be successful and and that's what is what was the future thirty years ago
when you started that type of research but it's still the future and now we are know much better how to go there to to
move there to move forward and to really make working systems based on that where
you have a learning model of the world a model of the world that learns to predict what's going to happen if I do
that and that and then the controller uses that model
to more quickly learn successful action sequences and then of course always this
crazy thing in the beginning the model is stupid so the controller should be motivated to come up with experiments
with action sequences that lead to data that improve the model do you think
improving the model constructing an understanding of the world in this connection is the in now the popular
approaches have been successful you know grounded in ideas of neural networks but
in the 80s with expert systems there's symbolic AI approaches which to us
humans are more intuitive in a sense that it makes sense that you build up
knowledge in this knowledge representation what kind of lessons can we draw in our current approaches mmm
for from expert systems from symbolic yeah so I became aware of all of that in
the 80s and back then a logic program logic programming was a huge thing was
inspiring to yourself did you find it compelling because most a lot of your work was not so much in that realm mary
is more in learning systems yes or no but we did all of that so we my first
publication ever actually was 1987 was a the implementation of genetic algorithm
of a genetic programming system in prologue prologue that's what you learn
back then which is a logic programming language and the Japanese the anthers huge fifth-generation AI project which
was mostly about logic programming back then although a neural networks existed
and were well known back then and deep learning has existed since 1965 since
this guy and the UK and even anko started it but the Japanese and many other people they
focus really on this logic programming and I was influenced to the extent that I said okay let's take these
biologically inspired rules like evolution programs and and and implement
that in the language which I know which was Prolog for example back then and then in in many ways as came back later
because the Garuda machine for example has approved search on board and without
that it would not be optimal well Marcus what does universal algorithm for solving all well-defined problems as
approved search on board so that's very much logic programming without that it
would not be a Centanni optimum but then on the other hand because we have a very pragmatic is also we focused on we
cannula networks and and and some optimal stuff such as gradient based
search and program space rather than provably optimal things the logic
programming does it certainly has a usefulness in when you're trying to
construct something provably optimal or probably good or something like that but is it useful for for practical problems
it's really useful at volunteer improving the best theorem provers today are not neural networks right no say our
logic programming systems and they are much better theorem provers than most math students and the first or second
semester on but for reasoning to for playing games of go or chess or for
robots autonomous vehicles that operate in the real world or object manipulation
you know you think learning yeah as long as the problems have little to do with
with C or improving themselves then as
long as that is not the case you you just want to have better pattern recognition so to build a self-driving
car you want to have better pattern recognition and and pedestrian recognition and all these
things and you want to your minimum you want to minimize the number of false
positives which is currently is slowing down self-driving cars in many ways and and all that has very little to do with
logic programming yeah what are you most
excited about in terms of directions of artificial intelligence at this moment in the next few years in your own
research and in the broader community so I think in the not so distant future we
will have for the first time little robots that learn like kids and I
will be able to say to the robot um look here robot we are going to assemble a
smartphone it's takes a slab of plastic and the school driver and let's screw in
the screw like that no no not like that like so hmm not like that like that and
I don't have a data glove or something he will see me and he will hear me and
he will try to do something with his own actuators which will be really different
from mine but he will understand the difference and will learn to imitate me
but not in the supervised way where a teacher is giving target signals for all
his muscles all the time no by doing this high level imitation where he first has to learn to imitate
me and then to interpret these additional noises coming from my mouth as helping helpful signals to to do that
Hannah and then it will by itself come
up with faster ways and more efficient ways of doing the same thing and finally
I stopped his learning algorithm and make a million copies and sell it and so
at the moment this is not possible but we already see how we are going to get there and you can imagine to the extent
that this works economically and cheaply it's going to change everything almost
all our production is going to be affected by that and a much bigger wave
much bigger ai wave is coming than the one that we are currently witnessing which is mostly about passive pattern
recognition on your smartphone this is about active machines that shapes data Susy actions they are executing and they
learn to do that in a good way so many
of the traditional industries are going to be affected by that all the companies
that are building machines well equip these machines with cameras
and other sensors and they are going to learn to solve all kinds of problems
through interaction with humans but also a lot on their own to improve what they
already can do and lots of old economy
is going to be affected by that and in recent years I have seen that all the economy is actually waking up and
realizing that those vacations and are you optimistic about the future are you
concerned there's a lot of people concerned in the near term about the
transformation of the nature of work the kind of ideas that you just suggested
would have a significant impact of what kind of things could be automated are you optimistic about that future are you
nervous about that future and looking a little bit farther into the future
there's people like you la musk - a rustle concerned about the existential
threats of that future so in the near term job loss in the long term
existential threat are these concerns to you or yalta mele optimistic so let's
first address the near future we have
had predictions of job losses for many decades for example when industrial
robots came along many people many people predicted and lots of jobs are
going to get lost and in a sense say were right because back then there were
car factories and hundreds of people and these factories assembled cars and today
the same car factories have hundreds of robots and maybe three guys watching the robots on the other hand those countries
that have lots of robots per capita Japan Korea and Germany Switzerland a
couple of other countries they have really low unemployment rates
somehow all kinds of new jobs were created back then nobody anticipated
those jobs and decades ago I already
said it's really easy to say which jobs are going to get lost but it's really
hard to predict the new ones 30 years ago who would have predicted all these
people making money as YouTube bloggers
200 years ago 60% of all people used to
work in agriculture today maybe 1% but
still only I don't know 5% unemployment lots of new jobs were created and Homo
Luden's the the playing man is inventing new jobs all the time most of these jobs
are not existentially necessary for the survival of our species there are only
very few existentially necessary jobs such as farming and building houses and
and warming up the houses but less than 10% of the population is doing that and most of these newly invented jobs are
about interacting with other people in new ways through new media and so on
getting new high types of kudos and forms of likes and whatever and even
making money through that so homo Luden's the playing man doesn't want to
be unemployed and that's why he is inventing new jobs all the time and he
keeps considering these jobs as really important and is investing a lot of energy and hours of work into into those
and new jobs it's quite beautifully put were really nervous about the future because we
can't predict what kind of new jobs would be created but your ultimate ly optimistic that we humans are so
Restless that we create and give meaning to newer in your jobs telling you likes on faith things that
get likes on Facebook or whatever the social platform is so what about long-term existential threat of AI where
our whole civilization may be swallowed up by this ultra super intelligent
systems maybe it's not going to be smaller DUP but I'd be surprised if B
were B humans were the last step and the evolution of the universe you you've
actually at this beautiful comment somewhere that I've seen saying that
artificial quite insightful artificial general intelligence systems just like
us humans will likely not want to interact with humans they'll just interact amongst themselves
just like ants interact amongst themselves and only tangentially
interact with humans hmm and it's quite an interesting idea that once we create a GI that will lose interest in humans
and and have compete for their own Facebook Likes on their own social platforms so within that quite elegant
idea how do we know in a hypothetical sense that there's not already
intelligent systems out there how do you think broadly of general intelligence greater than us how do we know it's out
there mmm how would we know it's around us and could it already be I'd be
surprised even with within the next few decades or something like that we we
won't have a eyes that truly smarts in every single way and better problem solvers and almost every single
important way and I'd be surprised as
they wouldn't realize what we have realized a long time ago which is that
almost all physical resources are not here and this biosphere but for thou
the rest of the solar system gets 2 billion times more solar energy than our
little planet there's lots of material out there that you can use to build robots and self-replicating robot
factories and all this stuff and they are going to do that and there will be scientists and curious and they will
explore what they can do and in the beginning they will be fascinated by
life and by their own origins and our civilization they will want to understand that completely just like
people today would like to understand how life works and um and also the
history of our own existence and civilization and also on the physical
laws that created all of that so they in the beginning they will be fascinated my
life once they understand that I was interest like anybody who loses interest
and things he understands and then as you said the most interesting sources
information for them will be others of their own kind
so at least in the long run there seems to be some sort of protection through
lack of interest on the other side
and now it seems also clear as far as we understand physics you need matter and
energy to compute and to build more robots and infrastructure and more AI
civilization and III ecology is consisting of trillions of different
types of AIS and and so it seems inconceivable to me that this thing is
not going to expand some AI ecology not controlled by one AI but one by
trillions of different types of AI is competing and all kinds of quickly
evolving and disappearing ecological niches in ways that we cannot fathom at the moment but it's going to expand
limited by Lightspeed and physics it's going to expand and and now we realize
that the universe is still young it's only 13.8 billion years old and it's going to be a thousand times
older than that so there's plenty of time to conquer the entire universe and
to fill it with intelligence and senders and receivers such that AI scan trouble
the way they are traveling in our labs today which is by radio from sender to
receiver and let's call the current age of the universe one Eon
one Eon now it will take just a few eons
from now and the entire visible universe is going to be full of that stuff and
let's look ahead to a time when the universe is going to be one thousand times older than it is now they will
look back and they will say look almost immediately after the Big Bang only a few eons later the entire
universe started to become intelligent now to your question how do we see
whether anything like that has already happened or is already in a more advanced stage in some other part of the
universe of the visible universe we are trying to look out there and nothing like that has happened so far or is that
her do you think we'll recognize it or how do we know it's not among us how do we know planets aren't in themselves
intelligent beings how do we know ants
seen as a collective are not much greater intelligence in our own these
kinds of ideas no but it was a boy I was thinking about these things and I
thought hmm maybe it has already happened because back then I know I knew I learned from popular physics books
that the structure the large-scale structure of the universe is not homogeneous and you have these clusters
of galaxies and then in between there are these huge empty spaces and I
thought hmm maybe they aren't really empty it's just that in the middle of that some AI civilization already has
expanded and then has covered a bottle of a billion light-years diameter and is
using all the energy of all the stars within that bubble for its own unfathomable purposes and so it always
happened and we just failed to interpret the signs but then alarmed effect
gravity by itself explains the large-scale structure of the universe and that this is not a convincing
explanation and then I thought maybe maybe it's the dark matter because as
far as we know today 80% of the measurable matter is invisible and we
know that because otherwise our galaxy or other galaxies would fall apart they
would they are rotating too quickly and then the idea was maybe all us he is AI
civilizations and hourly out there they they just invisible because they are
really efficient in using the energies at their own local systems and that's why they appear dark to us but this is
awesome at a convincing explanation because then the question becomes why is
there are there still any visible stars left in our own galaxy which also must have a
lot of dark matter so that is also not a convincing thing and today I like to
think it's quite plausible that maybe are the first at least in our local light cone within a few hundreds of
millions of light years that we can reliably observe is there exciting to
you it will might be the first and it would make us much more important
because if we mess it up through a nuclear war then then maybe this will
have an effect on the on the on the development on of the entire universe so
let's not mess it up let's not mess it up Union thank you so much for talking today I really appreciate it it's my
pleasure
you

----------

-----
--51--

-----
Date: 2018.12.16
Link: [# Pieter Abbeel: Deep Reinforcement Learning | Lex Fridman Podcast #10](https://www.youtube.com/watch?v=l-mYLq6eZPY)
Transcription:

the following is a conversation with Petera Beal he's a professor UC Berkeley and the director of the Berkeley
robotics learning lab he's one of the top researchers in the world working on how we make robots understand and
interact with the world around them especially using imitation and deeper enforcement learning this conversation
is part of the MIT course and artificial general intelligence and the artificial intelligence podcast if you enjoy it
please subscribe on YouTube iTunes where your podcast provider of choice or simply connect with me on Twitter at Lex
Friedman spelled Fri D and now here's my conversation with Peter a Biel you've
Robot tennis
mentioned that if there was one person you could meet you'll be Roger Federer so let me ask when do you think we will
have a robot that fully autonomously can beat Roger Federer at tennis Roger
Federer level player at tennis huh well first if you can make it happen for me to meet Roger let me know terms of
getting a robot to beat him at tennis it's kind of an interesting question
because for a lot of the challenges we think about in AI the software is really
the missing piece but for something like this the hardware is nowhere near either
like to really have a robot that can physically run around the Boston
Dynamics robots are starting to get there but still not really human level ability to to run around and then swing
a racket that's a hardware problem I don't think it's a harder problem only I
think it's a hardware and a software problem I think it's both and I think they'll they'll have independent
progress so I'd say the the hardware maybe in 10-15 years I'm just late not
grass I've dressed with a sliding yeah oh plague I'm not sure what's Carter
grass or clay the clay involves sliding which might be harder to master actually
yeah but you're not limited to bipedal I mean I'm sure there's I can build a
machine it's a whole different question of course you know you can if you can say okay this robot can be on wheels they can move around on
wheels and can be designed differently then I think that that can be done
sooner probably than a full humanoid type of setup what do you think is swing a racket so you've worked at basic
manipulation how hard do you think is the task of swinging or racket would be
able to hit a nice backhand or a forehand okay let's say let's say we just set up
stationary a nice robot arm let's say you know a standard industrial arm and
it can wash the ball come and then swing the racket it's a good question I'm not
sure it would be super hard to do I mean I'm sure it would require a lot if we do
it breed with reinforced Maleny would require a lot of trial and error it's not gonna swing it right the first time around but yeah I don't I don't see why
I couldn't see the right way I think it's learn about I think if you set up a
ball machine let's say on one side and then a robot with a tennis racket on the other side
I think it's learn about and maybe a little bit of pre training and
simulation yeah I think that's I think that's feasible I think I think the swinging the racket is feasible I'd be
very interesting to see how much precision it can get listen I mean that's that's where I mean
some of the human players can hit it on the lines which is very high precision with spin this win is it is an
interesting whether RL can learn to put a spin on the ball well you got me interested maybe someday we'll set this
is your answer is basically okay for this problem it sounds fascinating but
for the general problem of a tennis player we might be a little bit farther away what's the most impressive thing
you've seen a robot do in the physical world so physically for me it's the
Robot parkour
Boston Dynamics videos always just ring home and just super impressed
recently the robot running up the stairs doing the parkour type thing I mean yes we don't know what's
underneath they don't really write a lot of detail but even if it's hard coded underneath which you might or might not
be just the physical abilities of doing that parkour that's a very impressive so a lot right there have you met spot many
or any of those robots in person might spot mini last hearing in April at the
Mars event that Jeff Bezos organizes they brought it out there and it was
nicely falling around Jeff when Jeff left the room they had it follow him along which is pretty
impressive so I think there's some confidence to know that there's no learning going on in those robots the
The psychology of robots
psychology of it so while knowing that while knowing there's not if there's any learning going on it's very limited
I met spot Minnie earlier this year and knowing everything that's going on
having one-on-one interaction so I got to spend some time alone and there's a
immediately a deep connection on the psychological level even though you know the fundamentals how it works there's
something magical so do you think about the psychology of interacting with
robots in the physical world even you just showed me the pr2 the the robot and
and there was a little bit something like a face head a little bit something like a face there's something that
immediately draws you to it do you think about that aspect of of the robotics problem well it's very
hard with bread here we'll give him a name Berkeley robot for the elimination
of tedious tasks is very hard to not think of the robot as a person and it
seems like everybody calls him a he for whatever reason but that also makes it more a person than if it was a it and
it's it seems pretty natural to think of it that way this past weekend really struck me I've seen pepper many times on
on videos but then I was at an event organized by this was by fidelity and
they had scripted pepper to help moderate some sessions and yet scripted
pepper to have the personality of a child a little bit and it was very hard to not think of it as its own person in
some sense because it was just kind of jumping it would just jump into conversation making it very interactive moderate will be saying pepper just jump
in hold on how about me can I participate in this doing it just like I heard this is like like a person and I
was 100% scripted and even then it was hard not to have that sense of somehow there is something there so as we have
robots interact in this physical world is that a signal that can be used in reinforcement learning you've you've
worked a little bit in this direction but do you think that's that psychology can be somehow pulled in now so that's a
question I would say a lot a lot of people ask and I think part of why they ask it is
Can robots have emotion
they're thinking about how unique are we really still ask people like after they
see some results they see a computer play go to say computer do this that they're like ok but can it really have
emotion can it really interact with us in that way and then once you're around
robots you already start feeling it and I think that kind of maybe mythologically the way that I think of
it is if you run something like reinforce some Linux about optimizing some objective and there's no reason
that D object couldn't be tied into how much there's a person like interacting
with this system and why could not the reinforcement learning system optimized for their robot being fun to be around
and why wouldn't it then naturally become more and more interactive and more and more maybe like a person or like a pet I
don't know what it would exactly be but more more have those features and acquire them automatically as long as
you can formalize an objective of what it means to like something what how you
exhibit what's the ground truth how do you how do you get the reward from human
cause you have to somehow collect that information within you human but you you're saying if you can
formulate as an objective it can be learned there is no reason it couldn't emergent through learning and maybe one
way to formulate has an objective you wouldn't have to necessarily score it explicitly so standard rewards are
numbers and numbers are hard to come by this is a 1.5 or 0.7 on some scale it's
very hard to do for a person but much easier is for a person to say okay what you did the last five minutes was much
nicer than we did the previous five minutes and that now gives a comparison compare and in fact there have been some
results in that for example Paul Christiana and collaborators at open e I had the hopper madoka Hopper one legged
robot the Batman's little back flips yeah purely from feedback I like this better than that that's kind of equally
good and after a bunch of interactions it figured out what it was the person was asking for it namely a back flip and
so I think the same thing od wasn't trying to do a back flip it was just getting a score from the
comparison score from the person based on hers and having a mind in their own mind what I wanted to do a back flip but
the robot didn't know what it was supposed to be doing it just knew that sometimes the person said this is better
this is worse and then the robot figure it out what the person was actually after was a back flip and I'd imagine
the same would be true for things like more interactive robots that the robot would figure out over time oh this kind
of thing apparently has appreciated more than this other kind of thing so when I
first picked up Sutton's Richard Sutton's reinforcement learning book before sort of this deep
learning before the re-emergence of neural networks is a powerful mechanism for machine learning IRL seemed to me
like magic as a as beautiful so that seemed like what intelligence is RL
reinforcement learning so how do you think we can possibly learn anything
about the world when the reward for the actions is delayed is so sparse like
where is why do you think RL works why do you think you can learn anything
under such sparse awards whether it's regular reinforcement learning a deeper enforcement learning what's your
intuition the kind of part of that is why is RL why does it need so many
Intuition behind RL
samples so many experiences to learn from because really what's happening is when you have a sparse reward you do
something maybe for like I don't know you take a hundred actions and then you get a reward and maybe get like a score
of three and I'm like okay three not sure what that means you go again and now I get to and now you know that that
sequence of hundred actions that you did the second time around somehow was worse than the sequence of hundred actions you did the first time around but that's
tough to now know which one of those were better or worse some might have been good and bad in either one and so
that's why I need so many experience but once you have enough experiences effectively rlist easing that apart it's
time to say okay when what is consistently there when you get a higher reward and what's consistently there
when you get a lower reward and then kind of the magic of sums is the policy grant update is to say
now let's update the neural network to make the actions that were kind of present when things are good more likely
and make the actions that are present when things are not as good less likely so that's that is the counterpoint but
it seems like you would need to run it a lot more than you do even though right now people could say that RL is very
inefficient but it seems to be way more efficient than one would imagine on paper that the the simple updates to the
policy the policy gradient that that's somehow you can learn is exactly users said what are the common actions that
seem to produce some good results that that somehow can learn anything it seems
counterintuitive at least did is there some intuition behind yeah so I think
there's a few ways to think about this the way I Tennant about it mostly originally when so when
we started working on deep reinforcement learning here at Berkeley which was maybe two thousand eleven twelve thirteen around that time
challenge Schulman was a PhD student initially kind of driving it too forward here and did it the way we thought about
it at the time was if you think about rectified linear units or kind of break the fire type neural networks what do
you get you get something that's piecewise linear feedback control and if you look at the literature linear
feedback control is extremely successful can solve many many problems surprisingly well
I remember for example when we did helicopter flight if you're in a stationary flight regime not a non
station by the stationary flight regime like hover you can use linear feedback control to stabilize a helicopter a very complex dynamical system but the
controller is relatively simple and so I think that's a big part of is that if you do feedback control even though the
system you control can be very very complex often relatively simple control
architectures can already do a lot but then also just linear is not good enough and so one way you can think of these
neural networks is that in sometimes they tile the space which people were already trying to do more by hand or
with finite state machines say this linear controller here this leaner controller here you'll network learns
that alva spins a linear controller here another linear controller here but it's more subtle than that yeah and so it's
benefiting from this linear control aspect is benefiting from the tiling but it's somehow tiling it one dimension at
a time because if let's say you have a two layer network even the hidden layer you make a transition from active to
inactive or the other way around that is essentially one axis but not acts as a line but one direction that you change
and so you have this kind of very gradual tiling of the space we have a lot of sharing between the linear
controllers that tile the space and that was always my intuition s of why to expect that this might work pretty well
it's essentially leveraging the fact that linear feedback control is so good but of course not enough and this is a
gradual tiling of the space with linear feedback controls that share a lot of expertise across them so that that's
that's really nice intuition do you think that scales to the more and more general problems of when you start going
up the number of controllers dimensions when you start going down in terms of
how often you get a clean reward signal does that intuition carry forward to
those crazy or weird or worlds that we think of as the real world so I think
Time skills
where things get really tricky in the real world compared to the things we've looked at so far with great success in
reinforcement learning is the time skills which takes us to an
extreme so when you think about the real world I mean I don't know maybe some
student decided to do a a PhD here right okay that's that's the decision that's a
very high-level decision but if you think about their lives I mean any person's life it's a sequence of muscle
fiber contractions and relaxations and that's how you interact with the world and that's a very high frequency control
thing but it's ultimately what you do and how you affect the world until I guess we have brain readings and you can
maybe do it slightly differently but typically that's how you affect the world and the decision of doing a PhD is
like so abstract relative to what you're actually doing in the world and I think that's where credit assignment becomes
just completely beyond what any current RL algorithm can do and we need
hierarchical reasoning at a level that is just not available at all yet where
do you think we can pick up hierarchical reasoning by which mechanisms yeah so maybe let me highlight what I think the
Limitations
limitations are of what already was done 20-30 years ago in fact you'll find
reasoning systems that reason over relatively long horizons but the problems that they were not grounded in
the real world so people would have to hand design some kind of logical
dynamical descriptions of the world and that didn't tie into perception and so
then time to real objects and so forth and so that that was a big gap now with deep learning we start having the
ability to really see with sensors
process that and understand what's in the world and so it's a good time to try to bring these things together one I see
a few ways of getting there one way to get there would be to say deep learning can get bolted on somehow to some of
these more traditional approaches now bolted on would probably mean you need to do some kind of end-to-end training
where you say my deep learning processing somehow leads to a representation that in Perm uses some
kind of traditional underlying dynamical systems that can be used for planning
and that's for example the direction Aviv Tamar and the North Korea touch here have been pushing with causal info
gone and of course other people to that that's that's one way can we somehow force it into the form factor that is
amenable to reasoning another direction we've been thinking about for a long time and they didn't
make any progress on was more information theoretic approaches so the idea there was that what it means to
take high-level action is to take and choose a latent variable now that tells
you a lot about what's gonna be the case in the future because that's what it means to to take a high-level action I
say what I decide I'm gonna navigate to the gas station because need to get gas
for my car well that'll now take five minutes to get there but the fact that I get there I could already tell that from
the high-level action it took much earlier that we had a very hard time
getting success with not saying it's a dead-end necessarily but we had a lot of
trouble getting that to work and then we start revisiting the notion of what are we really trying to achieve what we're
trying to achieve is non ously hierarchy per se but you could think about what does hierarchy give us what it's we hope
it would give us is better credit assignment kind of what is better credit ominous is given is giving us it gives
us faster learning right and so faster
learning is ultimately maybe what we're after and so that's what we ended up with the RL squared paper on learning -
reinforcement learn which at a time rocky duan LED and that's exactly the
meta learning approach or is say okay we don't know how to design hierarchy we know what we want to get from it let's
just enter an optimize for what want to get from it and see if it might emerging we saw things emerge the maze navigation
had consistent motion down hallways which is what you want a hierarchical
control should say I want to go down this hallway and then when there is an option to take a turn I can this art will take a turn or not and repeat even
had the notion of where have you been before or not do not revisit places you've been before it still didn't scale
yet to the real world kind of scenarios I think you had in mind but it was some
sign of life that maybe you can meta learn these hierarchal concepts I mean it seems like through these meta
learning concepts get at the what I think is one of the hardest and most important problems of
AI which is transfer learning so it's generalization how far along this
journey towards building general systems are we being able to do transfer learning well so there's some signs that
you can generalize a little bit but do you think we're on the right path or it's totally different breakthroughs are
needed to be able to transfer knowledge between different learned models yeah
Reusable results
I'm I'm pretty tired on this and then I think there are some very many there
there's just some very impressive results already right I mean yes I would say when even with the initial and a big
breakthrough in 2012 with Aleks net right the initial the initial thing is okay great this does better on imagenet
hands image recognition but then immediately thereafter that was of course the notion that Wow
what was learned on image net and you now want to solve a new task you can fine-tune Aleks net for new tasks and
that was often found to be the even bigger deal that you learned something that was reusable which was not often
the case before usually machine learning you learned something for one scenario and that was it and that's really exciting I mean that's just a huge
application that's probably the biggest success of transfer learning today in terms of scope and impact that was huge
breakthrough and then recently I feel like similar kind of but by scaling
things up it seems like this has been expanded upon like people training even bigger networks they might transfer even
better if you looked at for example some of the opening eye results on language models and some of the recent Google
results on language models they are learned for just prediction and then
they get reused for other tasks and so I think there is something there where
somehow if you train a big enough model on enough things it seems to transfer some deepmind results I thought were
very impressive unreal results where it was learned to navigate mazes in ways
where it wasn't just reinforcement learning going to have other objectives was optimizing for so I think there's a lot of interesting
results already I think maybe words hard to wrap my head around this to which
extend or when do we call something generalization right or the levels of generalization involved in these
different tasks alright so you draw this by the way just to frame things you've
heard you say somewhere it's the difference between learning to master versus learning to generalize that it's
a nice line to think about and it guess you're saying that's a gray area of what
learning to master and learning to generalize where once think I might have heard this I might have heard it
somewhere else and I think it might have been one of one of your interviews and maybe the one with yo show Benjamin on
hundred percent sure but I like the example I'm gonna act not sure who it
was but the example was essentially if you use current deep learning techniques what we're doing to predict let's say
the relative motion of our planets it would do pretty well but then now if a
massive new mass enters our solar system it would prompt predict what will happen
right and that's a different kind of journal is a Shahnaz a generalization that relies on the ultimate simplest
simplest explanation that we have available today to explain the motion of planets where I was just pattern
recognition could predict our current solar system motion pretty well no problem and so I think that's an example
of a kind of generalization that is a little different from what we've achieved so far and it's not clear if
just you know regularizing more I'm forcing it to come up with a simpler simpler simple experience but it's not
simple but that's what physics researchers do right to say can I make this even simpler how simple can I get
this what's a simplest equation I can explain everything right yeah the master equation for the entire dynamics of the
universe we haven't really pushed that direction as hard in in deep learning I would say not sure if it should be
pushed but it seems a kind of generalization you get from that that you don't get in our current methods so far so I just talked to vladimir
vapnik for example who was a statistician the statistical learning and he kind of dreams of creating these
are the a equals e equals mc-squared for learning right the general theory of
learning do you think that's a fruitless pursuit in the near term in within the
next several decades I think that's a really interesting pursuit and in the
Modularity
following sense and that there is a lot of evidence that the brain is pretty
modular and so I wouldn't maybe think of it as the theory maybe the the underlying theory but more kind of the
principle where there have been findings where people who are blind will use the
part of the brain usually used for vision for other functions and even
after some kind of if people will get rewired in some way they might I'm able to reuse parts of their brain for other
functions and so what that suggests is some kind of modularity and I think it
is a pretty natural thing to strive forward to see can we find that modularity can we find this thing of
course it's not every part of the brain is not exactly the same not everything can be rewired arbitrarily but if you
think of things like the neocortex which is pretty big part of the brain that seems fairly modular from what the
findings so far can you design something equally modular and if you can just grow
it it becomes more capable probably I think that would be the kind of interesting underlying principle to
shoot for that is not unrealistic do you think you prefer math or empirical trial
and error for the discovery of the essence of what it means to do something intelligent so reinforcement learning embodies both
groups right then prove that something converges prove the bounds and then at
the same time a lot of those successes are well let's try this and see if it works so which do you gravitate towards
how do you think of those two parts of your brain so
Mathematical Formalisation
maybe I would prefer we could make the progress with mathematics and the reason
maybe I would prefer that is because because often if you have something you can mathematically formalise you can
leapfrog a lot of experimentation and experimentation takes a long time to get through and a lot of trial and error
kind of reinforcement learning your research process but you need to do a lot of trial and error before you get to
a success so if we can leapfrog doubt in my mind that's what the math is about and hopefully once you do a bunch of
experiments you start seeing a pattern you can do some derivations that leapfrog some experiments but I agree
with you I mean in practice a lot of the progress has been such that we have not been able to find the math that allows
it to leapfrog ahead and we are kind of making gradual progress one step at a time a new experiment here a new
experiment there that gives us new insights and gradually building up but not getting to something yet where we're
just okay here's an equation that now explains how you know that would be have been two years of experimentation to get
there but this tells us what the results going to be unfortunately not so much yes not so much yeah but your hope is
there in trying to teach robots or systems to do everyday tasks or even in
simulation what what do you think you're more excited about imitation learning or
self play so letting robots learn from humans or letting robots plan their own to try to
figure out in their own way and eventually play eventually interact with
humans or to solve whatever problem is what's the more exciting to you what's more promising you think as a research
direction so when we look at self play
Selfplay
what's so beautiful about it is goes back to kind of the challenges in reinforcement learning so the challenge
of reinforced learning is getting signal and if you don't never succeed you don't get any signal in self play you're on
both sides so one of you succeeds and the beauty is also one of you fails and so you see the contrast you see the one
version of me that it better the other version and so every time you play yourself you get signal and so
whenever you can turn something into self play you're in a beautiful situation where you can naturally learn
much more quickly than in most other reinforced learning environments so I think I think if somehow we can turn
more reinforcement learning problems into self play formulations that would go real really far so far south play has
been largely around games where there is natural opponents but if we could do
self play if for other things and let's say I don't know a robot learns to build a house I mean that's a pretty advanced thing to try to do for a robot but maybe
it tries to build a hut or something if that can be done through self play it would learn a lot more quickly if
somebody can figure that out and I think that would be something where it goes closer to kind of the mathematical leap
frogging where somebody figures out a formalism to it's okay any RL problem by playing this and this
idea you can turn it into a self play problem where you get signal a lot more easily
reality is many problems we don't know how to turn the self lay and so either we need to provide detailed reward that
doesn't just reward for achieving a goal but rewards for making progress and that becomes time-consuming and once you're
starting to do that let's say you want a robot to do something you need to give all this detailed reward well why not just give a demonstration right because
why not just show the robot and now the question is how do you show the robot one way to show is to tally operate the
robot and then the robot really experiences things and that's nice because that's really high signal-to-noise ratio data and we've
done a lot of that and you teach your robot skills in just 10 minutes you can teach your robot a new basic skill like
okay pick up the bottle place it somewhere else that's a skill no matter where the bottle starts maybe it always goes on to a target or something
that's fairly is a teacher about with tally up now what's even more
interesting if you can now teach robot through third person learning where the robot watches you do something and
doesn't experience it but just watches it and says okay well if you're showing me that that means I should be doing
this and I'm not gonna be using your hand because I don't get to control your hand but I'm gonna use my hand I'd do that mapping and so that's where I think
one of the big breakthroughs has happened this year this was led by Chelsea Finn here it's almost like
machine translation for demonstrations were you have a human demonstration and the robot learns to translated into what
it means for the robot to do it and that was a meta learning for a Malaysian learn from one to get the other and that
I think opens up a lot of opportunities to learn a lot more quickly so my focus is on autonomous vehicles do you think
this approach of third-person watching is about the autonomous driving is amenable to this a kind of approach so
for autonomous driving I would say it's third-person is slightly easier and the
reason I'm gonna say slightly easier to do a third-person is because the hard
dynamics are very well understood so the easier than of first-person you mean or
easier so I think the distinction between third-person and first-person is not a very important distinction for
autonomous driving they're very similar because the distinction is really about
who turns the steering wheel and or maybe I'll let me put it differently how
to get from a point where you are now to a point let's say a couple meters in front of you and that's a problem that's
very well understood and that's the only distinction being third and first-person there whereas with the robot manipulation interaction forces are very
complex and it's still a very different thing for autonomous driving I think
there is still the question imitation versus RL so imitation gives you a lot
more signal I think where imitation is lacking and needs some extra machinery
is it doesn't in its normal format doesn't think about goals or objectives
and of course there are versions of imitation learning inverse reinforce learning type imitation which also
thinks about goals I think then we're getting much closer but I think it's very hard to think of a fully reactive
car generalizing well if it really doesn't have a notion of objectives to
generalize well to the kind of general that you would want you'd want more than just that reactivity that you get from
just behavioral cloning / supervised learning so a lot of the work whether
its self play imitation learning would benefit significantly from simulation from
effective simulation and you're doing a lot of stuff in the physical world and in simulation do you have hope for
greater and greater power of simulation loop being boundless eventually to where
most of what we need to operate in the physical world would could be simulated to a degree that's directly transferable
to the physical world are we still very far away from that so I think we could
Simulation
even rephrase that question in some sense please so the power of simulation
right simulators get better and better of course become stronger and we can
learn more in simulation but there's also another version which is where you said the simulator doesn't even have to
be that precise as long as is somewhat representative and instead of trying to get one simulator that is sufficiently
precise to learn in and transfer really well to the real world I'm gonna build many simulators ensemble
of simulators ensemble of simulators not any single one of them is sufficiently
representative of the real world such that it would work if you train in there but if you train in all of them then
there is something that's good in all of them the real world will just be you know another one that's you know cannot
identical to any one of them but just another one of them another sample from the distribution of simulators exact we
do live in a simulation so this is just like oh one other one I'm not sure about that video it's definitely a very
advanced simulator if it is yeah it's pretty good one I've talked to this to Russell is something you think about a
little bit too of course you're like really trying to build these systems but do you think about the future of AI a
lot of people have concerned about safety how do you think about AI safety as you build robots that are operating
in the physical world what what is uh yeah how do you approach this problem in
an engineering kind of way in a systematic way so what a robot is doing
Safety
things you kind of have a few notions of safety to worry about one is that Throwbot is
physically strong and of course could do a lot of damage same for cars which we
can think of as robots do in some way and this could be completely unintentional so it could be not the
kind of long-term AI safety concerns that okay a is smarter than us and now what do we do but it could be just very
practical okay this robot if it makes a mistake whether the results going to be of
course simulation comes in a lot there too to test in simulation it's a
difficult question and I'm always wondering like I was wondering at let's go back to drivings a lot of people know
driving well of course what do we do to test somebody for driving right to get a
driver's license what do they really do I mean you fill out some test and then
you drive and I mean perfume in suburban California the driving test is just you
drive around the block pull over you do a stop sign successfully and then you
know you pull over again and you pretty much done and you're like okay if a self-driving car did dad would you trust
it that it can drive and be like no that's not enough for me to trust but somehow for humans we've figured out
that somebody being able to do that it's representative of them being able to do
a lot of other things and so I think somehow for you must we figured out representative tests of what it means if
you can do this what you can really do of course testing you must you must all want to be tested at all times
self-driving cars the robots can be tested more often probably you can have replicas that get testament are known to
be identical because they use the same neural net and so forth but still I feel like we don't have this kind of unit
tests or proper tests for for robots and I think there's something very interesting to be thought about there
especially as you update things your software improves you have a better self driving car suite you updated how do you
know it's indeed more capable on everything than what you had before that you didn't have any bad things creep
into it so I think that's a very interesting direction of research that there is no real solution yet
except that's somehow for you must we do because we say okay you have a driving test you passed you can go on the road
now and you must have accents every like a million or ten million miles something something pretty phenomenal compared to
that short test yeah that is being done so let me ask you've mentioned
you mentioned that Andrew Aang by example showed you the value of kindness and to do you think the space of
policies good policies for humans and for AI is populated by policies that
with kindness or ones that are the opposite exploitation even evil so if
you just look at the sea of policies we operate under as human beings or if AI system had to operate in this real world
do you think it's really easy to find policies that are full of kindness like we naturally fall into them or is it
like a very hard optimization problem I
Human evolution
mean there is kind of two optimizations happening for humans right so for you
most was kinda the very long-term optimization which evolution has done for us and we're kind of predisposed to
like certain things and that's in sometimes what makes our learning easier because I mean we know things like pain
and hunger and thirst and the fact that we know about those is not something
that we were taught that's kind of innate when we're hungry were unhappy when we're thirsty were unhappy when we
have pain we're unhappy and ultimately evolution built that into us to think
about this thing so so I think there is a notion that it seems somehow humans evolved in general to prefer to get
along in some ways but at the same time also to be very territorial and kind of
centric to their own tribe is it like it seems like that's the kind of space we
converge down to it I mean I'm not an expert in anthropology but it seems like we're very kind of good within our own
tribe but need to be taught but to be nice to other tribes well if you look at
Steven Pinker he highlights is pretty nicely in better better angels of our nature where
he talks about violence decreasing over time consistently so whatever attention whatever teams we pick it seems that the
long arc of history goes towards us getting along more and more so I hope so
so do you think that do you think it's possible to cheat teach RL bass robots
the this kind of kindness this kind of ability to interact with humans this kind of policy even - let me ask let me
ask a fun one do you think it's possible to teach RL based robot to love a human being and to inspire that human to love
the robot back so - like RL based algorithm that leads to a happy marriage
that's interesting question maybe I'll oh I'll answer it with with another
question right I mean it's it but I'll come back to it so another question you
can have is okay I mean how close does some people's happiness get from interacting with just
a really nice dog like I mean dogs you come home that's what dogs did they
greet you they're excited it makes you happy when you're coming home to your dog just like okay this is exciting
they're always happy when I'm here and if they don't greet you because maybe whatever your partner took them on a
trip or something you might not be nearly as happy when you get home right and so the kind of it seems like the
level of reasoning a dog houses is pretty sophisticated but then it's still not yet at the level of human reasoning
and so it seems like we don't even need to achieve human love reason to get like very strong affection with humans and so
my thinking is why not right why couldn't with an AI couldn't we achieve the kind of level of affection that
humans feel among each other or with friendly animals and so forth it's a
question is it a good thing for us or not that misses another going right because I mean
but I don't see why not why not yeah so he almost says love was the answer maybe
he should say love is the objective function and then RL is the answer maybe
I'll Peter thank you so much I don't want to take up more of your time thank you so much for talking today well
thanks for coming by great to have you visit
you

----------

-----

--50--

-----
Date: 2018.12.09
Link: [# Stuart Russell: Long-Term Future of Artificial Intelligence | Lex Fridman Podcast #9](https://www.youtube.com/watch?v=KsZI5oXBC0k)
Transcription:

the following is a conversation with Stuart Russell he's a professor of computer science at UC Berkeley and a
co-author of a book that introduced me and millions of other people to the amazing world of AI called artificial
intelligence a modern approach so it was an honor for me to have this conversation as part of MIT course and
artificial general intelligence and the artificial intelligence podcast if you enjoy it please subscribe on youtube
itunes or your podcast provider of choice or simply connect with me on twitter at Lex Friedman spelled Fri D
and now here's my conversation with Stuart Russell so you've mentioned in
1975 in high school you've created one year first AI programs that play chess
were you ever able to build a program that beat you a chess or another board
game so my program never beat me at chess I actually wrote the program at
Imperial College so I used to take the bus every Wednesday with a box of cards
this big and shove them into the card reader and they gave us eight seconds of
CPU time it took about five seconds to read the cards in and compile the code so we had
three seconds of CPU time which was enough to make one move you know with a not very deep search and then we would
print that move out and then we'd have to go to the back of the queue and wait to feed the cards in again how do you
post a search well I would talk to no I think we got we got an eight move eight
you know depth eight with alpha beta and we had some tricks of our own about move
ordering and some pruning of the tree and we were still able to beat that program yeah yeah I I was a reasonable
chess player in my youth I did Anna fellow program and a backgammon program
so when I go to Berkley I worked a lot on what we call meta reasoning which
really means reasoning about reasoning and in the case of a game playing program you need to reason about what
parts of the search tree you're actually going to explore because the search tree is enormous or you know bigger than the
number of atoms in the universe and the way programs succeed and the way humans
succeed is by only looking at a small fraction of the search tree and if you look at the right fraction you play
really well if you look at the wrong fraction if you waste your time thinking about things that are never gonna happen
the moves that no one's ever gonna make then you're gonna lose because you you won't be able to figure out the right
decision so that question of how machines can manage their own computation either how
they decide what to think about is the meta-reasoning question we developed some methods for doing that
and very simply a machine should think about whatever thoughts are going to
improve its decision quality we were able to show that both for a fellow
which is a standard to play game and for backgammon which includes dice for also
it's a two-player game with uncertainty for both of those cases we could come up with algorithms that were actually much
more efficient than the standard alpha beta search which chess programs at the
time we're using and that those programs could beat me and I think you can see
same basic ideas in alphago and alpha zero today the way they explored the
tree is using a former meta reasoning to select what to think about based on how
useful it is to think about it is there any insights you can describe without
Greek symbols of how do we select which paths to go down there's really two
kinds of learning going on so as you say alphago learns to evaluate board
position so it can it can look at a go board and it actually has probably a
superhuman ability to instantly tell how promising that situation is to me the
amazing thing about alphago is not that it can be the world champion with its
hands tied behind his back but the fact that if you stop it from searching
altogether so you say okay you're not allowed to do any thinking ahead right you can just consider each of your
legal moves and then look at the resulting situation and evaluate it so what we call a depth one search so just
the immediate outcome of your moves and decide if that's good or bad that version of alphago can still play
at a professional level right and human professionals are sitting there for five ten minutes deciding what to do and
alphago in less than a second instantly into it what is the right move
to make based on its ability to evaluate positions and that is remarkable because
you know we don't have that level of intuition about go we actually have to think about the situation so anyway that
capability that alphago has is one big part of why it beats humans the other
big part is that it's able to look ahead 40 50 60 moves into the future mm-hmm
and you know if it was considering all possibilities 40 or 50 or 60 moves into
the future that would be you know 10 to the 200
possibility so wait way more than you know atoms in the universe and and so on
so it's very very selective about what it looks at
so let me try to give you an intuition about how you decide what to think about
it's a combination of two things one is how promising it is right so if you're
already convinced that a move is terrible there's no point spending a lot more time convincing yourself that it's
terrible because it's probably not gonna change your mind so the the real reason
you think is because there's some possibility of changing your mind about what to do mm-hmm right and is that changing your mind
that would result then in a better final action in the real world so that's the
purpose of thinking is to improve the final action in the real world and so if
you think about a move that is guaranteed to be terrible you can convince yourself is terrible and you're
still not gonna change your mind all right but on the other hand you I suppose you had a choice between two moves one of
them you've already figured out is guaranteed to be a draw let's say and then the other one looks a little bit
worse like it looks fairly likely that if you make that move you're gonna lose but there's still some uncertainty about
the value of that move there's still some possibility that it will turn out to be a win all right then it's worth
thinking about that so even though it's less promising on average than the other
move which is guaranteed to be a draw there's still some purpose in thinking about it because there's a chance that you will change your mind and discover
that in fact it's a better move so it's a combination of how good the move appears to be and how much I'm certainty
there is about its value the more uncertainty the more it's worth thinking about because there's a higher upside if
you want to think of it that way and of course in the beginning especially in the alphago 0 formulation it's
everything is shrouded in uncertainty so you're really swimming in a sea of uncertainty so it benefits you too I
mean actually following the same process as you described but because you're so uncertain about everything you you
basically have to try a lot of different directions yeah so so the early parts of the search tree a fairly bushy
that it will when looking a lot of different possibilities but fairly quickly the degree of certainty about
some of the moves I mean if a movies are really terrible you'll pretty quickly find out right you lose half your pieces
or half your territory and and then you'll say okay this this is not worth thinking about any more and then so a
further down the tree becomes very long and narrow and you're following various
lines of play you know 10 20 30 40 50 moves into the future and you know
that's again it's something that human beings have a very hard time doing mainly because they just lacked the
short-term memory you just can't remember a sequence of moves that's 50 movies long and you can't you can't
imagine the board correctly for that money moves into the future of course
the top players I'm much more familiar with chess but the top players probably
have they have echoes of the same kind of intuition instinct that in a moment's
time alphago applies when they see a board I mean they've seen those patterns human
beings have seen those patterns before at the top at the Grandmaster level it seems that there is some similarities or
maybe it's it's our imagination creates a vision of those similarities but it feels like this kind of pattern
recognition that the alphago approaches are using is similar to what human
beings at the top level or using I think there's there's some truth to that but
not entirely yeah I mean I think the the extent to which a human Grandmaster can
reliably wreak instantly recognize the right move instantly recognize the value of a position I think that's a little
bit overrated but if you sacrifice a queen for exam I mean there's these there's these beautiful games of chess
with Bobby Fischer somebody where it's seeming to make a bad move and I'm not
sure there's a a perfect degree of calculation involved were they've calculated all the possible
things that happen but there's an instinct there right that somehow adds up to the yeah so I think what happens
is you you you get a sense that there's some possibility in the position even if
you make a weird-looking move that it opens up some some lines of of
calculation that otherwise would be definitely bad and and is that intuition
that there's something here in this position that might might yield a win
down the side and then you follow that right and and in some sense when when a
chess player is following a line and in his or her mind they're they mentally
simulating what the other person is gonna do while the opponent is gonna do and they can do that as long as the
moves are kind of forced right as long as there's a you know there's a fourth
we call a forcing variation where the opponent doesn't really have much choice how to respond and then you see if you
can force them into a situation where you win you know we see plenty of mistakes even even in Grandmaster games
where they just miss some simple three four five move combination that you know
wasn't particularly apparent in in the position but we're still there that's the thing that makes us human
yeah so when you mentioned that in a fellow those games were after some meta
reasoning improvements and research I was able to beat you how did that make you feel part of the meta reasoning
capability that it had was based on learning and and you could sit down the
next day and you could just feel that it had got a lot smarter boom you know and
all the sudden you really felt like you sort of pressed against the wall because it was it was much more
aggressive and was totally unforgiving of any minor mistake that you might make
and and actually it seemed understood the game better than I did and you know
Gary Kasparov has this quote weary during his match against deep blue he
said he suddenly felt that there was a new kind of intelligence across the board do you think that's a scary or an
exciting possibility that's prevent for yourself in in the context of chess
purely sort of in this like that feeling whatever that is I think it's definitely
an exciting feeling you know this is what made me work on AI in the first
place was as soon as I really understood what a computer was I wanted to make it smart you know I started out with the
first program I wrote was for the sinclair programmable calculator and i think you could write a 21 step
algorithm that was the biggest program you could write something like that and
do little arithmetic calculations so I say think I implemented Newton's method for square roots and a few other things
like that um but then you know I thought okay if I just had more space I could make this
thing intelligent and so I started thinking about AI and
and I think the the the thing that's scary is not is not the chess program
because you know chess programs they're not in they're taking over the world business but if you extrapolate
you know there are things about chess that don't resemble the real world right we know we know the rules of chess
chess board is completely visible to the programmer of course the real world is not most you most the real world is not
visible from wherever you're sitting so to speak and to overcome those kinds of problems
you need qualitatively different algorithms another thing about the real
world is that you know we we regularly plan ahead on the timescales involving
billions or trillions of steps now we don't plan that was in detail but you
know when you choose to do a PhD at Berkeley that's a five-year commitment and that
amounts to about a trillion motor control steps that you will eventually be committed to including going up the
stairs opening doors drinking water type yeah I mean every every finger movement
while you're typing every character of every paper and the thesis and everything else so you're not commuting in advance to the specific motor control
steps but you're still reasoning on a timescale that will eventually reduce to
trillions of motor control actions and so for all these reasons
you know alphago and and deep blue and so on don't represent any kind of threat
to humanity but they are a step towards it right near that and progress in AI
occurs by essentially removing one by one these assumptions that make problems
easy like the assumption of complete observability of the situation right we
remove that assumption you need a much more complicated kind of a computing
design and you need something that actually keeps track of all the things you can't see and tries to estimate
what's going on and there's inevitable uncertainty in that so it becomes a much
more complicated problem but you know we are removing those assumptions we are
starting to have algorithms that can cope with much longer timescales they can cope with uncertainty they can
cope with partial observability and so each of those steps sort of
magnifies by a thousand the range of things that we can do with AI systems so
the way I started me I wanted to be a psychiatrist for long time to understand the mind in high school and of course
program and so on and then I showed up University of Illinois to an AI lab and
they said okay I don't have time for you but here's a book AI a modern approach I
think was the first edition at the time mmm here go go learn this and I remember
the lay of the land was well it's incredible that we solve chess but we'll never solve go I mean it was pretty
certain that go in the way we thought about systems that reason was impossible
to solve and now we've solved this as a very I think I would have said that it's
unlikely we could take the kind of algorithm that was used for chess and
just get it to scale up and work well for go
and at the time what we thought was that
in order to solve go we would have to do something similar to the way humans
manage the complexity of go which is to break it down into kind of sub games so when a human thinks about a go board
they think about different parts of the board as sort of weakly connected to each other and they think about okay
within this part of the board here's how things could go and that part about his how things could go and now you try to
sort of couple those two analyses together and deal with the interactions and maybe revise your views of how
things are going to go in each part and then you've got maybe five six seven ten parts of the board and that actually
resembles the real world much more than chess does because in the real world you
know we have work we have home life we have sport you know whatever different
kinds of activities you know shopping these all are connected to each other
but they're weakly connected so when I'm typing a paper you know I don't simul
taneous Li have to decide which order I'm gonna get the you know the milk and the butter you know that doesn't affect
the typing but I do need to realize okay better finish this before the shops
closed because I don't have anything you don't have any food at home all right right so there's some weak connection but not in the way that chess works
where everything is tied into a single stream of thought so the thought was
that go just sort of go we'd have to make progress on stuff that would be useful for the real world and in a way
alphago is a little bit disappointing right because the the program designed
for alphago was actually not that different from from deep blue or even
from Arthur Samuels checker playing program from the 1950s
and in fact the so the two things that make alphago work is one one is is amazing ability ability to evaluate the
positions and the other is the meta-reasoning capability which which allows it to to explore some paths in
the tree very deeply and to abandon other paths very quickly so this word
meta-reasoning while technically correct inspires perhaps the the wrong degree of
power that alphago has for example the word reasonings as a powerful word let me ask you sort of so you were part of
the symbolic AI world for a while like whatever the AI was there's a lot of
excellent interesting ideas there that unfortunately met a winter and so it do
you think it really emerges well I would say yeah it's not quite as simple as
that so the the AI winter so for the
first window that was actually named as such was the one in the late 80s
and that came about because in the mid 80s there was a really a concerted
attempt to push AI out into the real world using what was called expert
system technology and for the most part that technology was just not ready for
primetime they were trying in many cases to do a form of uncertain reasoning judge you
know judgment combinations of evidence diagnosis those kinds of things which
was simply invalid and when you try to apply invalid reasoning methods to real
problems you can fudge it for small versions of the problem but when it starts to get larger the thing just
falls apart so many companies found that the stuff just didn't work and they were
spending tons of money on consultants to try to make it work and there were you know other practical
reasons like you know they they were asking the companies to buy incredibly expensive lisp machine workstations
which were literally between fifty and a hundred thousand dollars in you know in
1980s money which was would be like between a hundred and fifty and three hundred thousand dollars per workstation
in current prices so then the bottom line they weren't seeing a profit from it yeah
they in many cases I think there were some successes there's no doubt about that but people I would say over
invested every major company was starting an AI department just like now
and I worry a bit that we might see similar disappointments not because the
technology is invalid but it's limited in its scope and it's almost the the
dual of the you know the scope problems that expert systems had so what have you
learned from that hype cycle and what can we do to prevent another winter for example yeah so when I'm giving talks
these days that's one of the warnings that I give to to pot warning slide one
is that you know rather than data being the new oil data is the new snake oil
that's a good line and then and then the other is that we might see a kind of
very visible failure in some of the major application areas and I think self-driving cars would be the flagship
and I think when you look at the history
so the first self-driving car was on the freeway driving itself changing lanes
overtaking in 1987 and so it's more than
30 years and that kind of looks like where we are today right you know
prototypes on the freeway changing lanes and overtaking now I think significant
progress has been made particularly on the perception side so we worked a lot on autonomous vehicles in the early mid
90s at Berkley you know and we had our own big demonstrations you know we we
put congressmen into yourself driving cars and and had them zooming along the freeway
and the problem was clearly perception at the time the problem that perception
yeah so in simulation with perfect perception you could actually show that
you can drive safely for a long time even if the other cars are misbehaving and and so on but simultaneously we
worked on machine vision for detecting cars and tracking pedestrians and so on
and we couldn't get the reliability of detection and tracking up to a high
enough particular level particularly in bad weather conditions nighttime
rainfall good enough for demos but perhaps not good enough to cover the general the general yeah the thing about
driving is you know suppose you're a taxi driver you know and you drive every day eight hours a day for ten years
right that's a hundred million seconds of driving you know and any one of those
seconds you can make a fatal mistake so you're talking about eight nines of
reliability right now if your vision system only detects ninety eight point
three percent of the vehicles right and that's sort of you know one on a bit
nines and reliability so you have another seven orders of magnitude to go and and this is what people don't
understand they think oh because I had a successful demo I'm pretty much done but
you know you're not even within seven orders of magnitude of being done and
that's the difficulty and it's it's not there can I follow a white line that's
not the problem right we follow a white line all the way across the country but it's the it's the weird stuff that
happens it's some of the edge cases yeah the edge case other drivers doing weird things you know so if you talk to Google
right so they had actually very classical architecture where you know
you had machine vision which would detect all the other cars and pedestrians and the white lines and the
road signs and then basically that was fed into a logical database and then you
had a classical 1970s rule-based expert system telling you okay if you're in the
middle lane and there's a bicyclist in the right lane who is signaling this then then then don't need to do that yeah right and what they found was that
every day they go out and there'd be another situation that the rules didn't cover you know so they they come to a
traffic circle and there's a little girl riding a bicycle the wrong way around a traffic circle okay what do you do we
don't have a rule oh my god okay stop and then you know they come back and had
more rules and they just found that this was not really converging and and if you think about it right how
how do you deal with an unexpected situation meaning one that you've never
previously encountered and the sort of the the reasoning required to figure out
the solution for that situation has never been done it doesn't match any previous situation in terms of the kind
of reasoning you have to do well you know in chess programs this happens all the time
you're constantly coming up with situations you haven't seen before and
you have to reason about them you have to think about okay here are the possible things I could do here the
outcomes here's how desirable the outcomes are and then pick the right one you know in the 90s we were saying okay
this is how you're gonna have to do automated vehicles they're gonna have to have a look ahead capability but the
look ahead for driving is more difficult than it is for chess because Huysmans the other right there's humans and
they're less predictable than just a standard well then will you have an opponent in chess who's also somewhat
unpredictable but for example in chess you always know the opponent's intention
they're trying to beat you right whereas in driving you don't know is this guy trying to turn left or has he just
forgotten to turn off his tone signal or is he drunk or is he you know changing
the channel on his radio or whatever it might be you got to try and figure out the mental state the intent of the other
drivers to forecast the possible evolutions of their trajectories and
then you've got to figure out okay which is the directory for me that's going to be safest and those all interact with
each other because the other drivers going to react to your trajectory and so
on so you know they've got the classic merging onto the freeway a problem where you're kind of racing a vehicle that's
already on the freeway and you are you gonna pull ahead of them or you're gonna let them go first and pull in behind and you get this sort of uncertainty about
who's going first so all those kinds of things
mean that you need decision-making architecture that's very different from
either a rule-based system or it seems to me a kind of an end-to-end neural network system you know so just as
alphago is pretty good when it doesn't do any look ahead but it's way way way way better when it does I think the same
is going to be true for driving you can have a driving system that's pretty good when it doesn't do any look ahead but
that's not good enough you know and we've already seen multiple deaths caused by poorly designed machine
learning algorithms that don't really understand what they're doing yeah and on several levels I think it's on the
perception side there's mistakes being made by those algorithms were the perception is very shallow on the
planning side to look ahead like you said and the thing that we come come up
against that's really interesting when you try to deploy systems in the real
world is you can't think of an artificial intelligence system as a thing that responds to the world always
you have to realize that it's an agent that others will respond to as well so in order to drive successfully you can't
just try to do obstacle avoidance you can't pretend that you're invisible thank you right you're the invisible car
right just look that way I mean but you have to assert yet others have to be scared of you just we're all there's
this tension there's this game so if we studied a lot of work with pedestrians
if you approach pedestrians as purely an obstacle avoidance so you either doing
look ahead isn't modeling the intent that you're you they're not going to they're going to take advantage of you
they're not going to respect you at all there has to be a tension a fear some amount of uncertainty that's how we have
create we or at least just a kind of a resoluteness right so you have you have
to display a certain amount of resoluteness you can't you can't be too tentative and yeah so the right the the solutions
then become pretty complicated right you get into game theoretic yes analyses and
so we're you know Berkeley now we're working a lot on this kind of
interaction between machines and humans and that's exciting yeah and so my
colleague and could drag an actually you
know if you if you formulate the problem game theoretically and you just let the system figure out the solution you know
it does interesting unexpected things like sometimes at a stop sign if no one is going first right the car
will actually back up a little all right and just to indicate to the other cars that they should go and that's something
it invented entirely by itself that's interesting you know we didn't say this is the language of communication at stop
signs it figured it out that's really interesting so let me one just step back for a
second just this beautiful philosophical notion so Pamela I'm a quartic in 1979
wrote AI began with the ancient wish to forge the gods so when you think about
the history of our civilization do you think that there is an inherent desire
to create let's not say gods but to create super intelligence is it inherent
to us is it in our genes that the natural arc of human civilization is to
create things that are of greater and greater power and perhaps no echoes of
ourselves so to create the gods as Pamela said
if the maybe I mean you know we're all we're all individuals
certainly we see over and over again in history individuals who thought about
this possibility hopefully when I'm not being too philosophical here but if you
look at the arc of this you know where this is going and we'll talk about AI
safety we'll talk about greater and greater intelligence do you see that
there in when you created the earth Allah program and you felt this excitement what was that excitement was it
excitement of a tinkerer who created something cool like a clock or was there
a magic or was it more like a child being born that yeah you know yeah so I
mean I certainly understand that viewpoint and if you look at the light
he'll report which was commit so in the 70s there was a lot of controversy in
the UK about AI and you know whether it was for real and how much the money
money the government should invest and there was a lot long story but the
government commissioned a report by by light Hill who was a physicist and he
wrote a very damning report about AI which I think was the point and he said
that that these are you know frustrated men who unable to have children would
like to create and you know create life you know as a kind of replacement you
know which I which I think is really pretty unfair
but there is I mean there there is a kind of magic I would say you when you
you build something and what you're building in is really
just you're building in some understanding of the principles of learning and decision-making and to see
those principles actually then turn into intelligent behavior in in specific
situations it's an incredible thing and
you know that is naturally going to make
you think okay where does this end and so there's a there's magical optimistic
views of word and whatever your view of optimism is whatever your view of utopia
is it's probably different for everybody yeah but you've often talked about
concerns you have of how things might go wrong so I've talked to max tegmark
there's a lot of interesting ways to think about AI safety you're one of the
seminal people thinking about this problem among sort of being in the weeds of actually solving specific AI problems
you also think about the big picture of where we're going so can you talk about several elements of it let's just talk
about maybe the control problem so this idea of losing ability to control the
behavior and of a AI system so how do you see that how do you see that coming
about what do you think we can do to manage it well so it doesn't take a
genius to realize that if you make something that's smarter than you you might have a problem you know in Turing
Alan Turing you know wrote about the gave lectures about this you know 19
1951 painted a lecture on the radio and
he basically says you know once the machine thinking method stops you know
very quickly they'll outstrip humanity and you know if we're lucky we might be
able to I think he says if we may be able to turn off the power at strategic
moments but even so a species would be humbled yeah you can actually I think
was wrong about that right here is you you know if it's a sufficiently intelligent machine is not gonna let you switch it off so it's actually in
competition with you so what do you think is meant just for a quick tangent if we shut off this super intelligent
machine that our species will be humbled I think he means that we would realize
that we are inferior right that we we only survive by the skin of our teeth
because we happen to get to the off switch just in time
you know and if we hadn't then we would have lost control over the earth so do you are you more worried when you
think about this stuff about super intelligent AI or are you more worried about super powerful AI that's not
aligned with our values so the paperclip scenario is kind of I think so the main
problem I'm working on is is the control problem the the problem of machines
pursuing objectives that are as you say not aligned with human objectives and
and this has been it has been the way we've thought about I eyes since the
beginning you you build a machine for
optimizing and then you put in some objective and it optimizes right and and
you know we we can think of this as the the King Midas problem right because if
you know so King Midas put in this objective right everything I touch you turned to gold and the gods you know
that's like the machine they said okay done you know you now have this power and of course his food and his drink and
his family all turned to gold and then he's sighs misery and starvation and
this is you know it's it's a warning it's it's a failure mode that pretty
much every culture in history has had some story along the same lines you know
there's the the genie that gives you three wishes and you know third wish is always you know please undo the first
two wishes because I messed up and you know and when author Samuel
wrote his chest his checkup laying program which learned to play checkers considerably better than Martha Samuel
could play and actually reached a pretty decent standard
Norbert Wiener who was a one of the major mathematicians of the 20th century
sort of a father of modern automation control systems you know he saw this and he basically
extrapolated you know as Turing did and said okay this is how we could lose
control and specifically that we have to
be certain that the purpose we put into the machine as the purpose which we really desire and the problem is we
can't do that right you mean we're not it's a very difficult to encode so to
put our values on paper is really difficult or you're just saying it's impossible your line is writing this so
it's it theoretically it's possible but in practice it's extremely unlikely that
we could specify correctly in advance the full range of concerns of humanity
that you talked about cultural transmission of values I think is how humans to human transmission of values
happens right what we learned yeah I mean as we grow up we learn about the
values that matter how things how things should go what is reasonable to pursue
and what isn't reasonable to pursue machines can learn in the same kind of way yeah so I think that what we need to
do is to get away from this idea that you build an optimizing machine and you put the objective into it
because if it's possible that you might put in a wrong objective and we already
know this is possible because it's happened lots of times alright that means that the machine should never take
an objective that's given as gospel truth because once it takes them the the
objective is gospel truth alright then it's the leaves that whatever actions
it's taking in pursuit of that objective are the correct things to do so you could be jumping up and down and saying
no you know no no no you're gonna destroy the world but the machine knows what the true objective is and it's
pursuing it and tough luck to you you know and this is not restricted to AI
right this is you know I think many of the 20th century technologies right so in statistics you you minimize a loss
function the loss function is exogenously specified in control theory you minimize a cost function in
operations research you maximize a reward function and so on so in all these disciplines this is how we
conceive of the problem and it's the wrong problem because we cannot specify
with certainty the correct objective right we need uncertainty we the machine
to be uncertain about a subjective what it is that it's post it's my favorite idea of yours I've heard you say
somewhere well I shouldn't pick favorites but it just sounds beautiful we need to teach machines humility yeah
I mean it's a beautiful way to put it I love it that they humble oh yeah they know that
they don't know what it is they're supposed to be doing and that those those objectives I mean they exist they
are within us but we may not be able to explicate them we may not even know you
know how we want our future to go so exactly and the Machine you know a
machine that's uncertain he's going to be deferential to us so if we say don't
do that well now the machines learn something a bit more about our true objectives because something that it
thought was reasonable in pursuit of our objectives turns out not to be so now it's learn something so it's going to
defer because it wants to be doing what we really want and you know that that point I think is
absolutely central to solving the control problem and it's a different kind of AI when you when you take away
this idea that the objective is known then in fact a lot of the theoretical
frameworks that we're so familiar with you know Markov decision processes goal
based planning you know standard games research all of these techniques
actually become inapplicable and you get a more complicated problem because
because now the interaction with the
human becomes part of the problem because the human by making choices is
giving you more information about the 'true objective and that information helps you achieve the objective better
and so that really means that you're mostly dealing with game theoretic
problems where you've got the machine and the human and they're coupled together rather than a machine going off
by itself with a fixed objective which is fascinating on the machine and the
human level that we when you don't have an objective means you're together
coming up with an objective I mean there's a lot of philosophy that you know you could argue that life doesn't
really have meaning we we together agree on what gives it meaning and we kind of culturally create things that give why
the heck we are in this earth anyway we together as a society create that meaning and you have to learn that
objective and one of the biggest I thought that's what you were gonna go for a second
one of the biggest troubles we've run into outside of statistics and machine learning and AI and just human
civilization is when you look at I came from the south was born in the Soviet
Union and the history of the 20th century we ran into the most trouble us
humans when there was a certainty about the objective and you do whatever it
takes to achieve that objective whether you talking about in Germany or communist Russia oh yeah I get the
trouble I would say with you know corporations in fact some people argue that you know we don't have to look
forward to a time when AI systems take over the world they already have and they call corporations right that
corporations happen to be using people as components right now but they are
effectively algorithmic machines and they're optimizing an objective which is quarterly profit that isn't aligned with
overall well-being of the human race and they are destroying the world they are primarily responsible for our inability
to tackle climate change right so I think that's one way of thinking about what's going on with
with cooperations but I think the point you're making you is valid that there
are there are many systems in the real world where we've sort of prematurely
fixed on the objective and then decoupled the the machine from those
that's supposed to be serving and I think you see this with government right
government is supposed to be a machine that serves people but instead it tends
to be taken over by people who have their own objective and use government
to optimize that objective regardless of what people want do you have do you find
appealing the idea of almost arguing machines where you have multiple I systems with a clear fixed objective we
have in government the red team and the blue team that are very fixed on their objectives and they argue and it kind of
maybe it would disagree but it kind of seems to make it work somewhat that the
the duality of it okay let's go a hundred years back when there was still
was going on or at the founding of this country there was disagreement and that disagreement is where so there's a
balance between certainty and forced humility because the power was distributed yeah I think that the the
the nature of debate and disagreement argument takes as a premise the idea
that you could be wrong right which means that you're not necessarily
absolutely convinced that your objective is the correct one right if you were
absolutely Guiness there'll be no point in having any discussion or argument because you would never change your mind and there wouldn't be any any sort of
synthesis or or anything like that so so I think you can think of argumentation as a as an implementation of a form of
uncertain reasoning and you know I I've been reading
recently about utilitarianism in the history of efforts to define in a sort
of clear mathematical way a I feel like a formula for moral or
political decision-making and it's really interesting that the parallels between the philosophical discussions
going back 200 years and what you see now in discussions about existential
risk because you it's almost exactly the same so someone would say okay well
here's a formula for how we should make decisions right so utilitarianism you know each person has a utility
function and then we make decisions to maximize the sum of everybody's utility
mm-hmm right and then people point out well you know in that case the best
policy is one that leads to the enormous lis vast population all of whom are
living a life that's barely worth living right and this is called the repugnant conclusion and you know another version
is you know that we we should maximize pleasure and that's what we mean by utility and then you'll get people
effectively saying well in that case you know we might as well just have everyone hooked up to a heroin drip yeah you know
and they didn't use those words but that debate you know what's happening in the 19th century as it is now about AI that
if we get the formula wrong you know we're going to have AI systems working
towards an outcome that in retrospect would be exactly wrong do you think
there's it has beautifully put so the the echoes are there but do you think I mean if you look at sam Harris is our
imagination worries about the AI version of that because of the speed at which
the things going wrong in the utilitarian context could happen yeah is
that is that a worry for you yeah I I think that you know it in most cases not in all but
you know if we if we have a wrong political idea you know we see it starting to go wrong and we're you know
we're not completely stupid and so we said okay that was maybe that was a mistake
let's try something different and and also we're very slow and inefficient
about implementing these things and so on so you have to worry when you have corporations or political systems that
are extremely efficient but when we look at AI systems or even
just computers in general right they have this different characteristic from
ordinary human activity in the past so let's say you were a surgeon you had
some idea about how to do some operation right well and let's say you were wrong all right that that way of doing the
operation would mostly kill the patient well you'd find out pretty quickly like
after three maybe three or four tries right but
that isn't true for pharmaceutical companies because they don't do three or
four operations they they manufacture three or four billion pills and they sell them and then they find out maybe
six months or a year later that oh people are dying of heart attacks or getting cancer from this drug and so
that's why we have the FDA right because of the scalability of pharmaceutical
production and you know and there have been some unbelievably bad episodes in
the history of pharmaceuticals and and adulteration of of products and so on
that that have killed tens of thousands or paralysed hundreds of thousands of people now with computers we have that
same scalability problem that you can sit there and type for I equals 1 to 5
billion do right and all of a sudden you're having an impact on a global scale and yet we have no FDA right
there's absolutely no controls at all it's over what a bunch of undergraduates
with too much caffeine can do to the world and you know we look at what
happened with Facebook well social media in general and click-through optimization so you have a simple
feedback algorithm that's trying to just optimize click-through that sounds
reasonable right because you don't want to be feeding people ads that they don't care about I'm not interested in
and you might even think of that process as simply adjusting the the feeding of
ads or news articles or whatever it might be to match people's preferences
right which sounds like a good idea but in fact that isn't how the algorithm
works right you make more money the algorithm makes more money if it could
better predict what people are going to click on because then it can feed them exactly that right so the way to
maximize click-through is actually to modify the people to make them more
predictable and one way to do that is to feed them information which will change
their behavior and preferences towards extremes that make them predictable now
whatever is the nearest extreme or the nearest predictable point that's where you're going to end up
the machines will force you there now and then I think there's a reasonable argument to say that this among other
things is contributing to the destruction of democracy in the world
and where was the oversight of this process where were the people saying
okay you would like to apply this algorithm to five billion people on the
face of the earth can you show me that it's safe can you show me that it won't have various kinds of negative effects
no there was no one asking that question there was no one placed between you know
the undergrads were too much caffeine and the human race well it's just they
just did it and but some way outside the scope of my knowledge so economists
would argue that the what is it the invisible hand so the the capitalist system
it was the oversight so if you're going to corrupt society with whatever decision you make is a company then
that's going to be reflected in people not using your product sort of one that's one model of oversight so we
shall see but you know in the meantime you know that but you you might even have broken the political system that
enables capitalism to function well you've changed it and so we should see
yeah change changes often painful so my question is uh absolutely it's
fascinating you're absolutely right that there is ZERO oversight on algorithms that can
have a profound civilization changing effect so do you think it's possible I
mean I haven't have you seen government so do you think it's possible to create
regulatory bodies oversight over AI algorithms which are inherently such
cutting edge set of ideas and technologies yeah but I think it takes
time to figure out what kind of oversight what kinds of controls I mean took time
to design the FDA regime you know and some people still don't like it and they want to fix it
and I think there are clear ways that it could be improved but the whole notion
that you have stage 1 stage 2 stage 3 and here are the criteria for what you
have to do to pass a stage 1 trial right we haven't even thought about what those would be
for algorithms so I mean I think there are there are things we could do right
now with regard to bias for example we we have a pretty good technical handle
on how to detect algorithms that are propagating bias that exists in data
sets how to D by us those algorithms and and even what it's going to cost you to
do that so I think we could start having some standards on that I think there are
there are things to do with impersonation of falsification that we
could we could work on so I thanks ya or you know in a very simple point so
impersonation ISM is a machine acting as if it was a person I can't see a real
justification for why we shouldn't insist that machines self-identify as
machines you know where is the social benefit in in fooling people into
thinking that this is really a person when it isn't you know I I don't mind if
it uses a human-like voice that's easy to understand that's fine but it should just say I'm a machine in
some some form people are speaking to that I would
think relatively obvious factors I think mostly yeah I mean there is actually a law in California that bans
impersonation but only in certain restricted circumstances so for the
purpose of engaging in a for Geling transaction and for the purpose of
modifying someone's voting behavior so those are those are the circumstances
where machines have to self-identify but I think this is you know arguably it
should be in all circumstances and then when you talk about deep fakes you know
we're just beginning but already it's possible to make a movie of anybody
saying anything in ways that are pretty hard to detect including yourself
because you're on camera now and your voice is coming through with high resolution so you could take what I'm
saying and replaces it with it pretty much anything else you wanted me to be saying yeah and even it will change my lips and expression expressions to fit
and there's actually not much in the way of real legal protection against that I
think in the commercial area you could say yeah that's you're using my brand
and so on that there there are rules about that but in the political sphere I think it's at the moment it's you know
anything goes so like that could be really really damaging and let me just
try to make not an argument but try to look back at history and say something
dark in essence is while regulation seems to be oversight seems to be
exactly the right thing to do here it seems that human beings what they naturally do is they wait for something
to go wrong if you're talking about nuclear weapons you can't talk about nuclear weapons
being dangerous until somebody actually like the United States drops the bomb or
Chernobyl melting do you think we will have to wait for things going wrong in a
way that's obviously damaging to society not an existential risk but obviously
damaging or do you have faith that I I hope not but I mean I think we do have
to look at history and when you know so the two examples you gave nuclear
weapons and nuclear power are very very interesting because you know in nuclear
weapons we knew in the early years of the 20th century that atoms contained a
huge amount of energy right we had e equals mc-squared we knew the the mass differences between the different atoms
and their components and we knew that you might be able to make an incredibly
powerful explosive so HG Wells wrote science fiction book I think in 1912
Frederick Soddy who was the guy who discovered isotopes so Nobel Prize
winner he gave a speech in 1915 saying that
this new explosive would be the equivalent of 150 tons of dynamite which turns out to be about right and you know
Kenton this was in World War one right so he was imagining how much worse the world would be if we were using that
kind of explosive but the physics establishment simply refused to believe that these things could be made
including the people who are making it well so they were doing the nuclear physics I mean eventually were the ones
who made it and Rockwell for me or whoever well so up to the the
development was was mostly theoretical so it was people using sort of primitive
kinds of particle acceleration and doing experiments at the at the level of
single particles or collections of particles they they they want
yet thinking about how to actually make a bomb or anything like that they but they knew the energy was there and they
figured if they understood it better it might be possible but the physics establishment their view and I think
because they did not want it to be true their view was that it could not be true
that this could not provide a way to make a super weapon and you know there
was this famous speech given by Rutherford who was the sort of leader of
nuclear physics and I was on September 11th 1933 and he he said you know anyone
who talks about the possibility of obtaining energy from transformation of
atoms is talking complete moonshine and the next the next morning Leo Szilard
read about that speech and then invented the nuclear chain reaction and so as
soon as he invented he soon as he had that idea that you could make a chain
reaction with neutrons because neutrons were not repelled by the nucleus so they could enter the nucleus and then
continue the reaction as soon as he has that idea he instantly realized that the
world was in deep doo-doo because this is 1933 right you know Hitler had
recently come to power in Germany Zil odd was in London and eventually
became a refugee and and came to the US and the in the process of having the
idea about the chain reaction he figured out basically how to make a bomb and also how to make a reactor and he
patented the reactor 2:34 but because of the situation the
great power conflict situation that he could see happening he kept that a secret and so between then and the
beginning of World War two people were working including the Germans on how to
actually create Neutron sources right what specific fission reactions would
produce neutrons of the right energy to continue the reaction and and that was
demonstrated in Germany I think in 1938 if I remember correctly the first
nuclear weapon patent was 1939 by the French so this was actually you know
this was actually going on you know well before World War two really got going and then you know
the British probably had the most advanced capability in this area but for safety reasons among others and blush
which is sort of just resources they moved the program from Britain to the US
and then that became Manhattan Project so the the the reason why we couldn't
have any kind of oversight of nuclear weapons and nuclear technology was
because we were basically already in an arms race in a war and but you you've
mentioned then in the 20s and 30s so what are the echoes yeah the way you've
described this story I mean there's clearly echoes why do you think most a I researchers
folks who are really close to the metal they really are not concerned about it and they don't think about it
whether they don't want to think about it it's but what are the yeah why do you think that is what are the echoes of the
nuclear situation to the current situation and what can we do about it I
think there is a you know a kinda modak motivated cognition which is a term in
psychology means that you believe what you would like to be true rather than
what is true and you know it's it's
unsettling to think that what you're working on might be the end of the human
race obviously so you would rather instantly deny it
and come up with some reason why it couldn't be true and the you know I have
I collected a long list of reasons that extremely intelligent competent AI
scientists have come up with for why we shouldn't worry about this you know for
example calculators are super human at arithmetic and they haven't taken over the world so there's nothing to worry
about well okay my five-year-old you know could have figured out why that was
an unreasonable and and really quite weak argument you know another one was
you know you while it's theoretically possible that you could have superhuman
AI destroy the world you know it's also theoretically possible that a black hole could materialize right next to the
earth and destroy humanity I mean yes it's theoretically possible quantum theoretically extremely unlikely that it
would just materialize right there but that's a completely bogus analogy
because you know if the whole physics community on earth was working to materialize a black hole in near Earth
orbit right wouldn't you ask them is that a good idea is that gonna be safe
you know what if you succeed all right right and that's the thing right the AI
is sort of refused to ask itself what if you succeed and initially I think that
was because it was too hard but you know Alan Turing asked himself that and he
said we'd be toast right if we were lucky we might be able to switch off the
power but probably we'd be toast but there's also an aspect that because
we're not exactly sure what the future holds it's not clear exactly so
technically what to worry about sort of how things go wrong and so there is
something it feels like maybe you can correct me if I'm wrong but there's something paralyzing about worrying
about something that logically is inevitable but you don't really know
what that will look like yeah I think that's that's it's a reasonable point
and you know the you know it's certainly in terms of existential risks it's
different from you know asteroid collides with the earth right right which again is quite possible you know
it's happened in the past it'll probably happen again we don't right we don't know right now but if we did detect an
asteroid that was going to hit the earth in 75 years time we'd certainly be doing
something about it well it's clear there's got big rocks we'll probably have a meeting you see what do we do
about the big rock will they I write with a I I mean the very few people who think it's not gonna
happen within the next 75 years I know rod Brooks doesn't think it's gonna happen maybe and ruing doesn't
think it's happened but you know a lot of the people who work day-to-day you
know as you say at the rock face they think it's gonna happen I think the median estimate from AI researchers is
somewhere in forty to fifty years from from now or maybe a little you know I think in Asia they think it's gonna be
even faster than that I am I'm a little bit more conservative I think probably
take longer than that but I think it's you know as happened with nuclear weapons
well I went overnight it can happen overnight that you have these breakthroughs and we need more than one breakthrough but you know the it's on
the order of half a dozen this is a very rough scale but so half a dozen breakthroughs of that nature it would
have to happen for us to reach the superhuman AI but the you know the AI
research community is vast now the massive investments from governments
from corporations tons of really really smart people you know you just have to
look at the rate of progress in different areas of AI to see that things are moving pretty fast so to say oh it's
just gonna be thousands of years I don't see any basis for that you know I see
you know for example the the Stanford
hundred year AI project right which is supposed to be sort of you know the
serious establishment view their most recent report actually said it's
probably not even possible Wow right which if you want a perfect
example of people in denial that's it because you know for the whole
history of AI we've been saying to philosophers who said it wasn't possible
well you have no idea what you're talking about of course it's possible right give me an give me an argument for why it couldn't happen and there isn't
one all right and now because people are worried that maybe a oh it might get a
bad name or or I just don't want to think about this they're saying okay well of course it's not really possible
you know and we imagine right imagine if you know the the leaders of the cancer
biology community got up and said well you know of course curing cancer it's not really possible complete outrage and
dismay and you know I I find this really
a strange phenomenon so okay so if you
accept it as possible and if you accept that it's probably going to happen
the point that you're making that you know how does it go wrong a valid
question without that without an answer to that question then you stuck with what I call the gorilla problem which is
you know the problem that the gorillas face right they made something more intelligent than them namely us a few
million years ago and now now they're in deep doo-doo yeah so there's really
nothing they can do they've lost the control theater they failed to solve the control problem of controlling humans
and so they've lost so we don't want to be in that situation and if the gorillas
problem is is the only formulation you have there's not a lot you can do right other than to say okay we should try to
stop you know we should just not make the humans or right in this case not
make the AI and I think that's really hard to do - I'm not actually proposing that that's
a feasible course of action I also think that you know if properly control a I
could be incredibly beneficial so the but it seems to me that there's a
there's a consensus that one of the major failure modes is this loss of control that we create AI systems that
are pursuing incorrect objectives and because the AI system believes it knows
what the objective is it has no incentive to listen to us anymore so to speak right it it's just carrying
out the the strategy that it it has computed as being the optimal solution
and you know it may be that in the process it needs to acquire more
resources to increase the possibility of success or prevent various failure modes
by defending itself against interference and so that collection of problems I
think is something we can address yes that the other problems are roughly
speaking you know misuse right so even if we solve the control problem we make
perfectly safe controllable AI systems well why you know why does dr. evil going to use those right he wants to
just take over the world and he'll make unsafe AI system said but then get out of control so that's one problem which
is sort of a you know a partly a policing problem partly a-- a sort of a cultural problem
for the profession of how we teach people what kinds of AI systems are safe you talk about autonomous weapon system
and how pretty much everybody agrees there's too many ways that that can go horribly wrong if this great slaughter
BOTS movie that kind of illustrates that beautifully I want to talk that's another there's another topic I I'm
happy talking about the I just want to mention that what I see is the third major failure mode which is overuse not
so much misuse but overuse of AI that we become overly dependent so I
call this the wooly problems if you seen wall-e the movie all right all the humans are on the spaceship and the
machines look after everything for them and they just watch TV and drink big gulps and they're all sort of obese and
stupid and they sort of totally lost any notion of human autonomy and
you know so a in effect right this would happen like the slow boiling frog right
we would gradually turn over more and more of the management of our civilization to machines as we are
already doing in this you know this if this process continues you know we sort
of gradually switch from sort of being the Masters of Technology to just being
the guests right so so we become guests on a cruise ship you know which is fine
for a week but not not further the rest of eternity right you know and it's
almost irreversible right once you once you lose the incentive to for example
you know learn to be an engineer or a doctor or a sanitation operative or or
any other of the the infinitely many ways that we maintain and propagate our
civilization you know if you if you don't have the incentive to do any of that you won't
and then it's really hard to recover and of course there's just one of the
technologies that could that third failure mode result in that there's probably other technology in general
detaches us from it does a bit but the the the difference is that in terms of
the knowledge to to run our civilization you know up to now we've had no
alternative but to put it into people's heads right and if you oh it's not we're with Google I mean so software in
general so I probably if computers in general but but the you know the knowledge of how you know how a
sanitation system works you know that's an the AI has to understand that it's no good putting it into Google so I mean we
we've always put knowledge in on paper but paper doesn't run our civilization it only runs when it goes from the paper
into people's heads again right so we've always propagated civilization through
human minds and we've spent about a trillion person years doing that
literature right you you can work it out yeah but right is about just over a hundred billion people who've ever lived
and each of them has spent about ten years learning stuff and to keep their
civilization going and so that's a trillion person years we put into this effort beautiful way to describe all of
civilization and now we're you know we're danger of throwing that away so this is a problem that AI console it's
not a technical problem it's a you know if we do our job right the AI systems
will say you know the human race doesn't in the long run want to be passengers in
a cruise ship the human race wants autonomy this is part of human preferences so we the AI systems are not
going to do this stuff for you you've got to do it for yourself right I'm not going to carry you to the top of Everest
in an autonomous helicopter you have to climb it if you want to get the benefit and so on so
but I'm afraid that because we are short-sighted and lazy we're gonna override the AI systems and and there's
an amazing short story that I recommend to everyone that I talk to about this
called the machine stops written in 1909 by Ian Foster who you
know wrote novels about the British Empire and sort of things that became costume dramas on the BBC but he wrote
this one science fiction story which is an amazing vision of the future it has
it has basically iPads it has video conferencing it has MOOCs
it has computer and computer induced obesity I mean literally the whole thing
it's what people spend their time doing is giving online courses or listening to online courses and talking about ideas
but they never get out there in the real world that they don't really have a lot of face-to-face contact everything is
done online you know so all the things we're worrying about now were described in
this story and and then the human race becomes more and more dependent on the Machine loses knowledge of how things
really run and then becomes vulnerable to collapse and so it's a it's a pretty
unbelievably amazing story for someone writing in 1909 to imagine all this loss
yeah so there's very few people that represent artificial intelligence more
than you Russell so it's all my fault
right you're often brought up as the person well Stuart Russell like the AI
person is worried about this that's why you should be worried about it do you feel the burden of that I don't know if
you feel that at all but when I talk to people like from you talk about set
people outside of computer science when they think about this still Russell is
worried about AI safety you should be worried too do you feel the burden of that I mean in a practical sense yeah
because I'd yet you know a dozen sometimes 25 invitations a day
to talk about it to give interviews to write press articles and so on so in
that very practical sense I'm seeing that people are concerned and really
interested about this are you worried that you could be wrong as all good scientists are of course I worry about
that all the time I mean that's that's always been the way that I I've worked you know is like I have an argument in
my head with myself right so I have some idea and then I think okay how could
that be wrong or did someone else already have that idea so I'll go and you know search and as much literature
as I can't to see whether someone else already thought of that or or even refuted it so you know I right now I'm
I'm reading a lot of philosophy because you know in in the form of the debate so
V over utilitarianism and other kinds of moral moral formulas shall we say people
have already thought through some of these issues but you know what one of the things I'm I'm not seeing in a lot
of these debates is this specific idea about the importance of uncertainty in
the objective that this is the way we should think about machines that are
beneficial to humans so this idea of provably beneficial machines based on
explicit uncertainty in the objective you know it seems to be you know my gut
feeling is this is the core of it it's gonna have to be elaborated in a lot of different directions and there are a lot
of lis beneficial yeah but they're I mean it has to be right we can't afford
you know hand-wavy beneficial yeah because there are you know whenever we do hand wavy stuff there are loopholes
and the thing about super intelligent machines is they find the loopholes you know just like you know tax evaders if
you don't write your tax law properly that people will find loopholes and end up paying no taxes and
and so you should think of it this way and in getting those definitions right
you know it is really a long process you
know so you can you can define mathematical frameworks and within that framework you can prove mathematical theorems that yes this will you know
this this theoretical entity will be proven beneficial to that theoretical entity but that framework may not match
the real world in some crucial way so long process thinking through it of iterating and so on the last question
yep you have ten seconds to answer it what is your favorite sci-fi movie about
AI I would say interstellar has my favorite robots or beat it Space Odyssey
yeah yeah yeah so so tars the robots one of the robots in interstellar is the way
a robot should behave and I would say ex machina is in some
ways the one like the one that makes you think in a nervous kind of way about a
lot where we're going well Stuart thank you so much for talking today pleasure
you

----------

-----

--49--

-----
Date: 2018.12.04
Link: [# Eric Schmidt: Google | Lex Fridman Podcast #8](https://www.youtube.com/watch?v=hIC9FQpxVwQ)
Transcription: 

- The following is a conversation with Eric Schmidt. He was the CEO of Google for 10 years and a chairman for six more,
guiding the company through an incredible period of growth and a series of world-changing innovations.
He is one of the most impactful leaders in the era of the internet and the powerful voice for the promise of technology
in our society. It was truly an honor to speak with him as part of the MIT course on artificial general intelligence
and the Artificial Intelligence podcast. And now, here's my conversation with Eric Schmidt.
First moment when you fell in love with technology
What was the first moment when you fell in love with technology? - I grew up in 1960's as a boy
where every boy wanted to be an astronaut and part of the space program. So like everyone else of my age,
we would go out to the cow pasture behind my house, which was literally a cow pasture, and we would shoot model rockets off,
and that I think is the beginning. And of course generationally today, it would be video games and all of the amazing things
that you can do online with computers. - [Lex] There's a transformative inspiring aspect
Discovering the beauty of math
of science and math that maybe rockets would instill in individuals.
You mentioned yesterday that eighth grade math is where the journey through mathematical universe diverges for many people.
It's this fork in the roadway. There's a professor of math at Berkeley, Edward Franco.
I'm not sure if you're familiar with him. - I am. - [Lex] He has written this amazing book I recommend to everybody called Love and Math.
Two of my favorite words. (laughs) He says that if painting was taught like math,
then students would be asked to paint a fence. It's just his analogy of essentially how math is taught.
So you never get a chance to discover the beauty of the art of painting or the beauty of the art of math.
So how, when, and where did you discover that beauty?
- I think what happens with people like myself is that you're math-enabled pretty early,
and all of the sudden you discover that you can use that to discover new insights.
The great scientists will all tell a story. The men and women who are fantastic today,
it's somewhere when they were in high school or in college they discovered that they could discover something themselves.
And that sense of building something, of having an impact that you own drives knowledge acquisition and learning.
In my case, it was programming and the notion that I could build things that had not existed,
that I had built that had my name of it. And this was before open-source,
but you could think of it as open-source contributions. So today if I were a 16 or a 17-year-old boy,
I'm sure that I would aspire as a computer scientist to make a contribution like the open-source heroes
of the world today. That would be what would be driving me, and I would be trying and learning, and making mistakes and so forth in the ways that it works.
The repository that GitHub represents and that open-source libraries represent
is an enormous bank of knowledge of all of the people who are doing that. And one of the lessons that I learned at Google
was that the world is a very big place, and there's an awful lot of smart people. And an awful lot of them are underutilized.
So here's an opportunity, for example, building parts or programs, building new ideas,
to contribute to the greater of society. - [Lex] So in that moment in the 70's,
Creating Lex
the inspiring moment where there was nothing and then you cerated something through programming, that magical moment.
So in 1975, I think, you created a program called Lex, which I especially like because my name is Lex.
So thank you, thank you for creating a brand that established a reputation that's long-lasting, reliable,
and has a big impact on the world and is still used today. So thank you for that. But more seriously, in that time,
in the 70's as an engineer personal computers were being born.
Did you think you would be able to predict the 80's, 90's and the noughts of where computers would go?
- I'm sure I could not and would not have gotten it right. I was the beneficiary of the great work
of many many people who saw it clearer than I did. With Lex, I worked with a fellow named Michael Lesk
who was my supervisor, and he essentially helped me architect and deliver a system that's still in use today.
After that, I worked at Xerox Palo Alto Research Center where the Alto was invented, and the Alto is the predecessor
of the modern personal computer, or Macintosh and so forth. And the Altos were very rare,
and I had to drive an hour from Berkeley to go use them, but I made a point of skipping classes
and doing whatever it took to have access to this extraordinary achievement.
I knew that they were consequential. What I did not understand was scaling.
I did not understand what would happen when you had 100 million as opposed to 100. And so since then, and I have learned the benefit of scale,
I always look for things which are going to scale to platforms, so mobile phones, Android, all of those things.
The world is a numerous, there are many many people in the world. People really have needs.
They really will use these platforms, and you can build big businesses on top of them. - [Lex] So it's interesting, so when you see a piece of technology,
Path to generality
now you think what will this technology look like when it's in the hands of a billion people. - That's right.
So an example would be that the market is so competitive now that if you can't figure out a way
for something to have a million users or a billion users, it probably is not going to be successful
because something else will become the general platform and your idea will become a lost idea
or a specialized service with relatively few users. So it's a path to generality. It's a path to general platform use.
It's a path to broad applicability. Now there are plenty of good businesses that are tiny, so luxury goods for example,
but if you want to have an impact at scale, you have to look for things which are of common value,
common pricing, common distribution, and solve common problems. They're problems that everyone has. And by the way, people have lots of problems.
Information, medicine, health, education, and so forth, work on those problems. - [Lex] Like you said,
Middle class
you're a big fan of the middle class-- - 'Cause there's so many of them. - [Lex] There's so many of them. - By definition.
- [Lex] So any product, any thing that has a huge impact and improves their lives is a great business decision,
and it's just good for society. - And there's nothing wrong with starting off in the high-end as long as you have a plan
to get to the middle class. There's nothing wrong with starting with a specialized market in order to learn and to build and to fund things.
So you start luxury market to build a general purpose market. But if you define yourself as only a narrow market,
someone else can come along with a general purpose market that can push you to the corner, can restrict the scale of operation,
can force you to be a lesser impact than you might be. So it's very important to think in terms
of broad businesses and broad impact, even if you start in a little corner somewhere.
Computers as tools
- [Lex] So as you look to the 70's but also in the decades to come and you saw computers,
did you see them as tools, or was there a little element of another entity?
I remember a quote saying AI began with our dream to create the gods.
Is there a feeling when you wrote that program that you were creating another entity,
giving life to something? - I wish I could say otherwise, but I simply found the technology platforms so exciting.
That's what I was focused on. I think the majority of the people that I've worked with, and there are a few exceptions, Steve Jobs being an example,
really saw this a great technological play. I think relatively few of the technical people understood
the scale of its impact. So I used MCP which is a predecessor to TCP/IP.
It just made sense to connect things. We didn't think of it in terms of the internet and then companies and then Facebook
and then Twitter and then politics and so forth. We never did that build. We didn't have that vision.
And I think most people, it's a rare person who can see compounding at scale.
Most people can see, if you ask people to predict the future, they'll give you an answer of six to nine months or 12 months
because that's about as far as people can imagine. But there's an old saying, which actually was attributed
to a professor at MIT a long time ago, that we overestimate what can be done in one year.
We underestimate was can be done in a decade. And there's a great deal of evidence
that these core platforms of hardware and software take a decade.
So think about self-driving cars. Self-driving cars were thought about in the 90's. There were projects around them.
The first DARPA Grand Challenge was roughly 2004. So that's roughly 15 years ago.
And today we have self-driving cars operating at a city in Arizona, so 15 years.
And we still have a ways to go before they're more generally available.
Predicting the future
- [Lex] So you've spoken about the importance, you just talked about predicting into the future.
You've spoken about the importance of thinking five years ahead and having a plan for those five years.
- The way to say it is that almost everybody has a one-year plan. Almost no one has a proper five-year plan.
And the key thing to have on the five-year plan is having a model for what's going to happen under the underlying platforms.
So here's an example. Moore's law as we know it, the thing that powered improvement
in CPUs has largely halted in its traditional shrinking mechanisms because the costs have just gotten so high
and it's getting harder and harder. But there's plenty of algorithmic improvements and specialized hardware improvements.
So you need to understand the nature of those improvements and where they'll go in order to understand
how it will change the platform. In the area of network conductivity, what are the gains that are to be possible in wireless?
It looks like there's an enormous expansion of wireless conductivity at many different bands
and that we will primarily, historical I've always thought that we were primarily going to be using fiber,
but now it looks like we're going to be using fiber plus very powerful high bandwidth
sort of short distance conductivity to bridge the last mile. That's an amazing achievement.
If you know that, then you're going to build your systems differently. By the way, those networks have different latency properties
because they're more symmetric. The algorithms feel faster for that reason.
The champions of the impossible
- [Lex] And so when you think about, whether it's fiber or just technologies in general, so there's this Barbara Wootton poem or quote
that I really like. It's from the champions of the impossible, rather than the slaves of the possible,
that evolution draws its creative force. So in predicting the next five years,
I'd like to talk about the impossible and the possible. - Well, and again, one of the great things about humanity
is that we produce dreamers. We literally have people who have a vision and a dream.
They are, if you will, disagreeable in the sense that they disagree with the, they disagree with what the sort of zeitgeist is.
They say there is another way. They have a belief. They have a vision. If you look at science,
science is always marked by such people who went against some conventional wisdom,
collected the knowledge at the time, and assembled it in a way that produced a powerful platform.
Planning for the impossible
- [Lex] And you've been amazingly honest about, in an inspiring way,
about things you've been wrong about predicting, and you've obviously been right about a lot of things. But in this kind of tension,
how do you balance as a company predicting the next five years planning for the impossible,
listening to those crazy dreamers, letting them run away and make the impossible real,
make it happen, and you know that's how programmers often think, and slowing things down and saying
well this is the rational, this is the possible, the pragmatic, the dreamer versus the pragmatist that is.
- So it's helpful to have a model which encourages a predictable revenue stream
as well as the ability to do new things. So in Google's case, we're big enough and well enough managed and so forth
that we have a pretty good sense of what our revenue will be for the next year or two, at least for a while.
And so we have enough cash generation that we can make bets.
And indeed, Google has become Alphabet, so the corporation is organized around these bets.
And these bets are in areas of fundamental importance to the world, whether it's artificial intelligence,
medical technology, self-driving cars, conductivity through balloons, on and on and on.
And there's more coming and more coming. So one way you could express this is that the current business is successful enough
that we have the luxury of making bets. And another one that you could say is that we have the wisdom of being able to see
that a corporate structure needs to be created to enhance the likelihood of the success of those bets.
So we essentially turned ourselves into a conglomerate of bets and then this underlying corporation, Google,
which is itself innovative. So in order to pull this off, you have to have a bunch of belief systems,
and one of them is that you have to have bottoms up and tops down. The bottoms up we call 20% time,
and the idea is that people can spend 20% of the time on whatever they want. And the top down is that our founders in particular
have a keen eye on technology, and they're reviewing things constantly. So an example would be they'll hear about an idea
or I'll hear about something and it sounds interesting. Let's go visit them, and then let's begin to assemble the pieces
to see if that's possible. And if you do this long enough, you get pretty good at predicting what's likely to work.
- [Lex] So that's a beautiful balance that's struck. Is this something that applies at all scale?
- Seems to be. Sergey, again 15 years ago,
came up with a concept called 10% of the budget should be on things that are unrelated.
It was called 70/20/10. 70% of our time on core business, 20% on adjacent business, and 10% on other.
And he proved mathematically, of course he's a brilliant mathematician, that you needed that 10% to make the sum of the growth work.
And it turns out that he was right. - [Lex] So getting into the world
Artificial Intelligence
of artificial intelligence, you've talked quite extensively and effectively
to the impact in the near term, the positive impact of artificial intelligence,
especially machine learning in medical applications and education
and just making information more accessible. In the AI community, there is a kind of debate.
There's this shroud of uncertainty as we face this new world of artificial intelligence. And there is some people like Elon Musk you've disagreed on,
at least in the degree of emphasis he places on the existential threat of AI. So I've spoken with Stuart Russell, Max Tegmark,
who share Elon Musk's view, and Yoshua Bengio, Steven Pinker who do not.
And so there's a lot of very smart people who are thinking about this stuff, disagreeing, which is really healthy, of course.
So what do you think is the healthiest way for the AI community to, and really for the general public to think about AI
and the concern of the technology being mismanaged in some kind of way.
- So the source of education for the general public has been robot killer movies and Terminator, etcetera.
And the one thing I can assure you we're not building are those kinds of solutions.
Furthermore, if they were to show up, someone would notice and unplug them. So as exciting as those movies are,
and they're great movies, were the killer robots to start, we would find a way to stop them,
so I'm not concerned about that. And much of this has to do
with the timeframe of conversation. So you can imagine a situation 100 years from now
when the human brain is fully understood in the next generation and next generation of brilliant MIT scientists
have figured all this out, we're gonna have a large number of ethics questions
around science and thinking and robots and computers and so forth and so on. So it depends on the question of the timeframe.
In the next five to 10 years, we're not facing those questions. What we're facing in the next five to 10 years
is how do we spread this disruptive technology as broadly as possible to gain the maximum benefit of it?
The primary benefit should be in healthcare and in education. Healthcare because it's obvious.
We're all the same even though we somehow believe we're not. As a medical matter,
the fact that we have big data about our health will save lives, allow us to deal with skin cancer and other cancers,
ophthalmological problems. There's people working on psychological diseases and so forth using these techniques.
I can go on and on. The promise of AI in medicine is extraordinary.
There are many many companies and start-ups and funds and solutions and we will all live much better for that.
The same argument in education. Can you imagine that for each generation
of child and even adult you have a tutor educator. It's AI based that's not a human
but is properly trained that helps you get smarter, helps you address your language difficulties
or your math difficulties or what have you. Why don't we focus on those two? The gain societally of making humans smarter
and healthier are enormous. And those translate for decades and decades, and we'll all benefit from them.
There are people who are working on AI safety, which is the issue that you're describing, and there are conversations in the community
that should there be such problems what should the rules be like? Google, for example, has announced its policies
with respect to AI safety, which I certainly support, and I think most everybody would support. And they make sense.
So it helps guide the research. But the killer robots are not arriving this year,
and they're not even being built. - [Lex] And on that line of thinking,
Thinking beyond 50 years
you said the timescale. In this topic or other topics have you found a useful,
on the business side or the intellectual side, to think beyond five to 10 years, to think 50 years out?
Has it ever been useful or productive-- - In our industry there are essentially no examples
of 50 year predictions that have been correct. Let's review AI.
AI, which was partially invented here at MIT and a couple of other universities in 1956, 1957, 1958,
the original claims were a decade or two. And when I was a PhD student, I studied AI,
and it entered during my looking at it a period which is known as AI winter
which went on for about 30 years, which is a whole generation of science, scientists, and a whole group of people
who didn't make a lot of progress because the algorithms had not improved and the computers had not improved.
It took some brilliant mathematicians starting with a fellow names Geoff Hinton at Toronto and Montreal
who basically invented this deep learning model which empowers us today. The seminal work there was 20 years ago,
and in the last 10 years it's become popularized. So think about the timeframes for that level of discovery.
It's very hard to predict. Many people think that we'll be flying around in the equivalent of flying cars.
Who knows? My own view, if I want to go out on a limb, is to say we know a couple of things
about 50 years from now. We know that they'll be more people alive. We know that we'll have to have platforms
that are more sustainable because the earth is limited in the ways we all know,
and that the kind of platforms that are gonna get built will be consistent with the principles that I've described.
They will be much more empowering of individuals. They'll be much more sensitive to the ecology 'cause they have to be.
They just have to be. I also think that humans are going to be a great deal smarter, and I think they're gonna be a lot smarter
because of the tools that I've discussed with you, and of course people will live longer. Life extension is continuing at a pace,
a baby born today has a reasonable chance of living to 100, which is pretty exciting. It's well past the 21st century,
so we better take care of them. - [Lex] And you've mentioned an interesting statistic on some very large percentage,
60%, 70% of people may live in cities. - Today more than half the world lives in cities,
and one of the great stories of humanity in the last 20 years has been the rural to urban migration.
This has occurred in the United States. It's occurred in Europe. It's occurring in Asia, and it's occurring in Africa.
When people move to cities, the cities get more crowded, but believe it or not their health gets better.
Their productivity gets better. Their IQ and educational capabilities improve.
So it's good news that people are moving to cities, but we have to make them livable and safe.
Leadership styles
- [Lex] So first of all, you are but you've also worked with some of the greatest leaders in the history of tech.
What insights do you draw from the difference in leadership styles of yourself,
Steve Jobs, Elon Musk, Larry Page, now the new CEO, Sundar Pichai and others,
from the I would say calm sages to the mad geniuses.
- One of the things that I learned as a young executive is that there's no single formula for leadership.
They try to teach one, but that's not how it really works. There are people who just understand what they need to do
and they need to do it quickly. Those people are often entrepreneurs. They just know, and they move fast.
There are other people who are systems thinkers and planners. That's more who I am, somewhat more conservative,
more thorough in execution, a little bit more risk-adverse. There's also people who are sort of slightly insane
in the sense that they are emphatic and charismatic and they feel it and they drive it and so forth.
There's no single formula to success. There is one thing that unifies all of the people that you named,
which is very high intelligence. At the end of the day, the thing that characterizes
all of them is that they saw the world quicker, faster. They processed information faster.
They didn't necessarily make the right decisions all the time, but they were on top of it. And the other thing that's interesting
about all of those people is that they all started young. So think about Steve Jobs starting Apple
roughly at 18 or 19. Think about Bill Gates staring at roughly 20, 21. Think about by the time they were 30,
Mark Zuckerburg a good example at 19 or 20, by the time they were 30, they had 10 years,
at 30 years old they had 10 years of experience of dealing with people and products
and shipments and the press and business and so forth. It's incredible how much experience they had
compared to the rest of us who are busy getting our PhDs. - [Lex] Yes, exactly. - So we should celebrate these people
because they've just had more life experience and that helps them form the judgment.
At the end of the day, when you're at the top of these organizations,
all of the easy questions have been dealt with. How should we design the buildings?
Where should we put the colors on our products? What should the box look like?
That's why it's so interesting to be in these rooms. The problems that they face in terms of the way they operate,
the way they deal with their employees, their customers, their innovation are profoundly challenging.
Each of the companies is demonstrably different culturally.
They are not, in fact, cut of the same. They behave differently based on input. Their internal cultures are different.
Their compensation schemes are different. Their values are different. So there's proof that diversity works.
Personal AI assistant
- [Lex] So when faced with a tough decision
in need of advice, it's been said that the best thing one can do is to find the best person in the world
who can give that advice and find a way to be in a room with them one-on-one and ask.
So here we are. And let me ask in a long-winded way. I wrote this down.
In 1998, there were many good search engines: Lycos, Excite, AltaVista, InfoSeek,
Ask Jeeves maybe, Yahoo even.
So Google stepped in and disrupted everything. They disrupted the nature of search, the nature of our access to information,
the way we discover new knowledge. So now it's 2018, actually 20 years later.
There are many good personal AI assistants, including, of course, the best from Google.
So you've spoken in medical and education the impact of such an AI assistant could bring.
So we arrive at this question. So it's a personal one for me, but I hope my situation represents that of many other
as we said dreamers and the crazy engineers. So my whole live I've dreamed
of creating such an AI assistant. Every step I've taken has been towards that goal. Now I'm a research scientist
in human-centered AI here at MIT. So the next step for me as I sit here facing my passion
is to do what Larry and Sergey did in '98, the simple start-up.
And so here's my simple question. Given the low odds of success, the timing and luck required,
the countless other factors that can't be controlled or predicted, which is all the things that Larry and Sergey faced,
is there some calculation, some strategy to follow in the step?
Or do you simply follow the passion just because there's no other choice? - I think the people who are in universities
are always trying to study the extraordinarily chaotic nature of innovation and entrepreneurship.
My answer is that they didn't have that conversation. They just did it.
They sensed a moment when in the case of Google, there was all of this data that needed to be organized,
and they had a better algorithm. They had invented a better way. So today, with human-centered AI,
which is your area of research, there must be new approaches. It's such a big field.
There must be new approaches different from what we and others are doing. There must be start-ups to fund.
There must be research projects to try. There must be graduate students to work on new approaches.
Here at MIT, there are people who are looking at learning from the standpoint of looking at child learning.
How do children learn starting at age one and two-- - Josh Tenenbaum and others. - And the work is fantastic. Those approached are different
from the approach that most people are taking. Perhaps that's a bet that you should make, or perhaps there's another one.
But at the end of the day, the successful entrepreneurs are not as crazy as they sound.
They see an opportunity based on what's happened. Let's use Uber as an example.
As Travis tells the story, he and his co-founder were sitting in Paris, and they had this idea 'cause they couldn't get a cab.
And they said we have smartphones, and the rest is history. So what's the equivalent
of that Travis Eiffel Tower where is a cab moment that you could as an entrepreneur take advantage of,
whether it's in human-centered AI or something else? That's the next great start-up.
- [Lex] And the psychology of that moment. So when Sergey and Larry talk about,
in listening to a few interviews, it's very nonchalant. Well here's a very fascinating web data,
and here's an algorithm we have. We just kind of want to play around with that data, and it seems like that's a really nice way
to organize this data. - Well I should say what happened, remember, is that they were graduate students at Stanford,
and they thought this was interesting. So they build a search engine and they kept it in their room.
And they had to get power from the room next door 'cause they were using too much power in their room, so they ran an extension cord over
and then they went and they found a house and they had Google world headquarters of five people to start the company.
And they raised $100,000 from Andy Bechtolsheim, who is the Sun founder to do this and Dave Cheriton and a few others.
The point is their beginnings were very simple, but they were based on a powerful insight.
That is a replicable model for any start-up. It has to be a powerful insight, the beginnings are simple,
and there has to be an innovation. In Larry and Sergey's case, it was PageRank,
which was a brilliant idea, one of the most sited papers in the world today. What's the next one?
- [Lex] So you're one of, if I may say, richest people in the world,
and yet it seems that money is simply a side effect of your passions and not an inherent goal.
But you're a fascinating person to ask.
So much of our society at the individual level and at the company level and as nations
is driven by the desire for wealth. What do you think about this drive,
and what have you learned about, if I may romanticize the notion, the meaning of life having achieved success
on so many dimensions? - There have been many studies of human happiness,
and above some threshold, which is typically relatively low for this conversation,
there's no difference in happiness about money. The happiness is correlated with meaning and purpose,
a sense of family, a sense of impact. So if you organize your life, assuming you have enough to get around
and have a nice home and so forth, you'll be far happier if you figure out what you care about and work on that.
It's often being in service to others. There's a great deal of evidence that people are happiest
when they're serving others and not themselves. This goes directly against the sort of press-induced excitement
about powerful and wealthy leaders of the world, and indeed these are consequential people.
But if you are in a situation where you've been very fortunate as I have, you also have to take that as a responsibility
and you have to basically work both to educate others and give them that opportunity but also use that wealth to advance human society.
In my case, I'm particularly interested in using the tools of artificial intelligence and machine learning to make society better.
I've mentioned education. I've mentioned inequality in middle class and things like this, all of which are a passion of mine.
It doesn't matter what you do. It matters that you believe in it, that it's important to you,
and your life can be far more satisfying if you spend your life doing that.
- [Lex] I think there's no better place to end than a discussion of the meaning of life. - Eric, thank you so much. - Thank you very much, Lex.

----------

-----

--48--

-----
Date: 2018.11.29
Link: [# Jeff Atwood: Stack Overflow and Coding Horror | Lex Fridman Podcast #7](https://www.youtube.com/watch?v=KZkYSSE8HHI)
Transcription:

the following is a conversation with Jeff Atwood he is the co-founder of Stack Overflow Stack Exchange websites that are visited
by millions of people every single day much like with Wikipedia it is difficult
to understate the impact on global knowledge and productivity that these networks of sites have created Jeff is
also the author of the famed blog coding horror and the founder of discourse an
open-source software project that seeks to improve the quality of our online
community discussions this conversation is part of the MIT course on artificial
general intelligence and the artificial intelligence podcast if you enjoy it subscribe on youtube itunes or your
podcast provider of choice or simply connect with me on twitter at Lex Friedman spelled Fri D and now here's my
conversation with Jeff Atwood having co-created and managed for a few years
What motivates most programmers
the world's largest community of programmers in Stack Overflow ten years ago what do you think motivates most
programmers is it fame fortune glory process of programming itself or is it
the sense of belonging to a community it's puzzles really I think it's this
idea of working on puzzles independently of other people and just solving a
problem sort of like on your own almost although you know nobody really works alone and programming anymore but I will
say there's that there's an aspect of sort of hiding yourself away and just sort of beating on a problem until you
solve it like brute force basically to me it's what a lot of programming is is like the computer so fast right you can
do things that would take forever for a human but you just do them like so many times and so often that you get the
answer right you're saying just the pure act of tinkering with the code yes is is
Data is fun too
the thing that drives most probably the joy the struggle balance within the joy
of overcoming the the brute-force process of pain and suffering that
eventually leads to something that actually works well data is fun too like there's this thing called the the
shuffling problem like the naive shuffle that most programmers right has a huge flaw and there's a lot of articles
online about this because it can be really bad if you're like a casino and you have an unsophisticated programmer
writing your shuffle algorithm there's surprising ways to get this wrong but the neat thing is the way to figure that out is just to run your shuffle a bunch
of times and see like how many orientations of cards you get you should get an equal distribution of all the
cards and with the naive method of shuffling if you just look at the data if you just brute force and say okay I
don't know what's gonna happen you just write a program that does it a billion times and then see what the
buckets look like of the data and the Monty Hall problem is another example of that where you have three doors and
somebody gives you information about another door so the correct answer is you should always switch and the Monty
Hall problem which is not intuitive and people it freaks people out all the time right but you can solve it with data if you write a program that does the Monty
Hall you know game and then never switches and always switches just compare you would immediately see that
you don't have to be smart right you know to figure out the answer algorithmically you can just brute force it out with data and say well I know the
answer is this because I ran the program a billion times and these are the data buckets that I got from it right so
What motivates you
empirically find it but what's the joy of that what so for you for you personally outside of family what
motivates you in this process yes well to be honest I don't really write a lot of code anymore like what I
do at discourse is like manager II stuff which I always kind of despised right like as a programmer you think of
managers as people who don't really do anything themselves but the weird thing about code is like you realize that like
language is code like the ability to direct other people lets you get more stuff than you've done then you could by
yourself anyway you should write languages code languages community communication yeah those are humans yes
you can think of it as a systemic so what what is it like to be what makes
before we get into program it what makes a good manager what makes a good leader well I think a leader it's all about
leading by example first of all like sort of doing and being the things that you want to be now this can be kind of
exhausting particular you have kids because you realize that your kids are watching you like all the time like even in ways that you've stopped seeing
yourself like the hardest person to see on the planet is really yourself right it's funnier to see other people and and and make judgments about them but
yourself like your for biased you don't actually see yourself the way other people see you often you're very very hard on yourself
in a way that other people really aren't going to be so you know that's one of the insights is you know you've got to
be really diligent about thinking like am i behaving in a way that represents how I want other people to behave right
like leading through example there's a lot of examples of leaders that really mess this up right like they make
decisions that are like wow that's why would you know it's just it's it's it's a bad example for other people so I
think leading by example is one the other one I believe it is working really hard now I don't mean like working
exhaustively but like showing a real passion for the problem like you know
not necessarily your solution the problem but the problem itself is just one that you really believe in like with discourse for example the problem that
we're looking at which is my current project is how do you get people in groups to communicate in a way that
doesn't like break down into the howling of wolves right like how do you deal with trolling not like technical
problems of how do I get people to post paragraphs how do I get people to use bold how to get people to use complete sentences although those are problems as
well but like how do I get people to get along with each other right like and then solve whatever problem it is they set up to solver you
know reach some consensus on discussion or just like not hurt each other even right like maybe it's a discussion doesn't really matter but are people
like yelling at each other right and why right like that's not the purpose of this kind of communication so I would
say you know leadership is about you know setting an example you know doing
the things that represent what you want to be and making sure that you're actually doing those things and there's a trick to that too because the things
you don't do also say a lot about what you are yeah so let's pause on that one
How do you have selfawareness
so those two things are fascinating so how do you have as a leader as that self-awareness so you just said it's really hard to be self-aware so for you
personally or maybe for other leaders you've seen or look up to how do you know the both that the things you're
doing are the wrong things to be doing the way you speak to others the way you behave and the things you're not doing
how do you how do you get that service there's two aspects that one is like processing feedback that you're getting so how you get feedback well right sorry
are you getting feedback right like so one way we do it for example a discourse we have three co-founders and we periodically talk about decisions before
we make them so it's not like one person can make a mistake or like that's you know there can be misunderstanding things like this so
it's part of like group consensus of leadership is like it's good to have I think systems where there's one leader and
that leader has the rule of absolute law are just really dangerous and my experience for communities for example like a few of communities run by one
person that one person makes all the decisions that person's gonna have a bad day something could happen to that person you know something you know
there's a lot of variables so like at first when you think about leadership haven't have multiple people doing leadership and have them talk amongst
each other so giving each other feedback about the decisions that they're making and then when you do get feedback I
think there's that little voice in your head right like or your gut or wherever you want to put it in your putti I think
that voice is really important like I think most people who have any kind of
moral compass or like want to do most people want to do the right thing I do believe that I mean there might be a handful of sociopaths out there that
don't but most people they want other people to think of them as a good person and why wouldn't you right like do you want people to despise you I mean that's
just weird right so you have that little voice that sort of the angel and devil on your shoulder sort of talking to you about like what you're doing how you're
doing how does it make you feel to make these decisions right and I think having some attunement to that voice is
important but you said that voice also for I think this is a programmer situation to what sometimes the devil on
Selfcriticism
the shoulder is a little a little too loud so you a little too self-critical for a lot of developers and especially
when you have introverted personality how do you struggle with the self-criticism other criticism others so
one of the things of leadership is to do something that's not potentially unpopular or what people doubt you and
you still go through with the decision so what's that balance like I think you
have to walk people through your decision-making right like if if this is where blogging is really important communication is so important again code
language is just another kind of code is like here is the program by which I arrived at the conclusion that I'm gonna
reach right it's one thing to say like this is decisions final deal with it right that's not usually
satisfying people but if you say look you know we've been thinking this problem for a while here's some stuff that's happened here's what we think is
right here's our goals here's one achieve and we've looked at these options and we think this of available
options is the best option people be like oh okay alright maybe I don't totally agree with you but I can kind of see where you're coming from and like
see it's not just arbitrary decision delivered from a cloud of flames in the sky right it's like a human trying to
reach some kind of consensus about you know goals and their goals might be different than yours that's completely legit right but if you're making that
clear it's like oh well the reason we don't agree is because we have totally different goals right like how could we agree it's not that you're a bad person
it's that we have radically different goals in mind when we started looking this problem and the other one you said
Passion
is passion so or hard work sorry well those are tied together to me out in my mind say Hardware compassionate like for
me like I just really love the problem discourse is sending out to solve because in a way it's like there's a
there's a vision of the world where it all devolves into Facebook basically owning everything and every aspect of
human communication right and this has always been kind of a scary world for me um first cuz I don't I think Facebook is
really good at execution I gotta compliment them they're very competent in terms of what they're doing but Facebook has not much of a moral compass
in terms of Facebook cares about Facebook really they don't really care about you and your problems what they
care about is how big they can make Facebook right is that you're talking about the company or just a mechanism how Facebook works kind of both really
right like and the idea with discourse the reason I'm so passionate about it is because I believe every community should have the right to own themselves right
like they should have their own software that they can run that belongs to them that's their space where they can set
the rules and if they don't like it they can move to different hosting or you know whatever they need they need to have it can happen but like this this
idea of a company town we're all human communication is implicitly owned by whatsapp Instagram and Facebook and its
really disturbing too because Facebook is really smart like I said they're great at execution buying and what's happened buying Instagram were
incredibly smart decisions and they also do this thing on if you know but they have this VPN software that they give
away for free on smartphones and it indirectly feeds all the the data about the traffic back to Facebook so they can
see what's actually getting popular through the VPNs right they have low level access to the network data because
users have let them have that so ok let's let's take a small pause here
Discourse
first of all discourse can you talk about can you lay out the land of all
the different ways you can have community so there's Stack Overflow that you've built there's discourse yeah so Stack Overflow
is kind of like a wiki Wikipedia you talk and it's a very specific scalpel very
focused so what is the purpose of discourse and maybe contrast that with Facebook first of all say what is this
course yeah start from the beginning well let me start with the very being so Stack Overflow is very structured wiki
style QA for programmers right and that was the problem we first worked on it when we started we thought it was
discussions because we looked at like programming forums and other things but we quickly realized we were doing QA
which is a very narrow subset of human communication sizes so when you start
Stack Overflow you thought you didn't even know the QA you know it would be well we didn't know we did we had an
idea of like ok these are things that we see working online we had a goal right our goal was there was this site experts
exchange with a very unfortunate thank you for killing that site yeah I know right like a lot of people don't
remember it anymore which is great like that's the measure of success when people don't remember the thing that you were trying to replace then you've totally won so it was a place to get
answers to programming questions but it wasn't clear if it was like focused Q&A if it was a discussion there were plenty
of programming forums so we weren't really sure we were like ok we'll take aspects of Digg and reddit like voting
we're very important reordering answers based on votes wiki style stuff of like being able to edit post not just your
posts but other people's post to make them better and keep them more up-to-date ownership of blogging of like
ok this is me I'm saying this is my voice you know this is the stuff that I know and you know you give your
reputation accrues to you and it's pure recognition so you asked earlier like
what motivates programmers I think peer recognition motivates them a lot that was one of the key insights of Stack
Overflow was like recognition from your peers is why things get done initially moneyness well your boss but like your
peers saying wow this person really knows their stuff has a lot of value so the reputation system came from that so
we were sort of frankensteining a bunch of stuff together in Stack Overflow of like stuff we had seen working and we
knew worked and that became Stack Overflow and over time we realized it
wasn't really discussion it was very focused questions and answers there wasn't a lot of room on the page for let
me talk about this tangential thing it was more like ok he's an answering question is it clarifying the question or could it be an alternative answer to
the same question because there's usually more than one way to do it in program there's say five to ten ways and one of the
patterns we got into early on stackoverflow was there are questions where there would be like hundreds of answers more like Wow
how can there be a programming question with 500 200 500 answers and we looked
at those we realized those were not really questions in the traditional sense they were discussions it was stuff
that we allowed early on that we eventually decided wasn't allowed such as what's your favorite programming food
you know what's the funniest programming cartoon you've seen and we had to sort of backfill oh into rules about like why
isn't this allowed such as is this a real problem you're facing like nobody goes to work and says wow I can't work
because I don't know what the funniest programming cartoon is so sorry can't compile this code now right it's not a
real problem you're facing in your job that was run rule and ii like what can you really learn from that it's like
what i call accidental learning or reddit style learning where you just acknowledge browse some things oh wow you know did you know tree frogs
only live three years I mean I just made that up I don't know that's true but uh I didn't really set out to learn that I don't need to know that right it's an
accidental learning it was more intentional learning we were like okay I have a problem and I want to learn about stuff around this problem having right
and it could be theory could be compiler theory it could be other stuff but I'm having a compiler problem hence I need
to know the compiler theory that aspect of it that gives me the the gets me to my answer right so kind of a directed
learning so we had to backfill all these rules as we sort of figured out what the heck it was we were doing and the system
came very strict over time and a lot of people still complain about that and I wrote my latest blog entry what the
Stack Overflow want to be I wanted to be when it grows out celebrating the 10-year anniversary yeah yeah so ten
years and it that system is trended towards strictness there's a variety of reasons for this one is people don't
like to see other people get reputation for stuff as they view they view as frivolous which I can actually understand because if you saw a program
or got like five hundred up votes for funniest programming cartoon or funniest comment they had seen in code it's like
well why do they have that reputation is because they wrote the joke probably not I mean if they did maybe or the cartoon
right they're getting a bunch of reputation based on someone else's work that's not even like programming it's
just a joke right it's a related to birth so you begin to resent that like well that's not fair and it isn't at
some level they're correct I mean I empathize because like it's not correct you get reputation for that versus here's a really gnarly
regular expression problem and here's a really you know clever insightful you know detailed answer laying out oh
here's why you're seeing the behavior that you're seeing here let me teach you some things about how to avoid that in the future that's that's great like that's gold right you want people to
grab a petition for that not so much for wow look at this funny thing I saw alright great so there's this very
What is Stack Overflow
specific Q&A format and then take me through the journey towards this course in Facebook and Twitter so you start at
the beginning that Stack Overflow evolved to have a purpose so where does this course this passion you have for
creating community for discussion what is that when was that born and well part
of it is based on the realization the Stack Overflow is only good for very specific subjects where they're sort of it's it's based on data facts and
science where answers can be kind of verified to be true another form of that is there's the book of knowledge like
the tome of knowledge that defines like whatever it is you can refer to that book and I'll give you the answer there
has to be it only works on subjects where there's like semi clear answers to things that can be verified in some form
now again there's always more than one way to do it there's complete flexibility and system around that but
where it falls down is stuff like poker and Lego like we had if you go to Stack Exchange calm we have an engine that
tries to launch different Q&A topics right and people can propose Q&A topics
sample questions and and if he gets enough support within the network we launch that Q&A site so someone's we
launched where poker and Lego and they did horribly right because I mean there might still be there lingering on in
some form but it was an experiment this is like a test right and some subjects work super well in the stack engine and
some don't but the reason Lego and Poker don't work is because they're so social really it's not about you know what's the rule here
in poker it's like well you know what kind of cigars do we like to smoke while playing poker or you know what's what's
a cool set of cards to use when playing poker or you know what some strategies like say I have this hand come up with
some strategies I could use it's more of a discussion around like what's happening like with Lego you know same thing like here's this cool Lego set I found look how awesome
this isn't like yeah that's freaking awesome right it's not question right there's all these social components discussions that don't fit at all like
we literally have to just allow those in Stack Overflow kids it's not about being social it's about problems that you're facing in your work
that you need concrete answers for right like you have a real demonstrated problem that's sort of blocking you in something nobody's blocked by you know
what should I do when I have a straight flush right like blocking problem in the world it's just an opportunity to hang
out and discuss so this course was a way to address that and say look you know
discussion forum software ahead was very very bad and when I came out of Stack Overflow until late or early 20 2013
2012 it was still very very bad I've expected it improved and in the four
years since I last looked but it had not improved at all and I was like well that's kind of terrible because I love
these communities of people talking about things that they love you know that there's just communities of
interest right and there's no good software for them like startups would come to me and say hey Jeff I wanna you
know I have this startup here's my idea and the first thing I would say them is like well first why are you asking me
like I don't really know your field right let it's necessarily like why aren't you asking like the community
like the people that are interested in this problem the people that are using your product why aren't you talking to them and then they say Oh a great idea
like how do I do that and then that's when I started playing sad trombone because I realized all the software involving talking to your users
customers audience patrons whatever it is it was all really bad you know I was like stuff that I would be embarrassed
to recommend to other people and yet that's where I felt they could get the biggest and strongest most effective
input for what they should be doing with their product right it's from their users from their community right that's
what we did on Stack Overflow so what we're talking about with forms the what is it the dark matter of the
What is Forum
Internet it's still I don't know if it's still but for a longest time it has some of the most passionate and fascinating
discussions and what's the usual structure there's usually what it's a it's linear so it's sequential it's
you're posting one after the other and there's pagination so it's every there's a 10th post and you go to the next page
and that format still is used by like I'm we're doing a lot of research with
Tesla of vehicles and there's Tesla Motors Club forum which is extremely really wanted to run that actually they
pinged us about I don't think we got but I really would like to gotten that one but they've started before even 2012
I believe I mean they've been running for a long time it's still an extremely rich source of information so what what's broken about that system and how
are you trying to fix it I think there's a lot of power in in connecting people
that love the same stuff around that specific topic meaning Facebook's idea of connection is just any human that's
related to another human right like like through friendship or you know any other reason Facebook's idea of the world is sort of
the status update right like a friend of yours did something ate at a restaurant right
whereas discussion forums were additionally around the interest graph like I love electric cars specifically I
love Tesla right like I love the way they approach the the problem I love the style of the founder I just love the the
design ethic there's a lot to like about Tesla if you saw the oatmeal he did a whole love comic to Tesla and it was
actually kind of cool because I learned some stuff he was some how great Tesla cars were specifically like how they were built differently and he went into
a lot of great detail that was really interesting to me that oatmeal post if you read it is the genesis of pretty much all interest communities I just
really love this stuff's like for me devilish yo-yos right like I'm into the yo-yo communities and there's these interest communities are just really
fascinating to me and I feel more connected to the yo-yo communities than I do to you know friends that I don't
see that often right like to me that the powerful thing is the interest graph and Facebook kind of dabbles in the interest
graph I mean they have groups you can sign up for groups and stuff but it's really about the relationship graph like
I'm this is my coworker this is my relative this is my friend but not so much about the interest so I think
that's the the linchpin of which forums and communities are built on that I personally love like I I like I said
leadership is about passion right and being passionate about stuff is is a really valid way to look at the world and I think it's a way a lot of stuff in
the world gets done like I once said someone described me as he's like Jeff you're a guy who you just get super passionate about a few things at a time
and you just go super team from those things and I was like oh that's kind of right that's kind of what I do I'll get into something and just be super into
that for a couple years or whatever I just learn all I can about it and go super deep in it and that's how I enjoy
experiencing the world right like not being shallow on a bunch of things but being really deep on a few things that I'm interested in so forums
kind of unlocked that right and you know you don't want a world where everything belongs to Facebook at least I don't I
want a world where communities can kind of own themselves set their own norms set their own rules control the experience because commit community is
also about ownership right like if if you're meeting at the Barnes & Noble every Thursday at Barnes & Noble says
get out of here you guys don't buy enough books well you know you're kind of hose right Barnes and Noble owns you right like you can't but if you have
your own meeting space you know your own Clubhouse you can set your own rules decide what you want to talk about there
and just really generate a lot better information than you could like hanging out at Barnes & Noble every Thursday at
3:00 p.m. right so that's kind of the vision of discourse is a place where it's it's fully open source you can take
the software you can saw it anywhere and you know you and a group of people can go deep on whatever it is that you're
into and it this works for startups right startups are a group of people who go super deep on a specific problem right and they want to talk to the
comedian's like well install this course right that's what we do at this course that's what I did a stack overflow I spent a lot of time on meta stack
overflow which is our internal well public community feedback site and just
experiencing what the users were experiencing right because they're the ones doing all the work in the system and they had a lot of interesting
feedback and there's that 90/10 rule of like 90% of the feedback you get is not really actionable for a variety reasons
it might be bad feedback it might be crazy feedback it might be feedback you just can't act on right now but there's 10% of it that's like gold it's like
literally gold and diamonds where it's like feedback of really good improvements to your core product that
are not super hard to get to and actually make a lot of sense and my favorite is about 5% of those stuff I didn't even see coming it's like oh my
god I never even thought of that but that's a brilliant idea right and I can point to so many features of Stack Overflow that we drive
from metastatic overflow feedback and meta discourse right same exact principle at discourse you know we're
getting ideas from the comedian's like oh my god I never thought of that but that's fantastic right like I love that relationship with the community from
having built these communities what have you what have you learn about what's the process of getting a critical mass of
members in a community is it luck skill timing persistence what is is it the
tools like discourse that empower that community what what's the key aspect of starting
one guy a gal and then building it to 210 and 100 and a thousand so on I think
we're starting with an end of one I mean I think it's persistence and and also you have to be interesting like somebody
I really admire once that's something that I always liked about blogging he's like here's how you blog you have to have something interesting to say and
have an interesting way of saying it right yeah and then do that for like 10 years so that's the genesis is like you
have to have sort of something interesting to say that's not exactly what everyone else is saying and an interesting way of saying which is
another one same kind of entertaining way of saying it and then as far as growing it it's like ritual you know
like you have to like say you're starting a blog you have to say look I'm gonna blog every week three times a week
and you have to stick to that schedule right because until you do that for like several years you're never gonna get
anywhere like it just takes years to get to where you need to get to and part of that is having the discipline to stick
with the schedule and it helps you get if it's something you're passionate about this won't feel like work like I love this I could talk about this all
day every day right you just have to do in a way that's interesting to other people and then as you're growing the
community that pattern of participation within the community of like generating these artifacts and inviting other
people to help you like collaborate on these artifacts like even in case of blogging like I felt in the early days
of my blog which I started 2004 which is really the genesis of Stack Overflow if you look at all my blog it leads up to
Stack Overflow which was I have all this energy in my blog but I don't like 40,000 people were subscribing to me and
I was like I want to do something and then then I met Joel and said hey Joel I want to do something take this ball of energy for my blog and do something and
all the people reading my blog saw that's oh cool you're involving us you're saying look you're part of this
community let's build this thing together like they pick the name like we voted on the name for Stack Overflow on my blog like we came and naming is super
hard first why the hardest problem computer science is coming with a good name for stuff right yeah but there you
can go back to my log there's the poll where we voted and Stack Overflow became the name of the site and all the early beta users are stuck over we're audience
of my blog plus Joel's blog right so we started from like if you look at the Genesis okay I was just a programmer who
said hey I love programming but I have no outlet to talk about it so I'm just gonna blog about it because I don't have enough people to work to talk to about
it because at the time I worked a place where you know programming wasn't the core output of the company was a pharmaceutical company and I just love
this stuff you know to an absurd degree so I was like I'll just blog about it and then I'll find an audience and eventually found an audience eventually
I found Joel and eventually built Stack Overflow from that one core of activity right but it was that repetition of
feeding back in feedback from my blog comments feedback from Joel feedback from them the early Stack Overflow
community when people see that you're doing that they will follow along with you right they say look cool you're here
in good faith you're actually you know not listening to everything because I'm impossible that's impossible but you're actually you know waiting our
feedback and what you're doing because I'm and why wouldn't I because who does all the work on Stack Overflow me Joel no it's the other programmers that are
doing all the work so you gotta have some respect for that and then you know discipline around look you know we're
trying to do a very specific thing here on Stack Overflow we're not trying to solve all the world's problems we're trying to solve this very specific QA
problem in a very specific way not because we're jerks about it but because these strict set of rules help us get
really good results right and programmers that's an easy sell for the most part because programmers are used
to dealing with ridiculous systems of rules like constantly that's basically their job so they're they're very oh
yeah super strict system of rules that lets me get on what that's programming right that's what Stack Overflow is so
Coding Horror
so you're making it sound easy but in 2004 let's go back there in 2004 you
started the blog I'm quoting horror was it called that at the beginning at the very beginning was one of the smart
things I did it's from a book by Steve McConnell code complete which is where my favorite programming but still probably my number one programming book
for anyone to read one of the smart things I did back then I don't always do smart things when I start stuff
I contacted Stephen said hey I really like this it was a sidebar illustration indicating danger in code right coding
horror was like watch out and I love that illustration cuz it spoke to me because I saw that illustration go oh my
god that's me like I'm always my own worst enemy like that and a key insight and programming is every time you write
something think how am I gonna screw myself because you will constantly right
so that that icon was like oh yeah I need to constantly hold that mirror up and look and say look you're very
fallible you're gonna screw this up like how can you build this in such a way that you're not gonna screw it up later
like how can you get that discipline around making sure at every step I'm thinking through all the things that I could do wrong or that
other people could do wrong because that is actually how you get to be a better programmer a lot of times right so that
sidebar illustration I loved it so much and I wrote Steve before I started my belonging say hey can I have permission to use this cuz I just really likes
illustration and Steve was kind enough to give me a portion to do that and just continues to give me permission so yeah
Writing Advice
really that's awesome but in 2004 you started this blog you know you look at
it Stephen King this book on writing or Steven Pressfield the war of art book I
mean it seems like writers suffer I mean it's a hard process of writing write is
there's gonna be suffering I mean I won't kid you like well the work is suffering right like doing the work like
even when you're every week you're like okay that blog post wasn't very good or you know people didn't like it or people write said disparaging things about it
you have to like have the attitudes like you know no matter what happens I want to do this for me right it's not about
you it's about me I mean in the end it is about everyone because this is how good work gets out into the world but
you have to be pretty strict about saying like you know I'm selfish in the
sense that I have to do this for me you know you mentioned Stephen King like his book on writing but like one of things I do for example when writing is like I
read it out loud one of the best pieces of advice for writing anything is read it out loud like multiple times and make
it sound like you're talking because that is the goal of good writing it should sound like you said it with with
slightly better phrasing because you have two more time to think about your saying but like it should sound natural when you say it and I think that's
probably the single best writing advice and give anyone it's just just read it over and over outloud make sure it
sounds like something you would normally say and it sounds good and what's your process of writing so there's usually a
Writing Process
pretty good idea behind the blog post so ideas right so I think you gotta have
the concept that there's so many interesting things in the world like I mean my god the world is amazing right
like it's you could never write about everything that's going on because it's so incredible but if you can't come up
with like let's say one interesting thing per day to talk about then you're not trying hard enough because the world
is full of just super interesting stuff and one great way to like mine stuff is go back to old books because they bring
old stuff that's still super relevant and I did that a lot because I was like reading classic program books and a lot
of the early blockbuster like oh I was reading this program but can they brought this really cool concept and I want talk about some more and you get
the I mean you're not claiming credit for the idea but it gives you something interesting to talk about that's kind of evergreen right like you don't have to go what should I talk about so just go
dig up some old classic programming books and find something that oh wow that's interesting or how does that apply today or what about X&Y or compare
these two concepts so pull a couple of sentences from that book and then sort of play off of it almost reader disagree
NonLinear Decisions
that so in 2007 you wrote that you were
offered a significant amount of money to sell the blog you chose not to what were
all the elements you were thinking about because I'd like to take you back it seems like there's a lot of non-linear decisions you made through life that's
so what was that decision like right so i one of the things I love is the choose your own adventure books which I loved
as a kid and I feel like the early programmer books cuz they're they're all about if-then statements right if this then this and they're also very very
unforgiving like there's all these sites that map the the classic teacher and venture books and how many how comes are
bad there's a lot of bad outcomes so part of the game is like oh I got a bow come go back one step go back on further
steps like how did I get here right like it's a sequence of decisions and this is true of life right like every decision
is a sequence right individually any individual decision is not really right
or wrong but they lead you down a path right so I do think there's some truth to that so this particular decision the
blog II got fairly popular there's a lot of RSS readers that I discovered and this guy contacted me out of the blue
from this like bug tracking companies like I really want to buy your blog for like I think it was around it was a
hundred thousand dollars when I'm in like eighty thousand but it was it was a lot right like and that's you know at the time like I would have a year's
worth of salary all at once so I'd really think about like well you know and I remember talking to people the
times like wow that's a lot of money but then I'm like I really like my blog right like do I want to sell my blog because it wouldn't really belong to me
anymore at that point and one of the guidelines that I like to I don't like to give advice to people a lot but one
of the piece of advice I do give because I do think it's really true and it's generally helpful is whenever you're looking at a set of decisions like
shut you a B or C you got to pick the thing that's a little scarier in that list because not you know not like jump
off a cliff scary but the thing that makes you nervous because if you pick the safe choice it's usually you're not really pushing you're not pushing
yourself you're not choosing the thing that's gonna help you grow so for me the scarier choice was to say no I was like
well no let's just see where this is going right because then I own it I mean it belongs to me it's my thing and I can
just take it and to some other logical conclusion right because imagine how different the world would've been had I said yes and sold the blog it's like
they're probably gonna be stackoverflow yeah you know a lot of other stuff would have changed so for that particular
decision I think it was that same rule like what scares me a little bit more do the thing that scares you yeah so speaking of which startups I think
The Birth of Stack Overflow
there's a specific some more general questions that a lot of people would be interested in you've started
Stack Overflow you started this course so what's the here's one two three guys
whatever it is in the beginning what was that process like do you start talking
about it do you start programming do you start like where is the birth and the catalyst that actually I can talk about
in the context of Oh Stack Overflow and discourse so I think the key thing initially is there is a problem something the some state of the world
that's unsatisfactory to the point that like you're upset about it right like in that case it was experts exchange I mean
Joel's original idea because I approached I was like look joy I have all this energy by my blog I want to do something I want to build something but
I don't know what it is because I'm not I'm honestly not a good idea person I'm really not I'm like the execution guy I'm really good at execution but I'm not
good at like blue skying ideas not my forte which is another reason why I like the community feedback because they blue
sky all day long for you right so when I can just go in and cherry-pick a blue sky idea from community even if I have
to spend three hours reading to get one good idea it's worth it man but anyway so the idea from Joel was hey experts
exchange it's got great data but the spirits is hideous right it's it's trying to trick you it feels like used-car salesmen it's
just bad so I was like oh that's awesome it feeds in a community it feeds into like you know we can make a Creative Commons so I think the core is to have a
really good idea that you feel very strongly about in the beginning that like there's a wrong in the world that we will an injustice that we will right
through the process of building this thing for discourse it was like look there's no good software for communities
to just hang out and like do stuff right like whether it's problem-solving start up whatever
forums are such a great building block or online community and they're hideous they were so bad right it was embarrassing like I literally was
embarrassed to be associated with this software right I was we have to have software they could be proud of it's like this is competitive with
Reddit this is competitive Twitter this is competitor with Facebook right I would be proud to have the software on
my site so that was the genesis of discourse was feeling very strongly about there needs to be a good solution
for communities so that's step one Genesis why do you feel super strongly about right and then people galvanize around the idea like Joel was already
super excited with the idea I was excited about the idea so with the forum software I was posting on Twitter I had
research as part of my research I start researching the problem right and I found a game called forum Wars which was
a parody of forum it's still very very funny of like foreign behavior circle like I would say 2003 and it's aged some
right like the behavior is a little different in there of Twitter but it was awesome it was very funny and it was like a game as like an RPG and it had a
forum attached to it so it was like a game about forums with a forum attached I was like this is awesome right this is so cool and the founder of that company
or that project it wasn't really a company contacted me this guy Robin Ward from Toronto's hey you know I saw you
been talking about forums and like I really love that problem space he's like I'd still love to build really good forum software cuz I don't think
anything out there is any good and I was like awesome at that point I was like we're starting a company because like I couldn't have wished for a better person
to walk through the door and say I'm excited about this - same thing with Joe right I mean Joel is a legend in the
industry right so when he walks through so I'm excited about as problems like me - man we can do this right so that to me
is the most important step it's like having ID you're super excited about and another person a co-founder right because again you get that dual
leadership right of like am I making a bad decision sometimes it's nice to have checks of like is this a good idea I
don't know right so those are the the crucial seeds but then starting to build stuff whether it's you programmer
there's video types so there's tons of research there's tons of research like what what's out there that failed because a lot of people looked at
successes I look at how successful X's everybody looks at the successes those are boring show me the failures because
that is what's interesting that's where people were experimenting that's where people were pushing but and they failed but they probably failed
for reasons that weren't directly about the quality of their idea right yeah so look at all the failures don't just look
what everybody looks at which is a go gosh look at all these successful people look at the failures look at the things that didn't work research the entire
field and so that's the research that I was doing that led me to Robin Wright was that and then when we for example we
did Stack Overflow we're like okay well I really like elements of voting and Digg and reddit I
like the the Wikipedia everything is up to date nothing is like an old tombstone that like has horrible out-of-date
information we know that works Wikipedia is an amazing resource blogging the idea of ownership is so powerful right like
oh I i jo wrote this and look how good Joe's answer is right like all these concepts were rolling out researching
all the things are out there that we're working and why they were working and trying to like fold them into that again that Frankenstein's monster of what
Stack Overflow is and by the way that wasn't a free decision because there's still a ton of tension in the Stack Overflow system there's reasons people
complain about Stack Overflow because it's so strict right why is it so strict why you guys always closing my questions
it's because there's so much tension that we built into the system around like trying to get good good results out
of the system and you know it it's not a free that stuff doesn't come for free
right it's not like we we're all have perfect answers and nobody will have to get their feelings hurt or nobody will
have to get down voted like that it doesn't work that way right like so this is an interesting point a small tangent
Anxiety on Stack Overflow
yeah you're right about anxiety so I've posted a lot of questions and answers on
Stack Overflow and the questions I usually go to something very specific to something I am working on this is
something you talk about that really the goal of Stack Overflow isn't about is to write a question not that's not about
you it's about the question that will help the community in the future right
but that's a tough sell right because people are like well you know I don't really care about the committee what I care about is my problem my problem and
then that's fair right is it sort of that again that tension that balancing active we want to help you but we also hope that everybody comes behind you
right the long line of people are gonna come up say oh I kind of have that problem too right and if nobody's ever going to come up and say I have this
problem too then that question shouldn't exist on Stack Overflow because the question is too specific and that even
that's tension right how do you judge the how do you know that nobody's ever gonna have this particular question again so there's a lot of tension in the
Stack Overflow QA
system do you think that anxiety of asking the question the anxiety of answering that tension is inherent to
programmers is inherent to this kind of process or can it be improved can be happy land
where the that tension is not quite so harsh uh I don't think Stack Overflow
can totally change though it works one thing they are working on finally is the ask page had not changed since 2011 I'm
still kind of bitter about this because I feel like you have a QA system and what are the core pages in a KA system
well first of all the question all the answers and all the also the ask page particularly when you're a new user or someone trying to ask question that's
the point on what you need the most help and we just didn't adapt with the times but the good news is they're working on
this from what I understand and it's gonna be a more wizard based format and you could envision a world where as part
of this wizard based program when you're asking questions okay come up with a good title what are good words up in the title one word that's not good to put in
the title is problem for example I have a problem oh you have a problem okay a problem that's great right like you need
specifics right like so it's trying to help you make a good question title for example that step will be broken out all
that stuff but one of those steps in that wizard of asking could say hey I'm a little nervous you know I've never done this before can you put me in a
queue for like special mentoring right you could opt into a special mentor I think that would be fantastic like I
don't have any objection to that at all in terms of be an opt-in system because there are people there like no I just
want to help them I want to help a person no matter what I want to go above and beyond I want to spend like hours with this person uh Ben's what their
goals are right a great idea Who am I to judge right so that's fine it's not precluded from happening but there's a
certain big-city ethos that we started with like look we're of New York City you don't come to New York City and expect them to be Oh welcome to the city
Joe how's it going come on in let me show you around that's not how New York City works right I mean and you know again New York City
is a reputation for being rude which I actually don't think it is having been there fairly recently it's not rude people are just like going about their business right now look look I have
things to do I'm busy I'm a busy professional as are you and since you're a busy professional certainly when you ask a question you're
gonna ask the best possible question right because you're a busy professional and you would not accept anything less than a very well waiting question with a
lot of detail about why you're doing it what you're doing what you researched what you found right because you're a professional like me right and this rubs
people sometimes the wrong way and I don't think it's wrong to say look I don't want that experience I want just a
more chill place for beginners and I still think sacrifice is not was never designed for beginners right there's
this misconception that you know even Joel says some - oh yes deck overflow for beginners and I think if you're a prodigy it can be all right but that's
not not really representative right like I think as a beginner you want a totally different set of tools you want like
live screen sharing live chat you want access to resources you want a playground like a playground you can
experiment in and like test and all this stuff that we just don't give people because that was never really the the
audience that we were designing the second true flow for that doesn't mean it's wrong and I think it would be awesome if there was a site like that on
the internet or if stack overlies and hey you know we're gonna start doing this that's fine too you know I'm not there I'm not making those decisions but
I do think the pressure the tension that you describe is there for people to be look I'm a little nervous cuz I know I
gotta do my best work right the other one is something you talk about which is also really interesting to me is
Duplicate Questions
duplicate questions or do it's a it's a really difficult problem that you
highlight super far is super hard like you could take one little topic and you could probably write 10 20 30 ways of
asking about that topic and there will be all different I don't know if there should be one page that answers all of
it is there a way that Stack Overflow can help disambiguate like separate
these duplicate questions or connect them together or is it a totally hopeless difficult impossible task I
think it's a very very hard computer science problem and partly because people are very good at using completely
different words it always amazed me on Stack Overflow you'd have two questions that were functionally identical and one question had like zero words in common
with the other question like oh my god from a computer science perspective how do you even begin to solve that and it
happens all the time people are super-good at this right accidentally at asking the same thing in in like in 10
20 different ways and the other complexity is we want some of those duplicates to exist because if there's five versions with different words have
those five versions point to the one centralized answer right it's like okay this is duplicate nope no worries this
here's here's the answer that you wanted over here on this this this you know the prime example that we want to have
rather having ten copies of the question and the answer because if you have 10 copies of the question the answer this
also devalues the reputation system which programmers hate as I previously mentioned you're getting reputation for
an answer that somebody else or engaged it's like well it's an answer but somebody are sorry gave that answer so why are you getting reputation for the
same answer as the other guy who gave it 4 years ago people get offended by that right so the reputation system itself
adds tension to the system in that the people who have a lot of reputation become very incentivized to enforce the
reputation system and for the most part that's good I know it sounds weird but for most parts like look strict systems
I think to use Tec powerful you have to have the idea that ok strict systems ultimately work better and I do think in
programming you're familiar with loose typing versus strict typing right the idea that you can declare a variable not
declare a variable rather you start using a variable and ok I see it's implicitly an integer BAM awesome duck equals 5 well duck is now an in
under 5 right and you're like cool awesome simpler right why would I want to worry about typing and for a long
time like in the Ruby community they're like yeah this is awesome like you just do a bunch of unit testing which is testing your programs validity after the
fact to catch any bugs that that strict typing of variables would have caught and now you have this thing called
typescript from Microsoft from the guy who built c-sharp Manders who's one of the greatest minds in software
development right like in terms of language design and says no no no we want to bolt on a strict type system to JavaScript because it makes things
better and now everybody's like oh my god we we deployed typescript and found 50 latent bugs that we didn't know about
right like this is super common so I think there is a truth in programming
that strictness it's not the goal we're not saying be super strict cuz strictness is correct no it's no no
strictness produces better results that's what I'm saying right so strict typing of variables I would say you
almost universally have consensus now is basically correct should be that way in every language right duck equals 5
should during an error because you know you didn't clear you didn't tell me the duck was an integer right that's a bug right
or maybe you missed time you typed deck right instead of duck right you never know this happens all the time right so with that in mind I will say that the
strictness the system is correct now that doesn't mean cruel that doesn't mean mean that doesn't mean angry it just means tricked okay so I
think where there's misunderstanding is and people get cranky right like another question you asked is like why are programmers kind of mean sometimes well
who'da programmers work with all day long so I have a theory that if you're at a job and you work with all
day long what do you eventually become an an and what is the computer
except the world's biggest because the computer has no time for your the computer the minute
you make a mistake everything else crashing down right one semicolon has crashed space missions right so that's
normal so you begin to internalize that you begin to think oh my coworker the
computer is super strict and kind of a jerk about everything so that's kind of how I'm gonna be because I work with
this computer and I have to accede to its terms on everything so therefore you start to absorb that and you start to
think oh well being really strict arbitrarily is really good an error of error code five six two four nine is a
completely good error message because that's what the computer gave me right so you kind of forget to be a person at
some level and you know they say great detectives internalized criminals and kind of are criminals themselves like
this trope of the master detective is good because you can think like the criminal well I do think that's true of
programmers really good programmers think like the computer because that's their job but if you internalize it too
much you become the computer you become a kind of become a jerk to everybody because that's what you've internalized
you're almost not a jerk but you have no patience for a lack of strictness as you said it's not out of a sense of meanness
it's accidental but I do believe it's an occupational hazard of being a programmer is you start to behave like the computer you're very unforgiving
you're very terse you're very Oh wrong and correct move on it's like well can you help me like what could I do to fix
now wrong say next question right like that's normal for the computer right
just fail next right like out of you remember in Saturday Night Live like in
the nine they had this character was an IT guy yeah the move guy move was that Jimmy
Fallon no no can't play dumb okay yeah I remember move right he had no patience
for he might have been MADtv actually might have been might a bit but anyway that was the that's always been the
perception right you start to behave like the computer it's like oh you're wrong out of the way you know you've written so many blog posts about
Solo Programming
programming about programs programming programmers what do you think makes a
good let's start with what makes a good solo programmer well I don't think you
should be a solo programmer I think to be a good solo programmer it's kind of like what I talked about well not on mic but one of the things john carmack one
of the best points he makes in the book masters of doom which is a fantastic book anybody listening this who hasn't
read it please read it's such a great book is that at the time they were working on stuff like Wolfenstein and
doom like they didn't have the resources that we have today they didn't have Stack Overflow they didn't have
Wikipedia they didn't have like discourse forums they didn't have places to go to get people to help them write
they had to work on their own and that's why it took a genius like Carmack to do this stuff because you had to be a
genius to invent from first principles a lot of the stuff he was he was like the hacks he was coming up with were genius
right genius level stuff but you don't need to be a genius anymore and that means not working by yourself you have to be good at researching stuff online
you have to be good at asking questions really good questions that are really well researched which implies oh I went out and researched for three hours
before I wrote those questions like that's what you should be doing because that's what's gonna make you good write to me this is the big difference between
programming in like the 80s versus programming today is like you you kind of had to be by yourself back then like
where would you go for answers I remember in the early days when I was a learning Visual Basic for Windows like I
would call the Microsoft helpline on the phone when I had like program because I was like I don't know what to do so I
would like go and call and they have these huge phone banks and like can you imagine how alien that is now like who would do that right like that's crazy
so there was just nowhere else to go when you got stuck right like I had the books that came with it I read those
study those religiously I I just saw a post from Steve Sinofsky that said this C++ version seven
came with like 10,000 pages of written material because where else were you
gonna figure that stuff out go to the library I mean you don't have what capito you didn't have you know read it
you know were to go to answer these questions so you you've talked about through the years basically not having
Being Effective at Programming
an ego and not thinking that you're the best programmer in the world it's always
kind of just looking to improve to become a better programmer than you were
yesterday so how have you changed as a programmer and as a as a thinker
designer around programming over it'll past what is it 15 years really of being
a public figure I would say the big insight that I had is eventually as a programmer you have to kind of stop
writing code to be effective which is kind of disturbing because you really love it and but you realize like being
effective at program at programming in the general sense doesn't mean writing
code and a lot times you can be much more successful by not writing code and writing code in terms of just solving the problems you have essentially hiring
people that are really good and like setting them free and like giving them basic direction right like on strategy
and stuff because a lot of the problems you encounter aren't necessarily solved through like really gnarly code they're
solved by conceptual solutions which can then be turned into code but are you even solving the right problem I mean so
I would say for me the main insight I have is to succeed as a programmer you
eventually kind of stop writing code that's gonna sound discouraging probably to people hearing but I don't mean it
that way what I mean is that you're coding at a higher level language eventually like okay so we're coding an assembly language right that's the
beginning right you're hard coded to the architecture then you have stuff like see we're cool we can abstract across
the architecture you can write code I can then compile that code for arm or you know you know whatever you know x86
or whatever else is out there and then even higher level net right like you're looking like Python Ruby interpreted
languages and then to me as a programmer like okay I want to go even higher I want to go higher than that how do I
abstract higher than the language it's like well you abstract in spoken language and written language right like you're sort of inspiring people to get
things done giving them guidance like what if we did this what if we did this you're writing in the highest level language that there is
which is for me English right whatever your spoken language is so it's all about being effective right and I think
a patrick mckenzie Patio 11 on Hacker News and works at stripe has a great
post about this of how calling yourself a programmer is a career limiting move at some level once you get far enough
from your crin I really believe that and again I apologize this is sound discouraging I don't mean it to be but he's so right because all the stuff that
goes on around the code like the people mm-hmm like that's another thing if you look at my early blogging piece is about Wow
programming is about people more than it's about code which doesn't really make sense right but it's about can
these people even get along together can they understand each other can you even explain to me what it is you're working
on are you solving the right problem people weren't right another classic programming book which again up there with code complete please read people
where it's that software is people right people are the software first and foremost so a lot of the skills that I
was working on early on the blog were about figuring out the people parts of programming which were the harder parts
the hard part of programming once you get to a certain skill of in programming you can pretty much solve any reasonable problem that's put in front of you
you're not writing algorithms from scratch right that just doesn't happen so any sort of reasonable problem for in
front of you're gonna be able to solve but what you can't solve is our manager is a total jerk you cannot solve that
with code that is not a codes problem and yet that will you way more
than oh we had to use this stupid framework I don't like or or you know Sam keeps writing bad code that I hate
or you know you know Dave is off there in the wilderness writing god knows what right these are not your problems your
problems your manager or a co-worker is so toxic to everybody else in your team that like nobody can get anything done
because everybody's so stressed out and freaked out right these are the problems that you have to attack absolutely and
so as you go to these higher level abstractions as you developed as a programmer to higher higher level abstractions go into natural language
you're also the guy who kind of preached you know building it you know diving in
and doing it and and and like learn by doing yes do you do you worry that as
you get to higher higher level abstractions you lose track of the lower level of just building is
like do you worry about that you know even not maybe now but 10 years from now 20 years from now well no I mean there
is always that paranoia and oh gosh I don't feel as valuable since I'm not writing code but for me like when we started the discourse project it was
Ruby which I didn't really know Ruby I mean as you pointed out and this is another valuable have straight from Stack Overflow you can be super
proficient for example C sharp which I was working in that's what we built Stack Overflow and and still is written in and then switch to Ruby and you're a
newbie again right like I'm but but you have the framework I know what a for loop is I know what recursion is I know
you know what would attract a stack traces right like I have all the fundamental concepts to be a programmer
I just don't know Ruby so I'm still on a higher level I'm not like a beginner beginner like you're saying I'm just like I need to apply my programming
concepts I already know to Ruby what so there's a question that's really interesting so looking at Ruby how do
you go about learning enough that your intuition can be applied well that carryover that's all trying to get to is
like what I realized written when I started was just me and Robin I realized if I bother Robin I am now costing us
productivity right every time I go to Robin rather than building the the are
our first alpha version of this course he's now answering my stupid questions about Ruby is that a good use of his
time is that a good use of my time the answer to both of those was resoundingly no right like we were
getting to an alpha and it was a pretty much disk ok we'll hire more programmers right like we eventually hired Neil and
then eventually Sam who came in as a co-founder actually was Sam first then Neil later but the answer of the problem
is just hire other competent programmers it's not like teach now I shalt pull myself up by my bootstraps and Ruby but
at some point writing code becomes a liability to you in terms of getting things done there's so many other things
that go on in the project like building the prototype like you mentioned like well how do you if you're not writing code has every keep focus on like what
what are we building well first basic mock-ups and research right like what what do we even want to build there's a
little bit of that that goes on then very quickly get to the prototype stage like build a prototype let's iterate on the prototype really really rapidly that's what we do at this
course and that's what we we demoed to get our seed funding for this course was the the alpha version of discourse that
we had running and ready to go and it was very it was bad I mean it was I'll just tell you it was bad I have we have screenshots and I'm
just like embarrassed to look at it now but it was the prototype we were figuring out like what's working what's not working because there's such a broad
gap Bateen between the way you think things will work in your mind or even on
paper and the way they work once you sit and live in the software like actually spend time living and breathing us out
we're so different so my philosophy is get to a prototype
and then what you're really optimizing for speed of iteration like how you can turn the crank how quickly can we
iterate that's the absolutely critical metric of any software project and I had a tweet recently that people liked and I
totally this is so fundamental to what I do is like if you want to measure the core competency of any software tech
company it's the speed at which somebody can say hey we really need this word in the product change this word right
because it will be more clear to the users like what like instead of respond it's a reply or something but there's some from the conception of that idea to
how quickly that single word can be changing your software rolled out to users that is your lifecycle that's your
health your your heartbeat if your heartbeat is like super slow you're basically dead no seriously like if it
takes two weeks or even a month to get that single word change that was oh my god this great idea that word is so much
clearer I'm talking like a super like everybody's on board for this change it's not like let's just change at work cuz we're bored it's like this is an
awesome change and then it takes a you know months to roll out it's like what you're dead like you can't iterate you
can't do anything right like so anyway about the heartbeat it's like get the
the prototype and then iterate on it that's that's what I view is like the central tenets of some modern software
development that's fascinating you put it that way it's actually so I work in I build a Thomas vehicles and when you
look at what maybe compare Tesla to most other automakers the the psych the
whatever the heartbeat for Tesla is literally days now in terms of they can
over-the-air deploy software updates to all their vehicles which is markedly
different than every other automaker which takes years to update a piece of
software and so and that's reflected in everything that's the the final product
that's reflected and really how slowly they adapt to the times clear I'm not saying being a hummingbird
is the goal either it's like you don't a heartbeat it's like so fast it's like you're your wing you know you're just freaking out but like it is a measure of
health you should have a healthy heartbeat it's up to four people listening this decide what that means but it has to be healthy has to be
reasonable because otherwise you just get me frustrated because like that's how you build software you make mistakes you roll it out you live with it
you see what it feels like and say oh god that was a terrible idea oh my gosh this could be even better if we did why right you turn the crank and then the
more you do that the faster you get ahead of your competitors ultimately because you're it's rate of change right
delta-v right how fast are you moving well within a year you're gonna be miles away
by the time they catch up with you right like that's the way it works and plus users like I as a software developer I
love software that's constantly changing because I don't understand people get super pissed off when like oh they
changed the software on me how dare they I'm like yes change the software change it all the time man that is that's what
makes this stuff great is that it can be changed so rapidly and become something
that that is greater than it is now now credit there's some changes that suck I admit I've seen it many times but in
general it's like that's what makes software cool right is that it is so malleable like fighting that is like
weird to me because it's like well you're fighting the essence of the thing that you're building like that doesn't make sense you want to really embrace
that not not to be a hummingbird but like embrace it to a healthy cycle of your heartbeat right so you talk about
that people really don't change it's true that's why probably a lot of the stuff
you write about in your blog probably will remain true there's a flip side of the coin people don't change so
investing and understanding people is is like learning Unix in 1970 because and
nothing has changed right like yeah all those things you've learned about people will still be valid 30 40 years from now whereas if you learn the latest
JavaScript framework that's gonna be good for like two years right yeah exactly so but if you look at
the future of programming so there's a people component but there's also the
technology itself do you what do you see as the future of programming will it change significantly or as as far as you
can tell people are ultimately programming and so it will not it's not
something that you foresee changing and you fund the month away well you gotta go look
on sort of the basics of programming and one things that always shocked me is like source control like I didn't learn
anything about source control I graduate from college in 1992 but I remember
hearing from people like in ladies like 1998-99 like even maybe today they're not learning source control and to me
it's like well how can you not learn source control that is so fundamental to working with other programmers working
in a way they don't lose your work like just just basics off the bed literal bedrock software development is source
control now you compare today like github right like Microsoft brought github which I think was incredibly smart acquisition move on their part now
they have anybody who wants like reasonable source control to go sign them and github it's all set up for you right there's tons of walkthroughs tons
of tutorials so from the concept of like has programming advanced from say 1999 it's like well hell we have github I
mean my god yes right like it's it's massively advanced over over what it was now as to whether program is is
significantly different I'm gonna say no but I think the baseline of like what we view is like fundamentals will continue
to go up and actually get better like source control that's one of them in fundamentals that has gotten I mean hundreds of orders of magnitude better
than it was 10 20 years ago so those are the fundamentals let me introduce two things that maybe you can comment on so
one is mobile phones so that could fundamentally transform what what
programming is or maybe not maybe you can comment on that and the other one is artificial intelligence which promises
to in some ways to do some of the programming for you is one way to think
about it so it's really what a programmer is is using the intelligence
that's inside your skull to do something useful the hope with artificial intelligence is that it does some of the
useful parts for you you don't have to think about it so do you see smart phones the fact that everybody has one
and they're getting more and more powerful as potentially changing programming and do you see AI is
potentially changing problem okay so that's good so smart phones have definitely changed I mean since you know
I guess 2010 that's when they really started getting super popular I mean in the last eight years the world has
literally changed like everybody carries a computer around and that's normal I mean that is such a huge change in society I think we're
still dealing with a lot of the positive negative ramifications of that right like everybody's connected all the time everybody's on the computer all the time
that was my dream world as a geek right but it's like be careful what you ask for right like wow no everybody's a
computer it's not quite the utopia that we thought it would be right computers can be used for a lot of stuff that's not necessarily great so to me that's
the central focus of the smartphone is just that it puts a computer in front of everyone granted a small touchscreen smallish
touchscreen computer but as for programming like I don't know I don't think that I've kind of over time come
to subscribe to the UNIX view of the world when it comes to programming it's like you want to teach these basic command line things and that is just
what programmers gonna be for I think a long long time I don't think there's any magical like visual programming that's
gonna happen I just I don't know I've over time I've become a believer in that
UNIX philosophy it was just you know they kind of had it right with UNIX that's gonna be the way it hits for a
long long time and well we'll continue to like I said raise the baseline the tools will get better it'll get simpler but it's still fun mental gonna be
command-line tools you know makes fancy IDs that's kind of it for the foreseeable future I'm not seeing any
visual programming stuff on the horizon because you can I think like what do you do on a smartphone that will be directly
analogous to programming like I'm trying to think right like and there's really not much so not necessarily analogous to
programming but the kind of things that
the kind of programs you would need to write might need to be very different
yeah and the kind of language is I mean but I probably also subscribed to the
same just because everything in this world might be written in JavaScript oh yeah that's different that's already
happening I mean this course is a bit on discourses itself javascript is another bet on that side of the table and I still strongly believe in that so I
would say smartphones have mostly a cultural shift more than a programming shift now your other question was about
artificial intelligence and like sort of devices predicting what you're gonna do and I do think there's some strengths to
that I think artificial intelligence kind of overselling it in terms of what it's doing it's more like people are predictable right people do the same things like let me
give you an example one one cheque we put in a discourse that's in a lot of big commercial websites is say you log
in from New York City now and then an hour later you log in from San Francisco like well hmm that's interesting how did
you get from New York to San Francisco in one hour so at that point you're like okay this is a suspicious login at that
point so we would alert you it's like okay but that's an AI right that's just a heuristic of like how did you in one
hour get 2,000 miles right that doesn't when you grab maybe you're on a VPN there's other races happen but that's
just a basic prediction based on the idea that people pretty much don't move around that much like they may travel
occasionally but like nobody I mean unless you're a traveling salesman that's literally we're traveling the world every day like there's so much
repetition and predictability in terms of things you're going to do and I think good software anticipate your needs like
for example Google I think it's called Google now or whatever that Google thing is that predicts your commute and predicts them based on your phone
location like where are you every day well that's probably where you work that kind of stuff I do think computers can
get a lot better at that but I hesitate to call it like full-blown AI it's just computers getting better at like first
of all they have a ton of because every has a smartphone now I'm suddenly how all this data that we didn't have before about location about like you know
communication and feeding that into some some basic heuristics and maybe some fancy algorithms that turn it into
predictions of anticipating your needs like like a friend would write like oh hey I I see your home would you like
some dinner right like let's go get some food because that's usually what we do this time of day right and the context of actually the act of programming DCI
des improving and making the life of programming is better I do think that is possible cuz things a lot of repetition
in programming right oh you know Clippy would be the bad example of oh I see it looks like you're writing a for loop
um but there are patterns in code right like in and actually libraries are kind of like that right like rather than go
you know code up your own HTTP request library it's like what you'd use one of the existing ones that we have that's
already troubleshot right it's not a I per se it's just you know building
better Lego bricks bigger Lego bricks that have more functionality in them so people don't have to worry about the
low-level stuff as much anymore like WordPress for example to me is like a tool for someone who is in a programmer to do something I mean you
can turn WordPress into anything it's kind of crazy actually through perla plugins right and that's not programming per se it's just Lego bricks stacking
WordPress elements right a little bit of configuration glue so I would say maybe in a broader sense what I'm seeing like
they'll be more gluing and less like actual programming and that's a good
thing right because most of the stuff you need is kind of out there already you said 1970 is Unix do you see PHP and
these kind of old remnants of the early
birth of programming remaining with us for a long time like you said Unix in itself
do you see ultimately you know this stuff just being there out of momentum I
kind of do I mean I was a big believer in Windows early on and I was a big you know I was like a UNIX what a waste of
time but over time I've completely flipped on that where I was like okay the UNIX guys were right and pretty much Microsoft and windows were kind of wrong
at least on the server side not on the desktop right you need a GUI you know what stuff and yeah the two philosophies
like Apple built on UNIX effectively Darwin and on the desktop is a slightly
restore even on the server side where you're going to be programming now it's question where the program is gonna be there's gonna be a lot more like
client-side programming because technically discourse is client-side programming the way you get discourse we
deliver a big ball of JavaScript which is then execute locally so we're really using a lot more local computing power
will still retrieve the data obviously we have to display the posts on the screen and so forth but in terms of like sorting and a lot of the basic stuff
we're using the host processor but to the extent that a lot of programming is still gonna be server-side I would say
yeah the UNIX philosophy definitely one and they'll be different veneers over the UNIX but it's still if you if you
peel away one or two layers it's gonna be UNIX safe for a long I think UNIX one I mean so definitively it's interesting
to hear you say that because you've done so much excellent work on the Microsoft and aside in terms of back-end
development cool so what's the future hold for Jeff Atwood amid the discourse
continuing the discourse in trying to improve conversation on the web
this force is whatever be it is a and originally I call it a five-year project then really quickly revised that to a ten-year project so where we started in
early to that 2013 that's we launched the first version so we're still you know five years in this is the part
where it starts getting good like we have a good product out this course there's any any project building software it takes three years to build
what you wanted to build anyway like v1 is gonna be terrible which it was but you ship it anyway cuz that's how you
get better at stuff it's about turning the crank it's not about v1 being perfect because that's ridiculous it's about v1 then let's get really good at V
1.1 1.2 1.3 like how fast can we iterate and I think we're iterating like crazy on discourse the point that like it's a
really good product now we have serious momentum and my original vision was I
want to be the wordpress of discussion meaning someone came to you and said I want to start a blog although the very
question is kind of archaic now it's like who actually blogs anymore but I wanted the answer to that to be it would
be what did WordPress normally because that's the obvious choice for blogging most the time but if someone said hey I
want to I need a group of people to get together and do something the answer should be discourse right that should be
the default answer for people cuz it's open source it's free doesn't cost you anything you control you can run it your
minimum server across four discourses five bucks a month at this point they actually got the VPS prices down it used
to be ten dollars a month for one gigabyte of RAM which we where our dependent we have a kind of heavy stack
like there's a lot of stuff in discourse you need post grass you need Redis you need Ruby on Rails you need a sidekick
for scheduling it's not a trivial amount of stuff because we were architected for like look we're building for the next ten years I don't care about shared PHP
hosting that's that's not my model my idea is like hey you know eventually this is gonna be very cheap for
everybody and I want to build it right using again you know hire bigger
building block levels right that have more requires and there's a wordpress model of wordpress.org juarez calm is
their central hosting for this course or no there is we're not strictly segmenting into the open source versus
the commercial side we have a hosting business that's how this course makes money is we host discourse instances and we have really close relationship with
our customers of the symbiosis of them giving us feedback on the product we definitely wait feedback from customers
a lot heavier than feedback from somebody who just wanders by and gives feedback but that's where we make
all our money but we don't have a strict division we encourage people to use this course like the whole point is that it's
free right you're anybody can set it up I don't want to be the only person that hosts discourse that's absolutely not
the goal but it is a primary way for us to build a business and it's actually kind of a great business I mean the business is going really really well in
terms of hosting so I I used to work at Google research is a company that's basically funded on advertisement so
it's Facebook let me ask if you can comment on it I think advertisement is best so you'd
be extremely critical on what ads are but at its best it's actually serving
you in a sense as giving you it's connecting you to what you would want to explore so it's like related posts or
related content is the same that's the best of advertisement so this course is
connecting people based on their interests it seems like a place where advertisement at its best could actually
serve the users is that something that you're considering thinking about as a way to bring to financially support the
platform that's interesting because I actually have a contrarian view of advertising which I kind of agree with you I recently installed that blocker
like reluctantly because I don't like to do that but like the performance of the ads man like they're so heavy now and
like it's just crazy so like it's almost like a performance argument more than like I actually am Pro ads and I
contrary I have a contrarian viewpoint I agree with you if you do ads right it's showing you stuff you'll be interested
in anyway like I don't mind that that actually is kind of a good thing so plus I think it's it's rational to
want to support the people that are doing this work through seeing their ads and but that said I run adblock now which I I didn't want to do but I was
convinced by all these artists like 30 40 megabytes of stuff just to serve you ads yeah it feels like as now or like
the experts exchange of whenever you started Stack Overflow it's a little bit it's all there's so many companies and
Antec though it's embarrassing like you can do that if you see those logo charts of like just a whole page just like you can't even see them they're so small
there's so many companies in the space but since you brought it up I do want to point out that very very few discourse
sites run using an ad-supported model it's not effective like it's too diluted it's too
weird it doesn't pay well and like users hate it so it's a combination of like users hate it it doesn't actually work
that well in practice like in theory yes I agree with you but if you clean fast ads that were exactly the stuff you
would be interested awesome we're so far from that though right like Google does an okay job retargeting and stuff like that but in
the in in the real world discourse sites rarely can make ads work it just doesn't work for so many reasons
but you know it does work is subscriptions patreon affiliate codes
for like Amazon of like just oh here here's a cool yo-yo click and then you click and go to Amazon they get a small
percentage of that which is fair I think because you saw the yo-yo on that site and you click through and you bought it
right that's fair for them to get 5% of that or 2% of that or whatever it is those things definitely work in fact a
site that I used to participate on a lot I helped the owner one things I I got
them switched to discourse obviously paid them to switch to discourse because I was like look you guys got a switch I can't come here anymore all this terrible in software but I was like a
look and on top of that like you're serving people ads that they hate like you should just go full on patreon because he had a little bit of patreon
go full on patreon do the Amazon affiliates thing for any Amazon links to
get posted and just do that and just triple down on that stuff and that's worked really well for them and this
creator in particular so that stuff works but traditional ads I mean definitely not working at least on this
course so last question you've created the code keyboard I've programmed most
of my adult life and a Kinesis keyboard I have one upstairs now can you describe
what a mechanical keyboard is and why is it something that makes you happy well you know this is another fetish item
really like it's not required you can do programming on any kind of keyboard right even like an on-screen keyboard oh
god that's terrifying right like well you could but if you look back to the early days computing there were chiclet keyboards which are I
think those are awful right but what's a chick like you were oh god okay well it's just like thin rubber membranes all
the rubber ones oh no super bad right yeah so it's a fetish item all it really says is look I care really about
keyboards because the keyboard is the primary method of communication with computer right so it's just like having a nice mic for this this podcast you want a
nice keyboard right because it has tat very tactile feel I can tell exactly when I press the key I get that little click so oh and it feels good and it's
also kind of a fetish shot it was like wow I care enough about programming that I care about the tool the primary tool
that I use committing to computer make sure it's as good as it feels good to use for me and like I can be very
productive with it so to be honest it's a little bit of a fetish item but a good one it indicates that you're serious and
in case you're interested it indicates that you care about the fundamentals because you know what makes you a good programmer being able to type really
fast right like this is true right so a core skill is just being able to type fast enough to get your ideas out of
your head into the codebase so just practicing your typing can make you a better programmer it is also something
that makes you well makes you enjoy typing correct the actual act something
about the process I got played piano it's time so there's a tactile feel that
ultimately feeds the passion makes you happy right no totally that's it I mean and it's funny because artisanal
keyboards have exploded like mass drop has gone ballistic with this stuff there's probably like 500 keyboard
projects on mass drop alone and there's some other guy I follow on Twitter I used to write for this the site the tech report way back in the day and he's like
every week he's just posting like what I call keyboard porn of like just cool keyboards like how my god they look really cool right like that's like how
many keyboards this guy yeah it's got me with yo-yos how many rows do you have how many do you need well technically one but I like a lot I don't
know why so same thing with keyboards so yeah they're awesome like I highly recommend anybody who
doesn't have a mechanical to research it look into it and see what you like and you know it's ultimately a fetish item
but I think these sort of items these religious artifacts that we have are part of what make us human like that
that part you important right it's kind of makes life worth living and yes it's not necessary in the strictest sense but
ain't nothing necessary if you think of yet right like and so yeah why not so
sure Jeff thank you so much for talking today yeah you're welcome thanks for having
you

----------

-----

--47--

-----
Date: 2018.11.22
Link: [# Guido van Rossum: Python | Lex Fridman Podcast #6](https://www.youtube.com/watch?v=ghwaIiE3Nd8)
Transcription:

the following is a conversation with guido van rossum creator of Python one of the most popular programming
languages in the world used in almost any application that involves computers from web back-end development to
psychology neuroscience computer vision and robotics deep learning natural language processing in almost any
subfield of AI this conversation is part of MIT course on artificial general
intelligence and the artificial intelligence podcast if you enjoy it subscribe on YouTube iTunes or your
podcast provider of choice or simply connect with me on Twitter at lex friedman spelled FR ID and now here's my
conversation with guido van rossum you were born in the Netherlands in 1956
your parents and the world around you was deeply impacted by world war ii as
was my family from the soviet union so with that context well what is your view
of human nature are some humans inherently good and some inherently evil
or do we all have both good and evil within us ouch I did not expect such a
deep one I I guess we all have good and evil potential in us in a lot of it
depends on circumstances in context out
of that world at least on the Soviet Union side in Europe sort of out of
suffering out of challenge out of that kind of set of traumatic events often
emerges beautiful art music literature in an interview I read or heard you said
you enjoy Dutch literature when when you were a child can you tell me about the
books that had an influence on you in your childhood well as a teenager my favorite writer
was my favorite Dutch author was a guy named villain Phaedra chemins whose
writing certainly his early novels were all about sort of ambiguous things that
happened during World War two I think he was a young adult during that time and
he wrote about it a lot and and very
interesting very good books I thought I think in a nonfiction way no it was all
fiction but it was very much set in in the ambiguous world of resistance
against the Germans where often you couldn't tell whether someone was truly
in the resistance or really a spy for the Germans and and some of the
characters in his novels sort of crossed that line and you never really find out
what exactly happened and in his novels there's always a good guy and a bad guy
the nature of good and evil is it clear there's a hero it's no his heroes are
often more his main characters are often anti-heroes and and and so there they're
not not very heroic they're they're often they they fail at some level to
accomplish their lofty goals and looking at the trajectory through the rest of
your life has literature Dutch or English or translation and an impact
outside the technical world that you existed in
I still read novels I don't think that it impacts me that much directly doesn't
impact your work it's just it's uh it's a separate world my work is is highly
technical and sort of the the world of art and literature doesn't really
directly have any bearing on it you don't think there's a creative element to the design you know some would say
our design of a language is art I'm not
disagreeing with that I'm just saying that sort of I don't feel direct
influences from more traditional art on my own creativity right of course you
don't feel doesn't mean it's not somehow deeply there and your subconscious knows
who knows so let's go back to your early teens your hobbies were building
electronic circuits building mechanical models what if you could just put
yourself back in the mind of that young Guido 12 13 14 was that grounded in a
desire to create a system so to create something or was it more just tinkering
just the joy of puzzle solving uh I think it was more the leather actually I
maybe towards the end of my high school
period I felt confident enough that that I designed my own circuits that were
sort of interesting somewhat
but a lot of that time I literally just took a model kit and follow the
instructions putting the things together I mean that I think the first few years that I build electronics kits I really
did not have enough understanding of sort of electronics to really understand
what I was doing I mean I could debug it and I could sort of follow the instructions very carefully which has
had which has always stayed with me but I had a very naive model of like how a
transistor works and I don't think that that in those days I had any
understanding of coils and capacitors which which actually sort of was a major
problem when I started to build more complex digital circuits because I was
unaware of the sort of the analog part of the how they actually work and I
would have things that the scheme the
schematic looked every everything looked fine and it didn't work and what I
didn't realize was that there was some megahertz level oscillation that was
throwing the circuit off because I had a sort of two wires were too close or the
switches were were kind of poorly built but through that time I think it's
really interesting and instructive to think about because as echoes of it are in this time now so in the 1970s the
personal computer was being born so did you sense in tinkering with these
circuits did you sense the encroaching revolution and personal computing so if
at that point you're sick we will see you down and ask you to predict the 80s and the 90s do you think you would be
able to do so successfully to unroll this the process that's no I had no clue
I I remember I think in the summer after my
senior year or maybe it was the summer after my junior year well at some point
I think when I was 18 I went on a trip to the Math Olympiad in Eastern Europe
and there was like I was part of the Dutch team and there were other nerdy kids that sort of had different
experiences and one of them told me about this amazing thing called a computer and I had never heard that word
my own explorations in electronics were sort of about very simple digital
circuits and I I had sort of I had the
idea that I somewhat understood how a digital calculator worked hmm and so
there is maybe some echoes of computers there but I didn't didn't I never made
that connection I didn't know that when my parents were paying for magazine
subscriptions using punched cards that there was something called a computer
that was involved that read those cards and transferred the money between accounts that was also not really
interested in those things it was only when I went to university to study math
that I found out that they had a computer and students were allowed to
use it and there were some you're supposed to talk to that computer by programming it what did that feel like
yeah that was the only thing you could do with it I think the computer wasn't really
connected to the real world the only thing you could do was sort of you typed
your program on a bunch of punched cards you gave the punched cards to the
operator and an hour later the operator gave you back your printout and so all
you could do was write a program that did something very abstract and I don't
even remember what my first forays into programming were but they were sort of doing simple math
exercises and just to learn how a programming language worked did you
sense ok first year of college you see this computer you're able to have a
program and it generates some output did you start seeing the possibility of this
or was it a continuation of the tinkering with circuits the did you
start to imagine that one the personal computer but did you see it as something
that is a tool so got a tool like a word processing tool maybe maybe for gaming
or something or did you start to imagine that it could be you know going to the world of robotics
like you you know the Franklin is that picture that you could create an artificial being there's like another
entity in front of you you did not say I don't think I really saw it that way I
was really more interested in the tinkering it's maybe not a sort of a
complete coincidence that I ended up sort of creating a programming language
which is a tool for other programmers I've always been very focused on the
sort of activity of programming itself and not so much what happens with with
the program you write right I do remember and I don't dream it maybe in
my second or third year probably my second actually someone pointed out to
me that there was this thing called Conway's Game of Life you're probably
familiar with it I think the seventies I think yeah he came up with it so there
was a scientific American column by someone who did a monthly column about
mathematical diversions I'm also blanking out on the guy's name it was it was very famous at the time
and I think up to the 90s or so and one of his columns was about Conway's Game
of Life and he had some illustrations and he wrote down all the rules and sort of there was the suggestion
that this was philosophically interesting that that was why Conway had called it that and all I had was like
the two pages photocopy of that article I didn't even remember where I got it
but it spoke to me and I remember implementing a version of that game for
the batch computer we were using where I had a whole Pascal program that sort of
read an initial situation from input and read some numbers that that said do so
many generations and print every so many generations and then out would come
pages and pages of sort of things kinds
of different kinds and yeah and I remember much later I've done a similar
thing using Python but I'd sort of that original version I wrote at the time I
found interesting because I combined it with some trick I had learned during my
electronics hobbyists times I essentially first on paper I designed a
simple circuit built out of logic gates that took nine bits of input which is
the sort of the cell and its neighbors and produced a new value for that cell
and it's like a combination of a half adder and some other clipping you know
it's actually a full adder and so I had worked that out and then I translated
that into a series of boolean operations
on Pascal integers where you could use the integers as bitwise values and so I
could basically generate 60 bits of a generation in in like eight instructions
or so nice I was proud of that it's it's funny that you mentioned so for people who
don't know Conway's Game of Life is a there's it's a cellular automata whether it's single compute units that kind of
look at their neighbors and figure out what they look like in the next
generation based on the state of their neighbors and this is deeply distributed system that it in in concept at least
and then there's simple rules that all of them follow and somehow out of this
simple rule when you step back and look at what occurs it's it's beautiful
there's a emergent complexity even though the underlying rules are simple there's an emergent complexity now the
funny thing is you've implemented this and the thing you're commenting on is you're proud of a hack you did to make
it run efficiently when you're not commenting on what like this is a
beautiful implementation you're not commenting on the fact that there's an emergent complexity that you've you've
you've coded a simple program and when you step back and you print out those following generation after generation
that's stuff that you may have not predicted what happen is happening right
and there was that is that magic I mean that's the magic that all of us feel when we program when you when you create
a program and then you run it and whether it's hello world or show
something on screen if there's a graphical component for you seeing the magic in the mechanism of creating that
I think I went back and forth as a student we had an incredibly small
budget of computer time that we could use it was actually measured I once got
in trouble with one of my professors because I had overspent the department's budget it's a different story but so I I
actually wanted the efficient implementation because I also wanted to
explore what would happen with a larger number of generations and a larger sort
of size of the of the board and so once the implementation was flawless I would feed
at different patterns and then I think maybe there was a follow-up article where there were patterns that that were
like gliders parents that repeated themselves after a number of generations
but translated one or two positions to
the right or up or something like that and there were I remember things like
glider guns well you can you can google Conway's Game of Life is still of people
still go on and over it for a reason because it's not really well understood why I mean this is what
Stephen Wolfram is obsessed about yeah okay so he's just the the we don't have
the mathematical tools to describe the kind of complexity of the emerges in these kinds of systems and the only way
to do is to run it I'm not convinced that that it's sort of a problem that
lends itself to two classic mathematical analysis no and so one one theory of how
you create an artificial intelligence or artificial being is you kind of have to send with a game of life you kind of
have to create a universe and let it run that creating it from scratch in a
design way in the you know coding up a Python program that creates a full
intelligence system may be quite challenging that you might need to create a universe just like the game of life is
well you might have to experiment with a lot of different universes before there
there is a set of rules that doesn't essentially always just end up repeating
itself in in a trivial way yeah and analyst Steve wolf from Stephen Wolfram
works with these simple rules says that it's kind of surprising how quickly find rules that create interesting things you
shouldn't be able to but somehow you do and so maybe our universe is laden with
with rules that will create interesting things that might not look like humans but yeah you know emergent phenomena
that's interesting may not be as difficult to create as we think sure but let me sort of ask at that time
you know some of the world's least in popular press was kind of captivated
perhaps at least in America by the idea of artificial intelligence that that
these computers would be able to think pretty soon and yeah that touch you at
all did that in science fiction or in reality in uh in anyway I didn't really
start reading science fiction until much much later
I think as a teenager I I read maybe one bundle of science fiction stories was in
my background somewhere like in your thoughts that sort of the using
computers to build something intelligent always fell to me because I had I felt I
had so much understanding of what actually goes on inside a computer I I
knew how many bits of memory it had and how difficult it was to program and sort
of I didn't believe at all that that you
could just build something intelligent out of that that that would really sort
of satisfy my definition of intelligence
I think the most the most influential thing that I read in my early 20s was
girlish ABBA that was about consciousness and that was a big
eye-opener in in some sense in what
sense oh so console yeah so on your own brain did you do use did you at the time
or do you now see your own brain as a computer or is there a total separation of the way so yeah you're very
pragmatically practically know the limits of memory the limits of this
sequential computing or weakly paralyzed computing and you just know what we have
now and it's hard to see how it creates but it's also easy to see it was in the
40s 50s 60s and now at least similarities between the brain and our
computers oh yeah I mean I I totally believe that brains are computers in
some sense I mean the rules they they used to play by are pretty different
from the rules we we can sort of implement in in our current hardware but
I don't believe in like
a separate thing that infuses us with intelligence or consciousness or any of
that there's no soul I've been an atheist probably from when I was 10
years old just by thinking a bit about math and the universe and then well my
parents were atheists now I know that you you you could be an atheist and
still believe that there is something sort of about intelligence or
consciousness that cannot possibly emerge from a fixed set of rules I am
NOT in that camp I I totally see that sort of given how
many millions of years evolution took its time DNA is is a particular machine
that that sort of encodes information
and an unlimited amount of information in in chemical form and has figured out
a way to replicate itself I thought that death was maybe it's 300 million years
ago but I thought it was closer to half a billion years ago that that's sort of
originated and it hasn't really changed that the sort of the structure of DNA hasn't changed ever since that is like
our binary code that you're having hardware I mean the basic programming
language hasn't changed but maybe the programming itself of has lead it did it
sort of it it happened to be a set of rules that was good enough to to sort of
develop endless variability and and sort of the the idea of self-replicating
molecules competing with each other for resources and and one type eventually
sort of always taking over that happened before there were any fossils so we
don't know how that exactly happened but I believe it it's it's clear that
that did happen and can you comment on consciousness and how you see it because
I think we'll talk about programming quite a bit we'll talk about you know intelligence connecting to programming
fundamentally but consciousness consciousness is this whole lot of other thing do you think about it often as a
developer of a programming language and and as a human those those are pretty
sort of separate topics my sort of my line of work working with programming
does not involve anything that that goes in the direction of developing
intelligence or consciousness but sort of privately as an avid reader of
popular science writing I I have some
thoughts which which is mostly that I don't actually believe that
consciousness is an all-or-nothing thing I have a feeling that and and I forget
what I read that influenced this but I
feel that if you look at a cat or a dog or a mouse they have some form of
intelligence if you look at a fish it has some form of intelligence and that
evolution just took a long time but I feel that the the sort of the evolution of more and more intelligence that led
to to sort of the human form of intelligence follow the evolution of the
senses especially the visual sense I mean there is an enormous amount of
processing that's needed to interpret a scene and humans are still better at
that than then computers yeah and so and and and I have a feeling
that there is a sort of the reason that
that like mammals is in particular developed the levels of consciousness
that they have and that eventually read sort of informative going from
intelligence to to self-awareness in consciousness has to do with sort of
being a robot that has very highly developed senses as a lot of rich
sensory information coming in so the it's a really interesting thought that
the that whatever that basic mechanism of DNA whatever that basic building blocks are
programming is you if you just add more abilities more more high resolution
sensors more sensors you just keep stacking those things on top that there's basic programming in trying to
survive develops very interesting things that start to us humans to appear like
intelligence and consciousness yeah so in in as far as robots go I think that
the self-driving cars have the sort of the greatest opportunity of developing
something like that because when I Drive myself I don't just pay attention to the rules
of the road I also look around and I get clues from that oh this is a shopping
district oh here's an old lady crossing the street oh here is someone carrying a
pile of mail there's a mailbox thatthat should they're gonna cross the street to
reach that mailbox and I slowed down and I don't even think about that yeah and and so there is there's so much where
you turn your observations into an understanding of what utter
consciousnesses are going to do or what what utter systems in the world are
going to be oh that tree is gone at fault yeah I see sort of I see much more of
expect somehow that if anything is going to become conscious it's going to be the
self-driving car and not the network of a bazillion computers at in a Google or
Amazon data center that are all networked together to to do whatever
they do so in that sense so you actually have like is that's what I work in
autonomous vehicles you highlight a big gap between what we currently can't do
and what we truly need to be able to do to solve the problem under that formulation and consciousness and
intelligence is something that basically a system should have in order to
interact with us humans as opposed to some kind of abstract notion of a
consciousness consciousness is something that you need to have to be able to empathize to be able to fear the
understand what the fear of death is all these aspects that are important for interaction with pedestrians you need to
be able to do basic computation based on our human desires and flaws sort of yeah
if you if you look at the dog the dog clearly knows I mean I'm not the dog out on my brother I have friends who have
dogs the dogs clearly know what the humans around them are going to do or the least they have a model of what
those humans are going to do and they learn the dot some dogs know when you're going out and they want to go out with
you they're sad when you leave them alone they cry they're afraid because
they were mistreated when they were younger we we don't assign sort of
consciousness to dogs or at least not not all that much but I also don't think
they have none of that so I think it's it's consciousness and intelligence are
not all or nothing the spectrum it's really interesting but
in returning to programming languages and the way we think about building
these kinds of things about building intelligence building consciousness building artificial beings I think one
of the exciting ideas came in the 17th century and with liveness Hobbes decart
where there's this feeling that you can convert all thought all reasoning all
the thing that we find very special in our brains you can convert all that into
logic you can formalize it form a reasoning and then once you formalize
everything all of knowledge and you can just calculate and that's what we're doing with our brains is we're
calculating so there's this whole idea that we that this is possible that this
we're aware of the concept of pattern matching in the sense that we are aware
of it now add a sort of thought you they they had discovered incredible bits of
mathematics like Newton's calculus and
they're sort of idealism they're they're sort of extension of what they could do
with logic and math sort of went along those lines and they thought there
there's like yeah logic there's there's like a bunch of rules and a bunch of
input they didn't realize that how you recognize a face is not just a bunch of
rules but it's a ton of data plus a circuit that that sort of interprets the
visual clues and the context and everything else and somehow can
massively parallel pattern match against stored rules I mean but if I see you
tomorrow here in front of the drop box office I might recognize you even if I'm
wearing a different shirt yeah but if I if I see you tomorrow in a coffee shop in Belmont
I might have no idea that was you or on the beach or whatever hey I make those mistakes myself all the
time I see someone that I only know s like oh this person is a colleague of my
wife's yeah and then I see them at the movies and I didn't recognize them but
do you see those you call it pattern matching do you see that rules is unable
to encode that to you you everything you see all the pieces of information you
look around this room I'm wearing a black shirt I have a certain height I'm a human all these you can there's
probably tens of thousands of facts you pick up moment by moment about this scene you take them for granted and you
accumulate aggregate them together to understand the scene you don't think all that could be encoded to where at the end of the day
you can just put it all on the table and calculate oh I don't know what that
means I mean yes in the sense that there is no there there is no actual magic
there but there are enough layers of abstraction from sort of from the facts
as they enter my eyes in my ears to the understanding of the scene that that's I
don't think that that AI has really covered enough of of that distance it's
like if you take a human body and you realize it's built out of atoms well
that that is a uselessly reductionist view right right the body is built out
of organs the organs are built out of cells the cells are built out of proteins the proteins are built out of
amino acids the amino acids are built out of atoms and then you get to quantum
mechanics so that's a very pragmatic view I mean obviously is an engineer I
agree with that kind of view but I also you also have to consider the the with
the same harris view of well well intelligence is just information processing these just like you said you
take in sensory information you do some stuff with it and you come up with actions that are intelligent that McGee makes it sound so
easy I don't know who Sam Harris is oh let's philosopher so like this how philosophers often think right and
essentially that's what the car was is wait a minute if there is like you said no magic
so you basically says it doesn't appear like there is any magic but we know so little about it that it might as well be
magic so just because we know that we're made of atoms just because we know we're made of organs the fact that we know
very little hot to get from the atoms to organs in a way that's recreate able means it that you shouldn't get too
excited just yet about the fact that you figured out that we're made of atoms right and and and the same about taking
facts as are our sensory organs take them in and turning that into reasons
and actions that sort of there are a lot of abstractions that we haven't quite
figured out how to how to deal with those I mean I so sometimes I don't know
if I can go on a tangent or not I dragged you back in sure so if I take a
simple program that parses say say have a compiler it parses a program in a
sense the input routine of that compiler of that parser is a sense a sensing
Oregon and it builds up a mighty complicated internal representation of
the program it just saw it doesn't just have a linear sequence of bytes
representing the text of the program anymore it has an abstract syntax tree
and I don't know how many of your viewers or listeners are familiar with
compiler technology but there's fewer and fewer these days right that's also
true probably people want to take a shortcut but they're sort of this
abstraction is a data structure that the compiler then uses to produce outputs
that is relevant like a translation of the program to machine code that can be executed by by hardware and then the
data structure gets thrown away when a fish or a fly sees sort of gets visual
impulses I'm sure it also builds up some
data structure and for the fly that may be very minimal a fly may may have only
a few I mean in the case of a fly's brain I could imagine that there are few
enough layers of abstraction that it's not much more than when it's darker here
than it is here well I can sense motion because a fly sort of responds when you
move your arm towards it so clearly it's visual processing is intelligent well
not intelligent but it has an abstraction for motion and we still have
similar things in in but much more complicated in our brains I mean otherwise you couldn't drive a car if
you if you couldn't sort if you didn't have an incredibly good abstraction for motion yeah in some sense the same
abstraction for motion is probably one of the primary sources of our of
information for us we just know what to do I think we know what to do with that we've built up other abstractions on top
we've much more complicated data structures based on that and we build
more persistent data structures sort of after some processing some information
sort of gets stored in our memory pretty much permanently and is available on
recall I mean there are some things that you sort of you're conscious that you're
remembering it like you give me your phone number I well at my age I have to write it down
but I could imagine I could remember those seven numbers or 10 10 digits
and reproduce them in a while if I sort of repeat them to myself a few times so
that's a fairly conscious form of memorization on the other hand how do I
recognize your face I have no idea my brain has a whole bunch of specialized
hardware that knows how to recognize faces I don't know how much of that is sort of coded in our DNA and how much of
that is trained over and over between the ages of 0 and 3 but but but somehow
our brains know how to do lots of things like that that are useful in our
interactions with with other humans with without really being conscious of how
it's done anymore right so where are actual d-day lives we're operating at the very highest level of abstraction
we're just not even conscious of all the little details underlying it there's compilers on top of sec Turtles
on top of turtles or Turtles all the way down it's compilers all the way down but that's essentially you see that there's
no magic that's what I what I was trying to get at I think is with decart started
this whole train of saying that there's no magic I mean there's always before well then the cart also have the notion
though that the soul and the body were were fundamentally separate yeah I think
you had to write in God in there for political reasons so I don't actually not historian but there's notions in
there that all of reasoning all of human thought can be formalized I think that
continued in the 20th century with with Russell and with with Gaydos
incompleteness theorem this debate of what what what are the limits of the things that could be formalized that's
where the touring machine came along and this exciting idea I mean underlying a lot of computing that you can do quite a
lot with a computer you can you can encode a lot of the stuff we're talking
about in terms of recognizing faces and so on theoretically in an algorithm they
can then run on a computer and in that context I'd like to ask programming in a
philosophical way so what so what it what does it mean to program a computer
so you said you write a Python program or a compiled a C++ program that
compiles to somebody code it's forming layers your your programming a layer of
abstraction is higher how do you see programming in that context can it keep
getting higher and higher levels of abstraction I think and at some point
the higher level of levels of abstraction will not be called programming and they will not resemble
what we we call programming at the moment there will not be source code I
mean there will still be source code sort of at a lower level of the machine
just like they're still molecules and electrons and and sort of proteins in
our brains but and and so they're still
programming and and and system administration and who knows what's keeping to keep the machine running but
what the machine does is is a different level of abstraction in a sense and as
far as I understand the way that for last decade or more people have made
progress with things like facial recognition or the self-driving cars is all by endless endless amounts of
training data where at least as a
layperson and I feel myself totally as a layperson in that field
it looks like the researchers who
publish the results don't necessarily know exactly how how their algorithms
work and that I often get upset when I sort of read a sort of a fluff piece
about Facebook in the newspaper or social networks and they say well Albert
and that that's like a totally different interpretation of the word algorithm
yeah because for me the way I was trained or what I learned when I was
eight or ten years old an algorithm is a set of rules that you completely
understand that can be mathematically analyzed and and and you can prove things you can like prove that Aires
Dawson E's sieve produces all prime numbers and only prime numbers yes so I
don't know if you know how Andre Carpathia's I'm afraid not so he's a ahead of hey aya Tesla now but
his Stanford before and he has this cheeky way of calling this concept
software 2.0 so let me disentangle that for a second so the so kind of what
you're referring to is the traditional traditional the the algorithm the concept of an algo something that's
there is clear you can read it you understand it you can prove its functioning it's kind of software 1.0
and what software 2.0 is is exactly what you described which is you have neural
networks which is a type of machine learning that you feed a bunch of data and that neural network learns to do a
function all you specifies the inputs and the outputs you want and you can't
look inside you can't analyze it all you can do is train this function to map the
inputs the outputs by giving a lot of data in that sense programming becomes getting a lot of cleaning getting a lot
of data that's what programming is in this well that would be programming 2.0 2.0 to programming 2.0 I I wouldn't call
that programming it's just a different activity just like building organs out
of cells is not called chemistry well so let's just set that back and think sort
of more generally of course but you know it's like as a parent teaching teaching
your kids things can be called programming in that same sense that
that's how program has been used you're providing them data examples use cases
so imagine writing a function not by not
with for loops and clearly readable text but more saying well here's a lot of
examples of what this function should take and here's a lot of examples when
it takes those functions it should do this and then figure out the rest so
that's the 2.0 concept and the this is the question I have for you is like it's
a very fuzzy way this is a reality of a lot of these pattern recognition systems and so on
it's a fuzzy way of quote-unquote programming what do you think about this kind of world it should be called
something totally different than programming it's like if you're a software engineer does that mean you're
you're designing systems that are very can be systematically tested evaluated
they have a very specific specification and then this other fuzzy software 2.0
world machine learning world that's that's something else totally or is there some intermixing that it's
possible well the question is probably
only being asked because we we don't quite know what that software 2.0
actually is and it sort of I think there
is a truism that every task that AI has
has tackled in the past at some point we realized how it was done and then it was
no longer considered part of artificial intelligence because it was no longer
necessary to to use that term it was just oh now he we know how to do this
and a new field of science or
engineering has been developed and I don't know if sort of every form of
learning or sort of controlling computer systems should always be called programming I
said I that I don't know maybe I'm focused too much on the terminology i but i expect that that there just will
be different concepts where people with
sort of different education and a different model of what they're trying
to do will will develop those concepts
yeah and i guess if you could comment and another way to put this concept is i
think i think the kind of functions that neural networks provide is things as
opposed to being able to upfront prove that this should work for all cases you
throw at it all you're able it's the worst case analysis versus average case analysis all you're able to say is it's
it seems on everything we've tested to work 99.9 percent of the time but we
can't guarantee it and it it fails in unexpected ways but can't even give you examples of how it fails in unexpected
ways but it's like really good most of the time yeah but there's no room for
that in current ways we think about programming programming 1.0 is actually
sort of getting to that point to where
the sort of the ideal of a bug-free program has been abandoned long ago by
most software developers we only care about bugs that manifest themselves
often enough to be annoying and we're willing to take the occasional crash or
outage or incorrect result for granted
because we can't possibly we don't have enough programmers to make all the code
bug free and it would be an credibly tedious business and if you try to throw formal methods at it it gets it
becomes even more tedious so every once in a while the user clicks on a link in
and somehow they get an error and the average user doesn't panic they just
click again and see if it works better the second time which often magically it
does or they go up and they try some other way of performing their tasks so
that's sort of an end-to-end recovery mechanism and inside systems there is
all sorts of retries and timeouts and fall backs and I imagine that that sort
of biological systems are even more full of that because otherwise they wouldn't survive do you think programming should
be taught and thought of as exactly what you just said before I come from is kind
of you're almost denying that fact always in the insert of basic
programming education the sort of the
program's you're you're having students right are so small and simple that if
there is a bug you can always find it and fix it because the sort of
programming as it's being taught in some even elementary middle schools in high
school introduction to programming classes in college typically it's
programming in the small very few classes sort of actually teach software
engineering building large systems I mean every summer here at Dropbox we
have a large number of interns every tech company on the west coast has the
same thing these interns are always amazed because this is the first time in
their life that they see what goes on in a really large software development environment
and everything they've learned in
college was almost always about a much smaller scale and somehow the difference
in scale makes a qualitative difference in how you how you do things and how you think
about it if you then take a few steps back in two decades seventies and
eighties when you're first thinking about Python or just that world of programming languages did you ever think
that there would be systems as large as underlying Google Facebook and Dropbox did you when you were thinking about
Python I was actually always caught by surprise by yeah pretty much every stage of
computing so maybe just because uh you
spoken in other interviews but I think the evolution of programming languages are fascinating it's especially because
it leads from my perspective towards greater and greater degrees of intelligence I learned the first programming language
I played with in in Russia was with the turtle logo logo yeah and if you look I
just have a list of programming languages all of which I've known played with a little bit and they're all beautiful in different ways from Fortran
COBOL Lisp Algol 60 basic logo and C as
a few the object-oriented came along in the 60s Simula Pascal small talk all of
that lean all the classics the classics yeah the classic hits write scheme built
that's built on top of Lisp on the database side SQL C++ and all that leads
up to Python Pascal - and that's before Python MATLAB these kind of different
communities different languages so he talked about that world I know that
Python came out of ABC which actually never knew that language I just having
researched this conversation went back to ABC and it looks remarkably it it has a lot of annoying qualities but
underneath those like all caps and so on but underneath that there's elements of
Python that are quite if they're already there that's where I got all the good stuff all the good stuff so but in that world
you're swimming these programming languages were you focused on just the good stuff in your specific circle but
did you have a sense of what what is everyone chasing you said that every programming language is built to scratch
an itch mm-hmm were you aware of all the itches in the
community and if not or if yes I mean what H we trying to scratch with Python
well I'm glad I wasn't aware of all the itches because I would probably not have
been able to do anything I mean if you're trying to solve every problem at
once you saw nothing well yeah that it's it's too overwhelming and so I had a
very very focused problem I wanted a programming language that set somewhere
in between shell scripting and C and now
arguably there is like one is higher level one is lower level and Python is
sort of a language of an intermediate level although it's still pretty much at
the high level and no I was I was thinking about much more about I want a
tool that I can use to be more productive as a programmer in a very
specific environment and I also had given myself a time budget for the
development of the tool and that was sort of about three months for both the
design like thinking through what are all the features of the language syntactically and semantically
and how do i implement the whole pipeline from parsing the source code to
executing it so I think both were the timeline and the goals it seems like
productivity was at the core of it as a goal so like for me in the 90s and the
first decade of the 21st century I was always doing machine learning AI programming for my research was always
in C++ and then and then the other people who are a little more mechanical
engineering Electrical Engineering our MATLAB II they're a little bit more
MATLAB focus those are the world and maybe a little bit Java too but people
who are more interested in and emphasizing the object oriented nature of things so but then in last 10 years
or so especially with a calming of neural networks and these packages are built on Python to interface with with
neural networks I switch to Python and it's just I've noticed a significant
boost that I can't exactly because I don't think about it but I can't exactly put into words why I'm just except much
much more productive just being able to get the job done much much faster so how
do you think whatever that qualitative difference is I don't know if it's quantitative it could be just a feeling
I don't know if I'm actually more productive but how do you think about Layar yeah well that that's right I
think there's elements let me just speak to one aspect that I think those affect that productivity is C++ was I really
enjoyed creating performant code and creating a beautiful structure where
everything that you know this kind of going into this especially with the newer newer standards of templated
programming of just really creating this beautiful formal structure that I found
myself spending most of my time doing that as opposed to get you parsing a file and extracting a few
key words or whatever the task was trying to do so what is it about Python how do you think of productivity in
general as you were designing it now sort of through the decades last three decades what do you think it means to be
a productive programmer and how did you try to design it into the language there
are different tasks and as a programmer it's it's useful to have different tools
available that sort of are suitable for different tasks so I still write C code
I still write shellcode but I write most
of my things in Python why do I still
use those other languages because sometimes the task just demands it and
well I would say most of the time the task actually demands a certain language
because the task is not write a program that solves problem x from scratch but
it's more like fix bug in existing program X or add a small feature to an
existing large program but even if if
you sort of if you're not constrained in your choice of language by context like
that there is still the fact that if you
write it in a certain language then you sort of you you have this balance
between how long does it time does it take you to write the code and how long
does the code run and when you're in
sort of in the face of exploring solutions you often spend much more time
writing the code than running it because every time you've sort of you've run it
you see that the output is not quite what you wanted and you spend some more
time Cody and a language like Python just makes
death iteration much faster because there are fewer details there is a large
library sort of there are fewer details that that you have to get right before
your program compiles and runs there are libraries that do all sorts of stuff for
you so you can sort of very quickly take a bunch of existing components put them
together and get your prototype application running just like when I was
building electronics I was using a breadboard most of the time so I had
this like sprawl out circuit that if you
shook it it would stop working because it was not put together very well but it
functioned and all I wanted was to see that it worked and then move on to the next next schematic or design or add
something to it once you've sort of figured out oh this is the perfect design for my radio or light sensor or
whatever then you can say okay how do we design a PCB for this how do we solder
the components in a small space how do we make it so that it is robust against
say voltage fluctuations or mechanical
disruption I mean I know nothing about that when it comes to designing
electronics but I know a lot about that when it comes to to writing code so the
initial initial steps are efficient fast and there's not much stuff that gets in
the way but you're kind of describing from a like Darwin described the
evolution of species right you're you're observing of what is about true about
Python now if you take step back if the art of if the act of creating languages
is art and you had three months to do it and initial steps and ha so you just
specified a bunch of goals sort of things that you observe about Python perhaps you had those goals but how do
you create the rules the syntactic structure the the features that result
in those so I have in the beginning and I have follow-up questions about through the evolution of Python 2 but in the
very beginning when you're sitting there creating the lexical analyzers or whatever evolution was still a big part
of it because I I sort of I said to
myself I don't want to have to design everything from scratch I'm going to
borrow features from other languages that I like Oh interesting so you basically exactly you first observe what
you like yeah and so that's why if you're 17 years old and you want to sort
of create a programming language you're not going to be very successful at it because you have no experience with
other languages whereas I was in my
let's say mid-30s I had written parsers
before so I had worked on the implementation of ABC I had spent years
debating the design of ABC with its authors its with its designers I had
nothing to do with the design it was designed fully as it was ended up being
implemented when I joined the team but so you borrow ideas and concepts and
very concrete sort of local rules from different languages like the indentation and certain other syntactic features
from ABC but I chose to borrow string literals and how numbers work from C and
various other things so in then if you take that further so yet you've had this
funny sounding but I think surprisingly accurate and or at least practical title
of a benevolent dictator for life for quite you know for last three decades whatever or no not the actual title but
functionally speaking so you had to make decisions design decisions can you maybe
let's take Python - there's a Python releasing Python 3 as an example mm-hmm
it's not backward-compatible - Python - in ways that a lot of people know so
what was that deliberation discussion decision like we have what was the psychology of that experience
do you regret any aspects of how that experiments undergone that else yeah so
it was a group process really it at that point even though I was be DFL in nine a
name and and certainly everybody sort of respected my my position as the creator
and and the current sort of owner of the language design I was looking at
everyone else for feedback sort of Python 300 in some sense was sparked by
other people in the community pointing out oh well there are a few issues that
sort of bite users over and over can we do something about that and for Python
three we took a number of those Python wards as they were called at the time
and we said can we try to sort of make small changes to the language that
address those warts and we had sort of in the past we had always taken
backwards compatibility very seriously and so many Python warts in earlier
versions had already been resolved because they could be resolved while maintaining backwards compatibility or
sort of using a very gradual path of evolution of the language in a certain
area and so we were stuck with a number of warts that were widely recognized as problems not like
road blocks but nevertheless sort of things that some people trip over and
you know that that's always the same thing that that people trip over when
they trip and we could not think of a backwards compatible way of resolving
those issues but it's still an option to not resolve the issues and so yes for
for a long time we had sort of resigned ourselves to well okay the language is not going to be perfect in this way and
that way that way and we sort of certain
of these I mean there are still plenty of things where you can say well that's that particular detail is better in Java
or in R or in Visual Basic or whatever
and we're okay with that because well we can't easily change it it's not too bad
we can do a little bit with user education or we can have a static analyzer or warnings in in the parser or
something but there were things where we thought well these are really problems that are
not going away they are getting worse in the future we should do something about
do something but ultimately there is a decision to be made right yes so was
that the toughest decision in the history of Python yet to make as the benevolent dictator for life or if not
what are there maybe even on a smaller scale what was a decision where you were really torn up about well the toughest
decision was probably to resign all right let's go there hold on a second
then let me just because in the interest of time too because I have a few cool questions for you I let's touch a really
important one because it was quite dramatic and beautiful in certain kinds of ways then in July this year three
months ago you wrote now that pepp 572 is done I don't ever want to have to
fight so hard for a and find that so many people despise my decisions I would like to remove myself
entirely from the decision process I'll still be there for a while as an ordinary core developer and I'll still
be available to mentor people possibly more available but I'm basically giving
myself a permanent vacation for being be DFL yeah but not well in dictator for
life and you all will be on your own it's just this it's a it's almost
Shakespearean I'm not going to appoint a successor so water you're all going to
do create a democracy anarchy a dictatorship a federation so that was a
very dramatic and beautiful set of statements it's almost it's open-ended
nature called the community to create a future for Python this is kind of a beautiful aspect to it well so what end
and dramatic you know what was making that decision like what was on your heart on your mind stepping back now a
few months later we could take you to your Maya thing I'm glad you liked of
writing because it was actually written pretty quickly it was literally something like after
months and months of going around in circles I had finally approved Pet 572
which I had a big hand in its design although it I didn't initiate it
originally I gave it a bunch of nudges
in a direction that would be better for the language so I just asked it's a sink
I oh no the one or no no kept 572 was actually a small feature which is
assignment expressions assignment expressions dad had been taught there was just a lot
of debate where a lot of people claimed that they knew what was pythonic and
what was not pythonic and they knew that this was going to destroy the language this was like a violation
of pythons most fundamental design philosophy and I thought that was all because I was in favor of it
and that I would think I know something about pythons design philosophy so I was really tired and also stressed of that
thing and literally after sort of announcing I was going to accept it a
certain Wednesday evening I had finally send the email it's accepted now let's
just go implement it so I went to bed feeling really relieved that's behind me
and I wake up Thursday morning 7:00 a.m. and I think well that was the last one
that's going to be such such a terrible debate and that's it going to be said
that's the last time that I let myself be so stressed out about a peb decision
I should just resign I've been sort of thinking about retirement for half a
decade I've been joking and sort of mentioning retirement sort of telling
the community some point in the future I'm going to retire don't take that FL
part of my title too literally and I thought okay this is it I'm done I had
the day off I wanted to have a good time with my wife we were going to a little beach town nearby and in he think maybe
15-20 minutes I wrote that thing that you just called Shakespearean yeah the funny thing is I
get so much crap for calling you Shakespearean I didn't even I didn't even realize what
a monumental decision it was because five minutes later I read that's a link
to my message back on Twitter where people were already discussing on
Twitter guido resigned as the BD FL and I had I had posted it on an internal
forum that I thought was only read by core developers so I thought I would at
least have one day before the news would sort of get out the on your own aspect I
had also an element of quite it was quite a powerful element of the
uncertainty that lies ahead but can you also just briefly talk about you know
like for example I play guitar as a hobby for fun and whenever I play people
are super positive so super friendly they're like this is awesome this is great but sometimes I enter as an
outside observer I enter the programming community and there seems to some sometimes be camps on whatever the topic
and and the two camps the two or plus camps are often pretty harsh are
criticizing the opposing camps as an onlooker I may be totally wrong on this
yeah well because like wars are sort of a favorite activity in the programming
community and what is the psychology behind that is is that okay for a healthy community to have is that is
that a productive force ultimately for the evolution of the language well if everybody is betting each other on the
back and never telling the truth yes it
would not be a good thing I think there is a middle ground where sort of being
nasty to each other is not okay but there there is is a middle ground where
there is healthy ongoing criticism and feedback that is very productive and you
you mean at every level you see that I mean someone proposes to fix a very
small issue in a codebase chances are
that some reviewer will sort of respond by saying well actually you can do it
better the other way right when it comes to
deciding on the future of the Python core developer community we now have I
think five or six competing proposals for a constitution so that future do you
have a fear of that future do you have a hope for that future I'm not very confident about that future it by and
large I think that the debate has been very healthy and productive and I
actually when when I wrote that resignation email I knew that that
Python was in a very good spot and that the Python core development community that the group of fifty or a hundred
people who sort of write or review most
of the code that goes into Python those people get along very well most of the
time a large number of different areas of expertise are represented different
levels of experience in the Python core deaf community different levels of
experience completely outside in software development in general large
systems small systems embedded systems so I I felt okay resigning because I
knew that that the community can really take care of itself and out of a grab
bag of future future developments let me ask if you can comment maybe on all very
quickly concurrent programming parallel computing async IL these are things that
people have expressed hope complained about whatever have discussed on reddit
async i also the parallelization in general packaging i was totally clueless
on this I just used piston install stuff but apparently this paper and in poetry there's these dependency packaging
systems that manage dependencies and so on there urging and there's a lot of confusion about what's what's the right thing to
use then also functional programming the the ever you know the the are we're
going to get more functional programming or not this kind of this kind of idea and of course the the gill is a
connected to the parallelization I suppose the global interpreter lock problem can you just comment on
whichever you want to comment on well let's take the gill and paralyzation and
async io as one one topic I'm not that
hopeful that Python will develop into a
sort of high concurrency high parallelism language that's sort of the
the way the language is designed the way most users use the language the way the
language is implemented all make that a pretty unlikely future so you think it
might not even need to really the way people use it it might not be a something that should be a of Greek I
think I think async IO is a special case because it sort of allows overlapping IO
and only IO and that is is a sort of best practice
of supporting very high throughput IO many collections per second I'm not
worried about that I think async IO will evolve there are a couple of competing packages we have some very smart people
who are sort of pushing us in sort of to make async IL better parallel computing
I think that Python is not the language for that there are there are ways to
work around it but you sort of you can't expect to write an algorithm in Python
and have a compiler or paralyzed that what you can do is use a
package like numpy and they're a bunch of other very powerful packages that
sort of use all the CPUs available because you tell the package here's the
data here's the abstract operation to apply over it go at it and then then
we're back in the c++ world but those packages are themselves implemented
usually in c++ that's right that's so that's where Tenzin phoned all these acts just come in where they paralyze across GPUs for example they take care
of that fit so in terms of packaging can you comment on this yeah my it packaging
has always been my least favorite topic it's it's it's a really tough problem
because the OS and the platform want to
own packaging but their packaging
solution is not specific to a language like if you take Linux there are two
competing packaging solutions for Linux or for UNIX in in general and but they
all work across all languages and several languages like node JavaScript
and Ruby and Python all have their own packaging solutions that only work
within the ecosystem of that language well what should you use that is a tough
problem my own own approach is I use the system packaging system to install
Python and I use the Python packaging system then to install third party
Python packages that's what most people do ten years ago Python packaging was
really a terrible situation nowadays pip is the future there is there is a
separate ecosystem for numerical and scientific Python Python based on
anaconda those two can live together I don't think there is a need for more
than that great so that's that's packaging that's well at least for me that's that's where I've been extremely
happy I didn't I didn't even know this was an issue until it's brought up well in interest of time I mean sort of
skipped through a million other questions I have so I watched the five hour five five and a half hour oral
history they've done with the Computer History Museum and the nice thing about it it gave this because of the linear
progression of the interview he gave this feeling of a life you know a life well-lived with interesting things in it
sort of a pretty I would say a good spend of of this little existence we
have on earth so outside of your family looking back what about this journey are
you really proud of their moments that
stand out accomplishments ideas is it the creation of Python itself that
stands out as a thing that you look back and say damn I did pretty good there
well I would say that Python is definitely the best thing I've ever done and I
I wouldn't sort of say just the creation of Python but the way I sort of raised
by farm like a baby I didn't just conceive a child but I
raised the child and now I'm setting the child free in the world and I've set up
the child to to sort of be able to take care of himself and I'm very proud of
that and as the announcer of Monty Python's Flying Circus used to say and
now for something completely different do you have a favorite Monty Python moment or a moment Hitchhiker's Guide or
any other literature show a movie that cracks you up when you think about it oh you can always play me the parrots the
dead parrot sketch oh that's brilliant yeah that's my favorite as well pushing up the daisies
okay greeted thank you so much for talking with me today lecture there's
been a great conversation
you

----------

-----

--46--

-----
Date: 2018.11.16
Link: [# Vladimir Vapnik: Statistical Learning | Lex Fridman Podcast #5](https://www.youtube.com/watch?v=STFcvzoxVw4)
Transcription:


Introduction
The following is a conversation with Vladimir Vapnik. He is the co-inventor of support vector machines, support vector clustering, VC theory, and
many foundational ideas in statistical learning. He was born in the Soviet Union and worked at the Institute of Control Sciences in Moscow.
Then in the United States, he worked at AT&T, NEC Labs, Facebook Research, and now
is a professor at Columbia University. His work has been cited over 170,000 times.
He has some very interesting ideas about artificial intelligence and the nature of learning, especially especially, on the limits of our current approaches and the open problems in the field.
This conversation is part of the MIT course on Artificial General Intelligence and the Artificial Intelligence Podcast.
If you enjoy it, please subscribe on YouTube or rate it on iTunes or your podcast provider of choice
or simply connect with me on Twitter or other social networks at Lex Fridman,
spelled F-R-I-D. And now, here's my conversation with Vladimir Vapnik.
God doesnt play dice
Lex: Einstein famously said that God doesn't play dice. Vladimir: Yeah.
Lex: You have studied the world through the eyes of statistics, so let me ask you in terms of the nature of reality--fundamental nature of reality.
Does God play dice? Vladimir: We don't know some factors.
And because we don't know some factors, which could be important, it looks like God plays dice,
but you should describe. In philosophy, they distinguish between two positions: positions of instrumentalism,
where you're creating theories of prediction and position of realism, where you're trying to
understand what God did. Lex: Can you describe instrumentalism and realism a little bit?
For example, if you have some mechanical laws,
what is that? Is it law which is true always and everywhere
or is it a law which allows you to predict a position of moving elements?
What do you believe? Do you believe that it is God's law, that God created the world which is this
physical law, or is it just law for predictions? Lex: And which one is instrumentalism?
For predictions. If you believe that this is the law of God and it is always true everywhere,
that means that you're a realist. You're trying to understand God's thought.
Lex: So the way you see the world is as an instrumentalist? Vladimir: You know I'm working from some models--
Models of Machine Learning. So in this model, you can see settings
and you try to resolve the problem.
And you can do it in two different ways from the point of view of the instrumentalist,
and that's what everybody does now because the goal of machine learning
is to find the rule for classification.
That is true, but it is an instrument for prediction. But I can say, the goal of machine learning is to learn about conditional probability,
so how God play and use. Does he play what is the probability for one and what is the probability for another
in a given situation? But for prediction, I don't need this. I need the rule.
But for understanding, I need conditional probability. Lex: So let me just step back a little bit first to talk about, you mentioned which I read
Is math a poetry
last night the parts of the 1960 paper by Eugene Wigner,
Unreasonable Effectiveness of Mathematics in the Natural Sciences. It's such a beautiful paper, by the way.
To be honest, to confess my own work in the past two years on deep learning heavily applied,
it made me feel that I was missing out on some of the beauty of nature in the way that
math can uncover. So let me just step away from the poetry of that for a second.
How do you see the role of math in your life? Is it a tool? Is it poetry?
Where does it sit? And does math, for you, have limits?
Vladimir: Some people are saying that Math is language which use god.
Lex: Speak to god or use god? - Use God. Lex: Use God
Vladimir: I believe that this article
about Unreasonable Effectiveness of Math is that if you look
at mathematical structures, they know something about reality.
And most scientists from Natural Science, they look at an equation
in trying to understand reality, so the same with machine learning.
If you try to very carefully look on all the equations which define conditional probability,
you can understand something about reality more than from your fantasy.
Lex: So math can reveal the simple underlying principles of reality, perhaps.
Vladimir: You know, what may seem simple, it is very hard to discover them.
But then, when you discover them and look at them, you see how beautiful they are.
And it is surprising why people did not see that before when you look at an equation and
derive it from the equations. For example, I talked yesterday about the Least Squares Method and people had a lot
of fantasies about improving least squares method. But if you look, going step by step by solving some equations, you suddenly will get some terms
which after thinking; you understand it, the described position of an observation point.
Least squares method, they throw out a lot of information. You don't look at the composition of point of observations.
We're looking only on the details. But, when you understood that very simple idea, which is not too simple to understand
and you can derive this just from equations. Lex: So some simple Algebra, so a few steps will take you to something surprising that when
Human intuition
you think about-- Vladimir: Absolutely, yes. And that is proof that human intuition is not too rich
and very primitive, and it does not see very simple situations.
Lex: So let me take a step back, in general, yes.
What about human ingenuity as opposed to intuition, the moments of brilliance?
Do you have to be so hard on human intuition? Are there moments of brilliance on human intuition that can leap ahead of math,
and then the math will catch up? Vladimir: I don't think so. I think the best human intuition, it is putting in axioms, then it is technical
where you have to arrive. Lex: See where the axioms take you. Vladimir: Yeah. But if they correctly take axioms.
Axioms are polished during generations of scientists and this is integral wisdom.
The role of imagination
Lex: That's beautifully put.
When you think of Einstein and especially, relativity, what is the role of imagination
coming first there in the moment of discovery of an idea?
So, that's obviously a mix of math and out of the box imagination there.
Vladimir: That, I don't know. Whatever I did, I exclude any imagination because whatever I saw in machine learning
that come from imagination, like features, like deep learning, they're not really one
to the problem. When you're looking very clearly from a mathematical equation, you'd arrive in very simple story
which goes far beyond, theoretically, than whatever people can imagine because it is
not good fantasies. It is just interpretation. It is just fantasy, but it is not what you need.
You don't need any imagination to derive mind principle of machine learning.
The role of interpretation
Lex: When you think about learning and intelligence, maybe thinking about the human brain in trying
to describe mathematically the process of learning that is something like what happens
in the human brain, do you think we have the tools, currently?
Do you think we will ever have the tools to try to describe that process of learning?
Vladimir: It is not description what's going on. It is interpretation. It is your interpretation.
Your vision can be wrong. You know, when the guy who invented the microscope, Leeuwenhoek, for the first time,
only he got this instrument and he kept it secret.
But he wrote a report in the London Academy of Science. In his report, when he's looking on the blood, he looked everywhere--on the water, on the
blood on those film, but he described blood like a fight between queens and kings.
So he saw blood cells, red cells and he imagines it is like an army fighting each other.
And it was his interpretation of the situation. And he sent it as a report in the Academy of Science.
They very carefully looked because they believe that he is right. He saw something, but he gave a wrong interpretation.
And I believe the same can happen with the brain.
The most important part, you know, I believe in human language.
In some proverbs, there's so much wisdom. For example, people say that it is better than a thousand days of diligent study
is one day with a great teacher. But if you'll ask what the teacher does, nobody knows.
And that is intelligence. But we know from history, and now from machine learning
is that a teacher can do a lot. Lex: So what from a mathematical point of view is a great teacher?
Vladimir: I don't know, but we can say what a teacher can do.
He can introduce some invariants, some predicate for creating invariants.
How is he doing it, I don't know, because a teacher knows reality and can describe from
his reality a predicate and invariants. But we know when you're using invariant, you can decrease the number of observations
a hundred times. Lex: Maybe try to pull that apart a little bit, but I think you mentioned that like a piano
The nature of information
teacher saying to the student, "Play like a butterfly." I played piano.
I played the guitar for a long time
and maybe it's romantic and poetic, but it feels like there's a lot of truth in that statement, like there's a lot of instruction to that statement.
Can you pull that apart? What is that? The language itself may not contain this information.
Vladimir: It's not blah, blah, blah because it affects you. It's what? Affects you, affects your playing.
Lex: Yes it does,
but what is the information being exchanged there? What is the nature of information? What is the representation in that information?
Vladimir: I believe that it is a sort of predicate, but I don't know. That is exactly what intelligence in machine learning should be
because the rest is just mathematical technique. I think that what was discovered recently is that there are two mechanisms of learning.
One is called strong convergence mechanism and big convergence mechanism.
Before, people used only one convergence. In big convergence, you can use predicate.
That's what "fly like butterfly" is and if you immediately effect your plan.
You know there is an English proverb which is "If it looks like a duck, sleeps like a duck,
and quack like a duck, then it is probably a duck." But this is exact about predicate.
It looks like a duck, what does it mean? So, you saw many ducks--that's your training data.
You have a description that looks like ducks.
Lex: Yeah, the visual characteristics of a duck, yeah. Vladimir: Yeah, and you have a model for recognizing ducks.
So you would like that theoretical description from the model to coincide.
There's empirical description which you saw. So, about "it looks like a duck," it is general.
But, what about swims like a duck? You should know that ducks swim.
You can't say it plays chess like a duck. Okay, ducks doesn't play chess.
It's a completely legal predicate but it is useless.
So, how can a teacher recognize a non-useless predicate?
So, up to now, we don't use this predicate in existing machine learning,
so why do we need zillions of data? But this English proverb say use only three predicates--looks like a duck,
swims like a duck and quack like a duck. Lex: So you can't deny the fact that swims like a duck and quacks like a duck has humor
The English proverb
in it, has ambiguity? Vladimir: Let's talk about "swims like a duck."
It does not say jumps like a duck, why? Lex: It's not relevant.
Vladimir: It means that you know ducks and you know different birds.
You know animals and you derived from this that it is relevant to say "swim like a duck."
Lex: So in order for us to understand "swims like a duck," it feels like we need to know millions of other little pieces of information we pick up along the way.
You don't think so? That doesn't need to be this knowledge-based, in those statements, carry some rich information
that helps us understand the essence of duck? Vladimir: Yeah. Lex: How far are we from integrating predicates?
Vladimir: You know that when you can see the complete story of machine learning, so what it does,
you have a lot of functions, and then you're talking it looks like a duck.
You see your training data. From the training data, you recognize what the expected duck should look like.
Then, you remove all functions which do not look like what you think it should look from
the training data. So, you decrease the amount of function from which you pick up one.
Then, you give a second predicate and again, they create a set of functions.
And after that, you pick up the best function you can. It is standard machine learning.
So, why do you need not too many examples?
Lex: Because your predicates are very good. Vladimir: Yeah, that's exactly basic predicate because every predicate is invented to decrease the
admissible set of functions. Lex: So you talk about admissible set of functions and you talk about good functions.
A admissible set of functions
So what makes a good function? Vladimir: So admissible set of function is a set of function which has a small capacity or small
diversity, a small dimension, which contains good functions inside.
Lex: By the way, for people who don't know VC, you're the V in the VC.
So how would you describe to a lay person what VC theories are?
How would you describe VC? Vladimir: When you have a machine, a machine capable to pick up one function
from the admissible set of function. But the set of admissible functions can be big.
They contain all continuous functions and theories. You don't have so many examples to pick up functions.
But it can be small--
what we call capacity, but maybe diversity-- so not very different functions in the settings,
an infinite set of functions but not very diverse. So, if it's a small VC dimension and when the VC dimension is small,
you need a small amount of training data.
So the goal is to create admissible set of functions which have small VC dimension
and contains good functions. Then, you'll be able to pick up the function using a small amount of observations.
The task of learning
Lex: So that is the task of learning is creating a set of admissible functions
that has a small VC dimension and then you figure out a clever way of picking up the good.
Vladimir: That is the goal of learning which I formulated yesterday. Statistical learning theory does not involve creating admissible set of functions.
In classical learning theory everywhere, in 100% of textbooks, the admissible set of functions
is given, but this is telling us about nothing because the most difficult problem is to create
admissible set of functions given, say,
a lot of functions, a continuous set of functions. Create admissible set of functions, that means that the finite VC dimension, small VC dimension
and contains good functions. So, this was out of consideration. Lex: So what's the process of doing that, I mean, that's fascinating?
The process of learning
What is the process of creating this admissible set of functions?
Vladimir: That is invariance. Lex: That's invariance. Can you describe invariance? Vladimir: Yeah. You have to think of properties of the training data and properties means they have some function
and you just count what is the average value of function of training data.
You have a model and what is the expectation of this function on the model
and they should coincide. So, the problem is about how to pick up functions.
It can be any function. In fact, it is true for all functions,
but when I say a duck doesn't jump, so you don't
ask a question on "jumps like a duck" because it is trivial. It does not jump, so it does not help you at all.
But you know something on which questions to ask like when you ask "swims like a duck."
But "looks like a duck," it is a general situation. But, looks like, say, a guy who has this illness, this disease, it is legal.
So, there is a general type of predicate, "It looks like," and a special type of predicate
which is related to this specific problem. And that is the intelligence part of this business and that is where a teacher is involved.
Deep learning as neural networks
Lex: Incorporating the specialized predicates. Vladimir: Yes. Lex: Okay.
What do you think about deep learning as neural networks, these architectures,
as helping accomplish some of the tasks you're thinking about? Their effectiveness or lack thereof,
what are the weaknesses and what are the possible strengths? Vladimir: You know, I think that this is fantasy, everything like deep learning, like features.
Let me give you this example. One of the greatest books is Churchill's book about the history of the Second World War.
He starts in his book describing that in the old times when a war is over,
the great kings, they gather together--and most of them are relatives--and they discuss what should be
done to create peace and they come to an agreement. And what happens in the First World War?
The general public came in power. They were so greedy that robbed Germany.
It was clear for everybody that it is not peace, that peace will only last for 20 years
because they were not professionals. I see the same in machine logic.
There are mathematicians looking for the problem from a very deep mathematical point of view
and there are computer scientists that mostly do not know mathematics.
They just have interpretations of that and they invented a lot of blah, blah interpretations
like deep learning. Why did you do deep learning? Mathematics does not know deep learning.
Mathematics does not know neurons; it is just functions. If you like to say piecewise linear function, say that
and do it in a class of piecewise linear function. But they invented something and then they tried to prove the advantage of that
through interpretations, which was mostly wrong. And when it is not enough, they appeal to the brain and they say they know nothing about that.
Nobody knows what's going in the brain. So, I think it is more reliable to work on math.
This is a mathematical problem, do your best to solve this problem. Try to understand that there is not only one way of convergence,
which is the strong way of convergence. There is a big way of convergence which requires predicates.
And if you will go through all this stuff, you will see that you don't need deep learning.
Even more, I would say one of the theorems, which is called Representer theorem,
it says that optimal solution of mathematical problems,
which describe learning, is on a shallow network,
not on deep learning. Lex: On a shallow network. Yeah, the problem is there. Absolutely. So, in the end, what you're saying is exactly right.
The question is, you have no value for throwing something on the table, playing with it--not math.
It's like a neural network where you said throwing something in the bucket or the biological
example in looking at kings and queens or the cells on the microscope, you don't see value in imagining the cells or the kings and queens and using that as inspiration,
an imagination for where the math will eventually lead you? Do you think that interpretation basically deceives you in a way that's not productive?
Vladimir: I think that if you're trying to analyze this business of learning
and especially, the discussion about deep learning, it is a discussion about interpretations and not about things,
about what you can say about things. Lex: That's right. But, aren't you surprised by the beauty of it, not mathematical beauty but the fact
The beauty of deep learning
that it works at all? Or, are you criticizing that very beauty, our human desire to interpret,
to find our silly interpretations in these constructs?
Like, let me ask you this, are you surprised or does it inspire you, how do you feel about
the success of a system like AlphaGo at beating the game of Go
using neural networks to estimate the quality of a board?
Vladimir: That is your interpretation--quality of the board. Lex: Yes.
It is not our interpretation. The fact is a neural network system--it doesn't matter--a learning system
that we don't, I think, mathematically, understand that well, beats the best human player, that's something that was thought impossible.
Vladimir: That means it's not a very difficult problem. That's it. Lex: So we've empirically have discovered that this is not a very difficult problem.
That's true. I can't argue.
Vladimir: Even more, I would say, if they used deep learning, it is not the most effective way
of learning theory. And usually, when people use deep learning, they're using zillions of training data,
but you don't need this. So when I describe a challenge, can we do some problems that you did well
with deep learning method, with deepnet, using a hundred times less training data?
Even more, there are some problems that deep learning cannot solve because it's not necessarily
that they created admissible set of functions. To create deep architecture means to create admissible set of functions.
You cannot say that you're creating good admissible set of functions. It's your fantasy.
It does not come from us. But, it is possible to create admissible set of functions because you have your training data
Actually, for mathematicians, when you consider a variant,
you need to use the law of large numbers. When you make a training in existing algorithms, you need a uniform law of large numbers,
which is much more difficult. It requires VC dimension and all that stuff. But nevertheless, if you use both big and strong way of convergence, you can decrease
a lot of training data. Lex: Yeah, you could do the three--that swims like a duck and quacks like a duck.
Can machines think
So let's step back and think about human intelligence in general.
And clearly, that has evolved in a non-mathematical way.
Lex: As far as we know, God or whoever didn't come up with a model and placed in our brain
of admissible functions; it kind of evolved. I don't know your view on this but Alan Turing in the 50's in his paper asked and interjected
the question: Can machines think? It's not a very useful question, but can you briefly entertain this useless question
"Can machines think?" So, talk about intelligence and your view of it. Vladimir: I don't know that.
I know that Turing described imitation--if a computer can imitate a human being.
Let's call it intelligence and he understands that it is not a thinking computer.
He completely understands what he was doing, but he set up a problem of imitation.
So now we understand it as a problem of not an imitation. I'm not sure that intelligence is just inside of us.
It may also be outside of us. I have several observations,
so when I prove some theorems, it's very difficult theorems.
In a couple of years, in several places, people will prove the same theorem, say,
saw a dilemma after ours was done, then another guy proves the same theorem.
In the history of science, it has happened all the time. For example, geometry, it happens simultaneously.
First is Lobachevsky and then Gauss and Bolyai and then other guys, and approximately,
in a ten-year period of time, and I saw a lot of examples like that.
And when a mathematician thinks it, when they develop something, they develop something
in general which affects everybody. So, maybe our model of intelligence is only inside of us is incorrect.
Complexity
Lex: It's our interpretation. Yeah. Vladimir: It may be that they exist with some connection with world intelligence.
I don't know that. Lex: You're almost like plugging in into... Vladimir: Yeah, exactly. Lex: ...and contributing to this.
Vladimir: ...into a big network. Lex: Into a big, maybe a neural network.
On the flip side of that, maybe you can comment on the big O complexity and how you see classifying
algorithms by worst-case running time in relation to their input. So, that way of thinking about functions, do you think P equals un-P?
Do you think that's an interesting question? Vladimir: Yeah, it is an interesting question. But let me talk about complexity and about worst-case scenario.
There is a mathematical setting. When I came to the United States in 1991, people did not know this.
They did not know statistical learning theorem. In Russia, it was published in our monographs, but in America, they did not know,
and then, they learned it. Somebody told me that it was worst-case theory and they will create real-case theory,
but until now, they haven't. Because it is a mathematical tool, you can do only what you can do using mathematics,
which is clear understanding and clear description.
For this reason, we introduced complexity.
In VC dimension you can prove some theorems. But we also create theory for cases when you know probability measure
and that is the best case it can happen.
So from a mathematical point of view, you know the best possible case is the worst possible case.
You can derive different models in the middle, but it's not so interesting.
Lex: Do you think the edges are interesting? Vladimir: The edges are interesting because it is not so easy to get the exact bounds.
It's not, in many cases where you have the bounds are not exact, but interesting principles
are discovered the most. Lex: Do you think it's interesting because it's challenging and reveals interesting principles
Edges
that allow you to get those bounds or do you think it's interesting because it's actually very useful for understanding the essence of a function of an algorithm?
So, it's like me judging your life as a human being by the worst thing you did and the best
thing you did versus all the stuff in the middle. It seems not productive.
Vladimir: I don't think so because you cannot describe situations in the middle or it will not be general.
So you can describe edge cases and it is clear it has some models, but you cannot describe
a model for every new case. So, you'll never be accurate when you're using models.
Learning in the world
Lex: But, from a statistical point of view, the way you studied functions and the nature of learning and the world,
don't you think that the real world has a very long tail
that the edge cases are very far away from the mean,
the stuff in the middle, or no?
Vladimir: I don't know that. I think that from my point of view,
if youwill use formal statistics, you need uniform law of large numbers,
if you will use this invariance business,
you don't need just law of large numbers. And there's a huge difference between uniform law of large numbers and large numbers.
Lex: Is it useful to describe that a little more or shall we just take it at... Vladimir: No. For example, when I'm talking about ducks, I get three predicates and that was enough.
But, if you will try to do formally distinguish, you will need a lot of observations.
So that means that information about "looks like a duck" contained a lot of bit of information
formal bits of information. So we don't know how much bit of information is contained from intelligence
and that is a subject of analysis. Until now,
on business, I don't have people consider artificial intelligence.
They consider it as some codes which imitate activities of human beings.
It is not science. It is applications. You would like to imitate Go. Okay, it's very useful and a good problem,
but you need to learn something more
on how people came to develop, say,
predicates "sleeps like a duck" or "fly like a butterfly"
or something like that. It's not that the teacher tells you how it came to his mind, how he chooses the image.
That is a problem of intelligence. Lex: That is the problem of intelligence. And you see that connected to the problem of learning?
Learning absolute
Are they? Vladimir: Absolutely, because you immediately give this predicate like specific predicates
"swims like a duck" or "quacks like a duck." It was chosen somehow.
Line of work
Lex: So what is the line of work, would you say, if you were to formulate as a set of open problems
that will take us there, to fly like a butterfly, we'll get a system to be able to?
Vladimir: Let's separate two stories--one mathematical story that if you have predicates
you can do something, and another story on how to get predicates.
It is an intelligence problem and people even did not start understanding intelligence.
Because to understand intelligence, first of all, try to understand what they will teach us,
how a teacher teach, why one teacher is better than another one. Lex: Yeah. And so, do you think we really even haven't started on the journey of generating the predicates?
Open problem
Vladimir: No. We don't understand. We even don't understand that this problem exists.
Lex: You do. Vladimir: No. I just know a name. I won't understand why one teacher is better than another
and how the teacher affects the student.
It is not because he is repeating the problem which is in the textbooks.
He makes some remarks. He makes some philosophy of reasoning.
Lex: Yeah, that's beautiful. It is a formulation of a question that is the open problem:
Why is one teacher better than another? Vladimir: Right. What he does about it.
Lex: "Why" at every level. How did they get better?
What does it mean to be better? Vladimir: Yeah. From whatever model I have,
one teacher can give a very good predicate. One teacher can say "swims like a duck" and another can say "jumps like a duck."
And jumps like a duck carries zero information.
Lex: So what is the most exciting problem in statistical learning you ever worked on or are working on now?
Vladimir: I just finished this invariance story
and I'm happy that I believe that it is an ultimate learning story.
At least, I can show that there are no other mechanisms. There are only two mechanisms but they separate statistical parts from intelligence parts
and I know nothing about the intelligence part. And if you will know there's the intelligence part, it will help us a lot in teaching
and in learning. Lex: And we'll know it when we see it?
So for example, in my talk, in the last slide was a challenge. So you have a NIST digit recognition problem
and deep learning claims that they did it very well say 99.5% correct answers,
but they used 60,000 observations. Can you do the same using a hundred times less but incorporating invariants,
what it means, you know, digit 1, 2, 3? Just looking on that, explain the vision variant I should keep, to use a hundred times less
examples, to do the same job. Lex: Yeah, that last slide, unfortunately, your talk ended quickly, but that last slide was
Invariance
a powerful open challenge and a formulation of the essence there.
Vladimir: That is the exact problem of intelligence because everybody, when machine learning started
and it was developed by mathematicians, they immediately recognized that they use much
more training data than humans needed. But now, again, we came to the same story of how to decrease.
That is a problem of learning. It is not like in deep learning, they use zillions of training data
because maybe zillions are not enough if you have a good invariance.
Maybe, you'll never collect some number of observations. But now, it is a question of intelligence on how to do that
because the statistical part is ready. As soon as you supply us this predicate, we can do a good job
with the small amount of observations and the very first challenges of a long digital cognition and you know digits
and 12 invariants. I'm thinking about that and I can say for digit 3, I would introduce the concept
of horizontal symmetry, so digit 3 has horizontal symmetry more than digit 2 or something like that.
But as soon as I get the horizontal symmetry, I can mathematically invent a lot of measure
of horizontal symmetry or the vertical symmetry or the diagonal symmetry, whatever,
if I have the ideal symmetry. What would it tell us?
Looking on digits, I see that it is a meta-predicate which is not shaped into something like symmetry,
like how dark is the whole picture, something like that,
which can certify as a predicate. Lex: Do you think such a predicate could rise out of something that's not general,
The problem of intelligence
meaning, it feels like for me to be able to understand the difference between the two and the three,
I would need to have had a childhood of 10 to 15 years playing with kids, going to school,
being yelled at by parents, all of that, walking, jumping, looking at ducks.
And now, then, I would be able to generate the right predicate for telling the difference
between a two and a three, or do you think there's a more efficient way? Vladimir:I don't know.
I know for sure that you must know something more than digits.
Lex: Yes, and that's a powerful statement. Vladimir: Yeah, but maybe there are several languages of description around these elements of digits.
So, I'm talking about symmetry, about some properties of geometry.
I'm talking about something abstract. I don't know about that, but it is a problem of intelligence.
So in one of our articles, it is trivial to show that every example can carry not more
than one bit of information because when you show an example and you say, this is a one,
you can remove functions which doesn't tell you one.
The best strategy if you can do it perfectly is to remove half of that.
But when you use one predicate which is "looks like a duck," you can remove
much more functions in half, and that means it contains a lot of bit of information from a formal point of view.
But, when you have a general picture,
on whatyou want to recognize and a general picture of the world, can you invent this predicate?
And, that predicate carries a lot of information.
Lex: Beautifully put. Maybe it's just me, but in all the math you show in your work, which is some of the most
Poetry and music
profound mathematical work in the field of learning AI and just math, in general,
I hear a lot of poetry and philosophy. You really kind of talk about philosophy of science.
There's a poetry in music to a lot of the work you're doing and the way you're thinking about it, so where does that come from?
Do you escape to poetry? Do you escape to music? Vladimir: I think that there exists ground truths
and that can be seen everywhere. The smart guy philosopher, sometimes I'm surprised how they see deeply.
Sometimes I see that some of them are completely out of subject.
But the ground truths, I see in music.
Lex: Music are the ground truth? Vladimir: Yeah. And in poetry, many poetry, they believe that they take dictation.
Lex: So what piece of music as a piece of empirical evidence gave you a sense that they are touching
something in the ground truth? Vladimir: It is structure. Lex: The structure, the math of music.
Vladimir: Because when you're listening to Bach, you see the structure--very clear, very classic,
very simple. And the same it was when you have axioms in geometry, you have the same feeling.
And in poetry, sometimes, this is the same. Lex: Yeah. And if you look back to your childhood, you grew up in Russia.
Happiest moments
You maybe were born as a researcher in Russia, you developed as a researcher in Russia.
You came to the United States and a few places. If you look back, what were some of your happiest moments as a research?
Some of the most profound moments, not in terms of their impact on society,
but in terms of their impact on how damn good
you feel that day and you remember that moment? Vladimir: You know, every time when you found something,
it is the greatest moments in life, every simple thing.
But, my general feelings most of the time was wrong.
You should go again and again and again and try to be honest in front of yourself,
not to my interpretation, but try to understand that it is related to ground rules
and it is not my blah, blah, blah interpretation or something like that.
The possibility of discovery
Lex: But, you're allowed to get excited at the possibility of discovery. Vladimir: Oh, yeah.
Lex: You have to double check it. Vladimir: No, but how it's relates to the ground rules.
Is it just temporary or is it forever?
You know, you always have a feeling when you found something.
How big is that? So 20 years ago, when we discovered statistical learning theory, nobody believed
except for one guy, Dudley from MIT.
And then, in 20 years, it became in fashion, and the same with Support Vector Machines.
Lex: So, with support vector machines and learning theory, when you were working on it,
you had a sense, a sense of the profundity of it, how this seems to be right, this seems to be powerful?
Vladimir: Right. Absolutely. Immediately. I recognized that it will last forever.
And now, when I found this invariant story,
I have a feeling that this is complete learning because I have proved that there are no different mechanisms.
You can have some cosmetic improvements that you can do, but in terms of invariants,
you need more invariants in statistical learning organization work together.
But, also, I'm happy that you can formulate what is intelligence from that
and to separate from the technical point. That is completely different.
Lex: Absolutely. Well, Vladimir, thank you so much for talking today. Vladimir: Thank you. Lex: It's an honor.

----------

-----
--45--

-----
Date: 2018.10.20
Link: [# Yoshua Bengio: Deep Learning | Lex Fridman Podcast #4](https://www.youtube.com/watch?v=azOmzumh0vQ)
Transcription:

what difference between biological neural networks and artificial neural networks is most mysterious captivating
and profound for you first of all there's so much we don't know about
biological neural networks and that's very mysterious and captivating because maybe it holds the key to improving our
differential neural networks one of the things I studied recently something that
we don't know how biological neural networks do but would be really useful for artificial ones is the ability to do
credit assignment through very long time spans there are things that we can in
principle do with artificial neural nets but it's not very convenient and it's not biologically plausible and this
mismatch I think this kind of mismatch may be an interesting thing to study to
a understand better how brains might do these things because we don't have good corresponding theories with artificial
neural Nets and B maybe provide new ideas that we could explore about things
that brain do differently and that we could incorporate in artificial neural Nets so let's break created assignment
up a little bit yeah what it's a beautifully technical term but it could incorporate so many things so is it more
on the RNN memory side that thinking like that or is it something about
knowledge building up common sense knowledge over time or is it more in the
reinforcement learning sense that you're picking up rewards over time for a particular to achieve certain kind of
goals so I was thinking more about the first two meanings whereby we store all
kinds of memories episodic memories in our brain which we can access later in
order to help us both infer causes of
things that we are observing now and assign credit to decisions or
interpretations we came up with a while ago when you know those memories were stored and then we can change the way we
would have reacted or interpreted things in the past and now that's credit
assignment used for learning so in which way do you think artificial neural
networks the current LS TM the current architectures are not able to capture
the presumably you're thinking of very long term yes so current recurrent Nets
are doing a fairly good jobs for sequences with dozens or say hundreds of
time stamps and then it gets harder and harder and depending on what you have to
remember and so on as you consider longer durations whereas humans seem to
be able to do credit assignment through essentially arbitrary times like I could remember something I did last year and
then now because I see some new evidence I'm gonna change my mind about the way I
was thinking last year and hopefully not do the same mistake again I think a big
part of that is probably forgetting you're only remembering the really important things it's very efficient
forgetting yes so there's a selection of what we remember and I think there are
Current state of deep learning
really cool connection to higher-level cognition here regarding consciousness
deciding and and emotions like sort of deciding what comes to consciousness and what gets stored in memory which which
are not trivial either so you've been at the forefront there all along showing
some of the amazing things that neural networks deep neural networks can do in the field of artificial intelligence is
just broadly in all kinds of applications but we can talk about that forever but what in your view because
we're thinking towards the future is the weakest aspect of the way deep neural networks represent the world what is
that what is in your view is missing so currently current state-of-the-art
neural nets trained on large quantities of images or texts have some level of
understanding of you know what explains those datasets but it's very basic it's
it's very low-level and it's not nearly as robust and abstract in general as our
understanding okay so that doesn't tell us how to fix things but I think it
encourages us to think about how we can
maybe train our neural nets differently so that they would focus for example on
causal explanations something that we don't do currently with neural net
training also one thing I'll talk about in my talk this afternoon is instead of
learning separately from images and videos on one hand and from text on the
other hand we need to do a better job of jointly learning about language and
about the world to which it refers so that you know both sides can help each
other we need to have good world models in our neural nets for them to really
understand sentences which talk about what's going on in the world and I think we need language input to help provide
clues about what high-level concepts like semantic concepts should be
represented at the top levels of these neural nets in fact there is evidence
that the purely unsupervised learning of representations doesn't give rise to
high level representations that are as powerful as the ones we are getting from
supervised learning and so the the clues we're getting just with the labels not even sentences is
already very powerful do you think that's an architecture challenge or is
Architecture vs dataset
it a data set challenge neither I'm
tempted to just end it there in your library of course data sets and
architectures are something you want to always play with but but I think the crucial thing is more the training
objectives the training frameworks for example going from passive observation
of data to more active agents which
learn by intervening in the world the relationships between causes and effects
the sort of objective functions which could be important to allow the the
highest level explanations to to to rise from from the learning which I don't
think we have now the kinds of objective functions which could be used to reward
exploration the right kind of exploration so these kinds of questions are neither in the dataset nor in the
architecture but more in how we learn under what objectives and so on yeah
Learning through interaction
that's a afraid you mentioned in several contexts the idea is sort of the way children learn they interact with
objects of the world and it seems fascinating because it's some sense
except with some cases in reinforcement learning that idea is not part of the
learning process in artificial neural network so it's almost like do you
envision something like an objective function saying you know what if you
poke this object in this kind of way would be really helpful for me to further
yes further learn right right sort of almost guiding some aspect of learning
right right so I was talking to Rebecca Saxe just an hour ago and she was
talking about lots and lots of evidence for infants seem to clearly take what
interest them in a directed way and so they're not passive learners they they
focus their attention on aspects of the world which are most interesting
surprising in in a non-trivial way that makes them change their theories of the
world so that's a fascinating view of
the future progress but Anna the more maybe boring a question do you think
going deeper and large so do you think just increasing the size of the things
that have been increasing a lot in the past few years will will also make significant progress so some of the
representational issues that you mentioned that is they're kind of shallow in some sense Oh higher in a
sense of abstraction up straight in a sense of abstraction they're not getting some I don't think that having more more
depth in the network in the sense of instead of a hundred layers we have ten thousand is going to solve our problem
you don't think so is that obvious to you yes what is clear to me is that
engineers and companies and labs grad students will continue to tune
architectures and explore all kinds of tweaks to make the current state of the Arts that he ever slightly better but I
don't think that's gonna be nearly enough I think we need some fairly drastic changes in the way that we're
considering learning to achieve the goal
that these learners actually understand in a deep way the environment in which they are you know observing and acting
but I guess I was trying to ask a question is more interesting than just
Our brain is big
more layers is basically once you figure out a way to learn through interacting
how many parameters does it take to store that information so
I think our brain is quite bigger than most neural networks right right oh I see what you mean oh I I'm with you
there so I agree that in order to build neural nets with the kind of broad
knowledge of the world that typical adult humans have probably the kind of
computing power we have now is going to be insufficient so well the good news is there are hardware companies building
neural net chips and so it's gonna get better however the good news in a way
which is also a bad news is that even our state-of-the-art deep learning
methods fail to learn models that understand even very simple environments
like some Grid worlds that we have built even these fairly simple environments I
mean of course if you train them with enough examples eventually they get it but it's just like instead of what
instead of what humans might need just dozens of examples these things will
need millions right for very very very simple tasks and so I think there's an
opportunity for academics who don't have the kind of computing power that say
Google has to do really important and exciting research to advance the
state-of-the-art in training frameworks learning models agent learning in even
simple environments that are synthetic that seem trivial but yet current
machine learning fails on we've talked about priors and common-sense knowledge
Knowledge
it seems like we humans take a lot of
knowledge for granted so what what's your view of these priors of forming
this broad view of the world this accumulation of information and how we
can teach a neural networks or learning systems to pick that knowledge up so knowledge you know for a while the
artificial intelligence what's maybe in the 80 there's a time or knowledge
representation knowledge acquisition expert systems I mean though the symbolic AI was was a view was an
interesting problem set to solve and it was kind of put on hold a little bit it
seems like because it doesn't work it doesn't work that's right but that's right but the goals of that remain
important yes remain important kind of how do you think those goals can be addressed right so first of all I
believe that one reason why the classical expert systems approach failed
is because a lot of the knowledge we have so you talked about common sense
intuition there's a lot of knowledge like this which is not consciously
accessible the lots of decisions we're taking that we can't really explain even if sometimes we make up a story and that
knowledge is also necessary for machines to take good decisions and that
knowledge is hard to codify in expert systems rule-based systems and you know
Costco EAJA formalism and there are other issues of course with the old AI like not really good ways of handling
uncertainty I would say something more subtle which we understand better now
but I think still isn't enough in the minds of people there is something
really powerful that comes from distributed representations the thing
that really makes neural Nets work so well and it's hard to replicate that
kind of power in a symbolic world the knowledge in in expert systems and so on
is nicely decomposed into like a bunch of rules whereas if you think about a
neural net it's the opposite you have this big blob of parameters which work
intensely together to represent everything the network knows and it's not sufficiently factorized and so I
think this is one of the weaknesses of current neural nets that we have to take lessons from classically I
in order to bring in another kind of compositionality which is common in
language for example and in these rules but that isn't so native to New Ulm Ed's
and on that line of thinking disentangled representations yes so so
let me connect with disentangled representations if you might if don't mind yes exactly so for many years I've
thought and I still believe that it's really important that we come up with learning algorithms either unsupervised
or supervised but or enforcement whatever that build representations in which the important factors hopefully
causal factors are nicely separated and easy to pick up from the representation so that's the idea of disentangle
representations it says transform the data into a space where everything becomes easy we can maybe just learn
with linear models about the things we care about and and I still think this is
important but I think this is missing out on a very important ingredient which
classically AI systems can remind us of so let's say we have these design
technologies invation you still need to learn about the the relationships between the variables
those high-level semantic variables they're not going to be independent I mean this is like too much of an assumption they're gonna have some
interesting relationships that allow to predict things in the future to explain what happened in the past the kind of
knowledge about those relationships in a classically AI system is encoded in the rules like a rule is just like a little
piece of knowledge that says oh I have these two three four variables that are linked in this interesting way then I
can say something about one or two of them given a couple of others right in addition to disentangling the the
elements of the representation which are like the variables in rule-based system you also need to disentangle the the
mechanisms that relate those variables to each other so like the rules so the
rules are neatly separated like each rule is you know living on its own and when I change a rule because I'm
learning it doesn't need to break other rules whereas current your Mets for example
are very sensitive to what's called catastrophic forgetting where after I've learned some things and then I learn new
things they can destroy the old things that I had learned right if the knowledge was better factorized and and
separated disentangled then you would avoid a lot of that now you can't do
this in the sensory domain but a decent
okay like an pixel space but but my idea is that when you project the data in the
right semantic space it becomes possible to now represent this extra knowledge
beyond the transformation from input to representations which is how representations act on each other and
predict the future and so on in a way that can be neatly disentangled so now
it's the rules or disentangle from each other and not just the variables that are disentangled from each other and you draw a distinction between semantic
space and pixel like yes there need to be an architectural difference or well yeah so there's the sensory space like
pixels which where everything is untangled the the information like the
variables are completely interdependent in very complicated ways and also computation like the it's not just
variables it's also how they are related to each other is is all intertwined but but I I'm hypothesizing that in the
right high-level representation space both the variables and how they relate
to each other can be disentangled and that will provide a lot of generalization power generalization
power yes distribution of the test set he assumed to be the same as a
distribution of the training set right this is where current machine learning is too weak it doesn't tell us anything
is not able to tell us anything about how are you let's say our gonna generalize to a new distribution and and
you know people may think well but there's nothing we can say if we don't know what the new distribution will be the truth is humans are able to
generalize to new distributions how are we able to do that so yeah because something these new distributions even
though they could look very different from the training solutions they have things in common so let me give you a concrete example you read a science
fiction novel the science fiction novel maybe you know brings you in some other
planet where things look very different on the surface but it's still the same
laws of physics all right and so you can read the book and you understand what's going on
so the distribution is very different but because you can transport a lot of
the knowledge you had from Earth about the underlying cause and effect relationships and physical mechanisms
and all that and maybe even social interactions you can now make sense of what is going on on this planet where
like visually for example things are totally different taking that analogy further and
distorting it let's enter a sign science fiction world to say Space Odyssey 2001
with hell yeah or or maybe which is probably one of my favourite AI movies
and then then - and then there's another one that a lot of people love that it may be a little bit outside of the AI
community is ex machina right I don't know if you've seen it yes yes but what
are your views on that movie alright does it does are you able to wear things I like and things I hate so maybe you
could talk about that in the context of a question I want to ask which is uh there's quite a large community of
people from different backgrounds often outside of AI who are concerned about existential threat of artificial
intelligence right you've seen now this community develop over time you've seen you have a perspective so what do you
think is the best way to talk about a a safety to think about it to have this course about it within AI community and
outside and grounded in the fact that ex machina is one of the main sources of
information for the general public about AI so I think I think you're putting it right there's a big difference between
the sort of discussion we oughta have within the AG community and the sort of
discussion that really matter in the general public so I think the the picture of terminator
and you know AI lose and killing people and super intelligence that's gonna
destroy us whatever we try isn't really so useful for the public discussion
because for the public discussion that things I believe really matter are the
short-term and mini term very likely negative impacts of AI on society whether it's from security like you know
Big Brother scenarios with face recognition or killer robots or the impact on the job market or
concentration of power and discrimination all kinds of social issues which could actually some of them
could really threaten democracy for example just to clarify when you said
killer robots you mean autonomous weapons yes weapon systems yes I do not terminator that's right
so I think these these short and medium-term concerns should be important
parts of the public debate now existential risk for me is a very unlikely consideration but still worth
academic investigation in the same way that you could say should we study what
could happen if meteorite you know came to earth and destroyed it so I think it's very unlikely that this is gonna
happen and or happen it in a reasonable future it's it's very the the sort of
scenario of an AI getting loose goes against my understanding of at least current machine learning and current
neural nets and so on it's not plausible to me but of course I don't have a crystal ball and who knows what a I will
be in fifty years from now so I think it is worth at scientists study those problems it's just not a pressing
question as far as I'm concerned so before continuing down the line a few
Ex Machina
questions there but what what do you like and not like about ex machina as a
movie because I I actually watch it for the second time and enjoyed it I hated it the first time and I enjoyed it quite
a bit more the second time when I sort of learned to accept certain pieces of it CC is the concept
movie hi what was your experience wouldn't Laura your thoughts so the negative is the picture it paints of
science is totally wrong science in general and AI in particular science is
not happening in some hidden place by some you know really smart guy one
person one person this is totally unrealistic this is not how it happens even a team of people in some isolated
place will not make it science moved by small steps thanks to
the collaboration and community of a large number of people interacting and
[Music] all the scientists who are expert in their field Canon Oh what is going on
even in the industrial labs its information flows and leaks and so on
and and and the spirit of it is very different from the way science is
painted in this movie yeah let me let me ask on that on that point it's been the case to this point yeah that kind of
Bottle Ideas
even if the research happens inside Google or Facebook inside companies it still kind of comes out like yes come on
absolutely think that will always be the case so there I is is it possible to bottle ideas to the point where there's
a set of breakthrough the go completely undiscovered by the general research community do you think that's even possible it's possible but it's unlikely
unlikely it's not how it is done now it's not how I can foresee it in in the
foreseeable future but of course I don't have a crystal ball and so who knows
this is science fiction after all but but usually the ominous that the lights went off during during that discussion
so the problem again there's a you know one thing is the movie and you could imagine all kinds of science fiction the
problem wouldn't for me may be similar to the question about existential risk is that this kind of movie pain
such a wrong picture of what is actual you know the actual science and how it's
going on that that it can have unfortunate effects on people's understanding of current science and and
so that's kind of sad is it an important principle in research which is diversity
so in other words research is exploration resources explosion in the space of ideas and different people will
focus on different directions and this is not just good it's essential so I'm
totally fine with people exploring directions that are contrary to mine or
look orthogonal to mine it's I I am more than fine I think it's important I and
my friends don't claim we have universal truth about what well especially about what will happen in the future now that
being said we have our intuitions and then we act accordingly according to
where we think we can be most useful and where society has the most gain or to lose we should have those debates and
and and and not end up in a society where there's only one voice and one way
of thinking in research money is spread out so disagreement is a sign of good
Bias in Machine Learning
research good science so yes the idea of bias in in the human sense of bias yeah
how do you think about instilling in machine learning something that's
aligned with human values in terms of bias we and intuitively human beings
have a concept of what bias means of what fundamental respect for other human
beings means but how do we instill that into machine learning systems do you think so I think there are short-term
things that are already happening and then there are long-term things that we need to do and the short term there are
techniques that have been proposed and I think will continue to be improved and maybe alternatives will come up to take
datasets in which we know there is bias we can measure it pretty much any data
set where humans are you know being observed taking decisions will have some sort of bias discrimination against
particular groups and so on and we can use machine learning techniques to try
to build predictors classifiers that are going to be less biased we can do it for
example using adversarial methods to make our systems less sensitive to these
variables we should not be sensitive to so these are clear well-defined ways of
trying to address the problem maybe they have weaknesses and you know more research is needed and so on but I think
in fact they are sufficiently mature that governments should start regulating companies where it matters say like
insurance companies so that they use those techniques because those techniques will produce the bias but at
a costs for example maybe their predictions will be less accurate and so companies will not do it until you force
them all right so this is short term long term I'm really interested in
thinking of how we can instill moral values into computers obviously this is
not something we'll achieve in the next five or ten years how can we you know
there's already work in detecting emotions for example in images and
sounds and texts and also studying how
different agents interacting in different ways may correspond to
patterns of say injustice which could trigger anger so these are things we can
do in in the medium term and eventually train computers to model for example how
humans react emotionally I would say the simplest thing is unfair situations
which trigger anger this is one of the most basic emotions that we share with other animals I think it's quite
feasible within the next few years so we can build systems that can take these kind of things to the extent
unfortunately that they understand enough about the world around us which is a long time away but maybe we can
initially do this in virtual environments so you can imagine like a video game we're agents interact in in
some ways and then some situations trigger an emotion I think we could
train machines to detect those situations and predict that the particular emotion you know will likely
be felt if a human was playing one of the characters you have shown excitement
Teaching Machines
and done a lot of excellent work with supervised learning but on a superbug
you know there's been a lot of success on the supervised learning yes yes and one of the things I'm really passionate
about is how humans and robots work together and in the context of
supervised learning that means the process of annotation do you think about the problem of annotation of put in a
more interesting way is humans teaching machines yes is there yes I think it's
an important subject reducing it to annotation may be useful for somebody
building a system tomorrow but longer-term the process of teaching I
think is something that deserves a lot more attention from the machine learning community so there are people have
coined the term machine teaching so what are good strategies for teaching a learning agent and can we design train a
system that gonna be is gonna be a good teacher so so in my group we have a project called the baby I or baby I game
where there is a game or scenario where there's a learning agent and a teaching
agent presumably the teaching agent would eventually be a human but we're
not there yet and the the role of the
teacher is to use its knowledge of the environment which it can acquire using whatever way brute force to help the
learner learn as quickly as possible so the learner is going to try to learn by it of maybe be using some exploration and
whatever but the teacher can choose can
can can have an influence on the interaction with the learner so as to guide the learner maybe teach it the
things that the learner has most trouble with or just at the boundary between what it knows and doesn't know and so on
so this is there's a tradition of these kind of ideas from other fields and like
tutorial systems for example and they I and and of course people in the
humanities have been thinking about these questions but I think it's time that machine learning people look at
this because in the future we'll have more and more human machine interaction with a human in the loop and I think
The Turing Test
understanding how to make this work better all the problems around that are very interesting and not sufficiently
addressed you've done a lot of work with language to what aspect of the
traditionally formulated Turing test a test of natural language understanding a generation in your eyes is the most
difficult of conversation but in your eyes is the hardest part of conversation to solve for machines so I would say
it's everything having to do with the non linguistic knowledge which
implicitly you need in order to make sense of sentences things like the Winograd schemas so these sentences that
are semantically ambiguous in other words you need to understand enough about the world in order to really
interpret probably those sentences I think these are interesting challenges for our machine learning because they
point in the direction of building systems that both understand how the
world works and it's causal relationships in the world and associate that knowledge with how to express it in
language either for reading or writing you speak French yes it's my mother
tongue it's one of the Romance languages do you think passing the Turing test and
all the underlying challenges we just mentioned depend on language do you think it might be easier in front
that is in English now is independent of language mmm I think it's independent of language I I
would like to build systems that can use
the same principles the same learning mechanisms to learn from human agents
whatever their language well certainly us humans can talk more beautifully and
smoothly in poetry some Russian originally I know poetry and Russian is
maybe easier to convey complex ideas than it is in English but maybe I'm
showing my bias and some people could say that about front half French but of
course the goal ultimately is our human brain is able to utilize any kind of
those languages to use them as tools to convey meaning you know of course there
are differences between languages and maybe some are slightly better at some things but in the grand scheme of things where we're trying to understand how the
brain works and language and so on I think these differences are a minut so
you've lived perhaps through an AI winter of sorts yes how did you stay
warm and continue and you're resurfacing stay warm with friends and with friends
okay so it's important to have friends and what have you learned from the experience listen to your inner voice
don't you know be trying to just please
the crowds and the fashion and if you have a strong intuition about something
that is not contradicted by actual evidence go for it I mean it could be
contradicted by people but not your own instinct of based on everything you know
of course of course you have to adapt your beliefs when your experiments
contradict those beliefs but but you have to stick to your beliefs otherwise
it's it's it's what allowed me to go through those years it's what allowed me to
persist in directions that you know took time whatever all the people think took
time to mature and you bring fruits so
Whats next
history of AI is marked with these of course it's mark with technical
breakthroughs but it's also marked with these seminal events that capture the imagination of the community most recent
I would say alphago beating the world champion human go player was one of
those moments what do you think the next such moment might be okay surface first
of all I think that these so-called seminal events are overrated as I said
science really moves by small steps now what happens is you make one more small
step and it's like the the drop that you know allows to that fills the bucket and
and and then you have drastic consequences because now you're able to do something you were not able to do
before or now say the cost of building some device or solving a problem becomes
cheaper than what existed and you have a new market that opens up right so so especially in the world of Commerce and
applications the impact of a small scientific progress could be huge but in
the science itself I think it's very very gradual and where these steps being
taken now so there's supervised right so if I look at one trend that I like in in
in my community so for example in at me lie in my Institute what are the two
hottest topics Gans and rain for spurning even though in the montreal in
particular like reinforcement learning was something pretty much absent just two or three years ago so it is really a
big interest from students and there's a big interest from people like me
so I would say this is something where are we gonna see more progress even though it hasn't yet provided much in
terms of actual industrial fallout like even though there's alphago there's no
like Google is not making money on this right now but I think over the long term this is really really important for many
reasons so in other words agent I would say reinforcement learning baby more
generally agent learning because it doesn't have to be with rewards it could be in all kinds of ways that an agent is
learning about its environment now reinforced learning you're excited about do you think do you think Gans could
Gans
provide something yes some moment in in a well Gans or other generative models I
believe will be crucial ingredients in building agents that can understand the
world a lot of the successes in reinforcement learning in the past has
been with policy gradient where you you'll just learn a policy you don't actually learn a model of the world but
there are lots of issues with that and we don't know how to do model-based our rel right now but I think this is where
we have to go in order to build models that can generalize faster and better
like to new distributions that capture to some extent at least the underlying
causal mechanisms in in the world last question what made you fall in love with
artificial intelligence if you look back what was the first moment in your life
when he's when you were fascinated by either the human mind or the artificial mind you know when I wasn't at the
lesson I was reading a lot and then I I started reading science fiction there
you go but I got that's that's it that that's that's where I got hooked and then and then you know I had one of the
first personal computers and I got hooked in programming and so it just you
know start with fiction and then make it a reality that's right Yoshio thank you so much for talking to
my pleasure
you

----------

-----
--44--

-----
Date: 2018.10.17
Link:  [# Steven Pinker: AI in the Age of Reason | Lex Fridman Podcast #3](https://www.youtube.com/watch?v=epQxfSp-rdU)
Transcription: 

you've studied the human mind cognition language vision evolution psychology
from child to adult from the level of individual to the level of our entire
civilization so I feel like I can start with a simple multiple-choice question
what is the meaning of life is it a to attain knowledge as Plato said B to
attain power as Nietzsche said C to escape death as Ernest Becker said d to
propagate our genes as Darwin and others have said e there is no meaning as the
nihilists have said F knowing the meaning of life is beyond our cognitive
capabilities as Steven Pinker said based on my interpretation twenty years ago and G none of the above
I'd say aid comes closest but I would amend that to attaining not only
knowledge but fulfillment more generally that is life health stimulation access
to the living cultural and social world now this is our meaning of life it's not
the meaning of life if you were to ask our genes their meaning is to propagate
copies of themselves but that is distinct from the meaning that the brain that they lead to sets for itself so to
you knowledge is a small subset or a large subset it's a large subset but
it's not the entirety of human striding because we also want to interact with
people we want to experience beauty we want to experience the the richness of the natural world but understanding the
what makes the universe tick is his way up there for some of us more than others
certainly for me that's that's one of the top five so is that a fundamental
aspect are you just describing your own preference or is this a fundamental aspect of human nature is to seek
knowledge just in your latest book you talk about the the the power the
usefulness of rationality and reason so on is that a fundamental nature human beings or is it something we
should just strive for it's both it is we're capable of striving for it because
it is one of the things that make us what we are Homo sapiens wise men we are
unusual among animals in the degree to which we acquire knowledge and use it to
survive we we make tools we strike agreements via language we extract
poisons we predict the behavior of animals we try to get at the workings of
plants and when I say we I don't just mean we in the modern West but we as a species everywhere which is how we've
managed to occupy every niche on the planet and how we've managed to drive other animals to extinction and the
refinement of Reason in pursuit of human well-being of health happiness social
richness cultural richness is our our main challenge in the present that is
using our intellect using our knowledge to figure out how the world works how we work in order to make discoveries and
strike agreements that make us all better off in the long run right and you do that almost undeniably and in a
data-driven way in a recent book but I'd like to focus on the artificial intelligence aspect of things and not
just artificial intelligence but natural intelligence too so twenty years ago in the book you've written on how the mind
works you conjecture again my right to interpret things you could you can
correct me if I'm wrong but you conjecture that human thought in the brain may be a result of and now we're a
massive network of highly interconnected neurons so from this interconnectivity emerges thought compared to artificial
neural networks we use for machine learning today is there something fundamentally more complex mysterious
even magical about the biological neural networks versus the ones we've been
starting to use over the past 60 years and it becomes a success in the past 10
there is something a little bit mysterious about the human
neural networks which is that each one of us who is a neural network knows that
we ourselves are conscious conscious not of a sense of registering our surroundings or even registering our
internal state but in having subjective first-person present-tense experience that is when I see red it's not just
different from green but it just there's there's a redness to it I feel whether
an artificial system would experience that or not I don't know and I don't think I can know that's why it's
mysterious if we had a perfectly lifelike robot that was behaviorally indistinguishable from a human would we
attribute consciousness to it or ought we to attribute consciousness to it and that's something that it's very hard to
know but putting that aside put inside that that largely philosophical question the question is is there some difference
between the human neural network and the ones that we were building in artificial intelligence will mean that we're on the
current trajectory not going to reach the point where we've got a lifelike
robot indistinguishable from a human because the way their neural so-called neural networks were organized are
different from the way ours are organized having there's overlap but I think there are some some big
differences that they're the current neural networks current so called deep
learning systems are in reality not all that deep that is they are very good at
extracting high order statistical regularities but most of the systems don't have a semantic level a level of
actual understanding of who did what to who why where how things work what
causes what else do you think that kind of thing can emerge as it does so artificial you know so much smaller the
number of connections and so on in the current human biological networks but do you think sort of go to go to
consciousness or to go to this higher level semantic reasoning about things do you think that can emerge with just a
larger network with a more richly weirdly interconnected network
separating consciousness because consciousness is even a matter of complex a really good one yeah you could have you could sensibly
ask the question of whether shrimp are conscious for example they're not terribly complex but maybe they feel
pain so let's just put that one that part of it aside yet but I think sheer
size of a neural network is not enough to give it structure and knowledge but
if it's suitably engineered then then why not that is where neural networks natural
selection did a kind of equivalent of engineering of our brains so I don't know there's anything mysterious in the
sense that no no system made out of silicon could ever do what a human brain
can do I think it's possible in principle whether it'll ever happen depends not only on how clever we are in
engineering these systems but whether even we even want to whether that's even a sensible goal that is you can ask the
question is there any locomotion system that is as as good as a human well we
kind of want to do better than a human ultimately in terms of legged locomotion there's no reason that humans should be
our benchmark they're their tools that might be better in some ways it may just be not as maybe that we can't duplicate
a natural system because at some point it's so much cheaper to use a natural system that we're not going to invest
more brainpower and resources so for example we don't really have a subsidy
and exact substitute for wood we still build houses out of would we still go furniture out of wood we like the look
we like the feel it's wood has certain properties that synthetics don't there's not that there's any magical or
mysterious about wood it's just that the extra steps of duplicating everything
about wood is something we just haven't bothered because we have wood likewise a cotton I mean I'm wearing cotton clothing now feels much better than the
polyester it's not that cotton has something magic in it and it's not that
if there was that we couldn't ever synthesize something exactly like cotton but at some point it just it's just not
worth it we've got cotton and likewise in the case of human intelligence the goal of making an artificial system that
is exactly like the human brain is a goal that we no one's gonna pursue to the bitter end
I suspect because if you want tools that do things better than humans you're not going to care whether it does something
like humans so for example you're diagnosing cancer or particularly whether why set humans as your benchmark
but in in general I suspect you also believe that even if the human should
not be a benchmark on women's don't want to imitate humans in their system there's a lot to be learned about how to
create an artificial intelligence system by studying the human yeah III think that's right there in in the same way that to build
flying machines we want understand the laws of aerodynamics and including birds but not mimic the birds right but the
same laws you have a view on AI artificial intelligence and safety that
from my perspective is refreshingly rational or perhaps more importantly has
elements of positivity to it which I think can be inspiring and empowering as
opposed to paralyzing for many people including AI researchers the eventual
existential threat of AI is obvious not only possible but obvious and for many
others including a researchers the threat is not obvious so Elon Musk is is
famously in the highly concerned about AI camp saying things like AI is far
more dangerous and nuclear weapons and that AI will likely destroy human
civilization so in February you said that if Elon was really serious about AI
they the threat of AI he would stop building self-driving cars that he's
doing very successfully as part of Tesla then he said Wow if even Pinker doesn't
understand the difference between arrow AI like a car in general AI when the latter literally has a million times
more compute power and an open-ended utility function humanity is in deep
trouble so first what did you mean by the statement about Elon Musk should
stop Bill ourselves driving cars if he's deeply concerned not last time that Elon Musk has fired
off an intemperate tweet well we live in a world where Twitter has power yes yeah
I think the the that there are two kinds
of existential threat that have been discussed in connection with artificial intelligence and I think that they're both incoherent one of them is vague
fear of AI takeover that it just as we subjugated animals and less
technologically advanced people's so if we build something that's more advanced than us it will inevitably turn us into
pets or slaves or or domesticated animal equivalents I think this confuses intelligence with
a will to power that it so happens that in the intelligence system we are most
familiar with namely Homo sapiens we are products of natural selection which is a competitive process and so bundled
together with our problem-solving capacity are a number of nasty traits like dominance and exploitation and
maximization of power and glory and resources and influence there's no
reason to think that sheer problem-solving capability will set that as one of its goals its goals will be
whatever we set it its goals as and as long as someone isn't building a megalomaniacal artificial intelligence
and there's no reason to think that it would naturally evolve in that direction now you might say well what if we gave it the goal of maximizing its own power
source well that's a pretty stupid goal to give a an autonomous system you don't give it that goal I mean that's just
self-evident we idiotic so if you look at the history of the world there's been
a lot of opportunities where engineers could instill in a system destructive power and they choose not to because
that's the natural process of Engineering well weapons I mean if you're building a weapon its goal is to
destroy people and so I think they're good reasons to not not build certain kinds of weapons I think the building
nuclear weapons was a massive mistake but probably do you think so
maybe pause on that because that is one of the serious threats do you think that it was a mistake in a sense that it was
should have been stopped early on or do you think it's just an unfortunate event of invention that this
was invented we think it's possible to stop I guess is the question it's hard to rewind the clock because of course it
was invented in the context of World War two and the fear that the Nazis might develop one first then once was
initiated for that reason it was it it was hard to turn off especially since winning the war against the Japanese and
the Nazis was such an overwhelming goal of every responsible person that there's
just nothing that people wouldn't have done then to ensure victory it's quite possible if World War two hadn't
happened that nuclear weapons wouldn't have been invented we can't know but I don't think it was by any means a
necessity any more than some of the other weapon systems that were envisioned but never implemented like
planes that would disperse poison gas over cities like crop dusters or systems
to try to do to create earthquakes and tsunamis in enemy countries to weaponize
the weather weaponize solar flares all kinds of crazy schemes that that we
thought the better off I think analogies between nuclear weapons and artificial intelligence are fundamentally misguided
because the whole point of nuclear weapons is to destroy things the point of artificial intelligence is not to
destroy things so the analogy is is misleading so there's two artificial
intelligence you mentioned the first one was the intelligence all know hungry yeah the system that we design ourselves
where we give it the goals goals are external to the means to attain the
goals I if we don't design an artificial intelligence system to maximize
dominance then it won't maximize dominance it just that we're so familiar with Homo sapiens when these two traits
come bundled together particularly in men that we are apt to confuse high
intelligence with a will to power but that's just an error the other fear is
that we'll be collateral damage that will give artificial intelligence a goal like make paperclips and it will pursue
that goal so brilliantly that before we can stop it it turns us into paperclips we'll give it the goal of
curing cancer and it will turn us into guinea pigs for lethal experiments or give it the goal of world peace and its
conception of world pieces no people therefore no fighting and so it'll kill us all now I think these are utterly
fanciful in fact I think they're actually self-defeating they first of all assume that we're going to be so
brilliant that we can design an artificial intelligence that can cure cancer but so stupid that we don't
specify what we mean by curing cancer in enough detail that it won't kill us in the process and it assumes that the
system will be so smart that it can cure cancer but so idiotic that it doesn't
can't figure out that what we mean by curing cancer is not killing everyone so I think that the the collateral damage
scenario the value alignment problem is is also based on a misconception so one of the challenges of course we don't
know how to build either system currently or are we even close to knowing of course those things can
change overnight but at this time theorizing about it is very challenging in either direction so that that's
probably at the core the problem is without that ability to reason about the real engineering things here at hand is
your imagination runs away with things exactly but let me sort of ask what do
you think was the motivation the thought process of elam Wasco i build autonomous vehicles I study autonomous vehicles I
studied Tesla autopilot I think it is one of the greatest currently application large scale application of
artificial intelligence in the world it has a potentially a very positive impact on society so how does a person who's
creating this very good quote/unquote narrow AI system also seem to be so
concerned about this other general AI what do you think is the motivation
there what do you think is the thing really you probably have to ask him but there and and he is notoriously
flamboyant impulsive to the as we have just seen to the detriment of his own
goals of the health of a company so I don't know what's going on
on his mind you probably have to ask him but I don't think the and I don't think the distinction between special-purpose
a and so-called general is relevant that in the same way that special-purpose AI
is not going to do anything conceivable in order to attain a goal all engineering systems have to are designed
to trade off across multiple goals well we build cars in the first place we didn't forget to install brakes because
the goal of a car is to go fast it occurred to people yes you want to go fast but not always so you build an
brakes too likewise if a car is going to be autonomous that doesn't and program
it to take the shortest route to the airport it's not going to take the diagonal and mow down people and trees and fences because that's the shortest
route that's not what we mean by the shortest route when we program it and that's just what and an intelligent
system is by definition it takes into account multiple constraints the same is
true in fact even more true of so-called general intelligence that is if it's
genuinely intelligent it's not going to pursue some goal single-mindedly omitting every other consideration and
collateral effect that's not artificial in general intelligence that's that's artificial stupidity I agree with you by
the way on the promise of autonomous vehicles for improving human welfare I think it's spectacular and I'm
surprised at how little press coverage notes that in the United States alone something like 40,000 people die every
year on the highways vastly more than are killed by terrorists and we spend we
spent a trillion dollars on a war to combat deaths by terrorism but half a dozen a year whereas if you're an year
out 40,000 people are massacred on the highways which could be brought down to very close to zero so I'm with you on
the humanitarian benefit let me just mention that it's as a person who's building these cars it is it a little
bit offensive to me to say that engineers would be clueless enough not to engineer safety into systems I often
stay up at night thinking about those 40,000 people that are dying and everything I tried to engineer is to
save those people's lives so every new invention that I'm super excited about every new and the in all
the deep learning literature and cvpr conferences and nips everything I'm super excited about is all grounded in
making it safe and help people so I just don't see how that trajectory can all a
sudden slip into a situation where intelligence will be highly negative you
know you and I certainly agree on that and I think that's only the beginning of the potential humanitarian benefits of
artificial intelligence there's been enormous attention to what are we going to do with the people whose jobs are
made obsolete by artificial intelligence but very little attention given to the fact that the jobs that hooni made
obsolete are horrible jobs the fact that people aren't going to be picking crops and making beds and driving trucks and
mining coal these are you know soul deadening jobs and we have a whole literature sympathizing with the people
stuck in these menial mind deadening dangerous jobs if we can eliminate them
this is a fantastic boon to humanity now granted we you solve one problem and there's another one namely how do we get
these people a a decent income but if we're smart enough to invent machines that can make beds and put away dishes
and and handle hospital patients well I think we're smart enough to figure out how to redistribute income to apportion
some of the vast economic savings to the human beings who will no longer be
needed to to make beds okay Sam Harris says that it's obvious that eventually
AI will be in existential risk he's one of the people says it's obvious we don't
know when the claim goes but eventually it's obvious and because we don't know
when we should worry about it now this is a very interesting argument in my eyes so how do you how do we think about
time scale how do we think about existential threats when we don't really know so little about the threat unlike
nuclear weapons perhaps about this particular threat that it could happen
tomorrow right so but very likely won't yeah they're likely to be a hundred years
away so how do do we ignore it do how do we talk about it do we worry about it what how do we
think about those what is it a threat that we can imagine it's within the
limits of our imagination but not within our limits of understanding - sufficient
to accurately predict it but but what what is what is the ether asre AI xai
being the existential threat AI can always know like enslaving us or turning us into paperclips I think the most
compelling from the Sam Harris was fact it would be the paperclip situation yeah I mean I just think it's totally
fanciful I just don't build a system don't give it a don't first of all the
code of engineering is you don't implement a system with massive control before testing it now perhaps the
culture of engineering will radically change then I would worry I don't see any signs that engineers will suddenly
do idiotic things like put a electrical power plant in control of a system that
they haven't tested first or all of these scenarios not only imagine a
almost a magically powered intelligence you know including things like cure
cancer which is probably an incoherent goal because there's so many different kinds of cancer or bring about world
peace I mean how do you even specify that as a goal but the scenarios also imagine some degree of control of every
molecule in the universe which not only is itself unlikely but we would not
start to connect these systems to infrastructure without without testing
as we would any kind of engineering system now maybe some engineers will be irresponsible and we need legal and
regulatory and legal responsibilities implemented so that engineers don't do
things that are stupid by their own standards but the ii-i've never seen
enough of a plausible scenario of existential threat to devote large
amounts of brain power to to forestall it so you believe in the sort of the
power and mass of the engineering of reason as the argue this book of Reason science and sort of
be the very thing that puts the development of new technology so it's
safe and also keeps us safe it's the same and you know granted the same culture of safety that currently is part
of the engineering mindset for airplanes for example so yeah I don't think that
that that should be thrown out the window and that untested all-powerful system should be suddenly implemented
but there's no reason to think they are and in fact if you look at the progress of artificial intelligence it's been you
know it's been impressive especially in the last ten years or so but the idea that suddenly there'll be a step function that all of a sudden before we
know it it will be all powerful that there'll be some kind of recursive self-improvement some kind of Foom is
also fanciful we certainly by the technology that we that were now
impresses us such as deep learning when you train something on hundreds of thousands or millions of examples
they're not hundreds of thousands of problems of which curing cancer is a
typical example and so the kind of techniques that have allowed AI to
increase in the last five years are not the claim that are going to lead to this fantasy of of exponential sudden
self-improvement so it's may I think it's it's kind of a magical thinking it's not based on our understanding of
how AI actually works now give me a chance here so you said fanciful magical thinking in his TED talk Sam Harris says
that thinking about AI killing all human civilization is somehow fun intellectually now I have to say as a
scientist engineer I don't find it fun but when I'm having beer with my non-ai
friends there is indeed something fun and appealing about it like talking
about an episode of black mirror considering if a large meteor is headed
towards Earth we were just told a large meteors headed towards Earth something like this and can you relate to this sense of fun
and do you understand the psychology of it yeah that's a good question III personally don't find it fun
I find it kind of actually a waste of time because there are genuine threats
that we ought to be thinking about like like pandemics like like a cyber security vulnerabilities like the
possibility of nuclear war and certainly climate change this is enough to film it
many conversations without and I think there I think Sam did put his finger on
something namely that there is a community us sometimes called the rationality community that delights in
using its brain power to come up with scenarios that would not occur to mere
mortals to less cerebral people so there is a kind of intellectual thrill in
finding new things to worry about that no one has worried about yet I actually think though that it's not
only is it is a kind of fun that doesn't give me particular pleasure but I think there is there can be a pernicious side
to it namely that you overcome people with such dread such fatalism that
there's so many ways to die to annihilate our civilization that we may
as well enjoy life while we can there's nothing we can do about it if climate change doesn't do us in then runaway robots will so let's enjoy ourselves now
we've got to prioritize we have to look
at threats that are close to certainty such as climate change and distinguish
those from ones that are merely imaginable but with infinitesimal probabilities and we have to take into
account people's worry budget you can't worry about everything and if you so dread and fear and terror and numb and
fatalism it can lead to a kind of numbness well they're just these problems are overwhelming and the engineers are just gonna kill us all so
let's either destroy the entire infrastructure of science technology or
let's just enjoy life while we can so there's a certain line of worry which I'm worried about a lot of things
engineering there's a certain line of worry when you cross a lot across that it becomes paralyzing fear as
opposed to productive fear and that's kind of what they're highlighting there
exactly right and we've seen some we know that human effort is not well calibrated against risk in that because
a basic tenet of cognitive psychology is that perception of risk and hence
perception of fear is driven by imagined ability not by data and so we miss
allocate vast amounts of resources to avoiding terrorism which kills on average about six Americans a year with
a one exception of 9/11 we invade countries we invent entire new
departments of government with massive massive expenditure of resources and
lives to defend ourselves against a trivial risk whereas guaranteed risks
and you mentioned as one of them you mentioned traffic fatalities and even
risks that are not here but are
plausible enough to worry about like pandemics like nuclear war receive
far too little attention the in presidential debates there's no discussion of how to minimize the risk
of nuclear war lots of discussion of terrorism for example and and so we I
think it's essential to calibrate our budget of fear worry concern planning to
the actual probability of harm yep so let me ask this then this question
so speaking of imagined ability you said it's important to think about reason and
one of my favorite people who who likes to dip into the outskirts of reason
through fascinating exploration of his imagination is Joe Rogan oh yes you so
who has through reason used to believe a lot of conspiracies and through a reason has stripped away a lot of his beliefs
in that way so it's fascinating actually to watch him through rationality kind of
throw away that ideas of Bigfoot and 9/11 I'm not sure exactly trails I don't
know what the leaves in yet but you no longer know believed in that's right no either he's become a real force for for good yeah so you were
on the Joe Rogan podcast in February and had a fascinating conversation but as far as I remember didn't talk much about
artificial intelligence I will be on his podcast in a couple weeks Joe is very much concerned about
existential threat away I am not sure if you're this is why I was I was hoping that you would get into that topic and
in this way he represents quite a lot of people who look at the topic of AI from 10,000 foot level so as an exercise of
communication he said it's important to be rational and reason about these things let me ask if you were to coach
me as AI researcher about how to speak to Joe and the general public about AI
what would you advise well I'd the short answer would be to read the sections that I wrote an Enlightenment I know
about AI but a longer reason would be I think to emphasize and I think you're very well positioned as an engineer to
remind people about the culture of engineering that it really is safety oriented that another discussion in
enlightenment now I plot rates an accidental death from various causes
plane crashes car crashes Occupational accidents even death by lightning
strikes and they all plummet because the culture of engineering is how do you
squeeze out the the lethal risks death by fire death by drowning death by
asphyxiation all of them drastically declined because of advances in engineering then I gotta say I did not
appreciate until I saw those graphs and it is because exactly people like you
who stamp at night thing oh my god it is what a mime is what I mean what I'm inventing likely to hurt people and to
deploy ingenuity to prevent that from happening now I'm not an engineer although I spent 22 years at MIT so I
know something about the culture of engineering my understanding is that this is the way this is what you think if you're an engineer
and it's essential that that culture not be suddenly switched off when come start
official intelligence so I mean fact that could be a problem but is there any reason to think it would be switched off I don't think so and one there's not
enough engineers speaking up for this way for this the excitement for the
positive view of human nature what you're trying to create is the positivity like everything we try to
invent is trying to do good for the world but let me ask you about the psychology of negativity it seems just
objectively not considering the topic it seems that being negative about the future makes you sound smarter than me
positive about the future irregardless of topic am I correct in the observation and if you if so why do you think that
is yeah I think that I think there is that that phenomenon that as Tom Lehrer
the satirist said always predict the worst and you'll be hailed as a prophet it may be part of our overall negativity
bias we are as a species more attuned to their negative than the positive we dread losses more than we enjoy gains
and that mate might open up a space for
prophets to remind us of harms and risks and losses that we may have overlooked so I think there there there is that
asymmetry so you've written some of my favorite books all over the place so
starting from enlightenment now to the better angels of our nature blank slate how the mind works the the
one about language language instinct bill gates big fan to set of your most
recent book that it's my new favorite book of all time so for you as an author
what was the book early on in your life that had a profound impact on the way
you saw the world certainly this book enlightenment now is influenced by David
Deutsch as the beginning of infinity a rather deep reflection on knowledge and
the power of knowledge to improve the human condition the and with bits of
wisdom such as that problems are inevitable but problems are solvable given the knowledge and that solutions create new
problems have to be solved in their turn that's I think a kind of wisdom about the human condition that influenced the
writing of this book there's some books that are excellent but obscure some of which I have on my page of my website I
read a book called the history of force self-published by a political scientist named James Payne on the historical
decline of violence and that was one of the inspirations for the better angels of our nature the what about early on if we look back
when you're maybe a teenager loved a book called one two three infinity when
I was a young adult I read that book by George gamma the physicist very
accessible in humorous explanations of relativity of number theory of
dimensionality high multiple dimensional spaces in a way that I think is still
delightful seventy years after it was published I like that the time life science series these were books that
would arrive every month my mother subscribed to each one on a different topic one would be on electricity what
would be on forests want to be learned may evolution and then one was on the mind and I was just intrigued that there
could be a science of mind and that that book I would cite as an influence as well then later on you fell in love with
the idea of studying the mind that's one thing that grabbed you it was one of the things I would say the I read as a
college student the book reflections on language by Noam Chomsky spent most of
his career here at MIT Richard Dawkins two books the blind watchmaker and The
Selfish Gene or enormous Li influential partly for mainly for the content but
also for the writing style the ability to explain abstract concepts in lively
prose Stephen Jay Gould first collection ever since Darwin also excellent example
of lively writing George Miller psychologist that most psychologists are
familiar with came up with the idea that human memory has a capacity of seven
plus or minus two chunks and then Sophia's biggest claim to fame but he wrote a couple of books on language and
communication that I've read it's an undergraduate again beautifully written and intellectually deep wonderful Steven
thank you so much for taking the time today my pleasure thanks a lot Lex
you

----------

-----

--43--

-----
Date: 2018.09.29
Link: [# MIT Human-Centered Autonomous Vehicle](https://www.youtube.com/watch?v=OoC8oH0CLGc)
Transcription: 

this is the human center autonomous
vehicle one of the main ideas underlying
our work is that solving the task of
autonomous driving is more complicated
and more fascinating than the strictly
robotics challenges of localization
mapping perception control and planning
you also have to enable the vehicle to
perceive predict communicate and
collaborate with human beings
the humans inside the car like the
driver and the passengers and the humans
outside the car like the pedestrians
cyclists the drivers of other vehicles
and even tell the operators the studies
the code the data and the demos we
release all consider autonomous driving
in this kind of human centered way where
the control is transferred from human to
machine back to human based on the state
of the external driving environment and
the state of the driver what we'd like
to demonstrate today is the basics
voice-based transfer of control from
human to machine based on whether the
driver is paying attention to the road
or not inside we have two cameras on the
Description of components
driver one on the driver's face one on
the driver's body with two cameras
looking at the external roadway and we
have a few other cameras for filming
purposes there's a center stack display
showing who's in control of the vehicle
human or machine so currently the human
is in control of the vehicle let's drive
let's split the car and drive on the
center stack display it shows the gear
as drive
the perception control and driver states
sensing algorithms you see today I'm
running in real-time but the
visualizations you're seeing in video
are done in offline post-processing our
perception system today is vision based
using two neural networks one is doing
road segmentation the other is doing
object detection of vehicles cyclists
pedestrians traffic science traffic
lights the acceleration braking and
steering of the car is performed by PID
controllers the driver states sensing
that we're showing today is glance
region classification and that's
performed using 3d convolutional neural
networks high-level planning decisions
to transfer control or to stop the
vehicle are performed by a decision
fusion algorithm that combines risk
factors in the external environment and
driver state whether the drivers paying
attention to the road or not safety for
us is the number one priority always we
are on a test track the vehicles and
pedestrians here today are all part of
our team all part of the demonstration
there's another safety driver in the car
that can stop the vehicle at any moment
by pressing a single button ok
Tweeting
let's engage any distracting activity
Twitter and let's send a tweet
I'm typing
this tweet
while driving in the MIT semi autonomous
vehicle
on
a test track
Lex you appear distracted would you like
me to take over yes please
great I am taking control of steering
and braking the car is now in control as
the center stack display shows so I will
continue with the tweet the car knows
that I am NOT
paying attention
and has taken control after asking me
nicely for it
video out tomorrow okay here goes
nothing it's posted very well might be
the first tweet ever sent from an
autonomous vehicle while it's driving
itself
Pedestrian
elevated driving risk detected I am
stopping for a pedestrian Lex pedestrian
is blocking our lane of travel should i
honk
no please shift gear to park great we
are now in park
Outro
that was a demo of the basics perception
motion planning driver state sensing
transfer control and tweeting and we
have a lot more to explore together our
team is working on various aspects of
human and artificial intelligence toward
our mission to save lives through
effective human robot collaboration
you
you

----------

-----

--42--

-----
Date: 2018.09.25
Link: [# Arguing Machines: Tesla Autopilot vs Neural Network](https://www.youtube.com/watch?v=YBvcKtLKNAw)
Transcription:

our group at MIT is studying semi
autonomous vehicles now that includes
both inward-facing census for driver
state sensing and outward-facing sensors
for scene perception and the control
planning motion planning tasks now today
we'll look at the second part of that at
the perception and the control of the
vehicle on the dashboard of the Tesla
there's a Jetson tx2 with a camera
sitting on top of it
we have a neural network and two end
running on the Jetson
that's detecting the forward roadway
taking it a sequence of images and
producing steering commands we also have
here a Tesla that has a perception
control system on it in the form of
autopilot it's using a monocular camera
this is the hardware version one it's
making decisions based on this single
video stream producing steering commands
and we'll look at two systems arguing
today auto pilot arguing against a
neural network and we'll see what comes
out in this concept Tesla autopilot is
Concept overview
the primary AI system and the entire
neural network is the secondary AI
system and the disagreement between the
two is used to detect challenging
situations and seek human drivers
supervision it is important to clarify
that this is not a criticism of auto
pilot of the two it is by far the
superior perception control system the
question is whether the argument between
the two systems can create transparency
that leverage the human driver as a
supervisor of challenging driving
scenarios scenarios that may have not
otherwise been caught by auto pilot
alone this is a general framework for
supervision of blackbox AI systems that
we hope can help save human lives in the
paper accompanying this video we show
that we can predict driver initiate
disengagement of autopilot with a simple
threshold on the disagreement of
steering decisions we believe this is a
very surprising and powerful result that
hopefully may be useful for human
supervision of any kind of AI system
that operates in the real world and
makes decisions where errors may result
in loss of human life
a quick note that we use the intensity
of red color on the disagreement
detected text as the visualization of
disagreement magnitude in retrospect
this is not an effective visualization
because visually it looks like the two
systems are constantly disagreeing they
are not the intent of the on-road demo
is to show successful real-time
operation of the arguments framework the
paper that goes along with this approach
on the other hand is where we show the
predictive power of this approach on
large-scale naturalistic data
In-car description of components
inside the car we have a screen over the
center stack and a Jetson tx2 with a
camera on top of it the camera is
feeding a video stream into the Jetson
Island Jetson is a neural network that's
predicting the steering command taking
an end to end the video stream from the
forward roadway and as an output for the
neural network giving a steering command
that's being shown as pink on this
display the pink line is the steering
suggested by the neural network cyan
line is the steering of the car of the
Tesla that we're getting from the can
bus so when I moved the steering wheel
around we see that live in real-time
mapped on this graphic here showing in
cyan the steering position of the car
and up top is whenever the to disagree
significantly the disagreement detected
red sign appears showing that there's a
disagreement and I'll demonstrate that
on-road we're now driving on the highway
On-road demonstration
with the Tesla being controlled by
autopilot and the Jetson tx2 on the
dashboard with a camera plugged in has a
neural network running on it and to end
and the inputs of the neural network is
a sequence of images and the output of
steering commands now there's 2
perception control systems working here
one is autopilot the other one is an
end-to-end neural network both the
steering commands from both are being
visualized on the center stack here in
pink is the output from the neural
network and cyan is the output from
autopilot and whenever there is some
disagreement or a lot of disagreement up
on top there's a disagreement detected
text that becomes more intensely red the
greater the disagreement at the bottom
of the screen is the input to the neural
network that is a sequence of images
that are subtracted from each other
capturing the temporal dynamics of the
scene
all right so why is this interesting
there is two perception control systems
- AI systems taking in the external
world using a monocular camera and
making a prediction making steering
commands to control the vehicle now
whenever those two systems disagree
that's interesting for many reasons one
the disagreement is an indicator that
from a visual perspective from a
perception perspective the situation is
challenging for those systems therefore
you might want to bring the drivers
attention to the situation so they take
control back from the vehicle it's also
interesting for validating systems so if
you propose a new perception control
system you can imagine putting it into a
car to go along with autopilot or with
other similar systems to see how well
that new system works with autopilot 1in
disagrees when it doesn't and the
disagreement from the computer vision
aspect is also really interesting for
detecting edge cases so the challenge
you think about driving or for building
autonomous vehicles is that most of
driving is really boring the interesting
bits happen rarely so one of the ways to
detect those interesting bits the edge
cases is to look at the disagreement
between these perception systems to look
at cases when the two perception systems
diverge and therefore they struggle with
that situation finally when the driver
is controlling and takes control of the
vehicle which I am doing now and when my
steering decisions my turning of the
steering wheel is such that the neural
network disagrees it perhaps means that
I am either distracted or the situation
is visually challenging therefore I
should pay extra attention so it makes
sense for the system to warn you about
that situation
now the interesting thing about Tesla
and the autopilot system is that if we
instrument a lot of these vehicles as we
have we've instrumented 20 Tesla's as
part of the MIT autonomous vehicle study
and are collecting month
month after month year after year now
data video in and video out we can use
that data to train better systems to
Train perception systems control motion
planning and the end-to-end network that
we're showing today we have the
large-scale data to train the the
learning based perception and control
algorithms now an important thing to
mention is that these systems were
designed to work on the highway at
highway speeds
so the kind of disagreement is trained
to detect is disagreement between
autopilot and the neural network in
highway situations so the visual
characteristics of lane markings
deteriorating or construction zones and
so on now the details and if you're
interested in more can be found in a
paper titled arguing machines
you

----------

-----
--41--

-----
Date: 2018.05.29
Link: [# Christof Koch: Consciousness | Lex Fridman Podcast #2](https://www.youtube.com/watch?v=piHkfmeU7Wo)
Transcription:

as part of MIT course success zero nine nine on artificial general intelligence I got a chance to sit down with
Christophe Coe who's one of the seminal figures in neurobiology in neuroscience and
generally in the study of consciousness he is the president the chief scientific
officer of the Allen Institute for brain science in Seattle from 1986 to 2013 he
was the professor at Caltech before that he was at MIT he is extremely well sited
over a hundred thousand citations his research his writing his ideas have had
big impact on the scientific community and the general public in the way we think about consciousness in the way we
see ourselves as human beings he's the author of several books the quest for consciousness and your biological
approach and a more recent book consciousness confessions of a romantic reductionist if you enjoy this
conversation this course subscribe click the little bell I got to make sure you never miss a video and in the comments
leave suggestions for any people you'd like to see be part of the course or any
ideas that you would like us to explore thanks very much I hope you enjoy okay before we delve into the beautiful
mysteries of consciousness let's zoom out a little bit and let me ask do you
think there's intelligent life out there in the universe yes I do believe so we
have no evidence of it but I think the probabilities are overwhelming in favor of it give me a universe where we have 10 to
the 11 galaxies and each galaxy is between 10 to the 11 10 to the 12 stars
and we know more stars have one or more planets so how does that make you feel it still makes me feel special because I
have experiences I feel the world I experience the world and independent of
whether there are other creatures out there I still feel the world and I have access to this world in this very
strange compelling way and that's the core of human existence now he said
human do you think if those intelligent creatures are out there do you think they experience
their world yes they evolved if they are product of natural evolution if it would
have to be they will also experience their own world so consciousness isn't just a human your ID it's it's much
wider it's probably it may be spread across all of biology we have the only thing that we have special is we can
talk about it of course not all people can talk about the babies and little children can talk about the patients who
have have a Stoke and let's see the left inferior frontal gyrus can talk about it but most normal adult people can talk
about it and so we think that makes us special compared to little monkeys a dogs or cats or mice or all the other
creatures that we share the planet with but all the evidence seems to suggest that they to experience the world and so
it's overwhelmingly likely that other alien that aliens would also experience their world of course differently
because they have a difference in serum they've different sense of they had a very different environment but the fact
that I would strongly suppose that they also have experiences if your pain and
pleasure and see in some sort of spectrum and here and have all the other
sensors of course their language if they have one would be different so we might not be able to understand their poetry
about the experiences that they have that's correct right so in a talk in a
video I've heard you mention support so a DAC sound that you came up with
there you go up with as part of your family when you were young first of all you're a technically a Midwestern boy
you just secondly yes after that you
traveled around a bit and it's a little bit of the accent you talked about support so the DAC solid having these
elements of humaneness of consciousness that he discovered so I just wanted to
ask can you look back and you childhood and remember one was the first time you realized you yourself sort of from a
third-person perspective or our conscious being this idea of you know
stepping outside yourself and seeing well there's something special going on here in my brain I can't really actually
it's a good question I'm not sure I recall a discrete moment I mean you take it for granted because that's the only
world you know at the only world I know you know it's a world of seeing and hearing voices and
touching and all the other things so it's only much later at early in my
undergrad days when I became when I enrolled in physics and in philosophy that I really thought about it and
thought well this is really fundamentally very very mysterious and there's nothing really in physics right
now that explains his transition from the physics of the brain to feelings where do the feelings come in all right
so you can look at the foundational equation of quantum mechanics general relativity you can look at the period table of the elements you can look at
the endless 80g seat chat and our genes and no way is consciousness yet I wake
up every morning to a world where I have experiences and so that's the hub of the
ancient mind-body problem how do experiences get into the world so what
is consciousness experience consciousness is any any conte any
experience some people call it subjective feeling some people call it phenomenon phenomenology some people
call it quality of their philosophy all denote the same thing it feels like something in the famous word of as if a
loss at Thomas Nagel it feels like something to be a bad or to be a you know an American out to be angry or to
be sad or to be in love or to have pain and that is what experience is any
possible experience could be as mundane as just sitting in a chair could be as exalted as you know having a mystical
moment you know in in deep meditation those are just different forms of experiences experience so if you were to
sit down with maybe the next skip a couple generations of IBM Watson something that one jeopardy
what is the gap I guess the question is between Watson that might be much more
smarter than you then ask then all any human alive but may not have experience
what is the gap well so that's a big big question that's occupied people for the
last certainly last 50 years since we you know since he happened the birth of
of computers that's a question on chilling try to answer and of course he did it in this indirect way by proposing
its test and operational test so but that's not really that's you know he
tried to get it what does it mean for person to think and then he had this test like you lock him away and then you
have a communication with him and then you try to to guess after while whether that is a person or whether it's a
computer system there's no question that now or very soon you know Alexa or Siri or you know
Google now will pass this test right and you can game it but you know ultimately certainly in your generation
there will be machines that will speak with complete poise that will remember everything you ever said they'll
remember every email you ever had like like Samantha remember in the movie her yeah it's no question it's gonna happen
but of course the key questions is does it feel like anything to be Samantha in a movie home too does it feel like
anything to be Watson and there one has to be very very strongly think they're
two different concepts here that we call mingle there is the concept of intelligence natural or artificial and
there is a concept of consciousness of experience natural or artificial those are very very different things now
historically we associate consciousness with intelligence why because we live in
a world leaving aside computers of natural selection where we are surrounded by creatures either our own kin that are
less or more intelligent or we go across species some some are more adapted to
particular environment others are less a tablet whether it's a whale or dog or you go talk about a Paramecium or a
little worm alright and and we see the complexity of the nervous system goes from one cell to two specialized cells
to a worm that has three net that has 30% of its cells and nerve cells to creature like also like a blue whale
that ever has had a billion even more nerve cells and so they based on behavioral evidence and based on the
underlying neuroscience we believe that as these creatures become more complex they are better adapted to it to their
particular ecological niche and they become more conscious probably because
their brain calls and we believe consciousness unlike the ancient ancient people thought most almost every cult
thought that consciousness with intelligence has to do with your heart mm-hmm and you still to see that today
you see honey I love you is on my house yes but what you should actually say no honey I love you was all my lateral
hypothalamus and for Valentine's Day you should give you a sweetheart you know hypothalamic same piece of
chocolate another heart shaped chocolate right and you know so we still have this language but now we believe it's a brain and so we see brains of different
complexity and we think well they have different levels of consciousness they're capable of different experiences
[Music] but now we confront a world where we
know where we're beginning to engineer intelligence and it's radical unclear
whether the intelligence we're engineering has anything to do with consciousness and whether it can experience anything because
fundamentally what's the difference intelligence is about function intelligence no matter exactly how you
define it sort of an adaptation to new environments being able to learn and quickly understand you know you know the
setup of this and what's going on and who the actors and what's gonna happen next gets all about function consciousness is
not about function consciousness is about being it's in some sense much
fundamental you can see folks that you can see this in two in several cases you
can see it for instance in the case of the clinic when you're dealing with patients who are let's say had a stroke
or had were in traffic accident etc they're pretty much in mobile Terri
Schiavo you may have heard historically she was a person here in the in the 90s
in flora - heart Stood Still she was reanimated and for the next fourteen years she was what's called in a
vegetative state so there are thousands of people in a vegetative state so they're you know they're you know they're like this occasionally they open
their eyes for two three four five six eight hours and then close their eyes they have sleep-wake cycle occasionally
they have behavior they do you know there but there's no way that you can
establish a lawful relationship between what you see or the doctor says or the mom says and what the patient does
correctly so so the so the there isn't any behavior yet in some of these people
there is still experience you can you can design and build brain machine
interfaces where you can see there's they still explain something and of course at these cases of locked-in state
there's a famous book called that the diving bell and the butterfly well yet an editor French editor here the stroke
in the in the brainstem unable to move except his vertical eyes eye movement he
could just move his the eyes up and down and he dictated an entire book and some
people even lose this at the end it all the evidence seems to suggest that they're still in there in this case you
have no behavior your consciousness second cases tonight like all of us
you're gonna go to sleep close your eyes you go to sleep you will wake up inside your sleeping body and you will have
conscious experiences they are different from everyday experience you might fly you might not be surprised that you're
flying you might meet a long-dead pet childhood dog and you're not surprised that you're meeting them you know but
you have conscious experience of love of hate you know they can be very emotional your body during this stage typically to
them state sends an active signal to your motor neurons to paralyze you it's called atonia right because if you don't
have that like some patience what do you do you act out your dreams you get proximal and behavioral disorder which
is a bad which is bad juju to get okay third case is pure experience so I
recently had this what some people call a mystical experience I went to
Singapore and went into a flotation tank yeah alright so this is a big tub filled
was ever with water that's a body temperature and Epsom salt you still completely naked you lie inside of it
you close the layer Ignace complete darkness soundproof so very quickly you
become body less because you're floating and you're naked you have no rings no watch no nothing you don't feel your
body anymore it's no sound soundless there's no surf if a photon a sightless
timeless because after while early on you actually hear your heart but then that you you sort of adapt to that and
then sort of the passage of time ceases yeah and if you train yourself like in a
meditation not to swing early on you think aloud you it's a little bit spooky you feel somewhat uncomfortable or you
think well I'm gonna get bored but which I do not to think actively you become mindless so there you are body
less timeless you know sound less sightless mindless but you're in a
conscious experience you're not asleep you're not asleep you're you you are being of pure your pure being there
isn't any function you aren't doing any computation you're not remembering you're not projecting you're not planning yet you're fully conscious
you're fully conscious there's something going out there it could be just a side effect so what is the the you mean
epiphenomenon so what is the salaat effect meaning why what what what what
is the function of you being able to lay in this sense sensory free deprivation
tank and still have a conscious experience additionally myself obviously we didn't evolve with flotation tanks in our in
our environment I mean so biology is not totally bad at asking why question to
the nominal question why do we have two eyes why don't we have four eyes or three eyes or something well no there's
probably a there is a function to that but it's we're not very good at answering those questions we can
speculate endlessly where biology is very or science is very good about mechanistic question why is that charged in the universe right we find a certain
universe where there positive negative charges why why does quantum mechanics Hall you know what
why doesn't some other theory hold quantum mechanics hold in our universe is very unclear why so Tillie nominal
question why questions are difficult to answer clearly there's some relationship between complexity brain processing
power and consciousness but however in these cases in these three examples RK I
gave one is an everyday experience at night the other one is a young Tom on third one it's in principle you can
everybody can have these sort of mystical experiences you have a dissociation of function form of
intelligence from from conscious no consciousness you caught me asking a
white question let me ask a question that's not a white question you're giving a talk later today on the Turing
test for intelligence and consciousness drawing lines between the two so is there a scientific way to say there's
consciousness present in this entity or not and to anticipate your answer
because you also there's a neurobiological answer so we can test a human brain but if you take a machine brain that you
don't know tests for yet how would you even begin to approach a test if there's
consciousness present in this thing okay that's a really good question so let me take in two steps so as you point out
for for for for humans let's just stick with humans there's now a test called
the zap and zip it's a procedure where you ping the brain using transcranial magnetic stimulation you look at the
electrical reverberations essentially using EEG and then you can measure the complexity of this plain response and
you can do this in a way people in asleep normal people you can do it in a wake people and then anesthetize them
you can do it in patients and it's it it has hundred percent accuracy that in all
those cases when you're clear the patient or the person is either conscious or unconscious the complexity is either high or low and then you can
adopt these techniques to similar creatures like monkeys and dogs and and and mice that have very similar brains
now of course you you point out that may not help you because we don't have a cortex you know and if I send a magnetic
pulse into my iPhone or my computer it's probably gonna break something so we don't have that so what we need
ultimately we need a theory of consciousness we can't just rely on our
intuition our intuition is well yeah if somebody talks they're conscious however then they're all these page children
babies don't talk right but we believe that that the babies also have conscious experiences right and then there are
these patients I mentioned did and they don't talk when you dream you can't talk because you're paralyzed so so what
would we ultimately need we can't just rely on our intuition we need a theory of constants that tells us what is it
about a piece of matter what is it about a piece of highly excitable matter like the brain or like a computer that give
rise to conscious experience we all believe none of us believe anymore in the old story it's a soul but that used
to be the most common explanation that most people accept that in still a lot of people today believe well there's there's God and doubt only us was a
special thing that animals don't have Rene Descartes famously said a dog if he hit it with your carriage may Yelp me
cry but it doesn't have this special thing it doesn't have the magic the magic salt oh yeah
it doesn't have restaurants the soul now we believe that isn't the case anymore so what is the difference between brains
and and these guys silicon and in particular once a behavior matches so if
you have cereal of tea or Alexan 20 years from now that she can talk just as good as any possible human what counts
do you have to say she's not conscious in particular if she says it's of course he well cuz I'm conscious you are sir
are you doing and she'll say well you know they will generate some way to yeah she'll behave like a like a person now
there are several differences one is so this relates to the problem they're very
hard why is consciousness a hard problem it's because it's subjective right only I
have it for only I know I've direct experience of my own consciousness I
don't have experience your consciousness now I assume as a sort of Bayesian person who believes in probability
theory and all of that you know I can do I can do an abduction to the to the best available facts I deduce your brain is
very similar to mine if I put you in a scanner your brain is graphic on a behavior same with I do if if you know
if I give you this muesli and ask you how does it taste you tell me things that you know that that I would also say
more or less I yes so I infer based on all of that that you're conscious now we're silly I can't do that so there I really need a theory that tells me what
is it about above any system this or this it makes it conscious and we have
such a theory yes so the the integrator information theory is but let me first
maybe his introduction for people are not familiar the car can you you talked
a lot about pants psychism can you describe what physicalism versus dualism
this you mentioned the soul what what is the history of that idea what the idea
psychism although the debate really out of which pan site-- chasm can emerge of
dualism versus physicalism or do you not see pants psychism is fitting into that
and no you can argue there's some well ok so let's step back so kemp psychism is a very ancient belief that's been
around I mean Plato and us talks about it modern philosophers talk
about it of course in Buddhism the idea is very prevalent that I mean the
different versions of it one version says everything is in sold everything arcs and stones and dogs and people and
forests and iPhones all of us all right all matter is in soil that's sort of one version another version is that all
biology all creatures small a large from a single cell to a giant sequoia tree
feel like something that's one I think is somewhat more realistic so the different were willing me invite
feel like something I have have feeling have some kind of like some it may well
be possible that it feels like something to be a Paramecium I think it's pretty likely it feels like something to be a
bee or a mouse or dog sure so okay so so
that you can see that's also so pants item is very bored and you can to some
people for example Bertrand Russell try to advocate this for this idea it's
called gazelian monism that that pant psychism is really physics viewed from
the inside so the idea is that physics is very good at describing relationship
among objects like charges or like gravity all right you know this card the
relationship between curvature and mass distribution okay that's the relationship among thing physics doesn't really describe the ultimate reality
itself it's just relationship among you know quarks or all these other stuffs from like a third-person observer yeah
yes and consciousness is what physics feels from the inside so my conscious
experience it's a way the physics of my brain particular my cortex feel from the inside and so if you are Paramecium you
gotta remember you see Paramecium well that's a pretty dumb creature this but it has already a billion different
molecules probably you know five thousand different proteins assembled in
a highly highly complex system that no single person no computer system so far on this planet has ever managed to
accurately simulate its complexity vastly escapes us yes and it may well be that that little thing feels like a tiny
bit now it doesn't have a voice in the head like me it doesn't have expectations you know it doesn't have all that complex things but it may well
if you like something yep so this is really interesting can we draw some lines and maybe try to understand the
difference between life intelligence and consciousness how do you see all of
those if you have to define what is a living thing what is a conscious thing
and what is an intelligent thing do those intermix for you or they totally separate okay so a that's a question
that we don't have a full answer right after a lot of this stuff we're talking about today is full of mysteries and
fascinating ones right it was approximately can go to Aristotle who's probably the most important scientists
and philosophers ever lived in certainly in Western culture he had this idea it's called halo morphism it's quite popular
these days that there are different forms of soul the soul is really the form of something he saw he says all
biological creature have a vegetative soul that's life principle today we think we understand something molded
it's biochemistry nonlinear thermodynamics all right then he says they have a sensitive so only animals
and humans have also a sensitive soul or an appetitive soul they they can see they can smell and they have drives they
want to repeat use they want to eat etc and then only humans have what he called a rational soul okay right and that idea
that made it into christen dome and then the rational soul is the one that lives forever he was very young he wasn't
really I mean different readings of Aristotle give different was that did he believe that rational soul was immortal
or not I probably think he didn't but then of course that made it into its who Plato in the Christianity and then this
world became immortal and then became the connection where after to God now you so you ask me essentially you what
does our modern conception of these free Aristotle would have called them different forms life we think we know
something about it at least life on this planet right although we don't understand how to originate it but it's it's been difficult to rigorously pin
down you see this in modern definition of death it's in de facto right now
there's a conference ongoing again that tries to defined legally and medically what is death it
used to be very simple des is you stop breathing your heart stops beating you're dead right yeah totally unconverted
if you're unsure you wait another 10 minutes if the patient doesn't breathe you know he's well now we have ventilators we have
half a pacemaker so it's much more difficult to define what death is typically des is defined at the end of
life and life is defined before yes so before that okay so we don't have really
very good definitions intelligence we don't have a rigorous data definition we know something how to measure it's
called IG IQ or G factors right and and we're beginning to build it in in a
narrow sense right like go alphago and and and and Watson and you know Google
cars and uber cars and all of that that still narrow AI and some people are thinking about the artificial general
intelligence but roughly as we said before it's something lose ability to learn and to adapt to new environments
but that is as I said also it's radical difference from experience and it's very
unclear if you build a machine that has AGI it's not at all a priori it's not at
all clear that this machine will have consciousness it may or may not so let's ask it the other way do you think if you
were to try to build an artificial general intelligence system do you think figuring out how to build artificial
consciousness would help you get to an AGI so or put another way do you think
intelligent requires consciousness in human it goes hand in hand
in human or I think Ambala G consciousness intelligence goes hand in hand quite a solution because the the
brain evolved to be highly complex complexity via the theory integrated information theory is sort of ultimately
is what is closely tied to consciousness ultimately it's causal power upon itself and so in evolution evolved systems they
go together in artificial system particular in digital machines they do not go together and if you asked me
point-blank is Alexa 20 point O in the year 2041 she
can easily pass every Turing test is she conscious no even if she claims she's concerts in fact you could even do a
more radical version of this thought experiment we can build a computer simulation of the human brain you know
what Henry Markram in the Blue Brain Project or the human brain project in Switzerland is trying to do let's grant him all the success so
in ten years we have this perfect simulation of the human brain every new one is simulated in hasil Amex and it has motor neurons it
has a Ibaka's area and of course it'll talk and it'll say hi I just woken up I
feel great okay even that computer simulation that can imprint some map on to your brain will not be conscious why
because it simulates it's a difference between the simulated and the real so it simulates the behavior salted with
consciousness it might be it will if it's done properly will have all the intelligence that that particular person
they're simulating has but simulating intelligence is not the same as having conscious experiences and I'll give you
a really nice metaphor that engineers and physicists stupidly get I can write down in Stein's field equation nine or
ten equations that describe the link in general relativity between curvature and and mass I can do that I can run this on
my laptop to to predict that the sample the black hole at the center of our galaxy will be so massive that it will
twist space-time around it so no light can escape I it's a black hole right but funny have you ever won that why doesn't
this computer simulation suck me in alright it simulates gravity but it
doesn't have the causal power of gravity it's a huge difference so it's a difference between the real and and the
simulator just like it doesn't get wet inside the computer when the computer runs code that simulates a weather storm and so in order to have to have
artificial continents you have to give it the same causal power as a human brain yes you have to build so-called a
neuromorphic machine that has hardware that is very similar to the human brain not a digital clock for normal computer
so that's just to clarify though you think that consciousness is not required
to create human level intelligence it seems to accompany in the human brain
but for a machine not of court so maybe
just because this is AGI let's dig in a little bit about what we mean by intelligence so one thing is the G
factor these kind of IQ tests of intelligence but I think if you maybe
another way to say so in 2040 2050 people will have Siri that is
just really impressive do you think people will say serious intelligent yes
intelligence is this amorphous thing so it to be intelligent it seems like you
have to have some kind of connections with other human beings in a sense that you have to impress them with your
intelligence and their feels you have to somehow operate in this world full of
humans and for that there feels like there has to be something like consciousness so you think you can have
just the world's best natural NLP system natural language understanding a generation and that will be that will
get us happy and say you know what we've created an AGI I don't know happy no
well yes I do believe we can get what we call high-level functional intelligence
particular sort of the G you know this this fluid like intelligence that we
cherish particularly the place like MIT right in in in machines I see a boy I
know reasons and I see a lot of reason to believe it's gonna happen very you know over the next 50 years of 30 years
so for beneficial AI for creating an AI system that's so you mentioned ethics
that is exceptionally intelligent but also does not do does you know aligns
its values with our values as humanity do you think then in his consciousness yes I think that that is a very good
argument that if we're concerned about AI and the threat of a aisle and Nick Bostrom accidentally said I think having
an intelligent that has empathy right why do we find abusing a dog why do most
of us find that apartment abusing any animal right why do we find that apartment because we have this thing
called empathy which if you look at the Greek really means feeling with I feel a compass of empathy I have feeling with
you I see somebody else suffer that isn't even my conspecific it's not a person it's not a lot but it's not my wife or
my kids it's it's a dog but I feel naturally most of us not all of us most of us will feel emphatic and so it may
well be in the long-term interest of survival of Homo sapiens sapiens that if we do build AGI and it really becomes
very powerful that it has an emphatic response and doesn't just exterminate humanity so as
part of the full conscious experience to create a consciousness artificial or in
our human consciousness do you think fear maybe we're gonna get into the
earlier days with Mitch and so on but do you think fear and suffering are essential to have consciousness do you
have to have the full range of experience of it to have a system that has experience or can you have a system
that only has a very particular kinds of very positive experiences look you can have in principle you can people have
done this in the rat where you implanted electrode in the hypothalamus the pleasure center of the head and the rat
stimulated some above and beyond anything else it doesn't care about food or natural sex or drink anymore to
stimulate itself because it's it's such a pleasurable feeling I guess it's like an orgasm just you have you know all day
long and so a priori I see no reason why you need different forever I need a
great variety now clearly to survive that wouldn't work but if I'd engineered
artificially I don't think I don't think you need a great variety of conscious
expense you could have just pleasure or just fear it might be a terrible existence but I think that's possible at
least on conceptual logical count cause any real creature whether artificially engineered you want to give it fear the
fear of extinction that we all have and you also want to give it a positive appetitive states states that it wants
to that you want the Machine encouraged to do because if they give the Machine positive feedback so you mentioned
pants.i chasm to jump back a little bit you know everything having some kind of
mental property how do you go from there to something like human consciousness so
everything having some elements of consciousness - well is there something special about human consciousness what
so so just it's not everything like a spoon there's no I the the form of Pam
Jochum I think about doesn't ask I consciousness - anything like this the spoon my liver however it is the theory the
integrated information theory does say that system even ones that look from the outside relatively simple Atlee if they
have this internal causal power they are they it does feel like something the
theory a poet doesn't see anything what's special about human biologically we know what the one thing that special
about human is we speak and we have a overblown sense of our own importance
right we believe we exceptional and where does God's give - - into the universe but the
but behaviorally the main thing that we have we can plant we can plan over the long term and we have language and that
gives us enormous amount of power and that's why we are there the current dominant species on the planet
so you mentioned God you grow up a devout Roman Catholic you know Roman
Catholic family so you know with consciousness you're sort of exploring
some really deeply fundamental human things that religion also touches on so
where does where does religion fit into your thinking about consciousness and you've you've grown throughout your life
and changed your views and religion as far as I understand yeah I mean I'm now much closer to so I'm not a Roman
Catholic anymore I don't believe there's sort of this God the God I was I was educated to believe in you know sits
somewhere in the fullness of time I'll be united in some sort of everlasting bliss I just don't see any evidence for
that look the world the night is large and full of Wonders right there are many
things that I don't understand I think many things that we as a cult I look we don't even understand more than four
percent of all the universe right dark matter dark energy we have no idea what it is maybe it's lost socks what do I
know so so all I can tell you is it's a
sort of mom my current religious or spiritual sentiments much closer to some form of Buddhism can you - without the
reincarnation unfortunately there's no evidence for in reincarnation so can you describe the
way Buddhism sees the world a little bit well so the you know they talk about so when when I spent several meetings with
with the Dalai Lama and what always impressed me about him he really unlike for example at either the Pope was some Cardinal he
always emphasized minimizing the suffering of all creatures so they have this from the early beginning they look
at suffering in all creatures not just in people but in in everybody this universal and of course by degrees right
in an animal Jerell will have less is less capable of suffering than a then a well developed
normally developed human and they think consciousness pervades in this universe
and they have these techniques you know you can think of them like mindfulness etc and meditation that tries to access
sort of what they claim of this more fundamental aspect of reality I'm not sure it's more fundamentalist I think
about it there's a physical and then this is inside view consciousness and those are the two aspects that's the
only thing I've I have access to in my life and you gotta remember my conscious experience and your conscious experience
comes prior to anything you know about physics comes PI to knowledge about the universe and atoms and super strings and
molecules and all of that the only thing you directly are acquainted with is this world that's populated with with things
in images and and sounds in your head and touches on all of that I actually have a question so and it sounds like
you kind of have a rich life you talk about rock climbing and it seems like
you really love literature and consciousness is all about experiencing things so do you think that has helped
your research on this topic yes particular if you think about it the
the various states so for example you do our climbing or now I do oink-cool going and a bike every day you
can get into this thing called the zone and I've always I want to I want to Bob about a particular with respect to
consciousness because it's a strangely addictive state you want to you want to appear I mean once people have it once
you want to keep on going back to it and you wonder what is it so addicting about it and I think it's the experience of
almost close to pure experience because in this in the zone you're not conscious
over in a voice anymore but there's always this inner voice nagging you right you have to do this you have to do that you have to pay your taxes yet this
fight was your ex and all of those things are always there but when you're in the zone all of that is gone and your justice in this wonderful state
while you're fully out in the world a job you're climbing or you're hauling or biking or doing soccer what or whatever
you're doing and sort of consciousness sort of is is your all action or in this
case of pure experience you're not action at all but in both cases you experience some aspect of of can't you
touch some basic part of off of conscious existence that is so basic and
so deeply satisfying you I think you touch the root of being that's really
what you're touching there you're getting close to the root of being and that's very different from intelligence
so what do you think about the simulation hypothesis simulation theory the idea that we all live in a computer
simulation have you knowit's justice for her I think it's as likely as the
hypothesis had engaged hundreds of scholars for many centuries are we all just existing in the mind of God right
right and this is just a modern version of it it's it's it's it's equally plausible people love talking about
these sorts of things I know their book written is about the simulation hypothesis if that's what people want to do that's fine it seems rather esoteric
it's never testable but it's not useful for you to think of in those terms so maybe connecting to the questions of
free will which you've talked about I think vaguely wherever you saying that the idea that there's no free will it
makes you very uncomfortable so what do you think about free will and from that
you from a physics perspective or a consciousness perspective what is it all okay so from the physics perspective
leaving inside quantum mechanics we believe we live in a fully deterministic world right but then comes of course
quantum mechanics so now we know that certain things on principle not predictable which as you said I prefer
because the idea that at the initial condition of the universe and then everything else we're just acting out
the initial condition of the universe that doesn't that doesn't mean it's not a romantic notion no certainly not right
now when it comes to consciousness I think we do have certain freedom we are much more constrained by a physics of
course and by our past and by our own conscious desires and what our parents told us and what our environment tells us we we all
know that our there's hundreds of experiments that show how we can be influenced but finally in the in the
final analysis when you make a lifetime talk not really about critical decision what you really think should I marriage
should I go to this school that could should I take this job is that job should I cheat on my taxes or not these
sort of these are things what you really deliberate and I think under those conditions you are as free as you can be
when you when you bring your entire being anti conscious being to that
question and try to analyze it on all the the various condition and then you take you make a decision you are as free
as you can ever be that is I think what what free will is it's not a will that's totally free to do anything it wants
that's not possible right so as Jack mentioned yet you actually read a blog
about books you've read amazing books from I'm Russian from Bulgakov cha oh
yeah Neil Gaiman Carl Sagan Murakami so what is a book that early in your life
transformed the way you saw the world something that changed your life Nietzsche against did that spokes are
twister because he talks about some of these problems you know he was one of the first discoverer of the unconscious this is you know a little bit before for
it when it was in the air and you know he makes all these claims that people
sort of under the guise or under the mask of charity actually are very non charitable so he sort of really the
first discoverer of the great land of the of the unconscious and that that
really struck me and what do you think what do you think about the unconscious what do you think about Freud we think
about these ideas what's what's just like dark matter in the universe what's over there in that unconscious a lot I
mean much more than we think this is what a lot of last hundred years of research has shown so I think he was a
genius misguided towards the end but he was all he started out as a neuroscientist but he contributed he did
the studies on the on the lamprey he contributed himself to the neon
hypothesis the idea that there discreet units that we call nerve cells now and then he started then he he vote
you know about the unconscious and I think it's to there's lots of stuff happening you feel this particular when
you're in a relationship and it breaks a son alright and then you have this terrible you can have love and hate and
lust and anger and all of its mixed in and when you try to analyze yourself why am I so upset it's very very difficult
to penetrate to those basements those caverns in your mind because the prying
eyes of conscience doesn't have access to those but they're they are made in the amygdala or you know lots of other
places they make you upset or angry or sad or depressed and it's very difficult to try to actually uncover the reason
you can go to a shrink you can talk with your friend endlessly you couldn't start finally a story why this happened why you love you or don't
love or whatever but you don't really know whether that's actually the with that that actually happened because you
simply don't have access to those parts of the brain and they're very powerful you think that's a feature or a bug of
our brain the fact that we have this deep difficult to dive into subconscious I think it's a feature because otherwise
look we are we are see is like any other brain or nervous system or computer we
are severely band-limited if we if everything I do every emotion I feel
every my movements I make if all of that had to be another control of consciousness I couldn't I I couldn't I
wouldn't be here all right so so what you do early on your brain you have to
be conscious when you learn things like typing or like riding on a bike but then you what you do you train up or out I
think that involve basal ganglia and stratum you bear you train up different parts of your brain and then once you do
it automatically like typing you can show you do it much faster without even thinking about it because you've got this highly specialized what Francis
Crick and I called zombie agents that are sort of that taking care of that while your consciousness can sort of
worry about the abstract sense of the text you want to write and I think that's true for many many things but for
the things like all the fights you have with the ex-girlfriend things that you
would think are not useful to still linger somewhere in the sub conscious so that seems like a bug that
it would stay there you think it would be better if you can analyze it and then get it out of there or just forget it
ever happened you know that that seems a very buggy kind of well yeah but in
general we don't have and that's probably functional we don't have an ability unless it's extremely of cases
clinical dissociations right when people are heavily abused when they completely repress them they the memory but that
doesn't happen in in in you know in normal people if we don't have an ability to remove traumatic memories and
of course we suffer from that on the other hand probably if you had the ability to constantly wipe your memory
you probably do it to an extent that isn't useful to you so yeah it's a good question with the
balance so on the books is Jack mentioned correct me if I'm wrong but
broadly speaking in academia and the different scientific disciplines certainly an engineering reading
literature seems to be a rare pursuit perhaps I'm wrong in this but that's in
my experience most people are read much more technical text and do not sort of escape or seek truth in literature it
seems like you do so what do you think is the value what do you think literature asks the pursuit of
scientific truth do you think it's good it's useful for given access to much
wider array of human experiences how valuable do you think it is well if you
want to understand human nature and nature in general then I think you have to better understand wide variety of
experiences not just sitting in a lab staring at a screen and having a face flashed onto you've won a million
pushing a button that's what that's what I used to do that for most psychologists do there's nothing wrong with that but
you need to consider lots of other strange states you know and literature
is a shortcut for this well yeah as literature that's that's what literature is all about all sorts of interesting
experiences that people have the you know the contingency of it the fact that you know women experience what different
black people experience the world different and you know the one way to explain that is reading all these
different literature and try to find out you you see everything so relative read eBooks million years ago they
thought about certain problems very very differently than us today we today like any culture think we know it all that's
common to every culture every culture believes that at a day they know it all and then you realize well there's other
ways of viewing the universe and some of them may have lots of things in their favor so I this is a question I wanted
to ask about time scale or scale in general when you with IIT or in general
try to think about consciousness try to think about these ideas we kind of
naturally think in human timescales do you or and also entities that are
sized close to humans do you think of things that are much larger much smaller its containing consciousness and do you
think of things that take you know well is this you know it ages eons to uh to
operate in their conscious cause effect cause effect it's a very good question so I think a lot about small creatures
because experimentally you know a lot of people work on fly then and bees alright so and most people just think they are
tormented a this box for heaven's sake right but if you look at their behavior like bees they can recognize individual
humans they have this very complicated way to communicate if you've ever been involved or you know your parents when
they bought a house what sort of agonizing decision that is and bees have to do that once a year right when they
swarm in this spring and then they have this very lab that way they have three nut Scouts it did they go to the individual sites they come back there
this power this dance literally where they danced for several days they try to recruit other needs is that a complicated decision wait when they
finally want to make a decision the entire swarm the scouts warm up the entire swarm then go to one location
they don't go to fifty location they go to one location that the scouts have agreed upon by themselves that's awesome
if you look at the circuit complexity it's 10 times more denser than anything we have in our brain or the only of a
million neurons but then you know it's amazing complex complex behavior very complicated circuitry so there's no question they experience something their
life is very different they're tiny they only live you know for four workers live maybe for two months so I think IIT
tells you this in principle the substrate of consciousness is the substrate that maximizes the
cause-effect power over all possible space temple grains so when I think about for example do you know the science fiction
story the black cloud okay it's a classic by Fred Hoyle the astronomer he has this cloud intervening between the
earth and the sand the Sun and leading to some sort of to global cooling this
is written in the 50s it turns out you can using the the radio dish they communicate was actually an entity it's
actually an intelligent entity and they they sort of they convinced it to move away so here you have a radical
different entity and in principle IT says well you can measure the the integrated information in principle at
least and yes if that if the maximum of that occurs at a time scale of month rather than enough it sort of fraction
of a second yes and they would experience life where each moment is a month rather than or microsecond right
rather than a fraction of a second in in the human case and so there may be forms
of constants that we simply don't recognize for what they are because they are so radically different from anything
you and I are used to again that's why it's good to read or to watch science fiction what we want to think about this
like this is friend you know Stanislav LEM this polish science fiction writer he wrote Solaris I was turned into a
Hollywood movie yes his best novel it was in the 60s if there is a very ingenious and engineering background his most
interesting novel is called the victorious where human civilization they they they they they have this mission to
this planet and everything is destroyed and they discover machines humans got killed and then these machines took or
when there was a machine evolution a Darwinian evolution he talks about this very vividly and finally the dominant
they're the dominant machine intelligence organism that survive they're gigantic clouds of little
hexagonal Universal salata mater this is what in the Cygnus so typically they are
all lying on the ground individual by themselves but in times of crisis they can't communicate the assembly into
gigantic Nets into clouds trillions of these particles and then they become hyper intelligent and they can beat
anything that Youmans can can control at it it's a very beautiful and compelling where you have an intelligence where
finally the humans leave the planet they simply unable to understand and comprehend this creature
and they can say well either we can nuke the entire plan and destroy it or we just have to leave because fundamentally
it's an it's an alien it's so alien from us and our ideas that we cannot communicate with them
yeah actually in conversation so your talent US Steel or from brought up is
that there could be his ideas you know you already have these artificial
general intelligence like super smart or maybe conscious beings in the cellular Tom so we just don't know how to talk to
them so it's the language the communication because you don't know what to do with it so that's one sort of
view is consciousness there's only something you can measure so it's not
conscious if you can't measure it but so you're making an ontological and an epistemic statement one is there they
are it's it's just like seeing their multiverses that might be true but I can't communicate with them I don't have
I can't have any also that's an epistemic argument right so those are two different things so may well be possible look at not in other case
that's happening right now people are building these mini organoids do you know about this so you know you can take stem cells from under your arm
put in one dish add four transcription factors and then you can induce them to code to go into large or large they're a
few millimeters they're like a half a million neurons that look like matter of cells in a dish called mini organoids
at Howard at Stanford everywhere they're building them it may be well be possible that they're beginning to feel like
something but we we can't really communicate with them right now so people are beginning to think about the
ethics of this right so yes he may be perfectly right but they made its one
question are they conscious or not it's totally separate question how would I know those are two different things right if you could give advice to a
young researcher sort of dreaming of understanding or creating human level
intelligence or consciousness what would you say
follow your dreams read widely no I mean
I suppose what discipline what what is the pursuit that they should take on is it neuroscience this is a competition
cognitive science is it philosophy is a computer science or products
no in in a sense that okay so the only known system that have high level of
intelligence is Homo sapiens so if you wanted to build it it's probably good to continue to study closely what humans do
so cognitive neuroscience you know somewhere between cognitive neuroscience on the one hand and some philosophy of
mind and then ai ai computer science you can look at all the original ideas in
your network they all came from neuroscience right reinforcement whether it's snarky Minsky building is snarky or
whether it's you know the early supalen visa experiment that how about that then gave rise to networks and then multi-layer networks so it may well be
possible in fact some people argue that to make the next big step in AI once we'll realize the limits of deep
convolutional net works but they can do certain things but they can't really understand but they don't they don't
really can't really I can't really show them one image I can show you a single image of some knee a pickpocket who
steals a wallet from a purse you immediately know that's a big pocket right now computer system will just say
well it's a man it's a woman it's a purse right unless you train this machine on showing it a hundred thousand
pickpockets right so it doesn't it doesn't have this easy understanding that you have right so so some people
make yeah I mean in order to go to the next step or you really want to build machines that understand in a way you and I we have to go to psychology we
need to understand how we do it and our brains enable us to do it and so therefore being on the cusp it's also so
exciting I'd to try to understand better our nature and then to build to take some of those inside and build them so I
think the most exciting thing is somewhere in the interface between cognitive science neuroscience AI computer science and philosophy of mind
beautiful yeah I'd say if there is from the machine learning for from the computer science computer vision perspective many of the researchers kind
of ignore the way the human brain works nor even psychology or literature or studying the brain I would hope Josh
Tenenbaum talks about bringing that in more and more and that's yeah so you've
worked on some amazing stuff throughout your life what's the thing that you're really excited about what's the mystery
that you would love to uncover in the near term beyond beyond all the mysteries already
surrounded by well so there's a structure called the Klaus poem this is structures underneath our cortex
it's yay big you have one on the left am i right underneath this pie underneath a insula it's very sane it's like one
millimeter it's embedded in in wiring in white matters it's very difficult to image and it has it has connection to
every cortical region and Francis Crick the last paper you have of all he dictated Corrections the day he died in
hospital on this paper he now we hyper hypothesize well because it has this unique Anatomy it gets input
from every cortical area and projects back to every call every cortical area that the function of this structure is
similar that it's just a metaphor to work the role of a conducting and symphony orchestra
you've all the different cortical players you have some that do motion some they do theory of mind some that infer social interaction and color I'm
hearing and all the different modules and cortex but of course what consciousness is consciousness puts it
all together into one package like the binding problem all of that and this is really the function because it has a
relatively few nuance compared to cortex but it it talks it is all receive the input from all of them and it projects
back to all of them and so we are testing that right now we've got this beautiful neuronal reconstruction in the
mouse called crown of song and town of Thal nuan said there in the closed room that if the most widespread connection
of any nerve Neon I've ever seen they're very deep yeah you have individually on to sit in the clouds from tiny but then
they have this very single you have this huge axonal tree that cover both FC and contralateral cortex and and trying to
turn using you know fancy tools like optogenetics trying to turn those neurons on or off and study it what
happens in them in the mouse so this thing is perhaps where the parts become
the whole it very interface it's one of the structures it's a very good way of
putting it where the the individual parts turn into the whole of the whole of the conscious experience well with
that thank you very much for being here today thank you jack thank you much
you

----------

-----

--40--

-----
Date: 2018.05.25
Link: [# Ilya Sutskever: OpenAI Meta-Learning and Self-Play | MIT Artificial General Intelligence (AGI)](https://www.youtube.com/watch?v=9EN_HoEk3KY)
Transcription: 


Introduction
welcome back to 6 SZ row 99 artificial general intelligence today we have Ilya
sutskever co-founder and research
director of open AI he started in the amel group in Toronto Geoffrey Hinton then at Stanford with an jiaying
co-founded DNN research for three years as a research scientist at Google brain and finally co-founded open AI citations
aren't everything but they do indicate impact and his work recent work in the past five years has
been cited over forty six thousand times he has been the key creative intellect
and driver behind some of the biggest breakthrough ideas in deep learning and artificial intelligence ever
so please welcome Ilya alright thanks
Talk
for the introduction Lex alright thanks for coming to my talk I will tell you about some work we've done
over the past year on on meta learning and software open AI and before I dive
into some of the more technical details of the work I want to spend a little bit
of time talking about deep learning and why it works at all in the first place
which I think it's actually not a self-evident saying that they should work one fact it's actually a fact it's
a mathematical theory that you can prove is that if you could find the shortest
program the does very very well on your data then you will achieve the best
generalization possible with a little bit of modification you can turn it into a precise theorem
and on a very intuitive level it's easy to see what it should be the case if you
have some data and you're able to find a shorter program which generates this
data then you've essentially extracted all the all conceivable regularity from
this data into your program and then you can use these objects to make the best predictions possible like if if you have
data which is so complex but there is no way to express it as a shorter program
then it means that your data is totally random there is no way to extract any regularity from it whatsoever now there
is little known mathematical theory behind this and the proofs of these statements actually not even that hard
but the one minor slight disappointment is that it's actually not possible at
least given today's tools and understanding to find the best short program that explains or generates or
solves your problem given your data this problem is computationally intractable
the space of all programs is a very nasty space small changes to your
program result in massive changes in the behavior of the program as it should be it makes sense you have a loop you
change the inside of the loop of course you get something totally different so the space of programs is so hard at
least given what we know today search there seems to be completely off the table well if we give up on shorts on
short programs what about small circuits well it turns out that we are lucky it
turns out that when it comes to small circuits you can just find the best small circuits circuits that solves the
problem using back propagation and this is the miraculous fact on which the rest
of AI stands it is the fact but then you have a circuit and you impose
constraints on your circuits on your circuit using data you can find the way
to satisfy these constraints these constraints using that problem by iteratively making small changes
to the base of your neural network until its predictions satisfy the data what
this means is that the computational problem that so the back propagation is extremely profound it is circuit search
now we know that you can solve it solve it always but you can solve it sometimes
and you can solve it at those times where we have a practical data set it is
easy to design artificial data sets for which you cannot find the best neural network but in practice that seems to be
not a problem you can think of training a neural network as solving a neural
equation in many cases where you have a large number of equation terms like this
f of X I theta equals y I so you got your parameters and they represent all your degrees of freedom and you use
gradient descent to push the information from these equations into the parameters satisfy them all and you can see that
the neural network let's say one with 50 layers is basically a parallel computer
that is given 50 time steps to run and you can do quite a lot with a 15 with 50
time steps of a very very powerful massively parallel computer so for example I do I think it is not widely
known that you can learn to sort sort n
n bit numbers using a modestly sized neural network with just two hidden
layers which is not bad it's not self-evident especially since we've been
taught that sorting requires log n parallel steps with the neural network you can sort successful using only two
parallel steps so there's some things like an arm is going on now these are
parallel steps of threshold threshold neurons so they're doing a little bit more work let's answer to the mystery
but if you've got 50 such layers you can do quite a bit of logic quite a bit of reasoning all inside the neural network
and that's why it works given the data we are able to find the
best neural network and because the neural network is deep because it can run computation inside of its act inside
of its layers the best neural network is worth finding because that's really what
you need you need something you need the model class which is worth optimizing
but it also needs to be optimizable and deep neural networks satisfy both of these constraints and this is why
everything works this is the basis on which everything else resides now I want
to talk a little bit about reinforcement learning so reinforcement learning is a framework it's a framework of evaluating
agents in their ability to achieve goals and complicated stochastic environments
you've got an agent which is plugged into an environment as shown in the figure right here and for any given
agent you can simply run it many times and compute its average reward now the
thing that's interesting about the reinforcement learning framework is that there exist interesting useful
reinforcement learning algorithms the framework existed for a long time it
became interesting once we realized that good algorithms exist now these are there are perfect algorithms but they
are good enough to do interesting things and all you want the mathematical
problem is one where you need to maximize the expected reward now one
important way in which the reinforcement learning framework is not quite complete is that it assumes that the reward is
given by the environment you see this picture the agent sends an action while
the reward sends it an observation in a both the observation and the reward backwards that's what the environment
communicates back the way in which this is not the case in the real world is that we figure out
what the reward is from the observation we reward ourselves we are not told
environment doesn't say hey here's some negative reward it's our interpretation over census that lets us determine what
the reward is and there is only one real true reward in life and this is
existence or nonexistence and everything else is a corollary of that so well what
should our agent be you already know the answer should be a neural network because whenever you want to do
something dense it's going to be a neural network and you want the agent to map observations to actions so you let
it be parametrized with a neural net and you apply learning algorithm so I want to explain to you how reinforcement
learning works this is model free reinforcement learning the reinforcement learning has actually been used in practice everywhere but it's also deeply
it's very robust it's very simple it's also not very efficient so the way it
works is the following this is literally the one sentence description of what happens in short try something new add
randomness directions and compare the result to your expectation if the result
surprises you if you find that the results exceeded your expectation then
change your parameters to take those actions in the future that's it this is
the fool idea of reinforcement learning try it out see if you like it and if you do do more of that in the future and
that's it that's literally it this is the core idea now it turns out it's not
difficult to formalize mathematically but this is really what's going on if in a neural network in a regular neural network like this you might say
okay what's the goal you run the neural network you get an answer you compare it to the desired
answer and whatever difference you have between those two you send it back to change the neural network that's
supervised line in reinforcement learning you run in your own network you add a bit of randomness to your action
and then if you like the result your randomness turns into the desired target
in effect so that's it trivial now math
exists without explaining what these equations mean the point is not really
to derive them but just to show that they exist there are two classes of reinforcement learning algorithms one of
them is the policy gradient where basically what you do is that you take this expression right there the sum of
expected we work the sum of rewards and it just crunched through the derivatives you expand the terms iran you do some
algebra and you get a derivative and miraculously the derivative has exactly
the form that i told you which is try some actions and if you like them
increase the log probability of the actions that we truly follows from the math it's very nice when the intuitive
explanation has a one-to-one correspondence to what you get in the equation even though you have to take my
word for it if you are not familiar with it that's that equation at the top now there is a different class of
reinforcement learning algorithms which is a little bit more difficult to explain it's called the Q learning based algorithms they are a bit less stable a
bit more sample efficient and it has the property that it can learn not only from
the data generated by the actor but from any other data as well so it has it has
some rope but it has different robustness profile which would be a little bit important but it's only going
to be a technicality so yeah this is the own policy of policy distinction but
it's a little bit technical so if you find this hard to understand don't worry about it if you already know this then
you already know it so now what's the potential for enforcement learning wasn't it promised what is it actually
why should we be excited about it now there are two reasons the reinforcement learning algorithms of
today already useful and interesting and especially if you have a really good
simulation of your world you could train agents to do lots of interesting things
but what's really exciting is if you can build a super amazing sample efficient
out of reinforcement learning algorithm we just give it a tiny amount of data and the algorithm just crunches through
it and extracts every bit of entropy out of it in order to learn in the fastest way possible now today our algorithms
are not particularly efficient they are data inefficient but as our field keeps
making progress this will change next I want to dive into the topic of meta
learning the goal of meta learning so meta learning is a beautiful idea that
doesn't really work but it kind of works and it's really promising too it's another promising idea so what's the
dream we have some learning algorithms perhaps you could use those learning
algorithms in order to learn to learn I'd be nice if we could learn to learn
so how would you do that you will take a system which you train it not on one
task but on many tasks and you ask you that it learns to solve these tasks quickly and that may actually be enough
so here's how it looks like here's how most traditional metal earning look works like it looks like you have a
model which is a big neural network what what you do is that you treat every
instead of training cases you have training tasks and instead of test cases you have test tasks so your input may be
instead of just your current test case it would be all the information about the new T above the test tasks plus the
test case and you'll try to output the prediction reaction for that test case so basically you say yeah I'm going to
give you your ten examples as part of your input to your model figure out how to make the best use of them it's a
really straightforward idea u-turn the neural network into the learning algorithm by
turning a training task into a training case so training to ask a constraining
case this is meta learning just one sentence and so they've been several
success stories which I I think are very interesting one of the success stories
of meta learning is learning to recognize characters quickly so they've been a dataset
produced by MIT by lake corral and this
is a data set we have a large number of different handwritten characters and people have been able to train extremely
strong meta learning system for this desk another successful another very successful example of meta learning is
in that of neural architecture search by is openly from google where they found
neural architecture that solved one problem well small problem and then you could generalize and then if you
successfully solve large problems as well so this is the kind of the the small number of bits meta learning is
that when you learn the architecture or maybe even learn a program small program or learning algorithm which you apply to new tasks so this is the other way of
doing meta learning so anyway but the point is what's happening what's really happening in meta learning in most cases
is that you turn a training task into a training case and pretend this is
totally normal normal deep learning that's it this is the entirety of meta learning everything
else suggests minor details next I wanna dive in so now that I've finished the
introduction section I want to start discussing different work by different
people from opening I and I want to start by talking about hindsight experience replay it's been a large
effort by and recurvature all to develop a learning algorithm for reinforcement
learning that doesn't solve just one task but it
solves many tasks and it learns to make use of its experience in a much more efficient way and I want to discuss one
problem in reinforcement learning it's actually I guess a set of problems which all related to each other at one really
important thing you need to learn to do is to explore you're in that you start out in an environment you don't know
what to do what do you do so one very important thing that has to happen is that you must get rewards from time to
time if you try something and you don't get rewards then how can you learn so
said that's the kind of the crux of the problem how do you learn and relatedly is there any way to meaningfully benefit
from your ex from the experience from your attempts to from from your failures if you try to achieve a goal and you
fail can you still learn from it you tell you instead of asking your algorithm to achieve a single goal you
want to learn a policy that can achieve a very large family of goals for example instead of reaching one state you want
to learn a policy that reaches every state of your system and what's the implication anytime you do something you
achieve some state so let's suppose you say I want to achieve state a I try my
best and I end up achieving state B I can either conclude well that was
disappointing I haven't learned almost anything I'm still have no idea how to cheat how to achieve state aid but
alternatively I can say well wait a second I've just reached a perfectly good state which is B can I learn how to
achieve state B from my attempt to achieve state a an answer is yes you can and it just works and I just want to
point out this is the one case there is a small subtlety here which may be
interesting to those of you who are very familiar with on Part B the distinction between on policy and off policy when
you try to achieve a you are on you're doing on policy learning for reaching the state a but you're doing
off policy learning for it in the state be because you would take different actions if you would actually try to
reach they'd be so that's why it's very important that the algorithm you use here can support of policy learning but
that's a minor technicality at the crux the crux of the idea is you make the
problem easier by ostensibly making it harder by training a system which can
which aspires to reach to learn to reach every state to learn to achieve every goal to learn to master its environment
in general you build a system which always learn something it learns from
success as well as from failure because if it tries to do one thing one thing and it does something else
it now has training data for how to achieve that something else I want to show you a video of how this thing works
in practice so one challenge in reinforcement learning systems is the
need to shape the reward so what does it mean it means that at the beginning of the
system at the start of learning then the system doesn't know much it will probably not achieve your goal and so
it's important that you design your reward function to give it gradual increments to make it smooth and continuous so that even when the system
is not very good it achieves the goal now if you give your state your system a very sparse reward where the reward is
achieved only when you reach a final state then it becomes very hard for
normal reinforcement learning algorithms to solve a problem because naturally you never get the reward so you never learn
no reward means no learning but here because you learn from failure as well
as from success this is this problem simply doesn't occur and so this is this is nice I
think you know let's let's look at the videos a little bit more like it's nice how this is it confidently and
energetically moves the little green buck to its target and here's another one
you
okay so we can skip the it works on spawn on the face if you do it on physical robot as well but we can skip it so I think the point is that the
hindsight experience replay algorithm is directionally correct because you want
to make use of all your data and not only a small fraction of it now one huge
question is where do you get the high level states where do the high level
states come from because in the work of showing you so far
the system is asked to achieve low level States so I think one thing it will become very important for this kind
approaches is representation learning and unsupervised learning figure out what are the rights what are the right
states what's the state space of goals that's worth achieving now I want to go
through some real meta learning results and I'll show you a very simple way of
doing seem to reel from simulation to the physical robot with meta learning
and this is where my pain growl was an a and encouraged a really nice intern project in 2017 so I think we can agree
that in the domain of robotics it would be nice if you could train your policy
in simulation and then somehow this knowledge would carry over to the
physical robot now we can build we can
build simulators that are okay but they can never perfectly match the real world
unless you want to have an insanely slow simulator and the reason for that is that it turns out that simulating freaky
simulating contacts is super hard and I heard somewhere correct me if I'm wrong
that simulating friction is np-complete I'm not sure but it's like stuff like
that so your simulation is just not going to match reality there will be
some resemblance but that's it how can we address this problem and I want to show
you one simple idea so let's say one
thing once one thing that would be nice is that if you could learn a policy learn a policy that would quickly adapt
itself to the real world well if you want to learn a policy that can quickly
adapt we need to make sure it has opportunities to adapt during training time so what do we do instead of solving
a problem in just one simulator we add a huge amount of variability to the
simulator we say we will randomize the friction so we will randomize the masses
the length of the different objects and their I guess M dimensions so you try to
randomize physics they simulate in lots of different ways and then importantly
you don't tell the policy how you randomized it so what is it going to do
then you take your policy and you put it in an environment then says well this is really really tough I don't know what
the masses are and I don't know what the frictions are I need to try things out and figure out what the friction is as I
get it responses from the environment so you're building you you learn a certain
degree of adaptability into the policy and it actually works let's want to show you this is what
happens when you just strain a policy in simulation and deploy it on the physical robot and here the goal is to bring the
hockey puck towards the red dot and you will see that it will struggle and the
reason it struggles is because of the systematic differences between the simulator and the real physical robot so
I can even the basic movement is difficult for the policy because the assumptions are violated so much so if
you do the training as I discussed we train a recurrent neural network policy which learns to quickly infer properties
of the simulator in order to accomplish the task you can then give it the real
thing the real physics and it will do much better so now this is not a perfect
technique but it's definitely very promising it's promising whenever you are able to sufficiently randomize the
simulator so it's definitely very nice to see the closed-loop nature of the
policy you consider it would push the hockey puck and would correct it very very gently to bring it to the goal
yeah so that that was cool so that was
very that was a cool application of meta learning I want to discuss one more
application of meta learning which is learning a hierarchy of actions and this
was work done by France at all actually kept in France the ancient who did it
was in high school I mean he wrote this paper so one thing that would be nice is
if reinforcement learning was hierarchical if instead of simply taking
micro actions you've had some kind of little subroutines that you could deploy
maybe the term subroutine is a little bit too crude but if you had some idea of which action primitives are worth
starting with now no one has been able to to get actually like real value add
from curricula reinforcement learning yet so far all the really cool results all the really convincing is also
reinforcement learning do not use it that's because we haven't quite figured
out what's the right way for reinforcement learning for her ocular reinforcement learning I just want to show you one very simple
approach where you use meta-learning to
learn to learn a hierarchy of actions so here's what you do you have in this
specific work you have a certain yeah let's say you have a certain number of
low-level primitives let's say you have two ten of them and you have a distribution of tasks and your goal is
to learn low level primitives such that when they are used inside a very brief
run of some reinforcement learning algorithm you will make as much progress as possible so the idea is you want to
get the greatest amount of progress you want to learn policies that result in the great story you want to learn
primitives that result in the greatest amount of progress is possible when used inside learning so this is a meta
learning setter because any distribution of tasks and here we've had if we've had a little maze here the distribution of a
mazes and in this case the little bug learned three policies which move it in its fixed direction and as a result of
having this hierarchy you're able to solve problems really fast but only when the hierarchy is correct so horican reinforcement learning is
still working progress and this was an and this work is an interesting proof
point of how Haruko reinforcement could
be like how heretical reinforcement learning could be like if it worked now
I want to just spend one slide addressing the limitations of high
capacity method learning the specific limitation is that the training test
distribution has to be equal to the test test distribution and I think this is a
real limitation because in reality you the new test that you want to learn do
in some ways being fundamentally different from anything you've seen so
far so for example if you go to school you learn lots of useful things but then
they go to work only a fraction of this of the things that you've learned carries over you need to learn if you
need quite a few more things from scratch so metal owning would struggle
with that because it really assumes that the Train the training data is that the distribution over the training task has
to be equal to the distribution of the test tasks that's the limitation I think that as we develop better algorithms for
being robust when the test tasks outside
of the distribution of the training tasks the metal on would work much better now I want to talk about self
play the links of play is a very cool topic that's starting to get attention
only now and I want to start by reviewing very old work called TD gammon
it's back from all the way from 1992 so it's 26 years old now it was done by
Jerry to cero so this work is really incredible because it has so much
relevance today what they did basically they said okay let's take two neural
networks and let them let them play against each other let them play
backgammon against each other and let them in tray let them be trained particularly so it's a super-modern
approach and you would think this was a paper from 2017 except that then you
look at this plot it shows that you only have ten hidden units twenty hidden units forty and eighty for the different
M colors where you notice that the largest neural network works best so in
some ways not much has changed and this is the evidence and in fact they were able to beat the
world champion in backgammon and they were able to discover new strategies that the best human a backgammon players
weren't ever not noticed and they've determined that the strategy discovered
by TD gammon actually better so that's pure self play with cue learning which is which remained dormant
until the DQ and work with Atari mid mind so now other examples of self play
include alphago zero which was able to learn to beat the world champion and go
without using any external data whatsoever another result of this vein
is by open AI which is our dota 2 BOTS which was able to build the world champion on the 1v1 version of the game
and so I want to spend a little bit of time talking about the allure of self
play and why I think it's exciting so
one important problem that's a that that's that we must face as we try to
build truly intelligent systems is what is the task what are we actually
teaching the systems to do and one very attractive attribute of self play is
that the agents create the environment
by virtue of the agent acting in the environment the environment becomes
difficult for the other agents and you can see here an example of an iguana interacting with snakes that try to eat
it unsuccessfully this time so we can see what will happen in a moment the iguana
strains best and so the fact you have this arms race between the snakes and
the iguana motivates their development potentially without bound and this is what happens
in effect in but in biological evolution now interesting work in this direction
was done in 1994 but Carl says there is a really cool video on YouTube by Carl
seems you should check it out which really kind of shows all the work that he's done and here you have a little
competition between agents where you evolved both the behavior and their morphology when you when the agents is
trying to gain possession of a green cube and so you can see that the agents
create the challenge for each other and that's why they need to develop so one
thing that we did and this is work by advance a little from open ai is we said
okay well can we demonstrate some unusual results in self play that would
really convince us that there is something there so what we did here is that we created a small a small ring and
you have these two humanoid figures and their goal is just to push each other outside the ring and they don't know
anything about wrestling they don't know anything about standing your balance in each other they don't know anything about centers of gravity all they know
is that if you don't do a good job then your competition is going to do a better job now one of the really attractive
things about self play is that you always have an opponent that's roughly
as good as you are in order to learn you need to sometimes win and sometimes lose
but you can't always win sometimes you must fail sometimes you must succeed so
let's see what will happen here yeah so it was able to do so the green humanoid
was able to block the ball in a Cell in a well balanced self play environment
petition is always level no matter how good you are or how bad you are you have
a competition that makes it exact exactly of exactly the right challenge for you on one thing here so this video
shows transfer learning it takes a little wrestling humanoid and you take its friend away and you start applying a
big large random forces on it and you see if it can maintain its balance and the answer turns out to be but yes it
can because it's been trained against an opponent it pushes it and so that's why
even if it doesn't understand where the fresh force is being applied on it it's still able to balance itself so this is
one potentially attractive feature of subway environments that you could learn a certain broad set of skills although
it's real hard to control the square the skills will be and so the biggest open question with this research is how do
you learn agents in a software environment such that they do whatever
they do but then they are able to solve a battery of tasks that is useful for us that is explicitly specified externally
yeah I also want to want to highlight
one attribute of self play environments that we've observed in our dota BOTS and
that is that we've seen a very rapid increase in the competence of the bots so over the period over the course of
maybe five months we've seen the bots go from playing totally randomly all the
way to the world champion and the reason for that is that once you have a self
play environment if we put compute into it you turn it into data self play
allows you to turn compute into data and I think you will see a lot more of that as being an extremely important thing to
be able to turn compute into essentially data generalization simply because the
speed of neural net processors will increase very dramatically over the next few years so neural net cycles will be
cheap and it will be important to make use of this new of newly-found overabundance of cycles
I also want to talk a little bit about the endgame of the self approach so one
thing that we know about the human brain is that it has increased in sized fairly
rapidly over the past two million years my theory the reason I think it happened
is because our ancestors got to a point where the thing that's most important
for your survival is your standing in the tribe and less the tiger and the
lion once the most important thing is how you deal with those other things
which have a large brain then it really helps to have a slightly larger brain and I think that's what happened and
there exists at least one paper from science which supports this point of view so apparently there has been
convergent evolution between social apps and social Birds even though in terms of
various behaviors even though the divergence in evolutionary timescale
between humans and birds has occurred a very long time ago and humans and humans
apes and humans apes and birds have very different brain structure so I think
what should happen if we succeed if we successfully follow the path of this approach is that you should create a
society of agents which will have language and theory of mind negotiation
social skills trade economy politics justice system all these things should
happen inside the multi-agent environment and it will also be some alignment issue of how do you make sure
that the agents we learn behave in a way that we want now I want to make a
speculative digression here which is I want to make the following observation
if you believe that this kind of society of agents is a plausible place where
truly where the fuller fully general intelligence will emerge and if you
accept that our experience with the dota BOTS we've seen a very rapid increase in
competence will carry over once all the details are right if you assume both of these conditions then it should follow
that we should see a very rapid increase in the competence of our agents as they live in the Society of agents so now
that we've talked about a potentially interesting way of increasing the
competence and teachings of an agent's social skills and language and a lot of things that actually exist in humans as
well we want to talk a little bit about how you convey goals to agents and the
question of the main goal to eight calls to agents is just a technical problem but it will be important because it is a
lot more likely than not that the agents of evil train will eventually be
dramatically smarter than us and this is work by the opening eye safety team by
Paul Christiana at all and others so I'm just going to show you this video which
basically explains how the whole thing works you there is some behavior looking
for and you the human gets to see pairs of behaviors and you simply click on the
one that looks better and after a very
modest number of clicks you can get this little simulated leg to do back flips
and there
go picking out the back flips and in this to get this specific behavior it took about 500 clicks by human
annotators the way it works is that you take all the so this is a very data
efficient reinforcement learning algorithm but it is efficient in terms of rewards and not in terms of the
environment interactions so what you do here is that you take all the clicks so you've got your here is one B here which
is better than other you fit a reward function a numerical reward function to
those clicks so you want to fit a reward function which satisfies those clicks clicks and you optimize this reward function with reinforcement learning and
it actually works so this requires 500 bits of information you've also been
able to train lots of Atari games using several thousand bits of information so in all these cases you had human and
human annotators or human judges just like in the previous slide looking at
the pairs of trajectories and clicking on the one that they thought was better and here's an example of an unusual goal
where this is a car racing game but the goal was to ask the the agent to train
the white car drive right behind the orange car so it's a different goal and
it was very straightforward to communicate this goal using this approach so then to finish off alignment
is a technical problem it has to be solved but of course the determination of the correct goals we want array
assistance the systems to have will be a very challenging political problem and on this note I want to thank you so much
for your attention and I just want to say that will be a happy hour at Cambridge Brewing Company at 8:45 if you
want to chat more about AI and other topics please come by I think that deserves an applause
so back propagation is a or neural networks of bio-inspired but back
Q&A
propagation doesn't look as though it's what's going on in the brain because signals in the brain go one direction
down the axons whereas back propagation requires the errors to be propagated back up the the wires so can you just
talk a little bit about that whole situation where it looks as the brain is doing something a bit different than our
highly successful algorithms our algorithm is going to be improved once we figure out what the brain is doing or
is the brain really sending signals back even though it's got no obvious way of doing that what's what's happening in
that area so that's a great question so first of all I'll say that the true answer is that the honest answer is that
I don't know but I have opinions and so I'll say two things
but first of all given that look if you agree if we agree like so rather it is a
true fact the back propagation solves the problem of circuit search this
problem feels like an extremely fundamental problem and for this reason I think that it's unlikely to go away
now you also write that the brain doesn't obviously do back propagation although they've been multiple proposals
of how it could be how it could be doing them for example there's been a work by
Tim little crap and others where they've shown that if you use that it's possible to learn a different set of connections
but can be used for the backward pass and that can result in successful learning now the reason this hasn't been
like really pushed to the limit by practitioners is because they say well I got TF to the gradients I'm just not
going to worry about it but you are right this is an important issue and you know one of two things is going to
happen so my personal opinion is that back propagation is just going to stay with us till the very end and will
actually build fully human level and beyond systems before we understand how the brain does what it does so that's
what I believe but of course it is a difference that has to be acknowledged
okay thank you do you think it was a fair matchup for the dota bot and that
person given the constraints of the system so I'd say that like the biggest advantage computers have in games like
this like one of the big advantages is that they obviously have a better reaction time although in DotA in
particular the number of clicks per second over the top players is fairly
small which is different from Starcraft so in Starcraft stuff up is a very compact mechanically heavy game because
of a large number of units and so the top players that is click all the time in DotA every player controls just one
hero and so that greatly reduces the total number of actions they need to make now still precision matters I think
that will discover that but what I think it'll really happen is if you'll
discover that computers have the advantage in any domain or rather every
domain not yet so do you think that the emergent behaviors from the agent were
actually kind of directed because the constraints already kinda in place like so it was kind of forced discover those
or do you think that like that was actually something quite novel that like wow it actually discovered these on its
own like you didn't actually am biased towards constraining it so it's definitely discover new strategies and I
can share an anecdote where our tester we have a probe which would test the bots and he played against for a long
time and the bots would do all kinds of things against the player the human player which were effective then at some
point that Pro decided to play against the better plot Pro and he decided to
imitate one of the things that the bot was doing and this image but by imitating if he was able to defeat a
better pro so I think I think the strategy discovers are real and so like it means that like this very real
transformative Tran you know I would say I think what that means is that he
because the strategies discovered by the bot of the humans it means that we like a fundamental game plays deeply related
for a long time now I've heard that the objective of reinforcement learning is
to determine a policy that chooses an action to maximize the expected reward
which is what you said earlier would you ever want to look at the standard deviation of possible rewards does that
even make sense yeah I mean I think for sure I think it's a really application dependent one of the reasons to maximize
the expected reward it's because it's easier to design algorithms for it so you write down this equation the
formula you do a little bit of derivation you get something which amounts to a nice-looking algorithm now
I think there exist like really there exist applications where you'd never
want to make mistakes and you want to work on the standard deviation as well but in practice it seems that the just
looking at the expected reward covers a large fraction of the B the situation as
you'd like to apply this door Thanks
we talked last week about motivations and that has a lot to do with the
reinforcement and some of the ideas is that the our motivations are actually
connection with others and cooperation and I'm wondering if they're thrown off
and I understand it's very popular to have the computers play these competitive games but is there any use
in like having an agent self play collaboratively collaborative games Yeah
right that's an extremely good question I don't think one place from which we
can get some inspiration is from the evolution of cooperation like I think cooperation like we
cooperate ultimately because it's much better for you the person to be cooperative than not and so I think what
should happen if you have a sufficiently open-ended game then cooperation will be the
winning strategy and so I think we will get cooperation whether we like it or not Hey
you mentioned the complexity of this simulation of friction I was wondering
if you feel that there exists open complexity theoretic problems relevant to relevant to AI or whether it's just a
matter of finding good approximations that humans of the types of problems that humans tend to solve yeah so
complexity theory well like at a very basic level we know that whatever
algorithm we gonna run is going to run fairly efficiently on some hardware so
that puts a pretty strict upper bound and the true complexity of the problems
we're solving but by definition we are solving problems which aren't too hard in a complexity theoretic sense now it
is also the case that many of the problems so while the overall thing that
we do is not hard from a complexity theory makes sense and indeed humans cannot solve np-complete problems in
general it is true that many of the like optimization problems that we pose to
our algorithms are intractable in the general case starting from a neural net optimization itself it is easy to create
a family of data sets for a neural network with a very small number of neurons such that find a global optimum
is np-complete and so how do we avoid it well we just try gradient descent anyway
and somehow it works but without question like we cannot we do not solve
problems which are truly intractable so I mean I hope this answer the question
hello it seems like an important sub-problem on the path towards AGI will be
understanding language and the state of generative language modeling right now is pretty abysmal what do you think are
the most productive research trajectories towards generative language models so
I'll first say that you are completely correct that the situation with language is still far from great although
progress has been made even without any particular innovations beyond models
that exist today simply scaling up models that exist today on larger datasets is going to go surprisingly far
not even large datasets but larger and deeper models for example if you trained a language model be the thousand layers
and it's the same layer I think it's gonna be a pretty amazing language model
like we don't have the cycles for it yet but to think it will change very soon now I also agree with you that there are
some fundamental things missing in a current understanding of deep learning
which prevent us from really solving the problem that we want so I think one of
these problems one of the things that's missing is that or that seems like patently wrong is the fact that we train
a model then you stop training the model and you freeze it even though it's the
training process where the magic really happens but the magic is that if you
think about it like the training process is the true general part of the whole of
the whole of the whole story because you tends to flow code doesn't care which data set to optimize it just says
whatever just give me the data set I don't care which one solve I'll sew them all so like the ability to do that feels
really special and I think we are not using it at test time like it's hard to
speculate about like things which you don't know the answer but all I'll say is that simply train bigger deeper
language models you'll go surprisingly far scaling up but also doing things
like training a test them and inference the test time I think would be another important boosts the performance hi
thank you for the talk so it seems like right now another interesting approach to solving reinforcement learning
problems could be to go for the evolutionary roots using evolutionary strategies and although they have they
their cave Hut's I wanted to know if I'd open a I particularly you're working on something related and what are what is
your general opinion on them so like at present I believe that
something evolutionary strategies is not great for reinforcement learning I think that normal reinforcement learning
algorithms especially with big policies are better but I think if you want to evolve a small compact object like like
a piece of code for example I think that would be a place where this would be seriously was considering but this all
you know evolving a beautiful piece of code is a cool idea hasn't been done yet
so still a lot of work to be done before we get there hi thank you so much for coming my question is you mentioned what
is the right go is a political problem so I'm wondering if you can elaborate a bit on that and also what do you think
would be their approach for us to maybe get there well I can't I can't really
comment too much because all the thoughts that you know we have we now have a few people who are thinking about
this full-time at opening I I don't have enough of a super strong opinion to say
anything too definitive all I can say at the very high level is given the size
like if you go into the future whenever soon or late you know whenever it's going to happen when you build a
computer which can do anything better than a human it will happen because the
brain is physical the impact on society is going to be completely massive and
overwhelming it's it's very difficult to imagine even if you try really hard and
I think what it means is that people who care a lot and that's what I was
alluding to the fact that this will be something that many people who care about strongly and like as the impact
increases gradually with self-driving cars more automation I think we will see a lot more people care do we need to
have a very accurate model of the physical world and then simulate that in
order to have these agents that can eventually come out into the real world and do something approaching you know
human level intelligence tasks that's a very good question so I think if that
were the case be in trouble and I am very certain that
it could be avoided so specifically the real answer has to be that look you
learn the problem so we learn to negotiate you learn to persist you not a lots of different useful life lessons in
the simulation and yes you learn some physics too but then you go outside to the real world and you have to start over to some
extent because many of you are deeply held assumptions will be false in one of the goals so what was that's one reasons
I care so much about never stopping training you've accumulated your knowledge now we go into an environment
for some of your assumptions of valid you continue training you try to connect the new data to your old data and this is an important requirement from our
algorithms which is already met to some extent but it will have to be met a lot more so that you can take the partial
knowledge if you've acquired then go in a new situation learn some more literally the example of you go to
school ballon useful things then you go to work it's not a perfect it's not you know you pour your four years of CS and
undergrad is not going to fully prepare you for whatever it is you need to know it work it will help somewhat you'll be able to
get off the ground but it will be lots of new things you need to learn so that's that's the spirit of it I think of a toes of the school one of the
things you mentioned pretty early on in your talk is that one of the limitations of this sort of style of reinforcement
learning is there's no self-organization so you have to tell it when it did a good thing or did a bad thing and that's
actually a problem in neuroscience is when you're trying to teach a rat to you know navigate maze you have to artificially tell it what to do so where
do you see moving forward when we already have this problem with teaching you know not necessarily learning but also teaching so where do you see the
research moving forward in that respect how do you sort of introduce this notion of self-organization so I think without
question one really important thing you need to do is to be able to infer the
goals and strategies of other agents by observing them that's a fundamental skill we need to be able to learn to to
embed into the agent so if for example you have two agents one of them is doing something and the other agent says well
that's really cool I want to be able to do that too and you go and do that and so I'd say that this is a very important component in
terms of second every word oh you see what they do you infer the reward and
now we have a knob which says you see what they're doing now go and try to do the same thing let's say this this is as far as I know
as far as I know this is was one of the important ways in which humans are quite
different from other animals in way which in the like scale and scope in
which we copy the behavior of other humans might ask a quick follow-up work go for it so that's kind of obvious how
that works in the scope of competition but what about just sort of arbitrary tasks like I'm in a math class for
someone and I see someone doing a problem a particular way and I go that's a good strategy maybe I should try that out how does that work in a sort of non
competitive environment so I think that this will be I think that's going to be a little bit separate from the
competitive environment but it will have to be somehow either way you know
probably baked in maybe volved into the system where like if you have other
agents doing things they're generating data which you observe and the only way
to truly make sense of the data that you see is to infer the goal of the agent the strategy their belief state that's
important also for communicating them if you want to successfully communicate with someone you have to keep track both
of their goal and of their belief state instead of knowledge so I think you will find that there are many I guess
connections between understanding what other agents are doing inferring their goals imitating them and community
successfully communicating them all right let's give in the happy hour a big hand [Applause]
you [Applause]
you

----------

-----
--39--

-----
Date: 2018.04.19
Link:   [# Max Tegmark: Life 3.0 | Lex Fridman Podcast #1](https://www.youtube.com/watch?v=Gi8LUnhP5yU)
Transcription:


Introduction
as part of MIT course six as $0.99 artificial general intelligence I've gotten the chance to sit down with max
tegmark he is a professor here at MIT is a physicist spent a large part of his
career studying the mysteries of our cosmological universe but he's also
studied and delved into the beneficial possibilities and the existential risks
of artificial intelligence amongst many other things he's the co-founder of the
future of life Institute author of two books both of which I highly recommend first our Mathematica universe
second is life 3.0 he's truly an out-of-the-box thinker and fun
personality so I really enjoyed talking to him if you would like to see more of these videos in the future please subscribe and also click the little bell
icon to make sure you don't miss any videos also Twitter linked in AGI that
MIT that I do if you want to watch other lectures or conversations like this one
better yet go read Max's book life 3.0 chapter 7 on goals is my favorite it's
really where philosophy and engineer and come together and it opens with a quote by dusty s key the mystery of human
existence lies not and just stayin alive but in finding something to live for lastly I believe that every failure
rewards us with an opportunity to learn in that sense I've been very fortunate
to fail in so many new and exciting ways and this conversation was no different
I've learned about something called radio frequency interference or RFI look
it up apparently music and conversations from local radio stations can bleed into the audio that you're recording in such a
way that almost completely ruins that audio it's an exceptionally difficult sound source to remove so I've gotten
the opportunity to learn how to avoid RFI in the future during recording
sessions of also gotten the opportunity to learn how to use Adobe Audition and isotope rx6 to do some noise some
audio repair of course this is exceptionally difficult noise to remove I am an
engineer I'm not an audio engineer neither is anybody else in our group but we did our best
nevertheless I thank you for your patience and I hope you're still able to
enjoy this conversation do you think there's intelligent life out there in the universe let's open up with an easy question I
Are there intelligent life out there
have a lien minority of you here actually when I give public lectures Alfred asked for show of hands who
thinks there's intelligent life out there somewhere else and almost everyone put their hands up and when I ask why
they'll be like oh there's so many galaxies out there there's gonna be but
I'm a numbers nerd right so when you look more carefully at it it's not so
clear at all if we when we talk about our universe first of all we don't mean all of space did we actually mean I
We dont mean all of space
don't you can throw me in the universe if she wants behind you there it's we simply mean the spherical region of
space from which light has a time to reach us so far during the fourteen
point eight billion year 13.8 billion years since our Big Bang there's more space here but this is what we call a
universe because that's all we have access to mm-hmm so is there intelligent life here that's gotten to the point of
building telescopes and computers my guess is no actually no the probability
of it happening on any given planet is some number we don't know what it is and
what we do know is that the number can't be super-high because there's over a
billion earth-like planets in the Milky Way galaxy alone many of which are
billions of years older than Earth and aside from some UFO believers in other
reason is much evidence that any super 20 civilization has come here at all and so that's the famous Fermi paradox right
and then if you if you work the numbers what you find is that if you have no
clue what the probability is of getting life on a given planet could be 10 to the minus 10 and the
minus 20 or 10 minus to any power tensor equally likely if you want to be really
open-minded that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away 10
to the 17 meters away 10 to the 18 now by the time he gets much less than than
10 to the 16 already we pretty much know there is nothing else that's close and
when you get the other would have discovered us they yeah they would have been discovered as long or if they're really close we would have probably know
that some engineering projects that they're doing and if it's beyond 10 to the 26 meters that's already outside of
here so my guess is actually that there are we are the only life in here they've
gotten the point of building advanced tech which i think is very um puts a lot
of responsibility on our shoulders not screw up you know I think people who take for granted that it's okay for us
to screw up have an accident in a nuclear war or go extinct somehow because there's a star trek-like
situation out there with some other life forms are gonna come and bail us out and doesn't matters what I think they're
lulling us into a false sense of security I think it's much more prudent to say you know let's be really grateful
for this amazing opportunity we've had and make the best of it just in case it
Intelligent life
is down to us so from a physics perspective do you think intelligent
life so it's unique from a sort of statistical view of the size of the universe but from the basic matter of
the universe how difficult is it for intelligent life to come about the kind of advanced tech building life I in is
implied in your statement that is really difficult to create something like a human species well I think I think what
we know is that going from no life to having life that can do ARCA a level of
tech there's some sort of - going beyond that than actually settling our whole
universe with life there is some road major roadblock there which is
great filter as that's sometimes called which which tough to get through it's
either that roadblock is either beef behind us or in front of us I'm hoping
very much that it's behind us I'm super excited every time we get a new report
from NASA saying they failed to find any life on Mars like just awesome because that suggests
that the hard part maybe what maybe he was getting the first ribosome or or some some very low-level kind of
stepping stone so they were home free cuz if that's true then the future is
really only limited by our own imagination it'd be much luckier if it turns out that this level of life is
kind of a dime a dozen but maybe there is some other problem like as soon as a civilization gets advanced technology
within a hundred years they get into some stupid fight with themselves and poof yeah no that would be a bummer yeah so you've explored the mysteries of
Space and intelligence
the universe the cosmological universe the one that's sitting between us today
I think you've also begun to explore the other universe which is sort of the
mystery the mysterious universe of the mind of intelligence of intelligent life
so is there a common thread between your interest or in the way you think about space and intelligence oh yeah when I
was a teenager yeah I was already very fascinated by the biggest questions and
I felt that the two biggest quite mysteries of all in science where our universe out there and our universe in
here yeah so it's quite natural after having spent a quarter of a century on
my career thinking a lot about this one I'm now indulging in the luxury of doing research on this one it's just so cool I
feel the time is right now for you Trane's greatly deepening our
understanding of this just start exploring this one yeah because I think I think a lot of people view intelligence as something mysterious
that can only exist and biological organisms like us and therefore dismiss
all talk about artificial general intelligence is science fiction but from my perspective as a physicist
you know I am a blob of quarks and electrons moving around in a certain
pattern and processing information in certain ways and this is also a blob of quarks and electrons
I am NOT smarter than the water bottle because I'm made of different kind of works I'm made of up quarks and down
quarks exact same kind as this it's a there's no secret sauce I think in me
it's all about the pattern of the information processing and this means
that there's no law of physics saying the way that we can't create technology which can have helped us by being
incredibly intelligent and helped us crack mysteries that we couldn't in other words I think we really only seen the tip of the intelligence iceberg so
far yeah so the perceptron ium yeah so
you can't go in this amazing term it's a hypothetical state of matter sort of thinking from a physics perspective what
is the kind of matter that can help as you're saying a subjective experience emerged consciousness emerge so how do
you think about consciousness from this physics perspective very good question
so again I think many people have
underestimated our ability to make progress on this and by convincing
themselves it's hopeless because somehow we're missing some ingredient that we
need or some new consciousness particle or whatever I happen to think that we're
not missing anything and and that it's or not the interesting thing about consciousness that gives us this amazing
subjective experience of colors and sounds and emotions and so on is rather
something at the higher level about the patterns of information processing that's why that's why I am like to think
about this idea of perceptron Neum what does it mean for an arbitrary physical system to be conscious in terms of what
its particles are doing or its information is doing I don't think I don't hate carbon chauvinism you know
this attitude you have to be made of carbon atoms to be smart or conscious something about the information
processing yes kind of matter performs yeah and you know yeah I have my favorite equations here describing
various fundamental aspects of the world I feel that I think one day maybe someone who's watching this will come up
with the equations that information processing has to satisfy to be conscious I'm quite convinced there is
big discovery to be made there yeah because let's face it sumit we know that
some information processing is conscious because we are yeah conscious but we
also know that a lot of information processing is not conscious like most of the information processing happening in your brain right now is not conscious
there is like 10 megabytes per second coming in and even just through your visual system you are not conscious
about your heartbeat regulation or or most things by even even like if I just
ask you to like read what it says here you look at it and then oh now you know what it said but you don't aware of how
the computation actually happened you're like the your consciousness is like the CEO that got an email at the end we
leave with a final answer so what is it that makes the difference I think that's
a both of us great science mystery we're actually starting it a little bit in my lab here at MIT but I also I think it's
just a really urgent question the answer for started I mean if you're an emergency room doctor and you have an
unresponsive patient coming in and wouldn't it be great if in addition to having a CT scan
you had a consciousness scanner mm-hmm that could figure out whether this person is actually having locked-in
syndrome or is actually comatose and in the future imagine if we build the
robots or the machine that we can have really good conversations which I think
it's mostly very likely to happen right wouldn't you want to know like if your home helped a robot is actually
experiencing anything or just like a zombie I mean would you prefer what
would you prefer would you prefer that it's actually unconscious so that you don't have to feel guilty about switching it off or giving me boring
chores or would you prefer well the certainly would we would prefer
I would prefer the appearance of consciousness but the question is whether the appearance of consciousness is different
than cost consciousness itself and sort of ask that as a question yeah do you
think we need to you know understand what consciousness is solve the hard problem of consciousness in order to
build something like an a GI system no I don't think that and I think we we will
probably be able to build things even if we don't answer that question but if we want to make sure that what happens is a good thing we better solve it first so
it's a wonderful controversy you're raising there there where you have basically three points of view about the
heart problem sir there are two different points of view that both conclude that the hard problem of
consciousness is BS you're on one hand you have some people like Daniel Dennett who say this is our consciousness is
just BS because consciousness is the same thing as intelligence there's no difference so anything which acts
conscious is conscious just like like we are and then there are also a lot of
people including many top AI researchers I know you say all conscience is just because of course machines
should never be conscious tonight they're always gonna is gonna be zombies never have to feel guilty about how you
treat them and then there's a third group of people including Giulio Tononi
for example and and another just of chakana brothers
I would put myself Falls on this middle camp who say that actually some information processing is conscious and
in some is not so let's find the equation which can be used to determine which it is and I think we've just been
a little bit lazy kind of running away from this problem for a long time it's
been almost taboo would even mention the c-word a lot of circles because look but
we should stop making excuses this is a science question and we can the rock
there are ways we can even test test any theory that makes predictions for this and coming back to this helper robot I
mean so you said you'd want to help a robot to certainly act conscious and treat you like to have conversations
with us I think so wouldn't you would you feel would you feel a little bit creeped out if you realize that it was just glossed up the tape recorder they
know there was just Sambi and there's some faking emotion would you prefer that it actually had an experience or
Does consciousness have an experience
will you prefer that it's actually not experiencing anything so you feel you don't have to feel guilty about what you
do to it it's such a difficult question because you know it's like when you're in a relationship and you say well I
love you and the other person I love you back it's like asking well do they really love you back or are they just
saying they love you back do you don't you really want them to actually love you I it's hard to it's
hard to really know the difference between everything seeming like there's
consciousness present there's intelligence present there's affection passion love and and actually being
there I'm not sure do you have a question let's just like to make it a bit more pointed so Mass General
Hospital is right across the river right yes suppose suppose you're going in for a medical procedure and they're like you
know furnish the agent what we're gonna do is we're gonna give you a muscle relaxant so you won't be able to move and you're
gonna feel excruciating pain during the whole surgery but you won't be able to do anything about it but then we're gonna give you this drug that erases
your memory of it would you be cool about that no what
difference that you're conscious about it or not if there's no behavioral change right right that's a really
that's a really clear way to put it that's yeah it feels like in that sense experiencing it is a valuable quality so
actually being able to have subjective experiences at least in that cases is
valuable and I think we humans have a little bit of a bad track record also of
making these self-serving arguments that other entities aren't conscious you know
people often say oh these animals can't feel pain right it's okay to boil lobsters because we asked them if it
hurt and they didn't say anything and now there was just the paper out saying lobsters did do feel pain when you boil them and they're banning it in
Switzerland it and and we did this with slaves too often and say oh they don't mind they don't maybe or aren't
conscious or women don't have souls or whatever I'm a little bit nervous when I hear people just take as an axiom that
machines can't have experience ever I think this is just this really fascinating science question is what it
is let's research it and try to figure out what it is it makes the difference between unconscious intelligent behavior and
conscious intelligent behavior so in terms of so if you think of a Boston
Dynamics human robot being sort of with a broom being pushed around the its
starts it starts pushing on his consciousness question so let me ask do you think an AGI system like a few
neuroscientists believe needs to have a physical embodiment needs to have a body
or something like a body no I don't think so you mean to have to have a
conscious experience to have consciousness I do think it helps a lot
to have a physical embodiment learn the kind of things about the world that they're important to us humans for sure
but I don't think bah diamond is necessary after you've learned it just have the experience
think about when you're dreaming right your eyes are closed you're not getting
any sensory input you're not behaving or moving in any way but there's still an experience there right and so there's
clearly the experience that you have when you see something tool in your dreams isn't coming from your eyes it's just the information processing itself
Selfpreservation instinct
in your brain which is that experience right but if I put another way I'll say
because it comes from neuroscience is the reason you want to have a body and a physical something like a physical like
a you know a physical system is because you want to be able to preserve something in order to have a self you
could argue would you you need to have some kind of embodiment of self to want
to preserve well now we're getting a little bit on Drop amorphic that's inter
and super more fising things miss Mamie tossing like self-preservation instincts I mean we are evolved organisms right
right so Darwinian evolution endowed us and other involve all organism with the
self-preservation instinct as those that didn't have those self-preservation genes are clean out of the gene pool
right right but if you build an artificial general intelligence the mind
space that you can design is much much larger than just a specific subset of minds that can evolve that happen so
they CERN a GI mind doesn't necessarily have to have any self-preservation instinct it also doesn't necessarily
Fear of death
have to be so individualistic as I'd like imagine if you could just first of all it or we're also very afraid of
death you know I suppose you could back yourself up every five minutes and then your airplane is about to crash you like
shucks I'm just counted I'm gonna lose the last five minutes of experiences it's my last cloud backup you're dying
you know it's not this big a deal or if we could just copy experiences between
our minds easily like me which we could easily do if we were silicon based right
then maybe we would feel a little bit more like a hive mind actually but maybe is
he so so there's a so I don't think we should take for granted at all that AG I will have to have any of those sort of
competitive as alpha male instincts right on the other hand you know this is
really interesting because I think some people go too far and say oh of course we don't have to have any concerns
either that advanced AI will have those instincts because we can build anything
you want that there's there's a very nice set of arguments going back to Steve Omohundro and Nick Bostrom and
others just pointing out that when we build machines we normally build them with some kind of goal you know win this
chess game drive this car safely or whatever and as soon as you put in a goal into machine especially if it's
kind of open-ended goal and the machine is very intelligent it'll break that down into a bunch of sub goals and one
of those gold will almost always be self-preservation because if it breaks or dies in the process it's not gonna
accomplish the goal right like suppose you just build a little you have a little robot and you tell it to go down the Starmark get here and and and get
you some food make your cookin Italian dinner you know and then someone mugs it and tries to break it down the way that
robot has an incentive to not destroy it and defend itself or run away because
otherwise it's gonna fail and cooking you dinner it's not afraid of death but it really wants to complete the dinner
cooking gold so it will have a self-preservation instinct continue being a functional Asian yeah and and
similarly if you give any kind of warm and they she's go to an AGI
it's very likely they want to acquire more resources so it can do that better and it's exactly from those sort of sub
goals that we might not have intended that but some of the concerns about AGI safety come you give it some goal which
seems completely harmless and then before you realize it it's also trying
to do these other things which you didn't want it to do and it's moment be smarter than us so so lastly and let me
Intelligence and consciousness
pause just because I in a very kind of human centric way see
fear of death is a valuable motivator haha so you don't think do you think
that's an artifact of evolution so that's the kind of mind space evolution created they were sort of almost
obsessed about self-preservation kind of genetic well you don't think that's necessary to be afraid of death so not
just a kind of sub goal of self-preservation just so you can keep doing the thing but more fundamentally
sort of have the finite thing like this ends for you at some point the
interesting do I think it's necessary before what precisely for intelligence
but also for consciousness so for those for both do you think really like a
finite death and the fear of it is important so before I can answer well
before we can agree on whether it's necessary for intelligence or for consciousness we should be clear or how we define those two words because share
a lot of really smart people to find them in very different ways I was in this on this panel and with AI experts
and they couldn't they couldn't agree on how to define intelligence even so I define intelligence simply as the
ability to accomplish complex goals I like your broad definition because again I don't want to be a carbon
chauvinist right and in that case no it
certainly certainly doesn't require fear of death I would say alpha go alpha zero is quite intelligent
I don't think alpha zero has any fear of being turned off because it doesn't understand the concept of that even and
and similarly consciousness I mean you could certainly imagine very simple kind
of experience if you know if certain plants have any kind of experience I don't think they were afraid of dying if
there's nothing they can do about it anyway much so there wasn't that much value and but more seriously I think if
you ask not just about being conscious but maybe having what you would
we might call an exciting life for you feel passion and I didn't really appreciate the little things maybe there
but somehow maybe there perhaps it does help having having my backdrop today it's finite you know let's let's make
the most of this this live to the fullest so if you if you knew you were gonna slip forever if you think you
would change your yeah in some perspective it would be an incredibly
boring life living forever so in the sort of loose subjective terms that you
said of something exciting and something in this that other humans would understand I think is yeah it seems that
the the finiteness of it is important well the good news I have for you then is based on what we understand about
cosmology everything is in our universe is Pro ultimately probably finite alone
although pay crunch or bit or big what's to expand anything yeah we couldn't have a Big Chill or a Big Crunch or a big rip
or that's the big snap or death bubbles all over more than a billion years away
so we should we certainly have vastly more time than our ancestors thought but
there is still it's still pretty hard to squeeze in an infinite number of compute
cycles even though there are some loophole let's just might be possible but I think I you know some people like
to say that you should live as if you're about you're gonna die in five years or something that sort of optimal maybe
it's a good it subs we should build our civilization as if it's all finite to be
on the safe side right exactly so you mentioned in defining intelligence as
the ability solve complex goals where would you draw a line how would you try
to define human level intelligence and superhuman level intelligence where this
consciousness part of that definition no consciousness does not come into this definition so so I think your
AI
intelligence is it's a spectrum but there are very many different kinds of goals you can have you can have a goal to be a good chess player a good goal
player a good car driver a good investor good poet etc so
intelligence that bind by its very nature isn't something you can measure but it's one number overall goodness no
no there are some people who are more better at this some people are better than that um right now we have machines
that are much better than us at some very narrow tasks like multiplying large
numbers fast memorizing large databases playing chess playing go and soon
driving cars but there's still no machine that can match a human child in
general intelligence but but artificial general intelligence AGI in the name of your course of course that is by its
very definition the the quests the build a mission in seen that can do everything as well as we can up to the old holy
grail of AI from from back to its inception and then 60s if that ever
happens of course I think it's gonna be the biggest transition in the history of life on earth but it but it doesn't
necessarily have to wait the big impact about until machines are better than us at knitting the really big change
doesn't come exactly the moment they're better than us at everything the really big change comes first there
big changes when they start becoming better at us at doing most of the jobs that we do because that's it can takes
away much of the demand for human labor and then the really whopping change
comes when they become better than us at AI research right right because right
now the timescale of AI researcher is limited by the human research and
development cycle of years typically at all along the tape from one release of some software or iPhone or whatever to
the next but once once we have once Google can replace 40,000 engineers by
40,000 equivalent pieces of software or whatever right then that doesn't there's
no reason that has to be years it can be in principle much faster and the timescale of future progress in AI and
also all of science and technology will will be driven by machines not so it's this point simple point which
lives right this incredibly fun controversy about whether it can be an
intelligence explosion so-called singularities Vernor Vinge called it that the idea is articulated by IJ good
obviously way back fifties but you can see Alan Turing and others thought about
it even earlier not did you ask me what
exactly what I define England's yeah so this the the glib answer is it to say
something which is better than us at all cognitive tasks will look better than any human and all cognitive tasks but
the really interesting bar I think goes a little bit lower than that actually it's when they can when they're better
than us it AI programming and can a general learning so that they can can if
they want to get better than I said anything by just studying so they're better is a keyword and better as
towards this kind of spectrum of the complexity of goals it's able to accomplish yeah so another way to so no
and that's certainly a very clear definition of human law so there's it's
almost like a sea that's rising you could do more and more and more things as a graphic that you show it's really
nice way to put it so there's some Peaks that and there's an ocean level elevating and you saw more and more
problems but you know just kind of to take a pause and we took a bunch of questions and a lot of social networks
and a bunch of people asked a sort of a slightly different direction on creativity and and things like that
perhaps aren't a peak the it's you know
human beings are flawed and perhaps better means having being a having contradiction being fought in some way
so let me sort of yeah start and start easy first of all so you
have a lot of cool equations let me ask what's your favorite equation first of all I know they're all like your
Quantum Mechanics
children but like which one is that it's the master key of
want the mechanics of the microworld this equation to protect you like everything to do with atoms molecules
and all that we have yeah so okay it's a
quantum mechanics is certainly a beautiful mysterious formulation of our world so I'd like to sort of ask you
just as an example it perhaps doesn't have the same beauty as physics does but
in mathematics abstract the Andrew Wiles who proved the firm as last theta so he
just saw this recently and it kind of caught my eye a little bit this is three hundred fifty eight years after it was
conjectured so this very simple formulation everybody tried to prove it everybody failed and say here's this guy
comes along and eventually it proves it and then fails to prove it and proves it
again in 94 and he said like the moment when everything connected into place the
in an interview said it was so indescribably beautiful that moment when you finally realized the connecting
piece of two conjectures he said it was so indescribably beautiful it was so
simple and so elegant I couldn't understand how I'd missed it and I just stared at it in disbelief for twenty
minutes then then during the day I walked around the department and at Keamy keep coming back to my desk
looking to see if it was still there it was still there I couldn't contain myself I was so excited it was the most
important moment on my working life nothing I ever do again will mean as much so that particular moment and it
kind of made me think of what would it take and I think we have all been there
at small levels maybe let me ask have you had a moment like that in your life
where you just had an ideas like wow yes I wouldn't
self and the same breath as Andrew wilds but I've certainly had a number of um
aha moments mo when I realized something very cool about physics just as
The Future
completely made my head explode in fact some of my favorite discoveries I made later I later realize if they had been
discovered earlier someone who sometimes got quite famous for it so I find this too late for me to even publish it but
that doesn't diminish in any way an emotional experience you have when you realize it like yeah Wow yeah
so what would it take and at that moment that wow that was yours in a moment so
what do you think it takes for an intelligent system and a GI system an AI
system to have a moment like that that's a tricky question because there are actually two parts to it right one of
them is cannot accomplish that proof it cannot prove that you can never write a
to the N plus B to the N equals 3/2 that equals e to the N for all integers well
etc etc when when n is bigger than 2 the
simply in any question about intelligence can you build machines that are that intelligent and I think by the
time we get a machine that can independently come up with that level of proofs probably quite close to AGI the
second question is a question about consciousness when will we will willins
how likely is it that such a machine will actually have any experience at all as opposed to just being like a zombie
and would we expect it to have some sort of emotional response to this or
anything at all I can to human emotion work no but when it accomplishes its
machine goal it did the views it to somehow it's something very positive and right and and sublime and and and and
deeply meaningful I would certainly hope that if in the future we do create
machines that are our peers or even our dis
since yeah I would certainly hope that they do have this sort of sublime sublime appreciation of life in a way my
absolutely worst nightmare would be that
in at some point in the future the distant future maybe I cost much as
teeming with all this post biological life doing all the seemingly cool stuff and maybe the fun last humans or the
time era our species eventually fizzles out we'll be like well that's ok because
we're so proud of our descendants here and look what I like my most nightmare
is that we haven't solved the consciousness problem and we haven't realized that these are all the zombies
they're not aware of anything anymore than the tape recorders it has an any kind of experience so the whole thing
has just become a play for empty benches that would be like the ultimate zombie apocalypse me III would much rather in
that case that we have these beings which just really appreciate how how
amazing it is and in that picture what would be the role of creativity we had a few people
Creativity
ask about creativity do you think when you think about intelligence I mean
certainly the the story told the beginning of your book involved you know creating movies and so on yeah sort of
making making money you know you can make a lot of money in our modern world with music and movies so if you are
intelligent system you may want to get good at that yeah but that's not necessarily what I mean by creativity is
it important on that complex goals where the sea is rising for there to be
something creative creative or am I being very human centric and thinking
creativity somehow special relative to intelligence my hunch is
that we should think your creativity simply as an aspect of intelligence and
[Music] we we have to be very careful with with human vanity we had we have this
tendency to very often one and say as soon as machines can do something we try to diminish it that's a long but that's
not like real intelligence you know you're the night trader or there were or this or that or the other thing maybe if
we ask ourselves to write down a definition of what we actually mean by being creative what we mean by Andrew
Wiles what he did there for example don't we often mean that someone takes you very unexpected leap mm-hmm it's not
like taking feet 573 and multiplying in my 224 by justice step of
straightforward cookbook like rules right if this you may be making you even
make a connection between two things that people have never thought was connect very surprising or something like that I think I think this is an
aspect of intelligence and this is some actually one of the most important aspect of it maybe the reason we humans
are tend to be better at it than traditional computers is because it's something that comes more naturally if
you're a neural network then if you're a traditional logic gate based computer
machine you know we physically have all these connections and you activate here
activator here activate here ping you know I my hunch is that if we ever build
a machine where you could just give it the task hey hey you say hey you know I
just realized that I have I want to travel around the world instead this
months can you teach my eight a GI course for me and it's like ok I'll do it and it does everything that you would
have done and they provides us and so yeah that that would in my mind involve a lot of creativity yeah so I had such a
beautiful way to put it I think we do try to grab grasp at the you know the
definition of intelligence is everything we don't understand how how to build so
like so we as humans try to find things well that we have on machines don't happen maybe creativity is just one of
the things one of the words we use to describe that that's really interesting where to put it out think we need to be that defensive I
don't think anything good comes out of saying oh we're somehow special you know I it's contrariwise there are many
examples in history of we're trying to pretend that were somehow superior to
all other intelligent beings has led the pretty bad results right
Nazi Germany they said that they were somehow superior to other people today we still do a lot of cruelty to animals
by saying that we're social superiors and how and the other they can't feel pain slavery was justified by the same kind
of really weak weak arguments and and I don't think if we actually go ahead and
build artificial general intelligence it can do things better than us I don't
think we should try to found our self-worth on some sort of bogus claims
of superiority in in terms of our intelligence I think it's we shouldn't
stand Joe find our calling and then the
meaning of life from from experiences that we have right you know I can have I can have very meaningful experiences
even if there are other people who are smarter than me you know when I go to
faculty meeting here and I was talking about something that I certainly realize oh boy he has a Nobel Prize he has a
Nobel Prize he has no pride I don't have what does that make me enjoy life any less or would enjoy talking those people
less of course not see my and the contrariwise I I feel very honored and
privileged to get to interact with with other very intelligent beings that are
better than me a lot of stuff so I don't think there's any reason why we can't have the same approach with with
intelligent machines that's a really interesting so people don't often think about that they think about when there's
Intelligent Machines
going if there's machines that are more intelligent you naturally think that that's not going to be a beneficial type
of intelligence you don't realise it could be you know like peers of Nobel Prizes that
that would be just fun to talk with and they might be clever about certain topics and you can have fun having a few
drinks with them so well another example is we can all relate to it why it
doesn't have to be a terrible thing to be impressed the friends of people are even smarter than us all around is when
when you and I were both two years old I mean our parents were much more intelligent than us right here worked
out okay yeah because their goals were aligned with our goals yeah and that I think is really the
number one T issue we have to solve its value align the value alignment problem
exactly because people who see too many Hollywood movies with lousy science
fiction plot lines they worry about the wrong thing right they worry about some machines only turning evil it's not
malice they wish that the issue probably concerned its competence by definition
intelligent makes you makes you very competent if you have a more intelligent
goal playing mr. computer playing as the less intelligent one and when we define
intelligence is the ability to accomplish go winning right it's gonna be the more intelligent one that wins my
and if you have a human and then you have an AGI and that's more intelligent
in all ways and they have different goals guess who's gonna get their way right so I was just reading about I was
just reading about this particular rhinoceros species that was driven
extinct just a few years ago bummer is looking at this cute picture mommy run oestrus with it's it's child you know
and why did we humans private extinction wasn't because we were evil Rhino haters
right as a whole it was just because we our goals weren't aligned with those of the rhinoceros and it didn't work out so
well for the rhinoceros because we were more intelligent right so I think it's just so important that if we ever do
build AGI before we we have to make sure that it it learns
to understand our goals that it adopts our goals and it retains those goals so
Human Values
the cool interesting problem there is being able us as human beings trying to
formulate our values so you know you could think of the United States Constitution as a as a way that people
sat down at the time a bunch of white men but which is a good example I should
we should say they formulated the goals for this country and a lot of people agree that those goals actually hold up
pretty well that's an interesting formulation of values and failed miserably in other ways so for the value
alignment problem and a solution to it we have to be able to put on paper or in
in in a program human values how difficult do you think that is very but
it's so important we really have to give it our best and it's difficult for two separate reasons there's the technical
value alignment problem of figuring out just how to make machines understand our
goals adopt them and retain them and then there's a separate part of it the philosophical part whose values anyway
and since we it's not like we have any great consensus on this planet on values how what mechanism should we create them
to aggregate and decide okay what's a good compromise right at that second discussion can't this be left the tech
nerds like myself right that's right and if we refuse to talk about it and then
AGI gets built who's gonna be actually making the decision about whose values it's gonna be a bunch of dudes and some
tech company yeah yeah and are they necessarily - it's it's so
representative of all humankind that we want to just entrusted to them or they even is uniquely qualified to speak the
future human happiness just because they're good at programming any I I'd much rather have this be a really inclusive conversation but do you think
Is it possible
it's possible sort of so you create a beautiful vision that includes so the
diversity cultural diversity and various specs on discussing rights freedoms human dignity but how hard is it to come
to that consensus do you think it's certainly a really important thing that we should all try to do but do you think
it's feasible I I think there's no better way to guarantee failure than to
try to refuse to talk about it or or refuse to try and I also think it's a really bad strategy to say okay let's
first have a discussion for a long time and then once we reach complete consensus then we'll try to load it into
the Machine know it we shouldn't let perfect be the enemy of good instead we
should start with the kindergarten ethics - pretty much everybody agrees on and put that into our machines now we're
not doing that even look at the you know anyone who builds this passenger aircraft wants it to never under any
circumstances fly into a building or mountain right yet the September 11 hijackers were able to do that and even
more embarrassingly you know and that he has Lubitz this depressed Germanwings pilot when he flew his
passenger jet into the Alps killing over a hundred people he just told the autopilot to do it he told the freaking
computer to change the altitude 200 meters and even though it had the GPS maps everything the computer was like
okay no so which we should take those very basic values though where the
problem is not that we don't agree that maybe the problem is just we've been too lazy to try to put it into our machines
and make sure but from now on air airplanes will just which all have computers in them but we'll just never
just refuse to do something like that go into safe mode maybe lock the cockpit door or than here at the airport and and there's so much
other technology in our world as well now where it's really quite becoming quite timely to put in some sort of very
basic values like this even in cars we were have enough vehicle terrorism
attacks by now of you love different trucks and bands into pedestrians that it's not at all a crazy idea to just
have that hardwired into the car just yeah there are a lot of there's always gonna be people who for some reason want
to harm others most of those people don't have the technical expertise to figure out how to work around something like that so if
the car just won't do it it helps it let's start there so there's a lot of that's a great point so not not
Cellular automata
chasing perfect there's a lot of things that a lot that most of the world agrees on yeah and this look there let's start
there and and then once we start there we'll also get into the habit of having these kind of conversations about okay
what else should we put in here and I have these discussions this should be a gradual process then great so but that
also means describing these things and describing it to a machine so one thing we had a few conversation
was Stephen Wolfram I'm not sure if you're familiar with Stephen but yeah I know quite well so he is you know he
played you know works with a bunch of things but you know cellular automata are these simple computable things these
computation systems and he kind of mentioned that you know we probably have already within these systems already
something that's AGI meaning like we
just don't know it because we can't talk to it so if you give me this chance to
try to try to release form a question out of this is I think it's an
interesting idea to think that we can have intelligent systems but we don't know how to describe something to them
and they can't communicate with us I know you're doing a little bit work an explainable AI trying to get AI to
explain itself so what are your thoughts of natural language processing or some
kind of other communication how how does the AI explain something to us how do we explain something to it to machines or
you think of it differently so there are two separate parts to your question
there are them one of them has to do with communication which is super interesting you don't get that insect
the other is whether we already have AGI but we just haven't noticed it yeah right there I beg to differ right and
don't think there's anything in any cellular automaton or anything or the internet itself or whatever that has
artificial it didn't really do exactly everything we humans can do better I think today if
the day that happens when that happens we will very soon notice we will
probably notice even before andif because in a very very big way but for the second part though sorry so the
because you you have this beautiful way to formulating consciousness as as a you
Information processing
know as information processing you can think of intelligence and information processing and this you can think of the entire universe there's these particles
and these systems roaming around that have this information processing power you don't you don't think there is
something with the power to process information in the way that we human
beings do that's out there that that needs to be sort of connected to it
seems a little bit philosophical perhaps but there's something compelling to the idea that the power is already there
would you know yes the focus should be more on these I'm being able to communicate with it mhm well I agree
that that and some in a certain sense the hardware processing power is already
out there because our universe itself can think of it as being a computer
already right it's constantly computing what water waves have evolved the water waves and the river Charles and how to
move the air molecules around that s Lloyd has pointed out my colleague here that you can even in a very rigorous way
think of our entire universe as being a quantum computer it's pretty clear that our universe supports this amazing
processing power because you can even the within this physics computer that we
live in right we can even build actually laptops and stuff so clearly the power is there it's just that most of the
compute power that nature has it's in my opinion kind of wasting on boring stuff like simulating yet another ocean wave
somewhere where no one is even looking right so in a sense of what life does what we are doing when we build
computers is where we channeling all this compute that nature is doing anyway
into doing things that are more interesting than just yet another ocean wave you know and let's do something
cool here so the raw hardware power and sherbet and then and even just like
computing what's gonna happen for the next five seconds in this water ball you know it takes in a ridiculous amount of
compute if you do it on a human computer in yeah this water ball was did it but that does
not mean this water bottle has AGI and because AGI means it should also be able
to like have written my book during his interview yes and I don't think it's just communication problems as far as
you know don't think it can do it and other Buddhists say when they watch the
Communication
water and that there is some beauty that there's some depth and being sure that
they can communicate with communication that's also very important here because I mean look part of my job is being a
teacher and I know some very intelligent professors even who just have a better
hard time communicating they come up with all these brilliant ideas but but
to communicate with somebody else you have to also be able to simulate their own mind yes and pettite build well
enough and understand model of their mind that you can say things that they will understand and that's quite
difficult and that's why today it's so frustrating if you have a computer that makes some cancer diagnosis and you ask
it well why are you saying I should have a surgery if it and if they don't know can only reply or I was trained on five
terabytes of data and this is my diagnosis boop boop beep beep yeah I
didn't doesn't really instill a lot of confidence right right so I think we have a lot of work do one on
communication there so what kind of what kind of I think you're doing a little
bit work and explainable eh uh yeah what do you think are the most promising avenues is it mostly about sort of the
Alexa problem of natural language processing of being able to actually use human interpretable methods of
communication so being able to talk to a system and talk back to you or is there some more fundamental problems to be
solved I think it's all of above human the natural language processing is obviously important but they're also
more nerdy fundamental problems like if you if you take you play chess
mmm I have to give this Paris key when
did you learn Russian nobody watching papyrus key I talk after the back more people can you teach yourself Russian to
Tao what amalgam of bills of sim through dinner Wow but I would see languages do you
know wow that's really impressive I've had some contact base but my point was if
you play chess but you have you looked at the alpha zero games there are the actual games now just checking out some
of them are just mind-blowing really beautiful and if you ask how did it do
that you got that talk to them is hassabis I know others from beef mine all they will
ultimately be able to give you is big tables of numbers matrices that define the neural networking and you can stare
at these know people's numbers till your face turned blue and it's you know I can understand much about why it made that
move and even if you have a natural language processing that can tell you in
human language about all five seven points to eight still not gonna really help so I think think there's a whole
spectrum of a fun challenge they're involved in and taking a computation that does intelligent things and
transforming me into something equally good equally intelligent but it's more
understandable and I think that's really valuable because I think as we put
machines in charge of evermore infrastructure in our world the power grid the trading on the stock market
weapons systems and so on it's absolutely crucial that we can trust these a is a do or I want and
trust really comes from understanding all right in a very fundamental way and
that's why I'm that's why I'm working on this because I think the more if we're gonna have some hope of ensuring that
machines have adopted our goals and that they're gonna retain them that kind of trust and
thank you needs to be based on things you can actually understand preferably even make it perfectly to improve
theorems on even with a self-driving car right if someone just tells you it's been trained on tons of data and I never
crashed it's it's less reassuring than if someone actually has a proof maybe it's a computer verified proof but still
it says that under no circumstances is this car just gonna swerve into oncoming traffic and that kind of information
helps will build trust and build the alignment the alignment of goals the at
least awareness that your goals your values are aligned and I think even a very short term if you look at her you
know that today right this absolutely pathetic state of cybersecurity that we have when it's or is it three billion
yahoo accounts which are packed almost every American's credit card and so on
you know it's why is this happening it's ultimately happening because we have
software took nobody fully understood how it worked that's why the bugs hadn't
been found right now and I think AI can be used very effectively for offense for
hacking but it can also be used for defense know hopefully automating
verifiability and creating is systems that are built in different
so you can actually prove things about them right and it's it's important so speaking of software that nobody
understands how it works of course a bunch of people asked by your paper about your thoughts of why does deep and
cheap learning work so well that's the paper but what what are your thoughts on deep learning these kind of simplified
models of our own brains have been able to do some successful perception work
pattern recognition work and now with alpha zero and so on do some some clever things what are your thoughts about the
promise limitations of this piece great I think there are a number of very
important insights very important lessons we can already draw from these kind of successes one of them is when
you look at the human brain you see it's very complicated a tenth of eleven neurons and there are all these different kinds of neurons and
yadda-yadda and there's been a long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence
which a now I think quite convincingly answer that question no it's enough to
have just one kind if you look under the hood of alpha zero there's only one kind of neuron and it's ridiculously simple a
simple mathematical thing so it's it's not the it's just like in physics it's not the D if you have a gas with waves
in it it's not the detailed nature of the molecule the matter it's the collective behavior or somehow it
similarly it's it's it's this higher-level structure of the network
that matters not that you have twenty guys I think whom our brain is such a complicated mess because it wasn't
devolved just to be intelligent it was evolved to also be self assembling right
and self repairing right and evolutionarily attainable matches and so
on yeah so I think it's pretty my my hunch is that we're gonna understand how to build a GI before we fully understand
how our brains work just like we we understood how to build flying machines long before we were able to build a
mechanical work bird yes are you going names you're given that the example
exactly of mechanical birds and airplanes yeah my plans do a pretty good job of flying without really mimicking bird
flight and even now after 100 is 100 years later did you see the TED talk with a mr. mechanical bird you mentioned
it's amazing but even after that right we still don't fly in mechanical birds because it turned out the way we came up
with but simpler and it's better for our purposes and I think it might be the same there that's one lesson and another
lesson it is one what did when our paper was about well first we wife is a physicist
thought it was fascinating how there is a very closed mathematical relationship actually between our artificial neural
networks and a lot of things that we've studied for in physics go by nerdy names
like the renormalization group equation and napoleons and yada yada yada and
when you look a little more closely at this you have you at first there was a
well there's something crazy here that doesn't make sense because we know that
if you even want to build a super simple neural network with hell that part cat
pictures and dog pictures right that you can do that very very well now but if
you think about it a little bit you convince yourself it must be impossible because if I have one megapixel even if
each pixel is just black or white there's 2 to the power 1 million possible images which is way more than
there are atoms in our universe right so in order to and then for each one of
those I have to assign a number which is the probability that it's a dog right so an arbitrary function of images is a
list of more numbers than there are atoms in our universe so clearly I can't
store that under the hood of my my GPU or maybe my computer yet somehow works so what does that mean well it means
that the out of all of the problems that you could all try to solve with a neural
network almost all of them are impossible to solve with a reasonably sized one but
then what we should show it in our paper was was that they the fraks the kind of
problems the fraction of all the problems that you could possibly pose that there that we actually care
about given the laws of physics is also an infinitesimally tiny little part and amazingly they're basically the same
part yeah it's almost such that our world was created for I mean they kind of come together yeah but you could say
maybe where the world created the world that the world was created for us but I have a more modest interpretation which
is that instead evolution in downest but neural networks precisely for that reason because this particular
architecture as opposed to the one in your laptop is very very well adapted
solving the kind of problems of nature kept presenting it our ancestors will read so it makes sense that why do we
have a brain in the first place it's to be able to make predictions about the future mm-hm and so on so if we had a
sucky system which could never solve it wouldn't have a logic so but it's so
this is this is a I think you're very beautiful fact yeah we also we also
realize that there's there that we they've been it's been earlier work on on why deeper networks are good but we
were able to show an additional cool fact there which is that them even incredibly simple problems like suppose
I gave you it I found the numbers and asked you to multiply them together in re you can write it's the few lines of
code boom done trivial if you just try to do that with a neural network that has only one single hidden layer in it
you can do it but you're gonna need two to the power a thousand neurons and to
multiply a thousand numbers which is again more neurons than their atoms in our universe okay that's nothing but if
you're allowed if you love yourself make it a deep network with many layers you only need four thousand neurons it's
perfectly feasible so that's really interesting there yeah yeah so on
another architecture type I mean you mentioned Schrodinger's equation and what what are your thoughts about
quantum computing and the role of this kind of computational unit in creating
an intelligent system in some Hollywood movies that are a lot mentioned my name
you don't want to spoil them the the NAD is building a quantum computer list yes because the word quantum sounds
cool and so it's right mines first of all I think we don't need quantum
computers they build a GI I suspect your brain is not quantum computer and then
they found sense so you don't even wrote a paper about that what many years ago would excite Chocula the decoherence
so-called B coherence time that how long it takes until the quantum computer nosov what your neurons are doing gets
erased mm-hmm why just random noise from the environment and then it's about 10
to the minus 21 seconds so as cool as it would be to have a quantum computer in
my head I don't think that fast yeah on the other hand there are very
cool things you could do with quantum computers though I think we'll be able to do soon when we get big what bigger
ones that might actually help machine learning do even better than the brain mm-hmm though for example one this is
moonshot but hey you know learning is
very much same thing is search mm-hmm if you have if you try to train a neural
network to get really learn to do something really well you'd have some lost function you have some you have a
bunch of knobs you can turn represented by a bunch of numbers and you're trying to tweak them so that it become as good
as possible at this thing so if you think of a landscape with some Valley
where each dimension of the landscape corresponds to some number you can change you're trying to find the minimum
and it's well-known that if you have a very high dimensional landscape complicated things super hard to find
the minimum later quantum mechanics is amazingly good at this right if I want
to know what's the lowest energy state this water can possibly have incredibly
hard to compute but we can but nature will happily figure this out for you if you just cool it down and make you very
very cold if you put a ball somewhere it'll roll down to its minimum and this
happens metaphorically and the energy landscape too and quantum mechanics even used as a mode some
clever tricks which today is machine learning systems don't like if you're trying to find the minimum and you get
stuck in a little local minima here in quantum mechanics you can actually tunnel through the barrier and get
unstuck in Yemen and that's really interesting yeah so it may be for example it will one day use quantum
computers that help train neural networks better that's really
interesting okay so as a component of kind of the learning process for example yeah
let me ask sort of wrapping up here a little bit let me let me return to the
questions of our human nature and and love as I mentioned so do you think you
mentioned sort of a helper robot you can think of also personal robots do you think the way we human beings fall in
love and get connected to each other it's possible to achieve in an AI system
and human-level AI intelligence system do you think we would ever see that kind of connection or you know in all this
discussion about solving complex goals yeah as this kind of human social connection do you think that's one of
the goals and the peaks and valleys that with the raising sea levels that we'll be able to achieve or do you think
that's something that's ultimately or at least in the short term relative to other goals is not achievable I think
it's all possible and I mean in in recent there's that there's a very wide
range of guesses as you know among AI researchers when we're gonna get a GI
some people you know like your friend Rodney Brooks says it's gonna be hundred hundreds of years least and then there
are many others I think it's gonna happen relative much sooner and recent polls and be half or so or AI
researchers think it's we're gonna get AGI within decades so if that happens of
course then I think these things are all possible but in terms of whether it will happen I don't I think we shouldn't
spend so much time asking what do we think will happen in the future as if we are just some sort of pathetic your
passive bystanders you know waiting for the future happen to us hey we're the ones creating
this future right so we should be proactive about it and ask us of what
sort of future we would like to have happen that's right trying to make it like that well what I prefer it to some sort of incredibly
boring zombie like future where there's all these mechanical things happen it is no fashion no emotion no experience
maybe even no I would of course much rather prefer it if all the things that
we find that we value the most about humanity our subjective experience
passion inspiration you love you know if we can create a future where those are
those things do exist no I think ultimately it's not our universe giving
meaning to us just us giving me the universe and if we build more advanced
intelligence let's let's make sure we're building in such a way that meaning
these but it's part of it I want a lot of people that seriously study this problem and think of it from different
angles have trouble and the majority of cases if they think through that happen
you know are the ones that are not beneficial to humanity right and so yeah
so what what are your thoughts was an engine what's what should people you
know I really don't like people to be terrified you should what's a way for people to
think about it in a way that instead you know we can solve it okay to make it better yeah no I don't think panicking
is gonna help in any way it's not increase chances of things going well either even if you are in a situation
where there is a real threat does it help if everybody just freaks out right no of course of course not I
think yeah there are of course ways in which things can go horribly wrong first
of all it's important when we think about this thing this about the problems and risks that also remember how huge
the upsides can be if we get it right I had everything everything we love about society and civilization of the product
of intelligence so if we can amplify our intelligence or machine intelligence and not anymore lose our loved one to what
we're told as an uncurable disease and things like this of we should aspire to that so that can be
a motivator I think reminding ourselves that the reason we try to solve problems is not just because we're trying to
avoid gloom but because we're trying to do something great but then in terms of the risks I think um the entry the
important question is to ask what can we do today they will actually help yes how come good may in it and dismissing the
risk is not one of them you know it I find it quite funny often when I'm in on discussion panels about these things how
the people who work for come for companies lobbies they're always like oh
nothing to worry about nothing to worry about nothing to worry about and the it's always all it's only academics sometimes it's expressed
concerns that's not surprising at all if you think about it Upton Sinclair
quipped right that it's hard to make your man believe in something when you think some the fans are not believing in
it and and frankly we know a lot of these people in companies and that they're just as concerned as anyone else
but if you're the CEO of a company that's not something you want to go on record saying when you have silly journalists so we're gonna put a picture
of a Terminator robot when they quote you so so the issues are real and the
way I am the way I think about what the issue is it is basically you know but
the real choice we have is first of all are we gonna stir this dismiss this the
risks and say well you know let's just go ahead and build machines that can do everything we can do better and cheaper
you know let's just make yourselves obsolete as fast as possible or what could possibly go wrong right that's one
attitude the opposite attitude that I think is to say is incredible potential
you know let's think about what kind of future we're really really excited about
what are the shared goals that we can really aspire towards and then let's
think really hard on how about how we can actually get there as it's a start with it no don't start thinking about the risk start thinking about the goals
goals yeah and then when you do that then you can think about the obstacles you want to avoid well they often get
students coming in right here into my office for career advising always ask them this very question where you
want to be in the future man if all she can say is oh maybe I'll have cancer maybe I'll run over by a tortoise and
obstacles instead of the bill he's just gonna end up a hypochondriac paranoid yeah whereas if she comes in and fire in
her eyes and it's like I want to be there and then we can talk about the obstacles and see how we can circumvent
them that's I think a much much healthier attitude and um that's really
well plan and I I feel it's it's very challenging to come up with a vision for
the future which we wish we are unequivocally excited about I'm not just talking now in the vague terms like yeah
let's cure cancer fine I'm talking about what kind of society do we want to create what do we want it to mean you
know to be human in the Age of AI in the age of AGI so if we can have this
conversation broad inclusive conversation and gradually start
converging towards some some future that with some direction at least that we
want to steer towards right then then no we'll be much more motivated to constructively take on the obstacles and
I think if I had if I had the I think if you make if I try to wrap this up in a
more sixteenth way I think I think we can all agree already now that we should
aspire to build AGI but doesn't
overpower us but that empowers us and think of the many various ways that can
do that whether that's from my side of the world of autonomous vehicles I I'm
personally actually from the camp that believes there's human level intelligence is required to to achieve something like vehicles that would
actually be something we would enjoy using and being part of so that's one example and certainly there's a lot of
other types of robots in medicine and so on so focusing on those and then and
then coming up with the obstacles coming up with the ways that that can go wrong and solving those one at a time and just
because you can build an autonomous vehicle even if you could build one that would drive this finalize you know maybe
there are some things in life that we would actually want to do ourselves that's right my like for example if you think of our
society as a whole there's something that we find very meaningful to do and that doesn't mean we have to stop doing
them just because machines can do them better you know I'm not gonna stop playing tennis just the base of my build
a tennis robot yeah beat me people are still playing chess and even go yeah and I in this in the very near term even
some people are advocating basic income replace jobs but if you if the
government is gonna be willing to just hand out cash to people for doing nothing then one should also seriously
consider whether the government should also just hire a lot more teachers and nurses and the kind of jobs which people
often find great fulfillment in doing right I get very tired of hearing politicians saying oh we can't afford
hiring more teachers but we're going to maybe have basic income if we can have more serious research and thought into
what gives meaning to our lives and the jobs give so much more than income right mm-hm and then think about in the future
well what are the role of the yeah what are the roles that we want to have
people feeling empowered by machines and I think sort of I come from the Russia
from the Soviet Union and I think for a lot of people in the 20th century going to the moon going to space was an
inspiring thing I feel like the the the universe of the mind so AI understanding
creating intelligence is that for the 21st century so it's really surprising and I've heard you mention this it's
really surprising to me both on the research funding side that it's not funded as greatly as it could be but
most importantly on the politicians side that it's not part of the public discourse except in the kilobots
Terminator kind of view that people are not yet I think perhaps excited by the
possible positive future that we can build together certainly should be because politicians usually just focus
on the next election cycle right the single most important thing I feel we humans have learned and the entire
history of science is there were the Masters of underestimation we underestimated
the science of our cosmos again and again realizing of everything
we thought existed was just a small part of something grander right planet solar system the galaxy clusters of guises
universe so and we now know that we but
the future has just so much more potential than our ancestors could ever have dreamt of this cosmos well imagine
if all of Earth was completely devoid of life except for Cambridge Massachusetts
that would wouldn't it be kind of lame if all we ever aspired to it to stay in
Cambridge Massachusetts forever and then go extinct in one week even though Earth was gonna continue on
for longer that that sort of attitude I think we have now on the cosmic scale we
can fluid life can flourish on earth not foreign for four years but for billions of years yes I can even tell you about
how to move it out of harm's way when its own Sun gets too hot and and then we
have so much more resources out here which today yeah maybe there are a lot
of other planets with bacteria or a cow like life on them but I most of this all
this opportunity seems as far as we can fail to be largely dead like the Sahara
Desert and yet we have the opportunity but to help life flourish promise there are billions
of year and so like let's quit squabbling about when some little border
should be drawn one-fifth one mile to the left to right and realize hey you
know we can do such incredible things yeah and that's I think why it's really exciting that yeah you and others are
connected with some of the working la mosque is doing because he's literally going out into that space we're
exploring our universe and it's wonderful that is exactly why Elon Musk is so it misunderstood right misconstrue
him is some kind of pessimistic dooms there the reason he cares so much about the I safety is because he more than
almost anyone else appreciates these amazing opportunities they will squander if we wipe out out here on earth
and we're not just gonna wipe out the next generation but all generations and this incredible opportunity that's out
there that would be really a waste and AI for people who think that we better
to do without technology well let me just mention that if we don't improve
our technology the question isn't whether humanity is gonna go extinct question is just whether we're gonna get taken out by the next big asteroid or
the next supervolcano or something else dumb that we could easily prevent with more tech right and if we want life to
flourish throughout the cosmos AI is the key to it as I mentioned a lot of detail
in my book right there even many of the most inspired sci-fi writers I feel have
totally underestimated the opportunities for space travel especially to other
galaxies because they weren't thinking about the possibility of AGI which just
makes it so much easier right yeah so that goes to your view of AGI that
enables our progress that enables a better life so that's a beautiful that's a beautiful way to put it and then
something to strive for so max thank you so much thank you for your time today it's been awesome thank you so much
thanks Super Bowls Rory yes
you

----------

-----
--38--

-----
Date: 2018.04.17
Link: [# MIT AGI: Autonomous Weapons Systems Policy (Richard Moyes)](https://www.youtube.com/watch?v=U6lJI-NSfBY)
Transcription:

welcome back to 6s $0.99 artificial general intelligence today we have
Richard Moyes he's the founder managing director of article 36 a uk-based
not-for-profit organization working to prevent the unintended unnecessary and
unacceptable harm caused by certain weapons including autonomous weapons and nuclear weapons he will talk with us
today about autonomous weapon systems in the context of AI safety this is an
extremely important topic for engineers humanitarians legal minds policy makers
and everybody involved in paving the path for safe positive future for AI in
our society which I hope is what this course is about Richard flew all the way
from the UK to visit us today in snow in Massachusetts so please give him a warm welcome
thanks very much Lex and thank you all for coming out as Lex said I work for a
not-for-profit organization based in the UK we specialize in thinking about policy and legal frameworks around weapon
technologies particularly and generally about how to establish more constraining policy and legal frameworks around
around weapons and I guess I'm mainly going to talk today about these issues
of to what extent we should enable machines to kill people to make
decisions to kill people it's I think your conceptually very interesting topic quite challenging in lots of ways
there's lots of unstable terminology and lots of sort of blurry boundaries my own
background as we said we work on weapons policy issues that I've worked on the development of two legal international
legal treaties prohibiting certain types of weapons I worked on the development of a 2008 Convention on Cluster
Munitions which prohibits cluster bombs and worked on our organization pioneered
the idea of a treaty prohibition on nuclear weapons which was agreed last year in the UN and we're part of the
steering group of ICANN the international campaign to abolish nuclear weapons which won the Nobel Peace Prize last year so that was a good
year for for us the issue of autonomous weapons killer robots which I'm going to
talk about the day we're also part of an NGO non-governmental organization coalition on this issue called the
campaign to stop killer robots it's a good name however I think when we get
into some of the details of the issue will find that perhaps the the snappiness of the name in a way masks
some of the complexity that lies on underneath this but this is a live issue
in international policy and legal discussions at the United Nations for the last several years three or four
years now there have been groups of governments coming together to discuss autonomous weapons and whether or not
there should be some new legal instrument that that tackles this this issue so it's a it's a live political
issue that is being debated in in policy legal circles and really my my comments that
they are going to be speaking to that context I guess I'm going to try and give us a bit of a briefing about what
the issues are in this international debate how different actors are orientating to these issues some of the
conceptual models that we we use in that so I'm not really going to give you a particular sales pitch as to what you
should think about this issue though my own biases are probably going to be fairly evident during the process but
really to try and lay out a bit of a sense of how these these questions debated in the international political
scene and maybe in a way that's useful for reflecting on sort of wider
questions of how AI technologies might be orientated to an approach by by
policymakers and and and the legal framework so in terms of the structure
of my comments I'm going to talk a bit about some of the pros and cons that have put forward around autonomous
weapons or movements towards greater autonomy in weapon systems I'm going to talk a bit more about the political
legal framework within within which these discussions are taking place and then I'm going to try to sort of lay out
some of the models the conceptual models that we as an organization have developed and sort of using in relation
to these issues and perhaps to reflect a bit on where I see the political conversation the legal conversation on
this going at an international level and maybe just finally to try to reflect on
or just draw out some more general thoughts that I think occur to me about
what some of this says about thinking about AI functions in in different social social roles but before getting
into that sort of pros and cons type type stuff I just wanted to start by
suggesting a bit of a sort of conceptual timeline because one of the things this
could be the present one of the things
you find when we start when you say to somebody when we work on this issue of autonomous weapons they tend to
orientate to it in into fairly distant ways some people will say oh you mean
armed drones and you know we know what armed drones are they being used in the
world today and that's kind of an issue here and in the present right drones but
other people most of the media and certainly pretty much every media photo
editor thinks you're talking about the Terminator over here yeah and maybe a
bit of Skynet thrown in so this is a sort of advanced futuristic sci-fi
orientation to the to the issues am i thinking about this I come from a background of working on the impact of
weapons in the present unless I'm less concerned about this area of my thinking
of my anxieties or my concerns around this issue don't come from from this area I do this light a bit Wiggly here
because I also don't want to suggest there's any kind of you know teleological certainty going on here
this is just an imaginary timeline but I think it's important just in terms of
situating where I'm coming from in the debate that I'm definitely not starting at that end and yet in the political
discussion amongst governments and States well you have people come in and at all sorts of different positions
along here imagining their autonomous weapons may exist at you know somewhere
along this this sort of spectrum so I'm going to think more about stuff that's going on around here and how some of our
conceptual models really build around some of this thinking not so much actually armed drones but some other
some other systems but my background before I started working on policy and
law around weapons was was setting up and managing land my clearance
operations overseas and well they've been around for they've been around for
quite a long time land mines and
I think it's interesting just to start with just to reflect on the basic anti-personnel landmine it's simple but
it gives us I think some sort of useful entry points into thinking about what an autonomous some weapon system might be
in its most simple form if we think about a landmine well essentially we
have a person and there's an input into the landmine and there's a function that
goes on here pressure is greater than X person they turn on the landmine there's
a basic mechanical algorithm goes on and you get an output explosion that goes
back against the person who trod on the landmine so it's a fairly simple system
of a signal a sensor taking a signal from the outside world the landmine is
viewing the outside world through its sensor it's a basic pressure plate and according to a certain calculus here you
get an output and it's directed back at this person and it's a loop and that's one of the things that I think is
fundamental essentially to understanding the idea of autonomous weapons and in a way this is where the autonomy comes in
but there's no other person intervening in this process at any point there's just a sort of straightforward
relationship from the person or object that has initiated the the system back
into the back into the effects that are being that are being applied so in some
ways we'll come back to this later and think about how some of the basic building blocks of this may be there in
our thinking about other weapon systems and weapon technologies as they're they're developing and maybe thinking
about landmines and thinking about these the processes of technological change we see a number of different dynamics at
play in this sort of imaginary timeline anti-personnel landmines of course a static they just sit in the ground where
you have left them but we get more and more mobility pups as we go through this system certainly armed drones and other
systems that I'll talk about you start to see more mobility in the in the weapon system
perhaps greater sophistication of sensors I mean a basic pressure plate
just gauging weight that's a very simple sensor structure for interrogating the
world we have much more sophisticated sensor systems in weapons now so we have
weapon systems now that are looking at radar signatures they're looking at the heat shapes of objects and we'll come
back and talk about that but more sophistication of sensors and more sophistication of the of the computer
algorithms that are basically interrogating those sensor those sensor inputs perhaps a little bit as well of a
movement in this sort of trajectory from physically very unified objects always
sort of wrestle slightly whether this is the word I want but it's a sort of self-contained entity the the landmine
whereas as we move in this direction maybe we see more dispersal of functions through different through different
systems and I think that's another dynamic that when we think about the development of autonomy and weapon
systems it might not all live in one place physically moving around in one place it can be an array of different
systems functioning in different different places perhaps for people with a sort of AI
type of mindset maybe there's some sort of movement from more specific types of
AI functioning here use of different specific AI functions here to something more general going in this direction I'm
wary of necessarily buying straight forward into that but maybe you could see some movement in that sort of direction so I just want to sort of put
this to one side for now but we'll come back to it and think about some systems that are existing here that I think sort
of raise issues for us and around which we could expand some some models but I just wanted to have this in mind when
thinking about this that we're not necessarily we're definitely not for me thinking about humanoid robots walking
around fighting like a soldier rather we're thinking about developments
and trajectories we can see coming out of established military systems now so I
was going to now a bit about the political and the legal context obviously there's a lot of
complexity in the worlds of politics and legal structures and I don't want to get too bogged down in it but I think in
terms of understanding the basics of this debate on the international landscape have to have a bit of
background in that area essentially there's I think three main types of
international law that we're concerned with here and again concerned with international law rather than domestic
legislation which any individual state can put in place whatever domestic legislation they want we're looking at
the international legal landscape basically you have international human rights law which applies in pretty much
all circumstances and it involves the right to life and the right to dignity and a various other legal protections
people and then particularly prominent in this debate if you have what's called
international humanitarian law which is the rules that govern behavior during
armed conflict and provide obligations on militaries engage in armed conflict for how they have to conduct themselves
this isn't the legal framework that decides whether it's okay to have a war or not this is a legal framework that
once you have in the war this is the obligations that you've got you've got to follow and it basically includes
rules that say you know you're not allowed to directly kill civilians you've got a aim your military efforts
at the forces of the of the enemy at enemy combatants you're not allowed to
kill civilians directly or deliberately but you are allowed to kill some civilians as long as you don't kill too
many of them for the military advantage that you're trying to achieve so there's a sort of balancing acts like this this
is called proportionality nobody ever really knows where the balance lies but
it's a it's a sort of principle of the law that once you can't kill civilians you mustn't kill an excessive number of
civilians these are general rules these apply pretty much to all states in in
armed conflict situations and then you have treaties on specific weapon specific weapon types and this is really
where you have weapons that are considered to be particularly problematic in some way and it's decided
a group of states decide to develop and put in place agree a treaty that that applies specifically to
those to those weapons I think it's important to recognize that these legal
treaties are all developed and agreed by States they're agreed by international
governments talking together negotiating what they think the law should say and they generally only bind on States if
they choose to adopt that legal instrument so I guess what I'm
emphasizing there is a sense that these are sort of social products in a way their political products it isn't a sort
of magical law that's come down from on high perfectly written to match the needs of humanity
it's a negotiated outcome developed by a complicated set of actors who may or may
not agree with each other on all sorts of things and what that means is there's quite a lot of wiggle room in these
legal frameworks and quite a lot of uncertainty within them it lawyers of international military and law will tell
you that's not true but that's because they're particularly keen on that legal framework but in reality there's a lot
of a lot of fuzziness to what some of the legal provisions what some of the legal provisions to say and it also
means that the extent to which this law binds on people and bears on people is also requires some social enactment
there's not a sort of world police who who can follow up on all of these these
legal frameworks it requires a sort of social function from States and from other actors to keep articulating their
sense of the importance of these legal rules and keep trying to put pressure on other actors to to accord with them so
the issue of autonomous weapons is in discussion at the United Nations under a
framework called the UN Convention on conventional weapons and this is a body that has the capacity to agree new
protocols new treaties essentially on specific weapon systems and that means that diplomats from lots of countries
diplomats from the US from the UK from Russia and Brazil and China and other
countries of the world will be sitting around in a conference room putting forward their perspectives on this issue
and trying to find common ground or trying not to find common depending on what sort of outcome
they're they're working towards so you know the UN isn't a completely separate entity of its own it's just the
community of states in the world sitting together talking about talking about things so main focus of concern in those
discussions when it comes to autonomy is not some sort of generalized autonomy or
not autonomy of all of its forms that may be pertinent in the military space it's it's rather much more these these
questions of how the targets of an attack are selected identified decided
upon and how is the decision to apply force to those targets made and it's really these are sort of the critical
functions of weapon systems where the movement towards greater autonomy is considered a source of anxiety
essentially that we may see machines making decisions on what is a target for
an attack and choosing when and where forces apply to that specific to that
specific target so obviously in this context not
everybody's like minded on this there are potential advantages to increasing autonomy in weapon systems and there's
potential disadvantages and problems associated with it and within the you
know within this international discussion we see different perspectives laid out and some states of course will
be able to see some some advantages and some disadvantages it's not a black and white sort of discussion in terms of the
possible advantages for autonomy I mean one of the key ones ultimately is framed
in terms of military advantage that we want to have more autonomy and weapon systems because it will maintain or give
us military advantage over possible adversaries because in the end military stuff is about winning wars right so you
want to maintain military advantage and military advantage number of factors
really within that speed is one of the speed of decision making can computerize
or timer systems make decisions about where to apply force faster than a human would be capable of doing and and
therefore this is this is advantageous for us also speed allows for
coordination of numbers so if you want to have swarms of systems you know
swarms of small drones or somesuch you need quite a lot of probably autonomy
and decision-making and communication between those systems because again the level of complexity and the speed
involved is is greater than a human would be able to sort of manually engineer so speed both in terms of
responding to external effects but also practical donating your own forces reach
potential for autonomous systems to be able to operate in communication denied
environments where if you're relying on an electronic communications link to say a current armed drone maybe in a future
battle space where the enemy is denying communications in some way you could use
an autonomous system to still fulfill a mission without without needing to rely on that communications infrastructure
general force multiplication there's a bit of a sense that there's going to be more and more teaming of machines with with humans so machines
operating alongside humans in the battlespace and then there's importantly
as it's presented at least a sense that these are systems which could allow you to reduce the risk to your own forces
that maybe if we can put some sort of autonomous robotic system at work in a specific environment then we don't need
to put one of our own soldiers in that position and as a result we're less likely to have casualties coming home
which of course politically is problematic for maintaining any sort of conflict posture so against all that
stuff there's a sense that I think most fundamentally there's perhaps a moral
hazard that we come across at some point that there's some sort of boundary we're
seeing or conceptualizing a situation where machines are deciding who to kill
in a certain context is just somehow wrong and well that's not a very easy
argument to just start you know articulate in a sort of rationalized sense but there's some sort of moral
revulsion that perhaps comes about at this sense that machines are now deciding who should be killed in a
particular in a particular environment there's a set of legal concerns can
these systems be used in accordance with the existing legal obligations and I'm
going to come on a little bit later to our orientation and the legal side which is which is also about how they may
stretch the fabric of the law and the structure of the law as we see it there's some concerns in this sort of
legal arguments for me that we sometimes slip into a language of talking about
machines making legal decisions will a machine be able to apply the rule of
proportionality properly there's dangers in that I know what it means but at the
same time the law is addressed to humans the law isn't addressed to machine so it's humans who have the obligation to
enact the legal obligation a machine may do a function that is sort of analogous to that legal decision but ultimately to
my mind is still a human in us be making the legal determination based on some predict prediction of what that
machine will do and I think this is a very dangerous slippage because even you know senior legal academics can slip
into this mindset which is which is a little bit like handing over the legal framework to machines before you've even
got on to arguing about what we should or shouldn't have so we need to be careful in that area and it's a little
bit to do with for me continuing to treat these technologies as machines rather than into treating them as agents
in some way of a sort of equal or equivalent or similar moral standing to
two humans and then we have a whole set of wider concerns that are raised so
we've got moral anxieties legal concerns and then a set of other concerns around risks that could be unpredictable risks
there's a sort of normal accidents Theory maybe you come across that stuff there's a bit of that sort of language in the debate about complicated systems
and not being able to you know not be able to avoid accidents in in some respects some anxieties about maybe this
will reduce the barriers to engaging in military action maybe being able to use
autonomous weapons will make it easier to go to war and some anxieties about sort of international security and
balance of power and arms races and the like these are all significant concerns
I don't tend to think much in this area partly because there's they involved put a lot of speculation about what may or
may not be in the future and they're quite difficult to populate with with sort of more grounded arguments I find
but that doesn't mean that they aren't significant in themselves but I find them less straightforward as an entry
point so in all of these different issues there's lots of unstable
terminology lots of arguments come in in different directions and our job as an NGO in a way is we're trying to find
ways of building a constructive conversation in this environment which can move towards States adopting a more
constraining orientation to this movement towards autonomy and the main
tool we've used to work towards that so far has been - perhaps stop focusing on the
technology per se and the idea of what is autonomy and how much autonomy is a
problem and to bring the focus back a bit onto what is the human element that we want to preserve in all of this
because it seems like most of the anxieties that come from a sense of a
problem with autonomous weapons are about some sort of absence of a human element that we want to preserve but
unless we can in some way define what this human element is that we want to preserve I'm not sure we can expect to
define its absence very straightforwardly so I kind of feel like we want to pull the discussion on to a focus on the on the human on the human
element and the tool we've used for this so far has been basically a terminology
about the need for meaningful human control and this is just a form of words that we've sort of introduced into the
debate and we've promoted it in discussions with diplomats and with different actors and we've built up the
idea of this terminology as as being a sort of tool it's a bit like a meme right you you create the the terms and
then you use that to sort of structure the discussion in a in a productive in a productive way one of the reasons I like
it is it works partly because the word meaningful doesn't mean anything particular or at least it means whatever
you might want it to mean and I find that an enjoyable sort of tension in in
that but the term meaningful human control has been quite well picked up in in the literature on this issue and in
the diplomatic discourse and it's helping to structure us towards a what
we think of the key questions basic arguments for the idea of meaningful
human control from my perspective are quite simple and intended to use basically a sort of absurdist sort of
logic such a thing first of all really to recognize that no
governments are in favor of an autonomous weapon system that has no human control whatsoever right nobody is
arguing that it would be a good idea for us to have some sort of autonomous
weapon that just flies around the world deciding to kill people we don't know who it's going to kill or why it doesn't
have to report back to us but you know we're in favor nobody's in favor of this right this is obviously ridiculous so there needs to
be some form of human control because we can rule out that sort of you know
ridiculous extension of the argument and on the other hand if you just have a
person in a dark room with a red light that comes on every now and again and
they don't know anything else about what's going on but they're the human who's controlling this autonomous weapon and when the red light comes on they
push the fire button to launch a rocket or something we know that that isn't
sufficient human control either right there's a person doing something there's a person engaged in the process but
clearly it's just some sort of mechanistic pro-forma human engagement
so between these two kind of ridiculous extremes I think we get the idea that
there's the some sort of fuzzy fuzzy line that that must exist in there in
there somewhere and that everybody can in some way agree to the idea that such a line should exist so the question then
for us is how to move the conversation in the international community towards a productive sort of discussion of where
the parameters of this line might be conceptualized so that's brought us on
to thinking about a more substantive set of questions about what are the key elements of meaningful human control and
we've laid out some basic elements so I might get rid of that fuzzy line because it's a bit useless anyway isn't it and
then I can put my key elements on here well one of them is predictable reliable
transparent technology this is kind of
before you get into exactly what the system is going to do we want the technology itself to be sort of well
made and it's you know it's going to basically do what it says it's going to do whatever that is and we want to be
able to understand it to some extent obviously this becomes a bit of a challenge in some of the AI TAC
functions where you start to have machine learning issues unlike these issues of transparency perhaps they
start to come up a little bit a little bit there but these are kind of issues in the design and the development of
systems another thing we want to have is and I think this is a key one is
accurate information and it's accurate
information on the intent of the commander the world the outcome what's
the outcome we're trying to achieve how does the technology work and what's the
context third one there's only four so
it won't take long third one is timely intervention human
intervention it should be it would be good if we could turn it off at some
point if it's going to be a very long acting system good if we turn it off maybe and then the fourth one is just a
sort of framework of accountability
so we're thinking that basic elements of human control can be broken down into
these areas some of them are about the technology itself how it's designed and
made how do you verify and validate that it's going to do what the manufacturers have said it's going to do can you
understand it this one I think is the key one in terms of thinking about the
issue and this is what I'm going to talk about a bit more no but accurate information on what's the commander's
intent what do you want to achieve in the use of this system what effects
is it going to have I mean this makes a big difference how it works these factors here involve what are the target
profiles that it's going to use where is our land mine on the land mine of course it was just pressure right pressure is
being taken as a pressure on the ground is being taken as a proxy for a military target for a human who would you know
assume as a military target but in these systems we're going to have different target profiles different heat
shapes different different patterns of data that the system is going to operate on the basis of what sort of actual
weapon is it going to use to apply force it makes a difference if it's going to just fire a bullet from a gun or if it's going to drop a 2,000 pound bomb I mean
that has a different effect and the way in which you envisage and sort of control for those effects is going to be
different in those different cases and finally very importantly these issues of
context information on the context in which the system will will operate
context of includes are there going to be civilians present in the area can you assess are
there going to be other objects in the area that may present a similar pattern to the proxy data you know if you're
using a heat shape of a vehicle engine now it might be aimed at a tank but if there's an ambulance in the same
location is an ambulances vehicle engine heat shape sufficiently similar to the
tank to cause some confusion between the two sets of information like that in
context of course varies in different you know obviously varies in different environments but I think we can see different domains in this area as well
which is significant that operating in the water or in the ocean you've probably got a less cluttered
environment a less complex environment than if you're operating in an urban in an urban area so that's another factor
that needs to be taken into into accounting in this so I just wanted to
talk a little bit about some existing systems perhaps and think about them in
the context of this these sort of set of issues here one system that you may may
be aware of is sir it's on a boat okay
so something like the Phalanx anti-missile system it's on a boat but
there's various anti-missile systems and it doesn't the details don't matter in this context these are systems that a
human turns it on so a human is choosing when to turn it on and a human turns it
off again but when its operating it's the radar is basically scanning an area
of an area of sky up here and it's
looking for fast-moving incoming objects because basically it's designed to automatically shoot down incoming
missiles or rockets right so thinking about these characteristics you know
what the outcome you want is you want your boat not to get blown up by an incoming missile and you want to shoot down any incoming
missiles you know how the technology works because you know that it's basically using radar to see incoming fast-moving
signatures and you have a pretty good idea of the context because the skies
are fairly uncluttered comparatively and you'd like to think that any fast-moving
incoming objects toward you here are probably going to be incoming missiles not guaranteed to be the case one of
these systems shot Donna and Iranian passenger airliner but uh by accident which is obviously a significant
accident but basically you have a sense of you know so the fact that the data
that you're using tracked pretty well to the target objects if not absolutely precisely you've got a relatively
controllable environment in terms of the sky and you've got a human being this
system isn't really mobile I mean it's kind of mobile insofar as the boat can move around but the person who's
operating it is you know they're mobile in the same place so so it's relatively
static so I think looking at that you could suggest that there's still a
reasonable amount of human control over this system because when we look at it in terms of a number of the functions
here we can understand how that how that system is being managed in a human
controlled way and although there's still a degree of autonomy or at least it's sort of highly automated in the way
that it actually identifies the targets and moves the gun and shoots down the incoming object the basic framework is
one in which I feel like and I mean it's not for me to say but I feel like still a reasonable amount of human control as
being being applied okay I know that sort of system know I've got to draw
some tanks or something now see okay well I'm just going to draw them like
that because it otherwise it's actually long okay these are tanks armored
fighting vehicles ignore the graphic design skills there are sensor fuse
weapon systems so a commander at a significant distance right can't necessarily see the location of
the of the tanks but they know that there's some enemy tanks in this area over here right and maybe they have some
sense of what this area is they're not in the middle of a town they're out in the open so they have an understanding
of the context but maybe not a detailed understanding of the context so the weapon system is going to fire multiple
warheads into this target area the commander is decided upon the target of
the attack this group of tanks here but as the warheads approach the target area
the warheads are going to communicate amongst themselves and they're going to allocate themselves to the specific to
the specific objects and they're going to detect the heat shape of the vehicles
engines they're going to match that with some profile that says this is a enemy armored fighting vehicle as far as we're
concerned and then they're going to apply force downwards from the air using
a bit of explosive engineering shaped-charge which focuses a blasts a blast of explosive basically a jet of
explosives downwards onto the specific targets and okay
so in this situation well have the has the weapon system chosen the target well
it's a bit ambiguous because as long as we conceptualize the group of tanks as that as the target then a human has
chosen the target and the weapon system is essentially just been efficient in its distribution of force to the target
objects but if we see in the individual vehicles as individual targets maybe the
weapon system has chosen the targets potentially some advantages of automated
of autonomy in this situation from my perspective this kind of ability to
focus a jet of explosive force directly on the object that you're looking to strike so long as you've got the right
object this is much better than setting off lots of artillery shells in this area which would have a much greater
explosive force effect on the surrounding area probably put a wider population at risk
so there's a sort of set of considerations here that I think significant so we have these systems you
know these systems exist exist today you can ask questions about whether those Heat shape profiles of those
objects sufficiently tightly tied to enemy fighting vehicles or whatever but I think it can be conceptualized
reasonably straightforwardly in those terms but the area where I start have a
problem with this stuff is in the potential for this circle or this
pattern just to get bigger and bigger essentially because it's all reasonably
straightforward when you put the tanks reasonably close together and you can envisage having one sort of one sort of
information about this area which allows you to make the legal determinations that you need to make but once these
tanks get spread out over a much larger area and you have a weapon system that using basically the same sorts of
technological approach is able to cover a substantially wider area of enemy
terrain over a longer period of time then it suddenly gets much more difficult for the for the military
commander to have any really detailed information about the context in which force will actually be applied and for
me this is I think the main point of anxiety or point of concern that I have in the way in which autonomy and weapon
systems is is likely to develop over the immediate future because under the legal
framework a military commander has an obligation to apply certain rules in an attack and an attack is it's not
precisely defined but it needs to have some I think some spatial and conceptual
boundaries to it that allow a sufficient granularity of legal application because
if you if you treat this as an attack I think that's fine as you expand it out so you've got vehicles across a whole
wide area of a country say across the country as a whole using the same sort of extension logic as is in some
previous arguments once you've got vehicles across the whole country and you're saying in this attack I'm going
to just target the vehicles of the enemy and you send out your warheads across the whole location now I don't think
that's going to happen in immediate term but I'm just using that as a sort of conceptual
challenge you start to have applications of actual physical force in all sorts of locations where a commander really can't
assess in any realistic way what the actual effects of that are going to be and I think at that point you can't you
can no longer say that there is sufficient human control being being applied so this capacity of AI enabled
systems or AI driven systems to expand attacks across a much wider geographical
area and potentially over a longer period of time I think is a significant challenge to how the legal framework is
is understood at present not one that relies upon determinations about whether
this weapon system will apply the rules properly or not but rather one which
involves the the frequency and the proximity of human decision-making to be
sort of diluted progressively over progressively over time so that's a
significant area of concern for me final sort of sort of concerns in these areas is around these issues about
encoding of targets I think we could say pretty clearly that weight is a very
meager basis for evaluating whether something is a valid military target or
or not right the significant problems we're suggesting that we could just take
the weight of something as being sufficient for us to decide is this a target or not in any of these processes
we have to decide that certain patterns of data represent military objects of
some type and of course in a way I think what we sort of scenes are proponents of
greater and greater autonomy and weapon systems is a sense that well as we expand the scope of this attack we just
need to have a more sophisticated system that's undertaking the attack that can take on more of the evaluation and more
of this process of basically mapping the coding of the world into a set of
decisions about the application of force but overall yeah I'm skeptical about the
way in which our social systems are likely to go about mapping people
indicators of identities into some sort of fixed sense of military objects or
military targets as a society over you know the last hundred years there's been
plenty of times where we've applied certain labels to certain types of people certain groups of people based on
various indicators which apparently seemed reasonable to some significant
section of society at the time but that ultimately I think we've subsequently thought were highly problematic and so I
think we need to be very wary of any sort of ideas of thinking that we can encode in terms of humans particularly
very concrete indicators that certain groups of people should be considered valid targets or or not just going to
say a couple of final things about future discussions in the CCW the chair
of the group of governmental experts that's the body that's going to discuss autonomous weapons has asked States for
the next meeting which would take place in April to come prepared with ideas about the touch points of human machine
interaction this is a sort of code for what are the ways in which we can
control technology so I suppose from our context as an organization we'll be
looking to get States to start to try and lay out this kind of framework as being the basis for their perception of
the ways in which the entry points to control of technology could be thought about again it's really a question of
structuring the debate we won't get into detail across all of this but I think it's plausible that this year and next
we'll start to see the debate falling into some adoption of this kind of framework which i think will give us
some tools to work with I think at least if we start to get some agreement from a significant body of states that these
are the sort of entry points we should be thinking about in terms of control of technology it will give us a bit of
leverage for a start towards suggesting an overarching obligation that there should be some sort of meaningful or
sufficient human control but also in a way of thinking about that and interrogating that as new technologies
develop in the future that we can leverage in some in some I feel reasonably confident about that
but it's a difficult political environment and you know it's quite possible that I don't see any rush among
states to move towards any legal controls in this in this area just as a few very final thoughts which may be a
bit more abstract in my thinking on this I feel like and this sort of reflecting
on maybe some dynamics of AI functioning my anxiety here about the expansion of
the concept of attacks and in the same in in conjunction without a sort of
breaking down at the granularity of the legal framework I think this is another a sort of generalizing function again
and it's a movement away from more specific legal application by humans to perhaps
pushing humans people towards a more general legal orientation and I feel
like in the context of conflict we should be pushing for a more specific and more focused and more regular
application of human judgments and moral moral agency that isn't to say that I
think humans are perfect in any way there's lots of problems with humans but at the same time I think that we should
be very wary of thinking that violence is something that can be somehow perfected and that we can encode how to
conduct violence in some machinery that will then provide an adequate social
product for society as a whole and I guess there's a very final thought a bit linked to that is there's some questions
in my mind about how this all relates to bureaucracy in a way and in a sense that some of the functions that we're seeing here and some of the AI functions that
we see here in many ways related I think to bureaucracy to the encoding and
categorization of data in certain ways and just a very fast management of that
bureaucracy which is really an extension of the bureaucracies that we already that we already have and I think
extending that too far into the world of violence and the application of force to people will will precipitate painful
effects for us as a society and as it brings to the fore I think some of the underpinning and the paintings are
rationales of that of that beer framework so there we go it's a bit of a
broad-brush sketch so this questions got
Q&A
a little bit multifaceted but as humans evolve and adapt to increasingly autonomous weapons the complexity and
sophistication could increase with expansion of targets and types and target area is do you think there's like
a limit to which we can prepare against such an epic evolution and do you think
that bureaucracy can keep up with how fast these the autonomy of these weapons
couldn't develop over time yeah I'm not sure I caught all the first business
question but there's definitely it's definitely a challenge that the types of legal discussions at the UN Convention
on conventional weapons they they're not famous for going too quickly in fact
they're incredibly slow and in that framework every state essentially has a
veto over everything so even over the agenda of the next meeting if you know
if the US wants to block the agenda they can block the agenda let alone block the outcome that might come if you could
agree an agenda so so every state has an ability to keep things moving very
slowly there and that's definitely a challenge in the context where pace of technological development moves pretty
quickly the only thing I would say which I forgot to mention before in terms of thinking about the dynamics in this debate is that it's not
straightforwardly a situation where militaries really want loads more autonomous weapons and other people
don't I mean military commanders also like control and they they like troops on the
ground like control and they like trust and confidence in the systems that they're operating around you don't wanna
get blown up by their own equipment and military commanders like control and like to know what's happening so there
are some constraints within the military structures as well to to the overall
sort of development here I guess from our side in terms of this sort of how to constrain against this expansion of
attacks in the expansion of sort of so objects that may be attacked for
autonomous systems in a way that's why I feel like developing the idea that there's a principle of human control that needs to be applied even if it's a
bit fuzzy in its boundaries we can use that and interrogate it as a social process to try and keep constraint going
back towards the specific because in the end like I said earlier these legal structures are sort of social processes
as well and it's not very easy it's not something where you can just straightforwardly draw a line and then no new technologies will come along that
challenge your expectations right rather we need to find the sort of camp on the international legal political landscape
we need to sketch out that parameters of that camp in legal terms and then we
need people to turn up at those meetings and continuously complain about things and put pressure on things because
that's the only way over time where you maintain that sort of interrogation of future technologies as they come out of
the pipeline or or whatever so it's a sort of social function I think the
balance between like how fast science would be like dancing in this field versus like how fast we are so you can
move to keep up yeah I don't know you can just be resolved I think it's an ongoing it's got to be an ongoing social political process in a way given that
this course is on AGI and we'll likely see a wide variety of different kinds of
autonomous systems in the future can you give us perhaps some sort of extrapolation from this domain to a
broader set of potentially risky behaviors that more autonomous and more
intelligent systems would do and ways that you know the creators of such systems such as essentially the folks
sitting in this room can change what they're doing to make those safer yeah I
mean I think useful to think about in some ways these
ideas of from the present from where we are now how can people involved in
developing different technologies new technological capacities just be thinking of the potential outcomes in
this sort of weaponization area and building in some orientation to their work that the thinks about that and
thinks about what the potential consequences of work can be I mean I think in some ways the risky outcomes
type thinking I mean again it gets you into hypothetical arguments but the the
idea of two sides both with substantial autonomous weapon system capabilities is
probably the sort of area where these ideas of accidental escalations come to
the fore that if you've got to you know adversary orientated States with
substantial autonomous systems then there's a potential for interactions to
occur between those systems that rapidly escalate a violent situation in a way
that greater capacity for human engagement would allow you to to curtail
it and to stall it and I think I mean I know in other areas of you know
algorithm functioning in society we've seen aspects of that right in a sort of
probably in the financial sector and another such location so so I think yeah
those area those ideas have sort of rapidly escalating cascading risks is is
a is a concern in that area again based on hypothetical thinking about you know stuff last question all right what do
you think of this criteria so we have this tank example on the right our
simulations our ability to simulate things is getting better and better what if we showed a simulation of what would
happen to a person that has the ability to hit the Go button on it and if the simulation does not have enough fidelity
we consider that a no-go we we cannot do that or if the simulation shows it does
have a fun fidelity and it shows a bad outcome then maybe that would be a criterion in which
to to judge this circumstance on the right and that could also let us as that
circle gets bigger and bigger it can let us kind of put a it could let us cap
that by saying hey if we don't if we do not have enough information to make this
simulation to even show the person then it's a no-go yeah yeah I think in a way
this is an issue of modeling right based on contextual information that you that you have so maybe with technological
developments you have a better capacity for modeling specific situations I
suppose the challenge is how do you in a sort of timely manner especially in a conflict environment where tempo is
significant can you can you put the data that you have into some sort of modeling
system adequately but I don't see any problem with the idea of using AI to
model the outcomes of specific attacks and you know give you readouts on what
the likely effects are going to be I guess the challenge is that what counts as of adequate effect and where the
boundary lines of sufficient information and insufficient information fall they're kind of open questions as well
right and you know militaries tend to like to leave some openness on those
those points as well but but I think there can be definitely a role for modeling in better understanding what
what effects it can be great let's give her a chair big hand thank you

----------

-----
--37--

-----
Date: 2018.04.09
Link: [# MIT-AVT: Data Collection Device (for Large-Scale Semi-Autonomous Driving)](https://www.youtube.com/watch?v=HVx9bwiMWGQ)
Transcription:

the MIT autonomous vehicle technology
study is all about collecting large
amounts of naturalistic driving data
behind that data collection is this box
right here that Dan is term writer a Dan
is behind a lot of the hardware work we
do embedded systems and Michael is
behind a lot of the software the data
pipeline as well as just offloading the
data from the device would like to tell
you some of the details behind rider and
behind the sensors now we have three
cameras in the car and the wires are
running back into the trunk and that's
where the rider is sitting there's a lot
of design specifications to make this
system work month after month reliably
across multiple vehicles across multiple
weather conditions and so on at the end
of the day with multiple sensor streams
we have the three cameras coming in we
have IMU GPS and all of the raw canned
messages coming from the vehicle itself
and all of that has to be collected
reliably synchronized and post processed
once we offload the data first we have a
single board computer here running a
custom version of Linux that we wrote
specifically for this application this
single board computer integrates all of
the cameras all the sensors GPS can IMU
and offloads it all on to the
solid-state hard drive that we have on
board there are some extra components
here for cellular communication as well
as power management throughout the
device here we have our single board
computer as well as sensor integration
and our power system this is our
solid-state drive that connects directly
to our single board computer on our
single board computer we have a sensory
integration board on top here you'll be
able to see our real-time clock as well
as its battery backup and can
transceiver on the reverse side of this
board we have our GPS receiver an IMU
this is our can't control power board
which monitors can throughout the car
and determines whether or not the system
should be on or off when the system is
on this sends power through a buck
converter to reduce the 12 volts from
the vehicle down to 5 volts to operate
the single board computer we also have a
4G wireless connection on board to
monitor the health of rider and
determine things like free capacity left
on our dry
as well as temperature and power usage
information the cameras connect to Ryder
through this USB hub right here so we
needed the box to do at least three
things one was record from at least
three cameras record can vehicle
telemetry data and then lastly be able
to store all this data onboard for a
long period of time such that people
could drive around for months without
having us to offload the data from their
vehicles and so when we're talking about
hundreds of thousands of miles of worth
the data so for about every hundred
thousand miles uncompressed that's about
a hundred petabytes of video data so one
of the key other requirements was how to
store all this data both on the device
and how to be able to then offload us
successfully onto thousands of machines
to be then processed with the computer
vision with a deep learning algorithms
that we're using and one of the
essential elements for that was to do
compression onboard so these are
Logitech c920 webcam
they can do up to 1080p at 30 frames a
second the major reason why we went with
these is because they do onboard h.264
compression of the video so that allows
us to offload all the processing from
our single board computer onto these
individual cameras allowing us to use a
very slim pared-down
lightweight single board computer to run
all of these sensors this is the
original Logitech c920 that you would
buy at a store these are the two same
Logitech c920 s although they were put
into a custom-made camera case just for
this application what this allows us to
do is at our own C s type lenses to
enable us to have a zoom lens as well as
a fisheye lens from within the car
allowing us a greater range of field of
views inside the vehicle so this is the
fisheye lens this is the zoom lens and
the CS type there's also C type those
are types of standard lenses that are
connect to these types of cameras often
to the industrial cameras that are often
used for our Thomas vehicle applications
we tested these cameras to see what
would happen to them if placed inside of
a
a hot car and it's um on a summer day we
wanted to see what these cameras still
be able to hold up to this to the heat
in the summer and still function as
needed we put these cameras in a toaster
a scientific toaster what was the
temperature that went up to we cycled
these cameras between 58 and 75 degrees
Celsius which is about the maximum of a
hundred and fifty degree Fahrenheit max
temperature that a car would get in in
the summer we also cranked it up to 127
degrees Celsius just to see what would
happen to these cameras after prolonged
long-term high heat in fact these
cameras continued to work perfectly fine
after that creating a system that would
intelligently and autonomously turn off
and on to start and end recording was
also a key aspect to this device since
people were just going to be driving
their normal cars we couldn't rely on
them necessarily to start and end
recording so this device rider
intelligently figures out when the car
is running and when it's off to start
and stop recording automatically so how
does writers specifically know when to
turn on so we use can to determine when
the system should turn off and on when
can is active the car is running and we
should turn the system on when can is
inactive we should turn the system off
and end recording this also gives us the
ability to trigger on certain can
messages so for instance if we want to
start recording as soon as they approach
the car and unlock the door we can do
that or if they turn the car on or they
put it into drive or so on
the cost of the car that the system
resides in is about a thousand times
more than the system itself so these a
hundred thousand plus dollar cars so
we'll have to make sure that we design
the system we'll run the wires in such a
way that doesn't do any damage to the
vehicles what kind of things fail when
they fail the biggest issue we've had
with the system our camera cables
becoming unplugged so when a camera
cable becomes unplugged the system will
try to restart that subsystem multiple
times and if it's unable to it
completely shuts off recording and as
long as that cable is still unplugged
writer will not start up the next
so one issue that we've seen is that
cables becoming a plugged causes us to
lose the potential to record some data
and that was one of the requirements of
the system from the very beginning is
that all the video streams are always
recorded perfectly and synchronized now
if any of the systems are failing to be
recording from the sensors that we try
again restart the system restart the
system and if it's still not working it
should shut down so the video in order
to understand what drivers are doing
these systems the video is essential so
if one of the cameras is not working
that means the system that's not working
as a whole the other crucial component
of having a data collection system
that's taking the multiple streams is
that those streams have to be
synchronized perfectly synchronization
was the highest priority from the very
beginning of writers design we have a
real-time clock
onboard writer that allows us down to
two parts per million of accuracy and
time stamping this means over the course
of a one and a half hour drive our time
stamps issue to each of the different
subsystems may drift up to seven or so
milliseconds relatively this is
extremely small compared to most clocks
on computers today and once the data is
offloaded the very first thing we do is
make sure that the time stamping that
the data was time stamp correctly so
that we can synchronize it and the very
first thing is part of the data pipeline
would do is synchronize the data that
means using the time stamp that came
from the real-time clock that was
assigned to every single piece of sensor
data using that time stamp to align the
data together now for video that means
30 frames a second perfectly aligned
with other GPS signals and so on there
are some other sensors like I am you and
the can messages coming from the car
that come much more frequently than 30
Hertz 30 frames a second so we have a
different synchronization scheme there
but overall synchronization from the
very beginning of the design of the
hardware to the very end of the design
of the software pipeline is crucial
because we want to be able to analyze
what people are doing in these semi
autonomous vehicles how they're
interacting with the technology and that
means using data that comes from the
face camera the body camera the forward
view synchronized together with a GPS
that I'm you and all the messages coming
from the vehicle telemetry from camp the
video stream compression which is a very
much CPU or GPU intensive operations
performed onboard the camera there are
other CPU intensive operation performed
on Ryder like the sense of fusion for
IMU but for the most part there's
sufficient CPU cycles left for the
actual data collection to not have any
skips or drifts in the census stream
collection one of the questions we get
is how do we get the data from this box
to our computers then to the cluster
that's doing the compute so when we
receive a hard drive from one of these
Ryder boxes that we're swapping we
connect the hard drive locally to our
computers and then we do a remote copy
to a server that contains all of our
data we then check the data for
consistency and perform any fixes and
the raw data in preparation for a
synchronization operation so we're not
doing any remote offloading of data so
the data lives on Ryder until the
subjects the drivers the owners of the
car come back to us and offload the data
so we take the hard drive swap it out
and aweful the data from the hard drive
can you tell me this the journey that a
pixel takes on its way from the camera
to our cluster well first the camera
records the raw image data based on
these settings that we've configured
from the Ryder box and that raw image
data is compressed on the camera itself
into an h.264 come format and then
transmitted over the USB wire to the
single board computer on the Ryder box
then it's recorded on to the solid-state
drive in a video file where it will stay
until we do an offload in the course of
about six months for rnds subjects and
in one month for 50 subjects after that
it is connected to a local computer
synchronized within a remote server
and is then processed with initial
cleaning algorithms in order to remove
any corrupt data or to fix any subject
data in the configuration files for that
particular trip after the initial
cleaning is taken care of it is
synchronized at 30 frames per second and
can then be used for different detection
algorithms or manual annotation so the
important hard work behind the magic
that deep learning computer vision
unlocks is the synchronization the
cleaning of the messy data making sure
we get anything that's at all weird in
any way in the in the data out so that
at the end of the pipeline we have a
clean data set of multiple sensor
streams perfectly synchronized that we
can then use for both analysis and for
annotation so that we can improve the
neural network models used for the
various detection tasks so writers done
an amazing job over 30 vehicles of
collecting hundreds of thousands of
miles worth of data billions of video
frames so we're talking about an
incredible amount of data all compressed
with h.264 that's close to 300 terabytes
worth of data but of course you can
always improve so so what our next steps
one huge improvement for writer would be
transitioning to another single board
computer in particular a Jetson tx2
there's a lot more capability for added
sensors as well as much more compute
power and even the possibility for
developing some real-time systems with a
Jetson one of the critical things when
you're collecting huge amounts of data
and driving is you realize that most of
driving is quite boring nothing
interesting in terms of understanding
driver behavior or training computer
vision models for edge cases and so on
nothing interesting happens so one of
the future steps we're taking is based
on the thing we found in the data so far
we know which parts are interesting
which are not and so when a design on
board algorithms that are processing in
real time that video data
Herman is this the kind of data I want
to keep it this time and if not throw it
out that means we can collect more
efficiently just the bits that are
interesting for edge case neural network
model training or for understanding
human behavior now this is a totally
unknown open area because really we
don't understand what people do and send
me a time with vehicles when the car is
driving itself and the human is driving
itself so the initial stages of the
study were to keep all the data so we
can do the analysis to analyze the body
pose glance allocation activity
smartphone usage all the various Sun
decelerations autopilot usage where it's
used how it's used geographic weather
night so on but as we start to
understand where the fundamental
insights come from we can start to be
more and more selective about which
epochs of data we want to be collecting
now that requires real time processing
of the data and as Dan said that's where
the justin tx2 the power that the justin
takes to brings is becomes more and more
useful now all of this work is part of
the MIT autonomous vehicle technology
study we've collected over three hundred
twenty thousand miles so far and
collecting five hundred to a thousand
miles every day so we're always growing
adding new vehicles we're working at
adding a Tesla Model 3 a Cadillac ct-6
super cruise system and others one of
the driving principles behind our work
is that the kind of data collection we
need to design safe semi autonomous and
autonomous vehicles is that we need to
record not just the forward roadway or
any kind of sensor collection on the
external environment we need to have
rich sensor information about the
internal environment what the driver is
doing everything about their face the
glance all the cognitive load and body
pose everything about their activity we
truly believe that autonomy autonomous
vehicles require an understanding of how
human supervisors of those systems
behave how we can keep them attentive
keep their glance on the road keep them
as effective efficient supervisors of
those systems
you

----------

-----
--36--

-----
Date: 2018.03.20
Link: [# MIT AGI: Cognitive Architecture (Nate Derbinsky)](https://www.youtube.com/watch?v=bfO4EkoGh40)
Transcription:

Intro
so today we have nadir bin ski he's a professor at Northeastern University working on various aspects of
computational agents that exhibit human level intelligence please give Nate a warm welcome thanks a
lot and thanks for having me here so the title that was on the page was cognitive
modeling I'll kind of get there but I wanted to put it in context so the the bigger theme here is I want to talk
about what's called cognitive architecture and if you've never heard about that before that's great and I
wanted to contextualize that as how are we what how is that one approach to get us to AGI
Outline
and I say what my view of AGI is and put up a whole bunch of TV and movie
characters that I grew up with that inspire me that will lead us into what is this thing called cognitive
architecture it's a whole research field that crosses neuroscience psychology cognitive science and all the way into
AI so I'll try to give you kind of the historical big-picture view of it what some of the actual systems are out there
that might be of interest to you and then we'll kind of zoom in on one of them that I've done a good amount of work with called soar and what I'll try
to do is tell a story a research story of how we started with kind of a core
research question we look to how humans operate understood that phenomenon and
then took it and so really interesting results from it and so at the end if this field is of interest there's a few
pointers for you to go read more and and go experience more of cognitive architecture so just rough definition of
AGI given this in AGI class depending the direction that you're coming from it
might be kind of understanding intelligence or maybe developing intelligent systems they're operating at
the level of human level intelligence the the typical differences between this
and other sorts of maybe AI machine learning systems we want systems that are going to persist for a long period
of time we want them robust to different conditions we want them learning over time and here's the crux of it working
on different tasks and in a lot of cases tasks they didn't know we're coming ahead of time I got into this because I
clearly watched too much TV and too many movies and then I looked back at this
and I realized I think I'm covering 70's 80's 90's nots I guess it is and today
and so this is what I wanted out of AI and this is what I wanted to work with
and then there's the the reality that we have today
Expectations Meet (Current) Reality
so instead of so who's watched Knight Rider for instance I I don't think that
exists yet but but maybe we're getting there and in particular for fun during the
Amazon sale day I got myself an Alexa and I could just see myself at some point saying Alexa please might write me
an R sync script you know to sync my class and if you have an Alexa you
probably know the following phrase this this just always hurts me inside which is sorry I don't know that one which is
okay right that's a lot of people have no idea what I'm asking let alone how to do that so what I want Alexa to respond
with after that is do you have time to teach me and to provide some sort of
interface by which back and forth we can kind of talk through this that we aren't there yet to say the least but I'll talk
later about some work on a system called Rosie that's working in that direction
we're starting to see see some ideas about being able to teach systems out of work
Common Motivations
so folks who are in this field I think generally fall into these three
categories they're just curious they want to learn new things generate knowledge work on hard problems great I
think there are folks who are in kind of that middle cognitive modeling realm and
so I'll use this term a lot it's really understanding how humans think how
humans operate human intelligence at multiple levels and if you can do that one there's just knowledge in and of
itself of how we operate but there's a lot of really important applications that you can think of if we were able to
not only understand but predict how humans would respond react in various
tasks medicine is is an easy one there's some work in HCI or HR I I'll get to
later where if you can predict how humans would respond to a test you can iterate tightly and develop better
interfaces it's already being used in the realm of simulation and in defense
industries I happen to fall into the latter group which or the bottom group
which is systems development which is to say just the desire to build systems for various tasks that are working on tasks
that kind of current AI machine learning can't operate on and I think when you're
working at this level or on any system that nobody's really achieved before
what do you do you you kind of look to the examples that you have which in this case that we know of
it's just humans right irrespective of your motivation when you have kind of an
Motivations/Questions Dictate Approach
intent that you want to achieve in your research you kind of let that drive your approach and so I often show my AI
students this the touring test you might have heard of or variants of it that have come before
these were folks who are trying to create system that acted in a certain way that acted intelligently and the
kind of line that they drew the benchmark that they used was to say let's make systems that operate like
humans do cognitive modelers will fit up into this top point here to say it's not enough to
act that way but by some definition of thinking we want the system to do what
humans do or at least be able to make predictions about it so that might be things like what errors would the human
make on this task or how long would it take them to perform this task or what emotion would be produced in this task
there are folks who are still thinking about how the computer is operating but
it's trying to apply kind of rational rules to it so a logician for instance
would say if you have a and you have B the a gives you B B gives you see a
should definitely give you C that's just what's rational and so there folks operate in that direction and then if
you go to intro AI class anywhere in the country particularly Berkeley because
they have graphics designers that I get to steal from the benchmark would be what the system produces in terms of
action and the benchmark is some sort of optimal rational bound irrespective of
where you work in the space there's kind of a common output that arrives when you
research these areas which is you can learn individual bits and pieces and it
can be hard to bring them together to build a system that either predicts or acts on different tasks so this is part
of the transfer learning problem but it's also part of having distinct theories that are hard to combine
together so I'm going to give an example that come comes out of cognitive modeling or perhaps three examples so if
you were in a HCI class or some interest psychology classes one of the first things you'll learn about is Fitz law
which provides you the ability to predict the difficulty level of
basically a human pointing from where they start to a particular place and it turns out that you can
learn some parameters and model this based upon just the distance from where you are to the targets and the size of
the target so both moving along distance will take a while but also if you're aiming for a very small point that can
take longer then if there's a large area that you just kind of have to get yourself to and so this is held true for
many humans so let's say we've learned this and then we move on to the next task
and we learn about what's called the power law of practice which has been
shown true in a number of different tasks what I'm showing here is one of them where you're going to draw a line
through sequential set of circles here starting at 1 going to 2 and so forth not making a mistake or at least not
trying to and try to do this as fast as possible and so for a particular person
we would fit the a B and C parameters and we'd see a power law so as you perform this task more you're going to
see a decrease in the amount of reaction time required to complete the task great
we've learned two things about humans let's add some more in so for those who might have done some reinforcement
learning TV learning is one of those approaches temporal difference learning that's had some evidence of similar
sorts of processes in the dopamine centers of the brain and it basically says in a sequential learning tasks you
perform the task you get some sort of reward how are you going to kind of update your representation of what to do
in the future such as to maximize expectation of future reward and there are various models of how that changes
over time and you can build up functions that allow you to form better and better and better a given trial and error great
so we've learned three interesting models here that hold true over multiple
people multiple tasks and so my question is if we take these together and add
them together how do we start to understand a task as quote/unquote
simple as chess which is to say we could ask questions how how long would it take
for a person to play what mistakes would they make they played a few games how would they
adapt themselves or if we want to develop system that ended up being good
at chess or at least learning to become better at chess my question is if you could there
doesn't seem to be a clear way to take these very very individual theories and kind of smash them together and get a
reasonable answer of how to play chess or how do humans play chess and so
Unified Theories of Cognition
gentlemen in this slide is Alan Newell one of the founders of AI did incredible
work in psychology and other fields he gave a series of lectures at Harvard in 1987 and they were published in 1990
called the unified theories of cognition and his argument to the psychology community at that point was the argument
on the prior slide they had many individual studies many individual results and so the question was how do
you bring them together to gain this overall theory how do you make forward progress and so his proposal was unified
theories of cognition which became known as cognitive architecture which is to
say to bring together your core assumptions your core beliefs of what
are the fixed mechanisms and processes that intelligent agents would use across
tasks so the representations the learning mechanisms the memory systems
bring them together implement them in a theory and use that across tasks and the
core idea is that when you actually have to implement this and see how it's going to work across different tasks the
interconnections between these different processes and representations would add
constraint and over time the constraints would start limiting the design space of
what is necessary and what is possible in terms of building intelligent systems and so the overall goal from there was
to understand and exhibit human level intelligence using these cognitive architectures a'nature
Making (Scientific) Progress Lakatos 1970
question asked is okay so we've gone from a methodology of science that we
understand how to operate in we make a hypothesis we construct a study we
gather our data we evaluate that data and we falsify we do not falsify the original hypothesis and we can do that
over and over again and we know that we're making for progress scientifically if I've now taken that model and changed
it into I have a piece of software and it's representing my theories and to
some extent I can configure that software in different ways to work on different tasks how do I know that I'm making progress and so there's a form of
science called lactose ium and it's kind of shown pictorially here where you
start with your core of what your your beliefs are about where your head what
is necessary for achieving the goal that you have and around that you'll have kind of ephemeral hypotheses and
assumptions that over time may grow and shrink and so you're trying out different things trying out different things and if an assumption is around
there long enough it becomes part of that core and so as you work on more tasks can learn more
either by your work or by data coming in from with someone else the core is growing larger and larger
you've got more constraints and you've made more progress and so what I wanted to look at we're in this community what
are some of the core assumptions that are driving forward scientific progress so one of them actually came out of
Time Scales of Human Action Newell 1990
those lectures they're referred to as Newell's time scales of human action and so off on the left the left two columns
are both time units just expect somewhat differently second from the left being maybe more useful to a lot of us in
understanding daily life one step over from there would be kind of at what level processes are occurring so the
lowest three are down at kind of the substrate the neuronal level we're building up to deliberate tasks that
occur in the brain and tasks that are operating on the order of ten seconds some of these might occur in the
psychology laboratory but probably a step up to and ours and then above that really
becomes interactions between agents over time and so if we start with that the things to take away is that regular the
hypothesis is that regularities will occur at these different time scales and that they're useful and so those who
operate at that lowest time scale might be considering neuroscience cognitive neuroscience when you shift up to the
next couple levels what we would think about in terms of the areas of science that deal with that would be psychology
and cognitive science and then we shift up a level and we're talking about sociology and economics and the
interplay between agents over time and so what we'll find with cognitive
architecture is that most of them will tend to sit at the deliberate act we're trying to take knowledge of a situation
and make a single decision and then sequences of decisions over time will
build to tasks and tasks over time will build to more interesting phenomenon I'm actually going to show that that isn't
strictly true that there are folks working in this field that actually do operate one level below some other
Bounded Rationality Simon 1967
assumptions so this is herb Simon receiving the Nobel Prize in Economics
and part of what he received that award for was an idea of bounded rationality
so in various fields we tend to model humans as rational and his argument was
let's consider that human beings are operating under various kinds of
constraints and so to model the rational with respect to and bounded by how
complex the problem is that they're working on how big is that search space that they have to conquer cognitive
limitations so speed of operations amount of memory short-term as well as
long-term as well as other aspects of our computing infrastructure that are going to keep us from being able to
arbitrarily solve complex problems as well as how much time is available to
make that decision and so this is actually a phrase that came out of his speech when he received the Nobel Prize
decision-makers can satisfice either by finding optimum solutions for a simplified world just to
say take your big problem simplify in some way and then solve that or by
finding satisfactory solutions for a more realistic world take the world and all its complexity take the problem in
all its complexity and try to find something that works neither approach in general dominates the other and both
have continued to co-exist and so what you're actually going to see throughout the cognitive architecture community is
this understanding that some problems you're not going to be able to get an
optimal solution to if you consider for instance bounded amount of computation
bounded time the need to be reactive to a changing environment these sorts of issues and so in some sense we can
decompose problems that come up over and over again into simpler problems solve those newer optimally or optimally fix
those in optimize those but more general problems we might have to satisfy some
there's also the idea of the simple system hypothesis so this is Alan Newell
Physical Symbol System Hypothesis Newal & Simon 1976
and herb Simon they're considering how a computer could play the game of chess so
the physical system physical symbol system talks about the idea of taking something some signal abstractly
referred to as symbol combining them in some ways to form expressions and then
having operations that produce new expressions a weak interpretation of the
idea that symbol systems are necessary and sufficient for intelligent systems a
very weak way of talking about it is the claim that there's nothing unique about
the neuronal infrastructure that we have but if we got the software right we
could implement it in the bits bytes Ram and processor that make up modern computers that's kind of the weakest way
to look at this that we can do it with silicon and not carbon stronger way that
this used to be looked at was more of a logical standpoint which is to say if we
can encode rules of logic these tend to line up if we think intuitively of
planning and problem solving and if we can just get that right and get enough fat's in there and enough
in there that somehow intelligence well that's what we need for intelligence and eventually we can get to the point of
intelligence and that's what you need for intelligence and that was a starting
point that lasted for a while I think by now most folks in this field would agree
that that's necessary to be able to operate logically but that there are going to be representations and
processes that will benefit from non symbolic representation so particularly perceptual processing visual auditory
and processing things in a more kind of standard machine learning sort of way as
well as kind of statistic taking advantage of statistical representations
so we're getting closer to actually looking at cognitive architectures I did
Active Architectures by Focus
want to go back to the idea that different researchers are coming with different research foci foci and we'll
start off with kind of the lowest level and understanding biological modeling so Leiber and spawn both try to model
different degrees of low-level details parameters firing rates connectivities
between different kind of levels of neuronal representations they build that
up and then they tried to build tasks above that layer but always being very cautious about being true to human
biological processes at a layer above there would be psychological modeling
which is to say trying to build systems that are true in some sense to areas of
the brain interactions in the brain and being able to predict errors that we made timing that we produced by the
human mind and so there I'll talk a little bit about Akhtar this final level
down here these are systems that are focused mainly on producing functional
systems that exhibit really cool artifacts and and solve really cool
problems and so I'll spend most of the time talking about soar but I want to point out a relative newcomer in the
game called Sigma so to talk about spawn a little bit we'll see if the sound works in here I'm
going to let the Creator take this one
or not see how the AV system likes this
Semantic Pointer Architecture Unified Network
[Music]
but of course if I wouldn't be pleased with a pad of the microseconds and all celebrated since we're engineering is
critical goal engineering allows you to break down equation intense very precise descriptions which we can test like
building actual models one probably do recently is called the song model this Moscow has the two and a half million
individual mountains isolated and evens the model is a knife and the up the
canal is Bernard so essentially you can see images of numbers and that is something like a
progressive in the case of the discarded into that seat but magic tide reproduces style that
yeah so for instance it's easy to get the on environment and actually forgive separately and silently on
medical side we all know that we have cognitive town concession we get over and we can try that address accountant
spicy alienating process with these nice models another potential area in fact it's on artificial intelligence a lot of
working out visual Imperfects thanks to donations that are exceeded it at one pass pretty since plane test what's
special is fine is that it's like that many different paths and this X we have not found it might appear californee the
flow of information through different parts of the model something I haven't seen very well so provide a pointer at
the end he's got a really cool book called how to build a brain and if you google and you can google spun you can
find a toolkit where you can kind of construct circuits that will approximate
functions that you're interested in connect them together set certain properties that you would want at a low
level and build them up and actually work on tasks at the level of vision and
robotic actuation so that's a really cool system as we move into
Prototypical Architecture
architectures that are sitting above that biological level I wanted to give you kind of an overall sense of what
they're going to look like what a prototypical architecture is going to look like so they're gonna have some ability to have perception the
modalities typically are more digital symbolic but they will depending on the
architecture be able to handle vision audition and various sensory inputs
these will get represented in some sort of short-term memory whatever the state's representation for the
particular system is there it's typical to have a representation of the
knowledge of what tasks can be performed when they should be performed how they should be controlled and so these are
typically both actions that take place internally that manage the internal
state of the system and perform internal computations but also about external actuation and external might be
a digital system a game AI but it might also be some sort of robotic actuation in real world there's typically some
sort of mechanism by which to select from the available actions in a particular situation there's typically
some way to augment this procedural information which is to say learn about
new actions possibly modify existing ones there's typically some semblance of what's called declarative memory so
whereas procedural at least in humans if I asked you to describe how to ride a
bike you might be able to say get on the seats and pedal but in terms of keeping
your balance there you'd have a pretty hard time describing it declaratively so
that's kind of the procedural side the implicit representation of knowledge whereas declarative would include facts
geography math but it also include experiences that the agent has had a more episodic
representation of declarative memory and they'll typically have some way of learning this information on mending it
over time and then finally some way of taking actions in the world and they'll
all have some sort of cycle which is perception comes in knowledge that the
agent has is brought to bear on that an action is selected knowledge that knows
to condition on that action will act accordingly both with internal processes as well as eventually to take action and
then rinse and repeat so when we talk about in an AI system an agent in this
context that would be the fixed representation which is whatever architecture we're talking about plus
set of knowledge that is typically specific to the task but might be more
general so oftentimes these systems could incorporate a more general knowledge base of facts of linguistic
facts of Geographic facts let's take Wikipedia and let's just stick it in the brain of the system
there'll be more tasks in general but then also whatever it is that you're doing right now how should you proceed
in that and then it's typical to see this processing cycle and going back to
the prior assumption the idea is that these primitive cycles allow for the
agent to be reactive to its environment so if new things come in that has react to if the Lions sitting over there I
better run and maybe not do my calculus homework right so as long as this cycle
is going I'm reactive but at the same time if multiple actions are taken over time I'm able to get complex behavior
over the long term so this is the act our cognitive architecture it has many
of the kind of core pieces that I talked about before let's see if the mouse yes
mouse is useful up there so we have the procedural model here a short-term
memory is going to be these buffers that are on the outside the procedural memory is encoded as what I call production
rules or if-then rules if is this is the state of my short-term memory this is
what I think should happen as a result you have a selection of the appropriate
rule to fire and an execution you're seeing associated parts of the brain
being represented here cool thing that has been done over time in the act our community is to make predictions about
brain areas and then perform MRIs and gather that data and correlate that data
so when you use the system you will get predictions about things like timing of
operations errors that will occur probabilities that something is learned but you'll also get predictions about to
degree that they can kind of brain areas that are going to line light up and if
you want to that's actively being developed at Carnegie Mellon to the left
is John Anderson who developed this cognitive architecture ooh 30 ish years
ago and until the last about five years he was the primary researcher developer
behind it with Christian and then recently he's decided to spend more time on cognitive tutoring systems and so
Christian has become the primary developer there is an annual akhtar
workshop there's a summer school where if you're thinking about modeling a
particular task you can kind of bring your task to them bring your data they teach you how to use the system and try
to get that study going right there on the spot to give you a sense of what
ACT-R Notes
kinds of tasks this could be applied to so this is a representative of a certain
class of tasks certainly not the only one let's try this again
I think powerpoints going to want a restart every time okay so we're getting
predictions about basically where the eye is going to move what you're not seeing is it's actually processing
things like text and colors and making predictions about what to do and how to represent the information and how to
process the graph as a whole I had alluded to this earlier there's
work by Bonnie John very similar so making predictions about how humans
would use computer interfaces and at the time she got hired away by IBM and so
they wanted the ability to have software that you can put in front of software designers and when they think they have
a good interface press a button this model of human cognition would try to perform the tasks that have been told to
do and make predictions about how long it would take and so you can have this tight feedback loop from designers
saying here's how good your particular interfaces so act are as a whole it's
very prevalent in this community I went to their web page and counted up just the papers that they knew about it was
over 1,100 papers over time if you're interested in it the main distribution
is in Lisp but many people have used this and wanted to apply it to systems that need a little more processing power
so there's the NRL has a Java port of it that they use in robotics the Air Force
Research Lab and Dayton has implemented it in Erlang for a parallel processing
of large declare knowledge bases they're trying to do service-oriented architectures with it CUDA because they
want what it has to say they don't want to wait around for it to have to figure that stuff out
so that's the two minutes about Akhtar Sigma is a relative newcomer and it's
developed out at the University of Southern California by man named Paul rosenbloom mmm mentioned a couple
minutes because he was one of the prime developers of soar at Carnegie Mellon so he knows a lot about how store works and
he's worked on it over the years and I think originally I'm gonna speak for him and he'll probably say I was wrong I
think originally it was kind of a mental exercise of can i reproduce or using a
uniform substrate I'll talk about so in a little bit it's thirty years of research code if anybody is dealt with
research code it's thirty years of C and C++ with dozens of graduate students
over time it's not pretty at all and and theoretically it's got these boxes
sitting out here and so he reimplemented the the core functionality of soar all
using factor graphs and message passing algorithms under the hood he got to that
point and then said there's nothing stopping me from going further and so now it can do all sorts of modern
machine learning vision optimization sort of things that would take some time in any other architecture to be able to
integrate well so it's been an interesting experience it's now going to
be the basis for the virtual human project out at the Institute for Creative Technology it's Institute
associated with University of Southern California for him until recently could
get your hands on it but in the last couple years he's done some tutorials on it he's got a public release with
documentation so that's something interesting to keep an eye on but I'm
gonna spend all the remaining time on the Soraa cognitive architecture and so you see it looks quite a bit like the
prototypical architecture and I'll give a sense again about how this all operates give a sense of the people
involved we already talked about Alan Newell so both John Laird who is my advisor and Paul Rosenbloom were
students of Alan Newell John's thesis project was related to the chunking
mechanism and soar which learns new rules based upon sub-goal reasoning so
he finished that I believe the year I was born and so he's one of the few
researchers you'll find who's still actively working on their thesis project
beyond that's about I think about ten years ago he founded soar technology
which is company up in Ann Arbor Michigan while it's called solar technology it doesn't do exclusively soar but that's a part of the portfolio
general intelligence system stuff a lot of Defense Association so some notes of
Soar Notes
what's going to make soar different from the other other architectures that fall into this kind of functional
architecture category a big thing is a focus on efficiency so john wants to be
able to run soar on just about anything we just got on the soar mailing list a
desire to run it on a real-time processor and our answer while we had
never done it before was probably it'll work every release there's timing tests
and we always what we what we look at is in a bunch of different domains for a bunch of different reasons that relate
to human processing there's this magic number that comes out which is 50 milliseconds which is to say in terms of
responding to tasks if you're above that time humans will sense a delay and you
don't want that to happen now if we're working in a robotics task 50 milliseconds if you're dramatically
above that you just fell off the curb or worse or you just hit somebody in a car right so we're trying to keep that as
low as possible and for most agents it it doesn't even register it's below 1
millisecond fractions of millisecond but I'll come back to this because a lot of the work that I was doing was computer
science AI and a lot of efficient algorithms and data structures and 50 milliseconds was that very high upper
bound it's also one of the projects that has a public distribution you can get in all sorts of operating systems we use
something called swig that allows you to interface with it in a bunch of different languages we kind of describe the meta description and you are able to
basically generate bindings and different platforms Korres C++ there was
a team at sore tech that said we don't like C++ it gets messy so they actually did a port over to pure Java in case
that appeals to you there's an annual soar workshop that takes place in Ann
Arbor typically it's free you can go there get a sort tutorial and talk to
folks who are working on soar and it's fun I've been there every year but one in the last decade it's just fun to see
the people around the world that are using the system and all sorts of interesting ways to give you a sense of
the diversity of the applications one of the first was our one store which was back in the days when it was an actual
challenge to build a computer which is to say that your choice of certain components would have radical
implications for other parts of the computer so it wasn't just the Dell website where you just I want this much
RAM I want this much CPU there was a lot of thinking that went behind it and then physical labor that went to construct
your computer and so it was making that process a lot better there are folks that apply to natural language
processing I saw r7 was the core of the virtual humans project for a long time
HCI tasks terrasaur was one of the largest rule-based systems tens of thousands of rules over 48 hours
it was a very large-scale simulation a defense simulation lots of games it's
been applied to for various reasons and then in the last few years porting it on to mobile robotics
platforms this is Edwin Olsen's splinter bot an early version of it that went on
to win the magic competition then I went
on to put soar on the web and if after this talk you're really interested in a dice game that I'm going to talk about
you can actually go to the iOS App Store and download it's called Michigan liar's
dice it's free you don't have to pay for it but you can actually play a liar's dice with soar and it's even set the
difficulty level it's pretty good it beats me on a regular basis I wanted to
give you a couple other just kind of really weird feeling sort of applications and really cool applications the first one
Luminal ADAM Lab @ GATech
is out of Georgia Tech go PowerPoint is
dom-based interactive art installation in which she participants can engage and
collaborate the movement improvisation with each other and virtual advance permits this thing her actually creates
a hyperspace English virtual and quicker real bodies meet the line between human
and non-human is learned through images to examine a relationship with technology the night installation
ultimately examines how humans and machine can co-create experiences and it
ducks out in a playful environment the don't creates a social space that encourages human human interaction and
collective dance experiences allowing the depends to create an explorer movement while having fun the
development of lumini has been a hundred exploration in our forms of theatre and dance as well as research and artificial
intelligence and cognitive science lumahai draws inspiration from the
ancient art form of shot here the original two-dimensional version of the
installation led the conceptualization of the dome in the liminal space which
even silhouettes and virtual character is being danced together on the projection surface rather than relying
on a predominant library of movement responses the virtual dancer learns in
this part measurements and utilizes new points movement theory to systematically reason about them and working
improvisational shoes under the moon response the points theory is based in
dance and theater and analyzes the performance along the dimensions of tempo duration repetition kinesthetic
response shape spatial relationships gesture architecture and
Photography the virtual dancer is able to use several different strategies to
respond to human movements these include mimicry of a movement transformation of the movement along
viewpoints and mentions we're calling a similar or complementary movement from memory in terms of you fight revolutions
and define actually sponsor patterns of the agent has learned while dancing with its human partner the reason we did this
is this is part of a larger effort in our lab for understanding the relationship between compeition cognition and creativity
where a large amount of our efforts go into understanding human creativity and
how we make things together out were created together as a way that almost understand how we can build co-created
AI that serves the same purpose where to be a colleague and collaborate with us
and create things with us so Brian was a
graduate student in John leritz lab as well before I start this I lude
Rosie
into this earlier where we're getting closer to rosie saying can you teach me so let me give you some introduction to
this in the lower left you're seeing the view of a Kinect camera onto a flat
surface there's a robotic arm mainly 3d printed parts few servos above that
you're seeing an interpretation of the scene we're giving it kind of associations of the four areas with
semantic titles like one is the table one is the garbage just just semantic
terms for areas but other than that the agent doesn't actually know all that much and it's going to operate in two
modalities one is we'll call it natural language natural ich language restricted
subset of English as well as some quote unquote pointing so you're gonna see
some Mouse pointers in the upper left saying I'll talk about this and this is just a way to indicate location and so
starting off we're gonna say things like you know pick up the blue block and it's gonna be like I don't know what is what is blue we say oh well that's a
color okay you know so go get the green thing
what's green oh it's a color okay move the blue thing to a particular location where's that point it okay what is
moving like really it has to start from the beginning and it's described and it said okay now you've finished and once
we got to that point now I can say move the green thing over here and it's got everything that it needs to be able to
then reproduce the task given new parameters and it's learned that ability so let me give it a little bit of time
so you can look a little bit at top left in terms of the pointers you're going to see some text commands being entered so
what kind of attribute is blue we're gonna say it's a color and so that can map it then to a particular sensory
modality this is green so the pointing what kind of thing is green okay color
so now it knows how to understand blue and green as colors with respect to the visual scene move rectangle to the table
what is rectangle okay now I can map that on to or understanding parts of the
world is this the blue rectangle so the arm is actually pointing itself to get confirmation from the instructor and
then we're trying to understand in general when you say move something what is the goal of this operation and so
then it also has a declared representation of the idea of this task not only that it completed it then it
can look back on having completed the task and understand what were the steps that led to achieving a particular goal
so in order move it you're gonna have to pick it up it knows which one the blue thing is
great now
in the table so that's a particular location and at this point we can say
you're done you have accomplished the moved blue rectangle to the table and so
I can understand what that very simple kind of process is like and associate
that with the verb to move and now we can say move the green object or not do
the garbage and without any further interaction based upon everything that
learned up till that point it can successfully complete that task so this is work of chavala Mohan and others at
the shore group at the University of Michigan on the bruisy project and they're extending this to playing games
and learning the rules of games through text-based descriptions and multimodal experience so in order to build up to
here's a story and so I wanted to give you a sense of how research occurs in the group and so there's these back and
forth that occur over time between there's this piece of software called soar we want to make this thing better
and give it new capabilities and so all our agents are going to become better and we always have to keep in mind and
you'll see this as I go further that it has to be useful to a wide variety of agents it has to be task independent and
it has to be efficient for us to do anything in the architecture all of those have to hold true so we do
something cool in the architecture and then we say okay let's solve a cool problem so it's build some agents to do
this and so this ends up testing what are the limitations what are the issues that arise in a particular mechanism as
well as integration with others and we get to solve interesting problems we usually find there was something missing and then we can go back to the
architecture and rinse and repeat just to give you an idea again how sore works
Soar 9 [Laird 2012] Memory Integration
so the working memory is actually a directed connected graph the perception
is just a subset of that graph and so there's going to be symbolic representations of most of the world
there is a visual subsystem in which you can provide a scene graph just not showing it here actions are also a
subset of that graph and so the procedural knowledge which is also production rules can modify can
sections of the input modify sections of the output as well as arbitrary parts of the graph to take actions so the
decision procedure says of all the things that I know to do and I've kind of ranked them according to various preferences what single things should I
do semantic memory for facts there's episodic memory the agent is always
actually storing every experience it's ever had over time in episodic memory and it has the ability to get back to
that and so the similar cycle we saw before we get input in this perception called the input link rules are going to
fire all in parallel and say here's everything I know about the situation here's all the things I could do decision procedure says here's what
we're going to do based upon the selected operator all sorts of things
could happen with respect to memories providing input rules firing to perform
computations and as well as potentially output in the world and remember agent
reactivity is required we want the system to be able to react to things in
the world at a very quick pace so anything that happens in this cycle at max the overall cycle has to be under 50
milliseconds and so that's gonna be constraint we hold ourselves to and so the story I'll be telling will say how
we got to a point where we started actually forgetting things and we're an architecture that doesn't want to be
like humans we want to create cool systems but what we realized was something that we do there's probably
some benefit to it and we actually put it into our system in the lead to good outputs so here's the research path I'm
One Research Path
going to walk down we had just a simple problem which was we have these memory
systems and sometimes they're going to get a cue that could relate to multiple memories and the question is if you have
a fixed mechanism what should you return in a task independent way which one of
these many memories should you return that was our question and we looked to some human data on this something called
the rational analysis of memory done by John Anderson and realized that in human
language there are recency and frequency effects that maybe it would be useful
and so we actually did an analysis found that not only does this occur but it's useful in what
are called word sense disambiguation tasks I'll get to that what that means in a second develop some algorithms to
scale this really well and it turned out to worked out well not only in the original task when we learn look to two
other completely different ones the same underlying mechanism ended up producing some really interesting
outputs so let me talk about word sense disambiguation real quick this is a core problem in natural language processing
Problem ala Word-Sense Disambiguation
if you haven't heard of it before let's say we have an agent and for some reason it needs to understand the verb to run
looks to its memory and finds that it could you know run in the park it could
be running a fever could run an election it could run a program and the question is what should an task independent
memory mechanism return if all you've been given is the verb to run and so the
rational analysis of memory looks through multiple text corpora and what they found was if a particular word had
been used recently it's very likely to be reused again and if it hadn't been
used recently there's going to be this effect where the expression here the T is time since
the most recent use it's going to sum those with a exponential decay and so
what it looks like if time is going to the right activation hire as better as
you get these individual usages you get these little drops and then eventually drop down and so if we had just one
usage of a word the read would be what the decay would look like and so the
core problem here is if we're at a particular point and we want to select between kind of the blue thing or the red thing blue would have a higher
activation and so maybe that's useful this is how things are modeled with
human memory but is it useful in general for tasks and so we looked at common
WSD Evaluation Historical Memory Retrieval Blas
corpora used in word sense disambiguation and just said well if we just look at this corporate twice and we
just use answers prior answers you know I ask the question what is the sense of
this word I took a guess I got the right answer and I used that recency and frequency information in my task
independent memory would that be useful and somewhat of a surprise but somewhat maybe not of a
it actually performed really well across multiple corpora so we said okay this
seems like a reasonable mechanism let's look at implementing this efficiently in
Efficiency
the architecture and the problem was this term right here said for every
memory for every time step you're having to pay everything that doesn't sound
like a recipe for efficiency if you're talking about lots and lots of knowledge over long periods of time so we made use
of a nice approximation that petrol that come up with to approximate tale effect
so accesses that happen long long ago we could basically approximate their effect on the overall
sum so now we had a fixed set of values and what we basically said is since
these are always decreasing and all we care about is relative order let's just only recompute when someone gets a new
value so it's a guess it's a heuristic and approximation but we looked at how
this worked on the same set of corpora and in terms of query time if we made
these approximations well under our 50 millisecond the effect on task
performance was negligible in fact hunt a couple of these it got ever so slightly better terms of accuracy and
actually if we looked at the individual decisions that were being made making these sorts of approximations were
leading to up to 90 sorry at least 90 percent of the decisions being made were
identical to having done the true full calculation so I said this is great
and we implemented this and worked really well and then we started working on what seemed like completely unrelated
Related Problem: Memory Size
problems one was in mobile robotics we had a mobile robot I'll show picture of in a
little while roaming around the halls performing all sorts of tasks and what we're finding was if you have a system
that's remembering everything in your short-term memory and your short-term memory gets really really big I don't
know about you my short-term memory feels really really small I would love it to be big but if you make your memory
really big and you try to remember something you're not having to pull lots and lots and lots of information into your
short-term memory so the system was actually getting slower simply because it had a lot of short-term memory
representation of the overall map it was looking up so large working memory a
problem Liars dices game you play with dice we were doing in our L base system on this reinforcement learning and it
turned out it's a really really big value function we're having to store lots of data and we didn't know which
stuff we had to keep around to keep the performance up so we had a hypothesis
that forgetting was actually going to be a beneficial thing that maybe maybe the
problem we have with our memories that we really really dislike this forgetting thing maybe it's actually useful and so
we experimented with the following policy we said let's forget a memory if one we haven't really it's not predicted
to be useful by this base level activation we haven't used it recently we haven't used it frequently maybe it's not worth it
that and we felt confident that we could approximately reconstruct it if we
absolutely had to and if those two things held we could forget something so
it's this bait same basic algorithm but instead of the ranking them it's if we
set a threshold for base level activation finding when it is that a
memory is going to pass that threshold and try to forget based upon that in a way that's efficient that isn't going to
scale really really poorly so we were able to come up with an efficient way to
Efficient Implementation
implement this using an approximation
Approximation Quality
that ended up for most memories to be
exactly correct to the original I'm happy to go over details of this if anybody's interested later but end up
being a fairly close approximation one that as compared to an accurate
Prediction Complexity
completely accurate search for the value ended up being somewhere between 15 to
Prediction Computation
20 times faster and so when we looked at our mobile robot here oh sorry let me
Task #1: Mobile Robotics
get this back because our little robots actually going around it's the third floor of the computer science building at the University of
Michigan it's going around he's building a map and again the idea was this map is getting too big so here was the basic
idea as the robots going around it's going to need this map information about rooms the color there is describing kind
of the strength of the memory and as it gets farther and farther away and it hasn't used part of the map for planning
or other purposes basically make it 2 K away so that by the time it gets to the bottom it's forgotten about the top but
we had the belief that we could reconstruct portion that map if
necessary and so the hypothesis was this would take care of our speed problems and so what we looked at was here's our
Results: Decision Time
50 millisecond thresholds if we do no forgetting whatsoever bad things were happening over time so
just 3,600 seconds this isn't a very long time we're passing that threshold
this is dangerous for the robot if we implement a task specific basically cleanup rules which is really hard to
get right that basically solved the problem when we looked at our general forgetting mechanism that we're using in other
places at an appropriate level of decay we were actually doing better than hand-tuned rules so this was kind of a
surprise win for us the other task seems totally unrelated it's a dice game you
Task #2: Liar's Dice Michigan Liar's Dice
cover your dice you make bids about what are under other people's cups this is played in Pirates of the Caribbean when
they're on the boat in the second movie and bidding for lives of service honestly this is a game we love to play
in the University of Michigan lab and so we're like hmm could soar play this and so we built a system that could learn to
play this game rather well with reinforcement learning and so the basic idea was in a particular state of the
Reasoning -- Action Knowledge
game soar would have options of actions to perform it could construct estimates
of their associated value it would choose one of those and depending on the outcome something good happened you
might update that value and the big problem was that the size of the state space the number of possible states and
actions just is enormous and so memory was blowing up and so what we said
similar sort of hypothesis if we decay away these estimates that we could
Forgetting Action Knowledge
probably reconstructs and we haven't used it in a while our things going to get better and so if we don't forget it
all 40,000 games isn't a whole lot when it comes to reinforcement learning we were up at two gigs we wanted to put this on
an iPhone that wasn't going to work so well there had been prior work that had
used a similar approach they were down at four or five hundred Meg's the iPhones are not going to be happy
but it'll work so that gave us some hope and we implemented our system okay
we're somewhere in the middle we can fit on the iPhone a very good iPhone maybe an iPad the question was though one
efficiency yeah we we fit under our 50 milliseconds but - how does the system actually perform when you start
forgetting stuff can it learn to play well and so y-axis here you're seeing
Results: Competence
competency you play a thousand games how many do you win so the bottom here 500 that's you know flipping a coin whether
or not you're going to win if we do know forgetting whatsoever this is a pretty
good system the prior work while keeping the memory low is also suffering with
respect to how well it was playing the game and kind of cool was the system
that was basically more than having the memory requirement was still performing at the level of no forgetting whatsoever
so just to bring back why I went through this story was we had a problem we
looked to our example of human level AI which is humans themselves we took an idea it turned out to be
beneficial we found in efficient implementations and then found it was useful in other parts of the architecture and other tasks that didn't
seem to relate whatsoever but if you download soar right now you would gain access to all these mechanisms for
whatever task you want it to perform just to give some sense in the field of
Some CogArch Open Issues
cognitive architecture what some of the open issues are I think this is true in a lot of fields in AI but integration of
systems over time the goal was they wouldn't have all these theories and so
you could just kind of build over time particularly when folks are working on different architectures that becomes hard but also when you have very
different initial starting points that can still be an issue transfer learning is an issue we're building into the
space of multimodal representations which is to say not only abstract symbolic but also visual wouldn't it be
nice if we had auditory and other senses but building that into memories and processing is still an open question
there's folks working on metacognition which is to say the agent self assessing
its own State its own processing some work has been done in here but still a lot and I think the last one is a really
important question for anybody taking this kind of class which is what would happen if we did succeed if we did make
human-level AI and if you don't know that picture right there it's from a show that I recommend that
you watch that's by the BBC it's called humans and it's basically what if we were able to develop what are called
synths in the show think the robot that can clean up after your laundry and cook and all that good stuff interact with
you it looks and interacts as a human but is completely our servants and then
hilarity and complex issues ensue so I highly recommend if you haven't seen
that to go watch that I think these days there's a lot of attention play pay to
machine learning and particular deep learning methods as well it should they're doing absolutely amazing things and often the question is well you're
doing this and there's deep learning over there you know how do they compare
and I honestly don't feel that that's always a fruitful question because most
of the time they tend to be working on different problems if I'm trying to find
objects in the scene I'm gonna pull out tensorflow I'm really not going to pull outs or it doesn't make sense it's not
the right tool for the job they haven't been said there are times when they tend to work together really really well so
the Rosi system that you saw there there was some I believe neural networks being
used in the object recognition mechanisms for the vision system there's TD learning going
in terms of the dice game where we can pick and choose and use this stuff absolutely great because there are problems that are best solved by these
methods so why avoid it and then on the other side if you're trying to develop a
system where you you know in different situations know exactly what you want the system to do soar or other rule
based systems end up being the right tool for the right job so absolutely why not make it a piece of the overall system some recommended
readings and some venues I'd mentioned unified theories of cognition this is Harvard Press I believe the short
cognitive architecture was MIT press came out in 2012 I'll say I'm co-author and theoretically
would get proceeds but I've donated them all to the University of Michigan so I can just make this recommendation free
of ethical concerns personally it's an interesting book it brings together lots of history and lots of the new features
it's if you're really interested in soar it's an easy sell
I'd mentioned crystallize Smith's how to build a brain really cool read download the software go through toriel's it's
it's really great how can the human mind occur in the physical universe is one of
the court akhtar books so it talks through a lot of the psychological underpinnings and how the architecture
works it's a fascinating read one of the papers trying to remember what year 2008
this goes through a lot of different architectures in the field it's ten years old but it gives you a good kind
of broad sweep if you want something a little more recent this is last month's
issue of AI magazine completely dedicated to cognitive systems so it's a
good place to look for the sort of stuff in terms of academic venues triple AI often has cognitive systems track
there's a conference called aiccm international conference on cognitive modeling where you'll see kind of a span
from biologic all the way up to AI cognitive science or cogs AI they have a conference as well as a journal ACS has
a conference as well as an online journal advances in cognitive systems cognitive systems research is a journal
that has a lot of this good stuff there's AGI the conference Vica is biologically inspired cognitive
architectures and I had mentioned both there's a soar workshop and an act our workshop that go on annually so leave it
at this there's some contact information there and a lot of what I do these days actually involves kind of explainable
machine learning integrating that with cognitive systems as well as optimization and robotics that scales
really well and also integrates with cognitive systems so thank you if you
have a question please line up to one of these two microphones so what what are
the main heuristics that you're using in soar there can be heuristics at the task
level in the agent level or there's the heuristics that are built into the architecture to operate efficiently so
I'll give you a core example that comes into the architecture and it's a fun trick that if you're a programmer you
could use all the time which is only process changes which is to say one of
the cool things about soar is you can load it up with literally billions of rules and I say literally because we've
done it and we know that it can turnover still in under a millisecond and this happens because instead of most systems
which process all the rules we just say well anytime anything changes in the world that's what we're going to react
to and of course if you look at the biological world similar sorts of tricks are being used so that's one of the core
ones that actually permeates multiple of the mechanisms when it comes to individual tasks it really is task
specific what that is so for instance with the liar's dice game if you were to
go and download it when you're setting the level of difficulty of it what you're basically selecting is the subset
of heuristics that are being applied and it starts very simply with things like if I see lots of sixes then I'm likely
to believe a high number of sixes exist but if I don't they're probably not there at all so it's a start
but any Bayesian wouldn't really buy that argument so then you start tacking
on a little bit of probabilistic calculation and then it tacks on some history of prior actions of the agents
so it really just builds now the Rosi system one of the cool things they're
doing is game learning and specifically having the agent be able to accept by a
text like natural text heuristics about how to play the game even when it's not
sure what to do so you at one point you mentioned about like generating new rules yeah so I'm wondering like how do
you do that's so true and I'm the first thing that comes to my mind are local search methods okay so one thing is you
can actually implement heuristic search in rules in the system and that's actually how the robot navigates itself
so it does heuristic search but at the level of rules generating new rules the
chunking mechanism says the following if it's the case that in order to solve a
problem you had to kind of sub goal and do some other work and you figure out how to solve all that work and you've
got a result then and I'm greatly oversimplifying but if you ever were in the same situation again why don't I
just memorize the solution for that same situation so it basically learns over
all the sub processing that was done and encodes the situation I was in as conditions and the results that were
produced as action and that's the new rule all right thank you yeah hi so deep
learning and neural networks you know it looks as though there's a bit of an impedance mismatch between your system
and those types of system because you've got a fixed kind of memory architecture and they've got the memory and the rules
all kind of mixed together into one system but could you interface your system or a saw like system with deep
learning by playing in deep learning agents has rules in your system so you'd have to have some local memory but is
that is there some reason you can't plug in deep learning as a kind of a rule like module so I'm going to answer this
you work on it is that's the been any work on that oh it's yeah so I'll answer at multiple levels
one is you are writing a system and you want to use both of these things how do
you make them talk and there is an API that you can interface with any environment and any set of tools and if
deep learning is one of them great and if so or is the other one cool you have no problem and you can do that today and we have done this numerous times in
terms of integration into the architecture all we have to do is think
of a sub-problem in which all over simplify this but
basically function approximation is useful I'm seeing basically kind of the fixed structure of input I'm getting
feedback as to the output and I want to learn the mapping to that over time if you can make that case then you
integrate it as a part of the module great and we have learning mechanisms
that do some of that deep learning just hasn't been used to my knowledge to
solve any of those subproblems there's nothing keeping it from being one of those particularly when it comes down to
the low-level visual part of things a problem that arises so I'll say what
would actually make some of this difficult and it's a general problem called simple grounding so at the level
of what most have what happens mostly in store it is symbols being manipulated in the highly discrete way and so how do
you get yourself from pixels and low-level non symbolic representations to something that's stable and discrete
and can be manipulated and that is absolutely an open question in that
community and and that will make things hard so spawn actually has an
interesting answer to that and it has a distributive representation and it operates over distributed representations in what might feel like
a symbolic way so they're kind of ahead of us on that but they're they're starting from a lower point and so they
dealt with some of these issues and they have a pretty good answer to that and that's how they're moving up and that's also why I showed Sigma which is at its
low level it's message passing algorithms it's implementing things like slam and Sat solving and
other sorts of really really it can implement those on very low level primitives but higher up it can also be
doing what soar is doing so there's an answer there as well okay thank you so another way of doing it would be to layer the system so have one system
pre-processing the the the sensory input or post-processing their draft but the
other one that would be another way of combining two system and that's actually what's going on in the rosey system so the detection of objects in the scene is
a just just software that somebody wrote I don't believe it's a deep learning specifically but like the color
detection out of it I think is an SVM if I'm correct so easily could be deep
learning thanks you mentioned like the importance of forgetting in order for memory issues but you said
you could only forget because you could reconstruct and then curse how do you when you said we can start you need to know that it happened before so do you
just compress the data like do you really forget it order okay so and I put
quotes up and I said you think you can reconstruct it so we came up with
approximations of this and so let me try to answer this very grounded when it
comes to the mobile robot and you had rooms that you had been to before the
entire map in its entirety was being constructed in the robots semantic
memory so here's fats this room is connected this room which is connected this room which connected this room so we had those sorts of representations
that existed up in at semantic memory the rules can only operates down on anything that's in short-term memory so
basically we were removing things from the short-term memory and as necessary be able to reconstruct it from the
long-term you could end up in some situations in which you had made a change locally in short-term memory
didn't get a chance to get it up and it actually happened to be forgotten away so you weren't guaranteed but it was
good enough that the connectivity survived the agent was able to perform the exact same task and we gained some
benefit for the RL system the rule we came up with was the initial estimates
in the valley you system which is here's how good I think that is that's based on the heuristics I described earlier some
simple probabilistic calculations of counting some stuff that's where that number came from we computed before we could compute it again
the only time we can't reconstruct it completely is if it had seen a certain
number of updates over time it's such a large state space there are so many
actions so many states that most of the states were never being seen so most of
those could be exactly reproduced by the agent just thinking about it a little bit and there were only a tiny tiny I'm
gonna say under 1% of the estimate the value system that ever got updates and
that's actually not inconsistent with a lot of these kinds of problems that have really really large state spaces so I
think the statement was something like if we had ever updated it don't forget
it and you saw that was already reducing more than half of the memory load we
could have something higher to say 10 times something like that and that would say we could reconstruct almost all of
it the prior work that I referenced was strictly saying if it falls below
threshold no matter how many times in an update no matter how much information was there and so what we're adding was probably can reconstruct and that was
getting us the the balance between the efficiency and the ability to forget so
just under 7 you say we can probably we can show it means that you keep trying that you used to know it and so if you need to be constructed you will but it's
just you're gonna run it again in some times on the fly if I get back into that situation and I happen to forget it the
the system knew how to compute it the first time it goes and looks at all the hand and it just pretends it's in that
situation for the very very first time reconstructs that value estimate again
you're on that work question okay so the actual mechanism of forgetting is
fascinating so l STM's rnns have mechanisms for learning what to
forget and what not to forget have you has there been any exploration of
learning the forgetting process just doing something complicated or interesting with which parts to forget
or not the closest I will say was kind
of a metacognition project that's 10 or 15 years old at this point which was
what happens when soar gets into a place where it actually knows that it learned something that's harmful to it that's
that's leading to poor decisions and in that case it was still a very rule-based
process but it wasn't learning to forget he was actually learning to override its
prior knowledge which might be closer to some of what we do when we know we have a bad habit we don't have a way of
forgetting that habit but instead we can try to learn something on top of that that leads to better operation in the
future to my knowledge that's the only work at least in soar that's been done just sorry I find the topic really
fascinating what lessons do you think we can draw from the fact that forgetting
it's ultimately your the action of forgetting is driven by the fact you
want to improve performance but do you think forgetting is essential for AGI
the act of forgetting for building systems that operate in this world how
important is forgetting I can think of easy answers to that so one might be if
we take the cognitive modeling approach we know humans do forget and we know regularities of how humans forget and so
whether or not the system itself forgets it's at least has to model the fact that the humans that's interacting with are
going to forget and so at least it has to have that ability to model in order to interact effectively because if it
assumes we always remember everything and it can't operate well in that environment I think we're going to have
a problem is true forgetting going to be
necessary that's interesting our our AGI system is going to hold a grudge for all
eternity we might want them to forget this early age when we were forcing them to work in our laboratory I
think I know what you're trying to yeah exactly yeah exactly and how do we build such a
system yeah anyways go ahead so I have
two quick two quick questions and one is would you be able to speculate on how
you can connect function approximator such as deep networks you know to symbols and the second question
completely different this is regarding your action selection I know we didn't
speak much about that when you have different theories in your knowledge representation and you have an action
selection which has to make construct a plan by reasoning about the different
theories and the different pieces of knowledge that are now held within your
memory or anything like all your rules what kind of algorithms do you use in
the action selection to come up with the plan you know is there any concept of differentiation of the symbols or you
know or grammars or admissible grammars and things like that that you use in action selection I'm actually gonna
answer the second question first and then you're gonna have to probably remind me of what the first one was when
I get to the end so the action selection mechanism one of these core tenants I said is it's got to get through this
cycle fast so everything that's really really built in has to be really really simple and so the decision procedure is
actually really really simple it says the rules are gonna fire the rules are going the production rules are gonna
fire and there's gonna be a subset of them that will say something like here's an operator that you could select -
these are carlos acceptable operator preferences they're ones that going to say well based upon the fact that you said that that was acceptable I think
it's the best thing or the worst thing or I think 50/50 chance I'm going to get reward out of this there's actually a
fixed language of preferences that are being asserted and actually a nice fixed procedure by which if I have a set of
preferences to make a very quick and clean decision so what's basically
happened is you've pushed the hard questions of how to make complex decisions about actions up to a higher
level the low level architecture is always given a set of Jen's going to be able to make a
relatively quick decision and it gets pushed into the knowledge of the agent
to construct a sequence of decisions that over time is going to get to the
more interesting questions you're talking about but how can you reason that that sequence will take you to the goal that you desire so people is there
any guarantee on that is that in general across tasks no but people have for
instance implemented a star I was mentioning as wouls right yeah so I know given certain
properties about the search tack that task that's being searched based upon these rules given a finite search space
eventually it will get there and if I have a good heuristic in there I know certain properties about the optimality
so I can reason at that level in general I think this comes back to the assumption I made earlier about bounded
rationality to say parts of the architecture of solving subproblems optimally the general problems that it's
going to work on it's going to try its best based upon the knowledge that it has and that's about the end of
guarantees that you can typically make in the architecture okay I think your first question was speculate on
connecting symbol approach I mean function approximate is you know you know you know multiple layer function
approximate is like deep learning networks to two symbols that you can
reason about at a higher level yeah I think that's a great open space if I had
time this would be somebody I'll be working on right now which is somewhere before it basically said taking in a
scene and then detecting objects out of that scene and using those as symbols and reasoning about those over time I
think the spawn work is quite interesting so the symbols that they're
operating on are actually a distributed
representation of the input space and the closest I can get to this is if
you've seen a word Tyvek where you're taking a language corpus and what you're getting out of there is a vector number
that has certain properties but it's also a vector you can operate on as a unit so it has nice properties you can
operate with it on other vectors you know that if I got the same word in the
same context I would get back to that exact same vector so those are that's
the kind of representation that seems like it's going to be able to bridge that chasm where we can get from sensory
information to something that can be operated on and reasoned about in this sort of symbolic architecture and get us
from there from actual sensory information I had a question what do you
think are the biggest strengths of the cognitive architecture approach compared
to other approaches in artificial intelligence and the flip side of that what do you think are the biggest
shortcomings of cognitive architecture with respect to us with respect to you
being humans yeah a human level like like what needs to be like how come
cognitive architecture has not solved AGI because we want job security that's
the answer we've totally solved it already so strengths I think
conceptually is keeping an eye on the ball which is if what you're looking at
is trying to make human-level AI I it's
hard it's challenging it's ambitious to say that's the goal because for decades
we haven't done it it's extraordinarily hard it it is less difficult in some
ways to constrain it yourself down to a single problem that having been said I'm
not very good at making a car drive itself in some ways that's a simpler problem it's great at challenging it of
itself and it'll have great impact on humanity it's a great problem to work on human level AI is huge it's not even
well-defined as a problem and so
what's the strength here bravery stupidity in the face of failure
resilience over time keeping alive this idea of trying to reproduce a level of
human intelligence that's more general I don't know if that's a very satisfactory answer for you
downside home runs are fairly rare and
by home run I mean a system that finds its way to the the general populace to
the marketplace I'd mentioned Bonnie Johns specifically because you know this
is twenty thirty years of research and then she found a way that actually makes a whole lot of sense under direct
application so it was a lot of a lot of years of basic research a lot of researchers and then there was there was
the big win there what was this one oh this was a bunny John was a researcher
this was using akhtar models of I gaze and reaction and so forth to be able to
make predictions about how humans would use user interfaces so those sorts of
outcomes are rare it it if you work in AI one of the first things you learn
about is blocks world it's kind of in the classic AI textbook I will tell you
I've worked on that problem at about three different variants I've gone to many conferences where presentations
have been made about blocks world which is to say we're good progress is being made but the way you end up thinking
about is it really really small constrained problems ironically you you have this big vision but in order to
make progress that ends up being on moving blocks on a table and so it's
it's a big challenge I just think it'll take a lot of time the I'll say the
other thing they haven't we haven't really gotten to although I brought up spawn and I brought up Sigma
an idea of how to scale this thing something I like about deep learning is
just some extent with lots of asterisks and 10,000 foot view it's kind of like well we've gotten this far all right
let's just provided different inputs different outputs and we'll have some tricks on the middle and suddenly you have you know end to end deep learning
of a bigger problem and a bigger problem there's a way to see how this expands given enough data given enough computing
and incremental advances when it comes to soar it takes not only a big idea but
it takes a lot of software engineering to integrate it there's a lot of constraints built into it it slows it
down so something like Sigma is oh well I can change a little bit of the
configuration of the graph I can use variants on the algorithm boom it's integrated I can experiment fairly
quickly so starting with that sort of infrastructure does not give you the
constraint you kind of want with your big picture vision of going towards human level AI but in terms of being
able to be agile in your research it's it's kind of incredible Izzie thank you you'd mention that ideas such
as base level decay at these techniques they were based their original inspirations were based off of human
cognition and and because humans can't remember everything so were there any instances of the other way around where
some discovery in cognitive modeling fueled it another discovery in cognitive
science so what one thing I'm gonna
point out and your question was based on the decay with respect to human cognition the study actually was let's
look at text and properties of text and use that to then make predictions about
what must be true about human cognition so John Anderson and the other
researchers looked at believe it was New York Times articles
his Oh John Anderson's emails and I'm trying to remember what the third I
think it was parents utterances with their kids or something like this it was
actually looking at text corpora and the words that were occurring in at varying
frequencies that that analysis that rational analysis actually led to models
that got integrated within the act arc architecture that then became validated
through multiple trials that then became validated with respect to MRI scans and is now being used to both do study back
with humans but also develop systems that interact well with humans so I
think that in and of itself ends up being an example it's a cheat but the
UAV the soar UAV system I believe is a single robot that has multi multiple
agents running on it so where is this I
got it off your website ok but either way your systems allow for multi agents
ok so my question is how are you preventing them from converging with new
data and are you changing what they're forgetting selectively as one of those
ways so I'll say yes you can have multi agent source systems on a single system
on multiple systems there's not any real strong theory that relates to
multi-agent systems so there's no real constraint there that you can come up with a protocol for them interacting
each one is going to have its own set of memories set of knowledge there really
is no constraint on you being able to communicate like you would if it were any other system interacting with soar
so I don't really think I have a great answer for it so that is to say if you
had goo Theory's good algorithms about how multi-agent systems work and how they
can bring knowledge together form a fusion sort of way it might be something
that you could bring to a multi agent source system but there's nothing really there to help you there's no mechanisms
there really to help you do that any better than you would otherwise and you would have to kind of constraints of
your representations the process as to what it has fixed in terms of its sort of memory and its sort of processing cycle thank you


----------

-----
--35--

-----
Date: 2018.03.14
Link: [# Sterling Anderson, Co-Founder, Aurora - MIT Self-Driving Cars](https://www.youtube.com/watch?v=HKBhP9JISF0)
Transcription:

today we have sterling Anderson he's the co-founder of Aurora an exciting new
self-driving car company previously he was the head of the Tesla auto pilot team that brought both the first the
second generation auto pilot to life before that he did his PhD at MIT
working on shared human machine control of ground vehicles the very thing I've
been harping on over and over in this class and now he's back at MIT to talk
with us please give him a warm welcome [Applause]
thank you it's good to be here I was telling Lex just before I think it's been a little while since I've been back
after the Institute and it's great to be here I want to apologize in advance I've just landed this afternoon from Korea
via Germany where I've been spending the last week and so I may speak a little
slower than normal please bear with me if I become incoherent or slurred my speech
somebody flag at 2:00 and Lola will try to make corrections so tonight I thought I'd chat with you a little bit about my
journey over the last decade it's been just over ten years since I was at MIT a lot has changed a lot has changed for
the better in the self-driving community and I've been privileged to be a part of
many of those changes and so I wanted to talk with you a little bit about some of the things that I've learned some of the things that I've experienced and then
maybe end by talking about sort of where we go from here and and what the next
steps are both for you know the industry at large but also for the company that we're building that as Lex mention is
called Aurora to start out with and there are a few sort of key phases or
transitions in my journey over the last 10 years as Lex mentioned when I started
MIT I worked with Carly on Yemma Amelio Fazoli's John Leonard a few others on
some of these sort of shared adaptive automation approaches I'll talk a little
bit about those from there I spent some time at Tesla where I first led the Model X program as
we both finish the development and ultimately launched I took over the autopilot program where we introduced a
number of new both active safety but also sort of you know enhanced
convenience features from auto steer to adaptive cruise control that were able refine in a few unique ways and we'll
talk a little bit about that and then from there in December of last year of 2016 I guess now we started a new
company called Aurora and I'll tell you a little bit about that so to start out with when I KN OIT was 2007 the DARPA
urban challenge is were well underway at that stage and one of the things that we wanted to do is find a way to address
some of these safety issues in human driving earlier than potentially full
self-driving Qadeer and so we developed what became known as the intelligent co-pilot what you see here is a
simulation of that operating I'll tell you a little bit more about that in just a second but to explain a little bit
about the the methodology the innovation the key approach that we took that was
slightly different from what in traditional planning control theory we were doing was instead of designing in
path space for the robot we instead found a way to identify plan optimize
and design a controller subject to a set of constraints rather than paths and so
what we were doing is looking for Hama top Eastern environment so imagine for a moment an environment that's pockmarked
by objects by their vehicles by pedestrians etc if you were to create
the Voronoi diagram through that environment you would have a set of each unique set of paths or Hama top is
continuously deformable paths that will take you from one one location to another through it
if you then turn that into its dual which is the de'longhi triangulation of set environment presuming that you've
got convex obstacles you can then tile those together rather trivially to create a set of homotopy sand
transitions across which those paths can can stake out sort of a given set of
options for the human eye turns out humans tend to this tends to be a more intuitive way of imposing certain
constraints on human operation rather than enforcing that the ego vehicle
stick to some arbitrary position within you know some distance of a safe path you instead look to enforce only that
the that the state of the vehicle remain within a constraint bounded and dimensional tube in state space those
constraints being spatial imagine for a moment edges of the roadway or you know circumventing various objects in the
roadway imagine them also being dynamic right so limits of tire tire friction
imposed limits on side slip angles and so using that what we did is found a way
to create those Hammurabi's forwards simulate the trajectory of the vehicle given its current state and some optimal
set of controls inputs that would optimize its stability through that we use model creative control in that work
and then taking that forward simulated trajectory computing some metric of
threat for instance if the objective function for that minimize the or
maximize stability or minimize some some of these parameters like wheel side slip then wheel side slip is a fairly good
indication of how threatening that optimal maneuver is becoming and so what
we did is then use that in a modulation of control between the human and the car such that should the car ever find
itself in a state where that forward simulated optimal trajectory is very near the limits of what the vehicle and
it can actually handle we will have transition control fully to the to the vehicle to the automated system so that
it can avoid an accident and then it transitions back in some manner and we played with a number of different methods of transitioning this
control to ensure that that we didn't throw off the human mental model which
was which was one of the key concerns we also wanted to make sure that we were able to arrest accidents before they
happen what you see here is a simulation that was fairly faithful to the behavior
we saw in test drivers up at Dearborn in Dearborn Michigan Ford provided was provided us with a Jaguar s-type to test
this on and what we did so what you see here is there's a blue vehicle in the gray vehicle both in both cases we have
a poorly tuned driver model in this case if your pursuit controller with a fairly short look ahead shorter than would be
appropriate given this scenario in these dynamics the grey vehicle is without the
intelligent copilot in the loop you'll notice that obviously the driver becomes unstable loses control and
leaves the safe roadway the co-pilot remember is in is interested not in
following any given path it doesn't care where the vehicle lands on this road why
provided it remains inside the road in the blue vehicles case it's the exact
same human driver model now with the copilot in the loop you'll notice that as as this scenario continues what you
see here on the left is the green is in this green bar is the portion of available control authorities being
taken by the automated system you'll notice that it never exceeds half of the available control which is to say that
the steering inputs received by the vehicle end up being a blend of what the human and what the automation are
providing and what what results is a path for the blue vehicle that actually
better tracks the humans intended trajectory then even the copilot
understood right again the copilot is keeping the vehicle stable it's keeping it on the road the human is healing to
the centerline of that roadway so there was some very interesting things that came out of this there were a lot of we
did a lot of work in understanding what kind of feedback was most natural to provide to
a human our biggest concern was if you throw off a human's mental model by causing the vehicles at behaviors to
deviate from what they expect it to do in response to British control inputs that could be a problem so we tried
various things from you know adjusting for instance one of the one of the key questions that we had early on was if we
couple the computer control and the human control via planetary gear and
allow the human to feel a actually a backwards torque to what the vehicle is
doing so the car starts to turn right human will feel the wheel turn left they'll see it start to turn left
is that more confusing or less confusing they're human and it turns out it depends on how experienced a human is
some some drivers will modulate their input space on the torque feedback that they feel through the wheel and it for
instance a very experienced driver expects to feel the wheel pull left when they're turning right however less
experienced drivers in response to seeing the wheel turning opposite to what the what the car supposed to be
doing this for a rather confusing experience so there were a lot of really interesting human interface challenges
that we were dealing with here we ended up working through a lot of that
developing a number of sort of micro
applications for it one of those at the time Gill Pratt was leading a DARPA program focused on what they call the
time maximal mobility manipulation we decided to see what this system could do
in application to unmanned ground vehicles so in this case what you see is a human driver sitting at a remote
console as one would when operating an unmanned vehicle for instance in the
military what you see on the left top left is the top-down view of what the
vehicle sees I should have played this in repeat mode with bounding boxes
bounding various cones and what we did is we set up about 20 drivers 2020 test
subjects looking at this this troll screen and operating the vehicle
through this track and we set this up as a race with prizes for the winners as
one would expect and penalize them for every barrel they hit if they knocked
over the barrel I think they got a five-second penalty if they brushed a barrel they got a one-second penalty and they were to cross they work across the
field as fast as possible they couldn't they had no line-of-sight connection the vehicle and we played with some things on their interface we did you know we
caused it to drop out occasionally we delayed it as one would realistically expect in the field and then we either
engaged or didn't engage the copilot to try to understand what effect that had
on their performance and their experience and what we found was not surprisingly the incidence of collisions
declined it climbed by about 72% when the copilot was engaged versus when it was not we also found that you know even
with that seventy-two percent decline in collisions the speed increased by I'm blanking on the the amount but it was
you know 20 to 30 percentage finally in perhaps the most interesting to me after
every run I would ask the driver and again these were blind tests they didn't know if the copilot was active or not
and I would ask them how much control did you feel like you had over the vehicle and I found that there was a
statistically significant increase of about 12% when the copilot was engaged in that is to say drivers reported
feeling more control of the vehicle 12% more of the time when the copilot was engaged and when it wasn't and then
noticed the statistics it turns out they actually at the average level of control the the copilot was taking was 43% so
they were reporting that they felt more in control when in fact there were 43 percent less in control which was which
was interesting and I think a bears a little bit on sort of the human psyche
in terms of you know they were reporting the vehicle was doing what I wanted to do maybe not what I told it to do which
was which was kind of fun observation and and fun too I think I think the most
enjoyable part of this was getting together with the with the whole group at the end of the study and presenting
some of this and seeing some of the reaction so from there you know we looked at a
few other areas my Carl um and I looked
at a few different opportunities to commercialize this again this was years ago and the industry was in a very
different place than it is today we started a company first called gimlet then another called ride this is the
logo it may look familiar to you we turned that into we at the time it
intended to roll this out across various
automakers in their operations at the time very few saw self-driving as a
technology was really gonna impact their business going forward they were in fact
even even ride-sharing at the time was a fairly new concept that was I think to a
large degree viewed as unproven so as I mentioned December of last year i
co-founded aurora with a couple of folks who have been making significant
progress in this space for many years at Chris Urmson who formerly led Google's self-driving car group at drew back now
as a professor at Carnegie Mellon University exceptional machine learning in apply machine learning was one of the
founding members of Ober self-driving car team and led autonomy and perception there we felt like we had a unique
opportunity at the convergence of a few things one the automotive world has
really come into the full-on realization that self-driving and particularly self-driving and ride-sharing and
vehicle electrification are three vectors that will change the industry that was something that didn't exist ten
years ago two significant advances have been made in you know some of these
machine learning techniques in particular deep learning and other neural network network approaches in the
computers that run them and the availability of you know low-power GPU
and TPU options to really do that well in sensing technologies
in high-resolution radar and a lot of the light our development so it's really a unique time in the self-driving world
a lot of these things are really coming together now and we felt like by bringing together an experienced team we
had an interesting opportunity to build from a clean sheet a new platform a new
self-driving architecture that leverage the latest advances in most Reichman fly machine learning together with our
together with our experience of where some of the pitfalls tend to be down the road as you develop these systems
because you don't tend to see them early on they tend to express themselves as you get into the long tail of corner cases that you end up needing to resolve
so we've built that team we have offices in Palo Alto California and Pittsburgh
Pennsylvania we've got fleets of vehicles operating in both pallet on Pennsylvania a couple
of weeks ago we announced that Volkswagen Group one of the largest automakers in the world
Ondine Motor Company also one of the largest automakers in the world have both partnered with Aurora we will be
developing and are developing with them a set of platforms and ultimately will will scale that our technology on their
vehicles across the world and one of the important the important elements of building Lexus is Lex before coming out
here what this group would be most interested in hearing one of the things that he mentioned was what does it take to build a self-driving you know build a
new company in a space like this one of the things that we found very important was a business model that was
non-threatening to others we recognized that our strengths and our experience
over the last in my case a decade in Chris's case almost two really lies in
the development of the self-driving systems not in building vehicles that I
have had some experience there but but in developing the self-driving so our our feeling was if our mission is to get
a technology to market as quickly as broadly as safely as possible that mission is best served by playing our
position and working well with others who can play theirs which is why you see
the model that we've adopted and is now you'll start to see some of the fruits of that it through the partnerships with some of these
automakers so the end of the day our aspiration in our hope is that this
technology that that is so important the world in increasing safety in improving
access to transportation in improving efficiency in the utilization of our roadways in our cities I mean I this is
maybe the first stock I've ever given where I didn't start by rattling off statistics about safety and all the these other things if you haven't heard
them yet you should look them up there they're stark right the fact that most vehicles
in the United States today have an average on average three parking space
as space is allocated to them the amount of land that's taken up across the world
in housing vehicles that are used less than 5% of the time the number of people
I think in the United States the estimate has spent somewhere between 6 and 15 million people don't have access
to the transportation they need either the because they're elderly or disabled or you know one of many other factors
and so this technology is potentially one of the most impactful for our
society in the coming years it's a tremendously exciting technological challenge and you know the confluence of
those two things I think is a really unique opportunity for engineers and others who are not engineers who really
want to get involved to play a role in changing our changing our world going forward so with that maybe I'll maybe
I'll stop with this and we can go to go to questions
I am Wayne - hello thanks for coming um
I'm a question a lot of self-driving car companies are making extensive use of
lidar but you don't see a lot of that with Tesla wanted to know if you had any thoughts about that yeah I don't want to
talk about Tesla too much in terms of our specific any anything that wasn't public information I'm not going to get
into you I will say that for Aurora we believe that the right approach is
getting the market quickly and you get to market and doing so safely and you get to market most quickly and safely if
you leverage multiple modalities including layer these are the just to clarify what's running the
background these are all just aurora videos of our cars driving on various
test routes yeah hi I'm Luke ramzan from the stone school a lot of so a lot of customers have visceral type connections
to their automobile I was wondering how you see that market the car enthusiast market being affected by AVS and then
vice versa how the how the AVS will be designed around those type of oh yeah customers yeah it's a good question
thanks for asking but I am one of those enthusiasts I very much appreciate being
able to drive a car in certain settings I very much don't appreciate driving in
others right I remember distinctly several evenings I almost literally
pounding my steering wheel sitting in Quogue in in Boston traffic you know on
my way to somewhere I do the same in San Francisco I think the opportunity really
is to turn that it turned sort of personal vehicle ownership and driving into more of a sport and something you
do for leisure I see it a gentleman
some time ago asked me to talk hey don't you think this is a problem for the
country I think you meant the world if people don't learn how to drive that's just something a human should know how
to do my perspective is it's as much of a problem as people not intrinsically
knowing how to ride a horse today if you want to know how to ride a horse go ride a horse if you want to you want to race
a car go to a racetrack or go out to you know a mountain road that's been allocated for it ultimately I think I
think there is an important place for that because I certainly agree with you I'm very much a vehicle enthusiast
myself but I think there is so much opportunity here in alleviating some of
these other problems particularly in places where it's not fun to drive that I think there's a place for both yeah
yeah yeah congratulations on the partnership that was announced recently I think so I have
a two-part question the first one is so we heard last week from I think there
was a gentleman from talking about how long they have been working on this autonomous car technology and you simply
have rammed up extremely fast so is there a licensing model that you have
taken that I mean how are you able to commercialize the technology in one year
so just to be clear we're not actually commercializing we're just to
distinguish we are partnering and developing vehicles and Walter may be running pilots as we announced you know
we could to ago with the Moya shuttles we are however I will distinguish that
from broad commercialization of the technology and I don't want to get too much into you know the nuances of that
business model I will say that it is is one that's done in very close partnership with our automotive partners
because you know they at the end of the day they understand their cars they understand their customers they have
distribution networks they are you know our automotive partners are fairly well
positioned it provided they have the right support in developing a self-driving technology the fairly
fairly well positioned to you know roll it out of the scale so the second part
of my question is again looking at this you know pace of adoption and the maturity of technology do you see like
an open source model for autonomous you know cars as they become more and more
unclear I am not convinced that an open source model is what gets to market most
quickly in the long run it's not clear
to me what will happen I think there will be a handful of successful self-driving stacks that will make it
nowhere near the number of self-driving companies today but a handful I think
two questions one is in invariably a new product development there's typically
two types of bottlenecks there's a technological bottleneck and an economic bottleneck right so technological
bottleneck might be a you know the sensors aren't good enough or the machine learning algorithms aren't good
enough and so on I'd be interested to hear and it'll shift obviously over time so I'd be interested to know what you
would say is the current thing that if hey yeah if this part of the of the architecture was ten times better we
would and that on the economic side I'd be interested to know you know gee if if sensors were 100 times cheaper then so
it'd be interested to hear your perspective on that's a great question let me start with the economic side of
it and just to get that at the wake is a little bit quicker answer the economics
of operating a self-driving vehicle and a shared network today would close that
that business case closes even with high costs of sensors that is not that is not what's stopping us and that's part of
why the the gentleman earlier who asked you know should use lighter or not if
your target is to initially deploy these in fleets you would be wise to start at
the top end of the market develop and deploy a system that's as capable as possible as quickly as possible and then
costs it down over time and you can do that as computer vision and precision recall increase today they're not good
enough right and so so economically depending on your model of going to
market and we believe that the right model is through
mobility services you can cost out your
cost down the center inevitably you know there's no unobtainium in light our units today there's no reason fundamentally that he
should conserve a light our unit will lead you to a seventy thousand dollar price point right however if you build
anything in low enough volumes is going to be expensive many of these things will work their way into the standard automotive process
they'll work their way into Tier one suppliers and when they do the automotive community has shown
themselves to be exceptional at driving those costs down and so I expect them to come way down to your other question
technological bottlenecks and challenges one of the key challenges of self-driving rima is and remains that of
forecasting the intent and B and future behaviors of other actors both in
response to one another but also in response to your own decisions in motion that's a perception problem but it's
something more than a perception problem it's also a you know prediction and you
know there there are a number of different things that come together to have that have to come together to solve
this we're excited about some of the tools that we're using and interleaving various of modern machine learning
techniques throughout the system to do things like project our own behaviors
that were learned for the ego vehicle on others and assume that they'll behave as we would had we been in that situation
like an expert system kind of approach yeah yeah you you assume nominal
behavior and you guard against off nominal right but it's it's very much it's not a solved problem I wouldn't say
it's it's very much as you get into that really long tail of development when
you're no longer you know putting out demonstration videos but you're instead just putting your head down and eking
out those you know fine on lines that's the kind of problem you tend to deal with again so this question isn't
necessarily about the development of self-driving cars but more like an ethics question when you're putting
human lives into like the hands of software isn't there always the possibility for like outside agents with malicious
intent to use it for their own gain and how do you guys if you do have a plan
how do you intend to protect against yeah so security is a very real
aspect so we saw it's a constant game of cat
and mouse and so I think it just requires a very good you know team and a concerted effort
over time I I don't think I don't think you solve at once and I certainly
wouldn't pretend to have a plan that solves it and is done with it we're we
we try to leverage best practices where we can in the fundamental architecture of the system to make it less exposed
and in particular key parts of the system was exposed to nefarious actions of others but at the end of the day it's
just a constant is a constant development effort thank you for being
here so I had a question about what opportunities self-driving cars open up since driving has kind of been designed
around like a human being at the center since the beginning if you put a computer at the center what you know
society-wide differences and maybe even like within individual car differences that open up like you know could cars go
150 miles an hour on the highway and get places much faster what cars be like like look differently when a human
doesn't need to be paying attention and stuff like that yeah I think the answer is yes the and that's that something is
very exciting right so one of the I think one of the unique opportunities that automakers in particular have when
self-driving technology gets incorporated into their vehicles is they can do things like play like differentiate the user experience they
can provide services you know augmented reality services or
you know location services many other sort of it opens a new window into an
entirely new market that automakers haven't historically played in and it
allows them to change the the very vehicles themselves as you've mentioned
the interior can change as we validate
some of these self-driving systems and confirm that they do in fact reduce the collision the the rate of collisions is
we hope they will you can start to pull out a lot of the extra you know mass and
other things that we've added to vehicles to make them more passively safe right roll cages crumple zones airbags you
know a lot of these things you know presumably in a world where we don't
crash there is there is much less need for passive safety systems so yes I have
a question about the go no-go tests that you conduct for certain features like you mentioned the throttle control where
you slow down the throttle assuming that the driver has pressed the wrong wrong pedal when you test when you decide to
launch that feature how do you know it's definitely going to work in all scenarios because your data set might not be oh it's a it's a it's a
statistical evaluation every case right you're right there you will this is this
is part of the art of self-driving vehicle development is you will never have comprehensively captured every case
every scenario that is as my some of you
may want to correct me on this I think that's an unbounded set it may in fact be bounded at some point but I think
it's on and so you'll never you know there actually have characterized everything what you will have done
hopefully if you do it right is you will have established with a reasonable
degree of confidence that you can perform at a level of safety that's better than the average human driver and once you've reached that threshold and
you're confident that you've reached that threshold I think it the opportunity to launch is is real and you
should seriously consider it so thank you for your talk today first and my
question is self-driving seems to be able to ultimately take over the world to some extent but just like other
technologists today they open up new opportunities but also bring in adverse effects so how do you respond to fear
and nected effects that may come in one day and especially what do you see as the positive and active implications of
future day self-driving positive and negative implications
so the positive ones like kind of listed and you'll find your favorite press
article and they'll list them as well the negative ones in the near term I do
I do worry a little bit about the displacement of jobs not a little bit
this will happen it happens with every technology like this I think it's
incumbent on us to find a good way of transitioning those who are employed in
some of the transportation sectors that will be affected into better work right
there are a few opportunities that are interesting in that regard but I think
it's an important thing to start discussing now because it's gonna take you know a few years and you know by the
time we got these self-driving systems on the roads really starting to place that labor I'd really like to have a new
home for it now I I'm kasha from the Sloan School my question was more about
your business model again with partnering with both VW and he and a and
you're just perspective and how you were able to effectively do that did not one of them want to go sort of
exclusive with you and what was your sort of thought process about that yeah so our our mission as I mentioned used
to get the technology to market broadly and quickly and safely we are you know
have been and remain convinced that the right way to do that is by providing it to as much the industry as possible
to every automaker who shares our vision in our approach and we were pleased to see that both Volkswagen Group and I'm
assuming you all know the scope of Volkswagen right this is a massive automaker Hyundai Motor also very large
across Hyundai Kia and Genesis they both shared our vision of how we should do
this which was important to us they both shared you know a a keen interest in
making a difference at scale through their platforms Volkswagen has you know
I can give very admirable set of initiatives around electric and vehicle electrification a few other things Honda is doing similar things and so you know
for us it was important that we enable everyone and that was kind of what Aurora was started to do hi I had a
question now that I see a lot of companies are coming up with self-driving cars right so most of the
cars are pretty much all the technology is bound only to the car so would we see
something like an open network where car communicate with each other regardless of which company they come from and
would this in any way you know increase the safety or the performance of vehicles and stuff like that yeah I
think I think you're getting it vehicle to vehicle vehicle infrastructure type communication there there efforts
ongoing in that and it certainly it's it's only positive right the having that
information available to you can only make things better the challenge has historically been with
vehicle the vehicle and back to particular vehicle to infrastructure or vice versa it doesn't scale well one and two it's
been slow it's been much slower and coming than our development and so when we develop these systems we develop them
without the expectation that those that those communication protocol are available to us will certainly protect
for them and it will certainly be you know a benefit once or once they're here but until then many of the hard problems
that I would have welcomed 10 years ago to have a beacon on every traffic light that just told me at state rather than
having to perceive it I would have certainly used those ten years ago now they're less significant because
we've kind of worked our way through a lot of the problems that would have solved thank you for your talk my question is what's your opinion about
cooperation of self-driving vehicles so maybe I think if you can control a group
of self-driving vehicles at the same time you can achieve a lot of benefits to the traffic yes that is where one of
the that is where a lot of the benefits come from and infrastructure utilization or and is in ride-sharing with
autonomous vehicles and and specifically you know the better we understand demand
patterns people movement goods movement the better we can sort of optimally
allocate these vehicles and at locations where they're needed so yes that's that
certainly that that coordination this is where as I mentioned these three vectors of vehicle electrification ride-sharing
autonomy or transfer mobility as a service and autonomy really come together with a unique value
proposition yeah okay thank you yeah thank you so much for a great talking

----------

-----
--34--

-----
Date: 2018.03.09
Link: [# Emilio Frazzoli, CTO, nuTonomy - MIT Self-Driving Cars](https://www.youtube.com/watch?v=dWSbItd0HEA)
Transcription:


Introduction
today we have ameliafe Rizzoli he's the CTO of new Tata me one of the most
successful autonomous vehicle companies in the world he's the inventor of the RR T star algorithm
formerly a professor at MIT directing research group that put the first
autonomous vehicles on road in Singapore and now he returns to MIT to talk with
us give him a warm welcome oh thank you Lex
it's a great opportunity is a great pleasure to be back here I spent 15 years of my life here at MIT first as a
graduate student and then as a faculty as a faculty member and this is where
autonomy the company essentially was born and we did a lot of the research that led us to you know to start this
company and eventually you know develop all this technology what I will talk about today is a little bit about you
know our vision on autonomous vehicles why we want to have autonomous vehicles you know some of the guidelines you know
on the technology development why we are doing things in a certain way let's get started but and you know I really would
Why selfdriving cars
like to tell you you know a number of stories about why I started doing this
and why I think this is an important technology why we ended up starting this company so you know I've been a faculty
member here for 10 years I mean I was happily working with my UAVs and I was in Aero Astra at some point around 2005
mm yeah something you know there was these DARPA Grand Challenges that sounded cool right so I started working
on on cars as well but they are that were that I was doing was mostly you
know I was working on airplanes and cars to make them fly and drive by themselves
because it was cool you know just look you know no hands you know it drives and as it controls guys roboticist that's
all I needed right but then in 2009 there was this
new project that was starting in the team that was you know getting together to write a proposal for a project on
future urban mobility in Singapore okay now telling you the whole story but
essentially you know I got interested in that project just because I wanted to go to Singapore okay and then I you know
then I called the person who was putting together the team and okay yeah thank
you for your interest but you know what do you think that you bring to the table and you know we had just done the dark
urban child and so well you know I know how to make autonomous cars so what this is a project on future
urban mobility so what do cars have to do with with urban mobility autonomous
cars you know what would they had to do with mobility and you know there was the phone call the five minute phone call
that changed my life okay because she asked me this question that actually was Cindy Bernard who is now a chancellor
right and then I had to come up with an excuse right so why well imagine they
have a smart phone and then a smart phone app and then you use this app to call a car the car comes to you you get
on the car drive wherever you go want to go step off the car and the car you know goes to pick up somebody else it goes to
park or something right so this was two thousand in nine uber twas Travis kalanick and a couple of guys and black
cars in San Francisco right so and essentially she bought it so I joined
the team and and we started this activity but you know the important
thing is that I started thinking about you know there was something an excuse that they made up in those five minutes
okay but you know what kind of sounds like a good idea and I started thinking more
Why selfdriving vehicles
about this and I started thinking more about why do we want to have self-driving vehicles okay so the number
one reason that you typically hear is we want to have self-driving vehicles so that we make roads safer
okay a very large number of people die on on the road road accidents every year
what these people do not realize is that most of those people are actually you
know fairly young like in their 20s and 30s okay ompletely they you know what
people usually say is that you know Sebastian Thrun and you know back in the day he gave all these TED talks up
talking about his best friend from where he was young who died in a road accident right and then he made a mission for his
life to reduce the road accidents right but and I mean so any idea is that you
most of the road accidents are due to human errors you remove the human you remove the error
right and then you save lives okay so this is this is typically the number one reason that people mention when they
talk about why you want to have some tiny vehicles second reason is convenience
essentially if the car is driving by itself you can do other things you can
sleep you can read you you can text legally to your heart's content you can
check your emails or so and so forth right this is also great third thing is
you know improved access to mobility you know people who cannot drive me because
and I have some physical you know impairment or maybe they are too young they're too old already too intoxicated
to drive right so then you know if computer can take them home
another thing is increase efficiency throughput in in a city as cars can
communicate beyond you know visual range for example another one is reduce
environmental impact okay now these are all fantastic reasons you know why we
may want to have some driving vehicles the problem with me is that if you think
about this these are all you know good reasons but these are all ways that you take the status quo
you know how cars are used today and you make it a little bit better maybe a lot better but you do not make it different
okay and really that is what I am mostly what I was mostly interested in can we
you know use this technology leverage this technology to change the way that we think of mobility okay so how do you
Cost of selfdriving vehicles
compare all these different things okay so this is you know quick back of the envelope kind of calculation that you
can do in on your own you can question the numbers but I think that the orders
of magnitude are right okay so you know the first thing is okay so fine we heard
that a big reason for self-driving cars is to increase safety you know save lives great now how much is your life
worth well to yourself to your loved ones your friends your family is
probably you know priceless - the government is what about nine million dollars okay so this is what is
called the this is what is called the cost of a statistical life there was a
report that was released a few years ago probably you know there is an update now but I haven't seen it
the economic cost in road accidents the United States is evaluated to be about you know 300 billion dollars a year the
societal harm you know of road accidents is another you know all the pain and
suffering is evaluated to be another six hundred billion dollars a year so what we are getting to is about almost 1
trillion dollars okay it's a big number okay but let's look at where the other
effects are okay what is the cost of congestion is an estimate hundred
billion dollars a year the health cost of congestion of the extra pollution so
another fifty billion dollars a year so you see that these are a little it just a small change right the next effect is
actually important right so what is the value of the time that we as everybody
in society will get back from not having to drive okay simple calculation what I
did is I multiplied one half the median wage of workers in the United States
which is an embarrassingly low number multiplied by the number of hours that
Americans spend behind the wheel okay and what you get is about you know what
was it about 1.2 trillion dollars a year so something that you may notice is that
the value to society of getting the time back from having to drive is actually
more than the value to society or increased safety okay of course it's a
little bit cynical okay so take it with a grain of salt and a grain of salt but you start seeing you know how these
things compare and what you may notice from this pie chart is that you know there is still half of that is missing
what is the other half the other half is actually the value that you provide to society to you know
all individuals okay by essentially making car sharing finally something
that is convenient to use affordable reliable okay so for me car sharing or
you know vehicle share in general is a concept that everybody loves but nobody uses okay or not as many people as we
would like to you know use this kind of services examples when I was you know
here at MIT I really like using hub way you know the bicycle you know sharing
but you have to be very careful you know if you wait too long in the afternoon sorry there are no more bikes on campus
right or maybe very often you cannot find a bike or maybe you cannot find a
parking spot for your bike so then you had to buy somewhere else and then work so that defeats the purpose of of using
that bike same thing with with cars right so typically with you know car
sharing systems what you have is either you have a like a two-way which is essentially hourly rental right or you
have a one-way but in one way system then the distribution of cars tend to get skewed right and unless the company
you know rip repositions cars in some you know clever way then the year you're
not guaranteed that you will get a car where you need it and you're not guaranteed that you will get a spot a
parking spot when you don't need the car anymore okay if you think of that these are both like a friction points you know
for using vehicle sharing and these are both pre friction points that are actually addressed by if the car can
drive itself okay so if you bring in all the economic you know benefits of a a
car sharing system that actually works that's something that we estimate it to be you know it's about two thousand
dollars a year so you see that this actually it has a like a big chunk in this in this pie chart okay and that is
using an estimate of what we call the sheriff factor of four meaning that one of the shared vehicles can essentially
substitute for for in privately owned vehicles okay there are some studies that you know get
to this sharing factor up to ten and of course the benefits are even more now
every time I see inter write a round number like that I get suspicious right you know ten is a little bit too
convenient to be true right but any so that's something that you can find in
the literature so so this is really
What is a selfdriving car
where I think that the major impact of of autonomous driving or certain cars
will come from now if you I think also there is a lot of confusion in the community in the world about what a
self-driving car means now what I'm doing here I just listed this you know
five levels socially six levels of automation you know these are the Society of Automotive Engineers levels
okay so level zero is not a mission that's your you know great-grandfather's
car right driver assistance level one there is for example cruise control or
you know some simple single channel automation partial automation you have
you know something like for example lane-keeping and cruise control but you
still require the driver to pay attention and intervene conditioner
automation level three a driver is a necessity it's not required to pay attention all the time
but needs to be able to intervene given some notice okay and you know that some
losses I think is like ill-defined concept and then you have level four
level five that are like a higher donation essentially no driver needed in some condition that is level four and in
all conditions that level five okay now my first reaction when I started seeing
these levels and you know there is also similar version by Nitza
is that listening to me you know a horrible idea and the horrible idea in the sense in because they are given
numeric levels so you have level zero one two three five whenever you have a
sequence of numbers you are led to believe that these are actually sequential right that you do level zero
then you do level one thing you do level two three four five I think this isn't
like an enormously bad idea because I think that level 2 and level 3 that is anything where you require the human to
pay attention and supervise the automation and be ready to intervene with no notice or with some ambiguously
defined you know like a sufficiently notice they just go behind you know go
against human nature and you know this is especially painful for me as a former
aeronautics and astronautics professor where we saw in the airline industry that as soon as Auto Palace were being
introduced and everybody thought that accidents would go down actually there were more accidents
because now you have new failure modes induced by auto pilots okay you have
multiple fusion Pylos flu situation awareness pylos lose the ability to react in case of an emergency okay so
the idler and Industry had to essentially educate itself on how to deal with automation in a good way and
think of pile you know pilots are highly trained professionals which is not the
same that you can say about your everyday driver right so how do you train people who probably you know you
know the last time they said with a with an instructor in a car was you know when they were 16 right how do you train
people to use the automation technology in and do it safely right so I think
that you know distantly that front very scary on the other hand I think that you know the full automation when the car is
essentially able to drive itself does not rely on a human to take over isn't
it that in a sense is easier and you know this is what we are doing and but you know the point is that not
Value of selfdriving cars
all it is easier but I think that is essential to capture the value of the technology now if you think of it so how
do you realize the value of these self-driving vehicles okay so the first thing that people say is safety I think
it is true that eventually asymptotically self-driving cars will be
safer than their human driven counterparts however at what point can
we be confident that that is the case are we there yet not sure okay
so so how do you demonstrate the
reliability of these self-driving cars so we know you know they've driven that
cars for three million miles right so with a readily small number of accidents
if I remember correctly only one was their fault right but um actually humans
drive for many you know many times that without accidents or so how do you
really make sure that even though the number sounds impressive it really
doesn't have that much of a statistical significance right and then every time you make an update to a change to your
system to your software you really have to validate again right so I think that making the case for safety is actually
is a very challenging issue and we may not be positive that these self-driving
cars are actually safer than the human counterparts you know until you know a really long time from now
okay so safety for me remains kind of an questioned open question at this point
how do you get back the time value of driving if you had you know at least I'm
speaking for myself if I have to constantly pay attention to what the car is doing excuse me but I rather drive
myself okay because you know if the car is driving and you know this is the paradox
right so the better the car drives the harder it is for me to keep paying attention right and this is where the
whole problem is right so there would be very hard for me not to fall asleep or you know not to get distracted so if I
want to get that time back really you know the car must be able to drive itself without requiring me to pay
attention captioning again you know is a you know in order to make car sharing
really convenient and reliable and sounds fourth you need the car to come to you with nobody inside and Ford it
for that you need level four or level five okay anything else just doesn't cut
it you know everything else for me is just a nice gadget that you have on your
car that you show off to your friends or to your girlfriend okay so that's about it right is it's not that useful so my
point is that level four or five automation is really essential to capture the value of this technology and
in fact the one game-changing feature of these cars is the fact that these cars
now can move around with nobody inside that's really the game-changing feature okay good and you know this is you know
really what we like to do now there are many paths that you can go after this
target okay I usually show this this fear okay so on this figure what I show
on the horizontal axis is the scale or the scope of the kind of driving that
you can do okay so on the left is like a small you know pilot maybe a closed
course on the right is driving everywhere okay on the you know like
complex environments right mass deployment and so forth on the left
there is on the vertical axis is the level of automation okay now really what
we would like to do is get to the top right corner right so we have millions of cars driving all over the world
are completely you know completely out in a completely automated way okay
what I see is there are two different paths that the industry is taking okay what I show here is what I call this is
the OEM path okay so this is the the automaker's right so
they're used to thinking of production production of cars in the orders of many
many millions okay and essentially what they do is they make a lot of cars and they are adding
features to discuss you know advanced driver assistance systems and so on so forth right and essentially they're
following these levels 0 1 2 3 4 5 ok and you know today you can buy cars
which even though they claim fully autonomous you know package for $5,000
plus another $40,000 or something in the fine print this is level 2 rights or
level 2 or level 3 so you know Tesla said is I think the bau-t who the new
Audi a8 is a 8 they're coming out with this we just kind of feature Cadillac I think as a similar thing okay
the problem with that I seen that you know you had to cross this this red band
okay this red band where you're actually requiring human supervision you know of
your automation system another path where people are following is this other
okay so this is what we are doing what way more you know where these are where
all the indications or that Weimer is doing of course they're not telling me exactly what they do similar thing for
uber right so essentially what they're doing is they're working on cars would be fully automated from the beginning
and they start with a small you know maybe geofence application and then
scale that update operations outright but always remaining at the full you
know High full automation level okay another thing that is important that you
Consumer vs service
know people make a lot of confusion and don't seem to realize the big difference is the following when people ask me when
do you think that we will see autonomous vehicles everywhere on the city aware you know autonomous vehicle would be and
would be common I guess I'm okay but you know what do you mean exactly by that
right because if you ask me when you see that you will be able to walk into a car dealership and get out with the keys to
a car that you know you just push a button it takes you home that's not happening for another 20 years or at
least okay on the other hand if you ask me when you will be able to go to some
new city and some on one of these vehicles that piece you up and takes you to your destination the other thing is
happening within a couple of years okay what is the difference there is a big
difference between autonomous vehicles self-driving cars is a consumer product versus a service that you provide you
know to two passengers okay so for example what is the scope you know where
do these cars need to be able to drive okay if it's a product and I pay you
know ten thousand dollars for it then I want this thing to work everywhere right
so take me home you know pick two to be into this little alley you know drive me through the countryside on the other
hand if I'm a service provider and I'm offering the service I can decide you know I'm offering this service in this
particular location and by the way I'm offering this service under these weather conditions and maybe under these
traffic conditions okay so just the problem becomes much more much easier
what are the financials right so if I have to sell you in autonomy a car with
an autonomy package how much can i cost you know what would what are my
cross-country constraints on that autonomy package if I sell it to you you
know first of all the cost of the autonomy package must be comparable to the cost of the vehicle okay
you know you will not buy a $20,000 car with a half a million dollar autonomy
package right also you can do so another
back-of-the-envelope calculation that it is okay so let's say that what is the value to you as the buyer of this
autonomy package let's say that the value to you is the fact that now instead of dragging you know for the
rest of you know for the next 10 years you can have the computer grinding for you what is the value of your time as
you are not driving right so do a quick calculations again you know total number
of hours that Americans spend behind the wheel median wage or in a value of time
what you get is you know what I get is that you know the net present value of
the drivers time over the next 10 years is about twenty to twenty thousand
dollars okay so then you know a rational buyer will not pay more than that you
know to buy this autonomy package right so now you're constrained by twenty thousand dollars okay
or actually if you want to make a profit out of it you know your constraint your autonomy package cannot cost more than a
few thousand dollars okay on the other hand if you're thinking of this as a service then what you are comparing to
is the cost of providing the same service using a carbon-based life form
like a human behind the wheel okay so now you want to provide 24/7 service you
need to hire at least say three drivers per car okay then the cost is comparable
of the order of hundred K a year okay so now I'm comparing the cost of my
automation package to something that is going to cost me $100,000 a year over
the life of the car okay so now the cost of the Atlanta computer or that fancy
radar or something doesn't matter that much okay so I have much more freedom in
buying the sensor that I need infrastructure for example people talk
about maps HD maps right now again if I want to sell it as a product I need to
enter have to sell it I want to sell it on a globe scale well global could mean older the United States for example or all of
Europe then I need to have maps HD maps of the whole of Europe or the continent
or any other stays or whatever I want to sell the you know the cars if I'm providing a service then I only need to
map the area where I want to provide the service and by the way how do how does
the complexity of the maps scale with the customer base that you're serving if
you think of a uniform people density okay so then actually they land you
think that the complexity and the cost of generating Maps scales with the length of the road network then the cost
of the maps scales with the square root of my customer base meaning that will
become negligible as I serve more people okay so HD maps yes it's a pain in the
neck to collect them and to maintain them but it's much less of a pain in the neck that actually open it in the
logistics of a fleet serving the population of a city okay and servicing
and maintenance you know how would you calibrate your cameras and your sensors
you know that's not something that you would do as a normal consumer right oh we are not used to that when I was
little I was used to my father you know he was tinkering with the car all the time you know checking the you know the
timing belt or changing the oil or you don't do any of that nowadays right so
you just sit in the car switch it on if the yellow light you know Check Engine comes up into the dealership right
that's all you do now imagine that you know now you have if you want to use
your autonomy package you had to calibrate the sensors every every time you go out or you know you have to
upload you know like a new version of the drivers and these are that so you don't want to do that on the other hand
in the service model I had the maintenance crew that can take care of it in a professional way okay
so big difference between the two models so there are a couple of important takeaways right so one thing is that the
cost of the autonomy package is not really an issue really the cheaper I can make it the
better it is right but that is not really the main driver in particular if you need a lighter sensor for example to
detect a big truck that is crossing your path by the ladder sensor okay so that
is not making the difference and maybe you can save some lives okay any reference to other things is intentional
HD Maps
the other thing is HD Maps the people worry about you know 12 you know very
much today from my point of view HD Maps my expectation is that HD maps within a
few years will be a dime a dozen okay what is complicated what is expensive now in generating all these HD
maps the mapping companies need to put these sensors on a car on you know and
send these cars around now imagine that I have a fleet of 1,000 cars with these
sensors on board and these cars are just driving around the city all the time the
generating gigantic amount of data that I can just use to make and maintain my
HD maps so I think that you know especially from the point of view of the operators the providers of these
mobility services very easy to collect data to essentially make you know make
and maintain their own Maps okay so if you need HD maps that's fine because as
soon as you start offering this service you will be able to collect all the data you need to generate this a generate and
maintain these maps oh by the way this is showing an animation showing you know like a simulation of a fleet of I think
it's a couple of hundred vehicles in Zurich in Switzerland right so that's
where I was based until a few days ago and as you see in essentially you have
vehicles that going through go through most of the city you know every few hours okay I think that for
example the uber fleet goes through 95 percent of Manhattan every two hours or so
Advantages
cos advantages you know of course you know the you know most of the cost of
you know taxi services nowadays is is the driver you know it's about half of
course you remove the driver from the picture you don't have to pay them of course the automation costs you a little
bit more servicing cost you a little bit more but you see that you know you still have you know you you know you can get
like a really significant increase in the margin right meaning that you can
pass some of those you know savings to customers right but also you can make a very strong business case however this
is also misleading now if you think of it okay so typically what the reaction
that you get is the following oh my goodness now you make this thing
and then all taxi drivers all truck drivers would be out of a job okay
and in fact one day I was summoned by the Singapore Ministry of Manpower okay
and I was terrified oh my goodness they're gonna shut me down because they're afraid that that will put all of their taxi drivers on a
State on a street in the sense of being unemployed turns out it was the opposite
Mobility paradox
what most people do not realize is that actually mobility services worldwide are
actually meant power-limited okay in Singapore they would like to buy more
buses but they don't have enough people who are able and willing to ride the
buses okay this is true pretty much the same to for tracking same for Tarsus now
this is another back-of-the-envelope calculation that you can do on your own now imagine so as we know you know Ebers
be widely successful you know very high valuation a lot of this valuation is
predicated on the fact that everybody in the world will eventually use uber right or something similar now something that
people don't think about is the following now if everybody in the world you uber for their mobility means how many
people in the world need to be drivers for uber do the calculation what you see
is that one person out of seven must drive for uber if uber is surveying the whole world do you see that happening no
way right so people still need to be you know teachers doctors you know policemen
firemen you know or you know some people need to be kids you know so that is something this cannot happen how are we
facing these paradox in a sense right so you know today what you have is people who drive around but what is happening
today is that we are all doubling up as drivers for ourselves and in fact we do
spend about one-seventh one-eighth of our productive day behind the wheel
very often ok so you know for me you know did the big the big change is will
be more on the supply of mobility rather than on job loss I mean of course if you
increase supply of mobility you know the the cost of mobility will have to you know we will you know probably go down
wages for drivers will go down right so that is that is a that is a that is an
issue but you know maybe other you know baby balance by like a added value and
service or other things that you can imagine another thing about truck
drivers you know something that they recently learned 25 percent of all job
related deaths in the u.s. are actually by trucks drivers ok is the most the
single most dangerous industry that you can be in so maybe if you can take some
of those people out of those trucks and maybe supervise remotely control a truck sitting in their office instead of
sitting in the truck you know that that may be actually benefit to them back to the question of when we lot on most
When will selfdriving cars arrive
vehicles arrive and you know in a sense this is what you know what our prediction our vision is right so what
we will see is that what we think is that you have a fairly rapid adoption of
self-driving vehicles in these mobility as a service model okay as a fleet of
shared autonomous vehicles that people can use you know to go from point to point right rather than all of course
eventually you know people will be able to buy these cars and maybe own them if they really want but you know that is
something that is much later in time for for a number of reasons some which I
discussed okay so this is you know what we expect in terms of the timeline for
this now what is the state of the art
State of the art for autonomous technology today
for autonomous technology today you do see a lot of demos for from a number of
companies you know doing a number of things right but but a lot of the things
that you see are not too much different from this video I don't know if any of
you recognizes this video but you know look at the cars this was actually done
by LSD commands in the late 90s in Germany okay no fancy GPUs no it was
just a cameras and some you know basic computer vision algorithms but
essentially he was able to drive for hundreds of miles on the German highways okay if you're not showing
something that goes beyond that you have not made any progress you know over then over the past 20 years okay yeah you're
using fancy deep learning and GPUs and things nowadays but you're doing what people were doing 20 years ago you know
okay so you see arena clearly there's a lot of hype in these things but you know
if you see something like that I don't think it's very impressive okay people people you know knew how to
do that for for a very long time something that I find a little bit I may be biased clearly right but this is
Driving in traffic
something that I find a little bit more exciting this is actually footage from you know our daily drives in Singapore
okay this is four times in real time we don't drive that fast okay but essentially what we're doing in
Singapore we are driving you know in you know public roads normal traffic what you will see is not
so but you know do we have you know construction zones intersections traffic you know you know of both sides we will
get to a pretty interesting intersection has a red light will turn to green in a
second human mind in Singapore they drive on the left right so making the
right turn is what is hard because you had to cross traffic right and here you have in a lot of traffic and you know
the car is making the right decision in all of these without any human intervention right so I think that in
this day and age if you're not showing the capability of driving in traffic in
an urban situation like that you're not really showing any advance over what people were able to do 20 years ago okay
and you know I mean as you can see if I saw the intercessions other cars pedestrians you know all kind of like a
crazy interactions you know you know the cars park in the middle of the street that you had to avoid go to the other
lane you know things like that okay so this this is what you had to do every day and you know this is what we are
doing every day in Singapore we are doing every day here in the c4 if you're aware of botany we are driving
you know cars we are allowed by the city of Boston to drive our cars autonomously in the Seaport area so what are the
Technical challenges
technical challenges okay so actually this is a slide that I did I'm fairly
reusing from a talk that I'm not chakra the founder and CEO of mobile I gave
here at MIT a few months ago okay so this is what he said okay so it's not
what I say what he says is that the big challenges are sensing you know
perception it's mapping and then is what he called driving policy right that I
will call more like a decision-making okay now what he said is that sensing
perception is a challenge but is a challenge we are aware of and then we
are making rapid progress on getting better and better sensing perception algorithms okay second it's HD maps what
he said is that it was a huge logistical nightmare so he didn't want to deal with that you know like mobile I tries to
avoid that from my point of view as I said you know for me it's the maps it is
a replay in the neck to get those maps but in a few years
maps will be a dime a dozen okay so we'll get all the mapping data that we want and we need so the big problem is
during policy okay the remaining problem is drawn in policies so how do you do it not and you
Traffic light example
know this is a typical example of things that we encounter in you know in any color urban driving situation so you
will see a video so this is a case where we are at the traffic light we are
stopping the traffic you know the light turns green we are making the turn this is a pedestrian crossing the street wait
for the press tree and go through it and then we see that there is a truck that is part in the middle of our lane so we
need to go to the other lane which is in the opposite direction there is a model excuse me a motorcycle coming so we had
to handle all that kind of situation right so how do you write your software
in such a way that your car is able to deal with this kind of complicated situation by itself okay and
Rules of the road
my point is that you know this is not really about negotiation is not about
policy why do you have rules of the road my claim I have not proved it
mathematically yet but my claim is the following the touching the rules of the road were introduced exactly to avoid the need for
negotiation when you drive okay when you're walking as a person you just walking down the
hallway you know walking down the infinite corridor and there is a person come in the other direction there's always that awkward moment right
away you're trying to linger I go left I'll go right right with cause you you don't do that right so in cars the side everybody go
right or in other places everybody go left period and you don't negotiate that okay you get to an intersection the the
the light is red you stop you know saying I'm putting I'm really in a rush you know do you mind if I go no you
don't do that right so it's red and you stop okay so the rules of the road have been invented by humans in order to
minimize the amount of negotiation and you know and you know in particular okay
so this is a slightly I mean this is actually very old video but I kind of like it so now our car is a little bit
more aggressive but you know what you see here is this case you know this is how the car behaved in that particular
situation so you see it's raining red light turns green there's a pedestrian
crossing our path so we heel to the pedestrian you see that there is a you will see that there
is a truck that is parked on the on the left lane in the middle of the lane so we had to go around it but this is a
motorcycle that is approaching so we had to be careful in going to the other lane
okay so we squeezed through the through the motorcycle you know we try to go very slowly next to squishy targets
right but then as soon as we pass the truck the truck driver decides to get
moving okay so then what we do is we wait for the truck to get you know to get going and
then go back to our lane now imagine writing a script you know or you know if then else if there is a
track but the truck is moving and then do this and this the network so you know what to do that right so how do you
handle this kind of situations okay so the industry standard you know this approach to this was - and
The industry standard
by the way this is what we did at the time of the dark urban challenge okay so we had a lot of if-then-else statements
or you know finesse test machines or some logic that was encoded by you know some furnaces machine kind of kind of
things the problem with that is it's
very hard to come up with this logic and is essentially impossible to debug it
and verify it right so I spent many miserable months sitting in the naval
airbase in Weymouth right so here in a rental car just plain interference with
our autonomous car trying to adjust all these logic and parameters and things so
I vowed that I would never do it again I was just miserable experience I'm
happy to say that actually we did come up with a much better way of doing it and you know by the way this is a video
Caltechs mistake
from the Caltech team at the dark urban challenge as you can see they're trying to go to an intersection they decide to
go then for some reason they decide not to back up out of the intersection so
the director of DARPA you know Tony Taylor at the time he was there he went
like that so they were out of the race okay so as soon as CCO saw that what
happened here there was essentially a bug in the logic Caltech you know very a
team of very smart people very capable dedicated people work on these for months they didn't catch this Bank this
Bank they were out of the race right so it's very easy to make mistakes and it's very hard to find those bugs okay so as
Too many rules of the road
a reaction to that you know there is this new
is it possible to cut the sound thank
you so now what people what you hear people saying is well there are too many rules
of the road it's impossible to code all of them correctly so let's not do that
just feed the data you know feed the car a lot of data and let the car learn by
itself how to behave okay okay and this is what you see you know
you know there are a number of circuits and other efforts that are trying to use all these you know deep learning or
learning approaches to to get to the fore end to end driving of of cars okay
so you see a video from Nvidia okay
understand this is a course on deep learning for cars right but so so I
don't want to sound too negative on the other hand I will try to be honest in
what I think ok so you know there are a number of problems right so that's what
Learning the wrong thing
is happened to us right so one of our developers you know you know super bright lady from you know you know
Caltech and you know the first version of the code for dealing with traffic
lights essentially the reaction that you know that that they had for for the yellow light was if you see a yellow
light speed up what the heck oh this is what my brother does okay so there is
always the danger that you learn the wrong thing okay did the wrong behavior
in a sense of course there are some situations in which accelerating when
you see a yellow light is actually the right response but it is not always the case right so there are some other
features of the situation that you need to examine right also the other thing is
as a cartoon right so you know you want to be able to explain why the car did
something and I would say that more than explaining because now you also see articles in which people say Oh
a fun way of explaining why they do not not for him to carve decided to do something right I want to show you is
some okay so these are the noodles that were activated just saying that you know
what if I do an F in a fast MRI of the brain and they see what neurons what
areas of the brain are activated when I watch a movie then I know how the brain works no I have no idea okay the point
is that yes you want to trace the reason the cause for why they can't behave in a certain way but you also want to be able
to revert the cost right so you want that information would be actionable in some sense right so you want you want to
know that okay this happened because of this reason and this is how I fix it okay and the other thing that you know
society that is hard to do with purely based learning algorithms on the other
hand you can let me actually skip that in the interest of time okay the reality
The reality
is the following that it is simply not
true that there are too many rules of the road in fact any 16 year old in the
states can go to the DMV get the booklet study the booklet do a written test and
be given a learner's permit okay and actually this is what we require of
every single licensed driver in the United States okay we don't say just
drive with your dad or mom for a few thousand miles and that will give you the license no we ask them you know show
me that you study the rules and you understand the rules okay so how many
are the rules of the road actually went to an exercise of counting okay and what
they did I can do like a cluster them so essentially you have rules on who can
drive when and where what can be driven whenever you know at what speed in what
direction who yields to whom right how you use your signals active signalling how do
you interpret the signals that you see on the road right and where you can park
away you can stop that's essentially it you know this is this these are all the roads okay so not that many it's
collected twelve categories what is true is that the number of possible
combinations of rules and the instance instantiation of the rules given the
context of you know the scenario where other actors are pedestrians are and
where other cars are that is a humongous number okay
so you don't want to code you don't want to be to essentially any generative
model that gives you what is the right response to all possible combinations of
rules and instantiations of actors that is something that is just coming up
totally you know intractable you just cannot do that but the point is that not
only it is hard to code the good behavior what to do in every one of these situations I claim that is also
hard to learn the good behavior because now you have you need to have enough training data for every possible
combination of rules and instantiations good luck with that
okay on the other hand it is very easy
to assess what is a good behavior and that's why I was showing this slice on
np-hardness right so what is the problem that is np-hard the problem is np-hard
where if you have a non deterministic system that is generating a a candidate
solution then it is very easy to check whether or not that candidate is
actually a solution of your problem and that's something that you do in polynomial time okay so in a sense what
what I claim is that if you have an engine that is able to generate a very large
number of candidates and all you do is checking and then you know what you do
is checking whether or not each one of those candidates is good with respect to
the rules then that's all you need and turns out that you know the algorithms
that I worked on during my you know academic career where exactly generating that very large number in our TRC star these are
algorithms that work by generating a very large graph exploring all potential
trajectories reasonable trajectories that a robot a system that can take and then what you do is you check them for
you know whether they satisfy the rules or not you see that is very different
from giving the rules generates something that satisfies everything
rather than given a candidate check whether or not this candidate satisfies
the rules the generating the rules the generating candidates given all the all
the constraints is a combinatorial problem checking a single candidate for
compliance with a number of rules is a linear operation in the number of rules so that's something that you can do very
easily okay and then essentially what we have in our cars today we are using
Formal methods
these formal methods okay so essentially we write down all the rules in a in a
formal language you know so you know very precise you know like your syntax and then what you can do is you can
verify whether your trajectories satisfy all these rules written in this language
that is automatically that can be automatically translated into something look like a finite state machine by
computer okay but there's not something that you do by hand it's something that is done automatically and then what
Automatic trajectories
happens is that what we have is we generate trajectories these trajectories are you know you can think of these as
trajectories that now are not all the trajectories in the physical space and time but are also trajectories evolving
in this logical space telling me whether or not and to what extent I am satisfying the rules okay and that's all
there is okay so this is um you know for example
Automatic parking
regular little example so you know initially what we are doing is work so
this was very early days on Deuteronomy where we're still working on a research project with industry with customers so
our customer in this case wanted us to do an automated parking application and then what you see on the left is our
planner eager planet that is just trying to to park the car right avoiding hitting other cars but you see is kind
of ignoring the fact that you have lanes and direction of travels right so you're putting the rules and what you see is
what is on the on the right where now what the car is doing is not only finding the trajectory to go park but it
does so obeying all the rules that are imposed on that particular parking structure okay something that is very
Hierarchy of rules
important and you know this is something that we as humans do every day is to deal with infeasibility okay so very
often you're doing your planning you're trying to plan your trajectory you have
a number of constraints and well sorry but turns out that there is no trajectory there's no possible behavior
that you can do that will satisfy all the rules so what do you do the computer
time sorry does not compute unfeasible still driving this car I need to do
something right so you do need a way of dealing with infeasibility the way that we approach this problem is
being having this idea of hierarchy of rules okay and my claim is that all
bodies of rules generated by humans are actually organized hierarchically typical example is the Three Laws of
Robotics by asana right so the first law of robotics is a robot will not harm a human right or cause a human to come to
our second law is a robot will obey a human orders by a human a human unless
they violate the first law and the third law is a robot will try to preserve its own life or preserve itself unless it
violates the first two laws right same thing in in when you drive right so
there are some rules that are more important than others right so for example do not hit people do not hit other cars and then lower priority level
is to be driving your lane the lower priority level is maybe maintaining the speeding or something like that okay and
then what we do is come up with now we have this product graph of trajectories
Total order
in the physical and logical space on top of that we can give them a cost right what we need is a essentially a total
order what we use a lesser graphic or drink okay when we have violating an
important rule even by a tiny amount is much worse than violating a less important rule by a large amount okay so
that gives a total order structure for the cars and then essentially what we do is we solve a shortest path problem on
this graph okay which is exactly what you do the robot is one on one when you
try to do you know do any kind of motion planning okay and well you know this is
Other lane
in a collection of a few interesting things so here we need to go to the other Lane but you see that there is the
other vehicle coming so technically we could not go to the other Lane but you see that you know as long as it is safe
to do so the car will go into the other Lane okay you know and again you have
like a lot of you know like a difficult situations that the car was able to handle by itself without any scripting
or without any like a special instruction for that particular case okay so what is
The problem
here the problem here is that okay so you can do all of this right and but
then you know assuming that everybody is running this minimum violation planning you know everything will be okay the
problem is that humans introduce a lot of uncertainty in the whole thing okay
The fundamental norm
now you can think of disease asking the question so when I was young in a if that is two years ago I thought that I
take all the rules of the road and you convert them to this formal language you put them in your software and you're
done and then and then you go and look at these rules of the road and then you see that they are a mess
okay these rules are just not the sound theory in the sense that not complete do not cover every possible case and are
not consistent you know they're kind of like tell you to do different things in different cases my my prefer my favorite
rule is this one is actually called the fundamental norm in these with roots of the road look at that all road users
must behave in such a way not to post an obstacle of danger to other road users that behave according to the rules do
you see a problem there okay that doesn't mean that if I see somebody who is violating the rule I can just hit
them right so you can imagine that you have a fleet of vigilantes you know autonomous cars that just go around and
if you run the red light I'm gonna kill you right I mean technically they you
know the autonomous cars will be you know will be right right so the other the other guy would be you know they
want to blame right well you know do we really want that probably not right in
the fence of the Swiss they actually have you know that rule continuous a special care must be exerted in case do
you have evidence that other people are not following the rules but still doesn't tell you what you're supposed to
do when somebody else is violating the rule okay and you have totally problems
right so probably you have heard you know you hear about all these trolley problems to no end right and most of
these are fine you know I mean truly stupid you know in the sense is like a big waste of time in
the sense that yeah sorry I think it's extremely unlikely that you will be
given the choice of killing either Mother Teresa Hitler right so I mean for sure that
will never happen right but you know anything remotely similar will never happen to you on the other hand there
are versions of the trolley problem which are actually meaningful okay so this is one that you know my collaborator and their agency came up
with okay look at this case so you're driving down the road and you see a pedestrian that is jaywalking in front
of you okay if we stay the our current
course we will kill the pedestrian before reading one okay but it's not our
fault okay it's his fault panting Oh her his or her fault that they stepped in the road when they shouldn't have on the
other hand what we could do is we can try to swerve right but then with some probability P we may kill another person
who had nothing to do with this thing you know they were just walking around you know peacefully right so the reason
why I like this is because this problem actually has clear solutions in there to
extreme cases right so if P is one okay in the sense that if this word will kill
somebody else then we clearly kill the guy who was jaywalking right if P is
zero that is I'm sure that I'm not killing anybody if I swerve then clearly I will is worth what is the boundary so
I know that the solution exists for P is equal zero and all the solution exists with P equal one by some continuity
argument if you know I must have some value of P at which the solution changes
what is that value nobody knows how do
you evaluate that P nobody knows but you know these are the kind of question that
we actually need to answer somehow so it's a more you know a little bit more
sophisticated case now what we and you know this is what happens every day in our cars right so when the our computer
vision system is telling me that there is a pedestrian in front of us it's not telling me that there is a pedestrian for sure right so it's telling me that I
think that there is a pedestrian in front of us and you know I'm you know eighty percent confident
you know some probability Q okay now a wall combination of probability on the
pedestrian actually been there and my probability of killing somebody else would as well right so because if I is
worth and killed somebody because just a ghost you know like a false positive he'll be in serious
trouble right so how do we explain that well I thought there was someone in front of me was nobody there right so again you know you do have
solutions for some extreme cases but then you have this whole two-dimensional domain now which you had to you know
there would be a boundary where do you put the boundary okay and this is some something that somebody will need to
answer okay I I don't think it should be me you know of course I can't come up with an answer
when I write my code but I actually think it should be you right in the sense this should be the a community
effort in which the community agrees on how the car should behave or you know in
these kind of situations so let me conclude by saying you know when people ask me what do you think is the biggest
challenge in autonomous vehicles and something that I've come to realize only recently is that I think that the
biggest challenge in the development of autonomous vehicle technology is that we do not understand in a very precise way
rigorous way how we want vehicles in general including human driven vehicles
to behave okay a lot of these rules of the road are just like a giant pile of I
wouldn't say garbage but almost you know it's a it's very uncertain language very you know no rigorous laws rather rules
for example a lot of the rules are predicated on a concept of right away
you know I looked everywhere there is not a single definition of what right
away means in mathematical terms I know that he has something to do with distance as something to do the relative
speed maybe with absolute speed but know what are the values I don't know
what are the numbers if I had to write a function so if you see this car approaching and this car is farther away
than this distance and the relative speed is more than this then stop otherwise go there's nobody who is
telling me what that relationship should be anything again what we need is we
need to develop a sound theory for these rules of the road ok that cover precisely any kind of situation and
tells me you know any kind situation what is the right behavior what is the wrong behavior or little bit more maybe
what is if behavior hey if you have two behaviors which one is better okay I
need to be able to better do the comparison now we can use formal methods
at window there is a lot of room here for statistical or learning based methods you know like look at look at
what people actually do when what you know at what point will people funkateers right rather than in the
field at your cutting them off versus you know they feel that they a little done okay so we need to develop this
sound theory we need to be assessed the behaviors on realized space and time
trajectories what you thought that you had seen that doesn't matter okay oh you
know because if you say well if I if I didn't see the pedestrian that is not my fault that I hidden well then people
will start removing sensors right so if you don't see anything you can it hit anything you want you're not to blame
right but I really think that you know
the compliance of the rules once we have this precise rigorous rules will actually derive a lot of requirements
for the sensing perception system for the planning control system okay so from
my point of view the main message today is what I think is the biggest challenge
is that we don't know how precisely how we want human driven vehicles to to
behave okay once we answer that question I think that also designing automated
vehicles will be much much easier okay so let me stop here okay so I'm just
giving you know a few references so some of our you know published work you know on these topics and you know let me just
conclude you know okay so this is you know the company what we are trying to do allow me you know you're also hiding
so anybody's interested you know feel free to you know send me an email you
know contact us we want to double our size in the next couple of years so we're hanging having a couple of hundred
people okay thank you for your thank you

----------

-----

--33--

-----
Date: 2018.03.02
Link: [# Stephen Wolfram: Computational Universe | MIT 6.S099: Artificial General Intelligence (AGI)](https://www.youtube.com/watch?v=P7kX7BuHSFI)
Transcription:

welcome back to success $0.99 artificial general intelligence today we have
Stephen Wolfram Wow
that's the first I didn't even get started you're already clapping in his
book a new kind of science he has explored and revealed the power beauty and complexity of cellular automata as
simple computational systems for which incredible complexity can emerge it's
actually one of the books that really inspired me to get into artificial intelligence he's created the Wolfram Alpha competition knowledge engine
created Mathematica that has now expanded to become Wolfram language both he and his son were involved in helping
analyze create the alien language from the movie arrival of which they use the
Wolfram language please again gives Steven a warm welcome boy so I gather
the brief here is to talk about how artificial general intelligence is going to be achieved is that they set the
basic picture so I maybe I'm reminded of kind of a storage I don't think I've ever told in public but that something
that happened just a few buildings over from here so this was 2009 and Wolfram Alpha was was about to arrive on the
scene I assume most of you have used wolf now for a scene wolf alpha yes the
how many of you've used wolf alpha ok that's good so I had long been a friend
of Marvin Minsky's and Marvin was a sort of pioneer of the AI world and I kind of
seen for years you know question answering systems that tried to do sort
of general intelligence question answering and so at Marvin and so I was going to show Marvin you know Wolfram
Alpha he looks at it and he's like okay that's fine whatever said no Marvin this
time it actually works you can try real questions this is actually something useful this is not
just a toy and it was kind of interesting to see it took took about five minutes for Marvin to realize that
this was finally a to an answering system that could actually answer questions that were useful to people and so one question is
how did we how do we achieve that so you know you go to Wolf's malphur and you can ask it I mean it's I don't know what
we can ask it I don't know what's the some random question what is the
population of Cambridge actually here's a question / let's try that what's the
population of Cambridge is probably going to figure out that we mean Cambridge Massachusetts it's going to give us some number it's gonna give us
some plot actually what I want to know is number of students at MIT divided by
population of Cambridge see if it can figure that out and okay it's kind of
interesting right oh no that's / ah that's interesting a guest that we were talking about Cambridge University as
the as the denominator there so it says the number of students at MIT divided by the number of students at Cambridge
University that's interesting I'm actually surprised let's see what happens if I say Cambridge MA there now
as it probably fail horribly no that's that's good okay so no that's
interesting that's a plot as a function of time of the fraction of the of okay
so anyway so I'm glad it works the so
one one question is how did we manage to get so that many things have to work in order to get stuff like this to work you
have to be able to understand the natural language you have to have that data sources you have to be able to compute things from the data and so on
one of the things that was a surprise to me was in terms of natural language understanding was the critical thing
turned out to be just knowing a lot of stuff the actual pausing of the natural language is kind of I think it's kind of
clever and we use a bunch of ideas that came from my new kind of science project and so on but I think the most important
thing is just knowing a lot of stuff about the world is is really important to actually being able to to understand
natural language in a useful situation I think the other thing is having
actually having access to lots of data let me show you a typical example here of what is needed so I asked about the
ISS and hopefully it'll wake up and tell us something here come on what's going on here there we go okay so it figured
out that we probably are talking about a spacecraft not a file format and now it's going to give us a plot that shows
us where the ISS is right now so to make this work we obviously have to have some
feed of you know radar tracking data about satellites and so on which we have
for every satellite that's that's out there but then that's not good enough to just have that feed then you also have
to be able to do celestial mechanics to work out well where is the ISS actually right now based on the orbital elements
that have been deduced from radar and then if we want to know things like okay when is it going to it's not currently
visible from Boston Massachusetts it will next rise at 7:30 6:00 p.m. on
Monday on today so you know this requires a mixture of data about what's
going on in the world together with models about how the world is supposed to work being able to predict things and
so on and I think another thing that kind of realized about about AI and so
on from the wolfman alpha effort has been that you know one of the earlier
ideas for how one would achieve AI was let's make it work kind of like brains do and let's make it figure stuff out
and so if it has to do physics let's have it do physics by pure reasoning like you know people at least used to do
physics but in the last 300 years we've had a different way to do physics that wasn't sort of based on natural
philosophy it was instead based on things like mathematics and so one of the things that we were doing in in
Wolfman alpha was to kind of cheat relative to what had been done in previous AI systems which was instead of
using kind of reasoning type methods we're just saying okay we want to compute where the ISS is going to be well we've got a bunch of equations of
motion that corresponds to differential equations we're just going to solve the equations of motion and get an answer that's kind of leveraging the last 300
years or so of of exact science that have been done rather than trying to make use of kind
of human reasoning ideas and I might might say that in terms of the the
history of the wolf malphur project when I was a kid a disgustingly a long time
ago I was interested in AI kinds of things and I in fact I was kind of upset
recently to find a bunch of stuff I did when I was 12 years old kind of trying to assemble a pre version of Wolfram
Alpha way back before it was technologically possible but it's also a reminder that one just does the same
thing once whole life so to speak at some level um but what happened was when
when I am I started off working mainly in physics and then I got involved in
building computer systems to do things like mathematical computation and so on and I then sort of got interested in
okay so can we generalize this stuff and can we can we really make systems that
can answer sort of arbitrary questions about the world and for example sort of the the the the promise would be if
there's something that is systematically known in our civilization make it automatic to answer questions on the
basis of that systematic knowledge and back in the in around late 1970s early
1980s my conclusion was if you want to do something like that the only realistic path to being able to do it
was to build something much like a brain and so I got interested in neural nets and I tried to do things with neural
nets back in 1980 and nothing very interesting happened well I couldn't get him to do anything very interesting and
that um so I kind of had the idea that that the only way to get the kind of
thing that now exists in alpha for example was to build a brain like thing and then many years later for reasons I
can explain I kind of came back to this and realized actually it wasn't true that you had to build a brain like
things sort of mere computation was sufficient and that was kind of what got me started actually trying to build
Wolfram Alpha when we started building wolf malphur one of these I did was go to a sort of a field trip to a big
reference library and you know you see all these shelves of books and so on and the question is can we take all of this
knowledge that exists in all of these books and actually automate being able to answer questions on the base
Javad and I think we've pretty much done that for that at least the books you find in a typical reference library so
that was it looked kind of daunting at the beginning because it's this there's a lot of knowledge and information out
there but actually it turns out there are a few thousand domains and we've steadily gone through and worked on
these different domains another feature of the worth mouthful project was that we didn't really you know I've been
involved a lot in doing basic science and in trying to have sort of grand theories of the world one of my principles in building Wolfram Alpha was
not to start from a grand theory of the world that is not to kind of start from some global ontology of the world and
then try and build down into all these different domains but instead to work up from having you know hundreds then
thousands of domains that actually work whether they're you know information about cars or information about sports
or information about movies or whatever else how each of these domains sort of
building up from the bottom in each of these domains and then finding that there were common themes in these domains that we could then build into
frameworks and then sort of construct the whole system on the basis of that and that's kind of that's kind of how
its worked and I can talk about some of the actual frameworks that we end up using and so on but maybe I should
explain a little bit more so so one question is how does how does Wolf's
mouth actually sort of work inside and the answer is it's a big program it's
about it's the core system is about 15 million lines of Wolfram language code and it's some number of terabytes of raw
data and so the the way the thing that
sort of made building wolf now for possible was this language wolf and language which started with Mathematica
which came out in 1988 and has been sort of progressively growing since then so
maybe I should show you some things about both language and and you know it's easy you can you know use this mit
has a site license for it you can use it all over the places you can find it on the web but cetera etc etc but okay
the basics work the let's let's start off with something like let's make a
random graph and let's say we have a random graph with two hundred nodes
400 vertices okay so there's a random graph a first important thing about wolfing language is it's a symbolic
language so I can just pick up this graph and I could say you know I don't do some analysis of this graph that
graph is just a symbolic thing that I can just do computations on oh I could say let's let's get a another good thing
to always do is get a current image see there we go and now I could go and say
something like let's let's do some basic thing let's say let's edgy detect that
image again this this image is just a a thing that we can manipulate we could
take the image we could make it I don't know we could take the image and
partition it little pieces do computations on that I don't know simple let's do let's just say sort each row of
the image assemble the image again whoops assemble that image again we'll
get some some mixed up picture there if I wanted to I could for example let's say let's make that the current image
and let's say make that dynamic now I can be just running that code hopefully
and little loop and there we can make that work so the you know one one
general point here is there's you know this is just an image for us is just a
piece of data like anything else if we just have a variable a thing called X it just says okay that's X I don't need to
know particular value it's just a symbolic thing the corresponds to that's
a thing called X now you know what gets interesting when you have a symbolic
language and so on is we're interested in having it represent stuff about the world as well as just abstract kinds of
things that many you know I can abstractly say you know find some funky integral I don't know what you know
that's then representing using symbolic variables to represent algebraic kinds
of things but I could also just say I don't know something like Boston and Boston is another kind of symbolic thing
that has if I say what what is it really inside that's it's the
today a City Boston Massachusetts United States actually noticed when I type that
in I was using natural language to type it in and it gave me a bunch of disambiguation here it said assuming
Boston is a city assuming Boston Massachusetts use Boston New York or okay there's let's use let's use Boston
and the Philippines which I've never heard of but but um let's try using that instead and now if I look at that it'll
say it's Boston in some province of the Philippines etc etc now I might ask it
of that I could say something like what's the population of that and it um
okay it's a fairly small place or I could say for example let me let me do this let me say a geo list plot from
that Boston let's take from that Boston - and now
let's type in Boston again and now let's have it used the default meaning of the word of Boston and then let's join those
up and now this should plot this should show me a plot there we go okay so
there's the path from the Boston that we picked in the Philippines to the Boston
here oh we could ask you don't know I could just say I could ask it the distance from one to another or
something like that so the the one of the things here one things we found
really really useful actually in language was first of all there's a way of representing stuff about the world
like cities for example or let's say I want to say let's let's do this let's say let's do something with cities let's
say capital cities in South America okay so notice this is a piece of natural language this will get interpreted into
something which is precise symbolic wolfram language code that we can then
compute with and that will give us the citizens out the capital cities in South America I could for example let's say I
say find shortest to US and I'm going to use some some oops no I don't want to do
that what I want to do first is to say show me the geo positions of all those
cities on line 21 there so now it will find the geo positions and now it will say compute the shortest tour
so that's saying there's a 10,000 mile traveling salesman tour around those
cities so I could take those cities were on line 21 and I could say order the cities according to this and then I
could make another geo list plot of that join it up and this should now show us a
traveling salesman tour of the of the capital cities in South America um so
you know it's it's sort of interesting to see what's involved in making stuff like this work the one of you know my my
goal has been to sort of automate as much as possible about things that have
to be computed and that means knowing as many algorithms as possible and also
knowing as much data about the world as possible and I kind of view this as sort of a knowledge-based programming
approach where you have you know a typical kind of idea in programming languages is you know you have some
small programming languages has a few primitives that are pretty much tied into what a machine can intrinsically do
and then maybe you'll have libraries that add on to that and so on my kind of crazy idea of many many years
ago has been to build an integrated system where all of the stuff about
different domains of knowledge and so on are all just built into the system and and designed in a coherent way I mean
this has been kind of the story of my life for the last thirty years is trying to keep the design of the system coherent even as one adds all sorts of
different areas of of capability so as
some I mean we can go and dive into all sorts of different kinds of things here but maybe as an example well let's do
what could we do here we could take come let's try how about this is that a bone
I think so that's a bone so let's try that as a mesh region see if that works
so this will now use a completely different domain of human endeavor okay
oops there's two of those bones let's try let's just try them let's try
humorous let's try the that the mesh region for that and now we should have a
bone here okay there's a there's a representation of a bone let's take that bone and we could for example say let's
take the surface area of that as in some some units or I could let's do some much
more outrageous thing let's say we take region distance so we're going to take
the distance from some from that bone to a point let's say 0 0 Z and let's make a
plot of that distance with Z going from let's say I don't have no idea where the
where the spawn is but let's try something like this so that was really boring um let's try them so what this is
doing again a whole bunch of stuff has to work in order for this to operate this has to be this is a this is some
region in 3d space that's represented by some mesh you have to compute you know do the computational geometry to figure
out where it is if I want it to let's try anatomy anatomy plot 3d and let's
say something like left hand for example and now it's going to show us probably
the complete data that it has about the geometry of the left hand there we go ok
so there's there's the results and we could take that apart and start computing things from it and so on so
what um so this this is some so there's
a there's a lot of kind of computational knowledge that's built in here one let's
talk a little bit about kind of the modern machine learning story so for instance if I say let's get a picture
here let's say um let's let's just say picture of symbol got a favorite kind of
animal what's Panda okay so let's try ok
giant panda okay okay there's a panda let's see what now let's try saying um let's try for
this panda let's try saying image identify and now here we'll be embarrassed probably but let's just see
let's see what happens if I say image identify that and now it'll hopefully
wake up wake up wake up this only takes a few hundred milliseconds okay very good giant panda let's let's
see what it's we'll see what the runners-up were to the giant panda let's
say we want to say the ten runners-up in all categories for that thing okay so a
giant panda a prop here Ned which I've never heard of are pandas carniverous
ate bamboo shoots okay so that was so lucky I didn't get that one it's really
sure it's a mammal and it's absolutely certain it's a vertebrate okay so you
might ask how did it figure this out and so then you can kind of look under the hood and say so we have a whole
framework for representing neural nets symbolically and so this is the actual model that it's using to do this so this
is a so there's a neural net and it's got we can drill down and we can see there's there's a piece of the neuron
that we can drill down even further to one of these and we can probably see what that's a batch normalization layer
somewhere deep deep inside the entrails of the not panda but of this thing okay
so now let's take that object which is just a symbolic object and let's feed it the picture of the Panda and we can see
and there oops I was not giving it the
right thing what did I just do wrong here okay let's let's take our isolated okay let's take this thing and feed it
the picture of the Panda and it says a giant panda okay how about we do something more outrageous let's take
that neuron that and let's only use the first let's say 10 layers of the neuron that so let's just take out 10 layers of
the neuron that's and feed it the Panda and now what we'll get is something from the insides of the neuron that and I
could say for example let's just make those into images okay so that's what that's what the neuron that had figured out about the Panda after 10
layers of going through the neuron that and maybe actually be interesting to see let's do a feature space plots and now
we're going to of those intermediate things in the sort of in the brain of
the neuron that sort of speak this is now taking so what this is just doing is to do dimension reduction on this space
of images and so it's not very exciting it's probably mostly distinguishing these by total gray level but that's
kind of showing us the space of of different ton of different sort of features of the insides of the Shinra on
that so it's also what's interesting to see here is things like the symbolic representation of the neuron that's and
if you if you're wondering how does that hatch will work inside it's underneath it's using a max net which we happen to have contributed to a lot and there's
sort of a bunch of symbolic layers on top of that that feed into that and maybe I can show you here let me show
you how you would train one of these neural nets that's also kind of fun so we have a data repository that has all
sorts of useful data one piece of data it has is a bunch of neuron that training sets so this is a standard emne
straining set of handwritten digits okay so there's m missed and you notice
that these things here that's just an image which i could copy out and i could do you know let's say I could do color
negate on that image because it's just an image and there's there's the results and so on and now I could say let's take
let's take a neuron that like let's take a simple neuron that like Linette for example okay so let's take Linette and
then let's take the untrained initial evaluation Network so this is now a
version of Linette simple standard neural nets that didn't get trained so for example if I if I take that that
symbolic representation of Lynette and I could say net initialize then it will
take that and it'll just put random weights into Lynette okay so if I take those random weights and I feed it a
zero here I feed it that image of a zero it will presumably produce something completely random in this particular
case - right so now now what I would like to do is to take this so that was
just randomly initializing the weights so now what I'd like to do is to take the emne straining set and I'd like to
actually train Lynette using MMS training set so let's take let's take
this and let's take a random sample of let's say I don't know a thousand pieces
of Lynette come on why is it having to load it again there we go okay so
there's a there's a random sample there was on line 21 and now let me go down here and say where was it well look we
can just take this this thing here so this is the uninitialized version of
Lynette and we can say take that and then let's say net train of that with
the thing on line 21 which was that thousand instances so now what it's doing is its running training on and
that's you see the loss going down and so on it's running training for for
those thousand instances of Lynette and it will we can stop it if we want to
actually this is a new display this is very nice this is this is a new version of both languages is coming out next week which
I'm showing you but it's quite similar to what exists today but because that's
one of the features of running a software company is that you always run the the very latest version of things for better or worse and that's and this
is also a good way to debug it because supposed to come out next week if I find some horrifying bug maybe it will get
delayed but let's try them let's sum let's try this okay now it says it's
zero okay and so so this is now a trained version of Lynette trained with that with that
training data um one of the things so you know we can talk about all kinds of
details of your mats and so on but maybe I should zoom out to talk a little bit about bigger picture as I see it so one
question is sort of a question of what is in principle possible to do with
computation so you know we have as we're you know we're building all kinds of things we're making image identifies
we're figuring out those kinds of things about where the International Space Station is and so on question is what is
what is in principle possible to compute and so the you know
one of the places one can ask that question is when one looks at for example models of the natural world one
can say you know how do we make models of the natural world kind of a a traditional approach has been let's use
mathematical equations to make models of the natural world a question is if we want to kind of generalize that and say
well what are all possible ways to make models of things what can we say about that question so I spent many years of
my life trying to address that question and basically what what I've thought about a lot is that if you want to make
a model of a thing you have to have definite rules by which the thing operates what's the most general way to represent possible rules well in today's
world we think of that as a program so the next question is well what does the space of all possible programs look like
and most of the time you know we're writing programs like Wolfen language is 50 million lines of code and it's a big
complicated program that was for built for a fairly specific purpose but the question is if we just look at sort of
the space of possible programs more or less at random what's out there in the space of possible program so I got an
interest in many years ago in cellular automata which are a really good example of a very simple kind of program so let
me show you an example of one of these so this is these are the rules for a typical cellular automaton and this just
says you have a row of black and white squares and this just says you look at a black a look at a square say what color
is that square what color left or it's left and right neighbors decide what color the square will be on the next
step based on that rule okay so really simple rule so now let's let's take a look at what what actually happens if we
use that rule a bunch of times so we can take that rule the 254 is just the binary digits that correspond to those
positions in this rule so now I can say this I could say let's do 50 steps let
me do this sum and now if I run according to the rule I just defined it
turns out to be pretty trivial it's just saying if any if any square is if we
start off with a black square if any square is if any neighboring square is black make a black square so we've we've
used a very simple program we've got a very simple results out okay let's try a different program we can try
changing this we'll get some that's a program with one bit different now we
get that kind of pattern so the question is well what happens you might say okay
if you've got such a trivial program it's not surprising you're just going to get Trevor a results out so but you can
do an experiment to test that hypothesis you can just say let's take all possible programs there are 256 possible programs
that are based on these eight bits here let's just take well let's just whoops
let's just take come let's say the first 64 of those programs and let's just make
a echo let's just make a table of the
results that we get by running those first 64 programs here so here we get
the result and what you see is well most of them are pretty trivially the lake they start off with one black cell in
the middle and it just tools after one side occasionally we get something more exciting happening like here's a nice
nested pattern that we get if we were to continue it longer it would it would make you know more detailed nesting but
then my all-time favorite science discovery if you go on and just look at
these after a while you find this one here which is rule 30 in this in this
numbering scheme and that's doing something a bit more complicated you say well what's going on here you know we
just started off with this very simple rule let's see what happens maybe after a while you know if we run rule 30 long
enough it will resolve into something simpler so let's try running it let's say 500 steps and that's the whoops
that's the result we get I'd say let's
just make it fullscreen okay it's aliasing a bit on the projector
there but but you get the basic idea this is a so this just started off from one black cell at the top and this is
what it made and that's pretty weird because all this is you know this is sort of not the way it's supposed things
are supposed to work because what we have here is just that little program down there and it makes this big
complicated pattern here and you know we can see there's a certain amount of regularity on one side but for example
the center column this pattern is for all practical purposes completely random in fact it was reused as a random number generator
in Mathematica and Wolfram language for many years it was recently retired after after excellent service because we found
a somewhat more efficient one um the but the so you know what do we learn
from this what we learn from this is out in the computational universe of possible programs it's possible to get
even with very simple programs very rich complicated behavior well that's
important if you're interested in modeling the natural world because you might think that there are programs that
represent systems in nature that might work this way and so on it's also important for technology because it says
ok let's say you're trying to find a let's say you're trying to find a
program that's a good random number generator how are you going to do that well you could start thinking very hard and you could try makeup you know you
could try and write down all kinds of flowcharts about how this random number generator is going to work or you can
say forget that I'm just going to search the computational universe for possible programs and just look for one that
serves as a good random number generator in this particular case after you've searched 30 programs you'll find one
that makes a good random number generator why does it work that's a complicated story it's not a story that
I think necessarily we can really tell very well but what's important is that this is this idea that out in the
computational universe there's a lot of rich sophisticated stuff that can be
essentially mind for our technological purposes that's the important thing whether we understand how this works is
a different matter I mean it's like when we look at the natural world the physical world were used to kind of
mining things you know we started using magnets to do magnetic stuff long before we understand understood the theory of
ferromagnetism and so on and so similarly here we can sort of go out into the computational universe and find
stuff that's useful for our purposes now in fact the world of sort of deep
learning and neural nets and so on is a little bit like this it uses the trick that there's a certain degree of differentiability there so you can kind
of home in on let's try and find something that's incremental II better and for certain kinds of problems that
works pretty well I think the thing that we've done a lot I've done a lot it's just sort of exhaustive search in the computational
universe of possible programs just search of trillion programs and try and find one that does something interesting and useful for you um there's a lot of
things to say about what well actually in in these search of trillion programs and find one that's useful let me show
you another example of that um see so I was interested a while ago in the I have
to look something up here sorry um in C
in boolean algebra and in I was
interested in in the space of all possible mathematic says um and let me
just see here I I'm not finding what I
wanted to find sorry I was a good example I should have memorized this but
I haven't so um there we go there it is um so I was interested in if you just
look at so we talked about sort of looking at the space of all possible the
space of all possible programs another thing you can do is say if you're going to invent mathematics from nothing what
possible axiom systems could be used in mathematics so I was curious where do
and that again might seem like a completely crazy thing to do to just say let's just start enumerate axiom systems
at random and see if we find one that's interesting and useful but it turns out once you have this idea that out in the
computational universe or possible programs there's actually a lot of low-hanging fruit to be found it turns
out you can apply that in lots of places I mean the thing to understand is why why do we not see a lot of engineering
structures that look like this the reason is because our traditional model of engineering has been we engineer
things in a way where we where we can foresee what the outcome of our engineering steps are going to be and
when it comes to something like this we can find it out in the computational universe what we can't readily foresee
what's going to happen we can't do sort of a step by step design of this particular thing and so in
engineering and human engineering as it's been practiced so far most of it has consisted of building things where
we can foresee step by step what the outcome of our engineering going to be and we see that in programs we see that
in other kinds of engineering structures and so there's sort of a different kind of engineering which is about mining the
computational universe of possible programs and it's worth realizing there's a lot more that can be done a
lot more efficiently by mining the computational universe of possible programs than by just constructing
things step by step as a human so for example if you look for optimal algorithms for things like I don't know
even something like sorting networks the optimal sorting networks look very complicated they're not things that you
would construct by sort of step-by-step thinking about things with in a kind of
in a kind of typical human way and so this this idea you know if you're really
going to have computation work efficiently you are going to end up with these programs that are sort of just
mined from the computational universe and one of the issues with mining things so they're there this makes use of
computation much more efficiently than a typical thing that we might construct now one feature of this is it's hard to
understand what's going on and there's actually a fundamental reason for that which is in our efforts to sort of
understand what's going on we get to use our brains our computers our mathematics or whatever and our goal is this this
particular little program did a certain amount of computation to work out this pattern the question is can we kind of
outrun that computation and say oh I can tell that actually this particular bit down here is going to be a black black
bit you don't have to go and do all that computation but it turns out that then
again this will maybe as a digression which which there's this phenomenon I call computational irreducibility which
i think is really common and it's a consequence of this thing I call principle of computational equivalence and that the principle of computational
equivalence basically says as soon as you have a system whose behavior isn't fairly easy to analyze the chances are
that the computation it's doing is essentially as sophisticated as it could be and that has consequences like it
implies that the typical thing like this will correspond to a universal computer that you can use to program
anything it also has the consequence of this computational irreducibility phenomenon that says you can't expect
our brains to be able to outrun the computations that are going on inside the system if there was computational
reducibility then we can expect that this thing went to a lot of trouble and did a million steps of evolution but
actually just by using our brains we can jump ahead and see what the answer will be computational irreducibility suggests
that isn't the case if we're going to make the most efficient use of computational resources we will
inevitably run into computational irreducibility all over the place it has the consequence that we get the
situation where we can't readily sort of foresee and understand what's going to happen so back to mathematics for a
second so this is just an axiom system that so I looked for all possible look
through sort of all possible axiom systems starting off with very really tiny ones and I asked the question what's the first axiom system that
corresponds to boolean algebra so it turns out this this thing here this tiny little thing here generates all theorems
of boolean algebra it is that it is the simplest axiom for boolean algebra now something I have to show you this
because it's a new feature you see they um if I say find equation or proof let's
say I want to prove commutativity of the NAND operation I'm going to show you something here this is going to try to
generate let's see if this works this is going to try to generate an automated
proof based on that axiom system of that result so it had 102 steps in the proof
and let's try and say let's look at for example the proof network here actually
let's look at the proof data set um now that's not what I wanted I should learn
how to use this shouldn't I um let's see
what I want is the you know proof data set there we go very good ok so this is
actually let's let's say first of all let's say the proof graph ok so this is
going to show me the how that proof was done so they're a bunch of lemmas that got
proved and from those lemmas those lemmas were combined and eventually it proved the result so let's let's take a
look at the let's take a look at what some of those llamas were okay so here's
the results so after so it goes through and these are various lemmas it's using and eventually after many pages of
nonsense it will get to the result okay each one of these some of these llamas are kind of complicated there that's
that's that llama it's a pretty complicated lemma etc etcetera etcetera so you might ask what on earth is going
on here and the answer is so I first generated a version of this proof 20 years ago and I tried to understand what
was going on and I completely failed and it's sort of embarrassing because this is supposed to be a proof it's supposed
to be you know demonstrating some results and what we realize is that you know what does it mean to have a proof
of something what does it mean to explain how a thing is done you know what is the purpose of a proof purpose
of a proof is basically to let humans understand why something is true and so for example if you go to let's say we go
to wolf now fur and we do you know some random thing where we say let's do you
know an integral of something or another it will be able to very quickly in fact it will take it only milliseconds
internally to work out the answer to that integral okay but then somebody whose wants to hand in a piece of
homework or something like that needs to explain why is this true okay well we
have this handy step-by-step solution thing here which
explains why it's true now the thing I should admit about the step-by-step solution is it's completely fake that is
the steps that are described in the step by step solution have absolutely nothing to do with the way that internally that
integral was computed these are steps created purely for the purpose of telling a story to humans about why this
integral came out the way it did and now what we're seeing and so that's a so that's one thing is knowing the answer
the other thing is being able to tell a story about why the answer worked that way well what we see here is this is a proof
but it was an automatically generated proof and it's a really lousy story for us humans I mean if it turned out that
one of these theorems here was one that had been proved by Gauss or something and appeared in all the textbooks we
would be much happier because then we would start to have a kind of human representable story about what was going
on instead we just get a bunch of machine generated lemmas that we can't understand that we can't kind of wrap our brains around and it's sort of the
same thing that's going on in when we look at when these neural nets we're
seeing you know when we were looking wherever it was at the innards of that neuron that and we say well how is it
figuring out that that's a picture of a panda well the answer is it decided that you know if we humans were saying how
would you figure out if it's a picture of panda we might say well look and see if it has eyes that's a clue for whether
it's an animal look and see if it's looks like it's kind of round and furry and things that's a version of whether
it's a panda and Len cetera etcetera etcetera but what it's doing is it learnt a bunch of criteria for you know
is it a panda or is it one of 10,000 other possible things that it could have recognized and it learnt those criteria
in a way that was somehow optimal based on the training that it got and so on but it learnt things which were
distinctions which are different from the distinctions that we humans make in the language that we as humans use and
so in some sense you know when we start talking about will describe a picture we
have a certain human language for describing that picture we have you know in our human in typical human languages
we have maybe thirty to fifty thousand words that we use to describe things those words are words that have sort of
evolved as being useful for describing the world that we live in um when it comes to there's known that
it could be using it could say well that the words that it is effectively learnt
which allow it to make distinctions about what's going on in the in the analysis that it's doing it has
effectively invented words that describe distinctions but those words have nothing to do with our historically
invented words that exist in our languages so it's kind of an interesting situation that that it is its way of
thinking so to speak if you say well what's it thinking about how do we describe what it's thinking that's a tough thing to answer because just like
with the with the automated theorem we're we're sort of stuck having to say
well we can't really tell a human story because the things that it invented are things for which we don't even have
words in our languages and so on okay so one thing to realize is in this kind of
space of sort of all possible computations there's a lot of stuff out there that can be done there's this kind
of ocean of sophisticated computation and then the question that we have to
ask for us humans is okay how do we make use of all of that stuff so what we've
got kind of on the one hand is we've got the things we know how to think about human language is our way of describing
things our way of talking about stuff that's the one one set of things the other set of things we have is this very
powerful kind of seething ocean of computation on the other side where lots of things can happen so the question is
how do we make use of this sort of ocean of computation in the best possible way for our human purposes and building
technology and so on and so the the way I see you know my kind of part of what
I've spent a very long time doing is kind of building a language that allows us to take human thinking on the one
hand and describe and sort of provide a sort of computational communication
language that allows us to get the benefit of what's possible over in the sort of ocean of computation in a way
that's rooted in what we humans actually want to do and so I kind of view both
from language as being sort of an attempt to make a bridge between so you on the one hand there's all possible
computations on the other hand there's things we think we want to do and I view
or from language as being my best attempt right now to make a way to take
our sort of human computational thinking and be able to actually implement it so
in a sense it's a language which works in two on two sides it's both a language where you as a as a the machine can
understand okay it's it's looking at this and that's what it's going to compute but on the other hand it's also a language for us humans to think about
things in computational terms so you know if I go and I don't know one of these one of these things that I'm doing
here whatever it is that this wasn't that exciting but but you know fine shortest tour of the Geo position of the
capital cities in South America that is a language that's a representation in a precise language of something and the
idea is that that's a language which we humans can find useful in thinking about
things in computational terms it also happens to be a language that the machine can immediately understand and
execute and so I think this is sort of a general you know when I think about AI in general the you know what is the sort
of what's the overall problem well part of the overall problem is so how do we tell the AI is what to do so to speak
there's this very powerful you know this sort of ocean of computation is what we get to mine for purposes of building AI
kinds of things but then the question is how do we tell the AI is what to do and the what I see what I've tried to do
with Wolfram language is to provide a a way of kind of accessing that
computation and sort of making use of the knowledge that our civilization has
accumulated and because that's the you know there's the general computation on
on this side and there's the specific things that we humans have thought about and the question is to make use of the
things that we've thought about to do do things that we care about doing actually if you're interested in these kinds of
things I happen to just write a blog post where last couple of days ago it's
kind the funny blog posts it's about some but you can see the title there it came because a friend of miners has this
crazy project to put little little sort of discs or something that should
represent kind of the best achievements of human civilization so to speak to send out it's it's hitchhiking on
various spacecraft that are going out into the solar system in the next little
while and the question is what to put on this little disc that kind of represents you know the achievements of
civilization it's kind of it's kind of depressing when you go back and you look at what some what people have tried to
do on this before and realizing how hard it is to tell even whether something is an artifact or not but this is this was
sort of a yeah that's a good one that's from 11,000 years ago can you the question is can you figure out what on earth it is and what it means and and
this is but but so what what's relevant about this is the this this whole
question of there are things that are out there in the computational universe and you know when we think about
extraterrestrial intelligence I find it kind of interesting that artificial intelligence is our first example of an
alien intelligence we don't happen to have found what we view as extraterrestrial intelligence right now
but we are in the process of building pretty decent version of an alien intelligence here and the question is if
you ask questions like well you know what is it thinking is it does it have a
purpose and what it's doing and so on and you're confronted with things like this it's very we you can kind of do a
test run of you know what's what's its purpose what is it trying to do in a way
that is very similar to the kinds of questions you would ask about about extraterrestrial intelligence but in
case the the that the main point is that I see this sort of ocean of computation
there's the let's describe what we actually want to do with that ocean of computation and that's where you know
that's one of the primary problems we have now people talk about you know AI and what is AI going to allow us to automate and my basic answer that would
be we'll be able to automate everything that we can describe the problem is
it's not clear what we can describe or put another way you know you imagine various jobs and people are doing things
they're repeated judgment jobs things like this there where we can readily automate those things but the thing that
we can't really automate is saying well what are we trying to do that is what are our goals because in a sense when
when we see one of these systems you know let's say let's say it's a cellular tartan here okay the question is what is
this cellular automaton trying to do maybe I can maybe I'll give you another cellular automaton that is a little bit
more exciting here let's do this one so that the the question is what is this
cellular automaton trying to do you know it's got this whole big structure here and things are happening with it we can
go we can run it for a couple thousand steps we can ask it's a nice example of kind of undecidability in action what's
going to happen here this is kind of the halting problem is this going to halt what's it going to do there's computational irreducibility so
we actually can't tell this is the case where we know this is a universal computer in fact eventually well I don't
even spoil it for you if I went on long enough it would it would go into some kind of cycle but um we can ask what is
this thing trying to do what is it you know is it what's it thinking about what's its um you know what's its goal what's its
purpose and you know we get very quickly in a big mess thinking about those kinds of things I've one of the things that
comes out of this principle of computational equivalence is thinking about what kinds of things have are
capable of sophisticated computation so so I mentioned a while back here sort of
my personal history with Wolff malphur of having thought about doing something like wolf now for when I was a kid and then believing that you sort of had to
build a brain to make that possible and so on and one of the things that I then thought was that there was some kind of
bright line between what is intelligent and what is merely computational so to
speak in other words that there was something which is like oh we've got this great thing that we humans have that you know as intelligence and all
these things in nature and so on and all the stuff that's going on it's just computation or it's just you know things
operating according to rules that's different there's some bright line distinction doing these things well I think the
thing that came about after I'd looked at all these cellular automata and all kinds of other things like that
is I sort of came up with this principle of computational equivalence idea which
we've now got quite a lot of evidence for which I talked about people are interested in but that basically there
isn't a that once you reach a certain level of of computational sophistication
everything is equivalent and that means that that implies that there really isn't a bright line distinction between
for example the computations going on in our brains and the computations going on in these simple cellular automata and so
on and that essentially philosophical point is what actually got me to start trying to build both malphur because I
realized that gosh you know I've been looking for this sort of the the magic bullet of intelligence and I just
decided probably there isn't one and actually it's all just computation and so that means we can actually
impractical intelligent like thing and so that's
what I think is the case is that there really isn't sort of a bright line distinction and that has that has more
extreme consequences like people will say things like you know the weather has a mind of its own okay
sounds kind of silly sounds kind of animistic primitive and so on but in fact the you know fluid dynamics of the
weather is as computationally sophisticated as the stuff that goes on in our brains but we can start asking
but then you say but the weather doesn't have a purpose you know what's the purpose of the weather well you know maybe the weather is trying to equalize
the temperature between the you know the the North Pole and the tropics or something and then we have to say well
but that's not a purpose in the way that we think about purposes that's just you know and we get very confused and in the
end what we realize is when we're talking about things like purposes we have to have this kind of chain of
provenance that goes back to humans and human history and all that kind of thing and I think it's the same type of thing
when we talk about computation and AI and so on the thing that we this question of sort of purpose goals things
like this that's a thing which is intrinsically human and not something that we can ever sort of automatically
generate it makes no sense to talk about automatically generating it because these computational systems they do all kinds of stuff you know we can
say they've got a purpose we can attribute purposes to them etcetera etcetera etcetera but you know ultimately it's sort of the
human thread of purpose that we have to have to deal with so that means for example when we talk about AIS and we
were interested in things like so how do we tell you know like like we'd like to be able to tell we talk about AI ethics
for example we'd like to be able to make a statement to the AIS like you know please be nice to us humans um and
that's a you know that's something so one of the issues there is so talking
about that kind of thing one of the issues is how are we going to make a statement like be nice to us humans
what's the you know in how are we going to explain that to an AI and this is
where again you know my my efforts to build a language a computational
communication language that bridges the world of what we humans think about and
the world of what is possible in computation is important and so one of things I've been interested in is
actually building what I call a symbolic discourse language that can be a general representation for sort of the kinds of
things that we might want to put in that we might want to to say and things like
be nice to him and so sort of a little bit background to that so you know in the modern world people are keen on
smart contracts they often think of them as being deeply tied into blockchain which I don't think is really quite
right the important thing about smart contracts is it's a way of having sort
of an agreement between parties which can be executed automatically and that
agreement may be you know you may choose to sort of anchor that agreement in a
blockchain you may not but the whole point is you have to what you you know when people write legal contracts they
write them in an approximation to English they write them in legalese typically because they're trying to write them in something a little bit
more precise than regular English but the limiting case of that is to make a symbolic discourse language in which you
can write the contract and code basically and the the I've been very
interested in using wolfmann language to do that because in wolfen language we have a language which Candice bribe things about the world and we can
talk about the kinds of things that people actually talk about in contracts and so on and we're most of the way
there to being able to do that and then when you start thinking about that you
start thinking about okay so we've got this language to describe things that we that we care about in the world and so
when it comes to things like tell the AIS to be nice to the humans we can imagine using often language to sort of
build an AI Constitution that says this is how the AI supposed to work but when we talk about sort of just the the
untethered you know the untethered AI doesn't have any particular it's just going to do what it does and if we want
it to you know if we want to somehow align it with human purposes we have to have some way to sort of talk to the AI
and that's that's a you know I view my efforts to build or from language as as
a way to do that I mean I you know as I was showing at the beginning you can use you can take natural language and with
natural language you can build up a certain amount of you can say a certain number of things in natural language you
can then say well how do we make this more precise in a precise symbolic language if you want to build up more
complicated things it gets hard to do that in natural language and so you have to kind of build up more serious
programs in in in symbolic language and I've probably been numb been yakking a
while here and I'm happy to I can talk about all kinds of different things here but that
maybe I've not seen as many reactions as I might have expected to think so I I'm not sure which things people are
interested in which they're not but so maybe I should maybe I should stop here and we can have discussion questions
comments yes [Applause] if two microphones if you have questions
please come out so I have a quick question it's goes to the earlier part of your talk where you say you don't
build a top-down ontology you actually build from the bottom up but disparate domains what do you feel are the core
technologies of the knowledge representation which you use within Wolfram Alpha that allows you you know
different domains to reason about each other to come up with solutions and is there any feeling of differentiability
for examples if you were to come up with a plan to do something new within
Wolfram Alpha language you know how would you go about doing that me okay so
we've done maybe a couple of thousand domains okay the what is actually
involved in doing one of these domains it's it's a gnarly business every domain
has some crazy different thing about it I tried to make up actually a while ago we um let me show you something a kind
of a hierarchy of what it means to make um see if I can find this here kind of a
hierarchy of what it means to make a domain computable where is it that's
okay here we go so there's sort of a hierarchy of levels of what it means to make a domain computable from just you
know you've got some you know you've got some array of data that's quite structured forget you know the separate
issue about extracting things from unstructured data but let's imagine that you were given you know a a bunch of
data about landing sites of meteorites or something okay so you go through
various levels so you know things like okay the landing sites the meteorites are the are the positions just strings
or they some kind of canonical representation of geo position is the you know is the type of meteorite you
know some of them are iron meteorites some of them are stone meteorites have you made a canonical representation have
you made some kind of way to to identify what some sorry go ahead no no I mean to
do that so my question is like you know if you did have positions as a string as well as a canonical representation do
you have redundant pieces of the same redundant representations of the same information in the different no I mean I'll go you
always everything canonical that you have yeah I have a minimal representation of everything yeah our goal is to make everything canonical now
that's you know there is a lot of complexity in doing that I mean if you you know in each okay so another feature
of these domains okay so there's another another thing to say um you know it will be lovely if one
could just automate everything and cut the humans out of the loop turns out this doesn't work and in fact
whenever we do these domains it's fairly critical to have expert humans who really understand the domain or you
simply get it wrong and it's also having said that once you've done enough domains you can do a lot of cross
checking between domains and we are the number one reporters of error and of
errors and in pretty much all standardized data sources because we can do that kind of cross checking but I
think you know if you ask the question what's involved in in bringing online a
new domain it's you know those sort of hierarchy of things you know some of
those take a few hours you can get to the point of of having you know we've got good enough tools for ingesting data
figuring out oh those are names of cities in that column let's you know that's canonicalized those you know some
may be questions but many of them will be able to to nail down and to get to the full level of you've got some
complicated domain and it's fully computable is probably a year of work and and you might say well gosh why are
you wasting you their time you've got to be able to automate that so you can probably tell we're fairly sophisticated about machine learning kinds of things
and so on and we have tried you know to automate as much as we can and we have
got a pretty efficient pipeline but if you actually want to get it right and you see it is an example of what what
happens that there's a level even going between wolf now for more from language there's a level of so for example let's
say you're looking at you know lakes in Wisconsin okay so people are querying
about lakes in Wisconsin and WolframAlpha they'll name a particular lake and they want to know you know how
big is the lake okay fine in Wolfram language they'll be doing a systematic computation about
lakes in Wisconsin so if there's a lake missing you're gonna get the wrong answer and so that's a kind of higher
level of difficulty okay but the this yeah I think you're asking some more
technical questions about ontologies and I can try and answer those actually one quick question and you know that's
there's a lot of other questions yes that's right okay all right very much my cyclist as to the left here I got a
simple question who or what are your key influences oh gosh in terms of language
design for from language are in the context of machine intelligence if you like if you want to make it tighter to this audience I don't know I've been
absorbing stuff forever I think my main in terms of language design probably
list span APL were my sort of early influences but in terms of thinking
about AI hmm you know in I mean I'm kind
of quite knowledgeable I like history of science so I'm pretty knowledgeable about the the early history of kind of
mathematical logic symbolic kinds of things I would say okay maybe I can answer that in the negative okay I have
for example in building Wolfram Alpha I thought gosh let me do my homework let
me learn all about computational linguistics let me hire some computational linguistics PhDs that will be a good way to get this started
turns out we used almost nothing from the from the previous sort of history of
computational linguistics partly because what we were trying to do namely short question natural language understanding
is different from a lot of the national language processing which has been was done in the past I also have made to my
disappointment very little use of you know people like Marvin Minsky for
example I really don't think I mean I knew Marvin for years and in fact some of his early work on simple Turing
machines and things those are probably more influential to me than his work on on AI and you know probably
I my mistake of not understanding that better but really I would say that I'd been been rather uninfluenced by by sort
of the traditional AI kinds of things I mean it probably hasn't helped that I've kind of lived through a time when when
sort of AI went from you know when I was a kid a I was gonna solve everything in the world and then you know it kind of
decayed for a while and then sort of come back so I so I would say that I can describe my negative my non influences
better than my impression you gave is that you made your own head and it sounds as though that's pretty much right yeah I mean yes I I mean insofar
as those things to me I mean look things like the you know okay so for example
studying simple programs as and trying to understand the universe of simple programs actually the personal history
of that sort of interesting I mean I you know I used to do particle physics when
I was a kid basically and then I actually got interested okay so I'll
totally the history of that just as an example of how sort of interesting is a sort of history of ideas type thing so I
was interested in in how order arises in the universe so you know you start off from the hot Big Bang and then pretty
soon you end up with a bunch of humans and galaxies and things like this how does this happen so I got on just in
that question I was also interested in in things like knowing that works for
sort of AI purposes and I thought let me make a minimal model that encompasses
sort of how complex things arise from from other stuff and I ended up sort of
making simpler and simpler and simpler models and eventually wound up with cellular automata and which I didn't know were called cellular automata when
I started looking at them and then found they didn't interesting things and the two areas were cellular automata had
been singularly unuseful in analyzing things our large-scale structure in the
universe and neural networks so turned out but but that by the way the fact
that I kind of even imagined that one could just start yeah I should say you know I've been doing physics and in
physics the kind of intellectual concept is you take the world as it is and you try and drill down and find out what you
know what makes the world out of primitives and so on it's you know reduce to find things then I
built my first computer language a thing called SMP which went the other way around where I was just like I'm just
gonna make up this computer language and you know just make up what I want the primitives to be and I'm gonna build
stuff up from it I think that the fact that I kind of had the idea of doing things like making up cellular automata
as possible models for the world was a consequence of the fact that I worked on this computer language which was a thing
which worked the opposite way around from the way that one is used to doing natural science which is sort of this reductionist approach and that's I mean
so that's just an example of it you know I found I happen to have spent a bunch
of time studying as I say history of science and one of my one of my hobbies is sort of history of ideas I even wrote
this little book called idea makers which is about biographies of a bunch of people who for one reason or another I've written about and so I'm I'm always
curious about this thing about how do people actually wind up figuring out the things they figure out and you know one
of the one of the conclusions of my you know investigations of many people is there are very rarely moments of
inspiration usually it's long multi-decade kinds of things which only
later get compressed into something short and also the path is often much
you know it's it's it's quite what can I
say that the steps are quite small and you know but the path is often kind of complicated and that's what that's what
it's been for me so I simple question complex answer sorry so when I basically
see from the Wolfram languages it's a way to describe all of objective reality it's kind of formalizing just about the
entire domain of discourse use a philosophical term and you kind of hinted at this in your lecture where
that where it sort of leaves office is that when we start to talk about more esoteric philosophical concepts purpose
I guess this would lean into things like epistemology because essentially you only have science there and as amazing
as Sciences there are other things that are talked about not you know you know like idealism versus materialism etc do
you have an idea of how Wolfram might or might not be able to branch into those
discourses because I'm hearing echoes in my head at that time boström said that nai needs a you know
when you give an AI a purpose there's like I think he said philosophers are divided completely evenly between the
top four ways to measure how good something should be it's like utilitarianism and sure brother for most Japanese yeah so the first thing is I
mean this problem of making what okay about 300 years ago people like light
knits we're interested in the same problem that I'm interested in which is how do you formalize sort of everyday discourse and Leibniz had the original
idea you know he was originally trained as a lawyer and he had this idea if he could only reduce all law all legal
questions to matters of logic he could have a machine that would basically describe every you know answer every
legal case right he was unfortunately a few hundred years too early even though
he did have you know he tried to he tried to do all kinds of things very similar things I've tried to do like he tried to get various Dukes to assemble
big libraries of data and stuff like this but but the point so what he tried
to do was to make a formalized representation of everyday discourse for
whatever reason for the last 300 years basically people haven't tried to do that there's it's a almost completely
barren landscape there was this period of time in the 1600s when people talked
about philosophical languages Leibniz was why and a guy called John Wilkins was another and they tried to you know
break down human thought into something symbolic people haven't done that for a long time in terms of what can we do
that with you know I've been trying to figure out what the best way to do it is
I think it's actually not as hard as one might think these areas one thing you have to understand these areas like
philosophy and so on are they're on the harder end I mean things like a good example typical example you know I want
to have a piece of chocolate okay they in morphing language right now we have a pretty good description of pieces of
chocolate we know all sorts of you know we probably know 100 different kinds of chocolate we know how big the pieces are
all that kind of thing the I want part of that sentence we can't do that right now but I don't think that's that hard
and I'm you know that's now if you ask let's say we had I think the different
thing you're saying is let's say we had the omnipotent AI so to speak that was able to you know where we turn over the
control of the central bank to the AI we turn over all these other things to the AI then the question is we say to the AI
now do the right thing and then the problem with that is and this is why I
talk about you know creating AI constitutions and so on we have absolutely no idea what do the right
thing is supposed to mean and philosophers have been arguing about that you know utilitarianism is an example of that of one of the answers to
that although it's not a complete answer by any means it's not not really an answer it's just a way of posing the question and so I think that the you
know one of one of the features of so I think it's a really hard problem to you
know you think to yourself what should the AI Constitution actually say so first thing you might think is oh
there's going to be you know something like Asimov's laws of robotics there's going to be one you know golden rule for
a eyes and if we just follow that golden rule all well okay I think that that is
absolutely impossible and in fact I think you can even sort of mathematically prove that that's impossible because I think as soon as
you have a system that you know essentially what you're trying to do is you're trying to put in constraints that
okay basically as soon as you have a system that shows computational irreducibility I think it is inevitable
that you have ace of have unintended consequences of things which means that
you never get to just say put everything in this one very nice box you always
have to say let's put in a patch here let's put in a patch there and so on a version of this much more abstract version of this of girdles theorem so
girdles theorem is you know it starts up by taking the you know it's girls
theorem is trying to talk about integers it says start off with piano's axioms
turner's axioms you might say in piano thought describe the integers and nothing but the integers okay so
anything that's provable from pianos axioms will be true about integers and vice-versa okay
what girls theorem shows is that you can that will never work that there are an infinite hierarchy of patches that you have to
put on two pianos axioms if you want to describe the integers and nothing about the integers and I think the same is
true if you want to have a legal system effectively that has no bizarre unintended consequences so I don't think
it's possible to just say you know if you when you're describing something in the world that's complicated like I
don't think it's possible to just have a small set of rules that will always do
what we want so to speak I think it's inevitable that you have to have a long essentially code of laws and that's what
you know so my guess is that what will actually have to happen is you know as we try and describe what you want the
eyes to do you know I don't know the socio-political aspects of how we'll figure out whether it's 1 AI
Constitution or 1 per you know city or whatever we can talk about that that's a
separate issue but but um you know I think what will happen is it'll be much like human laws it'll be a complicated
thing that gets progressively patched and so I think it's it's some and these ideas like you know oh we'll just make
the eyes you know run the world according to you know Mills you know
John Stuart Mill's idea it's not gonna work which is not surprising this
philosophy has has has made the point that it's not as easy it's not an easy problem for the last two thousand years and they're right it's not an easy
problem thank you yeah I you're talking about computational irreducibility and
computational equivalents and also that earlier on in your intellectual adventures you're interested in particle
physics and things like that I've heard you make the comment before in other
contexts that things like molecules compute and I was just ask you exactly
you you know what you mean by that in what sense does a molecule I mean what
would you like to compute so to speak I mean in other words you what what is the case is that you know one definition of
you're computing is given a particular computation like I don't know finding square roots or something you know you
can program a you know the surprising thing is that an awful lot of stuff can be programmed to do any
computation you want that's some and you know when it comes to I mean I think for
example when you look at nanotechnology and so on the the current you know one
of the current beliefs says to make very small computers you should take what we
know about making big computers and just you know make them smaller so to speak I
don't think that's the approach you have to use I think you can take the components that exist at the level of
molecules and say how do we assemble those components to be able to do
complicated computations I mean it's like the cellular automata that the you know the underlying rule for the
cellular automaton is very simple yet when that rule is applied many times it can do a sophisticated computation so I
think that that's the that's the sense in which what can I say the raw material
that you need for computation can be you know there's a great diversity in the raw material that you can use for
computation our particular human development you know stack of of
technologies that we use for computation right now is just one particular path and we can you know so a very practical
example of this is algorithmic drugs so the question is right now drugs pretty much work by most drugs work well you
know there is a binding site and a molecule drug fits into binding site does something question is can you
imagine having something where the molecule you know is something which has computations going on in it where it
goes around and it looks at that you know that thing it's supposed to be binding to and it figures out oh there's
this knob here and that knob there it reconfigures itself it's computing something it's trying to figure out you
know is this likely to be a tumor cell or whatever based on some more complicated thing that's the type of
thing that I mean by by computations happening at an R color scale okay I guess I meant to ask if it follows from
that if in your view like the the molecules in the chalkboard and in my
face and in the table are in any sense currently during doing computer I mean the question of what computation look
one of the things to realize if you look at kind of the sort of past and future of things the the
okay so here's an observation actually I was about light nets actually and lightning says time live Nets made a
calculator type computer out of brass took him 30 years okay so in his day
there was you know at most one computer in the world as far as he was concerned right today's world there may be 10
billion computers maybe 20 billion computers I don't know the question is what's that going to look like in the future and I think the answer is that in
time probably everything we have will be made of computers in the following sense
that basically it won't be you know in today's world things are made of you know metal plastic whatever else but
actually that won't make it there won't be any point in doing that once we know how to do you know molecular scale
manufacturing and so on we might as well just make everything out of programmable stuff and I think that's a that's a
sense in which you know the the and you know the one example we have molecular computing right now is us bio in biology
you know biology does a reasonable job of specific kinds of molecular computing it's kind of embarrassing I think that
the only you know molecule we know that sort of a memory molecule is DNA that's kind of you know which is kind of the
you know the particular biological solution in time we'll know lots of others and you know I think the the sort
of the the end point is so if you're asking is you know is computation going
on in you know in this water bottle the answer is absolutely it's probably even many aspects of that computation are
pretty sophisticated if we wanted to know what would happen to particular molecules here it's going to be hard to tell there's going to be computational
irreducibility and so on can we make use of that for our human purposes can we piggyback on that to achieve something
technological that's different issue and that's the four that we have to build up this whole sort of chain of technology
to be able to connect it which is what I've kind of been been keep on talking about is how do we connect sort of what
is possible computationally in the universe to what we humans can kind of conceptualize that we want to do in
computation and that's you know that's the bridge that we have to make and that's the hard part but getting the intrinsic getting the computation done
is is you know there's computation going on all over the place there may be a
couple more questions I was hoping you could elaborate on what you're talking about earlier of like
searching the entire space of possible programs so that's very broad so maybe
like what kind of searching of that space we're good at and like what we're not and I guess what the outright so I
mean I would say that we're at an early stage in knowing how to do that okay so I've done lots of these things and they
are the thing that I've noticed is if you do an exhaustive search then you
don't miss even things that you weren't looking for if you do a non exhaustive search there is a tremendous tendency to
miss things that you weren't looking for and so you know we've done such as a
bunch of the function evaluation and Wolfram language is done by was done by searching for optimal approximations in
some big space a bunch of stuff with hashing is done that way bunch of image processing is done that way what we're
just sort of searching this you know doing exhaustive searches and maybe trillions of programs to find things now
you know there is on the other side of that story is the incremental improvements story with with deep
learning and neural networks and so on where because there is differentiable 'ti you're able to sort of incrementally
get to a better solution now in fact people are making less and less differentiability and deep learning
neural nets and so I think eventually there's going to be sort of a grand unification of these kinds of approaches
right now we're still you know I don't really know what the you know the
exhaustive search side of things which you can use for all sorts of purposes I mean there's the reason the surprising
thing that makes you is also search not crazy is that there is rich sophisticated stuff near at hand in the
computational universe if you had to go you know quadrillions you know through a quadrillion cases before you ever found
anything the exhaustive search will be hopeless but you don't in many cases and
you know I would say that we are in a fairly primitive stage of the science of how to do those searches well my guess
is that there'll be some sort of unification which needless to say I've thought a bunch of out and between kind of than known that
so you know the trade-off typically in Iran that says you can have an Iran that that is very good at that is you know
uses its computational resources well but it's really hard to train or you can have an Iran that that doesn't use its
computational resources so well but it's very easy to train but this is very you know smoothly and you know my guess is
that somewhere in the you know harder to train but makes use of things that are
closer to the complete computational universe is is where one's going to see progress but it's it's a it's a really
interesting area and you know I consider us only at the at the beginning of
figuring that out thank you for your
talk I just to give you a bit of context for my question I research how we could teach AI to kids and evolving platforms
for that how we could teach artificial intelligence and machine learning to children and I know you develop resources for that as well so I was
wondering like where do you think it's problematic that we have computation that is very efficient and can do you
know from utilitarian and problem solving perspective it's all the goals but we don't understand how we how it
works so we have to create the this fake steps and if you could think of scenarios where that could become very
problematic over time and why do we approach it such in such a deterministic way and when you mentioned that
computation and intelligence are dafair differentiated by this like very thin line how does that affect the way you
learn and how do you think that will affect the way we kids learn we learn right so I mean look my general
principle about you know future generations and what they should learn I mean first point is you know very
obvious point that you know for every field that people study you know
archeology to zoology there either is now a computational X or there will be
soon so you know every field the paradigm of computation is becoming important
perhaps the dominant paradigm in that field okay so how do you teach kids to be useful in a world where everything is
computational I think the the number one thing is to
each them how to think in computational terms what does that mean that doesn't mean writing code necessarily I mean in
other words one of the things that's happening right now as a practical matter is you know they've been these waves of enthusiasm for teaching coding
of various kinds you know we're in a we're not actually we're in the end of an uptick wave I think it's going down
again um you know it's been up and down for 40 years or so um okay why doesn't
that work well it doesn't work because while there are people like people who are students at MIT for example for whom
they really want to learn you know engineering style coding and it really makes sense to them to learn that the
vast majority of people it's just not going to be relevant because they're not going to write a low-level C program or
something and it's the same thing that's happened in math education which has been sort of a disaster there which is
the number one takeaway for most people from the math they learn in school is I don't like math and you know that's not
for all of them obviously but that's the you know if you asked no general scale you know what people and why is that
well part of the reason is because what's been taught is rather low level of mechanical it's not about
mathematical thinking particularly it's mostly about you know what teachers can teach and what assessment processes can
assess and so on okay so how should one teach computational thinking I mean I'm I'm kind of excited about what we can do
with whorfin language because I think we have a high enough level language that people can actually write you know that
for example I I reckon by age 11 or 12 and I've done many experiments on this I
have some the only problem with my experiments is most of my experiments end up being with kids who are high
achieving kids despite many efforts to reach lower achieving kids that always ends up that the kids who actually do
the things that I set up or the high achieving kids but but you know like setting that aside you know you take the typical you know
11 12 13 year-olds and so on and they can learn how to write stuff in this
language and what's interesting is they learn to start thinking here I'll show you let's be very practical I can show
you I was doing every Sunday I do a little little thing with some middle school kids and I might even be able to find my
stuff from yesterday this is this is um okay let's see programming adventures Janerio 28 okay
let's see what I did oh look at that that was that was why I thought of the South America thing here because I just done that with these kids
the and so what are we doing we were
trying to figure out this this some trying to figure out the shortest tour
thing like that I just showed you which is this is where I got what you is is what I was doing with these kids but
this this was my version of this but the kids all had various different versions of this and we had somebody suggested
you know let's just enumerate let's just look at all possible permutations of
these these cities and figure out what their distances are there's the histogram of those that's what we get
from those okay how do you get the largest distance from those etcetera etcetera and this is okay this was my
version of it but the kids had similar stuff and this is you know this is I think and it probably went off into oh
yeah there we go there's there's the one for the whole whole earth and then they wanted to know how do you do that in 3d
so I was showing them how to convert to XYZ coordinates in 3d and make the
corresponding thing in 3d so what's this maybe isn't the this is a random example
from yesterday so it's not not a highly considered example but but um what I
think is interesting is that we seem to have finally reached the point where we've automated enough of the actual
doing of the computation that the kids can be exposed mostly to thinking about
what you might want to compute and you know part of our role in language design as far as I'm concerned is to get it as
much as possible to the point where for example you can do a bunch of natural language input you can do things which
make it as easy as possible for kids to not get mixed up in the kind of what the
you know how the computation gets done but rather to just think about how you formulate the computation so for example
a typical example I've used much times in you know what does it mean to do write code versus two other
things like a typical set of test example would be I don't know you ask somebody you're gonna there's practical
problem we had in wolf's mouth you give a lat long position on the earth and you say you're gonna make a map of that like
long position what what scale of map should you make alright so if the lat/long is in the middle of the Pacific
making a ten mile you know radius map isn't very interesting if it's in the middle of
Manhattan a 10-mile radius map might be quite quite a sensible thing to do so the question is come up with an
algorithm come up with even a way of thinking about that question what do you do you know how should you figure that
out well you might say you know oh let's look at the visual complexity of the image let's look at how far it is to
another city let's fight you know there various different things but thinking about that as a kind of computational
thinking exercise that term is you know
that's the kind of thing so in terms of what one automates and whether people whether people need to understand how it
works inside okay main point is you'll
in the end it will not be possible to know how it works inside so you might as
well stop having that be a criterion I mean that is there plenty of things that one teaches people that let's say in
lots of areas of biology medicine whatever else you know maybe we'll know how it works inside one day but you can
still there's an awful lot of useful stuff you can teach without knowing how it works inside and I think also as we
get computation to be more efficient inevitably we will be dealing with things where you don't know how it works inside now you know we've seen this in
math education because I've happened to made tools that automate a bunch of things that people do in math education
and I think well to tell a silly story I'm in my my older daughter who at some
point in the past was doing you know calculus you know and learning doing integrals and things and I was saying to
her you know I didn't think humans still did that stuff anymore which was a very
unintelligent fit but in any case I mean the the you know there's a question of
whether do humans need to know how to do that stuff or not so I haven't done an integral by hand and probably thirty
five years a true more or less true then but when I
was using computers to do them the I was for a while you know I used to do
physics and so I used computers to do this stuff I was a really really good integrator except that it wasn't really
me it was me plus the computer so how did that come to be well the answer was that because I was
doing things by computer I was able to try zillions of examples and I got a much better intuition the most people
got for how these things would work roughly how what you did to make the thing go and so on whereas people who
are like I'm just working this one thing out by hand you got a different you know you don't get that intuition so I think you know
two points first of all you know this how do you think about things computationally how do you formulate the
question computationally that's really important and something that we are now in a position I think to actually teach
and it is not really something you teach by you know teaching you know traditional quotes coding because a lot
of that is okay we're gonna make a loop we're going to define variables I just as I think I probably have a copy here
yeah they I wrote this book for this is a book kind of for kids about often language except it seems to be useful to
adults as well but I wrote it for kids so it's some and one of the amusing things in this book is it doesn't
talking it talked about assigning values to variables until chapter 38 so in
other words that will be a thing that you would find in Chapter one of most you know low-level programming coding
type type things turns out it's not that relevant to know how to do that it's also kind of confusing and not necessary
and so you know in terms of the you asked where will we get in trouble when people don't know how the stuff works
inside that's I mean you know I think one just has to get used to that because
it's like you know you might say well we live in the world and it's full of natural processes where we don't know
how they work inside but somehow we manage to survive and we go to a lot of effort to do natural science to try and
figure out how stuff works inside but it turns out we can still use plenty of things even when we don't know how they
work inside we don't need to know and I think the May I think the main
point is computational irreducibility guarantees that we will be using things where we don't know and can't know how
they work inside and you know I think the the perhaps the thing that is a
little bit you know to me a little bit unfortunate as a you know as a typical
human type thing the fact that I can readily see that you know the AI stuff
we build is sort of effectively creating languages and things that are completely
outside our domain to understand and we're by that I mean you know our human
language with its fifty thousand words or whatever has been developed over the last however many you know tens of thousands of years and as a society
we've developed this way of communicating and explaining things you know the AIS are reproducing that
process very quickly but they're coming up with a and a historical you know
something you know their way of describing the world that doesn't happen to relate at all to our historical way of doing it and that's you know it's a
little bit disquieting to me as a human that that you know there are things going on inside where I know it is you
know in principle I could learn that language but it's you know not the
historical one that we've all learnt and it really wouldn't make a lot of sense to do that because you learn it for one AI and then another one gets trained and
it's going to use something different so it's some but my main I guess my main point for for education another point
about education I just make which is something I haven't figured out but but um just is you know when do we get to
make a good model for the human learner using machine learning so in other words you know part of what we're trying to do
like like I've got that automated proof I would really like to manage to figure out a way what is the best way to
present that proof so a human can understand it and basically for that we
have to have a bunch of heuristics about how humans understand things so as an example if we're doing let's say a lot
of visualization stuff in welcomed language okay we have tried to automate do automated aesthetics so what we're
doing is you know we're laying out a graph what way of laying out that graph is most likely for humans to understand
and we've done that you know by building a bunch of heuristics and so on but that's an example of you know if we
could do that for learning and we say what's the optimal path given that the person is trying to understand this
proof for example what's the optimal path to lead them through understanding that proof I suspect we will learn a lot
more in probably a fairly small number of years about that and it will be the case that you know for example if you've
got oh I don't know you can do simple things like you know you go to Wikipedia and you look at what the path of you
know how do you if you want to learn this concept what other concepts you have to learn we have much more detailed symbolic information about what is
actually necessary to know in order to understand this and so on it is I think reasonably likely that we will be able
to I mean you know if I look at I was interested recently in the history of math education so I wanted to look at
the complete sort of path of math textbooks you know for the past well
basically the like twelve hundred you know people actually produced this one
of the early math textbooks so they've been these different ways of teaching math and you know I think we've we've
gradually evolved a fairly optimized way for the typical person though it's probably the variation of the population
is not well understood for you know how to explain certain concepts and we've gone through some pretty weird ways of
doing it from the 1600s and so on where which have gone out of style and possibly you know who knows whether
that's versus because of well but anyway so so you know we've kind of learnt this path of what's the optimal way to
explain adding fractions or something for humans for the typical human but I think we'll learn a lot more about how
you know by by essentially making a model for the human a machine model for the human we'll learn more about how to
you know how to optimize how to explain stuff to humans a coming attraction but
Tim thanks by the way do you think we're close to that at all because you you said that there's a something in Wolfram
Alpha that that presents the human a nice way are we how far said attraction
yeah right so I mean in in that explaining stuff to humans thing is a
lot of human work right now being able to automate explaining stuff to humans okay so some
of these things let's see I mean so an interesting question actually just today
I was working on something that's related to this yeah it's it's it's being able to the question is given a
whole bunch of can we for example train a machine learning system from explanations that it can see roughly can
we train it to give explanations that are likely to be understandable maybe I think the okay so an example that I'd
like to do okay I'd like to do a debugging assistant where the typical thing is program runs program gives
wrong answer human says why did you get the wrong why did it give the wrong answer well the first piece of
information to the computer is that was the human thought that was the wrong answer because the computer just did
what it was told and it didn't know that was supposed to be the wrong answer so then the question is can you in fact you
know in that domain can you actually have a reasonable conversation in which the human is explaining the computer
what they thought it was supposed to do the computer is explaining what happened and why did it happen and so on same
kind of thing for math tutoring you know we have a lot of you know we've got a lot of stuff you know we're sort of very
widely used for people who want to understand the steps in math you know can we make a thing where people tell us
I think it's this okay I'll tell you one one little factoid which I which you did work out so if you do multi digit
arithmetic multi-digit addition okay okay so the basis of this is its kind of
silly silly thing but you know if you get the right answer for an addition some okay you don't get very much
information the student gives the wrong answer the question is can you tell them where they went wrong so let's say you
have a four digit addition sum and the student gives the wrong answer can you back trace and figure out what they
likely did wrong and the answer is you can you know you just make this graph of all the different things that can happen
you know when did they you know there's certain things that are more common transposing numbers and things or you
know having a 1 and a 7 mixed up those kinds of things you can with very high power let's say given a for de division
some with the wrong answer you can say this is the mistake you made which is sort of interesting and that's
you know being done in a fairly symbolic way whether one can do that in a you
know more machine learning kind of way for more complicated derivations I'm not sure but that's a that's one that works
are you sir I just had a follow-up question so do you think you know like
in the future this is it possible to simulate virtual environments which can
actually understand how the human mind works and then build you know like
finite state machines inside of this virtual environment to provide a better
learning experience and a more personalized learning experience well I mean so the question is if if you're
going to you know can you optimize if you're playing a video game or something and that video game is supposed to be
educational can you optimize the the experience based on a model of you so to
speak yeah I'm sure the answer is yes and I'm sure the you know the question of how complicated the model of you will
be is an interesting question I don't know the answer to I mean I've I've kind of wanted a similar question so I I'm a
kind of personal analytics enthusiast so I collect tons of data about myself and I mean I do it mostly because it's been
super easy to do and I've done it for like 30 years and I have you know every keystroke I've typed on a computer like
every keystroke I've typed here and I the screen of my computer every every 30 seconds or so of maybe 15 seconds I'm
not sure it there's a screen shot it's a super boring movie to watch but anyway I've been collecting all this stuff and
so a question that I've asked is is there enough data that a bot of me could
be made in other words do I have enough data about you know I've got I've
written a million emails I have all of those I've received three million emails
over that period of time I've got you know endless you know things I've typed
etc etcetera etcetera you know is there enough data to reconstruct you know me
basically I think the answer is probably yes not sure but I think the answer is
probably yes and so the question is in an environment where you are interacting with some video game trying to learn
something whatever else you know how long is it going to be before it can learn enough about you to change that
environment in a way that's useful for explaining the next thing to you I would guess I would guess that have done that
this is comparatively easy I might be wrong but that and that the I mean I
think you know it's an interesting thing because you know once dealing with you know there's a space of human personalities there's a space of human
learning styles you know I'm sort of always interested in the space of all possible XYZ and there's you know
there's that question over how do you parameterize the space of all possible human learning styles and is there a way
that we will learn you know like can we do that symbolically and say these are
ten learning styles or is it something I think that's a case where it's better to use you know sort of soft machine
learning type methods to kind of feel out that space well you know maybe very
last question I was just intuitively thinking when you spoke about an ocean I
thought of Isaac Newton when he said I mean you know the famous quote I might
not and I thought instead of Newton on the beach what if franz liszt were there
what question would he ask what would he say and I'm trying to understand you're the
alien ocean and humans through maybe Franz Liszt and music well so I mean the
the quote from Newton is is some sort of an interesting quote I think it goes something like this if you know people
are talking about how wonderful calculus and all that kind of thing are and Newton says you know to others I may
seem like I've done a lot of stuff but to me I seem like a child who who picked up a particularly elegant you know
seashell on the on the beach and I've been studying this this seashell for a while even though there's this ocean of
truth out there waiting to be discovered that's roughly the quote okay I find that quote interesting for the
following reason the what Newton did was you know calculus and things like kit if you look at the computational
universe of all possible programs there is a small corner Newton was exactly right and what he said that is he picked
off calculus which is a corner of the possible things that can happen in the computational universe that happened to
be an elegant seashell so to speak they happened to be a case where you can figure out what's going on and and so on
while there is still a sort of ocean of of other sort of computational
possibilities out there but but when it comes to you know you're asking about music I I think my computer stopped
being able to get anywhere but but um sort of interesting the cific get to the
site yeah so this is a this is a website that we made years ago and now my
computer isn't playing anything but [Music]
let's try that okay so these things are
created by basically just searching computational universe for possible programs it's sort of interesting
because everyone has kind of a story some of them are look more interesting than others let's try that one
anyway the the what's what's interesting actually what was interesting to me
about this was this is a very trivial you know what this is doing is very trivial at some level it's just it
actually happens to use cellular automata you can even have it show you I think someplace here where is it
somewhere there's a way of showing your show the evolution this is this is showing the behind the scenes what was
actually happening what it chose to use to generate that musical piece um and
what I thought was interesting about the site I thought well you know how would
computers be relevant to music etcetera etcetera etcetera well you know what would happen is a human would have an
idea and then the computer would kind of dressup that idea and then you know a bunch of years go by and I talked to
people you know who composers and things and they say oh yeah I really like that wolfram tones site okay that's nice they
say it's a very good place for me to get ideas so that's sort of the opposite of
what I would have expected namely what's happening is you know human comes here
you know listens to some 10-second fragment and they said oh that's an
interesting idea and then they kind of embellish it using kind of something that is humanly meaningful but it's like
you know you're taking a photograph and you see some interesting configuration and then kind of you're you know you're
filling that with kind of some human sort of context but but so I'm not quite
sure what what you were asking about I I
mean back to the Newton quote the thing that I think is some another way to
think about that quote is us humans you know with our sort of historical
development of you know our intellectual history have explored this very small
corner of what's possible in the computational universe and everything that we care about is contained in the
small corner and that means that you know you could say well gee you know I
want to you know what we what we end up wanting to talk about other things that
we as a society have decided we care about and what there's an interesting feedback loop I
just mentioned mr. den but but um so you might say so here's a funny thing so
let's take language for example language evolves we you say we we make up language to describe what we see in the
world okay fine that's a fine idea imagine the you know in Paleolithic times people make up
language they probably didn't have a word for table because they didn't have any tables they probably had a word for
rock but then we end up as a result of the particular you know development that
our civilization has gone through we build tables and there was sort of a
synergy between coming up with a word for table and deciding tables were a thing and we should build a bunch of
them and so there's a sort of complicated interplay between the things that we learn how to describe and how to
think about the things that we build and put in our environment and then the things that we end up wanting to talk
about because they're things that we have experience of in our environment and so that's the you know I think as we
look at sort of the progress of civilization there's you know there's various layers of first we you know we
invent a thing that we can then think about and talk about then we build an environment based on that then that
allows us to do more stuff and we build on top of that and that's why for example when we talk about computational thinking and teaching it to kids and so
on that's one reason that's kind of important because we're building a layer of things that people are then familiar
with that's different from what we've had so far and they give people a way to talk about things I give you one example that um see that I have that still up
the okay one one one example here from
this blog post of mine actually so there
okay so that that thing there is a nested pattern you know it's a bitter
sierpinski that that tile pattern was
created in 1210 ad okay and it's the first example I know of a fractal
pattern okay well the art historians wrote about
these patterns they're a bunch of this particular style of pattern they wrote about these for years they never
discussed that nested pattern these patterns also have you know pictures of lions and then you know elephants and
things like that on them they wrote about those kinds of things but they never mentioned the nested pattern until
basically about 25 years ago when fractals and so on became a thing and
then it's ah I can now talk about that it's a nested pattern it's fractal and then you know before that time the art
historians were blind to that particular part of this pattern it's just like I don't know what that is that there's no
you know I don't have a word to describe it I'm not going to I'm not going to
talk about it so that's a you know it's part of this feedback loop of things that we we learn to describe then we
build in terms of those things then we build another layer I think one of the things I mean you talk about you know
just in the sort of the thing like one thing I'm really interested in is the
evolution of purposes so you know if you look back in human history there's a you know what was thought to be worth doing
a thousand years ago it's different from what's thought to be worth doing today and part of that is is you know good
examples of things like you know walking on a treadmill or buying goods in virtual worlds both of these are hard to
explain to somebody from a thousand years ago because each one ends up being a whole sort of societal story about
we're doing this because we do that because we do that and so the question is how will these purposes evolve in the
future and I think one of the things that I view as a sort of sobering thought is that that term actually one
thing I found other disappointing and then I became less pessimistic about it is if you think about the future of the
human condition and you know we've been successful in making our AI systems and we can read out brains and we can upload
consciousnesses and things like that and we've eventually got this box with trillions of souls and and the question is what are these souls
doing and to us today it looks like they're playing video games to the rest
of eternity right and that seems like a kind of a bad outcome it's like we've gone through all of this long history
and what do we end up with we end up with a trillion souls in a box playing video games okay um and I thought this
is a very you know depressing outcome so to speak and then I realized that that actually you know if you look at the
sort of arc of human history people aren't any given time in history people have been you know they've my main
conclusion is that any time in history the things people do seem meaningful and purposeful to them at that time in
history and history moves on and you know like a thousand years ago there
were a lot of purposes that people had that you know what to do with weird
superstitions and things like that that we say why the heck are you doing that that just doesn't make any sense
right but to them at that time it made all the sense in the world and I think that you know the thing that makes me
sort of less depressed about the future so to speak is that at any given time in history you know you can still have
meaningful purposes even though they may not look meaningful from a different point in history and that there's sort
of a whole theory you can kind of build up based on kind of the the trajectories that you've followed through the space
of purposes and sort of interesting if you can't jump like you say let's get chronically frozen for a you know 300
years and then you know be be back again the the interesting cases then you know
are the purposes that you sort of you know that you find yourself in ones that
have any continuity with what we know today I should stop with that that's a beautiful way to end it

----------

-----
--32--

-----
Date: 2018.02.24
Link: [# Lisa Feldman Barrett: How the Brain Creates Emotions | MIT Artificial General Intelligence (AGI)](https://www.youtube.com/watch?v=qwsft6tmvBA)
Transcription:

Introduction
today we're going to try something different we're going to try a conversation we have Lisa Feldman
Barrett with us she is a university distinguished professor of psychology at Northeastern University director of the
interdisciplinary affective Science Laboratory author of the new amazing book how emotions are made the secret
life of the brain she studies emotion human emotion from social psychological
cognitive science and neuroscience perspectives and so I think our
conversation may help us gain intuition about how we instill emotional life into
future artificial intelligence systems as Josh Tenenbaum gave you a shout out
on Tuesday and said that if you want to understand how to create artificial general intelligence systems from an
engineering perspective we should study the human brain so with that let's have
some fun let me start with the curveball to conjure up an image of emotion have
you ever cried while watching a movie that you remember and what movie was it
Ive cried
I've cried during lots of movies
let me think the last time I cried
actually here's an interesting thing when I'm speaking about when I'm giving
an academic talk I sometimes will talk about a study that we did where we had people watch films and we have them
watch the most evocative clips of films and there's several clips that are
really powerful and a couple of them every time I talk about
them I'm gonna try not to cry now every time I talk about them I'm describing for the audience what subjects are
seeing one of the clips is from a movie called Sophie's Choice does anyone know
this film raise your hand if you know this film so we show this is a film about a woman who is forced in a
concentration camp to choose which of her children will die in the gas chambers and so I'm already you know
like if you were if I had a heart rate monitor and respiration monitor you
would see them like it's a really powerful scene Meryl Streep is Sophie
and it's very very evocative we have we
also show there's a scene from a film with Susan Sarandon
who is dying of breast cancer and she has to tell her 12 year old daughter that she's dying so there's another scene also that um
that I find very compelling and you use these scenes to listen to motion as part
of experiments we do yeah and in fact I was just giving a presentation to the
Supreme Judicial Court of Massachusetts on implicit bias and to start the you
know they want to understand the neuroscience of implicit bias and whether or not they should be crafting
jury instructions for juries to be aware of implicit bias and to open the
discussion I showed them a clip from a film that was filmed I you know almost
20 years ago actually called a time to kill a scene where Matthew McConaughey
is this kind of he's his closing statements in a case where he is
defending an african-american man who murdered two European American men who
raped his twelve-year-old daughter and so the scene is he's this completely pathetic lawyer until the end when he
masters this fantastic defense basically of this man on trial for you know
basically avenging his daughter's death and that one I hadn't seen that for 20
years that film and it brought me to tears actually it's just a really powerful powerful scene and it's it just
really punches you in the stomach you just can't help but just experience the
weight of racism in that in that room and the brilliance of the closing argument to sort of puncture through it
Common misconception
basically right okay so experience so one of the things
you talk a lot and you're working in your book is the difference in the experience of emotion the expression of
emotion so what our what's our biggest misconception about emotion for folks
who haven't considered have only considered emotions at a
surface level I would say one common misconception is that you can look at
someone's face and read their emotion the way you read words on a page that
everyone around the world when they're feeling angry they scowl when they're feeling happy they smile when they're
feeling sad that they frown the way that I'm saying it sounds preposterous and it is preposterous
but unfortunately that is actually what people a lot of people believe and tech companies around the world spend
tremendous amounts of money and you know in the investment of some of the most
creative people on this planet trying to build a motion detection systems when
really what they're building our excellent systems for reading facial movements which have no intrinsic
emotional meaning I mean sometimes facial movements communicate emotion but many times they
don't so people scowl for many reasons they scowl when they're concentrating
they scowl sometimes when they're sad they even can scowl when they're happy
people smile when they're angry they smile when they're sad they don't just
smile when they're happy they sometimes smile to indicate to send commute you know a social message that has something
to do with emotion and so the idea that there's one Universal facial expression
for example for each emotion is just there's no strong scientific evidence
How emotions are created
for that claim so how is emotion created them because we nevertheless feel like
we're observing emotional we're communicating with others so how does emotion the creation of emotion change
in the presence of others the does the audience change the display of emotion
is that essentially the message well emotions are not displayed I would say right so basically you and I are
having conversation right now and part of what you know my brain is
doing is it's guessing make making educated guesses about what your facial movements mean so right now you have a
slight smile on your face not exactly a smirk but and so you know say Russian by
the way so we're not allowed to show any emotion you know I have a friend of mine
who is Russian who told me and she when she moved to this country actually I've had several friends tell me this that
their cheeks hurt for a year for how much smiling they had to do I have also a friend from the Netherlands who moved
here who told me the same thing her face ached for how much smiling she did and in Bulgaria they haven't apparently like
a name for you know the pervasive American smile kind of like a not
flattering name for how much Americans smile but basically you when you look at
someone's face you're making a guess about how they feel and although you yourself are focused on their face to
you it feels as if that's where all the information is your brain is actually taking in the entire sensory array so
it's taking in also you know the sound of the person's voice and the person's
body posture and the dynamic temporal changes in all of those signals to make
sense of things it's not you're not really the face is not a lighthouse it's not a beacon that just displays
somebody's internal state in an obligatory way nevertheless there's some
Building blocks of emotion
signal there of course and so what are what would you say as far as I
understand there's no good answer yet from sciences what are the basic building blocks of emotion well I
wouldn't say that there's no good answer from science I would say scientists disagree I think it's very clear what
the building plugs are but you know in one way or another if
you look back all the way to ancient Greece you can see that there are two
kinds of views of emotion that have been battling it out for millennia one is the
idea that you have I will give you the modern versions of these views but they
really do have a very long history one is the idea that you are born with
circuits in your brain that are pre what you know kind of pre-wired for emotion so that everybody around the world is
born with an anger circuit a fear circuit a sadness circuit a happiness circuit some other circuits too you have
them we all have them all neurotypical brains have them and actually other animals have them too and the idea is
that when you know one of these circuits is triggered you have an emotional response which is obligatory so you have
a very stereotypic your breathing changes in a stereotypic way your you know heart rate changes
your the chemicals in your body change in a particular way you make a
particular facial expression and you are have a propensity to make a particular
action like you you know attack and anger and you run in fear or you freeze
in fear and then there's another view which says well there are some basic
kind of ingredients or building blocks that the human mind or the human brain now people talk about the brain now
there are some basic ingredients that your brain uses and it uses them to make
every kind of mental event that you experience and every action that you take the recipes are what are unique the
ingredients are common right just like you can take flour and water and salt and you can make a whole bunch of
different recipes with them some of which aren't even food like glue in a
similar way the idea is that your brain has some kind of all-purpose capacities and it can it puts these ingredients
together and it makes emotion as you need them on the spot and you don't have one anger you have a whole repertoire of
anger you don't have one sadness you have a whole repertoire of sadness and if you grow up in a culture that has no concept
for sadness you don't experience sadness and you don't perceive sadness because your brain becomes wired to make
whatever mental events that are exist in your particular culture so for
What makes us human
artificial intelligence systems the idea of emotional intelligence is really difficult and it seems like it's an
important thing to try to instill so for human beings where do you see the
importance on the priority list of what makes us human where does emotion sit I
usually think that's the wrong question to ask because no I mean I think I think
people constantly ask that question but I don't think it's the right question to ask because you know some cultures in
our on our planet don't even have a concept for emotion and people don't
while they experience what I'm going to refer to as in scientific terms we call
effect which is our simple feelings of feeling pleasant or unpleasant or feeling worked up or calm or comfortable
or discs or you know having discomfort these are feelings that come directly from the internal state of the physical
systems in your body not everybody makes emotions out of those feelings and in
fact we often don't make emotions out of this way so those feelings the way to think about it is that your brain comes
wired to regulate your body actually sort of take that back you your brain
comes wired when you're born your brain comes wired with the potential to regulate your body infants actually
don't regulate their own nervous systems very well they can't put themselves to sleep they can't calm themselves down
they can't regulate their own temperature that's what they need caregivers for and as caregivers
regulate the nervous systems of their infants that wires the infant's brain right so infant little infant brains
aren't born like little miniature adult brains they're born at waiting for a set
of wiring instructions from the world and they wire themselves to the physical and social
realities that they grow in and as they learn to do this they experience these
simple feelings that you know a feeling Pleasant or unpleasant feeling worked up or feeling calm these are kind of like
barometer readings in a way they're very simple and they lack a lot of detail because of how we're wired and we have
to make sense of them and the way that a culture makes sense of them is not always about emotion so I would say you
know in our culture when we lose something significant like a loved one we feel sad into heat intuition people
feel sick they they have an illness it's not sadness a hundred or two hundred
years ago there was an emotion called nostalgia which killed people was
thought to kill people after you know for example after serving in World War one we would now call that depression
it's not just a matter of changing the label of something it's actually the
formation of the experience is very different so if you want to build an intelligent agent
I don't think emotion is what you need to endow it with you need to endow it with these basic ingredients that it can
use to make whatever experiences or guide whatever actions make whatever
States or guide whatever actions are relevant to the situations that it's in that will be different if it's an
American or a British or a Western urbanized environment than say if you
were to go to Tanzania and steady you know the HUD's ax who are hunting
and gathering since that culture since the Pleistocene so do you have words or
Brain evolution
human interpretable labels on these basic ingredients that we can understand
so I mean I think the first thing to understand is that when we think about
building an intelligent agent we think about endowing the agent with cognition
or with emotion or with the ability to COO you to perceive things in the world because
as humans that those are these are the things that are really important to us especially in our culture thinking
feeling seeing and other cultures you know they have different ways of parsing
things but the truth is that your brain did not evolve so that you could think
and feel and see it evolved brains evolved to control bodies brains evolved
so that they could control the various systems of the body as creatures move
around in order to gain resources like food and water and a brain has to figure
out how much resources to expend on getting additional resources now that
may sound really trivial but it turns out it's actually really hard and scientists actually haven't really
figured out completely how brains do this I mean what's really interesting to
me is that if you look for example at computer vision try to figure out you know how how to make an agent see that's
a pretty much solved problem not completely it's a pretty much solved problem the basics are solved it's your
perception problems yeah the peer perception problem however if you want to create an agent that just reaches out
smoothly grabs a glass and brings it into the body to drink that problem is
not solved something is simple as movement which we think of as this really basic thing like oh it's so
trivial all animals can do it is actually the heart at one of the hardest problems to solve and the brains
basically I mean there's a whole story here about evolution which has nothing to do with having a lizard brain which
is wrapped in you know a cognitive brain or anything like that that's a reference
to the Trion brain which a lot of people believe it's a way of thinking about brain evolution instead what we what
seems to be the case is that as bodies got larger and there were more systems because the
nish of the animal the environment the animal got bigger and bigger and bigger brains also had to get bigger but they
had to get bigger to a point with some constraints like they have to be you
have to keep metabolic costs down it's really important if you don't you know
creatures get sick and die and we can talk about what that means in terms of depression or metabolic illnesses or
what-have-you but so what are the basic ingredients well one of the basic ingredients is that your brain is
controlling your body all the time whether you feel it or not whether you're thinking about it or not whether
you're asleep or awake certain parts of your brain are always very active all
the time even when you're sleeping or else you'd be dead and those parts of
the brain that are controlling your heart and your lungs and your immune system and all of those regions that are
controlling the systems of your body are also helping your brain to represent the
sensory consequences of those changes in your body which you don't feel directly
you don't feel your heart beating most of the time you don't feel your lungs
expanding most of the time and there's a really good reason why we are all wired not to feel those things and that is
you'd never pay attention to anything outside in the world ever again if you could feel every little movement that
was going on inside your body so your brain represents those as a summary these kind of simple summary feelings
you feel good you feel bad you feel great you feel like you feel really jittery you feel really calm and these
feelings are not emotions they sometimes get your brain can make them into emotions but they're with you every
waking moment of your life there are properties consciousness in the way that lightness
and darkness is a property of vision and
sometimes we make them into emotions when they're vit when we have a big change in our heart rate or a big change
in our in our breathing rate or a big change in our temperature or a big surge
of glucose we might the brain might make a motion out of those changes those very
strong changes which you will feel as really feeling unpleasant or really feeling Pleasant but your brain might
also make hunger or your brain might make an instance of a physical sensation
like nausea or your brain might even make a perception of the world like
that's a nice guy that guy is an this is a really delicious drink that's
a beautiful painting those are also moments where these simple feelings which we call effect are very strong so
effect is a basic ingredient there are others that I could talk about too it's
not the only one but one of the things I think that that sometimes people who are
studying to build AI systems don't realize is that the brain its
fundamental job is to keep your body alive and well and if you don't have
some kind of body to regulate with effective feelings that come from that
regulation or something like that it's
you're kind of gonna be out of luck I think in rendering something that looks
more something that seems more human right so maybe you can elaborate like in
Emotions are not real
the book sapiens that we as human beings are really good on mass as a thousands
millions of people together believing something even if it's not true so
while scientifically sort of from a neuroscience perspective it may be very true that emotions aren't real I didn't
think real but I said they're not there there isn't so interesting you finished
yeah yeah so what I'm trying to say is also from AI perspective is they become
these trivial ideas of mapping a smile to being happy and these kind of trivial
ideas become real to us through Hollywood through cultural spreading of
information and we start to believe this and therefore it becomes real innocent in in in as much as anything is
real about our cult our perception together so it's really important
scientifically the ideas that you're presenting but does that mean there's just because our brain doesn't feel
those explicit emotions does I mean they're not real I didn't say we don't feel explicit emotions so I want to be
really clear about this because it's an interesting this you know this sum this
inference it's an interesting inference that people often make and so but it's
it's a mistake and it's a mistake that betrays a certain kind of thinking that we do in this culture and is it's the
mistake of the following sort so when I say there is no facial expression that
is diagnostic of a single emotion that doesn't mean that people don't express
emotion they certainly do express emotion they just don't you know when when they're in a state of anger in a
state of sadness or in a state of awe their faces don't do one thing when I say well your body can do many things
when you're angry or when you're sad or but let's take anger your heart rate can
go up it can go down it can stay the same your breathing rate can go up it can go down it can stay the same the
same pattern that you see in anger you sometimes see in sadness and you sometimes see in fear you sometimes even
see it in enthusiasm and in awe so does that mean that emotions aren't real no
emotions are real but but sometimes things are real because the physical
meaning of the signal is endowed in the signal okay
so when your retina communicates to your brain that you have that you are faced
with a wavelength of that you know is 600 you know 600 nanometers the signal
is endowed in your brain that's like in the signal it's not like interpret you don't interpret that it's 600 you know
nanometers it is 600 nanometers the informations in the signal but when you
see read that information is not in the signal your brain has added information
that isn't in the signal itself in a sense your brain has imposed meaning on
a signal that the signal doesn't have on its own they'll let me back up and give
a different example to make it a little easier and then will reproach this there's a there are some things that we
impose this is true almost of all civilization right that we there are
some things that are real by virtue of the fact that we agree that they exist little pieces of paper serve as money or
now you know bitcoin or little pieces of plastic or gold or diamonds or in the
past barley salt shells rocks serve as currency have
value only because a group of people agree that they have value so we impose
meaning on objects and once we all agree
that that object actually has value we can trade it for material goods the minute that some of us disagree that we
risk we withdraw our consent right the
things lose their value that's what happened in the mortgage crisis that's what happened in the tulip crisis in the
you know the Netherlands in the 17th century or 16th century when it was
money currency this because we impose meaning on
objects in the world physical objects in the world that themselves don't have
that meaning on their own and they are very real money is very real to people I can stick somebody's head in a brain
scanner and show you that they experience value in a very real way but
that that reality is constructed by the
fact that they have learned the value in a particular culture well that's also what we do with emotion we impose
meaning on certain physical signals that they don't have by on their own and but
we have collective intentionality we all agree that scowling is sometimes anger
and so it becomes anger in a very real way just like little pieces of paper
become money so it sounds like you kind of think about the expression R emotions a kind of language as an extension of a
Emotions are a language
language that will learn in the same way that we collectively agree in a language ana lexicon and how we use that language
sure you could think of it that way I mean everything everything in our
culture is almost everything
agriculture is a function of social reality in this way we are citizens of a
country because we all agree that the country exists more or less and wow you
guys barely even laughed at that okay [Music] what's a revolution a revolution is when
some people in the country withdraw their consent they no longer agree right
a president has powers in a country because we all agree that a president has powers present only as powers by
virtue the fact that we all agree that he or she has powers if we stop agreeing
the president doesn't have those powers anymore it's very real people's lives
depend outcomes of real people depend on these social realities that we build and
nurture and we why are these social realities into the brains of our children as we socialize them and when
people move from one culture to another they have to learn the new social
reality that they are faced with and if they don't they get very sick physically
because our ability to agree on what something means actually is important
for regulating our nervous systems so can you speak to that a little bit I mean for machine learning methods for
How does an infant learn
systems that learn to behave based on a certain reward it's important to kind of
have some ground truth and and learn so how do it sounds like the expression of
emotion is learned can you talk about how we learn to fit into our culture by
expressing emotion with our phase body given the context given the rich what's
that process look like when does it happen how much sure well you know I mean yeah
I wrote a 400 page book so I'll try to do it in like a couple sentences yeah so
so how does it how does an infant learn anything so an infant's born and it
can't do anything for itself it can't regulate its own nervous system it can't keep its
body systems balanced this is a term scientific term for this is alice stasis
alice stasis is your brain's ability to predict what your body is going to need before it needs it and tries to meet
those needs before they arise so an example would be if you're gonna stand
up if your brain is gonna stand you up it has to raise your blood pressure before it stands you up if it doesn't
you'll fall that's costly from metabolic standpoint it's costly you'll hurt
yourself so an infant's brain can't do this very well an infant doesn't know
when to go to sleep and when to wake up an infant doesn't can't feed itself
can't regulate its own temperature someone else has to do it and when
someone does it the infant is learning the infant is learning it's taking in
sights and sounds and smells and the physical sensations from the body which
are comfortable and pleasant when the infant Alice stasis is maintained so
right from the get-go an infant is learning statistical learning you know
the capturing events including their consequence for the infant's body
some people think babies are born you know attached already to their caregivers but they're not actually
infants don't even know what a caregiver is it's just that the caregiver is there constantly meeting that infant's needs
that's how infants start to learn now if there are statistical regularities like
for example an infant is not born with the ability to recognize a face as a face but it learns that in like the
first couple of days of life why because human faces have some statistical regularities to them right to eyes and
nose and a mouth kind of in the same place most of the time so it learns really quickly but here's the
interesting thing around three months of age infants start to learn
what we call abstract categories they start to learn that some things which
don't look the same or sound the same or smell the same actually have the same
function and how do they learn this they learn it with words so if you do an
experiment with a three month old three months old okay and you say to that baby
very very intentionally look sweetie this is a one and you put the web down
and it makes a noise like a beep and then you say I'm like I don't have props
and then you see my wallet yeah okay and then you say give me your wallet yeah give me your wallet and then you say
look sweetie this is a and you put the down and it makes a beep if you say look
sweetie this is a that infant expects that
object to beep why is that important because in the real experiments this
might be yellow and squishy and tall and this might be red and pointy and you
know hard and this might be you know so lots of different perceptual features
but but the infant nose learns that the
word is inviting the infant to understand that the function of those
very different physical signals are actually the same similarly you can take
you know six objects that are exactly identical in their physical features how
they sound how they smell what they feel like what they look like and you can
name three of them with one word and three of them with the other word and the infant will understand that these
are actually different objects that happens a little after you know not not as early as three months but the point is that when we talk all
the time we use words all the time what do we do with infants we're constantly pointing things out and labeling them
this is a dog this is a cat you're angry this person's sad Oh mummys really happy
today oh you know mommy loves you Oh daddy's really excited about this and
so on and so forth and infants learn really really quickly words are
considered to be kind of invitations to form abstract concepts that is the basis
of almost all of the you know mental
categories that we that that we mental events that we experience we're
basically teaching children to form these abstract categories not and that's
the basis of money and it's the basis of rules that we have with each other and
what we expect from each other it's the basis of a lot of the sort of functional categories that we use in everyday life
we're impose meaning on sensory on sensory arrays that those sensory arrays
in and of themselves don't necessarily have they only have that meaning because you and I both learn that that package
of sensory array means something so when I make that you can anticipate what will happen next just because we've learned
those are they're wired into our brains you know in our culture and when we go
to a different culture we have to learn sometimes different packages yeah different mappings so you're saying that
Different mappings
there's a few sources of sensory data and a few building blocks inside us the
feelings of some kind that we learn to then from an early that we've come born with those or part of what your brain is
doing is it's trying to make sense of the sensory array around it so from your
brains purse so from your brains perspective just think about from your
brains perspective your brains perspective it spends its entire life
trapped in a dark silent box [Music]
Anna NASA makes sense of what's going on around in the world so that knows what
to do to keep itself alive right and well but it has to it has to know what
to do based on it has to know what what's happening all around it only from the effects that it receives through the
sensory systems of the body so a flash of light what's a flash of light it could be
anything what you know what's a look like a siren a siren could be you know a
firetruck or it could be somebody's car alarm went off or it could be a doorbell
or it could be right any particular sensory cue could have multiple causes so your brains trapped basically in your
skull and all it gets are the effects the sensory effects of stuff that
happens in the world but it has to figure out what those things are so that it knows what to do so how does it do
that well it has something else that it can draw on it has your past experiences your brain basically is doesn't store
experiences from the past it can reconstitute them in its wiring and
that's what it uses to guess at what those sensory cues me of those sensory
changes me so in one situation a siren
means one thing in another situation it means another a flash of light means one thing in one situation and a different
thing in another so your brain is using past experience to make guesses about what these sensory changes me and so
that it knows what to do and it has the same relationship to the sensory changes
in your body what's an ache in your stomach well it could be hunger it could be anger it
could be discussed it could be longing it could be nausea it's not that there's
one ache in your stomach for nausea and another ache in your stomach for hunger
there are many aches in your stomach any different feelings of achiness for nausea and many
different feelings of aching is for hunger and sometimes they overlap so your brain has to make the same kinds of
guesses about what's going on in your body as it does about what the sensory events mean in the world and that's
really what it's doing it's it's guessing and making sense of the sensory array so that it knows what to do next
and when it guesses wrong it takes in that the you know the the sort of
information that it didn't predict well which you know in psychology we have a
really fancy name for that we call it learning your brain takes in the
information that it didn't predict and so that it can predict better than the next time to make sense of things the
next time so you kind of answered this a
Building a robot
little bit I'd like to elaborate on it if you were to build a robot that performs maybe passes the Turing test or
performs at the low bar level of instead of myself here today it would be a robot
talking to you it'd be convincing as a human how would you what kind of how
would you build that system in a sense in paralleling the infant's what essential aspect of the infant
experience do you think is important it needs to well I mean I you know I don't
I'm not a computer scientist so but so the way that I would say it is it needs
to have a body these have something like physical systems or an analogy to physical
systems it has to do something analogous to a low stasis so whatwhat's sorry to
elaborate so what would be the goal for the system you kind of mentioned previously that the goal will be to for
the brain to just stabilize itself no it's not that the brain is stabilized though you know so people talk about
reward what is reward and machine learning is pretty easy it's it's
something but it's it's mathematical so it's there's
no philosophy to it you just oh yeah there's philosophy to everything right whether you admit it or not as a
different story right yeah so you wanted to play a game of chess playing give
them go you wanted to pick up a water bottle is uh okay but what is reward
existence dopamine is actually not
reward dopamine is effort dopamine is necessary for effort it's not necessary for reward
maybe it's commonly if you read the most caught those up to date literature that
is what you'll see that it's actually people can animals can find things
rewarding can be without without dopamine actually but they they they
need to open to move they need dopamine to encode fits and to learn information so it's really for effort that is
required to work towards getting a reward I would say and when the when a
brain an animal brain a human any kind of animal brain miss predicts what the
reward will be that's what you see a real surge of dopamine because it the
animal has to adjust its action but reward is basically bringing the body
back into a low stasis it feels good when that happens and people will and
animals will work tremendously hard to have that happen so you know what is
motivation motivation is is expending resources to get a reward so basically
if if you don't have something
like physical systems that have to be kept in balance water I mean for humans
or for actually any living creature on this planet even you know single-cell
organisms actually there's an analogy to what we're talking about here to brains but you know salt water glucose all
these systems have to be kept in balance and they have to be kept in balance in a very very efficient way and that's the
motivating so-called motivating force really that's what that's what that's
what really brains are for so yeah and that is the basis the consequence of
that regulation it are the basis of you know effective feelings which are for
many many creatures on this planet a property of consciousness ok so maybe if
Will it love you back
it's ok we'll take some questions in the audience but first let me ask the last question as so I'm building on the robot
question how would you build the same kind of robot that you would be able to
as a human being fall in love with well
you know people fall in love with their cars they fall in love with they fall in
love with their blankets they fall in love with their toys you know you don't need MIT doesn't need much to fall in
love with something the question is will it love you back I would elaborate I think I think yeah I
think you're answering that love in the way we're defining it loosely in poetry and culture as a social construct and
its relative what I mean is sort of the idea of monogamous law a long-term love
that we have deep connection with other human beings that we have you're saying you could do the same with a car like a nice 69 Mustang are you telling me that
you you telling me that you've never you know anyone who's like so in love with their car that you okay now here's the
thing so one so here's the thing we we are social animals okay what does that
mean what does it mean to be a social animal it means that we regulate each other's nervous systems so our brain my
brain isn't just regulating my nervous system right now it's regulating yours and actually it's regulating other other
people's in the audience too and vice versa and why is that you know I mean other animals do it too
we're just looking really good at it but other animals like there are some insects that are social species they
regulate each other's nervous systems they do it with chemicals they do it with smell primarily and a little bit
with touch like earwigs well you know like they can actually I have this great picture of there's like totally
disgusting looking little bug but it's like you know cuddling it's a little baby ugly little ugly baby bug - it's
adorable picture but you know what about mammals like rats well they also use
chemicals like smell but they also use touch and to some extent they also use
sound these hearing primates add vision and as primates we do all weaves all of
those senses to regulate each other and we also use something else words right
exactly and words the systems in our brains that allow us to speak and allow
us to understand words are directly connected to the parts of the brainstem
that control the body I don't mean like they're a bunch of I mean monitor I mean monosynaptic we connected so exactly the
same systems in your brain that are important for you to be able to understand language and to
speak are also directly directly affecting the systems of your body and
that is why I can say something to somebody I can speak to you and I can
have an impact on the nervous systems of people all the way at the back of this auditorium without they you know maybe
they can see me maybe they can't maybe they can't hopefully they can't smell me maybe they can hear me maybe they you
know but they can if they hear me speak words I can affect their nervous systems that's why a telephone works that's why
the telephone works to where you can feel connected to someone just merely by hearing their voice because the sound of
their voice has an effect on your nervous system it can it can make you breathe faster it can make you breathe
slower and the words also have an effect because when I say a word like hmm I
don't know when I say word like car that's a short
form I have a bunch of mental features in my mind when I say the word car and I
say that word and that invokes those similar mental features maybe not identical but similar enough that
invokes it in your mind and your mind is
made by your brain so it invokes if I just say the word car there are changes
in your motor system that would be exactly the same or very close as if you
were actually in a car right so this is something that we do and the fact we're
attachment comes from an infant to a caregiver or or to lovers or to really
close friends comes from the ability that we have to regulate each other's
nervous systems and that is why when you don't have that
kind of attachment you die sooner on average seven years sooner loneliness
kills I always tell my daughter my daughter's 19 years old I always tell her you know breaking up when you break up with someone it feels like it will
kill you but it won't loneliness however will kill you it will
kill you on average seven years earlier than it would if you didn't have an
attachment and that's because our nervous systems you know as our bodies
got really complex through evolution and our brains got bigger they could only get so big there are constraints on how
big any brain can get that have to do with you know birthing the infant but it
also has to do with the metabolic cost of a brain your brain is really expensive my brain really expensive
three pounds 20 percent of your metabolic budget that's a lot and so
what did evolution do to solve this problem well it couldn't make our brains any bigger so it just entrained other
brains to help manage our nervous systems so you bear the burden of other
people's Alice stasis and they bury your the burden of yours not always at the
same time but that's what it means to give people support when someone when you're feeling horrible and somebody
Pat's you on the back or says nice words to you or gives you a hug they are physically having an effect on your body
that they are helping your body to maintain a low stasis at a time when
your brain probably couldn't manage it on its own and so the basis of love or
attachment is basically that it's the ability to affect each other's nervous
systems in a positive way I always say to people you know the best thing for a
nervous system a human nervous system is another human and the worst thing for a
human nerve system is another human because we're
social animals well beautifully put so maybe a few
Audience questions
questions in the audience do you mind if there's a there's microphones on both sides okay sure hi thanks for talking here
you're saying cool stuff not a question
I'll take it it's all right so I was
thinking about what you're saying about reward and I'm wondering first of all is
he described as a return to a lo stasis is reward in any way linked to the and
just like the reinforcement of pathways or behavior so that the next time you get that stimulus you will you'll
respond in the same way and I'm also wondering about the link between the
desire for aloe stasis and the need for novelty and then he did like a great
it's a really great question so um the second question is so much
more interesting than the first actually so let me say this that that there is a
need for novelty the need differs right for different people I will say novelty
so first of all the we can think about
the need for novelty in a really proximal way we can think about it in a
really distal way like but basically
when I say that a brain is organized or engineered for metabolic efficiency that
doesn't mean that the goal is to to only ever have your prediction you know your
brains predicting all the time to always have its predictions completely perfect so you'll never learn nothing because
you'll be bored out of your mind right and also you know humans like to
and their niche they like to explore so it's a constant balance between what
biologists would call exploitation and exploration novelty is is um it's
exciting it there's actually an increase in norepinephrine an increase in arousal it feels really exciting but it's also
super costly novelty requires usually that you learn something new that means
that's actually really metabolically expensive thing to do and it also means usually that you're moving your body
around which is also metabolically expensive thing to do so the need for novelty is balanced by its cost and
different nervous systems can bear different amounts of cost so for example
if you take two rats that are somewhat genetically you know moderate like
they've been genetically bred one is bred when you stick it in a a novel cage
it just sits still and the other one when you put it a novel cage it like
roams all over the place and it's just you know it's going crazy kind of exploring everything well the one that
sits still scientists might say oh that's a nervous rat or that rats afraid
what is that rat doing the rat is not moving and it's not encoding anything
because encoding something is expense it's expensive this rat on the other hand is roaming
all over the place moving a lot learning a lot so it's encoding a lot spend spend spend save save save spend spend spend
there are time there are differences between people and there are also differences between times in your life
where moments where you feel like you have a little bit to spend and other moments where you feel like you really have to conserve when I talk to the
public I always talk about I don't use the word out of stasis it's just too boring a word but I sort of do is sort
of explain it like a budget you know like your brain is sort of like the financial office of a company a company
has lots of offices it has to balance the expenditures and revenues and it's
got to keep everything in balance so it might take a little money here move without office you know it's got to keep everything in balance we're just always
trying to do is spend a little bit to make a little bit more what happens when
it spends a little bit and it doesn't get a revenue back there's no reward what happens well it goes into the read a little bit so what do you do when
something goes into the read well you might do something risky you might actually spend a lot to try to really
may you know not just make back your deficit but actually make a lot that would be novelty that would be move and
spent moving and encode or you might reduce your spending you might say well
I'm gonna save a little bit now that would be I'm not gonna move too much I'm
not gonna spend too much I'm not gonna encode anything so I certainly don't mean to suggest to you that that novelty
is unimportant or that learning is unimportant and it's a really important question about what is there any
intrinsic value to novelty over and
above the rewards that it would give you an analysis at ik sense but it is really
clear to me that the extent to which you any nervous system will embrace novelty
and even seek it pretty much depends on the allostatic state of that of that
system if you don't have a lot to spend and you're already in the red you if you
at a certain point if you continue to spend when you're in the red you go bankrupt what that means in human terms
is you get depressed it means that your your brain makes you fatigued so you can't move and it makes you locks you in
so you stop paying attention to anything going on around you in the world and your experience is just what's in your
head that that's actually what depression is so that makes me think of
aloe stasis more of as a range than as a zero point it's not homeostasis it's
Alice stasis it's a range for sure but we answer some other questions and maybe I'll get back to your first question if
there's time so if I understand your argument correctly if we're going to
The need for embodied systems
make anything like a general intelligence something approaching not like like a human it
needs to be an embodied system well I want to be careful about saying that because for two reasons one because in
biology there is this concept of degeneracy just a sucky word but it's a
great concept and it means that there's more than one way to skin a cat basically you want a functional outcome
there are many ways to get to that functional outcome so genes for example you know there are a lot of
characteristics that are heritable but we don't know the genes for them and the reason why is that there isn't one set
of genes there are like multiple sets of genes that can give you actually the same outcome so what I want to say is
that you need something akin to a body it doesn't actually have to be a body I
imagine there are lots of ways that you could implement a system you could
implement an agent that has multiple systems of some sort that it has to manage but my point is that one thing
about that is very important that we continually miss when we think about building an agent with mental states we
continually miss the fact that it has a body it has about humans have bodies and
that's the brains primary task and our most fundamental feelings come from the
physical changes in our body even though we don't normally experience it that way
that actually is how it is if you just look at the wiring of the brain if you just see it so it seems to me that if
you want to build an agent that is human like it has to have something like a
body doesn't have to maybe be a body and I'm sure there are many clever ways that
you could implement something like a body without it actually being a body if you know if you understand what I mean
so Amazon Alexa could be there if we
just gave it some sort of I don't know representation of mental states or some kind of a low static yeah target sure
here's just say one other thing because I think it's really important all a brain requires is that you at some point
had a body you know right so basically being this is what phantom limb pain is
this is what chronic pain is this is what happened you know if at some point you cease to get information from your
body anymore your brain still can simulate still can reinstate the sensory
patterns that once came from the body and that's what's required right at some
point the body isn't really needed anymore yeah I think we're here yeah so
emotions in humans Lucas are they implemented by a bunch of hacks so there's a bunch of chemicals that go
into your brain those oxytocin serotonin a whole bunch of biochemical things that
diffuse around in the fluids in your brain that affect your emotional state and that seems like a Hank that we've
inherited over millions of years from premature ancestors and if you look at
the machine learning world we can do a bunch of similar things with you on that so you can increase the activation thresholds on a large scale you have
changed the map noise going into the system you can do a bunch of similar things but you don't have to rely on
fluids being kind of cleaned slowly by glial cells things don't diffuse around
in and fluid in the system necessarily seems like there's a lot more flexibility so when you come to an
implementation there's not so many constraints imposed by the evolutionary history on the whole system and it seems
like that would make it work better so when people are in negative emotional states and they can't think straight
people can think actually quite well a negative emotional state they don't tell you so but they can play with crimes
they can do very nefarious things very very effectively right so but the general point I think is true even if
that example is not so emotions kind of flood your nervous system without
emotions don't flood your nervousness all right so some of them do so now perfectly of yes sir
you thing in your bloodstream let's talk about this chemical let's talk about
this chemical there's not a single chemical in your brain or anywhere in your nervous system that is for emotion
serotonin is not for emotion don't mean it's not for emotion oxytocin is not for emotion well even opioid you know even
even Opie even opioids are not for emotion so they influence your emotions they're involved they influence every
mental event that you have not just emotion so your brain for example your
brain is a physical it's a set of physical cells that are bathed in neuro
chemical systems and the neuro chemical systems that you're referring to basically change the ease with which
information is passed back and forth between those neurons that's always true it's true regardless of whether the
event is a motion or whether it's a perception or whether it's a thought or whether it's a belief it's always true
so for example serotonin serotonin is a neurotransmitter that allows your brain
to delay gratification of a reward it allows you to expend energy now because
you anticipate a reward at some point in the future and if you have a deficit in
serotonin then you can't do that very well and it turns out for humans one of
our great superpowers is the ability to do mental time travel to remember in the
past and also to do things now because we know they're going to have an effect ten or twenty or fifty or a hundred
years from now so the the you know in when I said you have to have something
like a body I'm not saying literally you have to have a physical corporeal body I'm saying you have to have you I mean
it's just a fact it's not an argument it's a fact that your brain that brains
evolved for the purposes of regulating multiple systems and from a cybernetics
standpoint you know the best way to regulate a system is to build an internal model of it that's what your
brain is your brain is an internal model of your body in the world it's running simulations it's running this model and
if you want to have an age that is somewhat human-like that has feelings like humans then they have to
do something that they have to have to be able to do something similar and whether it's a actually physical
corporeal body or not I think is you know that's an open question right so it sounds a bit as though you're disputing
my premises before I got to my question so I started off by saying sorry I started off by saying emotions are
implemented as a bunch of hacks so would you say that was rub broadly correct or would you say that they're not hacks
they're finely tuned and adaptive and well I went there not maladaptive but would you say it's a bunch of hacks I
don't think I don't know what you mean by hacks I think luge's kind of historical
accidents I think they're wrong you're talking about emotions like they're they're talking the the premise of your
question I can't answer your question because I think it's not the correct question I mean what its emotions aren't
like blood pressure you know they don't exist in that sense they are they are
the way that they are first of all not all cultures have not all people in all
cultures have emotions everybody has effect assuming they have
a neurotypical brain of sorts but but they don't all have emotion and so to
answer your question that your answer asking me is I can't answer because I don't think it's the right I don't think
it's the right opioids and the the pain systems seem like things that influence
your emotions fairly directly so this it's not that it's the same thing but it's that there's a powerful link
opioids though so opioids are important
for instances of emotion but they are also important for every other category
of mental event that you brain can make other things too I agree so I you know
but you will see sometimes scientists will assign you know I'm an emotional
meaning to something like dopamine is for you know first hedonic pleasantness
and then it's for reward people like to assign single functions two biological entities
like a chemical or a brain region a cluster of neurons or it's just not
that's really I'm not saying every chemical does everything but whatever whatever opioids do they do in every
waking moment of your life not just in moments that are emotional for you
I should stop thank you very much yep I
think it is very interesting that you brought up the last topic of love because I think it actually brings up a
really important thing which is and what you were saying about connection that's
I mean the primary purpose of life is to procreate right I mean that that's what
our genes do so first of all right I'm not gonna be touching that yeah so yeah
and and it's of course in humans it's not just genetic it's mimetic I mean we
appropriated our ideas as well as you know physically and so a primary purpose
of our wanting our our reactions and interactions with other people and other
things is that goal is that we get
rewarded when we interact with other things in a way that creates something new whether it's art or you know a book
or technology or something like that and if we don't put that if there's no
inherent reason for a robot or a computer system to want to do that I
mean how do we how can we can even imagine
putting that into a system inherently that it wants to that it just
desperately wants to make something new I mean well here's what I would say you
know when we're we're first of all we're not we talk about we've been focusing a
lot on bodies I'm certainly not saying that's a sufficient condition right I'm just saying it's a Ceri one or something like a body but I
certainly have the motivation to create and I'm imagining that you do too I have
to tell you not everybody has that most adolescents don't have that many
adolescents don't have it okay that was a joke I have a teenage daughter I'm just telling you yeah but the point is
that that what people what people find rewarding is is remarkably diverse but
the property I think is that there has to be a feature of reward for for a lot
of people that's you know that's having an impact in some way having an impact on another person having an impact you
know on a building something that wasn't there before whatever you know in in
innovating or I'm discovering but it's not true for everybody it's just true for like a lot of people in this room
probably and certainly the people that we probably spend a lot of time with but not not for everybody
sure I mean look but if you want to you know if you want to if you you know we can certainly make a kinetic argument
here absolutely there there the there's nothing that
I've said today that is inconsistent with the idea that that you have to that
you have to pass your genes on to the next generation and actually make sure that that generation survives to
reproductive age it's not just enough to have offspring you have to make sure the
offspring survive to reproductive age and there's a whole argument about you
know the the learning of social reality
concepts of social reality that we've been talking about like money and emotions and so on that makes that
argument right that it's very expensive to have to encode everything in jeans or
to have to learn everything from scratch every generation so instead what we have
is a system a genetic system that allows us to wire the brains of the young with
what we know and that's what we do basically right so it's the I'm curious
about your analogy about intentionality that you talked about when you use the analogy between money and the perception
of red to the facts that we the fact that we have emotion because the
distinguishing feature it seems to me is the level of intentionality and as you said before our brain assigns meaning to
things but we don't or maybe and and my question is whether or not you agree with this I guess we don't always
deliberately assign me nothing I've said is about ever deliberate but sometimes
we do write often actually yeah so when you go back to like the question of what
makes something intelligent a lot of previous talks have been about you know we want to pick a goal and then we
create costs to achieve that goal but that goal is deliberately if assigned so
when you talk about like what makes something intelligent what do you think
the role of intentionality is and the spectrum therein so first of all we talk
about intentionality I think you have to really be careful that you are philosophers talk about intentionality in two ways they talk about
intentionality to mean a deliberate action the way you mean it but intentionality can also mean that
something has a referent out in the real we're out and outside of you really so that a word a word has a referent that's
the you know the intention of the of the word basically I think you have to be really careful I also think that you
have to make a distinction between a conscious deliberate explicitly a goal
that you can explicitly describe and I
mean you're you're sort of making you're sort of making I mean wait the kind of
question you're asking is getting very close to the question of free will so I would love to not have
disgust but but basically okay and and I what I'm about to say is gonna sound
very Cartesian unfortunately because that's English I don't know there's no other way to do it actually but what I
want to say is that your brain is always there is always a volition but it's not
always consciously experienced by you as as agency or will so yeah you're not
you're not a sea urchin you know your sensory neurons are not hardwired to
your motor neurons you have inter neurons that means you have choice do you consciously experience yourself as
making choices all the time no you don't but your brain is actually making choices all the time that's why people
who study decision making you know think they're studying the whole brain because they they are actually so I think you
have to be really careful about there are words that we use in English and in
science that have two meanings they can have a meaning that is about decision
making or choice that is just obligatory automatic and a function of how the
system works and then there's the kind of choice that feels deliberate and effortful and where we feel like we're
the agents we experience ourselves as the agents and intentionality usually
can be assigned to the second one but actually in truth in philosophical terms it can also be assigned to the first
that when you even if you're completely unaware of having made a choice you're
acting on something with some degree of volition because you you it's not a
reflex it's not like you know somebody hit your patellar tendon and nuke it and so it's really interesting so you know I
think you just have to you have to make that distinction and I probably should get to the next question we can question yeah thank you yep yeah so you've been
asked a lot of esoteric questions about AI but I think we might gain some insights by wondering about di that is a
dog intelligence oh sure so I believe I sort of understand what
my dog is feeling and III usually believe that my dog you know believes
the same but not the same with you know a cat because you're not a cat person
yeah sure I mean you know I'm not I don't know that much about monkeys but
I've never really seen a monkey be able to make the expressions that let's say a dog can and I was wondering if you had
any insights about you know why dogs are able to do this and why we're able to read dogs is it something just simple
like they're they have the right facial muscles or is it something some drive that allows them to learn this so I
think before I wrote my book I would have answered this question differently but now here's what I would say I think
what you know many creatures on this planet have effect right and we can
debate about whether you know I just came across a paper the other day about whether fly you know just your Safa I
have have effect and you know it's I mean it's actually really interesting question they certainly they have something like opioids and they you know
so it's consistory question but dogs dogs are really interesting because they
do seem to have some capacities that only that you only see in in great apes
and they may have capacities that great apes even other than us don't have and I
mean so they certainly have some capacities we don't have either but but here's my point we actually bred them we bred these
animals we selected them basically it's not natural selection it's it's you know
artificial selection and we selected them for a couple of things right if you look at the experiments on breeding
taking a fox you know taking foxes and breeding them into what looked like little dog like animals it's interesting
what they can do and one of the things they can do is they can move their facial muscles and in in in a lot of
ways that they have a lot more control over their facial muscles then you know chimpanzees and
do and and other apes and they also do
they do joint attention really well with gays so this is something that really no
other animal can do I think other than a dog other and humans and that is they
can they they meet your gaze and they use gaze for reference so you know
they'll look at something and they'll look back at you and you you know that's actually partly that's how we communicate with each other chimpanzees
lose that ability after about ten or eleven months a year overall of age but
but dogs continually do it and actually joint attention shared gaze is how we
communicate with our infants also that's actually partly how we teach infants about what's important in the world is
with gaze so I think that dogs may actually have some capacities probably
because we bred them to have those but we selected the animals that you know
and bred them to have those capacities that's very interesting again awesome well with that let's give these a big
hand thank you so much

----------

-----
--31--

-----
Date: 2018.02.16
Link: [# Sacha Arnoud, Director of Engineering, Waymo - MIT Self-Driving Cars](https://www.youtube.com/watch?v=LSX3qdy0dFg)
Transcription:

today we have the director of engineering head of perception at way mo a company that's recently driven over
four million miles autonomously and in so doing inspired the world in what
artificial intelligence and good engineering can do so please give a warm
welcome to Sasha our new [Applause]
thanks a lot Lex for the introduction well it's it's a pretty packed house
thanks a lot I'm really excited thanks a lot for giving me the opportunity to to
be able to come and share my passion with the Seb driving cars and be able to
share with you all the great work we've been doing at Weimer over the last 10
years and give you more details on the recent milestones we've reached
so as you see we'll cover a lot of different topics some more technical
some more about context but when either
the content I have three main objectives that that I'd like to convey today so
keep that in mind as we go through the through the presentation my first one is is to give you some background around
the self-driving space and what's happening there and what it takes to build self-driving cars but also give
you some some behind the scene views and tidbits on on the history of machine
learning deep learning and how it how it all came together within the big alphabet family from Google to way moe
another piece obviously another objective I have is to give you some
technical meat around the techniques that are working today on our self-driving cars so I think during the
the class you hear a lot you've heard a lot about different different deep
learning techniques models architectures algorithms and I try to put that in a
current hole so that you can you can see how those pieces fit together to build a system we have today and has been at
least I think as Lex mentioned it takes a lot more actually than
algorithms to build a sophisticated system such as our self-driving cars and
fundamentally it takes a a food industrial project to make that happen
and I'll try to give you some color with which hopefully is it are different from from what you've heard during the week
I'll try to give you some color on what it takes to actually pan out such an
industrial project in real life and make an essentially productionize machine learning so we hear a lot of talk we
hear a lot about self-driving cars it's a very hot topic and for very good
reasons I can tell you for sure that 2017 has been a great year for whammo
actually only a year ago in January 2017 when Moe became its own company so that
was a major milestone and a testimony to the to the robustness of distribution so that we could move to a product product
is Asian phase so what you see on the picture here is our latest generation
self-driving vehicle so it is based on on the chrysler pacifica you can already
see a bunch of sensors I'll come back to that and give you more more insights on what they do and how they operate but
that's that that's the latest and greatest so self-driving indeed is draws
a lot of attention and for very good reason I personally believe and I think
you will agree with me that self-driving really has as the potential to deeply
change the way we look about mobility and the way we move people and things
around so only to cover a few aspects here obviously that and I want to go
into too many details but safety is one of is one of the the main motivations
94% of us crashes today involve human errors a lot of those errors are around
distraction and things that could be avoided so safety is a big piece of it
disability and access to mobility is also a big motivation of ours
so obviously the the self-driving technology has the potential to make it
very available and cheaper for more people to to be able to move around and last but not least is efficiency a
collective efficiency so not only we spend a lot of time in our cars in in
long commute hours I personally spend a lot of time in on commit hours and that
time we spend in traffic probably could be better spent doing something else than having to drive to grab the coin in
complicated situations beyond beyond traffic obviously the self-driving
technology has the potential to deeply change the way we think about traffic parking spots urban environments city
design so that that's why it's a very exciting topic so that's why we made it
our our mission at Waco is fundamentally to to make it safe and easy to move
people and things around so that's a nice mission and we've been on it for a
very long time so actually the whole adventure started close to 10 years ago
in 2009 and at the time that was that starting under the umbrella of a Google
project that you may have heard of called chauffeur and back back back in
those days so remember we were before the deep learning days at least in the industry and so really back in those
days the the first the first objective of the project was to try and assemble first product a vehicle take
off-the-shelf sensors assemble them together and try to go and decide if
self-driving is even a possibility it is like it's one thing to to have some prototype somewhere but is that even a
thing that that that is worth pursuing which is a very common way for Google to to tackle problems so the genesis for
that work was to come up with a pretty aggressive objective
so the team the first milestone for the team was to essentially assembled 10100
my loops in Northern California around around Mountain View and try and figure
out so for a total of 1,000 miles and try and and see if they could build
first system that that would be able to go and drive those loops autonomously so
they were not afraid so the team was not afraid so those loops went through some
very aggressive patterns so you see that some of those loops go through the Santa
Cruz Mountains which is an area in California that as you'll see I'll show you a video that has very small roads
and two-way traffic and cliffs with negative obstacles and complicated
patterns like that some of those some of those paths were going on highways so
that and one of the the busiest highways some of those routes were going around
Lake Tahoe which is which is in the Sierras in California where you can
encounter different kinds of weather and again different kinds of roads conditions those routes were going
around bridges and the Bay Area has quite a few bridges to go through though
some of them were even going through a dense urban area so you can see San
Francisco being driven you can see Monterey some of the Monterey centers
being driven and as you see on the video those bring those truly bring dense
urban area challenges so since I promised it so here you're
gonna see some pictures of the driving and it's kind of working
so here with better quality so here you see the the roads I was talking about on
the mountain on the Santa Cruz Mountains driving in the night animals crossing the street freeway driving going through
patos just another area that is Charlie dance there's a aquarium there pretty
popular one that's the famous lombard street in san francisco that you may have heard of which in San Francisco
always brings unique set of challenges between fog and slopes and in that case even shop turns so that was all the way
back in 2010 so those ten loops were
successfully completed 100% autonomously back in 2010 so that's more than eight
eight years ago so on that on the heels of that success the team decided and
Google decided that self-driving was worth worth pursuing and moved and moved
forward with the development of the technology and and testing so we've been
at it for all those years and have been working very hard on it historically
way more and and and I think what the other companies out there have been relying on what we call safety drivers
to still sit behind the wheels even if the car is is driving autonomously you
still have a safety driver was able to take over at any time and make sure that we have very separations and and we've
been a committed my eyes and knowledge and developing the system many iterations of the system across all those enoguh lose years we reached a
major milestone as Lex mentioned back in back in November where for the first
time we reached a level of confidence and maturity in a system that we felt
confident and proved to ourselves that it was safe to remove the safety driver
as you can imagine that's that's a major milestone because it takes a very high
level of confidence to not have that backup solution of a safety driver to take over or something to arise so here
I'm gonna show you a small video a quick quick capture of that event so that the
video is from one of the first times we did that since then we've been continuously operating drug arrest cars
self-driving cars in the Phoenix area in Arizona to expand our testing so here
you can see the video swing so you can see our chrysler pacifica so here we
have members of the team who are acting as the passengers getting on a backseat there is you can notice that there is no
driver on the driver's seat so here we are running car having kind of service
so the passenger simply press the button the application knows where they want to go and the car goes nope no one on the
driver seat so we started with a fairly constrained geographical area in
Chandler close to Phoenix Arizona and we
we are hard working to expand testing and the scope of our operating area
since then so that goes well beyond a
single car a single day not only we do that continuously but we also have a growing fleet of self-driving cars that
we are deploying there all the way and looking for a product launch pretty quickly so I've talked about 2010 and we
are in 2018 and were getting there but what it took it took quite a bit of time so I think one of the one of the key
ideas that I'd like to convey here today and that I will I will go back to during
representation is how much work and how much work it takes to really take a demo
or something that's working in a lab into something that you feel safe to put on the roads and get all the way
to that to that depth of understanding that depth of perfection in your
technology that that you operate safely so one way to say that is that when you
are 90% done you still have 90 percent to go right so 90% of the technology takes only 10% of the time right in
other words you need to 10x right you need to 10x the the capabilities of your
technology you need to 10x your team size and find ways for more engineers and more researchers to collaborate
together you need to 10x the capabilities of your sensors you need to 10x fundamentally the overall quality of
the system right and your testing practices as we'll see and a lot of the aspects of the program and that's what
we've been that's what we've been working on so beyond the context of
self-driving cars I want to spend a little bit of time to give you kind of a
kind of an inside of view of the rise of deep learning Sumer I mentioned that
back in 2009 2010 deep learning was not ready available yet in full capacity in
the industry and so over those years actually it took a lot of breakthroughs
to to be able to reach that stage and one of them was the Agora algorithm
breakthrough that deep learning gave us and I'll give you a little bit of of backstage view on what happened at
Google during those years so as you know Google has been as committed itself to
machine learning and deep learning very early on you may have heard of the Google brain what we call internally the
Google brain team which is which is a team fundamentally hard at work to lead
the bleeding edge of research which is known but also leading the development
of the tools an infrastructure of the whole machine learning ecosystem at at Google and level to essentially low many
teams to develop machine learning at scale all the way to successful products so they've been working and pushing
that the deep learning technology has been pushing the field in many in many directions from computer vision to
speech understanding to NLP and all those directions are things that you can
see in Google products today so whether you're talking real assistant or Google photos speech recognition or even Google
Maps you can see the impact of deep learning in all those areas and actually
many years ago I was part of I myself was part of the street view team and I
was leading the what an internal program an internal project that we call the street smart and the good we had at
sweet smart was to use deep learning and machine learning techniques to go and
analyze Street imagery and as you know that that's a very big and varied corpus so that we could extract elements that
are core to our mapping strategy and build and that way build a better Google Maps so for instance in that picture so
that's that's a panorama or piece of a panorama from Street View imagery and
you can see that there are a lot of pieces in there that if you could find and and properly localized would
drastically help you build better maps so street numbers obviously that are really useful to map addresses street
names that when combined event on similar techniques from our views will
help you properly draw all the routes and give a name to them and those two combines actually allow you to do very
high quality address book apps which is a common query on Google Maps general text
and more specifically text on business facades that allow you to not only may be localized business listings that you
may have gotten by other means to actual physical locations weather so build some of those local listings directly from
scratch and and more traffic oriented patterns traffic whether it's traffic
lights traffic signs that can be used then for for ETA navigation ETA predictions and stuff like that so that
was our mission one of the as I mentioned one of the hot piece is to do
is to map addresses at Cal and so you can imagine that we had a breakthrough
when we first were able to properly find those street numbers out of the Street
View imagery and out of the facade solving that problem actually requires a lot of pcs not only you need to find
what where the the street number is on the facade which is if you think about
it a fairly hard semantic problem right what what's the difference between a street number versus another kind of
number versus other auto text but then obviously read it because there's no
point having pixels if you cannot understand the number that that's on on the facade all the way to properly draw
geo localizing it so that you can put it on on Google Maps and so the first
deepening application that that succeeded in production and that's all the way back to 2012 that we had the
first system in production was really the first breakthrough that we had across across alphabet on our ability to
properly understand real scene situations so here I'm gonna show you a
video that kind of sums it up so look every one of those segments is actually
a view from starting from the car going to the physical number of all those
house numbers that we've been able to detect and transcribe so here that's in Sao Paulo and well you can see that when
all that data is put together gives you a very consistent view of the addressing scheme so in in
so that's another example say similar things obviously we have more that in Paris where we are doing more imagery so
more views of those of those physical numbers that when you if you are going to triangulate you're able to do
localize them very accurately and have very accurate maps so the last example I'm going to show is in Cape Town in
South Africa where again the impact of that deep learning work has been huge in
terms of quality so many countries today actually have up tuned more than 95% of
addresses maps map to that way so doing similar things service you can see a lot
of parallelism between that work on 3d imagery and doing doing the same on the
real scene on the car but obviously doing that on the car is even harder is
even harder because you need to do that rigor time and and very quickly with low
latency and you also need to do that in in an embedded system right so the cars
have to be entirely autonomous you cannot rely on a connection to a Google
Data Centers and first you don't have the time in terms of latency to bring data back and forth but also you cannot
rely on a connection to for the safe operation of your system right so you need to do the processing within the car
but very so that's a that's a paper that you can read that dates all the way back
to 2014 where for the first time by using slightly different techniques we
were able to put deep learning at work inside inside that that constrained real-time environment and start to have
impact and in that case around a pedestrian detection so as I said there
are a lot of analogies you can see that to properly drive that scene like Street
View you need to find you need to see the traffic light you need to understand if the light is red or green and that's
what that's what essentially will allow you to to be at processing obviously driving is even more challenging beyond the
real-time and if you saw the cyclist going through so you have air stuff happening on the scene that you need to
detect and properly understand interpret and predict and at the same time he expressed explicitly took a night
driving example to show you that while you can choose when you take pictures of
street view and do it in in data I mean perfect conditions driving requires you
to take the conditions that they are and you have to deal with it so there has
been for from the very early beginning there's been a lot of cross pollenization
between the real scene work so here I took a few papers that we did in Street
View that obviously if you read them you see directly apply to some of the stuff we do on the cars well obviously that
collaboration between Google research and wham-o historically went well beyond
studio only and across all the resort groups and that still is a very strong collaboration going on that enables us
to be to stay on the bleeding edge right off of what we can do so now that we we
looked a little bit at how things happened I want to spend more time and and go into more of the details of
what's going on in the cars today and how deep learning is actually impacting
our current system so I think during the if I looked at the cursors properly I
think during the week you went through the major pieces that that you need to master to make a self-driving car so I'm
sure you heard about mapping localization so putting the car within those maps and understanding where you
are with it's pretty good accuracy perception scene understanding which is
a higher-level semantic understanding of what's going on in the scene starting to predict what the agents are going to do
around you so that you can do better motion planning obviously it is a whole robotics aspect at the end of the day
the car in many ways acts like a robot whether it's around the sensor data or
even the control interfaces to the car and for every one was was dead with
Holloway on robotics you will agree with me that that it's not a perfect world
and you need to deal with with with those errors other pieces that we may
have talked about is around simulation and essentially validation of whatever
system you put together so obviously machine learning and the planning have been having a deep impact in a in a
growing set of those areas but for the next for the next minutes here I'm going
to focus more on the on the perception piece which is which is a core element of what the self-driving car needs to do
so what is what is perception so fundamentally set perception is assist
in a system in the car that needs to build an understanding of the world around around it and it does that using
two major inputs the first one is prior on the scene so
for instance to give you an example it would be a little silly to to have to recompute the actual location of the
road the actual interconnectivity of the intersections of every intersection when
once you get on the scene because those things you can pre-compute you can pre-compute in advance and save your
onboard computing for all the tasks that are more critical so really so that's
often referred to as the mapping exercise but really it's about reducing the computation you're going to have to
do on on the car watch once it drives the other big input obviously is what
sensors are going to give you once you get on the spot so since your data is the is the the signal that's going to
tell you what is not like what you mapped and the things is the traffic light right or green where where are the
pedestrians where are the cars what are you doing so as we saw on the initial picture we
have quite a set of sensors on our self-driving cars so they go from vision
systems radar and later how the other three big families of sensors we have
one point to note here is is that they are designed to be complimentary right
so they are designed to be complimentary first in there in the localization on the car so we don't put them in the same
spot because obviously blind spots is is a major issues and and and you want to
have good coverage of the field of view the other piece is that there are
complementary India capabilities it's so for instance to give you an example cameras are going to be very good to
give you a dance representation it's like it is very dense set of information
it contains a lot of semantic information right you can you can see you can really see
a big number of a large number of details but Francis they are not really good to give you depth or it's much
harder computer and computer additionally expensive to get depth
information out of camera systems so systems like a lidar for instance will give you very good very good
when you hit when you hit objects will give you a very good depth estimation but obviously they're going to lack a
lot of the cementing information that you will find on camera systems so all those sensors are designed to be
complimentary in terms of their capabilities it goes without saying that
the better your sensors are the better your perception system is gonna be right
so that's why at way more we we took the path of designing our own sensors
in-house and and and and enhancing what's available of the shell today
because it's important for us to go all the way to be able to build a
self-driving system that we could believe in and so that's what perception
does take those two inputs and build a representation of the scene right so at
the end of the day you have to realize that that in nature that work of
perception is really what differentiates deeply differentiates what you need to
do in a safe driving system as opposed to a lower lower level driving
assistance system in many cases France we do speed control speed cruise or if
you do a lot of lower lower level drug resistance a lot of the strategies can
be around not bumping into things if you see things moving around you you group
them you segment them appropriately in blocks of moving things and you don't hit them you're good enough in most
cases when you don't have a driver on the dragon seat obviously the challenge totally changes scale so to give you an
example for instance if you're if you're on the lane and and you see a bicyclist going small slowly on the right on the
under on the lane right of you and there's a car and next to you you need to understand that there's a chance that
that car is going to want to avoid that bicyclist is going to swerve and you need to anticipate that behavior so that
you can you can properly decide whether you want to slow down give space for the car or speed up and have the car go
behind you those are the kinds of behaviors that go well beyond not bumping into things and that require
much deeper understanding of the world are going that's going on around you so
let me put it in picture and and we come back to that example in a court case so here is a typical scene that we
encountered at least so so he obviously you have a police car pulled over
probably pulled over someone there you have a cyclist on the road moving
forward and we need to drive through that situation so the first thing you
can do you have to do obviously is the basics right so out of your sensor data understand that a set of point clouds
and pixels belong to the cyclist find that you have two cars on the scene the
police car and the car park in front of it understand the policeman as a pedestrian so basic level of
understanding obviously you need a little more than that you need to go deeper in your semantics obviously you
need if you understand that the the flashing lights are on you understand
that the police car is becoming an Eevee and and it's performing something on the
scene if you understand that this car is parked and we see this a variable piece of information that's going to tell you
whether you can pass it or not something you may have not noticed is that there
are so cones so there are cones here on the scene that would prevent you for instance to go and drag that pathway if
you wanted to next level of getting closer to behavior prediction
obviously if you if you also understand that actually the police car has an open
door then all of a sudden you can start to expect it behavior where someone is gonna get over that car right and and
the way you swerve even if you were to decide to swerve or the way someone getting up out of that car would impact
the trajectory of the cyclist is something you need to understand in order to properly and safely Drive and
only then only when you have that that depth of understanding you can start to come up with realistic behavior
predictions and trajectory predictions for all those agents in the in on the scene so that you can come up with a
proper strategy for your planning control so how is a deep learning
playing into that whole space and how he is a deep learning impacting used to
solve many of those problems so remember when I said when you're 90%
down you still have 90% to go so I think that's not that starts to beat us I also
talked about how robotics and having sensors in real life is not a perfect world so actually it is
a big piece of the puzzle so I wish sensors would give us perfect data all
the time and we would give us a perfect picture that we can do reality use to do a deep learning but unfortunately that's
not how it works so here for instance you see an example where you have a
pickup truck so the imagery doesn't show it but you have a smoke coming off the out of the
exhaust and you have exhaust that's triggering a light our laser points
right not very relevant for your for any behavior prediction or for your driving
behavior so those points obviously and it's safe to go and drive through them
all right so those are very safe to ignore in terms of sin understanding
right so filtering the whole whole bunch of data coming off your sensors is is a
very important task because that reduces the computation you're gonna have to do whether Sookie to do to operator safely
a most more subtle one but important one are around reflections so we are driving
a scene there's a there's a car here on the camera picture the car is reflected in a bus and if you just do naive
detection especially that if the bus goes moves along with you and everything
move which is very typical and everything moves then you can have all of a sudden thing and have two cars on the scene and and if you take that car
too seriously all the way to impacting your behavior obviously you're gonna make mistakes right so here I showed you
an example of reflections on the on the visual range but obviously that affects
all sensors in slightly different matters but you could have the same effect for instance with a light our data where for instance when you drive
you drive a freeway and you have a road sign on top of the freeway that will reflect in the back window of the car in
front of you right and then showing a reflected sign on the road you better
understand that the thing you see on the road is actually a reflection and not try to swerve around and trying to avoid
that thing on the only sixty five miles per hour trajectory
so that's a big that's a big complicated challenge but assume we are able to get
to a proper sensor data that we can start the process with our machine
running so by the way a lot of the a lot of the the signal processing PC is
actually already used machine learning and deep learning too because as you can see Francis in the reflection space you
need to at the end of the day you can do some tricks to understand the difference in the signal but at the end of the day
at some point for some of them you're gonna have to understand to have a higher level of understanding of the scene and realize it's not possible that
the car is hiding behind the bus and given my field of view for instance but assuming you have do the sensor data
filter I would sensor data the very next thing I want to do is typically is apply
some kind of convolution layers on top
of that of that imagery so follow if you're not familiar with convolution
layers so that's that's a very popular way to do computer vision because it
relies on on connecting neurons with kernels that are gonna run that are
gonna learn layer after layer features of the imagery right so those kernels
typically work locally on this on this on region of the image and they can understand how they can understand lines
they can understand contours and as you build up layers are going to understand higher and higher levels of future
representations that ultimately will tell you what's happening on the on the image that's a very common technique and
much more efficient we slid and fully connected layers for instance that wouldn't work but unfortunately a lot of
a lot of the state of the art is actually in 2d convolutions right so again they've been developed on on
imagery and typically they require a fairly dense input rights so for an
imagery a crate is great because pixels are very dense you always have a pixel next to the next one there is not a lot
of void if you were for instance to think if you were to to plain convolutions on on a very sparse
laser point Swensen then you would have a lot of holes and those don't work nearly as well so typically what we do
is to first project sensor data into 2d planes and do processing on those so two
very typical views that we use the first one is a top-down so broad view is going
to give you a Google Maps kind of view of the scene so it's great for instance to to map up to map cars and objects
moving along along the scene but they don't it's harder to put imagery pixels
imagery you saw from the car into those top-down views so there's another famous
one common one that that is the driver view it's a projection onto the the
plane from the driver's perspective that are much better at utilizing imagery
because this essentially that's how imagery imagery got captured my name media news drone so here for instance you're gonna see
how you can if if your sensors are properly registered you can use both
lidar and imagery signals together to better understand the scene so the first
the first kind of processing you can do is is is what is called their
segmentation so once you have pixels or laser points you need to group them
together into together into objects that you can that you can then use for better
understanding and processing so unfortunately a lot of the objects you encounter while driving don't have a
predefined shape so here are two example of snow but if you think about vegetation or if you think about trash
bags for instance you can't you can't come up with
prior understanding on how they're gonna look like and so you have to be ready to have any shape of those objects so the
one of the techniques that works pretty well is to to build a smaller
convolution network that you're gonna slide across across Europe the protection of your sensor data so that's
the sliding window approach so here for instance if you have if you have a pixel
accurate snow detector that you slide across the image then you'll be able to
build a representation of those patches of snow and drag appropriately around
them so that works pretty well but as you can imagine is a little expensive
computation computation because it's like the if follow if you remember I
know if you if you've seen them actually it's like the old the whole the matrix printing it's like you had a printer and
it had to go and print the page point-by-point all right so it was pretty well but it's pretty slow
obviously but it's very analogous to that but it works pretty good so so that
was pretty well but you need obviously you need to be very conscious on which area of the of the of the scene you want
to apply it to to to stay efficient fortunately many of the objects you you
need to care about have predefined priors so Francis if you take a car from the bird from the top down view from the
birds view it's gonna be a rectangle you can you can take that that shape prior into consideration in most cases even on
the on the lanes on the driving lanes they're gonna go in in similar directions whether whether they go
forward or they come the other way they're gonna go in the direction of the lanes same for address and streets so
you can use those priors to actually do some more efficient deep learning that
in the literature is its convener the ideas of single-shot multi box constants
so so here again you would start with the convolution towers but what you do only one pass of convolution it's like
it's the same difference between a dot matrix printer and and press right that
would print a page at once it's not an allergy but I think that conveys the idea pretty well so here you
would train a deep deep net that would directly take the whole projection of just sensor data and output boxes that
that encode the pores you have so here for instance I can show you how such a
thing would work for cone detection so you can see that we don't have all the fidelity of the per pixel cone detection
but we not really care about that we just need to know there is a cone somewhere and we take a box prior and
obviously what what that image is also meant to show is that since it's a it's
a lot cheaper computed computationally you can obviously run that on a pretty wide range of space and and even if you
have a lot of them that's still easy the city is going to be a very efficient efficient way to get to get that data so
we talked about the member the flashing lights on top of the police car so even
if you if you properly detect and segment cars let's say on the road many
cars are very special semantics so here in that on that slide I'm showing you many examples of evie emergency vehicles
that you need to visually to understand you need to understand first that it is an Eevee and to whether the Eevee is
active or not so school births are not actually emergency vehicles but obviously whether the bus has lights on
or the bus has a stop sign open on the side carry heavy semantics that you need
to understand so how do you deal with that back to the deep learning techniques one thing you could do is is
take that patch build a new convolution tower and be the classifier on top of
that and essentially build a school bus classifier a school bus with light sound
classifier a school bus with stop sign open classifier I'm pretty sure that would work pretty well but obviously it
would be a lot of work and and pretty pretty expensive to run on the car because we need to and convolution
convolution layers typically are the most expensive pieces of a neural net so
one better thing to do is to use to use embeddings so if you're not familiar with it
embeddings essentially are vector representations of objects that you can
learn with deep nets that will that really carry some semantic meaning of those objects so for instance you've
given given a vehicle you can build a vector that's gonna carry the
information that that vehicle is a school bus whether the lights are on whether the stop sign is open and then
you you're back into a vector space which is much smaller much more efficient that you can operate in to do
further further processing so those embeddings have been actually historically they've been more closely
associated with word embeddings so in a typical text if you were able to build
those vectors with word alt of words right so out of every word in a piece of text you'll be the vector that
represents the meaning of that world and then if you look at the sequence of those words and operate in the vector
space you start to understand the semantics of those sentences right so
one of the early projects that you can look at is called work to Veck which was which was done in a DNP group at Google
where they were able to beat such things and and and they discovered that that embedding space actually carried some
interesting vector space properties such as if you took the vector for king- the
vector for man plus the vector for women actually you ended up with a vector whether the closest word to that vector
would be Queen essentially right so so that's to show you how those those vector representations can be very
powerful in the amount of information you can they can contain let's talk
about pedestrians so we talked about semantics image segmentation remember so
the ability to go pixel by pixel for for things that that don't really have a shape we talked about using shape priors
but pedestrians actually combine the complexity of those of those two
approaches for many reasons one is that they
obviously they are deformable and pedestrians come with many shapes and
poses as you can see here I think here you have a guy on someone on the on the
skateboard crouching more more unusual poses that you need to understand and
the recall you need to have on pedestrian is very high and pedestrians show up in many different situations so
for instance here you know clearly pedestrians that you need to see because that's a good chance when you when you
do your behavior prediction that that person here is gonna jump out of a car I need to be ready for that so last but
not least predicting the behavior of pedestrian is really hard because they
move in any direction that car moving that direction you can safely bet connect it's gonna it's not a drastic keychain angle in in a moment's notice
right but if you take children for instance it's a little more complicated right so they may not pay attention they
may jump in any direction and you need to be ready for that so it's harder in terms of shape prior it's harder in
terms of recall and it's also harder in terms of prediction right then you need to have a fine understanding of the
semantics to understand that another example here is that we encountered is
you get to an intersection and you have a visually impaired person that's jaywalking on the intersection and you
obviously need to understand all of that to know that you need to yield to that person pretty clearly so person on the
road maybe you should yield to it to him not easy so for instance here so there
is actually I don't I don't know if it's a real person or a mannequin or something right so but here we go
something that frankly really looks like a pedestrian that you should probably classify the pedestrian but lying on the
on the bed of a pickup truck so and obviously you shouldn't yield to that
person right because if you if you were to and yielding to a pedestrian at 35 miles per hour for instance ease is
hitting the brakes pretty hard right and with with the risk of where we are we New York Region so obviously you need to
understand that that that person is travelling with a truck and he's not
actually on the road and it's okay to not hear - to him so those are examples
of the rich region of the semantics you need to understand obviously one way to do that is to start and understand the
behavior of things over time everything we talked about up until now in the how we use deep learning to solve some of
these problems was on a pure friend basis but understanding that that person is moving with the truck versus the
jaywalker in the middle of the intersection viously do that kind of information you can get to if you
observe the behavior of a time back to the embeddings so if you had vector if
you have vector representations of those objects you can start and track them over time so a common technique that you can use
to get there is to use a recurrent neural networks that essentially are networks that will build a state that
gets better and better as it gets more observation sequential observations of for your pattern right so for instance
coming back to the to the world's example I gave her earlier you can you see you have one word you see its vector
representation another one the sentence saying you understand more but what did some what the author is trying to say
third word fourth word at the end of the sentence you had a good understanding and you can start to translate Winston's
right so he has a similar idea if you if you understand if you have a semantic
representation and coding in an embedding for the pedestrian and the car under it and track that over time and
build a state you that that gets more and more meaning as time goes by you're
going to get closer and closer to the to a good understanding of what's going on in the scene right so my my point here
is those vector representation combined with recurrent neural networks is a
common technique that that can help you figure that out
back to the point when you're 90% done you still have 90% to go and so to get
to the last leg of my talk here today I want to give you some appreciation for
what it takes to truly build a machine learning system at scale and in
sterilize it so up till now we talked a lot about algorithms as I said earlier
algorithms have been a breakthrough and and the efficiency of those algorithms has been a breakthrough for us to
succeed the self-driving task but it takes a lot more than algorithms to
actually get there the first piece that
you need to 10x is ease around labeling efforts so a lot of the algorithms we
talked about are supervised meaning that even if you have a strong Network attack
sure and you come up with the right one there are supervised in the sense that you need you need to give in order to to
train that network you need to come up with a representative set high-quality set of label data that's gonna map some
input to predict the output you want it to predict right so that's a pedestrian that's a car that's a pedestrian that's
a car and and the network will learn in a supervised way how to build the right
representations so there's a lot obviously the unsupervised space is a very active domain of research our own
team of research at wham-o and collaboration with Google is around either on that domain but today a lot of
it still is revised so to give you orders of magnitude so here represented in a logarithmic scale
the size of a couple data sets so you may be familiar with image net which i think is the 15 million of such labels
range that guy jumping represents number of seconds from birth to collect
correlation pre-cutting suing and so that's that's kind of that's more of an
historical tidbit but the first member the find I
the hustle the street number on the facade problem so in the back in those
days it took us a multi billion label data set to actually teach the network
right so those were very early days today we do a lot more a lot better obviously but that's to give you an idea
of scale so being able to put to have labeling operations that produce large
and high quality label data sets is key for your success and that's a big piece of the puzzle you need to solve
so obviously today we do a lot more better not only we require less data but
we also can generate those data set much much more efficiently you can use
machine running itself to come up with labels and use operators and more importantly use ibrain models where you
use labels to to more and more fix the discrepancies or the mistakes and I'll
have to label the whole thing from scratch so combining so that's a whole space of active learning and stuff like that
combining those those techniques together obviously you can get you can get to completion faster it's very
common to still need so that in the minions minions range kind of same pose to train a robust solution another piece
is around computation compute computing power so again that's that's that's kind
of a historical tidbit around the street number models so here it's a detection
model and here is the transcriber model so obviously comparison is not is only
worth what it's worth here but if you look at number of neurons or number of connections per neuron which are two
important parameters of a Fenny neural net that gives you an idea of scale it's
obviously it's many orders of magnitude away from what the human brain can do but you start to be competitive in
invent in some cases in the in the Mon space right so again historical historical data but
the main point here is that you need a lot of computation and you need a you need to have access to a lot of
computing to either train or an infer those train models on real time on the
sea and that requires a lot of very robust engineering an
infrastructure development to get to those to those scales but Google is
pretty good at that and and obviously we at Wayne who have access to the Google infrastructure and tools to essentially
get there so I know if you heard so the way the way it's happening at Google is around a
tensorflow so maybe you've heard about about it as a moral programming language
to program machine learning and and
encode network architectures but actually tensorflow is also becoming or
is actually the whole ecosystem that can combine combine all those pcs together
and do machine learning at scale at Google my mo so it's as I said it's a
language that allow teams that allows teams to collaborate and work together that's a data representation in which
you can represent your your label data sets for instance or your training batches
that's a runtime that that that you can deploy on to Google Data Centers and you
need you need it's good that we have access to that computing power another piece is his accelerators so back in the
early days when we had CPUs to 1d planning models at scale which is less
efficient and over time GPUs came into the mix and and and Google is proactive
into developing very advanced set of hardware accelerators so you have heard
about GPUs tensorflow processing units which has which are proprietary chipsets
that rule deploys in its data centers that are you to train and infer more efficiently this deep learning models
and tensorflow is the glue that allows you to deploy at scale across those
those pcs very important piece to get there so it's nice you're smart you
build we build a smart algorithm we were able to collect enough data to to train
it great ship it well self-driving system is pretty
sophisticated and that's a complex system to understand and that's a complex system
that that requires extensive testing and I think the last leg that you need to
cover to do machine learning at scale and and with a high safety bar is around
your testing program so we have three legs that that we that we use to make
sure that we our machine running is ready for production one is around we are what driving another one is around
simulation and the last one is around a structured testing so I'll come back to that in terms of we are about driving
obviously there is no way around it if if you want to encounter situations and
see and understand how you behave you need to drive so as you can see the
driving at way mo has been accelerating over time still accelerating so we crossed three million minds driven back
in May 2017 and only six months later back in November we reached four million
so that's an accelerating pace obviously not every mind is equal and what you
care about are the mice that carry new situations and important situations so what we do obviously is driving in many
different situations so those mice got acquired across 20 cities many weather conditions and many
environments it's forming a lot so to give you another of magnitude so that's when about 60 times around the globe
okay even more importantly it's not to point it's hard to estimate that's
probably around 300 years of human driving equivalent all right so so in
that data set potentially you have 300 years of experience that your machine learning can tap into to learn to learn
what to do even more importantly is your
ability to simulate obviously the software changes regularly so if for
each new revision of the software you need to go and we drive four million miles it's not very practical it's going
to take a lot of time so the ability to to good enough simulation that you can
replay all those miles that you've driven in any new iteration of the software is key for you to decide if the
new version is ready or not even more important is your ability to to make
those mozzie more even more efficient and tweak them so here is a screenshot of an internal tool that we call a car
craft that essentially gives us the ability to fast or change the parameters
of the actual scene we've driven so what if the cars were doing in a slightly different speed
what if there was an extra car that that was on the scene what if a pedestrian crossed in front of the car so so you
can use the actual live on Mars as a base and then augment them into new
situations that you can test your drive again your sub running system against so
that's a very powerful way to actually drastically multiply the impact of any animal you drive and simulation is
another of those massive scales project that you need to cover so a couple
orders of magnitude here so using Google's infrastructure we have the ability to run a vehicle fleet of 25,000
cars 24/7 in data centers so those those are those are software stacks that
immolate the driving across either roll miles that we've driven or modified miles that help us understand the
behavior of a software so do you another of magnitude last year alone we drove 2.5 billion of those
miles in in data centers right so remember four million driven miles total all the way to 2.5 so that's three
orders of magnitude of expansion in your in your ability to truly understand how
the system behaves but there's still a long tail there's a whole tail or a long
tail of situations that will happen very rarely so the way we decided to tackle
those is to set up our own testing facility that is a mark of of a city and
driving situation so we do that in a in a 90 acre testing facility on former Air
Force Base in to California that we set up with traffic lights railroad crossings I mean
truly trying to reproduce a real-life situation and where we set up very
specific scenarios that we haven't necessarily encountered during our guitar driving that but that we want to
test and again feedback into the simulation we augment using the same illumination strategies and an inject
into our 2.5 billion miles driven so here I'm gonna show you two quick examples of such tests so here just just
have a cab back up as the self-driving car get gets close and see what happens and use all those sensor data to and we
inject them into simulation another example is going to be around people dropping boxes so remember try to
imagine the kind of understanding segmentation you need to do to understand to understand what's
happening there and cementing understanding you have and to make it even more interesting note that the car
that has been put on the other side so that swerving is not an option right without hitting the car alright so
driving complex situations that go from perception to motion planning the whole stack and make sure that we are really
ball even in those long time ignore that examples and we're done it looks like a
lot of work I wish but no actually we still have we still have a lot of very
interesting work coming someone have much time to go into too many of those details but I'm just gonna give you two
the directions the first one is around growing our what we call OD d so
operating operating the main operating design domain so extending extending our
our fleet of the driving cars not only geographically so draw graphically meaning going into deploying into urban
cores deploying into different weather conditions so just as of this morning on
yesterday we announced that we we're gonna grow testing in San Francisco for instance with way more
cars that bring urban environments slopes fog as I said and so that's
that's obviously a very very important direction that we need to go into and
where machine learning is going to keep playing a very important role another area is around the cementing
understanding so in case you have an obvious haven't noticed yet I'm from
France that's a that's a famous roundabout in Paris + delete well which
seems pretty chaotic but I've driven it many times without any issues touching
wood but I know that it took a lot of semantics and an understanding for me to
do it safely I have a lot I had a lot of expectations and what people do had a
lot of communication visual gestures to essentially get it get through that that
thing safely right so and those require a lot of a lot of a lot deeper semantic
understanding of the scene around - for self-driving costume to get through so that's an example of a direction so back
to my objectives I hope I covered many of those at least you have you have directions to for further reading and
investigations on those those three objectives I had I had today first one
was around context context of the space context of the history at Google in way mo and and how and how deep the roots
the roots are of the way back in time my second objective was to give you to tie
in some of the technical algorithmic solutions that you may have talked about during that class into the practical
cases we need to solve in the production system and that's been at least really emphasize the scale and the engineering
infrastructure work that needs to happen to really take such a project into into
attrition in a production system last tweet
that's a scene with a kids on jumping on bags and as Frogger
of course the scene and I think we have time for a few questions
[Applause]
since tend to fail at this intersection between perception and planning so your planner might assume something about a
perfect world that perception cannot deliver so what's wondering if you use the simulation environment also to induce
these perception failures or whether that's really specific for scenario you're testing and whether you have
other validation arguments for the perception side very good question so
one thing I didn't mention is that the simulator obviously enables you to simulate many different layers in a
stack and one of the one of the hardcore engineering problems is to actually properly design your stack so that you
can isolate and test independently like like any dear August piece of software you need to have to have good aps and
layers so we have we have such a layer in in our system between perception and
planning and the way you write the way we test perception is more by measuring the performance of your part of your
perception system across more of the real miles and and use and tweak the the
output of the perception system with its mistakes so having having good understanding of the mistakes it make and reproduce those mistakes
realistically in the new scenarios you would come up with a part of your simulator to realistically test your
planning side of the planning side of the house conceived at scale and product
produced at scale do you have a systematic way of creating the
architectures of the embedded system you have so many choices for sensors algorithms each problem you showed has
many different solutions that's gonna create different interfaces between each elements so how do you choose which
architecture you put in a car that's that's true for any complex software
stack so there's a combination of different things so the first thing obviously that
I didn't talk too much here but it's around the vast amount of research that
we do that way mo but also we do in collaboration with Google teams to
actually understand even what building blocks we have at we are at our disposals to to even play with right and
come up with those production systems the other piece is obviously the one you
decide to take all the way to production so you're right so the the two big
elements here I would say the first one and the main element Frank frankly is is in your ability to so that that's that
that search actually will takes a lot of people to get to right so something I
try to say is that to really part of the the second 90% is your ability to grow
your team and essentially grow the number of people will be able to productively participate in your
engineering project and and that's where the the robustness we need to bring into
our development environment our testing is really key to be able to grow that
that team has that the biggest scale and essentially explore all those paths and come up with the best one right and at
the end of the day the the robustness of testing is the judge that's what tells
you whether an approach works not it's not a philosophical philosophical debate
thank you for your talk so the car is making a decision at every single stop
time you know on direction and speed and part of the reason why you have the simulation is so that you can test that
those decisions in every every like possible scenario so once self-driving cars become you
know production ready and out on the streets do you expect that the decision will be made based on prior
understanding of every single situation with which is possible or can the car
make a new decision in real time based on its scene understanding and everything around it
so I at the end of the day it's the goal of the system is not to to build a
library that a library of events that you can reproduce by one by one and make
sure that you encode if the analogy machine learning would be overfitting it's like if you if you if you
encountered five situations I'm pretty sure you can hard code the perfect thing
you need to do in those five situations but the sixth one happened if you don't generalize actually is gonna fall
through so the really the complexity of what you need to do is extract the core
principles that make that make you safely drive and and have the algorithms
learn those principles rather than the specifics of any situation because as
you said the parameter space of a real scene is infinite okay so we try to
first that a little bit with with the simulator what if the cars went little faster or slower but the goal is not to
enumerate all possibilities and make sure we dwell on those but the goal is to bring more diversity to the learning
of those general principles that will be run by the system or will be coded in a system for for the car to behave
properly and generalized when a new system new situation occurs okay okay
fantastic talk one of the questions I had was you mentioned the difficulty of
identifying snow because they could come in many different shapes one things that I immediately thought of was I know was
just an urban legend but it was that urban legend about the Inuit having like 150 different words for snow and you
mentioned embeddings of objects do you think one possible approach might be to
create a much wider array of object embeddings for things like snow I mean
if you're many different types of snow could actually have pretty different
impacts on driving whether it be just like a flurry or if it were be Thea kind
of like a really heavy blizzard like we we just had yeah I think from
if you look at it from from an algorithmic point of view that that may
make sense but maybe something I'd like to emphasize a little more is the the
very hard line to walk is to walk the line of what's a greatly possible
weather so what computationally feasible in the car right I think so too
to two points on on your on your remark so if you had the processing power to
process every point or every every to that to a load level of understanding and had the computing power to do that
maybe that would be an approach but that's that would be very expensive and that's a hard thing to do even more
importantly having fine sense it wouldn't make sense to have a behavior prediction of every snowflake of the
things you see on the side of the road right then and you need to group that's the whole point of segmentation you need to group what you see into semantic
objects that are likely to exhibit exhibit behavior as a whole and reason
at that level of abstraction to have a meaningful semantic understanding that you need to drive essentially right so
yeah it's an in-between last question
make it a good one thanks for the talk so if you're using perception for your
scene understanding are you worried about like adversarial examples or things that have been demonstrated or do
you can't believe that this like a real-world attack that could be used for perception based systems so generally
speaking yeah I think I think even beyond even before your saw your attacks
errors I mean errors can happen right there and Harris happen in every mode so
I think a prime example of that which is not adversarial is the reflection case it's like you could as well have put a
sticker on the car on the bus and say you're confused do you think it's a car it's not the car but you don't need to
put a sticker on the bus it's like the real life already brings a lot of those examples right so it's really the way
out is to way the first one is to to have sensors that complement each other
all right so I try to emphasize that but really different sensors or different
systems are not going to make the same mistakes and so they're gonna complement each other and that's a very important piece of redundancy that will be built
into the system the other one is is also even in a refraction case is is isn't
the understanding so so the way you as a human wouldn't be fooled is because you understand and you know it's not it's
not a thing as that can happen the same way you know that Cal reflecting in the bus there's no way you can see through
the bus and of a real car behind it so that level of an of semantic understanding is what is what he's gonna
tell you what what what is true and what is not or what is a mistake an error in your stack right and so similar patterns
apply we'd like to thank you very much Sasha Anu for coming to MIT

----------

-----
--30--

-----
Date: 2018.02.14
Link: [# Ray Kurzweil: Future of Intelligence | MIT 6.S099: Artificial General Intelligence (AGI)](https://www.youtube.com/watch?v=9Z06rY3uvGY)
Transcription:

welcome to MIT course 6 s 0 9 9 artificial general intelligence today we
have Ray Kurzweil he is one of the world's leading inventors thinkers and
futurists with a 30-year track record of accurate predictions called the Restless
genius by The Wall Street Journal and the ultimate thinking machine by Forbes magazine he was selected as one of the
top entrepreneurs by Inc magazine which described him as the rightful heir to Thomas Edison PBS selected him as one of
the 16 revolutionaries who made America Ray was the principal investigator of
the first ccd flatbed scanner the first omni font optical character recognition the first point to speech reading
machines for the blind the first text-to-speech synthesizer the first music synthesizer capable of creating
the grand piano and other orchestral instruments and the first commercially marketed large vocabulary speech
recognition among his many honors he received a Grammy Award for outstanding
achievements in music technology he's the recipient of the National Medal of Technology was inducted into the
National Inventors Hall of Fame holds 21 honorary doctorates and honors from
three u.s. presidents Ray has written five national best-selling books
including the New York Times bestsellers The Singularity is near from 2005 and how to create a mind from 2012 he is
co-founder and Chancellor of singularity University and a director of engineering at Google heading up a team developing
machine intelligence and natural language understanding please give ray a warm welcome
[Applause] [Music]
it's good to be back I've been in this lecture hall many times and walked the
infinite Carter I came here as an undergraduate in 1965 within a year of
my being here they started a new major called computer science it did not get
its own course number that's 6 1 even biotechnology recently got its own
course number but how many of you are CS majors ok how many of you do work in
deep learning how many of you have heard of deep learning here I came here first
in 1952 when I was 14 I became excited
about artificial intelligence it had only gotten its name six years earlier
the 1956 Dartmouth conference by Marvin Minsky and John McCarthy so I wrote
Minsky a letter there was no email back then and he invited me up he spent all
day with me as if he had nothing else to do he was a consummate educator
I then and the AI field had already bifurcated into two warring camps the
symbolic school which Minsk II was associated with and the connectionist
school was not widely known in fact I think it's still not widely known that Minsk II actually invented the neural
net in 1953 but he had become negative about it largely because there was a lot
of hype that these giant branes could solve any problem
so the first popular neural nets the perceptron was being promulgated by
Frank Rosenblatt at Cornell so Minsky set out what are you going now and saying I said to see Rosenblatt at core
now is that don't bother doing that and I went there and Rosenblatt was touting
the perceptron that it ultimately would be able to solve any problem so I brought some printed letters that had
the camera and it did a perfect job of recognizing them as long as they were courier ten different types I didn't
work at all and he said but don't worry we can take the output of the perceptron or feed it as the input to another
perceptron and take the output of that and feed it to a third layer and as we add more layers it'll get smarter and
smarter and generalize and so that's interesting if you even tried that well no but it's high on our research agenda
things did not move quite as quickly back then as they do now he died nine
years later never having tried that idea turns out to be remarkably prescient I
mean he never tried multi-layer neural nets and all the excitement we see now
about deep learning comes from a
combination of two things both many layer neural Nets and the law
of accelerating returns which I'll get to a little bit later which is basically the exponential growth of computing so
that we can run these massive nets and handle massive amounts of data it would
be decades before that idea was tried several decades later three level neural
nets were tried there were a little bit better they could deal with multiple type styles still weren't very flexible
that's not hard to add other layers it's a very straightforward concept there was
a math problem the disappearing gradient or the exploding gradient which I'm sure
many of you are familiar with basically you need to take maximum advantage of
the range of values in the gradients and
not let them explode or disappear and lose the resolution that's a fairly
straightforward mathematical transformation with that insight we could now go 200 layer neural nets and
that's behind sort of all the fantastic gains that we've seen recently
alphago trained on every online game and
then became a fair go player it then trained itself by playing itself and
soared past the best human alphago zero started with no human input at all
within hours of iteration sort Pascal
phago also soared past the best just programs they had another innovation
basically you need to evaluate the quality of the board at each point they used another hundred layer neural nets
to do that evaluation so there's still a
problem in the field which is there's a motto that life begins at a billion
examples one of the reasons I'm at Google is we have a billion examples for examples of
pictures of dogs and cats that are labeled so you got a picture of a cat and it says cat and then you can learn
from it and you need a lot of them alphago trained on a million online
moves that's how many we had of master games and that only created a sort of
fair go player a good amateur could defeated so they worked around that in
the case of go by basically generating an infinite amount of data by having the
system play itself had a chat with Denver's house office you know what kind
of situations can you do that with you have to have some way of simulating the world so go or chess are even though go
is considered a difficult game it's a-you know the definition of it can exist on one page so you can simulate it
that applies to math I mean amass axioms are can be contained on a page or two
it's not very complicated it gets more difficult when you have real-life situations like biology so we have
biological simulators but the simulators on perfect so learning from the simulators will only be as good as the
simulators that's actually the key to being able to do deep learning on biology
autonomous vehicles you need real-life data so the way mo systems have gone
three and a half million miles that's good that's enough data to then create a very good simulator so the
simulator is really quite realistic because they had a lot of real-world experience and the they've got a billion
miles in the simulator but we don't always have that opportunity to either
create the data or have the data around humans can learn from a small number of
examples your significant other your professor your boss your investor can
tell you something once or twice and you might actually learn from that some humans have been reported to do that
and that's kind of the remaining advantage of humans now there's actually
no back propagation in the human brain it doesn't use deep learning it uses a
different architecture that same year in 1962 I wrote a paper how I thought the
human brain worked there was actually very little neuroscience to go on there was one neuroscientist Vernon mount
Castle that had something relevant to say which as he did I mean there was a the common wisdom at the time and
there's still a lot of neuroscience that says say this that we have all these different regions of the brain they do different things they must be different
there's v1 in the back of the head where the optic nerve spills into that can
tell that that's a curved line that that's a straight line does these simple
feature extractions on visual images it's actually a large part of the neocortex does the fusiform gyrus up
here which can recognize faces we know that because if it gets knocked out
through injury or stroke people can't recognize faces they will learn it again with a different region of the neocortex
is the famous frontal cortex which does language in poetry and music so these
must work on different principles he did autopsies on the neocortex and all these different regions and found they all
looked the same they had the same repeating pattern same interconnections he said neocortex is neocortex so I had
that hint otherwise I can actually observe human brains in action which I
did from time to time and there's a lot of hints that you can get that way for
example if I ask you to recite the alphabet you actually don't do it from A to Z you do it as a sequence of
sequences ABCD efg hijk so we learn
things that secret forward sequences of sequences forward because if I ask you to recite the alphabet backwards you
can't do it unless you learn that as a new sequence so these are all interesting hints I wrote a paper that I
that the neocortex is organized as a hierarchy of modules in each module can
learn a simple pattern and that's how I got to meet President Johnson and that
initiated a half-century of thinking about this issue I came to MIT to study
with Marvin Minsky actually came for two reasons one the Minsky became my mentor
which was a mentorship that lasted for over 50 years the fact that MIT was so
advanced it actually had a computer which the other colleges I considered
didn't have it was an IBM 7090 for 32 K
of 36 bit words so it's 150 K of course storage to microsecond cycle time two
cycles for instructions or a quarter of a myth and that thousands of students
and professors shared that one machine in 2012 I wrote a book about this thesis
is now actually an explosion of neuroscience evidence to support it the European brain reverse engineering
project has identified a repeating module about a hundred neurons it's repeated three hundred million times
it's about 30 billion neurons in the neocortex the neocortex is the outer layer of the brain that's part where we
do our thinking and they can see in each module axons coming in from another
module and then the output acts the single output accent of that Jil goes as the input to another module
so we can see it organized as a hierarchy it's not a physical hierarchy
it's the hierarchy comes from these connections the neocortex is a very thin structure it's actually one module thick
there's six layers of neurons but it constitutes one module and we can see
that it learns in simple pattern and various reasons I cite in the book the
pattern recognition model that's using is basically a hidden Markov model how
many of you have worked with Markov models okay
that's usually no hands go open I asked that question but Markov model is not it
is learned but it's not back propagation it can learn local features so it's very
good for speech recognition and the speech recognition network I did in the 80s used these Markov models that became
the standard approach because it can deal with local variations so the fact
that a vowel is stretched you can learn that in a Markov model it doesn't learn
long distance relationships that's handled by the hierarchy and something
we don't fully understand yet is exactly how the neocortex creates that hierarchy but we have figured out how it can
connect this module to this module does it then grow I mean there's no virtual
communication or wireless communication it's actually connection so does it grow
an axon you know from one place to another which could be inches apart
actually they all all these connections are there from birth like the streets
and avenues of Manhattan there's vertical and horizontal connections so if the it decides and how it makes that
decision it's still not fully understood that it wants to connect this module to this module there's already a vertical
horizontal and a vertical connection it just activates them we can actually see
that now and I can see that happening in real time on non-invasive brain scans
so there's a current amount of evidence that's in fact the neocortex is a hierarchy of modules that can learn each
module learns a simple sequential pattern and even though the patterns we
perceived don't seem like sequences they may seem three-dimensional or even more complicated they are in fact represented
as sequences but the complexity comes in with the hierarchy so the neocortex
emerged 200 million years ago with mammals all mammals have a neocortex
it's one of the distinguishing features of mammals these first mammals were
small they were rodents but they were capable a new type of thinking other
non-mammalian animals had fixed behaviors but those fixed behaviors were very well adapted for their ecological
niche but these new mammals could invent a new behavior so creativity and
innovation was one feature of the neocortex so a mouse is escaping a predator its usual escape path is
blocked it will invent a new behavior to deal with it probably wouldn't work but
if it did work it would remember it and would have a new behavior and that behavior could spread virally through the community another Mouse watching
this was with say to itself that was really clever going around that rock I'm gonna remember to do that and it would
have a new behavior didn't help these early mammals that much because as I say
the non-mammalian animals were very well adapted to their niches and nothing much
happened for a hundred and thirty five million years but then 65 million years
ago something did happened there was a sudden violent change to the environment we now call it the Cretaceous extinction
event there's been debate as to whether it was a media or an asteroid I mean a
meteor or a volcanic eruption the asteroid or meteor hypothesis is in the
ascendancy but if you dig down to an area of rock reflecting 65 million years
ago the geologists will explain that it shows a very violent sudden change to the
environment we see it all around the globe so is a worldwide phenomenon the
reason we call it an extinction event is that's when the dinosaurs went extinct
that's when 75% of all the animal and plant species went extinct and that's
when mammals overtook their ecological niche so to anthropomorphize biological
evolution said to itself this neocortex is pretty good stuff and it began to grow it so-now mammals got bigger their
brains got bigger at an even faster pace taking up a larger fraction of their body the neocortex got bigger even
faster than that and developed these curvatures that are distinctive of a primate brain basically to increase its
surface area but if you stretched it out the human neocortex is still a flat structure it's about the size of a table
napkin just as thin and it's basically
created primates which became dominance in their ecological niche then something
else happened two million years ago biological evolution decided to increase the neocortex further and increase the
size of the enclosure and basically filled up the frontal cortex with our big skulls with more neocortex and up
until recently it was felt that as I said that this was the frontal cortex was different because it does these
qualitatively different things but we
now realize that it's really just additional neocortex so remember what we
did with it we're already doing a very good job of being primates so we put it at the top of the neocortical hierarchy
and we increased the size of the hierarchy it was maybe 20% more
neocortex but it doubled it tripled the number of levels because as you go up the hierarchy it's kind of like a
pyramid there's fewer and fewer modules and that was the enabling factor for us
to invent language and art music every human culture we've ever discovered has
music no primary culture really has music there's debate about that but it's really true
invention technology technology required another evolutionary adaptation which is
this humble appendage here no other animal has that if you look at a chimp and see it looks like they have a
similar hand but the thumb is actually down here doesn't work very well if you watch them trying to grab a stick so we
could imagine creative solutions yeah I could take that branch and strip off the
leaves and put a point on it and we could actually carry out these ideas and
create tools and then use tools to create new tools and it started a whole nother evolutionary process of
tool-making and that all came with the with the neocortex
so Larry Page read my book in 2012 and
liked it so I met with him in Essen for an investment in a company I'd started
actually a couple weeks earlier to develop those ideas commercially because that's how I went about things as a
serial entrepreneur and said well we'll invest but let me
give you a better idea what you do it here at Google we have a billion pictures of dogs and cats and we've got
a lot of other data and lots of computers and lots of talent all of which is true and says well I don't know
I just started this company to develop this is well by your company and how you
got a value a company that hasn't done anything just started a couple weeks ago and he said we can value anything so I
took my first job five years ago and I've been basically applying this model
this hierarchical model to understanding
language which i think really is the holy grail of AI I think Turing was
correct in designating basically text communication as what we now call a
turing-complete problem that requires there's no simple NLP tricks it you can apply to pass a valid Turing test with
an emphasis on the word valid mitch kapor and i had a six month debate on
what the rules should be because if you read Turing's 1950 paper he describes
this in a few paragraphs and doesn't really describe how to go about it but if it's a valid Turing test meaning it's
really convincing you through an interrogation and dialogue that it's a
human that requires a full range of human intelligence and I think that test
has to the test of time we're making very good progress on that I mean just
last week you may have read that two systems
asked paragraph comprehension test it's really very impressive winning came to
Google we were trying to past these paragraph comprehension tests we aced the first the first grade test second
grade tests were kind of got average performance and the third grade test had too much inference already you had to
know some common-sense knowledge as it's called and make implications of things
that were in different parts of the paragraph and there's too much inference and it really didn't didn't work so this
is now adult level it's just slightly surpassed average human performance but
we've seen that once something an AI does something it average human levels
it doesn't take long for it to soar past average human levels I think it'll take longer in language and it did in some
simple games like go but it's actually very impressive that it surpasses now
average human performance used at LST M long short temporal memory but if you
look at the adult test in order to answer these questions it has to put together inferences and implications of
several different things in the paragraph with some common sense knowledge is not explicitly stated so
that's I think a pretty impressive milestone so I I've been developing I've
got a team of about 45 people and we've been developing this hierarchical model
we don't use Markov models because we can use deep learning for each module
and so we create an embedding for each word and we create an embedding for each sentence this is we have a I can talk
about it because we have a published paper on it it can take into consideration context
if you use smart reply on G confused email on your phone you'll see it gives
you three suggestions for responses that's called Smart reply there are
simple suggestions but it has to actually understand perhaps a
complicated email and the quality of the suggestions is really quite good quite
on point that's for my team using this kind of hierarchical model so instead of
Markov models that uses embeddings because we can use back propagation we
might as well use it but I think what's missing from deep learning is this
hierarchical aspect of understanding because the world is hierarchical that's why evolution developed a hierarchical
brain structure to understand the natural hierarchy in the world
and there are several problems with big deep neural nets one is the fact that
you really do need a billion examples and we don't sometimes we can generate them it's in the case of NGO or if we
have a really good simulator as in the case of autonomous vehicles not quite the case yet in biology very often you
don't have a billion example if you suddenly have billions of examples of language but they're not annotated and
how would you annotate it anyway with more language that we can't understand in the first place so that's kind of a chicken and an egg problem so I believe
this hierarchical structures needed another criticism of deep neural Nets they don't explain themselves very well
it's a big black box that gives you pretty remarkable answers I mean in the
case of these games demos described it's playing in both go and chess is almost
an alien intelligence because we do things that were shocking to you and experts like sacrificing a queen and a
bishop at the same time or in close succession which shocked everybody but
then went on to win or early in a go game putting a piece at the corner of the board which is kind of crazy to most
experts because you really want to start controlling territory and yet it on reflection that was the brilliant move
that enabled it to win that game but it doesn't really explain how it does these
things so if yeah if you have a hierarchy it's much better at explaining it because you could look at the content
of the of the modules in the hierarchy and they'll explain what they're doing
and just and on the first application of
applying this to health and medicine this will get into high gear and we're going to really see us break out at the
linear extension to longevity that we've experienced I believe we're only about a
decade away from longevity escape velocity we're adding more time than is
going by not just the infant life expectancy but to your remaining life expectancy I think if someone is
diligent they can be there already I think I've at longevity escape velocity now a word
on what life expectancy means it used to be assumed that not much would happen so
whatever your life expectancy is with or without scientific progress it really
didn't matter now it matters a lot so life expectancy really means you know how long would you live what's the in
terms of a statistical likelihood if there were not continued scientific progress but that's a very inaccurate
assumption that scientific progress is extremely rapid I mean just as an AI in biotech there are advances now every
week is quite stunning now you can have a computed life
expectancies let's say 30 years 50 years 70 years from now you can still be hit
by the proverbial bus tomorrow we're working on that with self-driving vehicles but we'll get we'll get to a
point I think if you're diligent you can be there now in terms of basically advancing your own statistical life
expectancy at least to keep pace with the passage of time I think it would be there for
most of the population at least if they're diligent within about a decade
so if we can hang in there we may get to see the remarkable century ahead thank
you very much no question please raise
your hand we'll get your mic hi
so you mentioned both neural neural network models and symbolic models and I
was wondering how far have you been thinking about combining these two approaches creating a symbiosis between
neural models and symbolic ones I don't
think we want to use symbolic models as they've been used how many are familiar
with the psych project that was a very diligent effort in Texas
to define all of common-sense reasoning and it kind of collapsed on itself and
became impossible to debug because you fix one thing and it break three other
things that complexity ceiling has become typical of of trying to define
things through logical rules now it does seem that humans can understand logical
rules we have logical rules written down for things like law and game playing and
so on but you can actually define a connectionist system to have such a high
reliability on a certain type of action that it looks like it's a symbolic rule
even though it's represented in a connectionist way and connection systems
can both capture the soft edges because many things in life are not sharply
defined they can also generate exceptions so you you don't want to
sacrifice your queen in chess accept certain situations that might be a good idea so you can capture that kind of
complexity so we do want to be able to learn from accumulated human wisdom that
looks like it's symbolic but I think we'll do it with a connection system but
again I'm think the connection systems should develop a sense of hierarchy and
not just be one big massive neural net so I understand how we want you know use
the neocortex to extract useful stuff and commercialize that but I'm wondering how you know our middle brain and organs
that are below the neocortex will be useful for you know turn that into what
you want to do something well the cerebellum is an interesting case in point it actually has more neurons than
the neocortex and it's used to govern most of our behavior some things
if you write a signature that's actually controlled by the cerebellum so a simple sequence is stored in the cerebellum but
there's not many reasoning to it it's basically a script and most of our
movement now has actually been migrated from the center vellum to the neocortex cerebellum is still there some people
the entire cerebellum is destroyed through disease they still function
fairly normally their movement might be a little erratic as our movements is
largely controlled by the neocortex but some of the subtlety is a kind of pre-programmed script and so they'll
look a little clumsy but they're actually function okay a lot of other
areas of the brain control autonomic functions like breathing and but our
thinking really is is controlled by the neocortex in terms of mastering
intelligence I think the neocortex is the brain region we want to study I'm
curious what you think might happen after the singularity is reached in
terms of this exponential growth of information yes do you think it will
continue or will there be a whole paradigm shift what do you predict well
in the singularities near I talked about the atomic limits based on molecular
computing as we understand it and it can actually go well past 2045 and actually
go to trillions of trillions of times greater computational capacity than we have today
so I don't see that's stopping anytime soon and we'll go you know way beyond
what we can imagine and it becomes an
interesting discussion what the impact on human civilization will be so take it
may be slightly more mundane issue that comes up as a kind of eliminates most
jobs or jobs a point I make is it's not the first time in human history you've done
that how many jobs circa 1900 exist today and that was the feeling of the
Luddites which was an actual society that formed in 1800 the automation of the textile industry in England they
looked at all these jobs going away and felt that employment is going to be just limited to an elite indeed those jobs
didn't go away but new jobs were created so if I were oppression Futures to 1900
I would say well 38% of you work on farms and 25% work in factories it's 2/3
of the working force but I predict by
2015 115 years from now it's going to be 2% on farms and 9% factories and
everybody would go oh my God we're gonna be out of work and I said well don't worry for all these jobs we eliminate
through automation we're gonna invent new jobs and say oh really what new jobs and I'd say well I don't know we haven't
invented them yet that's the political problem we could see jobs very clearly
going away fairly soon like driving a car or truck and the new jobs haven't
been invented I mean just look at the last five or six years as many a lot of the increase in employment has been
through mobile app related types of ways of making money that just weren't
contemplated even six years ago if I really prescient I would say well you're
gonna get jobs creating mobile apps and websites and doing data analytics and
self-driving cars cars what's a car and nobody would have any idea what I'm
talking about now the new job some people say yeah we created new jobs
but it's not as many actually we've gone from 24 million jobs in nineteen hundred
242 million jobs today for 30 percent of the population to forty five percent of the population the new jobs pay eleven
times as much in constant dollars and they're more interesting and as I talk to people starting out their career now
they really want a career that gives them some life definition and purpose and gratification we're moving up Maslow's
hierarchy hundred years ago you were happy if you had a back-breaking job to put food on your family's table so and
we couldn't do these new jobs without enhancing our intelligence so we've been
doing that well for most of the last 100 years through education we've expanded
to K through 12 and constant dollars tenfold we've gone from 38,000 college students
in 1870 to 15 million today more
recently we have brain extenders and not yet connected directly in our brain but
they're very close at hand when I was here that my tía to take my bicycle across campus to get to the computer and
show an ID to get in the building now we carry them well you know in our in our
pockets and on our belts they're going to go inside our bodies and brains I think that's a notic really
important distinction but so we're basically going to be continuing to enhance our capability through merging
with AI and that's the I think ultimate answer to the kind of dystopian view we
see in futures movies where it's the AI versus a brave band of humans for control of humanity we don't have one or
two a eyes in the world today we have several billion three billion smartphones and last count will be six
billion in just a couple of years according to the projections so we're already deeply integrated with this and
I think that's going to continue and it's gonna continue to do things that you can't even imagine today just as we
are doing today things we couldn't imagine you know even twenty years ago you showed many graphs that goes through
exponential growth but I haven't seen one that isn't so I would be very interested in hearing you haven't seen
that what that is not exponential so tell me about regions that you've
investigated that have not seen exponential growth and why do you think that's the case well
price performance and capacity of information technology invariably follows a exponential when it impacts
human society it can be linear so for example the growth of democracy has been
linear but still pretty steady you can count the number of democracies on the fingers of one hand a century ago two
centuries ago you can count the number of democracies in the world on the fingers of one finger now there are
dozens of them that this and it's become kind of a consensus that that's how we should be governed
so the and I attributed all this to the growth and information technology
communication in particular for progression of social cultural
institutions but information technology because it ultimately depends on a
vanishingly small energy and material requirement grows exponentially and will
for a long time there's recently a criticism that well test scores have
it's actually a remarkably straight linear progression so humans think it's
like twenty eight hundred and it just sort passed out in 1997 with the blue and it's kept going and remarkably
straight and saying well this is linear not exponential but the chess score is a logarithmic measurement so it really is
exponential progression so if you're lhasa furs like to think a lot about the
meaning of things especially in the 20th century so for instance Martin Heidegger gave a couple of speeches and lectures
on the relationship of human society to technology and he particularly distinguished between the mode of
thinking which is calculating thinking and a mode of thinking which is reflective thinking or meditative
thinking and he posed this question what is the the meaning and purpose of
technological development and he couldn't find an answer he he recommended to remain open to what he
called and he called this an openness to the mystery I wonder whether you have
any thoughts on this is there is there a meaning of purpose to technological equipment and and is there a way for a
human success access that meaning well
we started using technology to shore up weaknesses and our own capabilities so
physically I mean who here could build this building so we've leveraged the power of our muscles with machines
and we're in fact very bad at doing things that you know the simplest computers can do like factor numbers or
even just multiply two eight digit numbers computers can do that trivially
we can't do it so we originally started using computers to make up for that
weakness I think the essence of what I've been writing about is to master the
unique strengths of humanity creating loving expressions in poetry and music
and the kinds of things we associate with the better qualities of humanity
with machines that's the to promise of AI that we're not there yet but we're
making pretty stunning progress just in the last year there's so many milestones that are really significant including in
language and but I think of technology
as an expression of humanity it's part of who we are and the human species is
already a biological technological civilization and it's part of who we are
an AI is it's part of humans so AI is
human and it's it's part of the technological expression of humanity and
we use technology to extend our reach you know I couldn't reach that fruit at
that higher branch a thousand years ago so we invented a tool to extend our physical reach we now extend our mental
reach we can access all of human knowledge with a few keystrokes and
we're going to make ourselves literally smarter by merging with AI hi
first of all honor to hear you speak here so I first read The Singularity is
near nine years ago or so and it changed the way I thought entirely but something
I think it caused me to over steeply discount was tail risk in geopolitics in
systems that span the entire globe and my concern is that there are there is
obviously the possibility of tail risk existential level events swamp in all of
these trends that are otherwise war proof climate proof you name it so my
question for you is what steps do you think we can take in designing
engineered systems in designing social and economic institutions to kind of
minimize our exposure to these tail risks and and and survive to make it to
UM you know a beautiful mind filled future yeah well the world was first
introduced to a human-made existential risk when I was in
elementary school we would have these civil defense drills to get under our desk and put our hands behind our head
to protect this from a thermonuclear war and it worked we made it through but
that was really the first introduction to an existential risk and those weapons
are still there by the way and they're still on a hair-trigger and they don't
get that much attention there's been a lot of discussion much of which I've
been in the forefront of initiating the existential risks of what sometimes referred to as GN rg4 genetics which is
biotechnology and for nanotechnology and gray goo robotics which is a
and I've been accused of being an optimist I think you have to be an
optimist to be an entrepreneur if you knew all the problems you were going to encounter you'd never start any project
but I've written a lot about the downsides I remain optimistic there are
specific paradigms and not foolproof that we can follow to keep these technologies safe so for example over 40
years ago some visionaries recognized the revolutionary potential both for
promise and peril of biotechnology neither the promise no peril was
feasible 40 years ago but they had a conference at the Asilomar conference
center in California and to develop both professional ethics and strategies to
keep biotechnology safe and they've been known as the Asilomar guidelines they've been refined through successive sell
more conferences much of that's baked into law and it in my opinion it's
worked quite well we're now as I mentioned getting profound benefit it's a trickle today it'll be a flood over
the next decade and the number of people who have been harmed either through intentional or accidental abuse of
biotechnology so far zero actually I take that back there was one boy who died in gene therapy trials but 12 years
ago and there's congressional hearings and they cancelled all research for gene
therapy for a number of years you could do an interesting master's thesis and demonstrate that you know 300,000 people
died as a result of that delay but you can't name them they can't go on CNN so we don't know who they are but it has to
do with the balancing of risk but in large measure virtually no one has been
hurt by biotechnology now that doesn't mean you can cross on our front list okay we took care of that one because
the technology keeps getting more sophisticated and Christopher's great opportunity there's hundreds of trials
of Christopher's technologies overcome disease but it could be abused you can
describe scenarios so we have to keep reinventing it January we had our first
Asilomar conference on AI ethics and so I think this is a good paradigm it's not
foolproof I think the best way we can
assure a democratic future that includes our ideas of Liberty is to practice that
in the world today because the future world of the singularity which is a merger of biological non-biological
intelligence it's not going to come from Mars I mean it's going to emerge from our society today so if we practice
these ideals today it's going to have a higher chance of us practicing them as we get more enhanced with technology if
that doesn't sound like a foolproof solution it isn't but I think that's the best approach in terms of technological
solutions I mean AI is the most daunting you can imagine there are technical solutions to
biotechnology and nanotechnology there's really no subroutine you can put in your
AI software there will assure that it remains safe intelligence it's
inherently not controllable there's some AI that's much smarter than you that's out for your destruction the
best way to deal with that is not to get in that situation in the first place if
if you are in that situation and find some AI that will be on your side but
basically it's going to eyeb Aleve we have been headed through technology
to event to a better reality look around the world and people really think things
are getting worse and I think that's because our information about what's wrong with the world is getting
exponentially better I say oh this is the most peaceful time on you in history if you say what are you crazy didn't you
hear about the event yesterday and last week and well a hundred years ago there
could be a battle that wiped out the next village in you wouldn't even hear about it for months of all these graphs on education and
literacy has gone from like 10% to 90% over a century and health wealth
poverty's declined 95% in Asia over the last 25 years document about the World
Bank all these trends are very smoothly getting better and everybody thinks things are getting worse but but but
you're right like on violence that curve could be quite disrupted there's an
existential event as I say I'm optimistic but I think that is something
if we need to deal with that a lot of it is not technological it's dealing with
our social cultural institutions so you
mentioned also exponential growth of software and IDs I guess related to software so one of the reasons for which
you said that all that information technology costs this exponential is because of fundamental properties of
matter and energy but in the case of ideas why would it have to be exponential well a lot of ideas produce
exponential gains they don't increase performance linearly there's actually
study during the Obama administration by his scientific advisory board on
assessing this question how much gains on 23 classical engineering problems
were gained through hardware improvements over the last decade and
software improvements and there's about a thousand to one improvement it's about doubling every year from Hardware there
was an averages of like twenty six thousand to one through softer improvements algorithmic improvements so
we do see both and apparently if you come up with in advance its it doubles
the performance or multiplies it by ten we see basically exponential growth from each innovation
so and we certainly see that in deep learning the architectures are getting
better while we also have more data and more computation and more memory to throw in these at these algorithms
thank you for being

----------

-----
--29--

-----
Date: 2018.02.08
Link: [# MIT AGI: Building machines that see, learn, and think like people (Josh Tenenbaum)](https://www.youtube.com/watch?v=7ROelYvo8f0)
Transcription:

today we have Josh Tenenbaum he's a professor here at MIT leading the computational cognitive science group
among many other topics and cognition and intelligence he is fascinated with
the question of how human beings learn so much from so little and how these
insights can lead to build AI systems that are much more efficient at learning from data so please give Josh a warm
welcome all right thank you very much
thanks for having me decided to be part of what looks like really quite a very impressive lineup especially starting
after today and it's I think quite a great opportunity to get to see perspectives on artificial intelligence
from many of the leaders in industry and other entities working on this this
great quest so I'm going to talk to you about some of the work that we do in our group but also I'm gonna try to give a
broader perspective reflective of a number of MIT faculty especially those who are affiliated with the Center for
brains minds and machines so you can see up there on my affiliation academically I'm part of brain and cognitive science
or course nine I'm also part of csail but I'm also part of the Center for brains minds and machines which is an
NSF funded Center Science and Technology Center which really stands for the bridge between the science and the
engineering of intelligence it literally straddles Vassar Street and that we have csail and DCs members we
also have partners at Harvard and other academic institutions and again what we stand for I want to try to convey some
of the specific things we're doing in the center and where we want to go with a vision that really is about jointly
pursuing the science the basic science of how intelligence arises in the human
mind and brain and also the engineering enterprise of how to build something increasingly like human intelligence in
machines and we deeply believe that these two projects have something to do with each other and our best pursued
jointly now it's really exciting time to be doing anything related to intelligence or certainly to AI for all
the reasons that you know brought you all here I don't have to tell you this we have all these ways in which AI is kind of finally here we finally live in
the era of something like real practical AI or for those who've been around for a
while and have seen some of the rises and falls you know AI is back in a big way but from my perspective and I think
maybe this reflects you know why we distinguish what we might call a GI from AI we we don't really have any real AI
basically we have what I like to call AI technologies which are systems that do things we used to think that only humans
could do and now we have machines that do them often quite well maybe even better than any human who's ever lived
right like a machine that plays go but none of these systems I would say are truly intelligent none of them have
anything like common sense none of them have anything like the flexible general-purpose intelligence that each
of you might use to learn every one of these skills or tasks right each of these systems had to be built by large
teams of engineers working together often for a number of years out often at great cost to somebody who's willing to
pay for it and each of them just does one thing so alphago might beat the worlds best but it can't drive to the
match or even tell you that go it what go is it can't even tell you the go is a
game because it doesn't even know what a game is right so what's missing why what what is it that makes every one of your
brains maybe you can't beat you know the world's best didn't go but any one of you can get behind the wheel of a car I
think of this because my daughter is gonna turn 16 tomorrow if she lived in California she'd have a driver's license
it's a little bit down the line for us here in Massachusetts but you know she
didn't have to be specially engineered by billion dollar startups and you know she got really into chess recently and
now she's taught herself chess by playing just you know a handful of games basically I mean she can do any one of
these activities and any one of us can so what is it what's that what makes up the difference well there's many things
right I'll talk about the the focus for us and our research and a lot of us
again in CBMM is summarized here um what what drives the success is right now in
AI especially in industry okay and all these AI technologies is many many things many things but what's what where
the progress has been made most recently and what's getting most of the attention is of course deep learning but other
kinds of machine learning technologies which essentially represent the maturation of a decades-long
for to solve the problem of pattern recognition that means taking data and finding patterns in the data that tells
you something you care about like how to label a class or how to predict some other signal okay
and pattern recognition is great it's an important part of intelligence and it's reasonable to say the deep learning as a
technology has really made great strides on pattern recognition and maybe even you know has coming close to solving the
problems of pattern recognition but intelligence is about many other things intelligence is about a lot more in
particular it's about modeling the world and think about all the activities that
a human does so model the world that that go beyond just say recognizing patterns and data but actually trying to
explain and understand what we see for instance okay or to be able to imagine things that we've never seen that never
seen maybe even very different from anything we've ever seen but might want to see and then to meet to set those as
goals to make plans and solve problems needed to make those things real or thinking about learning again the you
know some kinds of learning can be thought of as pattern recognition if you're learning sufficient statistics or weights in a neural net that are used
for those purposes but many activities of learning are about building out new models right either refining reusing
improving old models or actually building fundamentally new models as you've experienced more of the world and then think about sharing our models
communicating our models to others modeling their models learning from them all these activities of modeling these
are at the heart of human intelligence and it requires a much broader set of tools so I want to talk about the ways
we're studying these activities of modeling the world and something in a pretty non-technical way about what are
the kind of tools that allow us to capture these abilities now I think it's I want to be very honest up front and to
say this is just the beginning of a story right when you look at deep learning successes that itself is a
story that goes back decades I'll say a little bit about that history in a minute but where we are now is just looking forward to a future when we
might be able to capture these abilities you know at a really mature engineering scale and I would say we are far from
being able to capture the all the ways in which humans richly flexibly quickly build models of the world at the kind of
scale that say Silicon Valley wants either big tech companies like Google or soft or IBM or Facebook or small
startups right we can get there and I think what what I want to talk to you
about here is one route for trying to get there and this is the route that CBMM stands for the idea that by reverse
engineering how intelligence works in the human mind and brain that will give us a route to engineering these abilities in machines when we say
reverse engineering we're talking about science but doing science like engineers this is our fundamental principle that
if we approach cognitive science and neuroscience like an engineer where so the output of our science isn't just a
description of the brain or the mind in words but in the same terms that an engineer would use to build an
intelligence system then that will be both the basis for a much more rigorous and deeply insightful science but also
direct translation of those insights into engineering applications now I said before I talk a little about
history what I mean by that is is this again if if part of what brought you here is deep learning and I know even if
you've never heard of deep learning before which I'm sure is unlikely you saw some you know a good spectrum of
that in the in the overview session last night okay it's really interesting and
important to look back on the history of where did techniques for deep learning come from or reinforcement learning
those are the two tools in the in the current machine learning arsenal that are getting the most attention things like back propagation or end to end
stochastic gradient descent or temporal difference learning or cue learning here's a few papers from the literature
you know maybe some of you have read these original papers here's here's the original paper by rumelhart Hinton and
colleagues in which they introduced the back propagation algorithm for training multi-layer perceptrons right multi-layer neural networks here's the
original perceptron paper by Rosenblatt which introduced the one layer version of that architecture and the basic
perceptron learning algorithm here's the first paper on sort of the temporal difference learning method for
reinforcement learning from Sutton and Bartow here's the original Bolton machine paper also by Hinton and
colleagues which you know again is a those you don't know that architecture they give a kind of probabilistic
undirected multi-layer perceptron or for example before there were LS TMS if you
know about current recurrent neural network architecture earlier as much simpler versions of the same idea were proposed by Jeff Elman and his simple
recurrent networks the reason I want to put up the original papers here for you to look at both when they were
published and where they were published so if you look at the dates you'll see papers going back to you know the the
80s but even the 60s or even the 1950s and look at where they were published most of them were published in
psychology journals so the journal psychological review if you don't know it is like the leading journal of theoretical psychology and mathematical
psychology okay or cognitive science the Journal of the cognitive science Society or the the backdrop paper was published
in Nature which is a general interest science journal but by people who are mostly affiliated with an Institute for cognitive science in San Diego so what
you see here is already a long history of scientists thinking like engineers these are people who are in psychology
or cognitive science departments and publishing in those places but by formalizing even very basic insights
about how humans might learn or how you know brains might learn in the right kind of math that led to of course
progress on the science side but it led to all the engineering that we see now it wasn't sufficient right we needed we
needed of course lots of innovations and advances in computing hardware and software systems right but this is where
the basic the basic math came from and it came from doing science like an engineer so what I want to talk about in
our vision is what is the future of this look like if we were to look 50 years into the future what would we be looking back on now or you know over this time
scale well here's that here's a long-term research roadmap that reflects some of my ambitions and some of our
centers goals and many others too right we'd like to be able to address basic questions fundamental questions of what
it is to be and to think like a human questions for example of consciousness or meaning in language or real learning
right questions like you know even beyond the individual like questions of culture or creativity so our big ideas
up there and for each of these there are basic scientific questions right how do we become aware of the world in
ourselves in it starts with perception but it really turns into awareness awareness of yourself and of the world
and what we might call consciousness right or how does a word start to have a meaning what really is a meaning and how
does a child grasp it or how did children actually learn what do babies brains actually start with are they
blank slates or do they start with some kind of cognitive structure and then what is real learning look like these
are just some of the questions that were we're interested in working on or when we talked about culture we mean how do you learn all the things you
didn't directly experience right but that somehow you got from the accumulation of knowledge in society over many generations or how do you ever
think of new ideas or answers to new questions how do you think of the new questions themselves how do you decide what to think about these are all key
activities of human intelligence when we talk about how we model the world where our models come from what we do with our
models this is what we're talking about and if we could get machines that could do these things well again on the bottom row think of all the actual real
engineering payoffs now in our Center in both my own activities and a lot of what
my group does these days and what a number of other colleagues in the Center for brains minds and machines do as well as you know brought very broadly people
in VCS and csail one place where we work on the beginnings of these problems in the near term this is the long term like
think 50 years okay maybe short or maybe longer I don't know but think well beyond well beyond 10 years but in the
short term 5 to 10 years a lot of our focus is around visual intelligence and there's many reasons for that again we
can build on the successes of deep networks and a lot of pattern recognition and machine vision it's a
good way to put these ideas into practice when we when we look at the actual brain the visual system in the
brain in the human and other mammalian brains for example is really very clearly the best understood part of the
brain and at a circuit level it's the part of the brain that's most inspired current deep learning and neural network
systems but even there there's things which we still don't really understand like engineers so here's an example of a
basic problem in visual intelligence that we and others in the centre are trying to solve look around you and you
feel like there's a whole world around you and there is a whole world around you feel like your brain captures it but
what what the actual sense data that's coming in through your eyes looks more like this photograph here where you can
see there's a crowd scene but it's mostly blurry except for a small region of high resolution in the center so that
corresponds biologically to what part of the images in your fovea that's the central region of cells in the retina
where you have really high-resolution visual data the size of your phobia is roughly like if you hold out your thumb
at arm's length it's a little bit bigger than that but not much bigger right most of the image in terms of the actual
information coming in and a bottom-up sense to your brain is really quite blurry but somehow by looking at just one part
and then by secada around or making a few eye movements you get a few glimpses each not much bigger than the size of
your thumb at arm's length somehow you stitch that information together into what feels like and really is a rich representation of the whole
world around you and when I say around you I mean literally around you so here's another kind of demonstration um
without turning around nobody's allowed to turn around ask yourself what's behind you now the answer is going to be
different for different people depending on where you're sitting right for most of you you might think well there's I
think there's a person pretty close behind me all right you know you're in a crowded auditorium although you haven't seen that person you know that they're
there right for people in the very back row you know there isn't a person behind
you and you're conscious of being in the back row right you might be conscious that there's a wall right behind you but now for the people who are in the room
not in the very back think about how far behind you is the back like where's the nearest wall behind you so we can get
maybe we can call out try a little demonstration so I don't know I'm pointing to someone there can you see phrase say something if you think I'm
pointing at you well I could have been pointing at you but I'm pointing someone behind you okay I'll point to you yeah
I'm pointing to you all right so how far is the nearest wall no you can't turn around you've blown your chance right without turning around okay
so you you were laughs okay do you see I'm pointing to you there with the tie okay so without turning around how far
is the nearest wall behind you that's
sorry how far five meters okay well I mean that might be about right no other
people can turn around how about you how far is the nearest wall behind you
ten meters okay that might be right yeah how about here
how what do you think twenty okay see yeah since I didn't grow up in the metric system I barely know but yeah I
mean I mean the point is that like you're you're you each of you is is not
surely not exactly right but you're certainly within an order of magnitude and I guess if we actually tried to measure you know you're probably my
guess is you're probably right within you know fifty percent or less often you know maybe just twenty percent error okay so how do you know this I mean even
if it's not what did you say twenty meters even if it's not twenty meters it's probably closer to 20 meters than
it is to 5 or 10 meters and then it is 250 meters so how do you know this you haven't turned around in a while right
but some part of your brain is tracking the whole world around you right and how
many people are behind you yeah like a few hundred right I mean I don't know if it's 200 or 300 or but it's not a
thousand I mean I don't think so and it's certainly not ten or 20 or 50 right
so you track these things and you use them to plan your actions okay so again think about how instantly
effortlessly and very reliably okay your brain computes all these things so the people and objects around you and it's
not just you know approximations certainly when we're talking about what's what's behind you in space there's a lot of imprecision but when it
comes to reaching for things right in front of you very precise shape and physical property estimates needed to pick up and
manipulate objects and then when it comes to people it's not just the existence of the people but something about what's in their head right you
track whether someone's paying attention to you and you're talking to them what they might want from you what they might be thinking about you what they might be
thinking about other people okay so when we talk about visual intelligence this is the whole stuff we're talking about
and you can start to see how it turns into basic questions I think of not of what we might call the beginnings of
consciousness at least our awareness of ourself in the world and of ourselves as
a self in the world but also other aspects of higher-level intelligence and cognition that are not just about
perception like symbols right to describe even to ourselves what's around us and where we are and what we can do
with it you have to go beyond just what we would normally call the stuff of perception to say the thoughts in somebody's head and
your own thoughts about that okay so what we've been doing in CBMM is trying to develop an architecture for visual
intelligence and I'm not going to go into any of the details of how this works and this is just notional this is just a picture it's like a just a sketch
from a grant proposal of what we say we want to do but it's based on a lot of scientific understanding of how the
brain works there are different parts of the brain that correspond to these different modules in our architecture as well as some kind of emerging
engineering way to try to capture at the software and maybe even hardware levels how these modules might work so we talk
about a sort of an early module of a visual or perceptual stream which like bottom-up visual or other
perceptual input that's the kind of thing that is pretty close to what we currently have and say deep convolutional neural networks but then
we talk about some kind of the output of that isn't just pattern class labels but what we call the cognitive core core
cognition so we get an understanding of space and objects there physics other people their minds that's the real
stuff of cognition that has to be the output of perception but somehow we have to we have we have to have this is what
we call the brain OS in this picture we have to get there by stitching together the bottom-up inputs from glimpse here a
glimpse here a little bit here and there and accessing prior knowledge that comes from our memory systems to tell us how
to stitch these things together into the really core cognitive representations of what's out there in the world and then
if we're going to start to talk about it in language or to build plans on top of
what we have seen and understood that's where we talk about symbols coming into the picture ok the building blocks of
language and plans and so on so now we might say well ok this is an
architecture that is brain inspired and cognitively inspired and and we're planning to turn into real engineering
and you can say well do we need that maybe you know again I know this is a question you considered in the first lecture
maybe the engineering toolkit that's currently been making a lot of progress in let's say industry maybe that's good
enough maybe you know let's take deep learning but to stand for a broader set of modern pattern recognition based and
reinforcement learning based tools and say ok well maybe that can scale up to this and you might you know it but maybe
that's that's possible I'm happy in the question period of people want to debate this my sense is no I think that it's
not when I say no I don't mean like it can't happen or it won't happen what I mean is the highest value the highest
expected route right now is to take this more science-based reverse engineering approach and that if at least if you
follow the current trajectory that industry incentives especially optimized for it's not even really trying to take
us to these things so think about for example a case study of visual intelligence that is in some ways as
pattern recognition very much of a success it's again been mostly driven by industry it's something that if you read
in the Jews or even play around with in certain of it publicly available datasets feels
like we've made great progress and this is an aspect of visual intelligence which is sometimes called image
captioning it's bate or mapping images to text you know basically there's been
a bunch of systems here's a couple of press releases I guess this one's about Google Google's AI can now capture
images almost as well as humans here's ones about Microsoft a couple of years ago I think there were something
like eight papers all released onto archive around the same time from basically all the major industry computer vision groups as well as a
couple of academic partners okay which all driven by basically the same data set produced by some Microsoft
researchers and other collaborators trained a combination of deep convolutional neural networks you know
state of the art visual pattern recognition with recurrent neural networks which had recently been developed for you know basically kinds
of neural statistical language modeling glued them together and produced a system which which which made very
impressive results in a big training set and a held-out test set where the goal was to take an image and write a
sentence like a short sentence caption that that would seem like the kind of way a human would describe that image
and these systems you know surpassed human level accuracy on the held-out test set from a big training set but
what you can see when you really dig into these things is there's often a lot of what I would call data set overfitting it's not overfitting to the
training set but it's overfitting to whatever are the particular characteristics of this data set you know wherever ever came from certain set
of photographs and certain ways of captioning them okay which even a big data set it's not about quantity it's
more about the quality the nature of what people are doing all right so one way to test this system is to apply it
to what seems like basically the same problem but not within the a certain
curated or built data set and there's a convenient Twitter bot that lets you do this so there's something called the pic
desk bot which takes one of the state of the art industry AI captioning systems a very good one again this is not meant to
I'm not trying to critique these systems for what they're trying to do I'm just trying to point out what they don't really even try to do so this takes the
microsoft caption bot and just every couple of hours takes a random image from the web captions it and upload
the results to Twitter and a couple of months ago when I prepared a first version of this talk I just took a few
days in the life of this Twitter bot I didn't take every single image but I took you know most of the images in a
way that was meant to be representative of the successes and the kinds of failures that such a system will make so we can go through this and it's a little
bit entertaining and I think quite informative so here's just a somewhat random sample of a few days in the life
of one of these caption BOTS so here we have a picture of a person holding for
tonight my screen is very small here and I can't read up there so maybe you'll have to tell me was that but a person holding a cell phone I guess I'll just
read along with you so have a person holding a cell phone well it's not a person holding a cell phone but it's kind of close it's a person holding some
kind of machine so I don't even know what that is but it's some kind of musical instrument right
so that's a mixed success or failure here's some pretty good one a group of people on a on a field playing football
that's I would call that a you know a result maybe even A+ here's a group of
people standing on top of a mountain so less good there's a mountain but as far as I can tell there's no people but these systems like to see people because
of both the combination because in the data set they were trained on there's a lot of people and people often talk about people okay I mean and the fact
that you can appreciate both what I said and why it's funny that's there you did some of my cognitive activities that
this system is not even trying to do okay here we've got a building with the cake I'll go through these fast building
with the cake a large stone building with the clock tower I think that's pretty good I'd give that like a b-plus there's no clock but it's plausibly
right there might be a clock in there there's definitely something like that here's a truck parked on the side of a building I don't know maybe a b-minus
there there is a car on the side of a building but it's not a truck and it's and it's it's not doesn't seem like the
main thing in the image okay here's a necklace made of bananas here's
a large ship in the water this is pretty good I give this like an a-minus or b-plus because there is a ship in the
water but it's not very large it's really more of like a tugboat or something here's a sign sitting on the grass you know in some sense that's
great no but it but in another sense it's really missing what's actually interesting and important and meaningful to humans
here's a here's a garden is in the dirt a pizza
sitting on top of the building a small house with the red brick building that's pretty good although a kind of weird way of saying it a vintage photo of a pond
that's good they like vintage photos a group of people that are standing in the grass near a bridge again there's two people and there's some grass and
there's a bridge but it's really not what's going on a person in the yard okay kind of a group of people standing
on top of the boat there's a boat there's a group of people they're standing but again it's what the sentence that you see is is more based
on a bias of what people have said in the past about images that are only vaguely like this a clock tower is a
little at night that's really I think pretty impressive a large clock mounted to the side of the building a little bit less so a snow-covered feel very good a
building with snow on the ground a little bit less good there's no snow white some people who I don't know them
but I bet that's probably right because face identifying faces and recognizing people who are famous because they won
you know medals and the Olympics probably I would trust current pattern recognition systems to get that a painting of a base in front of a mirror
less good also a famous person there but we didn't get him a person walking in
the rain again there is sort of a person and there's some puddles but not you know a group of stuffed animals a car
parked in a parking lot that's good a car parked in front of a building less
good a plate with a fork and knife a clear blue sky okay so you get the idea again like if you actually go and play
with the system partly because I think Mike but my friends at Microsoft told me they've improved at some you know I this
is partly for entertainment values you know I chose what also would be the funnier example so I'm quite I want to
be quite honest about it and these are I'm not trying to take away what our impressive AI technologies but I think
it's clear that there's a sense of understanding any one of these images that it's important to see that even when it seems to be correct right if it
can make the kind of errors that it makes that even when it seems to be correct it's probably not doing what
you're doing and it's probably not even trying to scale towards the dimensions of intelligence that we think about when
we're talking about human intelligence okay another way to put this I'm going to show you a really insightful blog
post from one of your other speakers so in a couple of days I'm not sure you're going to have Andre Karpov a who's one of the leading people
in deep learning this is a really great blog post he wrote a couple of years ago
when he was I think still at Stanford he got his PhD from Stanford he did he worked at Google a little bit on some
early big neural net AI projects there he was an open AI he was one of the founders of open AI and recently he
joined Tesla as their director of AI research but about five years ago he was
looking at the state of computer vision from a human intelligence point of view and and lamenting how far away we were
okay so this is the title of his blog post the state of computer vision nai-nai we are really really far away
and he took this image which was a sort of a famous image in its own right it
was a popular image of Obama back when he was president kind of playing around as he liked to do when he was on tour so
if you take a look at this you can see you probably all can recognize the previous President of the United States
but you can also get the sense of where he is and what's going on and you might see people smiling and you might get the
sense that he's playing a joke on someone can you see that right so how do you know that he's playing a joke and
what that joke is well as Andre goes on to talk about in his blog post too if you think about all the things that that
you have to really deploy in your mind to understand that it's a huge list of course it starts with seeing people and
objects and maybe doing some face recognition but you have to do things like for example notice his foot on the
scale and understand enough about how scales work that when a foot presses down it exerts force that the scale is
sensitive doesn't just magically measure people's weight but it does that somehow through force you have to see who can
see that he's doing that and who can't who cannot see that he's doing that right in particularly the person on the scale and why some people can see that
he's doing that and can see that some other people can't see it why that makes it funny to them okay and someday we
should have machines that can understand this but hopefully you can see why what I would I what the kind of architecture
that I'm talking about would be the building blocks of the ingredients to be
able to get them to do that now I when I again I prepared a version of this talk a few months ago and I wrote to Andre
and I said I was gonna use this and I was curious if he how what you know if he had any reflections on this and where
he thought we were relative to five years ago because a certain a lot of progress has been made but he
said here's his email I hope he doesn't mind me sharing it but I mean again he's a very honest person and that's one of
the many reasons why he's such an important person right now in AI okay he's both very technically strong and honest about what we can do what we
can't do and as he says well what does he say it's nice to hear from you it's funny you should bring this up I was also thinking about writing a a return
to this and in short basically I don't believe we've made very much progress right he points out that in his long list of things that you'd need to
understand the image we have made progress on some the ability to again detect people and do face recognition for well-known individuals okay but
that's kind of about it all right and he wasn't particularly optimistic that the current route that's being pursued an industry is is anywhere close
to solving or even really trying to solve these larger questions um if we
give this image to that caption bot you know what we see is again represents the
same point so here's the caption bot it says I think it's a group of people standing next to a man in a suit and tie right so that's right right as far as it
goes it just doesn't go far enough and the current the current ideas of built a data set train a deep learning algorithm
on it and then repeat um aren't really even I would venture trying to get to
what we're talking about or here's another I'll just give you one other example of a couple of photographs from my recent vacation and a nice warm
tropical look how which I think illustrates ways in which again the gap where we have machines that can say beat
the world's best at go but can't even beat a child at tick-tack-toe now what do I mean by that well you know
of course we can build we don't even need reinforcement learning or deep learning to build a machine that can they can win or tie do is do optimally
in tic-tac-toe but think about this this is a real tic-tac-toe game which I saw on the grass outside my hotel right what
do you have to do to look at this and recognize that it's a tic-tac-toe game you have to see the objects you have to see what's you know in some sense
there's a three by three grid but it's but it's only abstract right it's only delimited by this these ropes or strings
okay it's not actually a grid in any simple geometric sense all right but yet
a child can look at that and indeed here's an actual child who was looking at it and recognized oh it's a game of tic-tac-toe and even know what they need
to do to win we put the X and completed and now they've got three in a row right that's that's literally child's play okay
you showed this sort of thing though to one of these you know image understanding caption BOTS and I think
it's a close-up of a sign okay again it's not like saying that this is a close-up of a sign is is not the same
thing I would venture as a as a cognitive or computational activity that's going to give us what we need to
say recognize the objects to recognize it as a game to understand the goal and how to plan to achieve those goals
whereas this kind of architecture is designed to try to do all of these things ultimately right and I bring in
these examples of games or jokes to really show where perception goes to
cognition you know that and all the way up to symbols right so to get objects and forces and mental states that's the
cognitive core but to be able to get goals and plans and what do I do or how do I talk about it that's symbols okay
here's another way into this and it's one that also motivates I think a lot of really good work on the engineering side
and a lot of our interest in the science side is think about robotics and think about what do you have to do to you know
what is the brain have to be light to control the body so again you're gonna hear from shortly I think maybe it's
next week from Mark raybert who's one of the founders of Boston Dynamics which is
one of my favorite companies anywhere they're without doubt the leading maker
of humanoid robots legged locomoting robots in industry they have all sorts of other really cool robots robots like
dogs robots that have all you know I think you'll even get to see a live demonstration of my new robots this
really awesome impressive stuff okay um but what about the minds and brains of
these robots well again if you ask mark ask them how much of human-like cognition do they have in their robots
and I think he would say very little in fact we have asked him that and he would say very little he has said very little
he's actually one of the advisors of our Center and I think in many ways were very much on the same page we both want
to know how do you build the kind of intelligence that can control these bodies like the way a human does alright
um here's another example of an industry robotics effort this is Google's arm farm where you know they've they've got lots
of robot arms and they're trying to train them to pick up objects using various kinds of deep learning and reinforcement learning techniques and I
think it's one approach I just think it's very very different from the way humans learn to say control their body
and manipulate objects and you can see that in terms of things that go back to what you were saying when you're introducing me right think about how
quickly we learn things right here you have these the arm farm is trying to generate you know effectively maybe if
not infinite but hundreds of thousands millions of examples of reaches and pickups of objects even with just a
single gripper and yet a child who in some ways can't control their body nearly as well as robots can be
controlled at the low level and is able to do so much more so I'll show you two of my favorite videos from YouTube here
which motivate some of the research that we're doing the one on the left is a one and a half year old and the other ones a
one year old so just watch this one and a half year old here doing a popular activity for many kids as a playing hmm
you see video up there I'd okay there we go okay so he's he's on doing this
stacking Cup activity alright he's stacking up cups to make a tall tower
he's got a stack of three and what you can see for the first part of this video is it looks like he's trying to make a
second stack and that he's trying to pick up at once basically he's trying to make a stack of two that'll go on the
stack of three and you know he's trying to debug his plan because it's it got a little bit stuck here but and think
about I mean again if you know anything about robots manipulating objects even just what he just did no robot can decide to do that and actually do it
right at some point he's almost got it it's a little bit tricky but at some point he's gonna get that stack of two
he realizes he has to move that object out of the way look at what he just did move it out of the way use two hands to
pick it up and now he's got a stack of two on a stack of three and suddenly you know subgoal completed he's now got a stack of five and he gives himself a
hand because he know he knows he accomplished a keyway point along the way to his final goal that's a kind of
early symbolic cognition right to understand that I'm trying to build a tall tower but a tower is made up of
little towers it's you know it can end and you can take a tower and put it on top of another tower or stack a stack on us
a can you have a bigger stack right so think about how he goes from bottom up perception to the objects of the physics
needed to manipulate the objects to the ability to make even those early kinds of symbolic plans at some point he keeps
doing this he puts another stack on there I'll just jump to the end oops sorry you missed it so he he gets
really excited and he gives himself another big hand but falls over okay again Boston Dynamics now has robots
that could pick themselves up after that that's really impressive again but all the other stuff to get to that point we
don't really know how to do in a robotic setting or think about this baby here this is a younger baby this is one of
the Internet's very most popular videos because it features a baby and a cat and
but the babies doing something interesting he's got the same cups but he's decided he's again decided to try a
new thing so this think about creativity he's decided that his goal is to stack up cups on the back of a cat I guess
he's asking how many cups can I fit on the back of a cat well three let's see can I fit more let's try another one
okay well he can't fit more than three it turns out and then he then does it's
not working so he changes his goal now his goal appears to be to get the cups on the other side of the cat now watch
that part when he reaches back behind him there that's I'll just pause it there for a moment umm someone he just reached back there
that's a particularly striking moment in the video it shows a very strong form of what we call in cognitive science object
permanence okay that's the idea that you represent objects as these permanent enduring entities in the world even when
you can't see them in this case he hadn't seen or touched that object behind him for like at least a minute
right maybe much longer I don't know and yet he still knew it was there and he was able to incorporate it in his plan
right there's a moment before that when he's about to reach for it but then he sees this other one right and it's only when he's now exhausted all the other
objects here that he can see he's like okay now time to get this object and bring it into play right so think about
what has to be going on in his brain for him to be able to do that right that's like the analog of you understanding
what's behind you okay um it's not that these things are impossible to capture machines far from it it's just that like
training a deep neural network or any kind of pattern recognition system we don't think is going to do it but we think by reverse engineering how it
works in the brain we might be able to do it I think we can can do it okay it's not just humans that do this kind of activity here's a couple
of again rather famous videos you can watch all of these on YouTube crows are famous object manipulators and
tool users but also orangutangs other primates rodents we can watch if we just
hey let me pause this one for a second if we watch this orangutan here he's got a bunch of big legos and over the course
of this video he's building up a stack legos it's really quite impressive
you're just jumping to the end there's actually some controversy out there of
whether this video is a fake but the controversy isn't about you know it's not like whether it was I don't know
dumb with computer animation some people think the video was actually filmed backwards that a human built up the
stack and the orangutan just slowly disassembled it piece by piece and it turns out it's remarkably hard to tell whether it's played forward or backwards
in time and people have argued over little details because you know it would be quite impressive if an orangutan actually was able to build up this
really impressive stack of Legos but I would submit that it would be almost as impressive if he disassembled it think
about the activity I mean if I wanted to disassemble that the easiest thing to do would just be to knock it over that's really all most robots could do
but to piece by piece disassemble it even if it's played backwards like this that's still a really impressive act of
symbolic planning on physical objects or here you've got this this famous Mouse this you can find on the internet under
the mouse versus cracker video and what you'll see here over the course of this video is a mouse valiantly and mostly
hopelessly struggling with a cracker that they're hoping to bring back to their nest I guess it's a very appealing
big meal and at some point after just trying to get it over the over the wall
at some point the mouse just gives up because it's just never gonna happen and he just goes away except that because
even Mouse's can dream or mice can dream some point he decides okay I'm just
gonna come out for one more try and he tries one more time and this time valiantly gets it over yeah isn't that
very impressive congratulations guys okay you don't have to clap form you can clap for me at the end or clap for
whoever later okay but I want to applaud the mouse there every time I see that okay but again think what had to be
going on in his brain able to do that all right it's a crazy thing and yet he formulated the goal and
was able to achieve it I'll just show one more video that is really more about science these other ones are you know
some of them actually were from scientific experiments but this is one that motivates a lot of the science that
I do and it's to me it sets up kind of a grand cognitive science challenge for AI and robotics it's from an experiment
with humans again eighteen month olds or one-and-a-half year old so the the kids in this experiment were the same age is the first baby I showed you the one who
did the stacking and 18 months is really a very very good age to study if you're interested in intelligence for reasons
we can talk about later if you're interested this is from a very famous experiment done by two psychologists
Felix Warren akin and Michael Tomasello and it was studying the spontaneous helping behavior of young children it
also contrasted humans and chimps and the punchline is that chips sometimes do things that are kind of like what this
human did but not nearly as reliably or as flexibly okay so not nearly it is and
I'll show you a particular kind of unusual situation where human kids had
relatively little trouble figuring out kind of what to do or even whether they should do it whereas basically no chimp
did what you're gonna see humans sometimes doing here so the experimenter in this movie I'll turn on the sound
here if you can hear it the experimenter is the tall guy and the participant is
the little kid in the corner there there there's sound but no words right and at
some point he stops and then the kid just does whatever they want to do so watch what he does he goes over he opens
the cabinet looks inside then he steps back and he looks up at felix and then
looks down okay and then the action is completed now well wonder I want you to watch it one more time and think about
what's gotta be going inside the kid's head to understand this to understand like so it seems like what it looks like
to us is the kid figured out that this guy needed help and helped him and the paper is full of many other situations like this this is just one OK but the
key idea is that the situation is somewhat novel people have seen people holding books and opening cabinets but
probably it's very rare to see this kind of situation exactly right it's different in some important details from
what you might have seen before and there's other ones in there that are really truly novel because they just made up a machine right there okay but somehow he has to understand
causally from the way the guy's banging the books against the thing that it's it's sort it's sort of both a symbol but
it's also somehow he's got to understand what he can do and what he can't do and then what the kid can do to help and
I'll show this again but really just watch the main part I want you to see is
I'll just sort of skip ahead so watch this part here let's say I'll just jump
right when he watch right now he's about to look up he looks up and makes eye contact and then his eyes look down so
again he looks up he looks up and then a saccade a sudden rapid eye movement down
down to his hands up down okay so that's again that's this brain OS in action
right he's making one glance small glance at the big guy's eyes just to
make eye contact to see to get a signal did I understand what you wanted and did
you did you register that joint attention and then he makes a prediction about what the guy's gonna do so he
looks right down he doesn't just like look around randomly he looks right down to the guy's hands to track the action
that he expects to see happening if I did the right thing to help you then I expect you're gonna put the books there okay so you can see these things
happening and we want to know what's going on inside the mind that guides all of that all right so that's the sort of
big scientific agenda that we're working on over the next few years where we think some kind of human understanding
of human intelligence in scientific terms could lead to all sorts of AI payoffs in particular suppose we could
build a robot that could do what this kid and many other kids and these experiments do just say help you out around the house without having to be
programmed or even really instructed just to kind of get a sense oh yeah you need to have at that shirt let me help
you out okay even 18 month olds will do that sometimes not very reliably or effectively sometimes they'll try to
help and really do the opposite right but imagine if you could take the the flexible understanding of humans actions
goals and so on and make those reliable engineering technology that would be very useful and it would also be related
to say machines that you can actually start to talk to and trust in some ways right that shared understanding so how
are we gonna do this well let me spend the rest of the time talking about how we try to do this right some of the some of the technology
that we're building both in our group and more broadly to try to make these kinds of architectures real and I'll
talk about two or three technical ideas again not in any detail all right um what is the idea of a probabilistic
program so this is a kind of a you think of it as a computational abstraction
that we can use to capture the common-sense knowledge of this core cognition so when I say we have an intuitive understanding of physical
objects in people's goals how do I build a model of that model you have in the head probabilistic programs a little bit
more technically our one way to understand them is as a generalization of Bayesian networks or other kinds of
directed graphical models if you know those okay but where instead of defining a probability model on a graph you
define it on a program and thereby have access to a much more expressive toolkit
of knowledge representation so data structures other kinds of algorithmic tools for representing knowledge okay
but you still have access to the ability to do probabilistic inference like in a graphical model but also causal
inference in a directed graphical model so for those of you who know about graphical models that might make some
sense to you but just more broadly what this is think of this as as a toolkit that allows us to combine several of the
best ideas not just of the recent deep learning era but over if you look back over the whole scope of AI and as well
as cognitive science I think there's three or four ideas there and more but definitely like three ideas we could
really put up there that have proven their worth and have have had have risen and fallen in terms of each of these had
ideas when the mainstream of the field thought this was totally the way to go and every other idea was was obviously a
waste of time and also had its time when many people thought it was a waste of time okay and these three big ideas I
would say are first of all the idea of symbolic representation or symbolic languages for knowledge representation
probabilistic inference in generative models to capture uncertainty ambiguity learning from sparse data and in their
hierarchical setting learning to learn right and then of course the recent developments with neural inspired
architectures for pattern recognition okay each of these things each of these ideas symbolic languages
probabilistic inference and neural networks has some distinctive strengths that are real weak points of the other
approaches right so to take one example but I haven't really talked about here people in the but I but you but you
mentioned as an outstanding challenge for neural networks transfer learning we're learning to take knowledge across
a number of previous tasks to transfer to others this is a real challenge and has always been a challenge in a neural net ok but is something that's addressed
very naturally and very scalable in for example a hierarchical Bayesian model and if you look at some of the recent
attempts really interesting attempts within the deep learning world to try to get kinds of transfer learning and learning to learn they're really cool ok
but many of them are in some ways kind of reinventing within a neural network paradigm ideas that people you know
maybe just 10 or 15 years ago developed in very sophisticated ways in let's say hierarchical Bayesian models ok and a
lot of attempts to get sort of symbolic algorithm like behavior in neural networks again are really you know
they're very small steps towards something which is a very mature technology in computer systems and
programming languages probabilistic programs I'll just sort of advertise mostly are a way to combine the
strengths of all of these approaches to have knowledge representations which are as expressive as anything that anybody
ever did in the symbolic paradigm that are as flexible at dealing with uncertainty and sparse data as anything
in the probabilistic paradigm but that also can support pattern recognition tools to be able to for example to do
very fast efficient inference in very complex scenarios and there's a number of probably that's that that's the kind
of conceptual framework there's a number of actually implemented tools I'm point two here on the slide a number of
probablistic programming languages which you can go explore for example there's one that was developed in our group a few years ago
almost 10 years ago now called church which was the antecedent of some of these other languages built on a functional programming course a church
is a probablistic programming language built on the lambda calculus or really in Lisp basically but there are many
other more modern tools especially if you are interested in neural networks there are tools like for example pyro or
prob torch or Bayes flow that try to combine all these ideas in a or for
example Jen here which is a project of the Koch men's singles probably the computing group these are all things
which are just in the very beginning stages very very alpha but you can find out more
about them online or by writing to their creators and I think this is a this is a very exciting place where the
convergence of a number of different AI tools are happening and when and this will be absolutely necessary for making
the kind of architecture that I'm talking about work another key idea which we've been building on in our lab
and I think again many people are using some version of this idea but maybe a little bit different from the way we're
doing it is what what version of this idea that I'd like to talk about is what I call the game engine in the head so
this is the idea that it's really what the programs are about when I talk about problems tick programs I haven't said
anything about what kind of programs we're using we're just basically these probablistic programming languages at their best and Church the language that
that was developed by Noah Goodman and Vikash and others and Dan Roy and our group some 10 years ago was intended to
be a turing-complete probabilistic programming language so any probability model that was computable or for whose
inferences conditional inferences are computable you could represent in these languages but that that leaves
completely open what what I'm actually gonna what what kind of proto I'm gonna write to model the world and I've been
very inspired in the last few years by thinking about the kinds of programs that are in modern video game engines so
again I'm probably most of you are familiar with these but if you're and increasingly they're playing a role in all sorts of ways an AI but these are
tools that were developed by the video game industry to allow a game designer to make a new game with without having
to do most of in some sense many must have the hard technical work bison from scratch but rather to focus on the
characters the world the story okay the things that are more interesting for designing a novel game in particular we
if we want a player to explore some so new three-dimensional world but to have them be able to interact with the world
in real time and to render nice looking graphics in in real time in an interactive way as the player moves
around and explores the world or if you want to populate the world with non-player characters that will behave in a even vaguely intelligent way okay
game engines give you tools for doing all of this without having to write all of graphics from scratch or all of
physics the rules of physics from scratch so what are called game physics engines
and in some sense are a set of principles but also hacks from Newtonian mechanics and other areas of physics
that allow you to simulate plausible looking physical interactions in very complex world very approximately but
very fast there's also what's called game AI which are basically very simple planning models so let's say I want to
have an AI in the game that is like unguarded that gardens of base and a player is gonna attack the space so back
in the old Atari days like when I was a kid you know the guards would just be like random things that would fire missiles kind of randomly in random
directions at random times right but let's say you want a guard to be a little intelligent so to actually look
around him oh and I see the player and then to actually start shooting at you and to even maybe pursue you so that requires putting a little AI in the game
and you do that by having basically simple agent models in the game so what we think and some of you might think
this is crazy and some of you might think this is very natural idea I get both kinds of reactions what we think is
that these tools of you know past approximate renderers physics engines and sort of very simple kinds of AI
planning are an interesting first approximation to the kinds of common-sense knowledge representations
that evolution has built into our brains so when we talk about the cognitive core or how do babies start what's what you
know ways in which a baby's brain isn't a blank slate one interesting idea is that it starts with something like these
tools and then wrapped inside a framework for probabilistic inference that's what we mean by promising programs that can support many
activities of common sense perception and thinking so I'll just give you one example what we call this intuitive
physics engine okay so this is work that we did in our groups that Pete Battaglia and Jess Hamrick did started this work
about five years ago now where we showed people you know in some
sense and this is this is also an illustration of a kind of experiment that you might do what you might keep talking about science like I'll show you
now a couple of experiments right so we would show people simple physical scenes like these blocks world scenes and ask
them to make a number of judgments and the model we built does it basically a little bit of probabilistic inference in
a game style physics engine it perceives the physical state and imagines a few different possible ways the world could
go over the next one or two seconds to answer questions like will the stack of blocks fall
or if they fall how far will they fall or which way will they fall or what would happen if say one of the colored
one color of blocks are one material like the green stuff is ten times heavier than the gray stuff or vice
versa how will that change the direction of fall or look at those red and yellow stack blocks some of which look like
they should be falling but aren't so why can you infer from the fact that they're not fall in that one color block is much
heavier than the other let me show you a sort of a slightly weird task it's in a
behavioral experiment sometimes we we do weird things so that we can test ways in
which you use your knowledge that you didn't just you know learn from pattern recognition but use it to do new kinds
of tasks that you'd never seen before so here's a task which you know many of you have maybe seen me talk about these
things so you might have seen this task but probably only if you saw me give a talk around here before we call this the red yellow task and again we'll make
this one interactive so imagine that the blocks on the table are knocked hard enough to bump the tables bumped hard
enough to knock some of the blocks onto the floor so you tell me is it more likely to be red blocks or yellow blocks what do you say red okay good
how about here yellow good how about here uh-huh here here okay here here
okay so you just experience for yourself what it's like to be an objective one of
these experience we just did the experiment here the data is all captured on video sort of right okay you could see that sometimes people were very
quick other times people were slower sometimes there was a lot of consensus sometimes there was a little bit less consensus right
that reflects uncertainty so again there's a long history of studying this scientifically that you know you could
but you can see something you can see the probabilistic inference at work probabilistic inference over what well I
would say one way to describe it is over one or a few short low precision simulations of the physics of these
scenes so here is what I mean by this I'm gonna show you a video of a game engine reconstruction of one of these
scenes that simulates a small bump so here's a small bubble here's the same scene with a big bump okay now notice
that at the micro level different things happen but at the cognitive or macro level that matters for common sense
reasoning the same thing happened namely all the yellow blocks went over onto one side of the table and few or none of the
red blocks did so it didn't matter reach of those simulations you ran in your head you'd get the same answer in this case right this is one that's very easy
and high confidence and quick also you didn't have to run the simulation for very long you only have to run it for a
few time steps like that to see what's gonna happen or similarly here you only have to run it for a few time steps okay
and it doesn't have to be even very accurate even a fair amount of imprecision will give you basically the
same answer at the level that matters for common sense so that's the kind of thing our model does it runs a few low
precision simulations for a few time steps but if you take the average of what happens there and you compare that
with people's judgments you get results like what I show you here the scatterplot shows on the y-axis the
average judgments of people on the x-axis the average judgments of this model and it does a pretty good job it's not perfect but the model basically
captures people's graded sense of what's going on in this scene and many of these others okay and it doesn't do it with
any learning but I'll come back to that in a second it just does it by probabilistic reasoning over a game physics simulation now we can use and we
have used the same kind of technology to capture in very simple forms really just proofs of concept at this point the kind
of common-sense physical scene understanding in child in a child playing with blocks or other objects or in what might go on in a young child
understanding of other people's actions what we called the intuitive psychology engine where now the probabilistic programs are
defined over these kind of very simple planning and perception programs and I won't go into any details I'll just
point to a couple of papers that my group played a very small role in but we provided some models which together with
some infant researchers people working on both of these are experiments that that were done with 10 or 12 month
infants so younger than even some of the babies I showed you before but basically like that youngest baby the one with the
cat here's an example of showing simple physical scenes these are moving objects to 12 month olds where they saw a few
objects bouncing around inside a gumball machine and after some point in time the scene gets occluded you'll see the scene
is occluded and then after another period of time one of the objects will appear at the bottom and the question is
is that the object you expected to see or not is its expected or surprising the standard way you study what infants know
is by is by what's called looking time methods just like an adult if I show you something that's surprising you might
look longer okay if you're bored you'll look away all right so you can do that
same kind of thing with infants and by measuring how long they look at a scene you can measure whether you've shown
them something surprising or not all right people have there are literally hundreds of studies if not more using looking
time measures to study what infants know but only with this paper that we published a few years ago did we have a
quantitative model we're able to show a relation between inverse probability in this case and surprise so things which
were objectively lower probability under one of these probabilistic physics simulations across a number of different manipulations of how fast the objects
were where they were when the scene was occluded how long the delay was various physically relevant variables how many objects there were one type or another
infants expectations connected with this model or another paper that we published that one was was done that the
experiments that were done by era note eggless and Luca bananas lab here is a study that was done just recently by
sherry Lu inless spell keys lab at there at Harvard but they're part they're partners with us and CBMM which was
about infants understanding of goals so this is more like again understanding of agents and intuitive psychology we're in again in very simple cartoon
scenes you show an infant an agent that seems to be doing something like an animated cartoon character but it jumps
over a wall or rolls up a hill or it jumps over a gap and the question is basically how much
does the agent want the goal that it seems to be trying to achieve and what this study showed okay and the models
here we're done by Tomer omen was that infants appeared to be sensitive to the physical work done by the agent the more
work the agent did in a sense of the integral of force applied over a path the more the infant's thought the agent
wanted the goal we think of this as representing what we've sometimes called the naive utility calculus so the idea
that there's a basic calculus of cost and benefit you know we take actions
which are a little bit costly to achieve goal states which give us some reward that's the most basic way the oldest way
to think about rational intentional action and it seems that even ten-month-old understand some version of that where
the cost can be measured in physical terms okay I see I'm running a little bit behind on time and and I wanted to leave
some time for discussion so I'll I'll just go very quickly through a couple of other things and and Lee and happy to stay around at the end for discussion
okay the what I showed you here was the science where does the engineering go so
one way one thing you can do with this is say build a machine system that can look not a little animated cartoon like
these baby experiments but a real person doing something and again combine physical COFF and constraints of actions
with some understanding of the agents utilities that's the math of planning to
figure out what they want it so look in this scene here and see if you can judge
which object that the woman is reaching for so you can see there's there's a grid of four by four objects there's
sixteen objects here and she's gonna be reaching for one of them raise it's gonna play in slow motion but raise your
hand when you know which one she's reaching for ok so just watch and raise your hand when you know which one she wants okay so most of
they're up by now alright and notice I was looking at your hands not here but went but what happened is most of the
hands were up at the about the time when that gray or the one that - line shot up okay
that's not human data you provided the data this is our model so our model is predicting more or less when you're able
to say what her goal was okay it's well before she actually touched the object how does the model work again I'll skip
the details but it does the same kind of thing that that our models of those infants did namely it but in this case
it does it with a full body model from robotics so we use what's called the mu Joko physics engine which is a standard
tool in robotics for planning physically efficient reaches of say a humanoid robot and we say we can give this
planner program a goal object as input we can give it each of the possible goal objects as input and say plan the most
physically efficient action so the one that uses like the least energy to get to that object and then we can do a
Bayesian inference this is the probabilistic inference part the program is them is the MU Joker planner okay but
then we can say I want to do Bayesian inference to work backwards from what I observed which was the action to the
input to that program what goal was provided as input to the planner and here you can see the full array of four
by four possible inputs and those bars that are moving up and down that's the Bayesian posterior probability of how
likely each of those was to be the goal and what you can see is it converges on the right answer at least well it turns
out to be the ground truth right answer but it's also the right answer according to what people think with about the same kind of data that people took now you
might say well okay I'm sure if I just wanted to build a system that could detect what somebody was reaching for I could generate a training data set of
this sort of scene and train something up to analyze patterns of motion but again because the engine in your head
actually does something we think more like this it does what we call inverse planning over a physics model it can
apply to much more interesting scenes that you haven't really seen much of before so take the scene on the left right where again you see somebody
reaching for one of a four by four array of objects but what you see is a strange kind of reach can you see why he's doing
that strange reach up there it's a little small but what is you can see that he's reaching over something right
it's actually a pane of glass right you see that and then there's this other guy who's helping him who sees what he wants
and hands the thing he wants so how does the firt the guy in the foreground see the other guy's goal
how does he and for his goal and know how to help him and then how do we look at the two of them and figure out who's
trying to help who or that in a scene like this one here that it's not somebody trying to help somebody but
rather the opposite okay so here's a model on the left of how that might work right and we think this is the kind of model needed to
tackle this sort of challenge here right basically it's a model it's a we take this model of planning sort of maximal
expected utility planning which you can run backwards but then we recursively nest these models inside each other so
we say an agent is helping another agent if this agent is acting apparently to us seems to be maximizing an expected
utility that's a positive function of that agents expectation about another agents expected utility and that's what
it means to be a helper hindering is sort of the opposite if one seems to be trying to lower somebody else's utility
okay and we've used these same kind of models to also describe infants understanding of helping and hindering
in a range of scenes I'll just say one last word about learning because everybody wants to know about learning
and and the the key thing here and it's definitely part of any picture of AGI but the thought I want to leave you on
is really about what learning is about ok I'll be just a few more slides and then I'll stop I promise none of the
models I showed you so far really did any learning they certainly didn't do any task specific learning ok we set up
a probable state program and then we let it to inference now that's not to say that we don't think people learn to do these things we do but the real learning
goes on when you're much younger right everything I showed you in basic form even a one-year-old baby can do ok the
basic learning goes on to support these kinds of abilities not that there isn't learning beyond one year but the basic
way you learn to say solve these physics problems is what goes on in your baton in the brain of a child between 0 and 12
months so this is just an example of some phenomena that come from the literature on infant cognitive development these are very rough
timelines you can take pictures of this if you like this is always a popular slide because it really is quite inspiring I think and I can give you
lots of literature pointers but I'm summarizing in very broad strokes with big error bars what we've learned in the
field of infant cognitive development about when and how kids seem to have to at least come to certain understand
of basic aspects of physics so if you really want to study how people learn to be intelligent a lot of what you have to
study are kids at this age you have to study what's already in their brain at zero months and what they learn and how
they learn between four six eight ten twelve and so on and on up beyond that okay now well effectively what that
amounts to we think is if what you're learning is something like a let's say an intuitive game physics engine to
capture these basic abilities then what we need if we're gonna try to reverse-engineer that is what we might
think of as a program learning program if your knowledge is in the form of a program then you have to have programs that build other programs right this is
what I was talking about the beginning about learning as building models of the world or ultimately if you think what we
start off with is something like a game engine that can play any game then what you have to learn is the program of the
game that you're actually playing or the many different games that you might be playing over your life so think of learning as like programming the game
engine in your head to fit with your experience and and to fit with the possibilities that you seem like you can
take now this is what you could call the hard problem of learning if you come to learning from say neural networks or
other tools and machine learning right so what makes machine makes most of machine learning go right now and
certainly what makes neural network so appealing is that you can set up a basically a big function approximator
that can approximate many of the functions you might want to do in a certain application or task but in a way
that's end-to-end differentiable and with a meaningful cost function so you can have one of these nice optimization
landscapes you can compute the gradients and basically just roll downhill until you get to an optimal solution but if
you're talking about learning as something like search in the space of programs we don't know how to do anything like that yet we don't know how
to set this up as any kind of a nice optimization problem with any notion of smoothness or gradients okay rather what
we need is a instead of learning as like rolling downhill effectively right a process which just if you're willing to
wait long enough you know some you know simple algorithm will take care of think
of what we call the idea of learning as programming there's a popular metaphor in cognitive development called the
child of scientists which emphasizes children as active theory builders and children's play as a kind of kind of
casual experimentation but this is the algorithmic complement to that what we could call the child as
or around MIT will say the child is hacker but the rest of the world if you say child is hacker they think of
something someone who breaks into your email and steals your credit card numbers we all know that hacking is you know making your code more awesome right
if your knowledge is some kind of code or legal library of programs then learning is all the ways that a child
hacks on their code to make it more awesome that more awesome can mean more accurate but it can also mean faster
more elegant more transportable to other applications or their tasks more explainable to others maybe just more
entertaining okay children do all of them have all of those goals and learning and the activities by which they make their code more awesome also
correspond to many of the activities of coding alright so think about all the ways on a day-to-day basis you might
make your code more awesome all right you might tune you might have a big library of existing functions with
some parameters that you can tune on a data set that's basically what you do with backprop or stochastic gradient descent in training a deep learning
system but think about all the ways in which you might actually modify the underlying function so write new code or
take old code from some other thing and map it over here or make a whole new library of code or refactor your code to
some other you know some other basis for that that will work more robustly and be more extensible or transpiling or
compiling right or even just commenting your code or asking someone else for their code ok again these are all ways
that we make our code more awesome and children's learning has analogs all of these that we would want to understand
as an engineer from an algorithmic point of view so in our group we've been working on on various early steps
towards this and again we don't have anything like program writing programs at the level of children's learning
algorithms but one example of something that we did in our group which you might not have thought of being about this but
it's definitely the AI work we did that got the most attention in the last couple of years from our group we had
this paper that was in science it was actually on the cover of science sort of just hit the market at the right time if
you like and it got about a hundred times more publicity than anything else I've ever done which is partly a testament to the really great work that
Brendan Lake who was the first author did for his PhD here but much more so just about the hunger for AI systems at
the time when we published this in 2015 and we built a machine system that the way we described it what
doing human level concept learning four simple concept very simple visual concepts these handwritten characters in
many of the world's alphabets for those of you who know the famous Emnes data set in the data set of handwritten digits 0 through 10 or 30 through 9
sorry that drove so much good research in deep learning and pattern recognition it did that not because Jana Kuhn who
put that together or Geoff Hinton who did a lot of work on deep learning with M Nez they were interested fundamentally
in character recognition that they saw that as a very simple testbed for developing more general ideas and
similarly we did this work on getting machines to do what we kind of one-shot learning of generative models also to
develop more general ideas we saw this as learning very simple little mini probabilistic programs in this case what
are those programs they're the programs you use to draw a character so ask yourself how can you look at any one of these characters and see in a sense how
somebody might draw it the way we tested this in our system was this little visual Turing test where we showed
people one character in a novel alphabet and we said draw another one and then we compared nine people like say on the
left and nine samples from our machine say on the right and we said we asked other people could you tell which was
the human drawing another example or imagining another example in which was the machine and people couldn't tell
when I said ones on the left ones on the right I don't actually remember and on different ones you can see if you can tell it's very hard to tell can you tell
which is for each one of these characters which new set of examples were drawn by a human versus a machine
here's the right answer and probably you couldn't tell the way we did this was by
assembling a simple kind of program learning program right so we basically said when you draw a character you're assembling strokes and
sub strokes with goals and sub goals that produce ink on the page and when you see a character you're working
backwards to figure out what was the program the most efficient program that did that so you're basically inverting a
probabilistic program doing Bayesian inference to the program most likely to have generated what you saw this is one
small step we think towards being able to learn programs to being able to learn something ultimately like a whole game
engine program the last thing I'll leave you with is just a pointer to sort of work in action right so this is some work being done by
a current PhD student who works partly with me but also with armando salar Lezama and cecil this is kevin Ellis
it's an example of what's now I think again a urging exciting area and AI well beyond
anything that we're doing is the is combining techniques from where amando comes from which is the world of
programming languages not machine learning or AI but tools from programming languages which can be used
to automatically synthesize code okay with the machine learning toolkit in this case a kind of Bayesian Men and a
minimum description length idea to be able to make again what is really one small step towards machines that can
learn programs by basically trying to efficiently find the shortest simplest program which can capture some data set
so we think by combining these kinds of tools in this case let's say from Bayesian inference over programs with a
number of tools that have been developed in other areas of computer science that don't look anything or haven't been
considered to be machine learning or AI like programming languages it's one of the many ways that going forward we're
gonna be able to build smarter more human-like machines so just to end then what I've tried to tell you here is
taught first of all identify the ways in which human intelligence goes beyond pattern recognition to really all these
activities of modeling the world okay to give you a sense of some of the domains where we can start to study this in
common sense scene understanding for example or you know something like
one-shot learning for example like what we were just doing there or learning is programming the engine in your head okay
and to give you a sense of some of the technical tools probabilistic programs program synthesis game engines for
example as well as a little bit of deep learning that bringing together we're starting to be able to make these things
real okay now that's the science agenda and the reverse engineering agenda but think about for those of you who are
interested in technology what are the many big AI frontiers that this opens up so the one I'm most excited about is
this idea which is which I've highlighted here in our big research agenda this is one I'm most excited about to work on for the you know it
could be the rest of my career honestly but it's really what is what is the oldest and maybe the best dream of AI
researchers of how to build a human-like intelligence system a real a GI system it's the idea that Turing proposed when
he proposed the Turing test or Marvin Minsky proposed this at different times in his life or many people have proposed this right which is to build a system
that grows into intelligence the way a human does that starts like a baby and learns like a child
tried to show you how we're starting to be able to understand those things what a baby's mind starts with how children
actually learn and looking forward we might we might imagine that someday we'll be able to build machines that can
do this I think we can actually start working on this right now and we're and that's something that we're doing in our
group so if that kind of thing excites you then I encourage you to work on it maybe even with us or if any one of
these other activities of human intelligence excite you I think taking the kind of science-based reverse
engineering approach that we're doing and then trying to put that into engineering practice it's it's this is
this is a this is not just a possible route but I think it's it's quite possibly the most valuable route that
you could work on right now to try to actually achieve at least some kind of artificial general intelligence
especially the kind of intelligence AI system that's going to live in a human
world and interact with human there's many kinds of AI systems that could live in worlds of data that none of us can understand or will ever live in
ourselves but if you want to build machines that can live in our world and interact with us the way we are used to
interacting with other people then I think this is a route that you should consider okay thank you
[Applause]
hi there so early in the talk you expressed some skepticism about whether or not industry would get us to
understanding human level intelligence it seems that there's a couple of trends that favor industry one is the industry
is better than that academia accumulating resources and plowing back into the topic and it seems at the
moment we've got a bit of brain drain going on form academia into industry and that seems like a on going trend yeah if
you look at something like learning to fly or learning to fly into space then it looks like a story is one of Industry
kind of taking over the field and going off on its own yeah a little bit academia academics still have a role but
industry kind of dominates so yes is industry going to overtake the field you think well that's a really good question
and it's got several good questions packed into one there right I didn't mean to say I didn't this wasn't meant
to say go academia bad industry right what I was taught what I what I tried to say was the approaches that are
currently getting the most attention in industry and they're really because they're really the most valuable ones right now for the short term you know
any industry is really focused on what it can do what are the value propositions on basically a two year
time scale at most I mean if you ask say Google researchers to take the most prominent example it's pretty much what
they'll all tell you okay maybe maybe things that might you know pay off
initially in two years but maybe take five years or more to really develop but if if you can't show that it's gonna do
something practical for us in two years in a way that matters for our bottom line then it's not really worth doing okay so what when we say what I'm
talking about is the technologies which right now industry sees as meeting that specification and what I'm saying is
right now I think those that's that's not where the route is to something like
human-like but not the most valuable promising route to human-like kinds of AI systems all right but I hope that
like in the cases you said you know the basic research that we're doing now will be successful enough that it will get
the attention of industry when the time is right but I think so you know I mean I hope at some point you know it won't
it will only at least the engineering side will have to be done in industry not just in academia but you're also
pointing to issues of like brain drain and other things like that but I think it's these are real issues confronting our community I think
everybody knows this and I'm this will come up multiple times here which is you know I think we have to
find ways to even now to combine the best of the idea of the energy and the resources of academia and industry if we
want to keep doing basically something interesting right if we will if we just want to redefine AI to be well whatever
people currently call AI but scaled up well then then then fine forget about it and or if we just want to say let me and
people like me do what we're doing at what industry would consider a snail's pace on toy problems okay fine but if
but if we want to if you know if I want to take what I'm doing to the level that that will really be you know paying off
that level the industry can appreciate or just that really has technological impact on a broad scale right or I think
if industry wants to take what it's doing and really build machines that are actually intelligent right our machine
learning that actually learns like a person then I think we need each other now and not just in some point in the future so this is a general challenge
for MIT and for everywhere and for Google I mean we just spent a few days talking to Google about exactly this
issue that this was a talk I prepared partly for that purpose so we wanted to raise those issues and and it's just I
mean really there I don't know what I mean well rather I can think of some solutions to that problem of what you
could call brain drain from the academic point of view or what you could call just narrowing in into certain local minima in the industry point of view but
they will require the leadership of both academic institutions like MIT and companies like Google being creative
about how they might work together in ways that are a little bit outside of their comfort zone I hope that will start to happen including at MIT and at
many other universities and at companies like Google and many others and I think we need it to happen for the health of all parties concerned okay thank you
very much things I'm curious about sort of the premise that you gave that one of
the big gaps missing at determining intelligence is the fact that we need to teach machines how to recognize models
and I'm curious as to what you think sort of non goal oriented cognitive
activity comes into play they're things like feelings and emotions and and y-you don't think that might not
necessarily be like that the no I'm I was born in questo the only reason
emotions didn't appear on my slide is because there's a few reasons but the slide is only so big I wanted the font
to be big readable for such an important slide I've had versions of my slide in which I do talk about that okay it's not
that I think feelings or emotions aren't important I think they are important and I used to not have many insights on it
about what to do about them but actually partly based on some of my colleagues here at MIT BCS Laura Schultz and
Rebecca Saxe two of my cognitive colleagues in who I work closely with they've been starting to do research on
how people understand emotions both their own and others and we've been starting to work with them on computational models so that's actually
something I'm actively interested in and even working on but I would say and again for those of you who study emotion
to know about this actually you're gonna have Lisa coming in right oh so she's gonna basically say a version of the same thing I think the deepest way to
understand she's one of the world's experts on this the deepest way to understand emotion is very much based on
our mental models of ourselves of the situation we're in and of other people right think about for example all of the
different I mean if you you know if you think about it I mean again Lisa will talk all about this but if you think
about emotion as just a very small set of what are sometimes called basic emotions like being happy or angry or
sad or you know those are a small number of them right there's usually only few
right you might not say you might see that it's somehow like very basic things
that are opposed to some kind of cognitive activity but think about all the different words we have for emotion
right for example think about an a famous cognitive emotion like regret
what does it mean to feel regret or frustration right just to know both for
yourself when you're not just feeling kind of down or negative but you're feeling regret that that means something
like I have to feel like there's a situation that came out differently from how I hoped and I realize I could have
done something differently right so that means you have to be able to understand you have to have a model you have to be
able to do a kind of counterfactual reasoning and to think oh if only I had acted to differ way then I can predict that the world
would have come out differently and that's the situation I wanted but instead it came up this other way right or think about frustration again that
requires something like understanding okay I've tried a bunch of times I thought this would work but it doesn't seem to be working maybe I'm ready to
give up though those are all those are those are very important human emotions we have to understand to understand
ourselves we need that to understand other people to understand communication but those are all filtered through the kinds of models of action that I was
just the ones I was talking about here with these say cost-benefit analyses of action so what I'm so I'm just trying to
say I think this is very basic stuff that will be the basis for building I think better engineering style models of
the full spectrum of human emotion beyond just like well I'm feeling good or bad or scared okay and if I think when you see Lisa she
will in her own way say something very similar interesting thanks yeah thanks
Josh for your nice talk so all is about human cognition and try to build a model to mimic those cognition but you don't
how much could help you to understand how the circuit implement those things hmm I mean like these circuits in the
brain yeah yeah that's the is that what you work on by any chance is that what you work on by any chance yeah yeah yeah
so so in the Center for brains minds of machines as well as in brain and cognitive science yeah we I have a
number of colleagues who study the actual hardware basis of this stuff in the brain and that includes like the
large-scale architecture of the brain say like what Nancy kanwisher Rebecca Saxe studied with functional brain imaging or the more detailed
circuitry which usually requires recording from say non-human brains right at the level of individual neurons
and connections between neurons all right so I'm very interested in those things although it's not mostly what I
work on right but I would say you know again liking in many other areas of science certainly in neuroscience the
kind of work I'm talking about here in a sort of classic reductionist program sets the target for what we might look
for like if I if I just want to go I mean I I would I would I would assert right or my working conjecture is that
if if you do the kind of work that I'm talking about here it gives you the right targets or gives you a candidate
set of targets to look for what are the neural circuits computing right whereas if you just go in and just say
poking around in the brain or have some idea that what you're gonna try to do is find the neural circuits which underlie
behavior without a sense of the computations needed to produce those behaviors I don't I think it's gonna be
very difficult to eat to know what to look for and to know when you've found even viable answers so I think that's
you know that's the standard kind of reductionist program but it's not that's it's not I also think it's it's not one
that is I'm divorced from the study of neural circuits it's also one if you look at the broad picture of reverse
engineering it's one where we're neural circuits and understanding the circuits in the brain play an absolutely critical
role okay I would say the mate as an when you look at the brain at the hardware level as an engineer I'm mostly
looking at the software level right but when you look at the hardware level there are some remarkable properties one
remarkable property again is you know how much parallelism there is and in many ways how fast the computations are
okay neurons are slow but the computations intelligence are very fast so how do we get elements that are in some sense
quite slow in their time constant to produce such intelligent behavior so quickly that's a great mystery and I
think if we understood that it would have payoff for building all sorts of you know Apple basically application
embedded circuits okay but also maybe most important is the power consumption and again many people have-have have
noted this right if you look at the power consumption the power that the brain consumes like what did I eat today
okay almost nothing um my daughter who's again she's doing an internship here she
literally yesterday all she ate was a burrito and yet she wrote 300 lines of code for her internship project on
really cool computational linguistics projects so somehow she turned a burrito into you know a model of child language
acquisition okay but how did she do that or how do any of us do this right um we're if you look at the power that we
consume when we simulate even a very very small chunk of cortex on our conventional hardware or we do any kind
of machine learning thing we have systems which are very very very very far from the power of the human brain
computationally but in terms of physical energy consumed way way past what any
individual brain is doing so how do we get circuitry of any sort biological or just any physical circuit
to be as smart as we are with as little energy as we are this is this is a huge
problem for basically every area of engineering right if you want to if you want to have any kind of robot the power
consumption is a key bottleneck same for self-driving cars if we want to build AI without contributing to global warming
and climate change let alone use AI to solve climate change we really need to address these issues and the brain is a
is a huge guide there right I think there are some people who are really starting to think about this how can we
say for example build somehow brain inspired computers which are very very
low-power but maybe only approximate so I'm thinking here of Joe Bates I don't know if none of you know Joe he's he's
been around MIT and other places for quite a while can I tell them about your company so so Joe has a start-up in
Kendall Square called singular computing and they have some very interesting ideas including some actual implemented technology for low power approximate
computing in a sort of a brain like way that might lead to possibly even like the ability to build something this is
Joe's dream to built in this about the size of this table but that has a billion course a billion cores and runs
on a reasonable kind of power consumption I would love to have such a machine if anybody wants to help Joe
build it I think he'd love to talk to you but that's it's one of a number of ideas I mean Google X people are working
on similar things probably most of the major chip companies are also inspired by this idea and I think even if you
don't didn't think you were interested in the brain if you want to build the kind of AI were talking about and run it on physical Hardware of any sort and
understanding how the brain circuits compute what they do what what I'm talking about with as little power as
they do I don't know any better place to look it seems like a lot of the improvements in AI have been driven by
increasing like computational power yeah how far you would you say me like GPUs or CMU yeah yeah how far would you say
we are from hardware that could run a general artificial intelligence of the
kind that I'm talking about yeah I don't know I'll start with a billion cores and then we'll see I mean I I think we're I
think we're I mean I think I think there's no way to answer that question in a way that software independent I don't know how to do that right but I
think that it's and and you know I don't know like
when you say how far are we you mean how far am i with the resources I have right now how far am i if if
Google decides to put all of its resources at my disposal like they might if I were working at deepmind I don't know the answer to that question
I but I think the I think what we can say is this um individual neurons I mean
again this goes back to another reason to study neural circuits um if you look at what we currently call neural networks in the AI side the model of a
neuron is this very very simple thing right individual neurons are not only much more complex but have a lot more
computational power it's not clear how they use it or whether they use it but I think it's just as likely that a neuron
is something like a rail you write is that a neuron is something like a computer like under one neuron in your
brain is more like a CPU node okay maybe and thus the ten billion or trillion you
know the large number of neurons in your brain I think it's like 10 billion cortical pyramidal neurons or something
might be like 10 billion cores okay for example that's at least as plausible I think to me as any other estimate so and
I think so I think we're on the definitely on the underside with very big error bars so I completely agree
that or if this is what you might be suggesting and may you know going back to my answer to your question I don't
think we're gonna get to what I'm talking about that anything like a real brain scale without major innovations on
the hardware side and you know it's it's interesting that what drove those innovations in that support current a I
was mostly not AI it was the video game industry I'm when I point to the video
game engine in your head that's a similar thing that was driven by the video game industry on the software side I think we should all play as many video
games as we can and contribute to the growth of the video game industry because no because I mean I mean you can
see this in very like there are companies out there for example there's a company called improbable which is a
London company London based startup a pretty sizable start-up at this point which is building something that they
call spatial OS which is it's a it's not a it's not a hardware idea but it's a kind of software idea for very very big
distributed computing environments to run much much more complex realistic simulations of the world for
much more interesting immersive permanent videogames I think that's one thing that might hopefully that will lead to more fun new kinds of games but
that's one example of where we might look to that industry to drive some of the you know just computer systems
really hardware and software systems that we'll take we'll take our game to
the next level just understanding on the algorithmic level or cognitive level is just to
understanding the learning the meaning of learning would be how to predict but on the circuit level is different but at
the what level on the circuit level well of course it's different right but already you I think you made a mistake
there honestly like you said the cognitive level is learning how to predict but I'm not sure what you mean by that there's many things you could
mean and are what our cognitive science is about is learning which of those versions like I don't think it's learning how to predict I think it's learning what you need to
know to plan actions and to a map you know all those things like it's not just about predicting it's because there are
things we can imagine so that you would never predict because there never happen unless we somehow make the world
different so generalizations are you're not predicting okay when your model could generalize but especially in the
transfer learning that you are interested in a few hundred of neurons in prefrontal cortex they have generalize a lot yes but not kind of a
Bayesian model do that you said but a thean model won't do that or they don't
do it the way a Bayesian model does for sure because that's in the abstract level well I mean how do you really know
like and what does it mean to say that some neurons do it like so maybe another way to put this is to say look we have a
certain math that we use to capture these you could call it abstract I call it software level abstractions right I
mean all engineering is based on some kind of abstraction but you might have a circuit level abstraction a certain kind
of hardware level that you're interested in describing the brain at and I'm mostly working out or starting from a more software level of abstraction right
they're all distractions we're not talking about molecules here right we're talking about some abstract notion of maybe a circuit or of a program okay
right now it's a really interesting question if I look at some circuits how do I know what program they're
implementing right if I look at the circuits in this machine could I tell what program they're implementing well maybe but certainly it would be a lot
easier if I knew something about what programs they might implementing before I start to look at the circuitry if I just looked at the circuitry without knowing what a program
was or what programs the thing might be doing or what kind of programming components would be mapable to circuits
in different ways right I don't even know how to begin to answer that question so I think you know we've made some
progress at understanding what neurons are doing in certain low-level parts of sensory system and certain parts of the
motor system like primary motor cortex like basically the parts of the neurons that are closest to the inputs and outputs of the brain right where we
don't eat when you can say we don't need the kind of software abstractions that I'm talking about or where we sort of
agree on what those things already are so we can make enough progress on knowing what to look for and how to how
to know when we found it but if you want to talk about flexible planning things that are more like cognition that you know go on in prefrontal cortex right I
this point I don't I don't think that just by recording from those neurons we're gonna be able to answer those
questions in a meaningful engineering way a way that that any engineer software a hardware whatever could
really say yeah okay I get it I get those insights in a way that I can engineer with and that's what my goal is right so my goal that's my goal to do at
the software level the hardware level or the entire systems level connecting them and I think that you know we can do that
by taking what we're doing and bringing into contact with people studying neural circuits but I don't think you can you can leave this level out and just go
straight to the neural circuits and I think the more you have the more progress we make the more we can help people who are studying at the neural
circuit level and they can help us address these other engineering questions that we don't really have access to like the power issue or the
speed issue thank you okay thanks that was great I thought maybe it'd give Jessica Han

----------

-----
--28--

-----
Date: 2018.02.03
Link: [# MIT AGI: Artificial General Intelligence](https://www.youtube.com/watch?v=-GV_A9Js2nM)
Transcription:


Intro
welcome to course six as $0.99 artificial general intelligence we will
explore the nature of intelligence from as much as possible and engineering
perspective you will hear many voices my voice will be that of an engineer our
MIT AGI Mission: Engineer Intelligence
mission is to engineer intelligence the
MIT motto is mind in hand what that means is we want to explore the
fundamental science of what makes an intelligence system the core concepts
behind our understanding of what is intelligence but we always want to
ground it in the creation of intelligent systems we always want to be in the now
in today in understanding how today we can build artificial intelligence
systems that can make for a better world that is the core for us here at MIT
first and foremost we're scientists and engineers our goal is to engineer
intelligence we want to provide with
this approach a balance to them very important but over represented view of
artificial general intelligence the black box reasoning view where the idea
is once we know how to create a human level intelligence system how will
society be impacted will robots take over and kill everyone will we achieve a
utopia that will remove the need to do any of the messy jobs that will make us
all extremely happy those kinds of beautiful philosophical concepts are
interesting to explore but that's not what we're interested in doing I believe that from an engineering perspective we
want to focus on the black box of a GI start to build insights and intuitions
about how we create systems that approach human level intelligence I believe we're very far away from
creating anything resembling human level intelligence however the dimension of
the metric behind the word Farr may not be time in time perhaps through a few
breakthroughs maybe even one breakthrough everything can change but as we stand now our current methods as
we will explore from the various ideas and approaches and the guest speakers coming here over the next two weeks and
beyond our best understanding our best intuition and insights are not yet at
the level of reaching without a major leap and breakthrough a paradigm shift
towards human level intelligence so it's not constructive to consider the impact
of artificial intelligence to consider questions of safety and ethics
fundamental extremely important questions we it's not constructive to
consider those questions without also deeply considering the black box of the
actual methods of artificial intelligence human level artificial intelligence and that's what I see what
Balance Between Paralyzing Technophobia and Blindness to Big Picture Consequences
I hope this course can be its first iteration its first exploratory attempt
to try to look at different approaches of how we can engineer intelligence
that's the role of MIT it's tradition of mine in hand it's to consider the big
picture the future impact of society 10 20 30 40 years out but fundamentally
grounded in what kind of methods do we have today and what are their
limitations and possibilities of achieving that the black box of a GI
in the future impact on society of creating artificial intelligence systems
that get become increasingly more intelligent the fundamental disagreement
lies in the fact the the very core of that black box which is how hard is it
to build an AGI system how hard is it to create a human level artificial
intelligence system that's the open question for all of us from from Josh
Tenenbaum to Andrey Carpathia to folks from open AI to Boston Dynamics to the
brilliant leaders in various fields of artificial intelligence that will come here that's the open question how hard
is it there's been a lot of incredibly impressive results in deep learning in
neuroscience and computational cognitive science in robotics but how far are we
still to go to the AGI that's the fundamental question that we need to explore before we consider the questions
the future impact on society and the goal for this class is to build
intuition one talk at a time a project at a time build intuition about where we
stand about what the limitations of current approaches are how can we close the gap a nice meme that I caught on
Twitter recently of the difference between the engineering approach at the
very simplest of a Google intern typing a for loop that just does a grid search
on parameters for a neural network and on the right is the way media would
report this for loop the Google AI created its own baby AI I think it's
easy for us to go one way or the other but we'd like to do both our first goal
is to avoid the pitfalls of black box thinking of the few tourism thinking that results in hype
that's detached from scientific engineering understanding of what the actual systems are doing that's what the
media often reports that's what some of our speakers will explore in a rigorous
way it's still an important topic to explore Ray Kurzweil's on Wednesday we'll look we'll explore this topic next
week talking about AI safety and autonomous weapon systems we'll explore this topic the future impact 10 20 years
out how do we design systems today that would lead to safe systems tomorrow still very important but the reality is
a lot of us need to put a lot more emphasis on the left on the four loops
on creating these systems at the same time the second goal of what we're
trying to do here is not emphasize the silliness the simplicity the naive basic
nature of this for loop in the same way as was the process in creating nuclear
weapons before during World War two the idea that as an engineer as a
scientist that I'm just the scientist is also a flawed way of thinking we have to
consider the big picture impact the near-term negative consequences that are
preventable the low-hanging fruit that can be prevented through that very engineering process we have to do both
and in this engineering approach we
always have to be cautious that just because we don't understand
we're just because we our intuition our best understanding of the capabilities
of modern systems that learn that act in this world seem limited seem far from
human level intelligence our ability to learn and represent common sense reasoning seems limited the exponential
potentially Exponential's could be argued and he will growth of technology
of these ideas means that just around the corner is a singularity is a breakthrough idea that will change
everything we have to be cautious of that moreover we have to be cautious of
the fact that every decade over the past century our adoption of new technologies
has gotten faster and faster the the rate at which a new technology from its
birth to its wide mass adoption has shortened and shortened and shortened
that means that new idea the moment it
drops into the world can have widespread effects overnight so as and I think the
in the engineering approach is fundamentally cynical on artificial general intelligence because every
aspect of its is so difficult we have to always remember that overnight everything can change through this
question of beginning to approach from a deep learning perspective deep reinforcement learning from brain
simulation computational cognitive science from computational neuroscience
from cognitive architectures from robotics from legal perspectives and
autonomous weapon systems as we begin to approach these questions we need to
start to build intuition how far away are we from creating intelligent systems
the singularity here is that spark that moment when we're truly surprised by the
intelligence of the systems we create I'd like to visualize it by the by a
certain analogy that we're in this dark room looking for a light switch with no
knowledge of where the light switch is there's going to be people that say well it's a smaller the rooms are all smaller
right there and say anywhere we'll be able to find it in any time the reality is we know very little so we have to
stumble around feel our way around to build the intuition a far far away we
really are many will speakers here will talk about
Human Drive to explore and Uncover the Mysteries of the Universe
how we define intelligence how we can begin to see intelligence what are the
fundamental impacts of creating intelligence systems I'd like to sort of see the positive reason for this little
class and for these efforts that have fascinated people throughout the century
of trying to create intelligent systems is that there's something about human beings that one that craves to explore
to uncover the mysteries of the universe fundamental in itself a desire to
uncover the mysteries of the universe not for a purpose and there's often an
underlying purpose of money of greed of the power craving for power and so on
but there's seems to be an underlying desire to explore nice little book an
exploration a very short introduction by Stewart Weaver he says for all the different forms it takes in different
historical periods for all the worthy and unworthy motives that lie behind it
exploration travel for the sake of discovery and adventure is a human
compulsion a human obsession even it is defining element of a distinctly human
identity and it will never rest at any frontier whether terrestrial or
extraterrestrial from 325 BCE with a
long 7500 mile journey on the ocean to
explore the Arctic to Christopher Columbus and his flawed harshly
criticized the modern scholarship trip that ultimately paved the way didn't
discover pave the way to colonization of the Americas to the DAR
trip the voyage of the Beagle whilst this planet has gone cycling on
according to the fixed law of gravity from so simple a beginning endless forms most beautiful and most wonderful have
been and are being evolved to the first
venture into space by Yuri Gagarin first
human in space in 1961 what he said over
the radio is the earth is blue it is amazing this these are the words they
think drive our exploration in the sciences in engineering and today an AI
and the first walk on the moon and now
the desire to colonize Mars and beyond
that's where I see this desire to create intelligent systems talking about the
positive or negative impact of AI on society talking about the business case of the jobs lost jobs gain jobs created
diseases cured the autonomous vehicles the ethical questions the safety of
autonomous weapons of the misuse of AI in the financial markets underneath it
all and they're people many people are spoken about this what drives myself and
many in the community is the desire to explore to uncover the mystery of the universe and I hope that you join me in
that very effort with the speakers that come here in the next two weeks and beyond the website for the course is a
GI that MIT died edu I am a part of an amazing team many of whom you know AGI
at MIT that edu is the email where on slack deep - MIT does slack for
registered MIT students you create account on the website and submit five new links and vote on ten to
vote AI which is an aggregator of information a material we've put together for the topic of AGI and submit
a entry to one of the competitions one of the three competitions projects that
we have in this course and the projects are dream vision I'll go over them in a
little bit dream vision angel ethical car and the aggregator of material vote
AI we have guest speakers incredible guest speakers I will go over them today and as before with a deep learning for
self-driving cars course we have shirts and they're free for in-person for
people that attend in person for the last lecture most likely or you can order them online
okay dream vision we take the Google G dream idea we explore the idea of
creativity where it is I ins view of intelligence the mark of intelligence is creativity this this idea is something
we explore by using neural networks and interesting ways to visualize what the
networks see and in so doing create beautiful visualizations in time through
video so taking the ideas of deep dream and combining them together with
multiple video streams to mix dream and reality and the competition is through
Mechanical Turk we set up a competition of who produces the most beautiful
visualization will provide code to generate this visualization and ideas of
how you can make it more and more beautiful and how to submit it to the
competition angel the artificial neural generator of emotion and language is a
ANGEL: Artificial Neural Generator of Emotion and Language
different twist on the Turing test where we don't use words we all
using motions to speak expression of those emotions and we create we use an
age a face customizable we're 26 muscles
all of which can be controlled with an LS TM we use a neural network to train
the generation of emotion and the
competition in you submitting the code to the competition is you get 10 seconds
to impress with the these expressions of emotion the viewer
it's a be testing your goal is to impress the viewer enough to where they
choose your agent versus another agent and those that are most loved the agents
most loved will be the ones that are declared winners in a twist we will add
human beings into this mix so we've created a system that map's our human
faces myself and the TAS to where we ourselves enter an outcome in the
competition and try to convince you to keep us as your friend that's the Turing test ethical car
EthicalCar: Machine Learning Approach
building and the ideas of the trolley problem and the moral machine done here
in the Media Lab the incredible interesting work we take a machine learning approach to it and take what
we've developed the deep reinforcement learning competition for success 0 9 for
the deep traffic and we add pedestrians into it stochastic astok irrational
unpredictable pedestrians and we add human life to the loss function where
there's a trade-off between getting from point A to point B so in deep traffic
the deep reinforcement learning competition the goal was to go as fast as possible here it's up to you to
decide what what your agents goal is there's a parade of front
trade-off between getting from point A to point B as fast as possible and
hurting pedestrians this is not a
ethical question it's an engineering question and it's a serious one because
fundamentally in creating autonomous vehicles that function in this world we
want them to get from point A to point B as quickly as possible the United States government insurance
companies put a price tag on human life we put that power in your hands
in designing these agents to ask the question of a how can we create machine
learning systems where the objective function the loss function has human life as part of it and vote AI is an
aggregator of different links different
articles papers videos on the topic of artificial general intelligence where people vote on vote quality articles up
and down and choose on the sentiment of
positive and negative we'd like to explore the different ways to the different arguments for and against
artificial general intelligence there is
an incredible list of speakers the best in their disciplines from Josh Tenenbaum
PN MIT to Ray Kurzweil at Google to lisa Feldman Barrett and Nader Pinsky from
Northeastern University Andre karpati Stephen Wolfram Richard
Moyes mark Robert Ilya sutskever and myself Josh Tenenbaum
Josh Tenenbaum, MIT Computational Cognitive Science
tomorrow I'd like to go through each of these speakers and talk about the
perspectives they bring that to try to see the approach the
ideas they bring to the table they're not in most cases interested in the
discussion of the future impact on society without grounding it into the
expertise into the actual engineering into creating these intelligent systems so josh is a computational cognitive
science expert professor faculty here at MIT he will talk about how we can create
common-sense understanding systems that see a world of physical objects and
their interactions and our own possibilities to act interact with others the intuitive physics how do we
build into systems the intuitive physics of the world more than just the deep
learning memorization engines that take patterns and learn through supervised
way to map those patterns to classification actually begin to
understand the intuitive the common-sense physics of the world and learn rapid model based learning learn
from nothing learn from very little just like we do as children just like we do as human being successfully often only
need one example to learn a concept how do we create systems that learn from
very few sometimes a single example and integrate ideas from various disciplines
of course from neural networks but also probabilistic generative models and symbol processing architectures it's
going to be incredible of course from a from a different area of the world
another incredible thinker intellectual speaker is Ray Kurzweil he'll be here on
Wednesday and 1:00 p.m. and he will do a whirlwind discussion of where we stand
with intelligence creating intelligent systems how we see natural intelligence our own human intelligence how we define
it how we understand it and how that transfers to the increasing exponential
growth of development of artificial general intelligence
Lisa Feldman Barrett, NEU Emotion Creation
something I'm myself very excited about is Lisa Feldman Barrett coming here on
Thursday she's written a book I believe how emotions are made she argues that
emotions are created that there is a distinction there's a detachment between
what we feel in our bodies the physical state of our bodies and the expression
of emotion from from body to the contextually grounded to the face
expressing that emotion which means now why is there as a person who is
psychology person in a fundamental engineering computer science topic like AGI because if emotions are created in
the way she argues and she'll systematically break it down that means we're learning societal as
human beings were learning societal norms of how to express emotion the idea of emotional intelligence is learned
which means we can have machines learn this idea it's a machine learn like it's
a human learning problem it's a machine learning problem in a little bit of a
twist she asked that instead of giving it talk I have a conversation with her
so it's going to be a little bit challenging and fun and she's great
looking forward to it and we'll explore different ways that we can get emotion
Re-Enacting Intelligence
expressed through video through audio through the project the angel project
that I mentioned so there's been worked in reenacting intelligence so well
reenacting mapping face to face mapping different emotions on video that was
previously recorded so if you can imagine that means we can take emotions
that we've created the kind of emotion creation we've been discussing and remap it on previous video that's one way to
see intelligence is taking raw human data that we already have and mapping
new computer-generated the the underlying fundamentals of human
but the surface appearance the representation of emotion visual or
auditory is generated by a computer it
could be in the embodied form
Sophia: Embodied Re-Enactment
[Music] very important to note for those
captivated by Sofia in the press or have seen these videos Sofia is an art exhibit she's not a
strong natural language processing system this is not an AGI system but
it's a beautiful visualization of embodying of Hollow it's a beautiful visualization of how
easy it is to trick us human beings that there's intelligence underlying something that the emotional expression
the physical embodiment and the emotional expression that has a that has
some degree of humor that has some degree of wit and intelligence is enough
to captivate us so that's an argument for not creating intelligence from scratch but having machines at the very
surface the display of that emotion the generation the mapping of the visual and
auditory elements worth underneath it is really trivial technology that's
fundamentally relying on humans like in the sophia's case and in the simplest
form we remove all elements of Hajus a
attractive appearance from from an agent we really keep it to the simplest
muscles characteristics of the face and see with 26 muscles controlled by a neural
network through time so recurrent neural network I was TM how can we explore the
generation of emotion can we get this thing and this is an open question for us too we just created the system we
don't know if we can can we get it to make us feel something make us feel
something by watching it express its feelings can it become human before our
eyes can I learn to by competing against other agents a be testing on Turk a
Mechanical Turk can the winners be very convincing to make us feel entertained
pity love maybe some of you will fall in love with angel here Nate dibinsky on
Nate Derbinsky, NEU Cognitive Modeling
Friday will talk about cognitive modeling architectures so you will speak about the cognitive modeling aspect can
we have a ma can we model cognition in some kind of systematic way to try to
build intuition of how complicated cognition is Andre karpati famous for
being the state-of-the-art human on the imagenet challenge the representative
the 95% accuracy performance among other things he's also famous for his now a
Tesla he will talk about the role the limitations the possibilities of deep
learning we'll talk as I have spoken
about in the past few weeks and throughout about our misunderstanding or
our flawed intuition about what are the difficult and what are the easy problems in deep learning and the power of
Deep Learning is Representation Learning Talca Feature Learning
representational learning the ability of neural networks to form deeper and deeper representations of the underlying
raw data that ultimately forms
takes complex information that's hard to make sense of and convert it into useful
actionable knowledge that is from a
certain lens in a certain a certain lens in a certain problem space can be
clearly defined as understanding of the complex information understanding is
ultimately taking complex information and reducing it to its simple essential elements representational learning is in
the trivial case here in drawing having to draw a straight line to separate the
blue and the red curves that's impossible to do in the in initial input
space on the Left what the act of learning is for deep neural networks in this formulation is to construct a
topology under which there exists a straight line to accurately classify blue versus red that's the problem and
for a simple blue and red line it seems trivial here but this works in the general case for arbitrary input
spaces for arbitrary nonlinear highly dimensional input spaces and the ability
to automatically learn features to learn hierarchical representations of the raw
sensory data means that you could do a lot more with data which means you can expand further and further and further
to create intelligent systems that operate successfully with real-world
data that's what representational learning means that deep learning allows because the arbitrary number of features
that can be automatically determined you can learn a lot of things about a pretty
complex world unfortunately there needs to be a lot of supervised data there still needs to be
a lot of human input Andre and others
Josh will talk about the difference between our human brain our biological
neural network and the artificial neural network the full human brain with 100
billion neurons 1000 trillion synapses and the biggest neural networks out
there the artificial neural network having much smaller 60 million synapses
for ResNet 152 the biggest difference the parameter is a human brain being
Neuron: Biological Inspiration for Computation
several orders of magnitude more synapses the topology being much more
complex chaotic the asynchronous nature of the human brain and the learning
algorithm of artificial neural networks is trivial and constrained with
backpropagation is essentially an optimization function over over a clearly defined loss function from the
output to the to the input using back propagation to teach to adjust the
weights on that network the learning algorithm for our human brain is mostly
unknown but it's certainly much more complicated than back propagation the
power consumption the human brain is a lot more efficient than artificial neural networks and there's a very kind
of artificial trivial supervised learning process for training artificial
neural networks you have to have a training stage and you have to have an evaluation stage and once the network is
trained there's no clear way to continue training it or there's a there's a lot of ways but they're inefficient it's not
designed to do online learning naturally to always be learning is designed to be
to learn and then be applied obviously our human brains are always learning but
the beautiful fascinating thing is that they're both distributed computation
systems on a large scale so it's not a there's it doesn't ultimately boil down
to a single compute unit the computation is distributed the back propagation
learning process is distributed can be paralyzed in a GPU massively paralyzed the underlying computational unit of a
neuron is trivial but can be stacked together to form forward neural networks recurrent neural networks to represent
both spatial information with images and temporal information we
the audio speech text sequences of images and video and so on mapping from
one-to-one one-to-many many-to-one so the mapping any kind of structure vector
and time data as an input to any kind of classification regression sequences
captioning video audio as output learning in the general sense but in a
domain that's precisely defined for the supervised training process we can think
Deep Learning from Human and Machine
of the in deep learning case you can think of the supervised methods where
humans have to annotate the data as memorization of the data we can think of the exciting new and growing field of
semi-supervised learning where most of the data through or through generative adversarial networks or through
significant data augmentation clever data augmentation most of it is done automatically the annotation process or
through simulation and then reinforcement learning where most of the most of the labels are extremely sparse
and come rarely and so the system has to figure out how to operate in the world with very little human input very little
human data we can think of that as reasoning because you take very little
information from our teachers the humans and transfer it across generalize it across to reason about the world and
finally unsupervised learning the excitement of the community that promise the hope you could think of that as
understanding because ultimately it's taking data with very little or no human input and forming representations that
that data is how we think of understanding requiring making sense of
the world without strict input of how to make sense of the world the kind of
process of discovering information maybe discovering new ideas new ways to
simplify the world to represent the world that you can do new things with it the new is the key element there
understanding and Andre and Ilya and others will talk
Past and Future of Deep Learning Breakthroughs
about the certainly the past but the future of deep learning where is it going to go
is it overhyped underhyped what is the future will the compute of cpu GPU si
Asics continue with the breakthroughs the Moore's law in its various forms of
massive parallelization continue and the large datasets with tens of millions of
images grow to billions and trillions will the algorithms improve is there a
groundbreaking idea that's still coming look with Jeff hiddens capsule networks
is there fundamental architectural changes to neural networks that we can come up with that will change everything
that will ease the learning process they'll make the learning process more efficient or we'll be able to represent
higher and higher orders of information such that you can transform knowledge
between domains and the software architectures that support intensive
florida pi torch i would say last year and this year will be the year of deep learning frameworks so those will
certainly keep coming in their various forms and the financial backing is growing and growing the open challenges
Current Challenges
for deep learning really a lot of this course is kind of connected to deep learning because that's where a lot of
the recent breakthroughs that inspire us to think about intelligence systems come
from but the challenges of many the need the ability to transfer between different domains as in reinforcement
learning and robotics the need for huge data in an official learning that we
still need supervised data an ability to learn in an unsupervised way is a huge
problem and not fully automated learning there's still a degree a significant
degree of hyper parameter necessary with the reward functions the loss functions are ultimately defined by humans and
therefore are deeply flawed when we release those systems into the real
world there is no ground truth for the testing set and the goal isn't achieving a class
high classification on a trivial image classification localization detection
problem but rather to have a autonomous vehicle that doesn't kill pedestrians or
an industrial robot that operates in jointly with other human beings and all
the edge cases that come up how does deep learning methods how do machine learning methods generalize over the
edge cases the weird stuff that happens in the real world those are all the problems there Stephen Wolfram will be
Stephen Wolfram Knowledge-Based Programming
here on Monday evening at 7 p.m. has done a lot of amazing things I would say
is very interesting from his recent interest in knowledge based programming Wolfram Alpha I think is the fuel for
most middle school and high school students now for the first time taking
calculus I pray probably go to Wolfram Alpha to answer their own questions but more seriously there is a a deep
connected graph of knowledge is being built there with the Wolfram or Wolfram
Alpha and Wolfram language that steel will explore in terms of language an
interesting thing he was part of the team on arrival that worked on the
language if for those of you are familiar the arrival were a alien
species spoke with us us humans through a very interesting beautiful complicated
language and he was brought in as a representative human to interpret that language just like in the movie he was
represent that in real life and you used the skills that him and his son Christopher used to analyze this
language very interesting that process is extremely interesting I hope he talks about it and his background with
"Artificial Life Simulation": Cellular Automata and Emerging Complexity
Mathematica and new kind of science the
sort of another set of ideas that have
inspired people in terms of creating
intelligence systems is the idea that from very simple things were very simple
rules extremely complex patterns can emerge his work was cellular automata
did just that taking extremely simple mathematical constructs here with
cellular automata these are these are grids of computational units that switch
on and off in some kind of a predefined way and only operate locally based on their local neighborhood and somehow
based on different kinds of rules different patterns emerge here's a three dimensional cellular automata with a
simple rule starting with nothing with a single cell they grow in really interesting complex ways this emergent
complexity is inspiring it's the same kind of thing that inspires us about
neural networks that you can take a simple computational unit and when combined together in arbitrary ways can
form complex representations that's also very interesting you can see knowledge
from a knowledge perspective you can see knowledge formation in the same kind of way simplicity at a mass distributed
scale resulting in complexity next Tuesday
Richard Moyes, Article36 Al Safety and Autonomous Weapon Systems
Richard Moyes from article 36 coming all the way from UK for us we'll talk about
it works with autonomous weapons systems works with also nuclear weapons but
primarily autonomous weapon systems and concern legal policy and technological
aspects of banning these weapons there's been a lot of agreement about the safety
hazards of autonomous systems that make decisions to kill a human being
mark Robert CEO of Boston Dynamics previously a long time ago faculty here
Marc Raibert, CEO, Boston Dynamics Robots in the Real World
at MIT will talk about will bring robots and talk to us about his work of robots
in the real world as doing a lot of exciting stuff with humanoid robotics and any kind of robots operating on legs
it's incredible work extremely exciting and gets to explore the idea of how difficult it is
to build these robot systems that operate in the real world from both the
control aspect and from the way the
final result is perceived by our society it's very interesting to see when
intelligence in robotics is embodied and then taking in by us and what that
inspires fear excitement hope concern and all the above Ilya sutskever is
expert in many aspects of machine learning he is the co-founder of open AI I'll
talk about their different aspects of game playing that they've recently been
exploring about using deeper enforcement learning to play our K games in D on the
deep mind side using deep reinforcement learning to beat the best in the world that the game of go in 2017 the big
fascinating breakthrough achieved by that team with alphago zero training an agent that through self play playing
itself not on expert games so truly from scratch learning to beat the best in the
world including the previous iteration of alphago we will explore what aspects of the
stack of intelligent robotic systems intelligent agents can be learned in
this way so deep learning the memorization the supervised learning memorization approach it looks at the
sensor data feature extraction representation learning aspect of this taking the sensor data from camera light
our audio extracting the features forming higher-order representations and
on those representations learning to actually accomplish some kind of classification regression task figuring
out based on the representation what is going on in the raw sensory data and then combining that data together to
reason about it and finally in the robotic domains taking it all together
as with human industrial robotics autonomous vehicles
taking all together and actually acting in this world with the effectors and the
open question is how much of this AI stack can be learned that's something
for us to discuss to think about that a Leo will touch on with deeper
enforcement learning we can certainly learn representations and perform classifications state-of-the-art better
than human and image classification imagenet and segmentation tasks and the
excitement of deep learning is what's highlighted there in the red box can be done end to ends raw sensory data out to the knowledge to
the output to the classification can we begin to reason is the open question with the knowledge based programming
that Stephen Wolfram will talk about can we begin to take these automatically generated high order representations and
combine them together to form knowledge bases to form aggregate graphs of ideas
that can then be used to reason and can we then combine them together to act in
the world for whether in simulation with arcade games or simulation of autonomous
vehicles or biotic systems or actually in the physical world with robots moving about can that end end from raw sensory
data to action be learned that's the open question for for artificial general
intelligence for this class can this entire process be end to end can we
build systems and how do we do it that achieve this process end to end in the
same way that humans do we're born in this raw sensory environment taking in very little information and learn to
operate successfully in arbitrary constraints arbitrary goals and to do so
we have lectures we have three projects and we have guest speakers from various
disciplines I hope that all these voices will be heard and will feed a
conversation artificial intelligence and it's positive and it's concerning effects in
society and how do we move forward from an engineering approach the topics will
be deep learning deep reinforcement learning cognitive modeling computational cognitive science emotion
creation knowledge based programming AI safety with autonomous weapon systems and personal robotics with human
centered artificial intelligence that's for the first two weeks of this class that's the the part where if you're
actually registered students that's where you need to submit the project that's when we all meet here every every
night with the incredible speakers but this will continue we already have several speakers scheduled in the next
couple of months yet to be announced but they're incredible and we have
conversations on video and we have new projects I hope this continues throughout 2018 on
the topics of IAI ethics and bias there's a lot of incredible work in we
now have a speaker there coming on the topic of how do we create artificial intelligence systems that I do not
discriminate do not form the kind of biases that us humans do in this world
that are operating under social norms but our reasoning beyond the flawed
aspects of those social norms with bias creativity as with a project of dream
vision and beyond there is so much exciting work in charin using machine
learning methods to create beautiful art and music brain simulation neuroscience
competition in neuroscience shockingly in the first two weeks we don't have a competition neuroscience speaker which
is a fascinating perspective brain simulation or neuroscience in general
computational neuroscience is a fascinating approach from the from the muck of actual brain work to get the
perspective of how our brain works and how we can create something that mimics that resembles the fundamentals of what
makes our brain intelligent and finally the touring test the traditional definition of intelligence defined by
Alan Turing was grounded in natural language processing creating chat BOTS that impress us that amaze us and trick
us into thinking they're human we will have a project and a speaker on natural
language processing in March with that I'd like to thank you for coming today
and look forward to seeing your submissions for the three projects thank you very much

----------

-----
--27--

-----
Date: 2018.01.30
Link: [# MIT 6.S094: Deep Learning for Human Sensing](https://www.youtube.com/watch?v=Z2GfE8pLyxc)
Transcription:


Intro
today we will talk about how to apply the methods of deep learning to
understanding the sense of the human being the focus will be on computer vision the visual aspects of a human
being of course we humans express ourselves visually but also through audio voice
and through text beautiful poetry and novels and so on we're not going to
touch those today we're just going to focus on computer vision how we can use computer vision to extract useful
actionable information from video images video of human beings in particular in
the context of the car so what are the
requirements for successfully applying deep learning methods in the real world so when we're talking about human
sensing we're not talking about a basic face recognition of celebrity images
we're talking about using computer vision deep learning methods to create
systems that operate in the real world and in order for them to operate in the real world there are several things they
sound simple some are much harder than they sound first and the most important
here for most to less more to less critical ordered is data data is
everything real world data we need a lot of real world data to form the data set
on which these supervised learning methods can be trained I'll say this
over and over throughout the day today data is everything that means data collection is the hardest part and the
most important part we'll talk about how that data collection is carried out here in our group at MIT all the different
ways to capture human beings in the driving context in the road user context pedestrians cyclists but the data it
starts and ends at data the fun stuff is the algorithms but the data is what
makes it all work real world data okay then once you have the data okay data
isn't everything I lied because you have to actually annotate it so what do we mean by data there's raw data video
audio lidar all the types of sensors we'll talk about to capture real world
you wrote user interaction you have to reduce that into meaningful
representative cases of what happens in that real world in driving 99% of the
time driving looks the same it's the it's the 1% the interesting cases that we're interested in and what we want is
algorithm to train learning algorithms on those 1% so we have to collect 100
percent we have to collect all the data and then figure out and automated semi-automated ways to find the pieces
of that data that could be used to train your own networks and that a representative of the general thing
kinds of things that happen in this world efficient annotation annotation
isn't just about drawing bounding boxes on images of cats annotation tooling is
key to unlocking real world performance
systems that successfully solve some problem accomplish some goal in real
world data that means designing annotation tools for a particular task annotation tools that are used for
glance classification for determining where drivers are looking it's very different than annotation tools used for
body pose estimation is very different than the tooling use that we use for
psyche views investing thousands of dollars for the competition for this class to annotate fully scene
segmentation where every pixel is colored there's needs to be tooling for each one of those elements and they're
key that's HCI question that's a design question there's no deep learning
there's no robotics in that question it's how do we leverage human
computation human the human brain to mow effectively label images such that we
can train y'all networks on them hardware in order to train these
networks in order to parse the data we collect and we'll talk about we have now
over five billion images of data of driving data in order to parse that you
can't do it on a single machine you have to do large-scale distributed compute
and large-scale distributed storage and finally the the stuff that's the most
exciting that people that there's this class and many classes and much of the
literature is focused on is the algorithms the deep learning algorithms the machine learning algorithms the
algorithms that learn from data of course that's really exciting and important but what we find time and time
again in real world systems is that as long as these algorithms learn from data
so as long as this deep learning the data is what's much more important of
course it's nice for the algorithms to be calibration free meaning they learn
to calibrate self calibrate we don't need to have the sensors in an exact same position every time that's a very
nice feature the robustness of the system is then generalizable across multiple multiple vehicles and multiple
scenarios and one of the key things that comes up time again time and time again
and we'll mention today is a lot of the algorithms developed in deep learning are really focused for computer vision
are focused on single images now the real world is happens in both space and
time and we have to have algorithms that both capture the visual characteristics but also look at the sequence of images
sequence of those digital characteristics that form the temporal dynamics the physics of this world so
it's nice when those algorithms are able to capture the physics of the scene
the big takeaway I would like if you leave with anything today
unfortunately it's that the painful boring stuff of collecting data of
cleaning that data of annotating that data in order to create successful
systems is much more important than good algorithms or great algorithms it's important to have good algorithms as
long as you have neural networks that learn from that data okay so today I'll
Human Imperfections
talk I like to talk about human imperfections and the various detection
problems the pedestrian body pose glance and motion cognitive load estimation
that we can use to help those humans as they operate in the driving context and
finally try to continue with the idea of
the vision that fully autonomous vehicles as some of our guest speakers have spoke about and sterling anis will
speak about tomorrow is really far away that the humans will be an integral part
of the operating cooperating with the AI systems and I will continue on on that
line of thought to try to motivate why we need to continuously approach the
autonomous vehicle the self-driving car paradigm in the human centered way okay
first before we talk about human imperfections let's just pause and
acknowledge that humans are amazing we're actually really good at a lot of
things that's sometimes sort of fun to talk about how much called terrible of
drivers who are how distracted we are how irrational we are but we're actually really damn good at driving here's a
video of stadia our soccer player messi the best soccer player in the world
obviously and the state-of-the-art robot on the right same thing
well there's it's not playing but I assure you the American Ninja Warrior
Casey is is uh is far superior to the
DARPA humanoid robotics systems shown on the right okay so continuing and the
line of thought to challenge to challenge us here that humans are amazing is you know there's record high
in 2016 in the United States there was over forty thousand since uh many years
it's across the forty thousand fatalities mark more than forty thousand people died in car crashes in the United
States but that's in three point two trillion miles traveled so that's one
fatality per eighty million miles that's one in 625 chance of dying in a car
crash in your lifetime interesting side fact for anyone in the United States
folks who live in Massachusetts are the least likely to die in a car crash
Montana is the most likely so for every
one that thinks of Boston drives is terrible maybe that adds some
perspective here's a visualization of ways data across a period of a day
showing you the rich blood of the city that the the traffic flow of the city the people getting from A to B and a
mass scale and doing it surviving doing it okay humans are amazing but they're
also flawed texting sources of distraction with a smartphone the eating
the secondary tasks of talking to other passengers grooming reading using
navigation system yes sometimes watching video and manually adjusting or
adjusting the radio and 3,000 people were killed and 400,000 were injured in
motor vehicle crashes vaulted involving distraction in 2014 distraction is a it's a very
serious issue for safety texting every day more and more people text
smartphones are proliferating our society 170 billion text messages are
sent in the United States every month that's in 2014 you can only imagine what it is today
eyes off road for five seconds is the average time your eyes off the road while texting five seconds if you're
traveling 55 miles an hour in that five seconds that's enough time to cover the length of a football field
so you're blindfolded you're not looking at the road in five seconds the average time of texting you're covering the
entire football field eight so many things can happen in that moment of time
that's distraction drunk driving 31% of
traffic fatalities involve a drunk driver drunk driving 23% of nighttime
drivers tested positive for a legal prescription or over-the-counter medication distracted driving as I said
is a huge safety risk drowsy driving people driving tired nearly three
percent of all traffic fatalities involve a drowsy driver if you are
uncomfortable with videos that involve risk I urge you to look away these are
videos collected by Triple A of teenagers a very large-scale naturalistic driving data set and it's
capturing clips of teenagers being distracted on their smartphone
[Music]
once you take it in the problem we're against
so in the cutting context of human imperfections we have
to ask ourselves is the human centered approach to autonomy in systems autonomous vehicles that are using
artificial intelligence to aid the driving task do we want to go as I mentioned a couple of lectures ago the
human centered way or the full autonomy way the tempting path is towards full autonomy where we removed this imperfect
flawed human from the picture altogether and focus on the robotics problem of
perception and control and planning and driving policy or do we work together
human and machine to improve the safety to alleviate distraction to bring drive
our attention back to the road and use artificial intelligence to increase safety through collaboration human robot
interaction versus removing the human completely from the picture as I've
mentioned as as sterling will certainly talk about tomorrow and and rightfully
so and yesterday or on Tuesday Emilio has talked about the elf four-way is
grounded in literature it's grounded in common sense since in some sense it's
you can count on the fact that humans the the natural flaws of human beings to
over trust to misbehave to be irrational about their risk estimates will result
in improper use of the technology and that leads to what I've showed before
the public perception of what drivers do and semi autonomous vehicles they begin to over trust the moment the system
works well they begin to over trust they begin to do stuff they're not supposed to be doing in the car taking it for
granted a recent video that somebody posted this is a common sort of more
practical concern that people have is while the traditional ways to ensure the
physical engagement of the driver is by saying they should touch the wheel the the steering wheel every once in a while
and of course there's ways to buy the need to touch the steering wheel
some people hang objects like I can off of the steering wheel in this case
brilliantly I have to say they shove an orange into the into the wheel to make
the touch sensor fire and therefore be able to take their hands off the autopilot and that that kind of idea
makes us believe that there's no way that you know humans will find a way to misuse this technology however I believe
that that's not giving the technology enough credit artificial intelligence
systems if are they're able to perceive the human being are also able to work with the human being and that's what I'd
like to talk about today teaching cars to perceive the human being and it all
starts with data it's all about data as I mentioned data is everything in these
real world systems with the MIT naturalistic driving data set of 25
vehicles of which 25 and 21 and equipped with Tesla autopilot we instrument them
this is what we do the data collection two cameras on the driver will see the cameras on the face capturing
high-definition video of the face that's where we get the glance classification the emotion recognition cognitive load
everything coming from the face that we have another camera or a fisheye that's looking at the body of the driver and
that from that comes the body pose estimation hands on wheel activity
recognition and then one video looking out for the full scene segmentation for all the scene perception tasks and
everything is being recorded synchronized together with GPS with audio with all the can covered from the
car on a single device synchronization of this data is critical so that's one
road trip in the data where thousands like it traveling hundreds of miles
sometimes hundreds of miles under automated control and autopilot that's
the data again as I said data is everything and from this data we can both gain
understanding what people do which is really important to understand how
autonomy successful autonomy can be deployed in the real world and to design
algorithms as for training for training the deep learning the deep neural
networks in order to perform the perception tasks better twenty five
beagles 21 Tesla's Model S Model X and
now model three over a thousand miles collected a day every single day we have
thousands of miles in the Boston Massachusetts area driving around all of that video being recorded now over five
billion video frames there are several
ways to look at autonomy one of the big ones is safety that's what everybody
talks about how do we make these things safe but the other one is enjoyment do
people actually want to use it it we can create a perfectly safe system we can
create it right now we've had it for ever before even cars a car that never
moves is a perfectly safe system well not perfectly but almost and but it
doesn't provide a service that's valuable it doesn't provide an enjoyable driving experience so okay what about
slow moving vehicles that's an open question the reality is with these Tesla
vehicles and l2 systems doing automated driving people are driving 33% of miles
using Tesla autopilot what does that mean that means that people are getting
value from it they a large fraction of their driving is done an automated way
that's value that's enjoyment the glance
suffocation algorithm we'll talk about today is used as one example that we use
to understand what's in this data shown with the bar graphs there and the red and the blue red is during manual
driving blues during autopilot driving and we look at glance classification regions of where drivers are looking on
road and off-road and if that distribution changes with automated driving or manual driving and would
these glass classification methods we can determine that there's not much difference at least until you dig into
the details which we haven't done and the aggregate there's not a significant difference that means people are getting
value enjoying using these technologies but yet they're staying attentive or at
least not attentive but physically engaged when your eyes are on the road
you might not be attentive but you're at the very least physically your body's
position in such a way your head is looking at the forward roadway that you're physically in position to be
alert and to take in the forward roadway so they're using it and they don't over
trust it and that's I think the sweet spot that human-robot interaction needs
to achieve is the human gaining through
experience through exploration through trial and error exploring and understanding the limitation of the
system to a degree that over trust can occur that seems to be happening in this system and using the computer vision
methods I'll talk about we can continue to explore how that can be achieved in other systems when the when the when the
fraction of automated driving increases from 30% to 40% to 50% and so on it's
all about the data and I'll I'll harp on this again the algorithms are interesting you know I will mention of
course it's the same convolution neural networks it's the same networks that
take in raw pixels and extract features of interest it's 3d convolutional neural
networks that take into sequences of images and extract the temporal dynamics along with the visual characteristic for
the individual images it's RN and zoella's TMS that use the convolutional
neural networks to extract features and over time look at the dynamics and the
images these are pretty basic architecture is the same kind of deep neural network architectures but they
rely fundamentally and deeply on the data on real-world data so let's start
Pedestrian Detection
where perhaps on the human sensing side it all began which is pedestrian detection decades ago to put it in con
texe pedestrian detection here shown from left to right on the left is green showing the easier human sensing tasks
tasks of sensing some aspect to a human being but as for your detection which is detecting the full body of a human being
in an image or video is one of the easier computer vision tasks and on the
right under in the red microcircuits these are the tremors of the eye or
measuring the pupil diameter or measuring the cognitive load or the fine blink dynamics of the eye the velocity
of the blink micro glances and I pose are much harder problems
so you think body pose estimation pedestrian detection phase classification detection recognition
head pose estimation all those are easier tasks anything that starts getting smaller looking at the eye and
everything that start getting fine-grained there's much more difficult so we start at the easiest pedestrian
detection and as the usual challenges of all of computer vision we've talked
about as the various styles of appearance so the inter class variation
the different possible articulations of put it of our bodies superseded only
perhaps by cats but as humans are pretty flexible as well the presence of
occlusion from the accessories that we wear to occluding self occlusion and including each other but that crowded
scenes have a lot of humans in them and they include each other and therefore to be able to disambiguate to figure out
each individual pedestrians is a very challenging problem so how do people approach this problem well there is I
need to extract features from raw pixels
whether that was hot cascades hog or CNN the through the decades the sliding
window approach was used because the pedestrians can be small in an image or big so there's the problem of scale so
you use a sliding window to detect where that pedestrian is you have a classifier
that's given a single image such as this that's you're not you take that classify you slide across the image to find where
all the pedestrians of scene are so you can use non neural network methods or you can use convolution neural networks
for that classifier it's extremely inefficient then came along our CNN fast
our CNN fast our CNN these are networks that as opposed to doing a complete
sliding window approach are much more intelligent clever about generating the
candidates to consider so as opposed to considering every possible position of a window different scales of the window
they generate more a small subset of candidates that are more likely and
finally using a CNN classify for those candidates whether there's a pedestrian or not whether the there's an object of
interest or not a face or not and using that maximum suppression because there's
overlapping bounding boxes to figure out what is the most likely bounding box around this pedestrian around this
object that's our CNN and there's a lot of variants now with masks our CNN
really the state-of-the-art localization Network mask also adds to this on top of
the body box also performed segmentation there's voxel net which does three-dimensional and light our data
uses localization and point clouds so it's not just using it to the images but in 3d but it's it's it's all kind of
grounded in the our CNN framework ok data so we have large-scale data
collection going on here in Cambridge if you've seen cameras a lidar various intersections throughout MIT we're part
of that so for example here's one of the intersections to collecting about 10 hours a day instrumenting it with
various sensors I'll mention but we see about 12,000 pedestrians a day across
that particular intersection using 4k cameras using stereo vision cameras 360
now the insta 360 which is an 8k 360 camera gopro lidar various sizes the 64
channel of the 6 and recording this is where this is the
this is where the data comes from this is from the 360 video this is from the
lidar data of the same intersection this is for the 4k camcorders pointing at a
different intersection and the different than capturing the entire 360 view with
the vehicles approaching in the pedestrians making crossing decisions this is understanding the negotiation
that pedestrian is the nonverbal negotiation that pedestrians perform and choosing to cross or not especially when
they're jaywalking and everybody jaywalks especially if you're familiar
with this particular intersection there's more Jay walkers than non jaywalkers it's a fascinating one and so
we record everything about the driver and everything about the pedestrians
again our CNN this is where it comes in is you do Bonney box detection of the
pedestrians here are the vehicles as well and allows you to convert this raw data into hours of pedestrian crossing
decisions and begin to interpret it that's pedestrian detection bounding box
for body pose estimation is the more
Body Pose Estimation
difficult task body pose estimation is also finding the joints the hands the
elbows the shoulders the hips knees feet the landmark points in the image XY
position that marked that those joints that's body pose estimation so why is
that important in driving for example it's it's important to determine the vertical position or the alignment of
the driver the seatbelts and the sort of the the airbag testing is always
performing the seatbelt testing is performed with the dummy considering the frontal position in a standard dummy
position the the greater greater degrees of automation comes more capability and
flexibility for the driver to get misaligned from the standard corner dummy position and so body pose or at
least upper body pose estimation allows you to determine how often these drivers get out of line from the standard
position the general movement and then you can look at hands on wheel smartphone smartphone detection activity
and help add context to glance estimation that which we'll talk about
so some of the more traditional methods were sequential is detecting first the
head and then stepping detecting the shoulders the elbows the hands the
depot's holistic view which has been the very powerful successful way for multi
person pose estimation is performing a regression of detecting body parts from
the entire image it's not sequentially stitching bodies together it's detecting
the left elbow the right elbow the hands individually it's performing that
detection and then stitching everything together afterwards allowing you to deal
with the crazy deformations of the body that happened the occlusions and so on
because you don't need all the joints to be visible and with this cascade of pose
regressors meaning these are convolutional neural networks had taken a raw image and produce an XY position
of their estimate of each individual joint input as an image output is an
estimate of a joint of elbow shoulder whatever one of several landmarks and
then you can build on top of that every estimation zooms in on that particular
area and performs a finer and finer grain estimation of the exact position
of the Joye repeating it over and over and over so through this process we can
do part detection and multi-person and multi-person scene that contain multiple
people so we can detect the the head the neck here the hands the elbows shown in
the various images on the right that don't have an understanding who the head the elbows the the hands belong to
it's just performing a detection without trying to do individual person detection
first and then finally connecting or not
finally but next step is connecting with part affinity fields is connecting those
parts together so first you detect individual parts then you connect them together and then through bipartite
matching you determine which is who is that each individual body part most likely belonging to so you kind of
stitch the different people together in the scene after the detection is performed with the CNN
we use this approach for detecting the upper body specifically the shoulders
the neck and the head eyes nose ears that is used to determine the the
position of the driver relative to the standard dummy position for example looking during autopilot driving
30-minute periods we can look at on the x-axis is time and the y-axis is the
position of the neck point that I pointed out in the previous slide that the the the midpoint between the two
shoulders the neck is the position over time relative to where it began this is
the slouching the sinking into the seat allowing the car to know that
information and allowing us or the designers of safety systems and all that information is really important we can
use the same body pose algorithm to from the perspective of the vehicle outside the vehicle perspective so the vehicle
looking out is doing the as opposed to just plain pedestrian detection using body pose estimation again here in
Kendall Square vehicles crossing observing pedestrians making crossing
decisions and performing body pose estimation which allows you to then
generate visualizations like this and gain understanding like this on the
x-axis is time on the y-axis is on the top plot in blue is the speed of the
vehicle the speed of the vehicle the ego vehicle from which the camera is
observing the scene and on the bottom in green up and down as a binary value
whether the Podesta when the pedestrian is not looking at the car one when the pedestrian is looking at the car so we
can look at thousands of episodes like this crossing decisions nonverbal communication decisions and determine
using body pose estimation the dynamics of this nonverbal
here just nearby by media lab crossing there's a pedestrian approaches we can
look in green there when the pedestrian glasses looks away glasses the car looks away fascinating glance behavior that
happens interesting most people look away before they cross same thing here
this is just an example we have thousands of these body pose estimation allows you to get this fine-grained
information about the pedestrian glance behavior pedestrian body behavior
hesitation glass classification one of
Glance Classification
the most important things in driving is determining where drivers are looking it
if there's any sensing that I advocate
and is has the most impact in the driving context is for the car to know
where the driver is looking and at the very crude region level information of
is the driver looking on road or off road that's what we mean by glance classification it's not the standard
gaze estimation problem of X Y Z determining where the eye pose and the head pose combined to determine where
the driver is looking no this is classifying two regions on road off-road
or six regions on road off road left right center stack rearview mirror and
instrument cluster so it's region based glance allocation not the geometric gaze
estimation problem why is that important it allows you to address it as a machine
learning problem it's a subtle but critical point every problem we try to solve in human sensing in driver sensing
has to be learn about from data otherwise it's not it's not amenable to
application in the real world we can't design systems in the lab that are
deployed without learning if they involve a human it's possible to do slam
localization by having really good sensors and doing localization using
those sensors without much learning it's not possible to design systems that deal with lighting variability and the full
variability of human behavior without being able to learn so gaze estimation
the geometric approach of finding the landmarks in the face and from those landmarks determining the the Jeremie
the orientation of the head and the orientation of the eyes there's no learning there outside of actually
training the systems to detect the different landmarks if we convert this
into a gaze classification problem shown here glass classification is when taking
the raw video stream determining in post so humans are annotating this video is
the driver which region the driver is looking at that's we're able to do by
converting the problem into a simple variant of classification on-road off-road left-right the same can be done
for pedestrians left forward right it can annotate regions of where they are
looking and using that kind of classification approach determine are
they looking at the cars or not are they looking away are they looking at their smartphone without doing the 3d gaze
estimation again it's a subtle point but think about it if you wanted to estimate exactly where they're looking
you need that ground truth you don't have that ground truth unless you there
there's no in the real world data there's no way to get the information about where exactly people were looking
you're only inferring so you have to convert it into a region based classification problem in order to be
able to train your networks on this and the pipeline is the same the source
video here the face the the 30 frames a second video coming in of the drivers
face of the human face there is some degree of calibration that's required you have to determine approximately
where the sensor is that's taking in the image especially for the glance classification task because its region
based needs to be able to estimate where the forward roadway is where the the camera
frame is relative the world frame the video stabilization and the face front
elevation all the basic processing they've removed the vibration of the noise that remove the physical movement
of the head that removed the shaking of the car in order to be able to determine
stuff about eye movement and blink dynamics and finally with the neural networks there is nothing left except
taking in the raw video of the face for the glass classification tasks and the
eye for the cognitive load tasks raw pixels that's the input to these networks and the output is whatever the
training data is and we'll mention each one so whether that's cognitive load
glance emotion drowsiness the input is the raw pixels and the output is
whatever you have data for data is everything here the face an alignment
problem which is a traditional geometric approach to this problem is designing
algorithms that are able to detect accurately the individual landmarks in the face and from that estimate the
geometry of the head pose for the class
of in version we perform the same kind of alignment or with the same kind of face
detection in alignment to determine where the head is but once we have that we pass in just the raw pixels and
perform the classification on that as opposed to doing the estimation its
classification allowing you to perform what's shown there on the bottom is the
real-time classification of where the driver is looking Road left right center
stack instrument cluster and rearview mirror and as I mentioned annotation
tooling is key so we have a total 5 billion video frames one and a half
billion of the face that would take tens
of millions of dollars to annotate just for the glass classification fully so we
have to figure out what to annotate in order to trade and you'll networks to perform this task and what we annotate
is the things that the network is not confident about the moments of highlighting variation the partial
occlusions from the light or self occlusion and the moving out of frame the outer frame occlusions all the
difficult cases going from frame to frame to frame here and the different pipeline starting at the table going at
the bottom whenever the classification has a low confidence we pass it to the
human it's simple we rely on the human only when the classifier is not confident and the fundamental trade-off
in all of these systems is what is the accuracy we're willing to put up with
here in red and blue and red is human choice decision and blue as a machine
tasks in red we select the video we want to classify in blue the the the neural
network performs the face detection task localizing the camera choosing what is the angle of the camera
and provides a trade opportunity and percent frames it can annotate so
certainly and you'll networking at a glance for the entire data set they would achieve accuracy in the case of
glass classification of nine low 90% classification on the sixth glass task
now if you want a higher accuracy that it will only be able to achieve that for us for a smaller fraction of frames
that's the choice and then a human has to go in and
perform the annotation of the frames that the algorithm was not confident
about and it repeats over and over the algorithm is then trained on the frames
that were annotated by the human and repeats this process over and over on the frames until everything is annotated
yes yes absolutely
the question was do you ever observe that the classifier is highly confident about the incorrect class yep right
question was hot well then how do you how do you deal with that how do you account for that how do you account for
the fact that highly confident predictions can be highly wrong yeah
false positives false positives that you're really confident in there there's
no at least in our experience there's no good answer for that except more more and more training data on the things
you're not confident about that usually seems to deal generalize over cases we
don't encounter obvious large categories of data where you're really confident
about the wrong thing usually some degree of human annotation fixes most
problems annotating the low the low confidence
part of the data solves all incorrect issues but of
course that's not always true in the general case that you can imagine a lot of scenarios whether that's not true for
example one one one thing they always perform is for each individual person we
usually entertain a large amount of the data manually no matter what so we have to make sure that the neural network has
seen that person in the various and the various ways their face looks like with
glasses with different hair with different a lighting variation so we
want to manually annotate that it's overtime we're allowing the machine to do more and more of the work so what's resulting in this in the
glance classification cases you can do real-time classification you can give the car information about whether the
driver is looking on road or off road this is critical information for the car to understand and you want to pause for
a second to realize that when you're driving a car for those our driver for those that driven any kind of car with
any kind of automation it has no idea about what you're up to at all there's
no it doesn't have any information about the driver except if they're touching the steering wheel or not more and more
now with the GM supercruise vehicle and Tesla now has added a dryer facing camera that slowly started to think
about moving towards perceiving the driver but most vehicles on the road
today have no knowledge of the driver this knowledge is almost common sense and trivial for the car to have the it's
common sense how important this information is where the driver is looking that's the glance classification
problem and again emphasizing that we've converted it's been three decades of
work on gaze estimation yet gaze estimation is doing head pose estimation so the geometric orientation of the head
combining the orientation of the eyes and using that combined information to determine where the person is looking
will convert that into a classification problem so the standard gaze estimation definition is not a machine learning
problem classification is a machine learning problem this transformation is key
Emotion Recognition
emotion human emotion is a fascinating thing so the same kind of pipeline
stabilization cleaning of the data raw pixels in and then the classification is
emotion the problem with emotion if I may speak as an expert human not am NOT
an expert in emotion is just an expert of being human is that there is a lot of ways that's a sodomize emotion to
categorize emotion to define emotion whether that's for the the primary
emotion of the para scale would love joy surprise anger sadness fear there's a lot of ways to mix those together to
break those apart into hierarchical taxonomies and the way we think about it
in the driving context at least there is a general emotion recognition task sort
of I mentioned I'll mention it but it's kind of how we think about primary
emotions is detecting the the broad categories of emotion of joy and anger
of disgust and surprise and then there is application specific emotion
recognition where you're using the facial expressions that all the various ways that we can deform our face to
communicate information to determine the
specific question about the interaction of the driver so I'll first for the
general case these are the building blocks I mean there's there's countless ways of deforming the face that we use
to communicate with each other there's 42 individual facial muscles that can be
used to form those expressions one of
our favorite work with is the effective SDK this is their their their task with the general
emotion recognition task is taking in raw pixels and determining categories of
emotion very subtleties of that emotion in the general case producing a classification of anger disgust fear
surprise so on and then mapping I mean essentially what these algorithms are
doing whether whether they using deep neural networks or not whether using face alignment to do the landmark
detection and then tracking those landmarks over time to do the facial actions they're determined they're
mapping the expressions the component their various expressions who can make with their eyebrows or their nose and
mouth and eyes to map them to the emotion so I'd like to highlight one
because I think it's an illustrative one for joy an expression of joy is smiling
so there's an increased likelihood that you observe a smiling expression on the
face when joy is experienced or vice versa if there's an increased probability of a smile there's an
increased probability of emotion of joy being experienced and then joy an
experience has a decreased probability likelihood of brow raising and brow following so if you see a smile that's a
that's a plus for joy if you see brow raised bright for Oh brow furrow is a minus for joy that's
for the general emotional recognition task that's been well studied that's sort of the core of affective computing movement from from the visual
perspective again from the computer vision perspective from the application of specific perspective which were
really focused on again data is everything what what are you annotating we can take here we have a large-scale
data set of drivers interacting with a voice based navigation system so they're
tasked with in various vehicles to enter a navigation so with they're talking to
their GPS using their voice this is for depending on the vehicle depending on the system in most cases an incredibly
frustrating experience so we have them perform this task and then the annotation is self-report after the
task they say on a scale of 1 to 10 how frustrating was this experience and when
you see on top is is the expressions detected and associated with a satisfied
a person who said a a 10 on the satisfaction so a 1 in the frustration
scale was perfectly satisfied with a voice based interaction on the bottom is
frustrated as a believin 9 on the frustration scale so the feature the
strongest there the expression remember joy smile was the strongest indicator of
frustration for all our subjects that was the strongest expression smile was the thing that was always there for
frustration there's other various frowning that followed and shaking the
head and so on but smiles were there so that shows you the kind of clean difference between general emotion
recognition tasks and the application-specific here perhaps they enjoyed an absurd
moment of joy at the frustration that were experiencing you can sort of get philosophical about it but the practical
nature is they were frustrated with the experience and we're using the 42 most of the face to make expressions to do
classification of frustrated or not and their data does the work not the
algorithms it's the annotation a quick mention for the AGI class next week for
the artificial general intelligence class one of the competition's we're doing is we have a JavaScript face
that's trained with a neural network to form various expressions to communicate
with the observer so we're interested in creating emotion which is a nice mirror
coupling of the emotional recognition problem it's gonna be super cool
cognitive load we're starting to get to the eyes
Cognitive Load Estimation
cognitive load is the degree to which a human being is accessing their memory or
as Lawson thought how hard they're working in their mind to recollect
something to think about something as cognitive load and to do a quick pause
of eyes as the window to cognitive load eyes the window to the mind there's a
different ways the eyes move so there's pupils the black part of the eye they can expand and and contract based on
various factors including the lighting variations in the scene but they also expand and contract based on cognitive
load that's a that's a strong signal they can also move around there's ballistic movement saccades when
we look around eyes jump around the scene they can also do something called smooth pursuit when you and connecting
to our animal past you can see a delicious meal flying by or running by that your eyes
can follow it perfectly they're not jumping around so when we read a book our eyes are using saccadic movements
where they jump around and when the purse muth pursuit the eye is moving perfectly smoothly those are the kinds
of movements who have to work with and cognitive load can be detected by
looking at various factors of the eye the blink dynamics the eye movement and
the eye the pupil diameter the problem is in the real world and real world data
with lighting variations everything goes out the window in terms of using pupil diameter which is the standard way to
measure non-contact way to measure cognitive load in the lab when you can control lighting conditions and use
infrared cameras when you can't all that goes out the window and all you have is the blink dynamics and the eye movement
so neural networks to the rescue 3d convolutional neural networks in this case we take a sequences of images that
I through time and use 3d convolutions as opposed to 2d convolutions on the
left is everything we've talked about previous to this as 2d convolutions when
the convolution filter is operating on the XY 2d image every channel is operated on
by the filter individual separately 3d convolutions combine those convolve
across the across multiple images across multiple channels therefore being able
to learn the dynamics of the scene through time as well not just spatially
temporal and data data is everything for
a cognitive load we have in this case 92 drivers so how do we sort of perform the
cognitive load classification task we have these drivers driving on the highway and performing the what's called
the n-back task zero back one back to back and that task involves hearing
numbers being read to you and then recalling those numbers one at a time so
one zero back the system gives you a number seven and then you have to just say that number back seven and it keeps
repeating that's easy it's supposed to be the easy task one back is when you hear number you have to remember it and
then that for the next number you have to say the number previous to that so
you kind of have to keep one number in your memory always and not get distracted by the new information coming
up but to back you have to do that two numbers back so you have to use memory more and more went to back so cognitive
load is higher and higher okay so what do we do we use face alignment face
front elevation and detecting the eye closest to the camera and extract the eye region and now we have this nice raw
pixels of the eye region across six seconds of video and we take that and
put that in as a 3d convolutional neural network and classify simply one of three
classes zero back one back and two back so we have a ton of data of people on the highway performing these tasks and
back tasks and that forms the classification supervised learning training data that's it the input is 90
images it's at 15 frames a second and the output is one of three classes
face fronto ization i should mention is the technique developed under for face recognition because most face
recognition tasks require frontal face orientation is also what we use here to normalize everything that we can focus
in on the exact blink it's taking the it's taking whatever the orientation of
the face and projecting into the frontal position taking the raw pixels of the
face is detecting the eye region zooming in and grabbing the eye where you find
and this is where the intuition builds it it's a fascinating one what's being
plotted here is the relative movement of the pupil the relative movement of the eye based on a different cognitive loads
for cognitive load on the left of zero so when your mind is not that lost in thought and cognitive load of two on the
right when it is lost in thought the eye moves a lot less eye is more focused on
the forward roadway that's an interesting finding but it's only in aggregate and that's what the neural
neural network is task would do it with extracting an a frame-by-frame basis
this is a standard 3d convolutional architecture again taking in the image
sequence is the input cognitive load classification is the output and classifying on the right is the accuracy
that's able to achieve of 86% that's pretty cool from real-world data the
idea is that you can just plop in a webcam get the video going in going into
the neural network and this predicting it continued
a stream from zero to two of cognitive load because every single zero want back
one back to back classes are have a confidence that's associated with them so you can turn that into a real value
between zero and two and when you see here's a plot of three of the people on
the team here driving a car performing a task of conversation and in white
showing the cognitive load frame by frame a thirty frames a second estimating the cognitive load of each of
the drivers on from zero to two on the y-axis so these are high cognitive load
and showing in on the bottom red and yellow of high medium cognitive load and
when everybody's silent the cognitive load goes down so we can perform now with this simple neural network with the
training data that we formed we can extend that to any arbitrary new data set and generalize okay those are some
Human-Centered Vision for Autonomous Vehicles
examples of Chania neural networks can be applied and why is this important again is while we focus on the sort of
the perception tasks of using neural networks of using sensors and signal
processing to determine where we are in the world where the different obstacles are informed trajectories around those
obstacles we are still far away from completely solving that problem I would
argue 20 plus years away the human will have to be involved and so when it's the
system is not able to control when the system is not able to perceive when there's some flawed aspect about the
perception or the driving policy the human has to be involved and that's where we have to know let the car know
what the human is doing that's the essential element of human robot interaction the most popular car in the
United States today is the Ford f-150 no automation the thing that sort of
inspires us and makes us think that transportation can be fundamentally
transformed is the Google self-driving mo our and although our guest speakers and
all the folks work in the autonomous vehicles but if you look at it the only
people who are at a mass scale or beginning to are actually injecting automation into our daily lives is the
ones in between it's the Tesla's the l2 systems it's the tesla system the supercruise the audio
as 90s the the vehicles that are slowly adding to some degree of automation and
teaching human beings how to interact with that automation and here's again
the the the path towards mass scale
automation we're steering wheels removed the consideration that humans removed I
believe is more than two decades away on the path to that we have to understand
and create successful human robot interaction approach autonomous vehicles
autonomous systems in a human centered way the mass scale integration of these
systems of the human center systems like to test the vehicles a Tesla is just a small company right now the the kind of
l2 technologies have not truly penetrated the the market have not penetrated that our vehicles even the
Brittain the new vehicles being released today I believe that happens in the early 2020s and that's going to form the
core of our algorithms that will eventually lead to the full autonomy all
of that data what I mentioned with Tesla with a 32% miles being driven all of
that is training data for the algorithms the edge cases arise there that's where we get all this data in our data set at
MIT is 400,000 miles Tesla has a billion miles so that that's all training data
on the way on the stairway to mass scale automation why is this
important beautiful and fundamental to the role of AI in society I believe that
self-driving cars when they're in this way are focused on a human robot interaction our personal robots they're
not perception control systems tools like a Roomba performing a particular
task when human life is a steak when there's a fundamental transfer between
of life of a human being giving their life over to an AI system directly one
on one is a transfer that is kind of a relationship that is one indicative of a
personal robot this is it requires all the things of understanding
communication of trust these are fascinating to understand how a human
and robot can form trust enough to create a really an almost
one-to-one understanding of each other's mental state learn from each other oh
boy so one of my favorite movies Good Will
Hunting we're in Boston Cambridge have two have two gonna regret this one this
is Robin Williams speaking about human imperfections so I'd like you to take
this quote and replace every time you mentioned girl with car people call
those things imperfections Robin Williams is talking about his wife who passed away in the movie talking about
her imperfections they call these things imperfections but they're not that's the good stuff and then we'll get to choose
who we let into our weird little worlds you're not perfect sport and let me save
you the suspense this girl you met she isn't perfect to you there you know what let me just
the video sequences that only I know about that's what made her my wife when she
had a puts on me - she all my pet dogs people call these things into fashions
suffice no need to choose we learn to obviate the words in my breath explore
things in suspense he has an air attack but the question is
what am i perfect for each other [Music]
[Music]
so the approach we're taking in building
the autonomous vehicle we are here at MIT in our group it's the human centered approach the autonomous vehicles they
were going to release in March of 2018 in the streets of Boston those who would
to help please do I will talk run a
course on deep learning for understanding the humans of Chi 2018 will be going through tutorials that go
far beyond the visual the convolutional neural network based detection of
various aspects of the face and body would look at natural language
processing voice recognition and Gans if you're going to Chi please join next
week we have an incredible course that's aims to understand to begin to explore
the nature of intelligence natural and artificial we have Josh Tenenbaum Ray
Kurzweil Lisa Barret Nate Dubinsky
looking at cognitive modeling architectures Andre karpati Stephen Wolfram Richard Moyes talking about
autonomous weapon systems and AI safety mark Robert from Boston Dynamics and the
amazing incredible robots I have and Ilya sutskever from open AI and myself
so what next for folks register for this course you have to submit by tonight a
deep traffic entry that achieves a speed of 65 miles an hour and I hope you
continue to submit more that win the competition the high performer award
will be given to folks the very few folks who achieved 70 miles an hour
faster we will continue rolling out seg fuse having hit a few snags and invested
a few thousands of dollars in the sanitation process of annotating a
large-scale data set for you guys we'll continue this competition that will take
us into into a submission to his nips where we'd hope to submit the results for this
competition and deep crash the deeper enforcement learning these competitions will continue through May 2018 I hope
you stay tuned and participate there's upcoming classes the a GI class
I encourage you to come to is going to be fascinating and there's so many cool
interesting ideas that we're going to explore it's gonna be awesome there's an introduction to deep learning
course that I'm also part of will get a little bit more applied and get folks
who are interested in the the very basic algorithms of deep learning how to get
started with those hands-on and there's an awesome class that ran last year for
those who took this class last year we also talked about it on the the global
business of AI and robotics the slides are online I encourage you to click a link on there and register it's in the
spring it's once a week and it's truly brings together a lot of cross-disciplinary folks to talk about
ideas of artificial intelligence and the role of AI and robotics and society it's an awesome class and if you're
interested in applying deep learning methods in the automotive space come work with us we have a lot of
fascinating problems to to solve or collaborate so with that I'd like to
thank everybody here everybody across the community that's been contributing
we have thousands of submissions coming in for deep traffic and I'm just truly humbled by the support we've been
getting and the team behind this class is incredible thank you to Nvidia Google Amazon Alexa auto live in Toyota and
today we have shirts extra large extra
extra large medium over there small and large over there the big and small
people over here and then the medium-sized people over here so just grab it grab one and enjoy thank you
very much [Applause]

----------

-----
--26--

-----
Date: 2018.01.27
Link: [# MIT 6.S094: Computer Vision](https://www.youtube.com/watch?v=CLOAswsxudo)
Transcription:


Computer Vision and Convolutional Neural Networks
today we'll talk about how to make machines see computer vision and we'll
present Thank You Claire said yes and today we will present a competition that
unlike deep traffic which is designed to explore ideas teach you about concepts
of deep reinforcement learning seg fuse the deep dynamic driving scene
segmentation competition that I'll present today is at the very cutting edge whoever does well in this
competition is likely to produce a publication or ideas that would lead the
world in the area of perception perhaps together with the people running this
class perhaps in your own and I encourage you to do so even more cats
today computer vision today as it stands is deep learning majority of the
successes in how we interpret form representations understand images and
videos utilize to a significant degree neural networks the very ideas we've
been talking about that applies for supervised unsupervised and reinforcement learning and for the
supervised case is just the focus of today the process is the same the data
is essential there's annotated data where the human provides the labels that serves as the ground truth in the
training process then the neural network ghost's through that data learning to
map from the raw sensory input to the ground truth labels and then generalize
or the testing data set and the kind of raw sensors were dealing with their
numbers I'll say this again and again that for human vision for us here would
take for granted this particular aspect of our ability is to take in raw sensory information through our eyes and
interpret but it's just numbers that's something whether you're an expert computer vision
person or new to the field you have to always go back to meditate on is what
kind of things the Machine is given what what what is the data that is tasked to
work with in order to perform the tasks you're asking it to do perhaps the data is given is highly
insufficient to do what you want it to do that's the question I'll come up again and again our images enough to
understand the world around you and given these numbers the set of numbers
sometimes with one channel sometimes with three RGB where every single pixel have three different colors the task is
to classify or regress produce a
continuous variable or one of a set of class labels as before we must be
careful about our intuition of what is hard and what is easy in computer vision
let's take a step back to the inspiration for neural networks our own
biological neural networks because the human vision system and the computer
vision system is a little bit more similar in these regards this
and visual cortex is in layers and as information passes from the eyes to the
to the parts of the brain that makes sense of the raw sensor information higher and higher order representations
have formed this is the inspiration the idea behind using deep neural networks
for images higher and higher order representations of form through the layers there early layers taking in the
very raw and sensory information then extracting edges connecting those edges
forming those edges to form more complex features and finally into the higher-order semantic meaning that we
hope to get from these images in computer vision deep learning is hard
I'll say this again the illumination variability is the biggest challenge or at least one of the
one of the biggest challenges in driving for visible light cameras pose
variability the objects as I'll also discuss about some of the advances geoff
hinton and the capsule networks the idea with the neural networks as they're
currently useful computer vision are not good with representing variable pose
these objects in images and this 2d plane of color and texture look very
different numerically when the object is rotated and the object is mangled and
shaped in different ways the deformable will truncated cat intraclass variability the for the classification
task which would be an example today throughout to introduce some of the networks over the past decade that have
received success in some of the intuition and insight that made those networks work classification there is a
lot of variability inside the classes and very little variability between the classes all of these are cats on top all
of those are dogs are bottom they look very different and the other I would say
the second biggest problem in driving perception visible light camera perceptions occlusion when part of the object is
occluded due to the three-dimensional nature of our world some objects in
front of others and they occlude the background object and yet we're still
tasked with identifying the object when only part of it is visible and sometimes that part told you there's cats is very
hardly visible here we're tasked with classifying a cat with just an ears visible just the leg and in
the philosophical level as we'll talk about the motivation for our competition here here's a cat dressed as a monkey
eating a banana on a philosophical level most of us understand what's going on in
the scene in fact a neural network it's to today successfully classify this
image this video as a cat but the
context the humour of the situation and in fact you could argue it's a monkey is
missing and what else is missing is the dynamic information the temporal
dynamics of the scene that's what's missing in a lot of the perception work
that has been done to date in the autonomous vehicle space in terms of
visible light cameras and we're looking to expand on that that's what psyche fuse is all about
image classification pipeline there's a bin with different categories inside
each class cat dog mug hat those bins there's a lot of examples of each and
your task with when a new example comes along you never seen before to put that image in a bin it's the same as the
machine learning tasks before and everything relies on the data that's
been ground truth that been labeled by human beings amnesty is a toy data set of handwritten
digits often used as examples and Koko safar imagenet places and a lot of other
incredible datasets rich data sets of a hundred thousands millions of images out
there represent scenes people's faces and different objects those are all
ground truth data for testing algorithms and for competing architectures to be
evaluated against each other see far ten one of the simplest almost toy datasets
of tiny icons with ten categories of airplane automobile bird cat deer dog
for our course ship and truck is commonly used to explore some of the basic convolution neural networks we'll
discuss so let's come up with a very trivial classifier to explain the concept of how we could go about it in
fact this is maybe if you start to think about how to classify an image if you don't know any of these techniques this
is perhaps the approach you would take is you would subtract images so in order to know that an image of a cat is
different than image of a dog if to compare them when given those two images what what's the what's the way you
compare them one way you could do it is you just subtract it and then sum all
the pixel wise differences in the image just subtract the intensity of the image pixel by pixel sum it up if that intent
if that difference is really high that means the images are very different using that metric we can look at C for
10 and use it as a classifier saying based on this difference function I'm
going to find one of the 10 bins for a new image that that is that has the
lowest difference find an image in this data set that is most like the image I
have and put it in the same bin as that images in so there's 10 classes if we
just flip a coin the accuracy of our classifier will be 10% using our image
difference classifier we can actually do pretty good much better than random much better than 10%
we can do 35 38 percent accuracy that's a classifier we have our first
classifier K nearest neighbors let's
take our classifier to a whole new level instead of comparing it to just fight
trying to find one image that's the closest in our data set we tried to find K closest and say what is what class do
the majority of them belong to and we take that k and increase it for 1 to 2 to 3 to 4 to 5 and see how that changes
the problem with seven years neighbors which is the optimal under this approach
for CFR 10 we achieve 30% accuracy
human level is 95% accuracy and with
convolutional neural networks will get very close to 100% that's where you'll
networks shine this very task of bending images it all starts at this basic
computational unit signal in each of the signals are weighed summed bias added
and put an input into a nonlinear activation function that produces an
output the nonlinear activation function is key all of these put together and
more and more hidden layers form a deep neural network and that deep neural
network is trained as we've discussed by taking a forward pass and examples have
garage with labels seeing how close those labels are to the real ground truth and then punishing the weights
that resulted in the incorrect decisions and rewarding the weights that resulted
in correct decisions for the case of 10 examples the output of the network is
different values the input being handwritten digits from 0 to 9 for 10 of
those and we wanted our network to classify what is in this image of a
handwritten digit is it 1 is 0 1 2 3 through 9 the way it's often done is
there's ten outputs of the network and each of the neurons on the output is
responsible for getting really excited when it's number is called and everybody
else is supposed to be not excited therefore the number of classes is the
number of outputs that's how it's commonly done and you assign a class to
the input image based on the highest the neuron which produces the highest output
but that's for a fully connected network that we've discussed on Monday there is
in deep learning a lot of tricks that make things work that make training much
more efficient on large class problems where there's a lot of classes on large
data sets when the representation that the neural network is tasked with learning is extremely complex and that's
where convolutional neural neural networks step in the trick they use a spatial invariance they use the idea
that a cat in the top left corner of an image is the same as a cat in the bottom
right corner of an image so we can learn the same features across the image
that's where the convolution operation steps in instead of the fully connected
networks here there's a third dimension of depth so the blocks in this neural
network as input take 3d volumes and as output produced 3d volumes
a slice of the image a window and slide it across applying the same exact
weights and we'll go through an example the same exact weights as in the fully connected network on the edges that are
used to map the input to the output here are used to map this slice of an image
this window of an image to the output and you can make several many of such
convolutional filters many layers many different options of what kind of
features you look for in an image what kind of window you slide across in order to extract all kinds of things all
kinds of edges all kind of higher-order patterns in the images the very
important thing is the parameters on each of these filters the subset of the image these windows are shared if the
feature that defines a cat is useful in the top left corner it's useful in the top right corner it's useful in every
aspect of the image this is the trick that makes convolutional neural networks save a lot of a lot of parameters reduce
parameter significantly it's the reuse the spatial sharing of features across
the space of the image the depth of
these 3d volumes is the number of filters the stride is the skip of the
filter the step size how many pixels you skip when you apply the filter to the
input and the padding is
they're padding the zero padding on the outside of the input to a convolutional
layer let's go through an example so on
the left here and the slides are now available online you can follow them along and I'll step through this example
on the left here is a input volume of three channels the left column is the
input the three block the three squares there are the three channels and there's
numbers inside those channels and then
we have a filter in red two of them two
channels of filters with a bias and we those filters are three by three each
one of them is size three by three and what we do is we take those three by
three filters that are to be learned these are our variables our weights that
we have to learn and then we slide it across an image to produce the output on
the right the green so by applying the filters in the red there's two of them
and within each one there's one for every input channel we go from the left
to the right from the input volume on the left to the output volume green on
the right and you can look it you can
pull up the slides yourself now if you can't see the numbers on the screen but the the operations are performed on the
input to produce the single value that's highlighted there in the green and the output and we slide this convolution no
filter along the image with a stride in this case of to skipping skipping along
they sum to the to the right the two channel output in green that's it
the convolutional operation that's what's called the convolutional layer neural networks and the parameters here
besides the bias are the read values in the middle that's what we're trying to
learn and there's a lot of interesting tricks we'll discuss today on top of
those but this is at the core this is the spatially invariant sharing of
parameters that make convolutional neural networks able to efficiently
learn and find patterns and images to build your intuition a little bit more
about convolution here's an input image on the left and on the right the
identity filter produces the output you see on the right and then there's different ways you can different kinds
of edges you can extract with the activate or the resulting activation map
seen on the right so when applying the filters with those edge detection
filters to the image on the left you produce in white are the parts that
activate the convolution the results of these filters and so you can do any kind
of filter that's what we're trying to learn any kind of edge any kind of any
kind of pattern you can move along in this window and this way that's shown here you slide along the image and you
produce the output you see on the right and depending on how many filters you have in every level you have many of
such slices VC on the right the input on the left the output on the right if you
have dozens of filters you have dozens of images on the right each with
different results that show where each of the individual filter patterns were
found and we learned what patterns are useful to look for in order to perform
the classification task that's the task for the neural network to learn these
filters and the filters have higher and higher order of representation going from the
very basic edges to the high semantics meaning that spans entire images and the
ability to spend images can be done in several ways but traditionally has been successfully done through max pooling
through pooling of taking the output of
convolutional operation and reducing the resolution of that byte by condensing
that information by for example taking the maximum values the maximum activations therefore reducing the
spatial resolution which has detrimental effects as we'll talk about in the scene segmentation but it's beneficial for
finding higher order representations and the images that bring images together that bring features together to form an
entity that we're trying to identify and classify okay so that forms a
convolution Yool network such convolutional layers stacked on top of each other is the only addition to a
neural network that makes for a convolutional neural network and then at the end the fully connected layers or
any kind of other architectures allow us to apply particular domains
Network Architectures for Image Classification
let's take image net as a case study an
image net the data set an image net the
challenge the task is classification as I mentioned the first lecture image net is
a data set one of the largest in the world of images with 14 million images
21,000 categories and a lot of depth to
many of the categories as I mentioned 1200 granny smith apples
these allow - these allow the newer networks to learn the rich
representations in both pose lighting variability and intraclass class variation for the particular things
particular classes like granny smith apples so let's look through the various
networks let's discuss them let's see the insights it started with Alex net the first
really big successful GPU trained neural network on image net that's achieved a
significant boost over the previous year and moved on to vgg net Google net ague
Lynnette ResNet see you image and as Annette in 2017 again the numbers will
show for the accuracy are based on the top five error rate we get five guesses
and it's a one or zero if you get guess if one of the five is correct you get a one for that particular guess otherwise
it's a zero and human error is five
point one when a human tries to achieve the same tries to perform the same task
as the machinist task of doing the air is five point one the human annotation is performed on the images based on
binary classification Granny Smith apple or not cat or not the actual tasks that
the machine has to perform and that the human competing has to perform is given an image is provide one of the many
classes under that human errors 5.1% which was surpassed in 2015 by ResNet to
achieve four percent error so let's
with Alex net I'll zoom in on the later networks they have some interesting insights but Alex net and vgg net both
fall at a very similar architecture very uniform throughout its depth vgg net in
2014 is convolution convolution pooling
convolution pooling convolution pooling and fully connected layers at the end
there's a certain kind of beautiful simplicity uniformity to these architectures because you can just make
it deeper and deeper and makes it very amenable to implementation in a layer
stack kind of way and in any of the deep learning frameworks it's clean and
beautiful to understand in the case of eg gina was 16 or 19 layers with 138
million parameters not many optimizations and these parameters therefore the number of parameters is
much higher than the networks that followed it despite the layers not being that large Google Net introduced the
inception module starting to do some interesting things with the small
modules within these networks which allow for the training to be more efficient and effective the idea behind
the inception module shown here with the previous layer on bottom and the
convolutional layer here with the inception module on top produced on top
is it used the idea that different size
convolutions provide different value for the network smaller convolutions are
able to capture or propagate forward features that are very local a high
resolution in in in texture larger convolutions are better able to
represent and capture and catch highly abstracted features higher-order
features so the idea behind the inception module is to say well as
opposed to choosing and high in a high pair tuning process or architecture design
process choosing which convolution size we want to go with why not do all of
them together while several together in the case of the Google net model there's
the one by one three by three and five by five convolutions with the old trusty
friend of max pooling still left in there as well which has lost favor more
and more over time for the image classification task and the results is there's fewer parameters are required if
you pick the placing of these inception modules correctly the number of
parameters required to achieve a higher performance is much lower res net one of
the most popular still to date
architectures that we'll discuss in scene segmentation as well came up and
use the idea of a residual block the initial inspiring observation which
doesn't necessarily hold true as it turns out but that network depth
increases representation power so these residual blocks allow you to have much
deeper networks and I'll explain why in a second here but the thought was they
work so well because the network's so much deeper the key thing that makes these blocks so effective is the same
idea that's that reminiscent of recurrent neural networks that I hope
would get a chance to talk about the training of them is much easier they
take a simple block repeated over and over and they pass the input along
without transformation along with the ability to transform it to learn to
learn the filters learn the weights so you're allowed to you're allow every
layer to not only take on the processing of previous layers but to take in the
wrong transform data and learn something new the ability to learn something new
allows you to have much deeper networks and the simplicity of this block allows
for more effective training the state of
the art in 2017 the winner is squeezed and excitation networks that unlike the
previous year will see you image which simply took ensemble methods and combined a lot of successful approaches
to take a marginal improvement se net got a significant improvement at least
in percentages I think there's a 25% reduction in error from 4 percent to 3
percent something like that by using a very simple idea that I think is
important to mention a simple insight it added a parameter to each channel and
the convolutional layer in the convolutional block so the network can
now adjust the weighting on each channel based for for each feature map based on
the content based on the input to the network this is kind of a take away to think about about any of the networks
who talk about any of the architectures is a lot of times your recurrent neural
networks and convolutional neural networks have tricks that significantly
reduce the number of parameters the bulk the sort of low-hanging fruit they use
spatial invariants a temporal invariants to reduce the number of parameters to represent the input data but they also
leave certain things not parameterize they don't allow the network to learn it allow in this case the network to learn
the weighting on each of the individual channels so each of the individual filters is something that you learn as
along with the filters takes it makes a huge boost the cool thing about this is it's
applicable to any architecture this kind of block that's kind of what the the squeeze and excitation block is
applicable to any architecture and because obviously it it just simply
permit Rises the ability to choose which filter you go with based on the content it's a subtle but crucial thing I think
it's pretty cool and for future research it inspires to think about what else can
be parameterize in your own networks what else can be controlled as part of the learning process including hiring
higher-order hyper parameters which which aspects of the training and the
architecture of the network can be part of the learning this is what this network inspires another network has
been in development since the 90s ideas with geoff hinton but really received
has been published on received significant attention 2017 that i won't go into detail here we are going to
release an online-only video about capsule networks it's a
little bit too technical but they inspire a very important point that we
should always think about with deep learning whenever it's successful is to think about what as I mentioned with the
cat eating a banana on a philosophical and the mathematical level you have to
consider what assumptions these networks make and what through those assumptions
they throw away so neural networks due to the spatial with convolutional neural networks due to their spatial invariants
throw away information about the relationship between the the hierarchies
between the simple and the complex objects so the face on the left and the face on the right looks the same to
accomplish a neural network the presence of eyes and nose and mouth is the
central aspect of what makes classification tasks work for
convolution Network where it will fire and say this is definitely a face but
the spatial relationship is lost is ignored which means there's a lot of
implications to this but for things like pose variation that information is lost
we're throwing away that away completely and hoping that the pooling operation
that's performing these networks is able to sort of mesh everything together to
come up with the features that are firing of the different parts of the face that then come up with the total
classification that it's a face without representing really the relationship between these features at the low level
and and the high level at the low level of the hierarchy at the simple and the complex level this is a super exciting
field now that's hopefully will spark developments of how we design your own networks that are able to learn this the
rotational the orientation invariance as well ok so as I mentioned you take these
Fully Convolutional Neural Networks
combos in your networks chop off the final layer in order to apply to a
particular domain and that is what we'll do with fully convolutional neural networks the ones that we task to
segment the image at a pixel level as a
reminder these networks through the convolutional process are really
producing a heat map different parts of the network are getting excited based on
the different aspects of the image and so it can be used to do the localization of detecting not just classifying the
image but localizing the object and they could do so at a pixel level so the
convolutional layers are doing the encoding process they're taking the rich
raw sensory information in the image and encoding them into an interpretable set
of features representation that can then be used for classification but we can
also then use it kotor up sample that information and produce a map like this fully
convolutional neural network segmentation semantic scene segmentation image segmentation the goal is to as
opposed to classify the entire image you classify every single pixel its pixel level segmentation you color every
single pixel with what that pixel what object that pixel belongs to in this 2d
space of the image the 2d projection the in the image of a 3-dimensional world so
the thing is there's been a lot of advancement in the last three years but
it's still an incredibly difficult problem if you if you think if you think about the amount of data that's used for
training and the task of pixel level of megapixels here of millions of pixels
that are tasked with having a scientist single label it's an extremely difficult problem why is this interesting
important problem to try to solve as opposed to bounding boxes around cats well it's whenever precise boundaries of
objects are important certainly medical applications when looking at imaging and detecting in particular for example
detecting tumors in the in in medical
imaging of different different organs and in driving in robotics when objects
are involved it's a done scene of all those vehicles pedestrians cyclists we need to be able to not just have a loose
estimate of where objects are we need to be able to have the exact boundaries and then potentially through data fusion
fusing sensors together fusing this rich textural information about pedestrians cyclists and vehicles
to lidar data that's providing us the three-dimensional map of the world or have both the semantic meaning of the
different objects and their exact three-dimensional location
a lot of this work successfully a lot of the work in the semantic segmentation
started with fully convolutional networks for semantic segmentation paper FCN that's where the name of FCN came
from in november 2014 now go through a few papers here to give you some intuition where the field is
gone and how that takes us to seg fuse the segmentation competition so FCM
repurposed the image net pre-trained nets the nets that were trained to classify what's in an image the entire
image and chopped off the fully connected layers and then added decoder
parts that that up sample there the image to produce a heat map here shown
with a tabby cat a heat map of where the cat is in the image it's a much slower
much coarser resolution than the input image 1/8 at best
skip connections to improve coarseness of up sampling there's a few tricks if
you do the most naive approach the up sampling is going to be extremely coarse because that's the whole point of the
neural network the encoding part is you throw away all the useless data the
YouTube the most essential aspects that represent that image so you're throwing away a lot of information that's
necessary to then form a high resolution image so there's a few tricks where you
skip a few of the final pooling operations to go in similar way and this
is a residual block to go to go to the output produce higher and higher resolution heat map at the end segment
in 2015 applied this to the driving context and really taking it to kitty
data set and have have shown a lot of interesting results and really explored
the encoder decoder or formulation of the problem
really solidifying this the place of the encoder/decoder framework for the
segmentation task dilated convolution I'm taking you through a few components
which are critical here to the state of the art dilated convolutions so the
convolution operation as the pooling operation reduces resolution
significantly and dilated convolution has a certain kind of gritting as
visualized there that maintains the local high resolution textures while
still capturing the spatial window necessary
it's called dilated convolutional layer and that's in a 2015 paper proved to be
much better at up sampling a high resolution image deep lab with a be v1
v2 Navi 3 added conditional random fields which is the final piece of the
of the state-of-the-art puzzle here a lot of the successful networks today
that do segmentation not all do post
process using CRFs conditional random fields and what they do is they smooth
the segmentation the up sample segmentation that results from the FCN by looking at the underlying image
intensities so that's the key aspects of
the successful approaches today you have the encoder decoder framework of a fully accomplished in your network it replaces
the fully connected layers with the convolutional layers deconvolution layers and as the years progress from
2014 to today as usual than underlying
networks from alex net to vgg net and to now ResNet have been one of the big
reasons for the improvements of these to be able to perform the segmentation so naturally they mirrored the imagenet
challenge performance in adapting these networks so the state-of-the-art uses ResNet or similar networks conditional
random fields for smoothing based on the input image intensities and the dilated
convolution that maintains the computational cost but increases the
resolution of the up sampling throughout the intermediate feature Maps and that
takes us to the state of the art that we used to produce the images to produce
the images for the competition present that do you see for dance up sampling
convolution instead of bilinear up sampling you make the up sampling learn
about you learn the upscaling filters that's on the bottom that's really the
key part that made it work there should be a theme here sometimes the the
biggest addition they can be done this parameter izing one of the aspects of the network they've taken for granted
letting the network learn that aspect and the other I'm not sure how important
it is to the success but it's a it's a cool little addition is a hybrid dilated convolution as I showed that
visualization where the convolution is spread apart a little bit in the input
from the input to the output the steps of that dilated convolution filter when
they're changed it produces a smoother result because when it's kept the same
there certain input pixels get a lot more attention than others so losing
that favoritism is what's achieved by using a variable different dilation rate
those are the two tricks but really the biggest one is the parameterization of the upscaling filters okay so that's
what we're that's what we used to generate that data and that's what we provides you the code with if you're interested in competing in psyche views
Optical Flow
the other aspect here that everything we've talked about from the classification to the segmentation to
making sense of images is it there the information about time the temporal
dynamics of the scene is thrown away and for the driving context of the robotics
contest and what we'd like to do with psyche fuse for the segmentation dynamics scene segmentation context of
when you try to interpret what's going on in the scene over time and use that information time is essential thus the
movement of pixels is essential through time that that understanding how those
objects move in a 3d space through the 2d projection of an image it's
fascinating and us there's a lot of set of open problems there so flow is what's
very helpful to as a starting point to help us understand how these pixels move
flow optical flow dense optical flow is the computation that our best of a best
approximation of where each pixel in image one and moved in the in
temporarily following image after that there's two images in 30 frames a second
there's one image at time zero the other is 33.3 milliseconds later and the
idents optical flow is our best estimate of how each pixel in the input image moved to in the output image the optical
flow for every pixel produces a direction of where we think that pixel moved and the magnitude of how far moved
that allows us to take information that we detected about the first frame and
try to propagate it forward this is the competition it's to try to segment an
image and propagate that information forward for manual annotation of a
image so this kind of coloring book annotation where you color every single pixel in the state-of-the-art dataset
for driving cityscapes that it takes 1.5
ninth and 1.5 hours 90 minutes to do that coloring that's 90 minutes per
image that's extremely long time that's why there doesn't exist today dataset
and in this class we're going to create one of segmentation of these images
through time through video so long
videos where every single frame is fully segmented that's still an open problem
that we need to solve flows a piece of that and we also provide you the this
computer state-of-the-art flow using flow net 2.0 so flow net 1.0 in May 2015
used neural networks to learn the optical flow the dense optical flow and
it did so with two kinds of architectures flow net s flowing that simple and flow net core flow net see
the simple one is simply taking the two images so what's what's the task here
there's two images and you you want to produce from those two images they follow each other in time thirty-three
point three milliseconds apart and your task is the output to produce the dense
optical flow so for the simple architecture you just stack them together each are RGB so it produces a
six channel input to the network there's a lot of convolution and finally it's the the same kind of process as the
fully convolution your networks to produce the optical flow then there is flow net correlation architecture where
you perform some convolution separately before using a correlation layer to combine the feature Maps both
effective in different data sets and different applications so flow net 2.0
in December 2016 is one of the
state-of-the-art frameworks code bases that we used to generate the data all
show combines the flow net Assam flow net C and improves over the initial flow
net producing a smoother flow field preserves the fine motion detail along
the edges of the objects and it runs extremely efficiently depending on the
architecture there's a few variants either eight to a hundred forty frames a
second and the process there is essentially one that's common across
various applications deep learning is stacking these networks together the
very interesting aspect here that we're
still exploring and again applicable in all of deep learning in this case it
seemed that there was a strong effect in taking sparse small multiple data set
and doing the training the order of which those data sets were used for the training process mattered a lot that's
very interesting so using flow net 2.0 here's the data
SegFuse Dynamic Scene Segmentation Competition
set we're making available for psych fuse the competition cars that mit.edu
slash psych fuse first the original video us driving in high-definition
1080p and a 8k 360 video original video
driving around Cambridge we're providing the ground truth for a
training set for that training set for every single frame 30 frames a second
we're providing the segmentation frame to frame to frame segmented on
Mechanical Turk we're also providing the output of the network that I mentioned
the state of their our segmentation network that's pretty damn close to the ground truth but still not and our task
is this is the interesting thing is our task is to take the output of this
network well there's two options one is to take the output of this network and
use use other networks to help you propagate the information better so what
this segmentation the output of this network does is it only takes a frame by
frame by frame it's not using the temporal information at all so the question is can we figure out a way can
we figure out tricks to use temporal information to improve this segmentation so it looks more like this segmentation
and we're also providing the optical flow from frame to frame to frame so the optical flow based
on flowing at 2.00 of how each of the pixels moved okay and that forms a seg
fuse competition 10,000 images and the task is to submit code we have starter
code in Python and on github to take in
the original video take in for the training set the ground truth the segmentation from the state-of-the-art
segmentation Network the optical flow from the state-of-the-art optical flow Network and taking that together to
improve the the stuff on the bottom left the segmentation to try to achieve the ground truth and on the top right okay
with that I'd like to thank you tomorrow at 1 p.m. is way mo in Stata 32 one two
three the next lecture next week will be on deep learning for a sense in the human understanding the human and we
will release online only lecture on capsule networks and Gans general
adversarial networks thank you very much [Applause]

----------

-----
--25--

-----
Date: 2018.01.25
Link: [# MIT 6.S094: Deep Reinforcement Learning](https://www.youtube.com/watch?v=MQ6pP65o7OM)
Transcription:


AI Pipeline from Sensors to Action
today we will talk about deep reinforcement learning the question we
would like to explore it's to which degree we can teach systems to act to
perceive and act in this world from data so let's take a step back and think of
what is the full range of tasks then artificial intelligence system needs to accomplish here's the stack from top to
bottom top the input bottom output the environment at the top the world that
the agent is operating in sensed by sensors taking in the world outside and
converting it to raw data interpretable by machines sensor data and from that
raw sensor data you extract features you extract structure from that data such
that you can input it make sense of it discriminate separate understand the
data and as we discussed you form higher
and higher order representations a hierarchy of representations based on which the machine learning techniques
can then be applied once the machine
learning techniques the understanding as I mentioned converts the data into
features into higher order representations and into simple actionable useful information we
aggregate that information into knowledge we take the pieces of knowledge extracted from the data
through the machine learning techniques and to build a taxonomy a library of
knowledge and with that knowledge we reason an aging estas to reason to
aggregate to connect pieces of data it's seen in the recent past or the distant
past to make sense of the world that's operating in and finally to make a plan
of how to act in that world based on its objectives based on what it wants to accomplished as I mentioned a simple but
commonly accepted definition of intelligence is a system that's able to accomplish complex goals so system
that's operating in the environment in this world must have a goal must have an objective function a reward function and
based on that it forms a plan and takes action and because there operates in
many cases in the physical world it must have tools effectors with which
it applies the actions to change something about the world that's the full stack of an artificial intelligence
system that acts in the world and the question is what kind of task can such a
system take on what kind of task can an artificial intelligence system learn as
we understand AI today we will talk about the advancement of deeper
enforcement learning approaches and some of the fascinating ways it's able to take much of the stack and treat it as
an end-to-end learning problem but we look at games we look at simple
formalized worlds while it's still impressive beautiful and unprecedented accomplishments it's nevertheless formal
tasks can we then move beyond games and into expert tasks of medical diagnosis
of design and into natural language and
finally the human level tasks of emotion imagination consciousness let's once
again review the stack in practicality in the tools we have the input for
robots operating in the world from cars to humanoid to drones as light our
camera radar GPS stereo cameras audio microphone networking for communication
and the various ways to measure kinematics with IMU
the raw sensory data is then processed features of form to representations are
formed and multiple higher and higher order representations that's what deep learning gets us before
neural networks before the advent of before the recent successes of neural
networks to go deeper and therefore be able to form high order representations of the data that was done by experts by
human experts today networks are able to do that that's the representation piece
and on top of the representation piece the final layers these networks are able
to accomplish the supervised learning tasks the generative tasks and the
unsupervised clustering tasks through machine learning that's what we talked
about a little in lecture one and we'll continue tomorrow and Wednesday
that's supervised learning and you can think about the output of those networks
as simple clean useful valuable information that's the knowledge and
that knowledge can be in the form of single numbers it could be regression
continuous variables it could be a sequence of numbers it can be images audio sentences text speech once that
knowledge is extracted and aggregated how do we connect it in multi resolution
always form hierarchies of ideas connect ideas the trivial silly example is
connecting images activity recognition and audio for example if it looks like a
duck quacks like a duck and swims like a duck we do not currently have approaches
that effectively integrate this information to produce a higher confidence estimate that is in fact the
duck and the planning piece the task of taking the sensory information fusing
the sensory information and making action control and longer-term plans based on that information as we'll
discuss today are more and more amenable to the learning approach to the deep learning
approach but to date have been the most successful and non learning optimization based approaches like with the several
of the guest speakers we have including the creator of this robot Atlas in Boston Dynamics so the question how much
of the stack can be learned and to end from the input to the output we know we can learn the representation and the
knowledge from the representation and to knowledge even with the kernel methods of SVM and certainly with with neural
networks mapping from representation to information has been where the primary
success of machine learning over the past three decades has been mapping from
raw sensory data to knowledge that's where the success the automated
representation learning of deep learning has been a success going straight from
raw data to knowledge the open question for us today and beyond is if we can
expand the red box there of what can be learned and to end from sensory data to
reasoning so aggregating forming higher representations of the extracted knowledge and forming plans and acting
in this world from the raw sensory data we will show the incredible fact that we're able to do CERN exactly what's
shown here and to end with deeper enforcement learning on trivial tasks in a generalizable way the question is
whether that can then move on to real-world tasks of autonomous vehicles
of humanoid robotics and so on that's
the open question so today let's talk about reinforcement learning there's three types of machine learning
Reinforcement Learning
supervised unsupervised are the categories at the
extremes in relative to the amount of human and human input that's required
for supervised learning every piece of data that's used for teaching these systems is first labeled by human beings
and unsupervised learning on the right is no data is labeled by human beings in
between is some sparse input from humans semi-supervised learning is when only
part of the data is provided by humans ground truth and the rest must be inferred generalized by the system and
that's what reinforcement learning Falls reinforcement learning has shown there
with the cats as I said every successful presentation must include cats they're
supposed to be Pavlov's cats and ringing a bell and every time they ring a bell
they're given food and they learn this process the goal of reinforcement
learning is to learn from sparse reward
data from learn from sparse supervised data and take advantage of the fact that
in simulation or in the real world there is a temporal consistency to the world there is a temporal dynamics that
follows from state to state the state through time and so you can propagate information even if the information that
you're received about the the supervision the ground truth is sparse you can follow that information back
through time to infer something about the reality of what happened before then even if your reward signals were weak so
it's using the fact that the physical world evolves through time and some some
sort of predictable way to take sparse information and generalize it over the
entirety of the experience as being learned so we apply this the two problems today we'll talk about deep
traffic as a methodology deep reinforcement learning so deep traffic
is a competition that we ran last year and expanded significantly this year and
I'll talk about some of the details and how the folks in this room can on your smart phone today or if you have a
laptop training agent while I'm talking training a neural network in the browser
some of the things we've added our we've added the capability we've now turned it
into a multi agent deeper enforcement learning problem where you can control up to ten cars within your network
perhaps less significant but pretty cool is the ability to customize the way the
agent looks so you can upload and people have to an absurd degree have already
begun doing so uploading different images instead of the car that's shown there as long as it maintains the
dimensions shown here is a SpaceX rocket the competition is hosted on the website
self-driving cars that MIT ID you slash deep traffic will return to this later
the code is on github with some more information a starter code and a paper
describing some of the fundamental insights that will help you win at this
competition is an archive so from supervised learning in lecture
one to today supervised learning we can think of as memorization of ground truth
data in order to form representations that generalizes from that ground truth
reinforcement learning is we can think of as a way to brute force propagate
that information the sparse information through time to to assign quality reward
to state that does not directly have a reward to make sense of this world when
the rewards are sparse but are connected through time you can think of that as
reasoning so the through time is modeled in most
reinforcement learning approaches very simply that there's an agent taking an
action in a state and receiving a little reward and the agent operating in an environment execute an action receives
an observed state and new state and receives their reward this process continues over and over and some
examples we can think of any of the video games some of which we'll talk about today like Atari breakout as the
environment the agent is the paddle each
action that the agent takes has an influence on the evolution of the
environment and the success is measured by some reward mechanism in this case
points are given by the game and every game has a different point scheme that
must be converted normalized into a way that's interpreted by the system and the
goal is to maximize those points maximize the reward the continuous
problem of card pole by balancing the goal is to balance the pole on top of a moving cart the state is the angle the
angular speed the position of horizontal velocity the actions are the horizontal
force applied to the cart and the reward is one at each time step if the pole is still upright
all the first-person shooters the video games is now Starcraft the strategy games in case
of first-person shooter and doom what is the goal the environment is the game the
goal is to eliminate all opponents the state is the raw game pixels coming in the actions is moving up down left right
and so on and the reward is positive when eliminating an opponent and
negative when the agent is eliminated
industrial robotics been packin with a robotic arm the goal is to pick up a
device from a box and put it into a container the state is the raw pixels of the real world that the robot observes
the actions are the possible actions of the robot the different degrees of freedom are moving through those degrees
moving the different actuators to realize of the position of the arm and the reward is positive when placing a
device successfully and negative otherwise everything could be modeled in
this way Markov decision process there's a state as zero action a zero and reward
received a new state is achieved again action rewards state action rewards
state until a terminal state is reached and the major components of
reinforcement learning is a policy some kind of plan of what to do in every
single state what kind of action to perform a value function a some kind of
sense of what is a good state to be in of what is a good action to take in a state and sometimes a model that the
agent represents the environment with some kind of sense of the environment its operating in the dynamics of that
environment that's useful for making decisions about actions let's take a
trivial example a grid world of three by four twelve
squares we start at the bottom left and their task with walking about this world
to maximize reward they're awarded at the top right is a plus 1 and a 1 square
below that is a negative 1 and every step you take is a punishment or is a
negative reward of 0.04 so what is the optimal policy in this world now when
everything is deterministic perhaps this is the policy when you start the bottom
left well because every step hurts every step has a negative reward then you want to take the shortest path
to the maximum square with a maximum reward when the state space is
non-deterministic as presented before with a probability of 0.8 when you
choose to go up you go up but with probability 0.1 you go left and point 1
you go right unfair again much like life that would be the optimal policy what is
the Keith observation here that every single state in the space must have a plan because you can't because then a
non-deterministic aspect of the control you can't control where you're going to
end up so you must have a plan for every place that's the policy having an action an optimal action to take in every
single state now suppose we change the reward structure and for every step we
take there's a negative reward is a negative 2 so it really hurts there's a
high punishment for every single step we take so no matter what we always take
the shortest path the optimal policy is to take the shortest path to the to the only spot on the board that doesn't
result in punishment if we decrease the
reward of each step to negative 0.1 the policy changes whether
some extra degree of wandering encouraged and as we go further and
further in lowering the punishment as before to negative 0.04 more wandering
and more wandering is allowed and when we finally turn the reward into positive
so every step it every step is increases
the reward then there's a significant incentive to to stay on the board
without ever reaching the destination kind of like college for a lot of people
so the value function the way we think about the value of a state or the value
of anything in the environment is the reward were likely to receive in the
future and the way we see the reward were likely to receive as we discount
the future award because we can't always count on it
here Gama further and further out into the future more and more discounts
decreases the reward the importance of the reward received and the good
strategy is taking the sum of these rewards and maximizing it maximizing the scoundrel ward
that's what reinforcement learning hopes to achieve and with cue learning we use
any policy to estimate the value of taking an action in a state so off
policy forget policy we move about the world and use the bellman equation here
on the bottom to continuously update our estimate of how good a certain action is
in a certain state so we don't need this
this allows us to operate in a much larger state space in a much larger action space we move about this world
through simulation or in the real world taking actions and updating our estimate of how good certain actions are over
I'm the new state at the left is the is the updated value the old state is the
starting value for the equation and we update that old state estimation with the sum of the reward received by taking
action s tax action a and state us and
the maximum reward that's possible to be received in the following states
discounted that update is decreased with
a learning rate the higher the learning rate the more value we the the faster
will learn the more value we assigned to new information that's simple that's it
that's Q learning the simple update rule allows us to to explore the world and as
we explore get more and more information about what's good to do in this world
and there's always a balance in the various problem spaces we'll discuss there's always a balance between
exploration and exploitation as you form
a better and better estimate of the Q function of what actions are good to take you start to get a sense of what is
the best action to take but it's not a perfect sense it's still an approximation and so there's value of
exploration but the better and better your estimate becomes the less and less exploration has a benefit so usually we
want to explore a lot in the beginning and less and less so towards the end and when we finally release the system out
into the world and wish it to operate its best then we have it operate as a
greedy system always taking the optimal action according to the q2 key value function and everything I'm talking
about now is permit rised and our parameters that are very important for
winning the deep traffic competition which is using this very algorithm with
a neural network at its core so for sin
table representation of a cue function where the y-axis is state four states s
one two three four and the x-axis is actions a one two three four we can
think of this table as randomly initiated or initiated initialized in any kind of way that's not
representative of actual reality and as we move about this world and we take actions we update this table with the
bellman equation shown up top and here slides now are online you can see a
simple pseudocode algorithm of how to update it how to run this bellman
equation and over time the approximation becomes the optimal cue table
the problem is when that cue table it becomes exponential in size when we take
Deep Reinforcement Learning
in raw sensory information as we do with cameras with deep crash or with deep
traffic it's taking the full grid space and taking that information the raw the
raw grid pixels of deep traffic and when you take the arcade games here they're
taking the raw pixels of the game or when we take go the game of go when it's
taking the units the the board the raw state of the board as the input the
potential state space the number of possible combinations of what states it
possible is extremely large larger than we can certainly hold the memory and
larger that we can ever be able to accurately approximate through the bellman equation over time through
simulation through the simple update of the bellman equation so this is where
deep reinforcement learning comes in neural networks are really good approximate errs they're really good at
exactly this task of learning this kind of cue table
so as we started with supervised learning or neural networks helped us memorize patterns using supervised
ground true data and we'll move to reinforcement learning that hopes to propagate outcomes to knowledge deep
learning allows us to do so on much larger state spaces are much larger
action spaces which means it's generalizable it's much more capable to
deal with the raw stuff of sensory data which means it's much more capable to
deal with the broad variation of real world applications and it does so
because it's able to learn the representations as we discussed on
Monday the understanding comes from
converting the raw sensory information into into simple useful information
based on which the action in this particular state can be taken in the same exact way so instead of the cue
table instead of this cue function we plug in a neural network where the input is the state space no matter how complex
and the output is a value for each of the actions that you could take input is
the state output is the value of the function it's simple this is deep Q
Network DQ one at the core of the success of deep mind a lot of the cool
stuff you see about video games D queuing or variants of DQ and our play
this is water first with a nature paper a deep mind the success came of playing
the different games including Atari games
how are these things trained very similar to supervised learning the
bellman equation up top it takes the reward and the discounted
expected reward from future states the
loss function here for neural network and you'll now work learners with a loss function it takes the reward received at
the current state does a forward pass through a neural network to estimate the value of the future state of the best
action to take in the future state and then subtract that from the forward pass
through the network for the current state in action so you take the difference between what your a Q
estimator then you'll network believes the value of the current state is and what it more
likely is to be based on the value of the future states that are reachable
based on the actions you can take here's
the algorithm input is the state output is the Q value for each action or in
this diagram input is the state in action and the output is the Q value it's very similar architectures so given
a transition of s a are s prime s
current state taking an action receiving reward and achieving US prime state the
the update is to a feed-forward pass through the network for the current
state do a feed-forward pass for each of the possible actions taken in the next
state and that's how we compute the two parts of the loss function and update
the weights using back propagation again loss function back propagation is how
the network is trained this has actually been around for much longer than the
deep mind a few tricks made it made it
really work experience replays the
biggest one so as the games are played through simulation or if it's a physical
system as it acts in the world it's actually collecting the observations
into a library of experiences and that training is performed by randomly
sampling the library in the past by randomly sampling the previous
experiences and batches so you're not always training on the natural
continuous evolution of the system you're training on randomly picked batches of those experiences that's like
huge it's a it's a seems like a subtle trick but it's a really important one so
the system doesn't over fit a particular evolution of this of the game of the
simulation another important again
subtle trick as in a lot of deep learning approaches the subtle tricks make all the difference is fixing the
target network for the loss function if you notice you have to use the neural
network thick the singly neural network the gqi network to estimate the value of the current state and action pair and
next so using it multiple times and as
you perform that operation you're updating the network which means the
target function inside that loss function is always changing so you're the very nature your loss function is
changing all the time as you're learning and that's a big problem for stability that can create big problems for the
learning process so this little trick is to fix the network and only update it
every safe thousand steps so as you
train the network the the network that's used to compute the target function
inside the loss function is fixed it produces a more stable computation on a
loss function so the ground doesn't shift under you as you're trying to find
a minimal for the loss function the loss function doesn't change in unpredictable
difficult to understand ways and reward clipping which is always true with
general systems that are operating it's seeking to operate in the generalized
way is for very for these various games the points are different some some
points are low some points are high some go positive and negative and they're all normalized to a point where the good
points or the positive points are a 1 and negative points are a negative 1
that's reward clipping simplify the reward structure and because a lot of
the games are 30 FPS or 60 FPS and the actions are not it's not valuable to
take actions at such a high rate inside of these as particularly Atari games then you only take an action every four
steps while still taking in the frames as part of the temporal window to make decisions tricks but hopefully gives you
a sense of the kind of things necessary for both seminal papers like this one
and for the more important accomplishment of winning deep traffic is that
the tricks make all the difference here on the bottom is the circle is when the
technique is used in the x1 it's not looking at replay and target takes target network and experience replay
when both are used for the game of breakout River raid sea quests and Space
Invaders the higher the number the better it is the more points achieved so when it
gives you a sense that when replay and target both gives significant improvements in the performance of the
system order of magnitude improvements two orders of magnitude for breakup and
here is pseudocode of implementing dq1
the learning the key thing to notice and you can look to the slides is the the
loop the while loop of playing through the games and selecting the actions to
play is not part of the training it's it's part of the saving the observations
the state action reward next state observation is saving them into replay
memory into that library and then you sample randomly from that replay memory
to then train the network based on the loss function and with probability up up
top with the probability epsilon select a random action that epsilon is the
probability of exploration that decreases that's something you'll see in
deep traffic as well is the rate at which that exploration decreases over
time through the training process you want to explore a lot first and less and less over time so this algorithm is
being able to accomplish in 2015 and since a lot of incredible things things
that made the AI world think that we
were onto something that general AI is within reach for the first
time that raw sensor information was used to create a system that acts and makes sense of the world make sense of
the physics of the world enough to be able to succeed in it from very little information but these games are trivial
even though there is a lot of them this
dqn approach has been able to outperform a lot of the Atari games that's what's been reported on
outperform the human level performance but again these games are trivial what I
AlphaGo
think and perhaps biased I'm biased but one of the greatest accomplishments of
artificial intelligence in the last decade at least from the philosophical
or the research perspective is alphago 0
first alphago and then alphago 0 its
deepmind system that beat the best in the world in a game of go so what's the
game of go it's simple I won't get into
the rules but basically it's a 19 by 19 board shown on the bottom of the slide
for the bottom row of the table for a board of 19 by 19 the number of legal
game positions is 2 times 10 to the power of 170 it's a very large number of
possible positions to consider any one time especially the game evolves the
number of possible moves is huge much larger than in chess so that's why AI
the community thought that this game is not solvable until 2016 when alphago
used this use human expert position play to seed in a supervised way
reinforcement learning approach and I'll describe in a little bit of detail and a
couple of slides here to beat the best in the world and then
alphago 0 that is the accomplishment of
the decade for me in AI is being able to play with no training data on human
expert games and beat the best in the
world in an extremely complex game this is not Atari this is and this is a much
higher order difficulty game and that and the quality of players that is
competing in is much higher and it's able to extremely quickly here to
achieve a rating that's better than alphago and better than the different
variants of alphago and certainly better than the best of the human players in 21
days of self play so how does it work all of these approaches much much like
the previous ones the traditional ones that are not based on deep learning are
using Monte Carlo tree search MCTS which is when you have such a large
state space you start at a board and you play and you choose moves with some
exploitation exploration balancing choosing to explore totally new
positions or to go deep in the positions you know are good until the bottom of the game is reached until the final
state is reached and then you back propagate the quality of the choices you
made leading to that position and in that way you learn the value of of board positions and play that's been
used by the most successful go playing engines before and alphago since but you
might be able to guess what's the difference with alphago verse to the previous approaches they use the neural
network as the intuition quote-unquote - what
are the good states what are the good next board positions to explore and the
key things again the tricks make all the difference that made alphago zero work
and work much better than alphago is first because there was no expert play
instead of human games alphago used that very same Monte Carlo
tree search algorithm MCTS to do an intelligent look ahead based on the
neural network prediction of where dove the good States to take it checked that
instead of human expert play it checked how good indeed are those states it's a
simple look ahead action that does the ground truth that does the target
correction that produces the loss function the second part is the multitask learning what's now called
multitask learning is the networkers is quote-unquote two-headed in the sense
that first it outputs the probability of which move to take the obvious thing and it's also producing a probability of
winning and there's a few ways to combine that information and continuously train both parts of the
network depending on the choice taken so you want to take the best choice in the short term and achieve the positions
that are highly a slightly hood of winning for the player that's whose turn it is and another big step is that they
updated from 2015 the updated of the state-of-the-art architecture which are
now the architecture that one imagenet as the residual networks ResNet for
imagenet those that's it and those little changes made all the
DeepTraffic
difference so that takes us to deep traffic and the eight billion hours
stuck in traffic America's pastime so we tried to
simulate driving that behavior layer of driving so not the immediate control not
the motion planning but beyond that on top on top of those control decisions
the human interpretable decisions of changing lane of speeding up slowing down modeling that in a micro traffic
simulation framework that's popular in traffic engineering the kind of shown here we apply deep reinforcement
learning to that I'll call it deep traffic the goal is to achieve the highest average speed over a long period
of time weaving in and out of traffic for students here the requirement is to
follow the tutorial and achieve a speed of 65 miles an hour and if you really
want to achieve a speed over 70 miles an hour which is what's acquired to win and
perhaps upload your own image to make sure you look good doing it what you
should do clear instructions to compete read the tutorial you can change
parameters in the code box on that website cars done on mighty dad you size deep traffic click the white button that
says apply code which applies the code that you write these are the parameters that you specify then you'll network it
applies those parameters creates the architecture do you specify and now you have a network written in JavaScript
living in the browser ready to be trained then you click the blue button that says run training and that trains
the network much faster than one's actually being visualized in the browser
a thousand times faster by evolving the game making decisions taking in the grid
space as I'll talk about here in a second the speed limit is 80 miles an hour based on the various adjustments
were made to the game reaching 80 miles an hour is certainly impossible an average and reaching some of the speeds
that we've achieved last year it's much much much more difficult finally when you're happy and the
training is done submit the model to competition for those super eager
dedicated students you can do so every five minutes and to visualize your
submission you can click the request visualization specifying the custom
image and the color okay so here's the simulation speed limit 80
miles an hour cars 20 on the screen one of them is a red one in this case that's that one is
controlled by a neural network its speed it's allowed the actions of speed up slow down change lanes left-right or
stay exactly the same the other cars are
pretty dumb they speed up slow down turn left right but they don't have a purpose
in their existence they do so randomly or at least purpose has not been
discovered the road the car the speed the road is a grid space an occupancy
grid that specifies when it's empty it's set to a B meaning that the the
grid value is whatever speed is achievable if you were inside that grid
and when there's other cars that are going slow the value in that grid is the
speed of that car that's the state space that's the state representation and you can choose how much what slice that
state space you take in that's the input to the neural network for a visual
Asian purposes you can choose normal speed or fast speed for watching the
network operate and there's display options to help you build intuition
about the network takes in and what space that car is operating in the default is no extra information is added
then there's the learning input which visualizes exactly which part of the
road the is serves as the input to the network then there is the safety system
which I'll describe in a little bit which is all the parts of the road the car is not allowed to go into because it
would result in a collision and that with JavaScript would be very difficult to animate and the full map here's a
safety system you could think of this system as a CC basic radar ultrasonic
sensors helping you avoid the obvious collisions to obviously detectable
objects around you and the task for this red car for the steel Network is to move about this space is to move about the
space under the constraints of the safety system the red shows all the
parts of the grid it's not able to move into so the goal for the car is to not
get stuck in traffic it's make big sweeping motions to avoid crowds of cars
the input like DQ n is the state space the output is the value of the different
actions and based on the epsilon parameter through training and through
inference evaluation process you choose how much exploration you want to do
these are all parameters the learning is done in the browser on your own computer
utilizing only the CPU the action space there's five giving you some of the
variables here perhaps you go back to the slides to look at it the brain quote unquote is the thing that takes in the
state and the reward takes a four passed through the state and produce to
the next action the brain is where the neural network is contained both of the
training and the evaluation the learning input can be controlled in width forward
length and backward length lane side number of lanes to the side that you see patches ahead as the patches ahead that
you see patches behind as patches behind the you see mu this year can control the
number of agents that are controlled by the neural network anywhere from one to
ten and the evaluation is performed
exactly the same way you have to achieve the highest average speed for the agents
the very critical thing here is the agents are not aware of each other so
they're not jointly jointly planning the network is trained under the joint
objective of achieving the average speed for all of them but the actions are taking in a greedy
way for each it's very interesting what can be learned in this way because this
kinds of approaches are scalable to an arbitrary number of cars and you could imagine us plopping down the best cars
from this class together and having them compete in this way the best neural
networks because they're full in their greedy operation the number of networks
that can concurrently operate is fully scaleable there's a lot of parameters
the temporal window the layers the many
layers types that can be added here's a fully connected layer with tenure ons the activation functions all of these
things can be customized as specified in the tutorial the final layer a fully
connected layer with output a five regression giving the value of each of
the five actions and there's a lot of more specific parameters some of which
have this just from gamma to epsilon to experience
replay size to learning rate in temporal window the optimizer the learning rate
momentum batch size l2 l1 to K for regularization and so on there's a big
white button that says apply code that you press that kills all the work you've done up to this point so be careful
doing it it should be doing it only at the very beginning if you happen to
leave your computer running in training for several days as as folks have done the blue training button you press and
it trains based on the parameters you specify and the network state gets shipped to the main simulation from time
to time so the thing you see in the browser as you open up the web site is running then the same network that's
being trained and regularly it updates that network so it's getting better and better even if the training takes weeks
for you it's constantly updating the network you see on the left so if the car for the network that you're training
is just standing in place and not moving it's probably time to restart and change
the parameters maybe add a few layers to your network number of iterations is
certainly an important parameter to control and the evaluation is something
we've done a lot of worked on since last year to remove the degree of randomness to remove the the incentive to submit
the same code over and over again to hope to produce a higher reward a higher evaluation score the method for
evaluation is we collect the average speed over ten runs about 45 seconds of
game each not minutes 45 simulated seconds and there is five hundreds of
those and we take the median speed of the 500 runs it's done server-side so
extremely difficult to cheat I urge you to try you can try it locally there's a
start evaluation run but that one doesn't count that's just for you to feel better by you network that's that should
produce a result that's very similar to the one we were produced on the server it's to build your own intuition and as
I said we significantly reduce the influence of randomness so the the score the speed you get for the network you
design should be very similar with every valuation loading is saving if the
network is huge and you want to switch computers you can save the network it saves both the architecture of the
network and the weights and the on the network and you can load it back in
obviously when you load it in it's not saving any of the data you've already
done you can't do transfer learning with javascript in the browser yet submitting
your network submit model to competition and make sure you run training first otherwise it'll be initiated the way to
initiate it randomly and will not do so well you can resubmit us off and you like and the highest score is what counts the
coolest part is you can load your custom image specify colors and request the
visualization we have not yet shown the visualization but I promise you it's
going to be awesome again read the tutorial change the parameters in the code box click apply code run training
everybody in this room on the way home on the train hopefully not in your car
should be able to do this in the browser and then you can visualize request visualization because it's an expensive
process you have to want it for us to do it because we have to run in server-side
competition link is there github starter code is there and the details for those
that truly want to win is in the archive paper so the question that will come up
Conclusion
throughout is whether these reinforcement learning approaches are at all or rather if action planning control
is amenable to learning certainly in the case of driving we can't do it alpha go
zero did we can learn from scratch from self play
because that will result in millions of crashes in order to learn to avoid the
crashes unless we're working like we are deep crash on the RC car or we're
working in a simulation so we can look at export data we can look at driver data which we have a lot of and learn
from it's an open question whether this is applicable to date and I'll bring up
two companies because they're both guest speakers deep IRL is not involved in the
most successful robots operating in the real world in the case of Boston
Dynamics most of the perception control
and planning like in this robot does not involve learning approaches except with
minimal addition on the perception side best of our knowledge and certainly the
same is true with Wei MO as the speaker on Friday will talk about deep learning
is used a little bit in perception on top but most of the work is done from the sensors and the optimization base
the model-based approaches trajectory generation and optimizing which trajectory trajectory is best to avoid
collisions deep IRL is not involved and
coming back and back again the unexpected local POC is a high reward which arises in all of these
situations and apply in the real world so for the cat video that's pretty short
where the cats are ringing the bell and they're learning that the ring in the bell is is mapping to food I urge you to
think about how that can evolve over time in unexpected ways they may not
have a desirable effect where the final reward is in the form of food and the
intended effect is to ring the bell that's
ASAT comes in for the artificial general intelligence course in two weeks that something will explore extensively its
how these reinforcement learning planning algorithms will evolve in ways
they're not expected and how we can constrain them how we can design reward
functions that result in safe operation so I encourage you to come to the talk
on Friday at 1:00 p.m. as a reminder so 1:00 p.m. not 7:00 p.m. in Stata 32 one
two three and two the awesome talks in two weeks from Boston Dynamics to Ray
Kurzweil and so on for AGI now tomorrow we'll talk about computer vision and
psyche fuse thank you everybody [Applause]

----------

-----
--24--

-----
Date: 2018.01.20
Link: [# MIT Self-Driving Cars (2018)](https://www.youtube.com/watch?v=_OCjqIgxwHw)
Transcription:


welcome back to six at zero night for deep learning for self-driving cars
today we will talk about autonomous vehicles also referred to as driverless
cars autonomous cars Robo cars first the
utopian view where for many autonomous
vehicles have the opportunity to transform our society into a positive direction 1.3 million people die every
year in the automobile crashes globally thirty five thirty eight forty thousand
died every year in the United States so the one opportunity that's huge that's
one of the biggest focus for us here and MIT for people who truly care about this
it's to design autonomous systems our artificial intelligence system that saves lies
and those systems help work with deal
with or take away what nitsa calls the four DS of human folly drunk drugged
distracted and drowsy driving autonomous vehicles have the ability to take away
drunk driving distracted drowsy and drugged eliminate car ownership
so taking shared mobility to another level
eliminating car ownership from the business side is the opportunity to save
people money and increase mobility and
access making vehicles removing ownership makes vehicles more accessible
because the cost of getting from point A to point B drops an order to magnitude
and the insertion of software and intelligence into vehicles makes those
vehicles makes the idea of Transportation makes the way we see moving from A to point B a totally
different experience much like with our smart phone it makes it a personalized
efficient and reliable experience now for the negative view for the dystopian
view eliminate jobs any technology
throughout its history throughout our history of human civilization has always created fear that jobs that rely on the
prior technology will be lost this is a huge fear especially in trucking because
so many people in the United States and across the world rely work in the
transportation industry transportation sector and the possibility that AI will
remove those jobs has potential catastrophic consequences the idea one
that we have to struggle with in the 21st century of the role of intelligence
systems that aren't human beings being further and further integrated into our
lives is the idea that a failure of an autonomous vehicle even if they're much
rare if they're even if they're much safer that there is a possibility for an AI algorithm designed by probably one of
the engineers in this room will kill a person where that person would not have
died if they were in control of the vehicle the idea of an intelligent system one
indirect interaction with a human being killing that human being is one that we have to struggle with in a philosophical
ethical and technological level artificial
systems in popular culture lesson
engineering concerns may not be grounded ethically grounded at this time much of
the focus of building these systems as we'll talk about today and throughout this course that focuses on the
technology how do we make these things work but of course decades out years or
decades out the ethical concerns starts arising for Rodney Brooks one of the
seminal people from MIT those ethical concerns will not be an issue for another several decades at least five
decades but they're still important it continues the thought the idea of what
is the role of AI in our society when that car gets to make a decision about human life
what is it making that decision based on especially when it's a black box what is the ethical grounding of that
system does it conform with our social norms does a goal go against them and
there's many other concerns security is definitely a big one a car that's not
even artificial intelligence based a car that's software basis they're becoming more and more millions most of the cars
on road today are run by millions of lines of source code the idea that those
lines of source code written again by some of the engineers in this room get
to decide the life of a human being means then a hacker from outside of the
car can manipulate that code to also
decide the fate of that human being that's a huge concern for us from the
engineering perspective the truth is somewhere in the middle we want to find
what is the best positive way we can build these systems to transform our society to improve the quality of life
of everyone amongst us
but there's a grain of salt to the hype of autonomous vehicles we have to
remember as we discussed in the previous lecture and it will come up again and again our intuition about what is
difficult and what is easy for deep learning for autonomous systems is
flawed if we use our if use ourselves in this example human beings are extremely
good at driving this will come up again and again our intuition has to be
grounded in the understanding of what is the source of data what is the annotation and what is the approach what
is the algorithm so you have to be careful while using our intuition extending it decades out and making
predictions whether it's towards the utopian or dystopian view and as we'll talk about
some of the advancements of companies working in the space today you have to
take what people say in the media what the companies say some of the speakers
that will be speaking at this class say about their plans for the future and their current capabilities I think us a
guy that can provide is when there's a promise of a future technology future
vehicles there are two years out or more that has to be that's a very doubtful
prediction one that is within a year as we'll give a few examples today is
skeptical the real proof comes in actual
testing of public roads or in the most impressive the most amazing the reality
of it is when it's available to consumer purchase I would like to use Rodney
Brooks as a so it doesn't come from my mouth but I happened to agree his
prediction is no earlier than 2032 a driverless taxi service in a major US
city will provide arbitrary pick up and drop off locations fully autonomously that's 14 years away and
bite one 45 it will do so in multiple cities across the United States so think about
that that a lot of the engineers working in the space a lot of folks are actually building these systems agree with this
idea and that is the earliest I believe this will happen and Rodney believes but
as all technophobes have been wrong who could be wrong this is a map on the
x-axis a plot on the x axis of time throughout the 20th century and the
adoption rate and the y axis from zero to 100% of the various technologies from electricity to cars to radio the
telephone and so on and as we get closer to today the technology adoption rate
when it goes from zero to a hundred percent the number of years it takes to
adopt that technology is getting shorter and shorter and shorter as a society
we're better at throwing away the technology of old and accepting the technology of new so if a brilliant idea
to solve some of the problems were discussing comes along it could change everything overnight so let's talk about
Different approaches to autonomy
different approaches to autonomy we'll talk about sensors afterwards we'll talk
about companies players in this space and then we'll talk about AI and the
actual algorithms and how they can help solve some of the problems of autonomous
vehicles levels of autonomy here's a useful tech solemnization of levels of
autonomy useful for initial discussion for legal discussion and for policy
making and for blog posts and media reports but it's not useful I would
argue for design and engineering of the underlying intelligence and the system
viewed from a holistic perspective the entire thing creating an experience that
safe and enjoyable so let's go over those levels the five the six levels
this is presented by SAE report J three zero one six the most widely accepted
taxonomies ation of autonomy no automation at level zero level 1 and
level 2 is increasing levels automation level one is cruise control level two is
adaptive cruise control lane keeping level three I don't know what level
three is there's a lot of people that will explain that level three is conditional automation meaning it's
constrained to certain geographical location I will explain that from an engineering perspective I'm personally a
little bit confused of where that stands I'll try to redefine how we should view
automation level four and level five is high full level automation level four is
when the vehicle can drive itself fully for part of the time there's certain
areas in which it can take care of everything no matter what no human interaction input safekeeping is
required level five automation is the car does everything everything I would
argue that those levels aren't useful for designing systems that actually work
in the real world I would argue that there's two systems but first a starting
point that every system to some degree involves a human it starts with manual control from a
human human getting in the car and a human electing to do something so that's
the manual control what we're talking about when the human engages the system when the system is first available and
the human chooses to turn it on that's when we have to AI systems human
centered autonomy when the human is needed is involved and full autonomy
when AI is fully responsible for everything from the legal perspective that
means a to full autonomy means the car they designer the I system is liable is
responsible and for the human-centered autonomy the human is responsible what
does this practically mean for human center autonomy and we'll discuss
examples of all of these when a human interaction is necessary the question
then becomes is how often is the system available is it available on in traffic
conditions so for traffic bumper-to-bumper is available on the highway is it sensor based like in the
tesla vehicle meaning based on the visual characteristics to the scene the vehicle is confident enough to be able
to control to make control decisions perception control decisions the other
factor poor not discussed enough and I
think poorly imprecisely discussed when it is is the number of seconds given to
the driver not guaranteed but provided as a sort of feature to the driver to
take over in the tesla vehicle in all vehicles on the road today that time is
zero zero seconds are guaranteed zero seconds are provided there is some there's some room sometimes it's
hundreds of milliseconds sometimes it's multiple seconds but really there's no standard of how many seconds you get to
say wake up take control then tally up
operation something that some of the companies will mention are playing with is when a human being is involved
remotely controlling the vehicle remotely so being able to take over control the vehicle when you're when
you're not able to control it so support by a human that's not inside the car that's a very interesting idea to
explore but for the human centered autonomy side all of those features are
not required they're not guaranteed the human driver the inside the car is always responsible at
the end of the day they must pay attention to a degree that's required to take over when the system fails and no
matter under this consideration under this level of autonomy the system will
fail at some point that is the that is the point this is a collaboration between human and robot as the system
will fail and the human has to catch it when it does and then full autonomy is
AI is fully responsible now that doesn't again as will present some
companies in the marketing material and the PR side of things they might present
that there is significant degrees of autonomy if you're talking about l3 or l4 or l5 you have to read between the
lines you're not allowed to have teleoperation if a human is remotely
operating the vehicle a human is still in the loop a human is still evolved
it's still a human senator autonomy system you don't get the ten second rule
which is just because you give the
driver ten seconds to take control that somehow removes liability for you if you
say that that's it as an AI system I can't take can't resolve can't deal
can't control the vehicle in this situation and you have ten seconds to take over that's not good enough the
driver might be sleeping that driver may have had a heart attack they're not able to control the vehicle full autonomous
systems might must find safe harbor they must get you full stop from point A to
point B that point B might be your desired destination or might be a safe parking lot but it has to bring you to a
safe location this is a clear definition of the two systems in the human of
course as far as our certain current conception of artificial intelligence in
cars today is a human always overrides the AI system so we should for them for
the in the general case the human gets to
choose to take control they I can't take control the human except when danger is
imminent meaning sudden crashes like in a bee events we're not yet ready for the I
systems to say as a society to say no no you're drunk you can't drive so beyond
the traditional levels from level zero to level five the starting point is level zero no automation all cars start
here level one level two and level three I would argue fall into human senator
autonomy systems a1 because they did
involve some degree of a human then l4 l5 to some degree there's some crossover
fall into full autonomy even though with l4 with way mo as you can ask on Friday
and anyone Cruz uber playing in the space there's very often a human driver
involved one of the huge accomplishments of way mo over the past month incredible
accomplishment where in Phoenix Arizona they drove without the car drove without
a driver the meaning there was no safety driver to catch there was no engineer
staff member there to catch the car a human being that doesn't work for Google
or way mo got into that car and got from A to point B without a safety driver that's an incredible accomplishment and
that particular trip was a fully autonomous trip that is full autonomy
well there's no human to catch the car
no way I press station is good without cats it's a full
autonomy a to system its when you do
nothing but right along human Senate autonomy system is when you have some
control I'm sorry I had to so the two
paths for autonomous systems they want to need to in blue on the left is a one
human centered on the right is a two full autonomy and then blue is from the
artificial intelligent perspective is easy easier and then red is harder
easier meaning we do not have to achieve a hundred percent accuracy harder means
everything that's off of a hundred percent accuracy no matter how small has
a potential of costing human lives and huge amounts of money for companies so
let's discuss we'll discuss later in the lecture about the algorithms behind each
of these methods and the left on the right but this summarizes the two approaches the localization mapping for
the car to determine where it's located for the human centered autonomy it's
easy it still has to do the perception it has to localize itself within the lane it has to find all the neighboring
pedestrians and the vehicles in order to be able to control the vehicle to some degree but because the human is there it
doesn't have to do so perfectly when it fails a human is there to catch it scene understanding perceiving everything in
the environment from the camera from whether its lidar radar ultrasonic the
planning of the vehicle whether it's just staying within lane or for adaptive cruise control controlling the
longitudinal movement of the vehicle or its changing lanes is the Tesla autopilot or higher degrees of
automation all of those movement planning decisions can be autonomous Lee when the human is there
to catch it's easier because you're allowed to be wrong rarely but wrong the
hard part is getting the human robot interaction piece right that's next Wednesday lecture as we'll
discuss about how deep learning can be used to interact first perceive everything about the driver and second
to interact with the driver that part is hard because you can't screw up on that
part you have to make sure you help the driver know where your flaws are so they can take over if the driver is not
paying attention you have to bring their attention back to the road back to the interaction you have to get that piece
right because for a flawed system one that's rarely flawed the rarity is the
challenge in fact has to get the interaction right and then the final
piece communication the autonomous vehicle fully autonomous vehicle must
communicate extremely well with the external world with the pedestrians that
jaywalkers the humans in this world the cyclists that communication piece one at
least that is part of a safe and enjoyable driving experience is extremely difficult on the taught a way
Moe vehicle I wish them luck if they come to Boston from getting from point A to point B because pedestrians will take
advantage a vehicle must assert itself in order to be able to navigate Boston
streets and that assertion is communication that piece is extremely
difficult for Tesla vehicle for for a human centered autonomy vehicle l2 l3
the way you deal with Boston pedestrians is you take over roll down the window yell something and
then speed up getting the piece for an artificial
intelligence system to actually be able to accomplish something like that as we'll discuss on the ethics side and the
engineering side is extremely difficult that said most of the literature and the
human factors field in the autonomous vehicle field anyone that studied autonomy in aviation and in vehicles is
extremely skeptical about the human centered approach they think it's deeply responsible it's deeply responsible
because as argued because human beings
when you give them a technology which will take control part of the time they
will get lazy they would take advantage of that technology they will over trust that technology they'll assume will work
perfectly always this is the idea that this this idea extended beyond further
and further means that the better the system gets the better the car gets it driving itself the more the humans will
sit back and be completely distracted it will not be able to re-engage themselves in order to safely catch when the system
fails this is Chris Urmson the founder of the Google self-driving cars program and now the co-founder of one at the
other co-founders a speaker this class on next Friday sterling Anderson of a company called Aurora a start-up he was
one of the big proponents or the I
should say opponents the idea that human senator autonomy could work they tried
it publicly is spoken about the fact that at Google as in the early
self-driving car program they've tried shared autonomy they've tried l2 and it
failed because they're engineers that people driving their vehicles fell asleep and that's the belief that people have
and we'll talk about why that may not be true there's a fascinating truth in the
way human beings can interact with artificial intelligence systems that may
work in this case as I mentioned it's the human robot interaction building
that deep connection between human and machine of understanding of communication this is what we believe
happens so there's a lot of videos like this as it's it's fun but it's also
representative of what what society believes happens when automation is
allowed to enter the human experience and driving or the human life is a stake
that you can become completely disengaged it's kind of it's kind of a
natural thing to think but the question is does this actually happen what
actually happens on public roads the amazing thing that people don't
often talk about is that there is
hundreds of thousands of vehicles on the road today
equipped with autopilot Tesla autopilot that have a significant degree of
autonomy that's data that's information so we can answer the question what
actually happens so many of the people behind this team have instrumented 25
vehicles 21 of which are Tesla autopilot vehicles now with over collected
recording everything about the driver 2 cameras 2 HD cameras on the driver 2
cameras on the external camera on the external roadway and collecting everything about the car including audio
the state that pulling everything from the cam bus the kinematics of the vehicle I am you GPS all of that
information over now over 300,000 miles over 5 billion video frames all as we'll
talk about analyze the computer vision you extract from that video of the driver of
everything they're doing that level distraction the allocation of attention
the drowsiness emotional states the hands on wheel hands off wheel body pose
activity smartphone usage all these factors all of these things that you
would think would fall apart when you start letting autonomy into your life
we'll talk about what the initial reality is that should be inspiring and
thought-provoking as I said three cameras single board computer recording
all the data over a thousand machines in Holyoke and distributed computation
running the deep learning algorithms I've I've mentioned on these five plus
billion video frames going from the raw data to the actionable useful
information the slides are up online if you'd like to look through them oh fly
through some of them and this is the video of one of thousands of trips we
have in autopilot in our data a car driving autonomously a large fraction of
the time on highways from here to California from here to Chicago to
Florida and all across the United States we take that data and using the
supervised learning algorithms semi-supervised the number of frames
here is huge for those that work in computer vision five billion frames is
several orders of magnitude larger than any data set that people are working
with in computer vision actively
annotated so we want to use that data
for understanding the behavior of what people actually doing in the cars and we
want to train the algorithms that do perception and control a quick summary over three hundred thousand miles twenty
five vehicles the colors are true to the actual colors of the vehicles little fun facts Tesla
Model X Model S and now model three five
hundred thousand five hundred plus sorry miles a day and growing now most days in
2018 are over a thousand miles a day this is a quick GPS map in red is manual
driving across the Boston area in blue cyan is autonomous driving this is
giving you the sense of just the scope of this data this is a huge number of miles with automated driving several
orders of magnitude larger than what Wei Mo's doing that what Cruise is doing and
what Ober is doing the miles driven in
this data with autopilot confirming what
y'all muska stated it's 33% of miles of
driven autonomously this is a remarkable number for those of you who drive and
for those of you who are familiar with these technologies that is remarkable adoption rate that 33 percent of the
miles are driven in autopilot that means these drivers are getting use out of the
system it's working for them that's an incredible number it's also incredible
because under the the decades of literature from aviation to automation
and vehicles to to Chris Urmson and way mo the belief is such high numbers are
likely to lead to crashes to fatalities to at the very least highly responsible
behavior drivers over trusting the systems and getting in trouble we can run the glance
classification algorithms again this is for next Wednesday discussion to the
actual algorithm it's the algorithm that tells you the region that the driver is looking at and it's comparing road
instrument cluster left rearview center stack and right does the allocation of glance change with autopilot or with
manual driving it does not appear to in any significant noticeable way meaning
you don't start playing chess you don't start you don't get in the backseat to sleep you don't start texting in your
smartphone watching a movie at least in this data set there's promise here for
the human centered approach the observation to summarize this particular
data is that people are using it a lot the percentage of miles the percentage of hours is incredibly high at least
relative to what was will be expected from these systems and given that
there's no crashes there's no near crashes in autopilot the row type is
mostly highway traveling at high speeds the mental engagement looked at 8,000
transyl of control from machine to human so human beings taking control of the vehicle saying you know what I'm going
to take control now I'm not comfortable with the situation for whatever reason either not comfortable or electing to do
something that the vehicle is not able to like turn off the highway make a right or left turn stop for a stop sign
these kinds of things physical engagement as I said glance remains the
same and what do we take from this it says something that I'd like to really
emphasize this we talked to was we talked about autonomous vehicles in this class and the guest speakers who are all
on the other side so I'm representing the human center side all our speakers
are focused on the full autonomy side because that's the side roboticists know
how to solve that's the fascinating algorithm nerd side and that's the side I love as
well just my belief stands that the solving the perception control problem
is extremely difficult and to three decades away so in the meantime we have to utilize the human robot interaction
to actually bring these AI systems onto the road to successfully operate and the
way we do that counter-intuitively is we have to have we have to let the
artificial intelligence systems reveal their flaws one of the most endearing
things to human beings can do to each other friends is reveal their flaws to
each other now from an automotive perspective from a company perspective it's perhaps not appealing for an AI
system to reveal what it sees about the world and what it doesn't see about the world where it succeeds and where it
fails but that is perhaps exactly what it needs to do in the case of autopilot
the way the very limited but I believe successful way is currently doing that
is allowing you to use autopilot basically anywhere so what people are doing is they're trying to engage their
turn on autopilot in places where they really shouldn't rural rural roads curvy
with terrible road markings with in in
heavy rain conditions with snow with lots of cars driving at high speeds all
around they turn autopilot on to understand to experience the limitations of the system to interact that
human-robot interaction is through its tactile by turning it on and seeing is
it going to work here how's it gonna fail and the human is always there to catch it that interaction that's
communication that intimate understanding is what creates successful integration of AI in the car before
we're able to solve the full autonomy puzzle learn the limitations by exploring it starts with this guy
and hundreds of others if you search on YouTube first time with autopilot the
amazing experience of direct transfer of control of your life to an artificial
intelligence system in this case giving control to Tesla autopilot system this
is why in the human centered camp of autonomy I believe that autonomous vehicles can
be viewed as personal robots with which you build build a relationship or the
human robot interaction is the key problem not the perception control and
they're the flaws of both humans and machines must be clearly communicated
and perceived perceived because we use the computer vision algorithms to detect
everything about the human it communicated because on the displays of the car or even through voice it has to
be able to reveal when it doesn't see different aspects of the scene from the
human centered approach then we can focus on the left the perception and
control side perceiving everything about the external environment and controlling the vehicle without having to worry
about being 99.99999% correct approaching a hundred percent correct
because in the cases where it's extremely difficult we can let the human catch the system we can reveal the flaws
and let the human take over when the system can't so let's get to the sensors
Sensors
the sources of raw data that we'll get to work with there
three there's cameras so image sensors RGB infrared visual data does radar and
ultrasonic and there's lidar let's
discuss the strengths first to discuss really what these sensors are the strengths the weaknesses and how they
can be integrated together through sensor fusion so radar is the trust of
the old trusted friend the sensor that's commonly available in most vehicles that
have any degree of autonomy on the left is a visualization of the kind of data on high-resolution radar that's able to
be extracted it's cheap both radar which works with
electromagnetic waves and ultrasonic which works with sound waves sending a
wave letting it bounce off the obstacles knowing the speed of that wave being able to calculate the distance to the
obstacle based on that it does extremely well in challenging weather rain snow
the downside is low resolution compared to the other sensors we'll discuss but
it is the one that's most reliable and used in automotive industry today and it's the one that's in sense of fusion
is always there lidar visualized on the
right the down size it's expensive but
it produces an extremely accurate depth information and a high resolution map of the environment that has 360 degrees of
visibility it has some of the big
strengths of radar in terms of reliability but with much higher resolution and accuracy the downside is
cost here is the visualization comparing the two of the
kind of information get to work with the the the density and the quality of
information with lidar is much higher and lighter has been the successful
source of ground truth the reliable sensor relied upon on vehicles that
don't care about cost and camera the
thing that most people here should be passionate about because machine learning deep learning has the most
ability to have a significant impact there why first it's cheap so it's everywhere
second it's the highest resolution so there's the most the most highly dense amount of information which means
information is something that could be learned and inferred to interpret the
external scene so that's why it's the best source of data for understanding
the scene and the other reason it's awesome for deep learning is because of
the huge eNOS of data involved the its
many orders of magnitude more data available for driving in camera visible
light or infrared than it is in lidar the and our world is designed for
visible light our eyes work in similar ways the cameras at least crudely so the
source data is similar the lane markings the traffic signs of traffic lights the
other vehicles the other pedestrians all operate with each other in this RGB
space in terms of visual characteristics the downside is cameras are bad at depth
estimation it's noisy and difficult even with stereo vision cameras to estimate depth relative to lidar and they're not
good in extreme weather and they're not good at least visible light cameras at night
compare the ranges here's a plot and meters on the x-axis of the range and
acuity and the y-axis with ultrasonic
lidar radar and camera passive visual
sensor plotted the range of cameras is the greatest this is looking at we're
going to look at several different conditions this is for clear well-lit conditions so during the day no rain no
fog lighter and radar have a smaller range under 200 meters and ultrasonic
sensors used mostly for Park assistance and these kinds of things and blind spot warning has terrible range is designed
for extremely close as high resolution distance estimation for extremely close
distances here a little bit small but looking at up top is clear well-lit
conditions the plot we just looked at and on bottom is clear dark conditions so just a clear night day no rain but
it's night and on the bottom right is heavy rain snow or fog vision falls
apart in terms of range and accuracy under dark conditions and in rain snow
or fog radar our old trusted friend stay strong the same range just under
two hundred meters and at the same acuity same with sonar lighter doesn't
works well at night but it does not do well with rain or fog or snow one of the
biggest downsides of lidar other than cost so here's another interesting way
to visualize this that I think is productive for our discussion of which sensor will win out is it the Elon Musk
prediction of camera or is that the way more prediction of lidar for
I'd are in this kind of plot that will look for every single sensor the greater
the radius of the blue the more successful that sensor is at
accomplishing that feature with a bunch of features lined up around the circle
so range for lidar is pretty good not great but pretty good resolution is also
pretty good it works in the dark it works in bright light but it falls apart
in the snow it does not provide color information texture information contrast
it's able to detect speed but the sensor size at least to date is huge the sensor
cost at least to date is extremely expensive and it doesn't do well in
proximity where ultrasonic shines speaking of which ultrasonic same kind
of plot does well in proximity detection it's cheap the cheapest sensor of the four and sensor size you can get it to
be tiny it works and snow and fog and rain but its resolution is terrible
its range is non-existent and it's not able to detect speed
that's where radar steps up it's able to detect speed it's also cheap it's also
small but the resolution is very low and
it's just like lidar is not able to provide texture information color information camera the sensor cost is
cheap the sensor size is small not good up close proximity the range is the longest
of all of them resolution is the best of all of them it doesn't work in the dark it works in
bright light but not always one of the biggest downfalls of camera senses is
the sensitivity to the lighting variation it works it doesn't work in
the snow fog rain so suffers much like lidar from that
but it provides rich interesting sectional information the very kind that
deep learning needs to make sense of this world so let's look at the cheap
sensors ultrasonic radar and cameras
which is one approach putting a bunch of those in a car and fusing them together
the cost there is low one of the nice
ways to visualize using this visualization technique when they're fused together on the bottom it gives
you a sense of them working together to complement each other as strengths and
the question is whether the camera or lidar will win out for partial autonomy
or full autonomy on the bottom showing this kind of visualization for a lidar
sensor and on top showing this kind of visualization for fused radar ultrasonic
and camera at least under these considerations the fusion of the cheap
sensors can do as well as lidar now the open question is whether lidar in the
future of this technology can become cheap and its range can increase because then lidar can win out
solid-state light our and a lot of developments with a lot of startup ladder companies are promising to
decrease the cost and increase the range of these sensors but for now we plow
along with dedication on the camera front the annotated driving data grows
exponentially more and more people are beginning to annotate and study the
particular driving perception and control problems and the very algorithms
for the supervised and semi-supervised and generative networks that we use to
work with this data are improving so it's a race and of course radar and ultrasonic I was
there to help so companies that are playing in the space some of them are
Companies in the self-driving car space
speaking here lame-o in April 2017 they
exited their testing their extensive impressive testing process and allow the
first rider in Phoenix Public rider in November 2017
it's an incredible accomplishment for a company and for an artificial intelligence system in November 2017 no
safety driver so the car truly achieved full autonomy under a lot of constraints
but it's full autonomy it's a step it's an amazing step in the direction towards
full autonomy much sooner than people would otherwise predict and the miles
four million miles driven autonomously by November 2017 and growing quickly
growing in terms of full autonomous driving if I can say so cautiously
because most of those miles have a safety driver so I would argue it's not
full autonomy but however they define full autonomy it's four million miles
driven incredible uber in terms of miles
second on that list they have driven two million miles autonomously by December
of this of last year 2017 the quiet
player here in terms of not making any
declarations of being fully autonomous just quietly driving in a human censored
way l2 over 1 billion miles in autopilot
over three hundred thousand vehicles today are equipped with autopilot
technology with the ability to drive control the car laterally and longitudinally and if anyone believes
the CEO of Tesla there'll be over 1 million such vehicles by the end of 2018
but no matter what the 300,000 is an incredible number and the 1 billion
miles is an incredible number autopilot was first released in September 2014 one
of the first systems on the road to do so autopilot and I call myself as one of
the skeptics in October 2016 autopilot
decided to let go of an incredible work done by Mobil I now Intel we're
designing their perception control system they decided to let go of it completely and start from scratch using
mostly deep learning methods the DRI px 2 system from Nvidia and 8 cameras they
decided to start from scratch that's the kind of boldness the kind of risk-taking
that can come with naivety but in this case it worked
incredible audio 8 system is going to be
released at the end of 2018 and it's promising one of the first vehicles that's promising what they're calling l3
and the definition of l3 according to
Thorsten Lionheart the head of the automated driving and Oddie in a naughty
is when the function is operate as intended if the customer turns the
traffic jam pilot on now this l3 system is designed only for traffic jazz
bumper-to-bumper traffic under 60 kilometers an hour if the customer
returns a traffic jam pilot on and uses it as intended and the car was in control at the time of the accident the
driver goes to the insurance company and the insurance company will compensate the victims of the accident and
aftermath they come to us we will pay them so that means the cars
liable the problem is under the
definition of l2 l3 perhaps there is some truth to this being an l3 system
the important thing here is it's nevertheless deeply and fundamentally human centered because even as you see
here in this demonstration video with a reporter the car for a poorly understood
reason transfer control to the driver says that's it I can't I can't take care
of the situation you take control how how much time do you have in terms of
seconds before you really need to know to take over well this is the new thing about level 3 with level 3 the system
allows the driver to give the prompt to take over vehicle control again ahead of
time which is in this case up to 10 seconds ok so if the traffic jam
situation clears up or any failure in the system occurs everything you might
think of the system still needs to be able to drive automatically because the driver has this time to take over
you might ask what its new about this so why is Howdy saying this is the first
level 3 system worldwide on the market when talking about these levels of
automation there's a classification which starts at lower zero which is basically the drivers doing everything
there's no assistance nothing and then it gradually becomes into partly
automation and when we're talking about these assistance functions like lane-keeping and distance keeping we're
talking about level 2 assistance function ok which is meaning that the
driver is obliged to permanently monitor the traffic situation to keep the hands
on the wheel even though there's a support and an assistance and to intervene immediately if anything is not
quite right so you know that from laying assistance systems when the steering is
not perfectly in the right lane we have to intervene and correct immediately and
that is the main difference now we got a takeover request so what so let's let's
talk about what that means this is still a human Center system it still struggles
that still must solve the human robot interaction problem and there's many
others playing in the space I'm the on the full autonomy side way mo uber GM
crews new tana me the CTO of which he'll speak here on Tuesday optimist ride its
annuity voyage the CEO of which will speak here next Thursday and Aurora not
listed this the founder of which will speak here next Friday and the human
centered autonomy side the reason I am speaking about us so much today is we
don't have any speakers I'm the speaker the Tesla autopilot is for several years
now doing incredible work on that side we are also working with Volvo pilot assist as a lot of different approaches
they're more concerned of interesting the audio traffic jam assist as I mentioned the a8 being
released at the end of this year the Mercedes drive pollicis in the e-class
an interesting vehicle that I got to drive quite a bit as the Cadillac supercruise the ct-6 which is very much
constrained geographically to highway driving and the loudest proudest of them
all george hotz of the comma a open pilot let's just
leave that there so where can a I help
Opportunities for deep learning
we'll get into the details of the coming lectures on each individual component I'd like to give some examples the key
areas problem spaces that we can use machine learning to solve from data his
localization and mapping so being able to localize yourself in the space the very first question that a robot needs
to answer where am I seen understanding taking the scene in and interpreting
that scene detecting all the entities in the scene detecting the class of those
entities in order to then do movement planning to move around those entities
and finally driver state essential element for the human robot interaction perceive everything about the driver
everything about the pedestrian and the cyclists and the cars outside the human element of those the human perception
side so first the where am I visual odometry using camera sensors which is
really where once again deep learning is most that a vision sensor is the most
amenable to learning based approaches and visual odometry is using camera to
localize yourself to answer the where am I question the traditional approaches
slam detect features in the scene and
track them through time from frame to frame and from the movement
those features are able to estimate thousands of features tracking estimate
the location the orientation of the vehicle or the camera those methods with
stereo vision first requires taking two camera streams on distorting them
competing disparity map from the different perspectives of the two camera computing the matching between the two
the feature detection thus if too fast or any of the methods of extracting non
deep learning methods of the extracting features strong detectable features that
can be tracked through from frame to frame tracking those features and estimating the trajectory the
orientation of the camera that's the traditional approach to visual odometry
in the recent years since 2015 but most success in the last year has been the
end end deep learning approaches either stereo or monocular cameras deep vo is
one of the most successful the antenna method has taken a sequence of images
extracting with a CNN from each image the central features from each image and
then using RNN recurrent neural network to track over time the trajectory the
pose of the camera image to pose and to
end here's the visualization on a kitty data set using deep vo again taking the
video up on the top right as an input and estimating what's visualized is the
position of the vehicle in red is the estimate based again and to end with a
CNN and RNN the in red is the estimate in blue is the ground truth in the kitty
dataset so this removes a lot of the modular parts a slam a visual odometry
and allows it to be and to end which means it's learner bull which means it
gets better with data that's huge
vision alone this is one of the exciting opportunities for AI or people working
in AI is the ability to use a single sensor and perhaps the most inspiring
because that sensor is similar to our own the sensor that we ourselves use of
our eyes to use that alone as the primary sensor to control a vehicle
that's really exciting and the fact that deep learning that the vision visible
light is the most amenable to deep learning approaches makes this particularly an exciting area for deep
learning research scene understanding of course who can do a thousand slides on this traditionally object detection
pedestrians vehicles there is a bunch of different types of classifiers of feature extractions harlech features and
deep learning has basically taken over and dominated every aspect of scene
interpretation perception understanding tracking recognition classification
detection problems and audio can't forget audio that we can use audio as
source of information whether that's detecting honks or in this case using the audio of the tires microphones on
the tires to determine visualize there's a spectrogram of the audio coming in
for those of you who are particularly have a particularly tuned ear can listen
to the different audio coming in here of wet road and dry road after the rain so
there's no rain but the road is nevertheless wet and detecting that is extremely important for vehicles because
they still don't have traction control estelle have poor control in road to road surface tired road surface
connection and being able to detect that from just audio is a very interesting approach
finally we're not finally next for the perception control side finally is the
movement planning getting from A to point from point A to point B traditional approaches the optimization
based approach determine the optimal control try to reduce the problem
formalize the problem in a way that's amenable to optimization based
approaches there's a lot of assumptions that need to be made but once those
assumptions are made you're able to determine to generate thousands or
millions of possible trajectories and have an objective function we determine which of the trajectories to take here's
a race car optimizing how to take a turn at high speed with deep learning
reinforcement learning the application mule networks
reinforcement learning is particularly exciting for both the control and the
planning side so that's where the two of
the competitions we're doing in this class come into play the simplistic two-dimensional world of deep traffic
and the high mood high speed moving
high-risk world of deep crash will
explore those tomorrow tomorrow's lectures on deeper enforcement learning
and finally drivers state detecting everything about the driver and then
interacting with them on the left and green are the easier problems on the right and red are the harder problems in
terms of perception in terms of how amenable they are to deep learning methods body pose estimation is a very
well studied problem we have extremely good detectors for estimating the pose
the hands the elbows the shoulders every aspect visible aspect of the body head
pose the orientation of the head or extremely good at that and as we get
smaller and smaller in terms of size blink rate blink duration I pose and
blink dynamics start getting more and more difficult all of these metrics all of these metrics extremely important for
detecting things like drowsiness or as components of detecting emotion or word people are looking in driving where your
head is turned is not necessarily where you're looking in regular life
non-driving life when you look somewhere you usually turn your head to look with
your eyes in driving your head often stay still or moves very subtly your
eyes do a lot more moving it's the kind of effect that we described as the
lizard owl effect some fraction of people a small fraction or owls meaning
they move their head a lot and some people most people are lizards
moving eyes to allocate their attention the problem with eyes is from the
computer vision perspective they're much harder to detect in lighting variation than real-world conditions they get
harder and we'll discuss how to deal with it of course that's where deep learning steps up and really helps with
real-world data cognitive load we'll discuss as well estimating the cognitive load of the
driver to give a quick clip is this as the driver glance we've seen before
estimating the very most important problem on driver stateside is
determining whether they're looking on road or off road it's the dumbest simplest but most important aspect are
they looking are they in the seat and looking on the road or are they not that's driver glance classification not
estimating the X Y Z geometric orientation where they're looking but actually binary class classification on
road or off road body pose estimation determining if the hands are on wheel or
not determining if the body alignment is standard is good for seatbelt for safety
this is one of the important things for autonomous vehicles if there's an imminent danger to the driver the driver
should be asked to return to a position that is safe for them in case of a crash driver in motion on the top is
satisfied on the bottom as a frustrated driver they self-reported satisfied this
is with a voice based navigation one of the biggest sources of frustrations for people in cars is voice based navigation
trying to tell an artificial intelligence system using your voice alone where you would like to go huge
source of frustration one of the interesting things in our large data set that we have from the effective
computing perspective is determining which of the features are most commonly
associated with frustrated voice based interaction and that's a smile as shown there it's the counter intuitive notion
that emotion in particularly emotion in the car is very context dependent that
smiling is not necessarily a sign of happiness and the stoic board look of
the driver up top is not necessarily a reflection of unhappiness he is indeed a
10 out of 10 in terms of satisfaction with the experience if he has ever been
satisfied with anything happens to be Dan Brown one of the
amazing engineers in our team cognitive load estimating from the eye region and
sequences of images 3d convolutional neural networks taking in a sequence of
images from the eye looking at the blink dynamics and the eye position to determine the cognitive load from 0 to 2
how deep in thought you are two paths to autonomous future again I would like to
maybe for the last time but probably not argue for the one on the left because
our brilliant much smarter than me guest speakers will argue for the one on the right the human centered approach allows
us to solve the problems of 99% accuracy of localization scene understanding movement planning those are the problems
were taking on in this class the scene segmentation that we'll talk about on Thursday the control they will talk
about tomorrow and the driver state that we'll talk about next Wednesday these problems can be solved with deep
learning today the problems on the right solving them to close to 100% accuracy are extremely difficult and may be
decades away because for full autonomy to be here we have to solve this
situation I've shown this many times octave Triomphe we have to solve this situation I give you just a few examples
what do you do you have to solve this situation a sort of subtler situation
here is a it's a busy crosswalk where no
autonomous vehicle will ever have a hope of getting through unless it asserts itself and that there's a couple of
vehicles here that kind of nudge themselves through or at least when they have the right-of-way don't necessarily
nudge but don't hesitate when a pedestrian is present an ambulance flying by even though if you use a
trajectory so and pedestrian intent modeling algorithm to predict the
momentum of the pedestrian to estimate where they can possibly go you would
then autonomous vehicle will stop but these vehicles don't stop they assert themselves they move forward now for a
full autonomy system this may not be the last time I show this video but because
it's taking full control it's following a reward function an objective function
and all of the problems the ethical and the AI problems that arise like this
Coast Runner problem will arise so we have to solve those problems we have to
design that objective function so with that I'd like to thank you and encourage
you to come tomorrow because you get a chance to participate in deep traffic a deep reinforcement learning competition
thank you very much [Applause]

----------

-----

--23--

-----
Date: 2018.01.15
Link: [# MIT 6.S094: Deep Learning](https://www.youtube.com/watch?v=-6INDaLcuJY)
Transcription:

Thank you everyone for braving the cold, and the snow To be here
This is 6.S094: Deep Learning for Self-Driving Cars
And, it's a course where we cover the topic of Deep learning
Which is a set of techniques, that have taken a leap in the last decade For our understanding
Of what artificial intelligence systems are capable of doing And self-driving cars, which is systems,
that can take these techniques, and integrate them In a meaningful, profound way into our daily lives
In a way that transforms society. So that's why both of these topics, are extremely important
And extremely exciting. My name is Lex Fridman, And I'm joined by an amazing team of engineers,
In Jack Terwilliger, Julia Kindelsberger, Dan Brown
Michael Glazer, Li Ding, Spencer Dodd and Benedikt Jenik,
Among many others... We build autonomous vehicles, here at MIT,
Not just ones that perceive, and move about the environment,
But ones that interact, communicate, and earn the trust, And understanding of human beings inside the car,
The drivers and the passengers, And the human beings outside the car the pedestrians and other drivers and cyclists.
The website for this course: selfdrivingcars.mit.edu if you have questions, email at: deepcars@mit.edu
Slack: deep-mit For registered MIT students, you have to register on the website
And, by midnight, Friday, January 19th
build a neural network, and submit it to the competition. That achieves the speed of 65 miles per hour
On the new deep traffic 2.0 It's much harder and much more interesting
than last year's for those of you who participated. There's three competitions in this class:
Deep Taffic,SegFuse DeepCrash There's guest speakers, that come from:
Waymo, Google, Tesla And, those are starting new, autonomous vehicle startups
In Voyage, NuTonomy and Aurora
And then use a lot today from CES. And, we have shirts! For those of you who braved the snow
and continued to do so towards the end of the class there will be free shirts.
Yes, I said free and shirts in the same sentence, You should be here.
Okay. First: The Deep Traffic competition There's a lot of updates, and we'll cover those on Wednesday.
it's a deep reinforcement learning competition. Last year we received over 18,000 submissions,
This year we're going to go bigger! Not only can you control one car, with your neural network
You can control up to ten This is multi agent deep renforcement learning. This is super cool!
Second: SegFuse - Dynamic Driving Scene Segmentation competition
Where, you're given the raw video,
The kinematics of the vehicles, the movement of the vehicle, The state-of-the-art segmentation.
For the training set you're given: Ground truth labels, pixel level labels Scene segmentation, and optical flow.
And with those pieces of data, You're tasked to try to perform better than the state-of-the-art
In image based segmentation. Why is this critical,
And fascinating, in an open research problem? Because, robots that act in this world,
In the physical space, not only must interpret, Use these deep learning methods to interpret, The spatial visual characteristics of a scene,
They must also interpret, understand, and track The temporal dynamics of the scene. This competition is about temporal propagaton of information,
Not just scene segmentation. You must understand the space, and time.
And finally Deep Crash Where we use deep reinforcement learning,
To slam cars thousands of times, Here, at MIT, at the gym.
You're given data on a thousand runs, where car Or a car knowing nothing is using a monocular camera's
Single input, driving over 30 miles an hour, Through a scene, it has very little control through
Very little capability to localize itself It must act very quickly. In that scene you're given a thousand runs, to learn anything.
We'll discuss this, in the coming weeks. This competition will result in four submissions
That; We evaluate everyone's in simulation But the top four submissions, we put head-to-head at the gym.
And, until there is a winner declared, we keep slamming cars ...at 30 miles an hour.
Deep crash, and also on the website is from the last year, And on GitHub there's DeepTesla.
Which is using the large-scale naturalistic driving data set We have to train a neural network to do enter and steering
That takes in monocular video from the forward roadway, And produces steering commands,
Steering commands for the car. Lectures: Today we'll talk about deep learning,
Tomorrow we'll talk about autonomous vehicles, Deep RL is on Wednesday,
Driving scene understanding So segmentation That's Thursday.
On Friday, we have Sacha Arnoud, The Director of Engineering at Waymo.
Waymo is one of the companies, that's truly taking Huge strides in fully autonomous vehicles.
They're taking the fully L4, L5, autonomous vehicle approach. and it's fascinating to learn,
he's also the head of perception for them. To learn from him; What kind of problems they're facing?
And what kind of approach they're taking on? We have Emilio Frazzoli, Who's one of last year's speakers
Sertac Karaman said Emilio is the smartest person he knows, So Emilio Frazzoli's the CTO of nuTonomy
An autonomous vehicle company, that was just acquired by Delphi
For a large sum of money. And they're doing a lot of incredible work in Singapore, and here in Boston.
Next Wednesday, we are going to talk about the topic of our research, or my personal fascination,
is deep learning for driver state sensing. Understanding the human, perceiving everything about the human
being inside the car, and outside the car. One talk, I'm really excited about,
is Oliver Cameron on Thursday. He is now the CEO of autonomous vehicle startup Voyage.
He's previously the director of the self-driving car program, for Udacity He will talk about: how to start a self-driving car company,
For those, who said that MIT folks are entrepreneurs. If you want to start one yourself, he'll tell you exactly how.
It's super cool! And then, Sterling Anderson! Who was the director previously, Tesla Autopilot team.
And now is a co-founder of Aurora, The self-driving car startup, that I mentioned,
...that has now partnered, with NVIDIA and many others. So, why self-driving cars?
Self-Driving Cars
This class is about applying data-driven learning methods, To the problem of autonomous vehicles.
Why self-driving cars are fascinating, And an interesting problem space?
Quite possibly, in my opinion, This is the first wide reaching, and profound integration
Of personal robots, in society. Wide-reaching, because there's one billion cars on the road,
Even a fraction of that, will change, ...the face of transportation, and how we move about this world.
Profound, and this is an important point, ...that's not always understood.
There's an intimate connection, between a human, And a vehicle, when there's a direct transfer of control.
It's a direct transfer of control... That takes that, his or her life, into the hands,
Of an artificial intelligence system. I showed a few quick,
Quick clips here, you can Google first time with Tesla autopilot, On YouTube and watch people, perform that transfer of control,
There's something magical... About a human and a robot working together,
That will transform, what artificial intelligence is, In the 21st century.
And this particular autonomous system, AI system, self-driving cars, is on the scale.
And the profound,the life-critical nature of it, is profound. In a way that, it will truly test the capabilities of AI.
There'a a personal connection, That will argue throughout these lectures, That we cannot escape considering the human being. That will argue throughout these lectures,
That we cannot escape considering the human being. That autonomous vehicle, must not only perceive and control
It's movement through the environment. You must also perceive everything about the human driver and the passenger
And interact, communicate, and build trust with that driver.
Because,... In my view, As I will argue throughout this course,
An autonomous vehicle is more of a personal robot, than it is a perfect perception controled system.
Because, perfect perception and control, For this world, full of humans,...
Is extremely difficult. And could be, two-three-four decades away.
Full autonomy. Autonomous vehicles are going to be flawed.
They're going to have flaws... And we have to design systems, that are effectively caught
That effectively transfer control to human beings, When they can't handle the situation.
And that transfer of control... Is an... Is a fascinating opportunity for AI.
Because the obstacle avoidance, Perception of obstacles, and obstacle avoidance,
It's the easy problem. It's the safe problem. Going 30 miles an hour Navigating through streets of Boston,
It's easy. It's when you have to get, to work, and you're late.
Or you're sick of the person in front of you, ...that you want to go in the opposing lane,
and speed up. That's human nature. And we can't escape it. Our artificial intelligence systems,
Can't escape human nature, they must work with it. What's shown here, is one of the algorithms,
We'll talk about next week, for cognitive load. Or we take, the raw,...
3D convolutional neural networks, Take in the eye region, the blinking, and the pupil movement
To determine the cognitive load of the driver. We'll see how we can detect everything about the driver,
Where they're looking? Emotion? Cognitive load? Body pose estimation?
Drowsiness. The movement towards full autonomy
...is so difficult... I would argue That it almost requires human level intelligence.
That the.... As I said, 2-3-4 decade out journey...
For artificial intelligence researchers, to achieve full autonomy Will require achieving, solving, some of the problems
Fundamental problems of creating intelligence. And... That's something we'll discuss,
In much more depth, In a broader view in two weeks, For the artificial general intelligence course,
Where we have Andrej Karpathy, from Tesla, Ray Kurzweil, Marc Raibert, from Boston Dynamics
Who asked for the dimensions of this room, because he's bringing robots
Nothing else was told to me... It'll be a surprise.
So that is why I argue the human centered Artificial intelligence approach In every algorithm of a design considers the human.
For autonomous vehicle on the left, the perception Scene understanding, and the control problem,
As we'll explore through the competitions, And the assignments, of this course Can handle 90, and increasing
...percent of the cases. But it's the 10, 1.1 percent of the cases as we get better and better,
That we have to... We're not able to handle through these methods And that's where the human, perceiving the human
is really important. This is the video from last year. Of Arc de Triomphe Thank you
Didn't know it last year, I know now. That is one of millions of cases,
Where human to human interaction is the dominant driver.
Not, the basic perception control problem
So why deep learning in this space? Because deep learning
Deep Learning
Is a set of methods, that do well from a lot of data.
And to solve these problems Where human life is at stake, We have to be able to have techniques
That learn from data, learn from real-world data. This is the fundamental reality of artificial intelligent systems
That operate in the real world. They must learn from real world data. Whether that's on the left for the perception, the control side,
Or on the right, for the human The perception, and the communication, Interaction
And collaboration with the human, And the human robot interaction.
Ok. So what is deep learning?
It's a set of techniques, if you allow me the definition, of intelligence Being the ability to accomplish complex goals,
Then I would argue, definition of understanding Maybe a reasoning is...
The ability to turn complex information Into simple, useful, actionable information.
And that is what deep learning does. Deep learning is representation learning,
Or feature learning, if you will. It's able to take raw information,
Raw complicated information, That's hard to do anything with, And construct hierarchical representations of that information,
To be able to do something interesting with it. It is the branch of artificial intelligence,
Which is most capable and focused, on this task. Forming representations from data,
Whether it's supervised or unsupervised, Whether it's with the help of humans, or not; It's able to construct structure,
Find structure in the data; Such that you can extract Simple, useful, actionable information.
On the left, From Ian Goodfellow's book,
Is the basic example of a misclassification. The input of the image,
On the bottom, with the raw pixels And as we go up the stack as we go up the layers,
Higher and higher order representations are formed. From edges, to contours The corners, to object parts
And then finally, The full object semantic classification, of what's in the image
This is representation learning A favorite example for me
Is, one from four centuries ago. Our place in the universe,
And representing that place in the universe, Whether it's relative to Earth, Or relative to the Sun.
On the left is our current belief, On the right is the one, that was held widely,
Four centuries ago Representation matters! Because,what's on the right
Is much more complicated than what's on the left.
You can think of, in a simple case here When the task is to draw a line that separates, Green triangles and blue circles
In the Cartesian coordinates space, on the left The task is much more difficult. Impossible, to do well
On the right, it's trivial, in polar coordinates. This transformation is exactly
Whan we need to learn, this is representation learning. So you can take the same task,
Of having to draw a line that separates The blue curve, and the red curve on the left . If we draw a straight line, it's going to be a high
There's no way to do it with zero error. With 100% accuracy
Shown on the right, is our best attempt. But what we can do with deep learning,
With a single hidden layer network done here, Is form the topology, the mapping of the space,
In such a way, in the middle, That allows for a straight line to be drawn, That separates the blue curve, and the red curve.
The learning of the function in the middle, Is what we're able to achieve with deep learning.
It's taking raw, complicated information, And making it simple, actionable, useful.
And the point is, that, this kind of ability to learn, From raw sensory information
Means that, we can do a lot more, with a lot more data. So, deep learning gets better with more data.
And that's important, for real world applications. Where edge cases are everything.
This is us driving, with two perception control systems. One is in Tesla vehicle, with the autopilot
Version one system that's using a monocular camera, To perceive the external environment, And produce control decisions.
And our own, neural network Running on adjacent TX2, that's taking in the same.
With a monocular camera, and producing control decisions. And, the two systems argue, and when they disagree
They raise up a flag, to say that this is an edge case That needs human intervention.
There is... Covering such edge cases, using machine learning, Is the main problem, of artificial intelligence, and...
When applied to the real world, It is the main problem to solve.
Okay. So what are neural networks? Inspired very loosely, and I'll discuss
About the key difference between, Our own brains and artificial brains Because there's a lot of insights, in that difference.
But inspired loosely by biological neural networks, Here, as a simulation of a...
Thalamocortical brain network, Which is only 3 million neurons, 476 million synapses... The full human brain,
Is a lot more than that. A 100 billion neurons, ...1,000 trillion synapses.
There's inspirational music, with this one That I didn't realize was here, it should make you think.
Artificial neural networks, yeah... Let's Just let it play...
The human neural network is, a hundred billion neurons, right? 1,000 trillion synapses.
One of the state-of-the-art, Neural network is ResNet-152, which has...
60 million synapses. That's a difference, of about...
A seven order of magnitude difference That's a difference, of about... A seven order of magnitude difference The human brains have, 10 million times more synapses,
Than artificial neural networks. Plus or minus one order of magnitude, depending on the network.
So, what's the difference, between A biological neuron, and an artificial neuron?
The topology of the human brain have no layers. Neural networks are stacked in layers
They're fixed, for the most part. There is chaos!
Very little structure in our human brain In terms of how neurons are connected.
They're connected, often, to 10,000 plus other neurons. The number of synapses, from individual neurons
That are... Input into the neuron is huge! They're asynchronous. The human brain works asynchronously.
Artificial neural networks work synchronously. The learning algorithm for artificial neuron networks,
The only one, the best one... Is back propagation.
And we don't know, how human brains learn...
Processing speed, this is one of the... The only benefits we have with artificial neural networks is...
Artificial neurons are faster. But they're also extremely power inefficient,
And... There is a division into stages, Of training and testing with neural networks.
With biological neural networks, as you're sitting here today They're always learning.
The only profound similarity, the inspiring one The captivating one, is that both are,
Distributed computation at scale. There is an emergent aspect to neural networks,
Where the basic element of computation: A neuron, Is simple. Is extremely simple.
But when connected together, beautiful Amazing, powerful approximators can be formed.
A neural network is built up with these computational units, They're the inputs, There's a set of edges, with weights on them.
The edges... The weights are multiplied by this input signal, A bias is added, with a nonlinear function.
That determines whether the network gets activated or not Well, the neuron gets activated or not.
Visualized here. And these neurons can be combined in a number of ways.
they can form a feed-forward neural network, Or they can feed back into itself,
To form... To have state memory. In Recurrent neural networks.
The ones on the left, are the ones that are most successful, For most applications, in computer vision.
The ones on the right are very popular, and specific. One temporal dynamics, or dynamics time series
of any kind are used. In fact, the ones on the right, are much closer
To the way our human brains are Than the ones on the left, But that's why, they're really hard to train.
One beautiful aspect, of this emergent power, For multiple neurons being connected together
Is the universal property That with a single hidden layer These networks can learn any function
Learn to approximate any function. Which is an important property to be aware of, because
The limits here, are not in the power of the networks The limit in... ...is in the methods by which
We construct them, and train them.
What kinds of machine learning, deep learning are there? We can separate into two categories.
Memorizers, The approaches, that essentially memorize patterns in the data.
And approaches that, we can loosely say Are beginning to reason
To generalize over the data, with minimal human input. On top, on the left are the, quote/unquote "Teachers",
Is how much human input in blue, is needed To make the method successful for supervised learning,
Which is what most of deep learning successes come from Or most of the data is annotated by human beings,
The human is at the core of the success. Most of the data, that's part of the training
Needs to be annotated by human beings. With some additional successes, coming from augmentation methods,
That extend that... Extend the data, based on which these networks are trained
And the semi-supervised reinforcement learning, And unsupervised methods, That we'll talk about, later in the course,
That's where the near-term successes we hope are. And with the unsupervised learning approaches,
that's where, the true excitement, About the possibilities of artificial intelligence lie.
Being able to make sense, of our world With minimal input from humans,...
So, we can think of two kinds of deep learning impact spaces.
One is a special purpose intelligence. It's taking a problem, formalizing it.
Collecting enough data on it, and being able to, Solve a particular case, that provides value.
Of particular interest here is a network That estimates apartment costs in the Boston area.
So you could take the number of bedrooms, The square feet, and the neighborhood... And provide as output, the estimated cost.
On the right is the actual data, Of apartment cost. We're actually standing,
In an area, that has over 3000 dollars for a studio apartment
Some of you may be feeling that pain. And then there's general-purpose intelligence.
Or something that feels like... Approaching general-purpose intelligence.
Which is reinforcement, and unsupervised learning. Here with Andrej, from Andrej Karpathy's, Pong to Pixels.
A system that takes in, 80 by 80 pixel image And with no other information is able to beat,
Is able to win at this game. No information except a sequence of images, Raw sensory information,
The same way, the same kind of information, That human beings take in, from the visual Audio, touch, sensory data.
The very low-level data, and be able to learn to win. And it's very simplistic, And it's very artificially constructed world,
But nevertheless, A world where no feature learning is performed. Only raw sensory information is used to win.
With very sparse minimal human input. We'll talk about that on Wednesday.
With deep reinforcement learning. So. But for now we'll focus on supervised learning.
Where there is input data, There is a network we're trying to train,
A learning system, and there's a correct output, That's labeled by human beings. That's the general training process for a neural network.
Input data, labels... And the training of that network , that model.
So that, in a testing stage, A new input data, that has never seen before, It's tasked with producing guesses, and is evaluated based on that.
For autonomous vehicles, that means being released Either in simulation, or in the real world, to operate.
And how they learn, how neural networks learn, Is given, the forward pass,
Of taking the input data, whether it's from the training stage In the training stage, taking the input data,
Producing a prediction. And then given that there's ground truth in the training stage, We can have a measure of error, based on a loss function.
That then punishes... The synapses, the connections, the parameters,
That were involved with making that wrong prediction.
And it back propagates the error, through those weights. We'll discuss that in a little bit more detail, in a bit here...
So what can we do with deep learning? You can do one-to-one mapping. Really you can think of input as being anything,
It can be a number, a vector of number, a sequence of numbers A sequence of vector of numbers...
Anything you can think of, from images to video, To audio, to text can be represented in this way. And the output can, the same, be a single number,
Or it can be images, video, text, audio. One-to-one mapping on the bottom,
One-to-many, many-to-one, many to many, and... Many to many with different starting points for the data.
Asynchronous. Some quick terms, that will come up
Deep learning is the same as neural networks, It's really deep neural networks, large neural networks
It's a subset of machine learning, that has been Extremely successful in the past decade.
Multi-layer perceptron, deep neural network , Recurrent neural network Long short-term memory network LSTM
Convolution neural network and deep belief networks, All of these will come up to the slides...
And, there is specific operations, Layers within these networks of Convolution, pooling, activation, and back propagation.
This concept that we'll discuss, In this class. Activation functions, there's a lot of variants.
On the left is the activation function, the left column, And the x-axis is the input,
On the y-axis is the output. The sigmoid function, the output.
If the font is too small, the output is... Not centered at zero.
For the Tanh function, it's centered at zero; But it still suffers from vanishing gradients.
Vanishing gradients is when the value, The input is low or high.
The output of the network, as you see in the right column, There, the derivative of the function is very low.
So the learning rate is very low. For ReLU,
Not, it's also not zero centered, But it does not suffer from vanishing gradients.
Back propagation is the process of learning It's the way we take goal from error, Compute as the loss function,
At the bottom right of the slide, Taking the actual output of the network with a forward pass,
Subtracting it from the ground truth, Squaring, dividing by two,
And than using that loss function. that back propagate, Through, to construct a gradient, to back propagate the error.
To the weights that were responsible, For making either a correct, or an incorrect decision.
So the subtasks are there, there's a forward pass, There's a backward pass, and...
A fraction of the weight's gradient subtracted from the weight. That's it! That process is modular,
So it's local to each individual neuron, Which is why it's extremely,... We're able to distribute it across multiple,
Across the GPU. Parallelize across the GPU.
So, learning for a neural network, These competition units are extremely simple.
They're extremely simple to then... Correct when they make an error, when they're Part of a larger network, that makes an error.
And, all that boils down to, Is essentially an optimization problem. Where the objective, utility, function is
The loss function, and the goal is to minimize it. And we have to update the parameters The weights, and the synapses,
And the biases to decrease that loss function.
And that loss function is highly nonlinear. Depending on the activation function's different properties,
Different issues arise. There's vanishing gradients, for sigmoid.
Where the learning can be slow There's dying ReLU's...
Where the derivative is exactly zero, For inputs less than zero.
There are solutions to this, like leaky ReLU's And a bunch of details, you may discover When you try to win the deep traffic competition
But, for the most part These are the main activation functions And it's the choice of the neural network designer
Which one works best... There's saddle points, all the problems From your miracle, non-linear optimization
That arise, come up here. It's hard to break symmetry,
And stochastic gradient descent Wthout any kind of tricks to it,
Can take a very long time, to arrive at the minima One of the biggest problems in all of machine learning
And certainly deep learning, is overfitting You can think of the blue dots and a plot here
As the data, to which we want to fit a curve We want to design a learning system that approximates
The regression of this data. So, in green, is a sine curve
Simple. Fits well. And then, there's a ninth degree polynomial Which fits even better, in terms of the error
But it clearly overfits this data If there's other data
That it has not seen yet that it has to fit It's likely to produce a high error So it's overfitting the training set
This is a big problem for small data sets And so we have to fix that, with regularization
Regularization is a set of methodologies That prevent overfitting Learning the training too well, in order
And then to not be able to generalize To the testing stage
And overfitting, the main symptom Is the error decreases in training set But increases in the test set.
So there's a lot of techniques and traditional machine learning That deal with this; Cross validation, and so on... But because of the cost of training
for neural networks Its traditional to use what's called a validation set
So you create a subset of the training That you keep away For which you have the ground truth
And use that, as a representative of the testing set. So you...
Perform early stoppage, or more realistically Just save a checkpoint. Often.
To see how, as the training evolves, The performance changes on the validation set,
And so you can stop, when the performance In the validation set is getting a lot worse It means you're overtraining on the training set.
In practice, of course, We run training much longer And see when, what is the best performing
What is the best performing Snapshot checkpoint of the network?
Dropout, is another very powerful regularization technique. Where we randomly remove part of the network
Randomly remove some of the nodes in the network Along, with it's incoming and outgoing edges
So what that really looks like, Is a probability of keeping a node. And in many deep learning frameworks today
It comes with a dropout layer So it's essentially a probability That's usually greater than 0.5
That a node will be kept. For the input layer The probability should be much higher,
Or, more effectively, what works well is just adding noise What's the point here?
You want to create enough diversity in the training data Such that it is generalizable, to the testing.
And as you'll see with deep traffic competition, There's L2 and L1 penalty, Weight decay, weight penalty
Where, there's a penalisation on the weights that get too large The L2 penalty keeps the weight small
Unless the error derivative is huge And produces a smoother model,
And prefers to distribute When there is two similar inputs It prefers to put half the weights on each
Distribute the weights As opposed to putting the weight on one of the edges.
Makes the network more robust L1 penalty has the one benefit That, for really large weights
They're allowed to be, to stay. So it allows for a few weights to remain very large.
These are the regularization techniques And I wanted to mention them because they're useful To some of the competitions, here in the course.
And I recommend to go to playground To tensorflow playground To play around with some of these parameters
Where you get to, online in the browser Play around with different inputs, different features
Different number of layers, and regularization techniques And to build your intuition about classification
Regression problems, given different input data sets.
So what changed? Why over the past many decades
Neural networks that have gone through two winters Are now again Dominating the artificial intelligence community
CPUs, GPUs, ASICs, So, computational power has skyrocketed
From Moore's law to GPUs There is huge data set, including ImageNet, and others
There is research; Back propagation In the 80's, The convolutional neural networks
LSTMs, there's been a lot of interesting breakthroughs About how to design these architectures
How to build them, such that they're trainable efficiently Using GPUs.
There is the software infrastructure From being able to share the data, or get; To being able to train networks, and share code
And effectively view neural networks as a stack of layers As opposed to having to implement stuff from scratch
With TensorFlow, PyTorch and other deep learning frameworks And there's huge financial backing from Google, Facebook, and so on...
Deep learning... ..is...
In order to understand, why it works so well And where it's limitations are...
We need to understand where our own intuition comes from About what is hard, and what is easy The important thing about computer vision
Which is a lot of what this course is about Even in deep reinforcement learning formulation
Is that visual perception for us human beings Was formed 540 million years ago
That's 540 million years worth of data
An abstract thought Is only formed about a 100 thousand years ago
That's several orders of magnitude less data So we can make, with the neural networks
Predictions that seemed trivial
Trivial to us human beings But completely challenging and wrong to neural networks
Here, on the left, showing a prediction of a dog With a little bit of a distortion and noise added to the image
Producing the image on the right And your network is confidently 99 percent plus accuracy, Predicting that it's an ostrich
And there's all these problems to deal with Whether it's in computer vision data, Whether it's in text data, audio...
All of this variation arises In vision, It's illumination variability
The set of pixels and the numbers look completely different Depending on the lighting conditions It's the biggest problem in driving
Is, lighting conditions, lighting variability. Pose variation Objects need to be learned from every different perspective
I'll discuss that for when sensing the driver Most of.... Most of the deep learning work that's done in the face
On the human, is done on the frontal face Or semi frontal face. There's very little work done on the full 360 pose
Variability that a human being could take on.
Intraclass variability for the classification problem, For the detection problem... There is a lot of different kinds of objects
For cats, dogs, cars, bicyclists, pedestrians.
So that brings us to object classification. And I'd like to take you through where deep learning
Has taken big strides for the past several years Leading up to this year, to 2018
So let's start at object classification Is when you take a single image,
And you have to say... One class, that's most likely to belong in that image.
The most famous variant of that is the ImageNet competition ImageNet challenge. ImageNet data set is a data set of 14 million images
With 21,000 categories And... For, say, the category of fruit
There's a total of 188,000 images of fruit And there is 1200 images of Granny Smith apples.
It gives you a sense, of what we're talking about here So this has been, the source
Of a lot of interesting breakthroughs in deep learning And a lot of the excitement, in deep learning
It's first, the big successful network At least, one that became famous
In deep learning is AlexNet in 2012 That took a leap of...
A significant leap in performance on the ImageNet challenge. So it was one of the first neural networks
That was successfully trained on the GPU And achieved an incredible performance boost Over the previous year on the ImageNet challenge.
The challenge is: ...and I'll talk about some of these networks... It's to given a single image, give five guesses,
And you have five guesses to guess For one of them to be correct
The human annotation is a question often comes up So how do you know the ground truth? Human level performance is 5.1 percent accuracy, on this task.
But, the way the annotation for ImageNet is performed, is There's a Google search, where you pull the images
Already labeled for you, and then the annotation that Mechanical Turk, other humans perform
Is just binary: Is this a cat, or not a cat So they're not tasked with performing The very high-resolution semantic labeling of the image.
Okay. So, through, from 2012 with AlexNet, to today
And the big transition in 2018 of the ImageNet challenge Leaving Stanford and going to Kaggle.
It's sort of a monumental step Because in 2015 with the ResNet network Was the first time
That the human level performance was exceeded And I think this is, a very important
Map of where deep learning is. For particularly what I would argue is a toy example
Despite the fact that it's 14 million images So we're developing state-of-the-art techniques here
And in next stage, as we are now exceeding Human level performance, on this task Is how to take these methods into the real world.
To perform scene perception, to perform driver state perception.
In 2016, and 2017 CUImage and SENnet has a very unique new addition
To the previous formulations that has achieved An accuracy of 2.2 percent error
2.25 percent error on the ImageNet classification challenge. It's an incredible result.
Ok, so you have this image classification architecture That takes in a single image, and produces convolution
And takes it through pooling convolution, and at the end Fully connected layers and performs
A classification task, or regression task. And you can swap out that layer to perform any kind of other task
Including with recurrent neural networks of Image captioning, and so on... Or localization of bounding boxes
Or, you can do fully convolutional networks Which we'll talk about on Thursday
Which is when you take an image as an input, And produce an image as an output.
But where the output image, in this case,is a segmentation. Is, where a color indicates what the object is.
The category of the object. So it's pixel level segmentation, Every single pixel in the image is assigned,
A class, a category, where that pixel belongs to. This is, the kind of task,
That's overlaid on top of other sensory information, Coming for the car in order to
Perceive the external environment You can continue to extract information
From images in this way To produce image to image mapping For example to colorize images
And take from grayscale images to color images
Or you can use that kind of heat map information To localize objects in the image So as opposed to just classifying that this is an image of a cow
R-CNN, Fast and Faster R-CNN, And a lot of other localization networks
Allow you to propose different candidates For where exactly the cow is located in this image
And thereby being able to perform object detection Not just object classification.
In 2017 there has been a lot of cool applications Of these architectures
One of which is background removal Again mapping from image to image Ability to remove background from selfies
Of humans or human-like pictures of faces
The reference is, with some incredible animations, Are in the bottom of the slide,
And the slides are now available online
Pix2pixHD There's been a lot of work in GANs
In Generative Adversarial Networks In particular in driving
GANs have been used to generate examples That generate examples from source data
Whether that's from raw data Or in this case with pix2pixHD Is taking coarse semantic labeling of the images
Pixel level, and producing Photorealistic, high-definition images of the forward roadway
This is an exciting possibility For being able to generate A variety of cases for self-driving cars
For autonomous vehicles to be able to learn To generate, to augment the data And be able to change the way different roads look
Road conditions, To change the way vehicles look cyclists, pedestrians.
Then we can move on to recurrent neural networks Everything I've talked about was one-to-one mapping
From image to image, or image to number Recurrent neural networks work with sequences
We can use sequences to generate handwriting
To generate text captions from an image Based on the localization, as the various detections, in that image.
We can provide video description generation So taking a video
And combining convolutional neural networks With recurrent neural networks Using convolutional neural networks to extract features
Frame to frame And using those extracted features To input into our RDRN ends, to then generate labeling
A description of what's going on in the video A lot of exciting approaches for autonomous systems
Especially in drones Where the time to make a decision is short
Same with the RC car traveling 30 miles an hour Attentional mechanisms For steering the attention of the network
Have been very popular For the localization tasks and for just saving
How much interpretation of the image How many pixels need to be considered In the classification task
So we can steer, we can model the way A human being looks around an image
To interpret it And use the network to do the same. And we can use that kind of steering
To draw images, as well.
Finally the big breakthroughs in 2017 Came from this Pong to Pixels
The reinforcement learning using sensory data Raw sensory data And use reinforcement learning methods
Deep are all methods of which we'll talk about on Wednesday I'm really excited about... The underlying methodology of deep traffic, and deep crash
Is using neural networks as the approximators
Inside reinforcement learning approaches. So AlphaGo in 2016, have achieved
a monumental task. That when I first started in artificial intelligence Was told to me is impossible for a system to accomplish
Which is to win at the game of Go Against the top human player in the world.
However that method was trained on human expert positions The Alphago system, was trained on previous games
Played by human experts. And in an incredible accomplishment
AlphaGo Zero in 2017 Was able to beat AlphaGo,
And many of it's variants By playing itself, from zero information
So no knowledge of human experts No games, no training data very little human input
And what more, it was able to generate Moves, that were surprising to human experts.
I think it's Einstein that said that intelligence That the key mark of intelligence is imagination.
I think it's beautiful to see an artificial intelligence system Come up with something that surprises human experts
Truly surprises... For the gambling junkies, DeepStack
And a few other variants Have been used in 2017 to win a heads-up poker.
Again another incredible result! I was always told an artificial intelligence would be impossible
For Deep, For any machine learning method to achieve And was able to beat a professional player
And several competitors have come along since We're yet to be able to beat
To win, in a tournament setting, so multiple players For those unfamiliar heads-up poker is one-on-one.
It's a much much smaller, easier space to solve. There's a lot more human-to-human dynamics going on,
For when there's multiple players. But that's the task for 2018
And the drawbacks! It's one of my favorite videos I show it often, of Coast runners.
For these deep reinforcement learning approaches The learning of the reward function
The definition of the reward function Controls how the actual system behaves
And this will come... This would be extremely important for us, with autonomous vehicles
Here the boat is tasked with Gaining the highest number of points,
And it figures out that it does not need to race, Which is the whole point of the game, In order to gain points
But instead, pick up green circles That regenerate themselves, over and over.
This is the... The counterintuitive behavior of a system
That would not be expected When you first designed the reward function
And this is a very formal simple system Nevertheless Is extremely difficult to come up with a reward function
That makes it operate in the way you expect it to operate Very applicable for autonomous vehicles
Of course in the perception side As I and mentioned with the ostrich and the dog A little bit of noise, with 99.6 percent confidence
We can predict That the noise up top is a robbing, a cheetah, Armadillo, lesser Panda...
These are outputs from actual state-of-the-art neural networks
Taking in the noise, and producing a confident prediction It should build our intuition, to understand that we don't
That the visual characteristics, The spatial characteristics of an image
Did not necessarily convey the level of hierarchy Necessary to function in this world.
In a similar way, with a dog and the ostrich And everything and an ostrich Network confidently, with a little bit of noise
Can make the wrong prediction Thinking that school bus, is an ostrich And a speaker is an ostrich
They're easily fooled But not really... Because they perform the task that they were trained to do, well
So we have to make sure we keep our intuition
Optimized to the way machines learn Not the way humans have learned
Over the 540 million years of data That we've gained Through developing the eye through evolution
The current challenges we're taking on First: Transfer learning There's a lot of success in transfer learning
Between domains that are very close to each other So, image classification from one domain to the next.
There's a lot of value in forming representations Of the way scenes look, in order Natural scenes look,
In order to do scene segmentation The driving case, for example. But we're not able to do any bigger leaps,
In the way it would perform transfer learning The biggest challenge for deep learning Is to generalize
Generalize across domains. It lacks the ability to reason, In the way that we've defined understanding previously
Which is the ability to turn complex information Into simple useful information.
Convert domain specific, Complicated sensory information.
That doesn't relate to the initial training set. That's the open challenge for deep learning
Train on very little data, and then go and reason, And operate in the real world.
Right now, you'll know, it's very inefficient They require big data
They require supervised data Which means they need human. Cost a human input
They're not fully automated, Despite the fact that the feature learning Incredibly the big breakthrough
Feature learning is performed automatically, You still have to do a lot of design, Of the actual architecture of the network
And all the different hyper parameter tuning needs to be performed. Human input
Perhaps a little bit more educated human input, A former PhD students, postdocs faculty
Is required to tune these hyper parameters. But nevertheless, human input is still necessary.
They cannot be left alone. For the most part...
The reward. Defining the reward As we saw with coast run Is extremely difficult For systems that operate in the real world
Transparency Quite possibly it's not an important one But neural networks, currently, are a black box.
For the most part. They're not able to accept Through a few successful visualization methods
That visualize different aspects of the activations They're not able to reveal, to us humans
Why they work, or where they fail And this is a philosophical question,
For autonomous vehicles, That we may not care as human beings If a system works well enough.
But I would argue that, it will be a long time, Before systems work well enough,
Or we don't care. We'll care, And we'll have to work together with these systems
And that's where transparency, communication, ...collaboration is critical. Edge cases. It's all about edge cases.
In robotics, in autonomous vehicles... The 99.9 percent of driving is really boring,
It's the same. Especially highway driving. Traffic driving. It's the same.
The obstacle avoidance, the car following the lanes... ...centering. All these problems are trivial.
It's the edge cases. Trillions of edge cases, They need to be generalised over,
On a very small amount of training data.
So again I return to: Why deep learning?
I mentioned a bunch of challenges, And this is an opportunity! It's an opportunity, to come up with techniques,
that operate successfully in this world. So I hope the competitions we present in this class,
And the autonomous vehicle domain, Will give you some insight, and an opportunity to apply...
In some of these cases are open research problems, Wth semantic segmentation of external perception,
With control of the vehicle, and deep traffic And, with deep crash,
Of control of the vehicle, and under actuated High speed conditions, and the driver state perception.
So with that, I wanted to introduce deep learning to you today, Before we get to the fun tomorrow of autonomous vehicles.
So, I would like to thank: Nvidia, Google, Autoliv, Toyota. And, at the risk of setting off people's phones:
Amazon Alexa, Auto... But, truly, I would like to say, that I've been humbled
Over the past year, by the thousands of messages were received By the attention. By the 18,000 competition entries.
By the many people across the world, not just here at MIT, That are brilliant, that I got a chance to interact with.
And I hope we go bigger, And do some impressive stuff in 2018. Thank you very much, and tomorrow is self-driving!

----------

-----
--22-- 

-----
Date: 2017.12.24
Link:  [# MIT Sloan: Intro to Machine Learning (in 360/VR)](https://www.youtube.com/watch?v=s3MuSOl1Rog)
Transcription: 

the video you're watching now is in 360 resolution is not great but we wanted to
try something different so if you're on a desktop or laptop you can pan around with your mouse or if you're in a phone
or tablet you should be able to just move your device to look around of course it's best viewed with a VR
headset the video that follows is a guest lecture on machine learning that I gave an MIT Sloan course on the business
of artificial intelligence the lecture is non technical and intended to build intuition about these ideas amongst the
business students in the audience the room was a half circle so we thought why not film the lecture in 360 we recorded
a screencast of the slides and pasted it into the video so that the slides are more crisp let me know what you think
and remember it's an experiment so this course is talking about the broad
Course Overview
context the impact of artificial intelligence the global there's global which is the global impact of artificial
intelligence says the business which is when you have to take these fun research ideas that I'll talk about today a lot
of them are cool on toy examples when you bring them to reality you face real challenges which is what I would like to
really highlight today that's the business part when you want to make real
impact when you Miller make these technologies of reality so I'll talk about how amazing the technology is for
a nerd like me but also talk about how when you take that into the real world
what are the challenges you face so machine learning which is the technology
at the core of artificial intelligence will talk about the promise the
excitement that I feel about it the limitations will bring it down a little bit what are the real capabilities the
technology where for the first time really as a civilization exploring the
meaning of intelligence it is if you pause for a second and just think you
know maybe of many of you want to make money out of this technology many of you want to save lives help people but also
in the philosophical level we get to explore what makes us human so while I'll talk about
the low-level technologies also think about the incredible opportunity here we
get to almost psychoanalyze ourselves by trying to build versions of ourselves in
the machine alright so here's the open question how powerful is artificial
How Powerful is Artificial Intelligence
intelligence how powerful is machine learning that lies at the core of artificial intelligence is it simply a
helpful tool a special-purpose tool to help you solve simple problems if your which is what it currently is currently
machine learning artificial intelligence is a way if you can formally define the
problem you can formally define the tools you're working with you can formally define the utility function where you want to achieve with those
tools as long as you can define those things we can come up with algorithms that can solve them as long as you have
the right kind of data which is all I'll talk about data is key and the question
is into the future can we break past
this very narrow definition of what machine learning can give us which is solve specific problems to something
bigger to where we approach the general intelligence that we exhibit as human beings when we're born we know nothing
and we learn quickly from very little data the right answer is we don't know
Supervised Learning
we don't know what are the limitations of technology what kind of machine learning are there there are several
flavors the first two is what's really the first is what's achieved success
today supervised learning what I'm showing here on the left of the slide is the teachers is the data that is fed to
the system and on the right is the students which is the system itself for machine learning so they're supervised
learning whenever everybody talks about machine learning today what for the most part they're referred to supervised
learning which means every single piece of data that is used to train the model is seen by human eyes and those human
eyes with an accompanying brain label that data in a way that makes it useful to the
machine this is this is critical because that's one the blue box the human is
really costly so whenever every single piece of data that needs to be that's used to train the machine needs to be
seen by a human you need to pay for that human and second you're limited to just the the time there's the amount of data
necessary to label what it means to exist in this world is humongous
Augmented Learning
augmented supervised learning is when you get machine to really to help you a little bit there's a few tricks there
but still it's still only tricks it's still the human is at the core of it and the promise of future research that
we're pursuing that I'm pursuing and perhaps in the applications if we get to discuss or some of the speakers here get
to discuss they're pursuing in semi-supervised and reinforcement learning where the human starts to play
a smaller and smaller role in how much they get to annotate they have to annotate the data and the dream of the
sort of Wizards of the dark arts of deep learning are all excited about
unsupervised learning that has very few actual successes in application in the
real world today but it is the idea that you can build a machine that doesn't
require a human teacher a human being to teach it anything is fills us artificial
intelligence researchers with excitement there's a theme here machine learning is
Machine Learning
really simple the learning system in the middle there's a training stage where
you teach it something all you need is some data input data and you need to
teach it the correct output for that input data so you have to have a lot of
pairs of input data and correct output there'll be a theme of cats throughout
this presentation so if you want to teach in a system difference being a cat
and a dog you need a lot of images of cats you need to tell it that this is a cat this bounding box here and the images of
cat you have to give it a lot of images of dogs and tell it ok for this in this
in these pictures they're dogs and then then there's a spelling mistake on the
second stage is the testing stage when you actually give it new input it has never seen before and you hope that it
has given for cat versus dog enough data to guess is this new image that I've
never seen before a cat or a dog now the
one of the open questions do you want to keep in mind is what in this world can
we not model in this way what activity what task what goal my I offer to you
that there's nothing you can't model in this way so let's think about what in
terms of machine learning can be so it
starts small what can be modeled in this way first on the bottom of the slide left is one-to-one mapping where the
input is an image of a cat and the output is a is a label that says cat or dog you can also do one-to-many where
the image the input is a image of a cat and the output is a story about that cat
captioning of the image you can first of all you can do the other way many to one
mapping where you give it a story about a cat and it generates an image there's
many to many this is Google Translate we translate a sentence from one language to another and there's various flavors of that
again same theme here input data provided with correct output and then
let it go into the wild where it runs on
input data hasn't seen before to provide guesses and it's as simple as this
whatever you can come into one of the following four things numbers vector of numbers so bunch of
numbers sequence of numbers or the temporal dynamics matters so like audio
video where the sequence the ordering matters or sequence of vector numbers
just a bunch of numbers if you can convert it into numbers and I propose to you that there's nothing you can't
convert it to numbers if you can convert it to numbers you can have a system
learn to do it and the same thing with the output generate numbers vectors and numbers sequence the numbers or sequence
of vectors and numbers first
Questions
is there any questions at this point well we have a lot of fun slides to get
through but I'll pause every once in a while to make sure we're on the same page here so what kind of input are we
talking about just to fly through it images so faces or medical applications for looking looking at scans of
different parts of the body to determine if they're to diagnose any kind of medical conditions text so conversations
your texts article blog posts for sentiment analysis question and answering so you ask it a question where
the output you hope is answers sound so voice recognition any kind of anything
you could tell from audio time series data so financial data stock market can
use it to predict anything you want about the stock market including whether
to buy or sell I think if you're curious doesn't work quite well as a machine
learning application physical world so cars or any kind of object any kind of
robot that exists in this world so location of where I am location of where
other things are the actions of others that could be all the input all of it can be converted to numbers and the
correct output same thing classification a bunch of numbers classification is saying is it's a cat or dog regression
is saying to what degree I turn the steering wheel sequence is generating
audio generating video generating stories captioning text images generate anything you could
think of as numbers and at the core of it is a bunch of data agnostic machine
learning algorithms there's traditional ones nearest neighbors Navy base support machine support vector machines a lot of them
are limited in all describe how and then
there's neural networks there's nothing special and new about neural networks
and I'll describe exactly the very subtle thing that is powerful that's
always been there all along and certain things have now been able to unlock that
power about neural networks but it's still just the flavor of a machine learning algorithm and the inspiration
for neural networks as Jonathan showed last time is our human brain as perhaps why the media perhaps why the hype is
captivated by the idea of neural networks is because you immediately jump to this feeling like because there's
this mysterious structure to them that scientists don't understand artificial neural networks I'm referring
to and the biological ones we don't understand them and the similarity
captivates our minds that we think well this approach is perhaps as limited as our as limitless as our own human mind
but the comparison ends there in fact the artificial neuron their artificial
Artificial Neuron
neural networks are much simpler computational units at the core of
everything is this neuron if this is a computational unit that does a very two
very simple operations on the left side it takes a set of numbers as inputs it
applies weights to those inputs sums them together applies a little bias and
provides an output somewhere between 0 and 1 so you can think of it as
computational entity that gets excited when it sees certain inputs and gets
totally turned off when it gets other kinds of inputs so maybe this neuron
with a zero with a point seven point six one point four weights it gets really
excited when it sees pictures of cats and totally doesn't care about dogs some
of us are like that so that's the job of this neuron it's to detect cats now what
Building an Artificial Neuron
the way you build an artificial neural network the way you release the power
that I'll talk about in the following slides about the applications what could
be achieved it's just stacking a bunch of these together think about it this is this is
a extremely simple computational unit there so you need to sort of pause
whenever we talk about the following slides and think that there there's a
few slides that I'll show that say neural networks are amazing now I want you to think back to this slide that
everything is built on top of these really simple addition operations with
the a simple nonlinear function applied at the end just a tiny math operation we
stack them together within a feed-forward way so there's a bunch of layers and when people talk about deep
neural networks it means there's a bunch of those layers and then there's
recurrent neural networks that are also a special flavor that's able to have memory so as opposed to just pushing
input into output directly it's also able to do stuff on the inside in a loop where it remembers things this is useful
for natural language processing for audio processing whenever the sequence is not the length of the sequence is not
defined okay slide number one in terms of neural networks are amazing
Neural Networks
this is this is perhaps for the math nerds but also I want you to use your
imagination there's a universality to neural networks means that this simple
computational unit on the left is an input on the right is the output of this network with just a single hidden layer
it's called a hidden layer because it sits there in the middle of the input and the output layers a single hidden
layer with some number of notes can represent any function any function that
means anything you want to build in this world everyone in this room can be
represented with a neural network with a single hidden layer so the power and
this is just one hidden layer the power of these things is limitless the problem of course is how do you find the network
so how do you build a network that as as
clever as many of the people in this room but the fact that you can build
such a network is incredible it's amazing I want you to think about that and the way you train a network so it's
born as a blank slate some random weights assigned to the edges again a
network is represented the numbers at the core the parameters of the core of this network are the numbers on each of
those arrows each of those edges and you start knowing nothing this is a baby
Network and the way you teach it something unfortunately currently as I
said in a supervised learning mechanism you have to give it pairs of input and output you have to give it pictures of
cats and labels on those pictures saying that they're cats and the basic
fundamental operation of learning is when
you compute the measure of an error and
you back propagate it to the network what I mean everything is easier with cats I
apologize I apologize too many cats and
so the input here is a cat and the neural network we trained
it's just guessing it doesn't know say I don't know it's guessing cat well it
happens to be right so we have to this is the measure of error yes you got a
right and you have to back propagate that error you have to reward the network for doing a good job and all you
do what I mean by a reward there's weights on each of those edges and so the the node that individual neurons
that were responsible that back to that cat neuron that cat neuron needs to be rewarded for seeing the cat so you just
increase the weights on the neurons that were associated with producing the correct answer now you give it a picture
of a dog and the neural networks is cat well that's an incorrect answer so no
there's a high error needs to be back propagated to the network so the weights are responsible with classifying this
out of this picture as a cat need to be punished they need to be decreased simple and you
just repeat this process over and over this is what we do as kids when we're first learning i I'm you know for the
most part that we have to we're also supervised learning machines in the sense that we have our parents
and we have the environment the world that teaches about what's correct and
what's incorrect and we back propagate this error and reward through our brain to learn the problem is as human beings
we don't need too many examples and I'll talk about some of the drawbacks of these approaches we don't need too many
examples you fall off your bike once or twice and you learn how to ride the bike unfortunately neural networks needs need
tens of thousands of times when they fall off the bike in order to learn how to not do it that's one of the
limitation and one key thing I didn't mention here is when we refer to input data it's when
Representation
we refer to input data we usually refer to sensory data raw data we have to
represent that data in some clever way in some deeply clever way where we can
reason about it whether it's in our brains or in the neural network in a
very simple example here to illustrate what representation of data matters so
the way you represent the data can make the discrimination of one class from
another a cat versus dog either incredibly difficult or incredibly
simple here is a visualization of the same kind of data and Cartesian coordinates and polar coordinates on the
right you can just draw a simple line to separate the two what you want is a
system that's able to learn the polar coordinate representation versus the
Cartesian representation automatically and this is where deep learning has
stepped in and revealed the incredible power of this approach which deep
learning is the smallest circle there is a type of representational learning
machine learning is the bigger second to the biggest up so this class is about the biggest circle AI includes robotics
includes all the fun things that are built on learning and I'll discuss while machine learning I think will close this
entire circle into one but for now AI is the biggest circle then a subset of that
is machine learning and a smaller subset of that is representation learning so
deep learning is not only able to say given a few examples of cats and dogs to
discriminate between a cat and a dog it's able to represent what it means to
be a cat it's so it's able to automatically determine what are the
fundamental units at the low level and the high level talking about this very Plato what it
means to represent a cat from the whiskers to the high level shape of the
head to the the fuzziness and the deformable aspects of the cat not a cat
expert but I hear this these are the features of a cat verses that are essential to discriminate between a cat
and a dog learning those features as opposed to having to have experts this
is the drawback of systems that Jonathan talked about from the 80s and 90s where you have to bring in experts for any
specific domain that you try to solve you had to have them encode that information deep learning this is this
is simply the only big difference between deep learning and other methods
is that it learns the representation for you it learns what it means to be a cat nobody has to step in and help it figure
out what what that cats have whiskers and dogs don't what does this mean the
fact that it can learn these features these whisker features is as opposed to
having five or ten or a hundred or five hundred features that are encoded by brilliant engineers with PhDs it can
find hundreds of thousands millions of features automatically hundreds of
millions of features so stuff that that can't be put into words are described in
fact it's one of the limitations the neural networks is they find so many fundamental things about what it means
to be a cat that you can't visualize what it really knows it just seems to know stuff and it finds that stuff
automatically what what does this mean it's the critical thing here is because
it's able to automatically learn those hundreds of millions of features it's able to utilize data it doesn't start
the diminishing returns don't hit on until what we don't know when they hit
the point is with the classical machine learning algorithms you start hitting a wall when you have tens of thousands of
images of cats with deep learning you get better better with more data neural networks
General Intelligence
are amazing slide two here's here's a game a simple arcade game where there's
two paddles the bouncing a ball back and forth okay great you can figure out an artificial
intelligence agent that can play this game it can and not even that well just kind of it kind of learns to do all
right and eventually win here's the
fascinating thing with deep learning as opposed to encoding the position of the
paddles the position of the ball having an expert in this game as many come in
and encode the physics of this game the input to the neural network is the raw
pixels of the game so it's learning in
the following way you give it an evolution of the game you give it a
bunch of pixels pixels are you know images are built up of pixels they're
just numbers from 0 to 256 so there's this array of numbers that represent
each image and then you give it several tens of thousands of images they're represented game so you have the stack
of pixels and stack of images that represents a game and the only thing you
know this giant stack of numbers the only thing he knows at the end you won or lost that's it so based on that you
have to figure out how to play the game you know nothing about games you know nothing about colors or balls or paddles
or winning or anything that's it so this is it's why is this amazing that it even
works and it works too it wins it's amazing because that's exactly what we do as human beings this is general
intelligence so I need you to pause and think about this well we'll talk about
special intelligence - the usefulness and it ok there's cool tricks here and there that we can do to get you an edge
on your high-frequency trading system but this is general intelligence general
intelligence is the same intelligence we use as babies when we're born what we get is an input sensory input of image
sensory input right now all of us most of us are seeing hearing feeling with
touch and that's the only input we get we know nothing and with that input we have to learn something
nobody is pre teaching us stuff and this is an example of that a trivial example
but one of the first examples where this is truly working I sorry to linger on
this but it's a fundamental fact the fact that we have systems that and now
outperform human beings in these simple arcade games is incredible this is the research side of things but
let me step back these again the takeaways that previous slide is why I
think machine learning is limitless in the future currently it's limited again
the representation of the data matters and if you want to have impact we
currently can only tackle the small problems what are those problems image
recognition we can classify given the entire image of a leopard of a boat of a
mite with pretty good accuracy of what's
in that image that's image classification what else we can find exactly where in that image
each individual object is that's called image segmentation again the same the
process is the same as the learning system in the middle and neural network
as long as you give it a set of numbers as input and the correct set of labels
as output it learns to do that for data hasn't seen the best let me pause a
second and maybe if you have any questions does anyone have any questions about
the techniques of neural networks yes
Data Representation
so that's a great question and in a couple of slides I'll get to it exactly
so the the the data representation I'll
elaborate in a little bit but loosely the data representation is for a neural network is in the weights of each of
those arrows that connecting your ons that's where the representation is so
I'll show to really clarify that example of what that means the Cartesian versus
polar coordinates is just the visual very simple visualization of the concept
but you want to be able to represent the data in an arbitrary way where there's
no limits to the representation it could be highly nonlinear highly complex any
other questions
Pattern Recognition
so I have a couple of slides almost asking this questions because there's no good answers but one could argue and I
think somebody in last class brought up that you know is machine learning just pattern recognition it's possible that
reasoning thinking is just pattern
recognition and I'll describe sort of an intuition behind that so we tend to
respect thinking a lot because we've recently as human beings learned to do
it in our evolutionary time we think that it's somehow special from for
example perception we've had visual perception for several orders of magnitude longer in our evolution
evolution as a living species we've started to learn to reason I think about
a hundred thousand years ago so we think it's somehow special from the same kind
of mechanism we use for seeing things perhaps it's exactly the same thing it's so perception is pattern recognition
perhaps reasoning is just a few more layers of that that's the hope that's an
open question it's
yes that's a great question there there's been very few breakthroughs in
your networks since through the AI winters that we discussed through a lot
of excitement in spurts and even recently there's been a very few
algorithmic innovations the big gains came from compute so improvements in GPU
and better faster computers the you can't underestimate the power of
community so the ability to share code and the internet ability to communicate
together through the internet and work on code together and then digitization of data so like ability to have large datasets
easily accessible and downloadable all of those little things but I think it in
terms of the future of deep learning and machine learning it it all rides on
compute I think meaning continued bigger and faster computers that doesn't
necessarily mean Moore's law in making small and smaller chips it means getting clever in different directions massive
parallelization coming up with ways to do super efficient power efficient
implementations and neural networks and so on so let me just fly through a few
Machine Learning Examples
examples of what we can do with machine learning just to give you a flavor I think in future lectures as possible
we'll discuss different speakers the different specific applications really
dig into those so we can as opposed to working with just images you can work with videos and segments those I
mentioned image segmentation we do video segmentation so through video segments the different parts of a scene that's
useful to a particular application here and driving you can segment the road from cars and
vegetation and lane markings you can
also a subtle but important point these
very small piece of information that we just we know are important like there is a red light like I have to stop I have
to slow down so hard questions so the
How to Detect Traffic Lights
question was how do you detect the traffic light and lights so how do we do
it as human beings first of all let's start there the way we do it is by the
knowledge we'll bring to the table so we we know what it means to be on the road there's a lot of the huge network of
knowledge that you come with and so that makes the perception problem much easier this is pure perception you take an
image and you separate different parts based purely on tiny patterns of pixels
so first it finds all the edges and it learns that traffic lights have certain
kinds of edges around them and then zoom out a little bit they have a certain
collection of edges that make up this black rectangle type shape so it's all
about shapes it kind of build up knowing this this shape structure of things but
it's a purely perception problem and one of the things that argue is that if it's purely a perception approach and you
bring no knowledge to the table about the physics of the world the three-dimensional physics and the temporal dynamics that you are now going
to be able to successfully achieve near 100% accuracy and some of the
so that's exactly the right question is you for all of these things think about
how you as a human being would solve these problems and what is lacking in the machine learning approach what data
is lacking in the machine learning approach in order to achieve the same kind of results the same kind of
reasoning required to that you would use as a human so there is also image
detection image detection which means the subtle but important point the stuff
I've mentioned before image classification is given them image of a cat you find the cat noting the side you
don't find the cat you say this images of a cat or not and then detection or localization is when you actually find
where in the image that is that problem is much harder but also doable with
machine learning with with deep neural networks now as I said inputs outputs
can be anything the input could be a video the output could be video and you could do anything you want with these
videos you can colorize the video you can add take an old black-and-white film
and produce color images again in terms
of being out in terms of having an impact in the world using these applications you have to think this is a
cool demonstration but how well does it actually work in the real world translation whether that's from text to
text or image to image you can translate here dark-chocolate from one language to
another it's class global business of artificial intelligence there's a
How to Generate Text
reference below there you can go and generate your own text you can generate the writing of the act of generating
handwriting so you can type in some text and given different styles that it learns from other handwriting samples it
can generate any kind of text using handwriting again the input is language the output
is a sequence of writing of pen movements on the screen you can complete
sentences this is kind of a fun one where if you start
so you can generate language you can generate language where you start you feed the system some input first so in
black there's says life is and then have the neural network complete those sentences life is about kids life about
life is about the weather there's a lot of knowledge here I think being conveyed and you can start
the sentence with the meaning of life is the meaning of life is literary recognition true for us academics or the
meaning of life is the tradition of ancient human production also true but
these are all generated by a computer you can also caption this has been become very popular recently is caption
generation given us input as an image the output is a set of text the cap captures the content of the image you
find the different objects in the in the image that's a perception problem and
once you find the different objects you stitch them together in a sentence that makes sense you generate a bunch of sentences and
classify which sentence is the most likely to fit this this image and you
EndtoEnd Approach
can so certainly in the I tried to avoid mentioning to driving too much because
it is my field with this what I'm excited about what then the moment I
start talking about driving it'll all be about driving so but I should mention of course the deep learning is critical to
driving applications for the both the perception and what is really exciting to us now is the end-to-end the
end-to-end approach so whenever you say end-to-end in any application what that means is you start from the very raw
inputs that the system gets and you produce the very final output that's
expected of the system so supposed to in the self-driving car case as opposed to breaking a car down into each individual
components of perception localization mapping control planning and just taking
the whole stack and just ignoring all the super complex problems in the middle
just taking the external scene as input and as output produced steering and acceleration of braking commands
and so in this way taking this input is the image of the external world in this
case in a Tesla we can generate steering commands for the car again input a bunch
of numbers that that's just images I'll put a single number that gives you the
steering of the of the car okay
What Cant We Do
so let's step back for a second and think about what can't we do with
machine learning we talked we talked about you can map numbers to numbers let's think about what we can't do this
at the core of artificial intelligence in terms of making an impact on this world is robotics so what can't we solve
in robotics and artificial intelligence with a machine learning approach and let's break down what artificial
intelligence means here's a stack starting at the very top is the environment the world you operate in
their sensors that sense that world there is feature extraction and learning from that data and there's some
reasoning planning and effectors are the ways you manipulate the world what can't
we learn in this way so we've had a lot of success as Jonathan talked about in
the history of AI with formal tasks playing games solving puzzles recently
we're having a lot of breakthroughs with medical diagnosis we're still we're
still struggling but are very excited about in the robotic space with more
mundane tasks of walking of basic perception of natural language written
and spoken and then there is the human tasks which are perhaps completely out
of reach of this pipeline at the moment is cognition imagination suggests a
subjective experience so high-level reasoning not just common sense or high level human level reasoning so let's fly
The Pipeline
through this pipeline they're sensors cameras lidar audio
there is communication that flies to the air or wired or wireless or wired I am
you measuring the movement of things so that's the way you think about it that's
the way assuming beings and as any kind of system that you design you measure the world you don't just get an API to
the world you need to somehow measure aspects of this world so that's how you
get the data so that's how you convert the world into data you can play with and once you have the data this is the
representation side you have to convert that raw data of raw pixels of raw audio raw lidar data you have to convert that
into data that's useful for the intelligence system for the learning
system to to use to discriminate between one thing and another for vision that's
The Machine Learning
finding edges corners object parts and entire objects there's the machine learning that I'll
talk about that I've talked about there's different kinds of mapping of the representation that you've learned
to an actual outputs there is once you have this so you have this idea of and
this goes to maybe a little bit of Simon's question is reasoning this is something that's out of reach or machine
learning at the moment this is going to your question then we can we can build a
world-class machine learning system for taking an image and classifying that it's a duck I wonder if this will work
wake you up so we could take this is
well studied exceptionally well studied problem could take audio sample of a doc
and tell that it's a duck in fact what species of bird it's
incredible how much research there is in bird species classification and you can look at video and we could tell that we
can do extra recognition that it's just swimming but we can't do with learning
now is reason that if it looks like a duck it swims like a duck and quacks
like a duck is very likely to be a duck this is the reasoning problem this is
the task that I personally am obsessed with and that I hope that machine
learning can close and then there is the planning action and the effectors
so this is another place where machine
learning has not had many strides there's mechanical issues here that incredibly difficult the degrees of
freedom with all the actuators involved with all the just just the ability to
localize every party yourself in this dynamic space where things are
constantly changing when there's degrees of uncertainty when there's noise just that basic problem is exceptionally
difficult
The Open Questions
let me just pose this question we talked about how machine what machine learning can do with the cats and the duck we
could do that given a representation it could predict what's in the image but one of the open questions is and deep
learning has been able to do the feature extraction the representation learning this is the big breakthrough that
everybody's excited about but can also reason these are the open questions in a
reason can it do the planning in action and as human beings do can it close the
loop entirely from sensors to effectors so learn not only the brain but the way
you sense the world and the way you affect the world
Pong
it the so the question was about the pong game thank you talk to it a little
longer it it doesn't get punished when it doesn't detect the ball this is the beautiful thing it gets punished only at
the very end of the game for losing the game and gets her water for winning the game so it knows nothing about that ball
and it learns about that ball that's something you really sit and think about
has like how do as human beings imagine if you're playing with a physical ball how do you learn what a ball is you you
get hurt by it you like squeeze and you throw it you feel the dynamics of it the physics of it and nobody tells you about
what a ball is you're just using the raw sensor input we take you for granted
and maybe this is what I can end on is this is what's something Jonathan
brought up is we take the simplicity of this task for granted because we've been
we've had eyes we broadly speaking as
living species on planet Earth there's eyes have been evolved for 540 million
years so we have 540 million years of data we've been walking for close to
that bipedal mammals we have been thinking only very recently so a hundred
thousand years versus a hundred million years and that's why we can't some of
The Mars Paradox
these problems that we're trying to solve you can't take for granted how actually difficult they are so for
example this is the marvex paradox the Jonathan brought up is that the easy problems are hard the things would think
are easy actually really hard this is state-of-the-art robot on the right playing soccer and that was a
state-of-the-art human on the left playing soccer and I'll give it a second the question
Neural Networks vs Natural Selection
was you know there's a fundamental difference between the way with train your networks and the way we've trained biological neural networks for evolution
by discarding through natural selection a bunch of the the the the neural
networks that didn't work so well that's so first of all the process of evolution is I think not well understood
meaning sorry the raw huh says he careful here the role of evolution in
the evolution of our cognition of our intelligence I don't know if that's so
this is an open question so maybe clarify this point his neural networks artificial neural networks are
fixed for the most part in size this is exactly right it's like a single human being that gets to learn we don't have
mechanisms of of modifying or revolving
those neural networks yet although you could think of researchers as doing
exactly that there you have grad students working on different neural networks and the ones that don't do a good job don't get
promoted and get a good you know there is a natural selection there but other than that it's a it's an open question
stay tuned and keep your head up because the future I believe is really promising
and the slides will be made available for sure
I think a lot of the explorations of what it means to build an intelligent
machine has been in sci-fi movies we're now beginning to actually make it a reality this is Space Odyssey to keep
with that theme in the previous lecture go ahead this is as opposed to the
dreamlike monolith view when the
astronaut is gazing out into the open sky at the stars we're going to look at the practice of AI today and how we go
if you're familiar with the movie when this new technology appeared before our eyes in we're full of excitement how we
transfer that into actual practical impact on our lives to quickly review
what we talked about last time we I presented the technology and asked the question of whether this technology
merely serves a special purpose to answer specific tasks that can be formalized or whether it can be through
through the process of transferring the knowledge learned on one domain be generalizable to where an intelligent
system that's trained in a small domain can be used to achieve general intelligent tasks like we do as human
beings the this is kind of a stack of artificial intelligence of going from
all the way up into the top of the environment the world the sensors sets the data the the
intelligence system the way it perceives this world then once you have this you convert the world into some numbers you
able to extract some representation of that world and this is where machine learning starts to come into play and
then there's the part where I rate I will raise it again today is can machine learning be doing the following steps to
that we can do very well as human beings is the reasoning step you know you can tell the difference in a cat and a dog but can you now start to reason about
what it means to be alive what it means to be a cat with living creature and what it means to be this kind of
physical object or this kind of physical object and take what's called common sense things we take for granted start
to construct models of the world through reasoning Descartes I think therefore I
am we want our neural networks to come up with that on their own and once
you do that action you'll go right back into the world you start acting in that
world so the question is can machine learning can this be learned from data or does do experts need to encode the
knowledge of reasoning the knowledge of actions the set of actions that's kind of the question open questions I raise
it continues throughout the talk today and so as we start to think about how
artificial intelligence especially machine learning as it realizes itself through robotics gets to impact the
world we start thinking about what are the easy problems what are the hard problems and it seems to us that vision
and movement walking is easy because we've been doing it for millions of years hundreds of millions of years and
thinking it's hard reasoning is hard I propose to you that it's perhaps because
we've only been doing it for a short time and so so think we're quite special because we're able to think so we have
to kind of question of what it's easy and what is hard because when we start to develop some of these systems and
what you start to realize that all these problems are equally hard so the problem of walking that we take for granted the
actuation and the physical the ability to recognize where you are in the
physical space the sense the world around you to deal deal with the
uncertainty of the perception problem and then so all of these robots by the
way this is for the most recent DARPA challenge which MIT was also part of and
so what what are these robots doing they they don't have any they only have
sparse communication with human beings on the periphery so most of the stuff
they have to do autonomously like get inside a car this is an MIT robot unfortunately that they have to get in
the car and the hardest tasks they have to get out of the car that's walking so
this kind of raises to you the very real aspect here you want to build
applications that actually work in the real world and that's the first challenge an opportunity here
than many of the technologies we talked about currently crumble under the the
reality of our world when we transfer
them from a small data set in the lab to the real world for the computer vision
is perhaps one of the best illustrations of this computer vision is the task as we talked about of interpreting images
and so when you there's been a lot of great accomplishments on interpreting images cats versus dogs now when you try
to create a system like the Tesla vehicle that I've often that we work
with and I always talk about is it's a
vision based robot right as radar for basic obstacle avoidance but most of the
understanding of the world comes from a single monocular camera now they've expanded the number of cameras but for
the most time there's been a hundred thousand vehicles driving on the roads today with a single essentially a single
webcam so when you start to do that you have to perform all of these extraction
of texture color optical flow so the the movement through time temporal dynamics of the images you have to construct
these patterns construct the understanding of objects and entities and how they interact and from that you
have to act in this world and that's all based on this computer vision system so it's no longer cats versus dogs it's
it's a huge detection of pedestrians or the wrong classification the wrong
detection is the difference between life and death so let's look at cats those
were things a little more comfortable so computer vision and I would like to illustrate to you why this is such a
hard task which we've talked about we've been doing it for 500 million years so we think it's easy computer vision is
actually incredible so all you're getting with your human eyes is you're getting essentially pixels in there's
light coming into your eyes and all you're getting is the reflection from the different surfaces in here of light
and there's perception they're sensors inside your eyes can burning that into numbers it's really
very similar to this numbers in this in the case of what we use with computers
RGB images or the individual pixels that are numbers from 0 to 255 so 256
possible numbers and there's just a bunch of them and that's all we get we get a collection of numbers where
they're spatially connected ones that are close together are part of the same object so cat-cat pixels are all
connected together that's the only thing we have to help us but the rest of it is just numbers intensity in hours and we
have to use those numbers to classify what's in the image and if you really
think about it this is a really difficult task all you get is these numbers how the heck are you supposed to
form a model of the world with which you can detect pedestrians with a with
really 99.99999% accuracy because these pedestrians are these cars are cyclists
in the car context or any kind of applications you're looking at even if your job is in the factory floor to
detect the the defective gummy bears they're flying past that like a hundred miles an hour
your task is you don't want that bad gummy bear to get by that your product and the the brand will be damaged
however serious are not serious your application is what you have to be you
have to have a computer vision system that deals with all of these aspects
viewpoint variation scale variation no matter the size of the object is still
the same object then no matter the viewpoint from which area you look at
that object is still the same object the lighting that moves with lighting consistent here because we're indoors
but when you're outdoors or you're moving the scene is moving the lighting
the complexity of the lighting variations is incredible from the illumination to just the movement of the
different objects in the scene I think
about you and this particular one it's
Twilight and the light is changing I think you know almost every time I Drive
there's one or two things that I see there really that I'm drawing like 200 million years in order
to be able to figure out it's not it's a guy who's open his car door and I can't see him but I can just see the light
doesn't look quite right on that side of the road and I'm yeah somehow I know I might in my mind it's a person but it
seems like a almost impossible problem for the machines to get right I will
argue that that the pure perception task is too hard that you come to the table
as human beings with all this huge amount of knowledge that you're not
actually interpreting all the complex lighting variations that you're seeing you actually know enough about the world
enough about your commute home enough about the way the kinds of things you
would see in this world about Boston about the way pedestrians move there's a certain light of day you bring all that
to the table that makes the perception task doable and that's one of the big missing pieces in the technology as I'll
talk about that's the open problem of machine learning it's how to bring all that knowledge
first of all build that knowledge and then bring that knowledge to the table as opposed to starting from scratch
every time and so Katz the promise gets
okay so the to me occlusion for most of the computer vision community this is
one of the biggest challenges and it really highlights how far we are from
being able to reason about this world occlusions are when what what an
inclusion is is when the objects you're trying to detect something about classify the object detect object the
object is blocked partially by another object in front of them this is
something you think it's trivial perhaps you don't even really think about it because we we reason a three-dimensional
way but the occlusion aspect is is makes makes perception incredibly difficult so
we have to design is think about this so this image is converted into numbers and we for the task of detecting is there a
cat in this image yes or no you have to be able to reason about this image with
object in the scene most of us are able to very easily detect if there's a cat in this image we're able to detect that
there is a cat in this image now think about this there's a single eye and there's an ear so you have to think
about what is it part of our brain that allows us to understand to suppose that
with some high degree of accuracy that there's a cat here in this picture I mean the degree of occlusion here is
immense and so I promise so this is for most of
you some of you will think this is in fact a monkey eating a banana but I
would venture to say that most of us are able to tell it's nevertheless a cat you
watch this for hours and so let me give you another this is kind of a paper
that's often cited our set of papers to illustrate how difficult computer vision
is how thin the line that we're walking
with all of these impressive results that we've been able to show recently in the machine learning community in this
case for deep neural networks are easily fooled paper the seminal paper at this
point shows that when you apply network trained on imagenet so basically on
detecting cats versus dogs or different categories in inside images if you're you can find an arbitrary number of
images that look like noise up in the top row where the algorithm used to
classify those images in the image net of cat versus dog is able to confidently
say with 99.6% accuracy or above that it's seeing a robin or a cheetah or an
armadillo or a panda you know in that noise so it's confidently saying given this
noise that that's obviously a robin so you have to realize that the kind of
this is patterns the kind of processes it's using to understand what's
containing the image is purely a collection of patterns that it has been able to extract from
other images that has been human annotated by humans and that perhaps is
very limiting to trying to create a system that's able to operate in the
real world this is a very sort of this is very clean illustration of that
concept and the same you can confidently predict and those images below where
there are strong patterns it's not even noise strong patterns that have nothing to do with the entities being detected
again confidently that same algorithm is able to see a penguin a starfish a baseball in the guitar in the in that
noise a more serious for people designing robots like myself in the on
the sensor side you can flip that and say I can take a image and I can distort
it with some very little amount of noise and if that if that noise is applied to
the image I can completely change the confident prediction about what's in that image so to explain what's being
shown so on the left and the column on the left and again here what's the the
same kind of neural network is able to predict accurately confidently that
there is a dog in that image but if we apply just a little bit of noise to that image to produce that image
imperceptible to our human eyes the difference between those two the same algorithm is is saying that there is
confidently in an ostrich in that image so another thing to really think about that noise can have such a significant
impact on the prediction of these algorithms this is really really quite
honestly out of all the things I'll say today and I'm aware of one of the biggest challenges of machine learning
being applied in the real world is robustness how much noise can you add
into the system before everything falls apart so how do you validate sensors so
say a car company has to produce a vehicle and it has sensors in that vehicle how do you know
that that those sensors will not start generating slight noise due to interference of various kinds and
because of that noise instead of seeing a pedestrian you will see nothing or the
opposite you'll see pedestrians everywhere so of course the most dangerous is when it will not see an
object and collide with it in the case of cars there's also spoofing which a lot of people as always with security people
are really concerned about and perhaps people here are really concerned about this issue I think this is a really
important issue but because you can apply noise and convince the system that you're seeing an ostrich when there is
in fact no ostrich you can do the same thing in a in an attacking way so you
can attack the sensors of a car and make it believe like with lidar spoofing so spoof lidar radar or ultrasonic sensors
to believe that you're seeing pedestrians when they're not there and the opposite to hide pedestrians make
pedestrians invisible to the sensor when they're in fact there so whenever you
have Indulgence systems operating in this world they become susceptible to
the fact that everything so much of the work is done in software and based on sensors so at any point in the chain if
there's a failure you have to be able to detect that failure and right now we have no mechanisms for automatically
detecting that failure so on the data side so one challenge is that we're
constantly dealing with is that we are
the algorithms in machine learning algorithms that we're using our need
labeled data and we have very little labeled data labeled data again is when
you have pairs of input data and the ground truth the the true label
annotation class that that image belongs to or concept and the it doesn't have to
be an image it could be any source of data it's a really costly process to do so because it's so costly we
rely every breakthrough we've had so far relies on that label data and because of
its cost we don't have much of it so all the problems that come from data can either be solved by having a lot more of
this data which I believe is most people believe it's too challenging it's too
challenging to have human beings annotate huge amounts of data or we have to develop algorithms that are able to
do something with the unlabeled data its the unsupervised semi-supervised sparsely supervised reinforcement
learning as we talked about last time I mention again here so one way you
understand something about data when you don't have labels is you reason about it
all you're given is a few facts when you're a baby your parents give you a few facts and you go into this world
with those facts and you grow your knowledge graph your knowledge base your understanding of the world from those
few facts we don't have a good method of doing that an automated unrestricted way
the inefficiency of our learners the machine learning algorithms I've talked about the neural networks need a lot of
examples of every single concept that they're given in order to learn anything about them thousands tens of thousands
of cats are needed to understand what the spatial patterns at every level the
representation of a cat the visual representation would cap we don't we can't do anything with a single example
there's a few approaches but nothing quite robust yet and we haven't come up
with a way this is also possible to make annotation this labeling process somehow
be very cheap so leveraging this is something being called human computation that term has fallen out of favor a
little bit one of my big passions is human computation is using something about our behavior something about what
we do in this world online or in the real world to annotate data automatically so for example as you
drive which is what we do everybody has to draw and we can collect data about you
driving in order to train self-driving vehicles to to to drive and that's a
free annotation so here are the annotated data sets we have the
supervised learning data sets there's many but these are ones some of the more famous ones from the very from
the toy data sets of M NIST - the large broad arbitrary categories
of images data sets and there which is what image net is and there's in
healthcare there's an audio there's an video there's are you know there's a huge number of data sets now but each
one of them is usually in the scale of hundreds of thousands millions tens of
millions not billions or trillions which is what we need to create systems that operate in the in the real world and
again these are the kinds of machine learning algorithms we have there's five
listed here the teachers on the left is what is what is the input to the system
that requires to Train it from the supervised learning at the very top is what we have all of our successes and
everything else is where the promise lies the semi-supervised the reinforcement or the fully unsupervised
learning where the input from the human is very minimal and another way to think about this so every whenever you think
about machine learning today whenever somebody talks about machine learning what they're talking about is systems that memorize that memorize
patterns and so this is one of the big criticisms of the current machine
learning approaches where all they're doing is you're providing there only as good as the human annotated data that
they're provided we don't have mechanisms for actually understanding you can pause and think about this in
order to create an intelligent system it shouldn't just memorize it should understand the representations inside
that data in order to operate in that world and that's the open question one
of them and one of the challenges and opportunities for machine learning researchers today is to extend machine
learning memorization to understanding this is that duck the reasoning if you get
information from the perception systems that it looks like a duck from the audio processing that it quacks like a duck
and then from video classification that it the activity recognition that it swims like a duck
the reasoning step is how to connect those facts to then say that it is in
fact a duck okay so that's on the algorithm side and the data side now
this is one of the reasons compute computational power computational hardware that is at the core of the
success of machine learning so our algorithms have been the same since the
60s since the 80s 90s depending on how you're counting the big breakthroughs
came and compute so there's Moore's law most of you know the way our the CPU
side of our computers works for a single CPU is that it's for the most part
executing a single action at a time in a sequence so sequential very different
from our brain which is a massively parallel eyes system so because it's
sequential the clock speed matters because that's how fast essentially those instructions are able to be
executed and so we're we're leveling off physics is stopping us from continuing
Moore's Law so Intel AMD are aggressively pushing this Moore's law
forward but and there's some promise that it will actually continue for
another ten or fifteen years then
there's another form of parallelism massive parallelism is the GPU and this is this is essential for neural networks
this is essential to the success recent success of neural networks is the ability to utilize these inherently
parallel architectures of graphics processing units GPUs the same thing
used for video games this is the this is the reason Nvidia stock doing extremely well is is GPUs so it's
parallelism of basic computational processes that make machine learning work on the GPU one of the limitations
of GPUs one of the challenges is in bringing them to in scaling and bringing
them into real-world applications this power usage its power consumption and so
there is a lot of specialized chips specialized just from the neural network
architectures coming out from Google with their tensor processing unit from IBM Intel and so on it's unclear how far
this goes so this is sort of the direction of trying to design an electronic brain so it has the
efficiency our human brain is exceptionally efficient at running the neural networks in our heads and the
orders of magnitude more efficient than our computers are and this is trying to design systems they're able to grow
towards that efficiency why do you care about efficiency for several reasons one
of course as I'm sure will talk about throughout this class is about the thing
in our smart phones battery usage and this is the big one community I think I
think it could be attributed to the big breakthroughs in machine learning recently in the last decade is the you
know compute as important algorithm development is important but it's the
community of nerds global this is global artificial intelligence and I will show
in several ways why global is essential here is is tens of hundreds of thousands
millions of programmers Mechanical Engineers building robots building
intelligent systems building machine learning algorithms the exciting nature of the growth of the community perhaps
is the key for the future to unlock in the power of machine learning so this is
just one example github is a repository for code and this is showing on the y-axis at the bottom is 2008 one github
first open Institute going up to 2012 quick near exponential growth of the number of
users participating and the number of repositories so these are standalone unique projects that are being hosted on
github so this is one example I'll show you about this competition that we're recently running and then I'll challenge
people here to participate in this competition if you dare so this is a
chance for you to build a neural network in your browser so you can do this on
your phone later tonight of course on your phone
you can specify various parameters of the neural network specify different numbers of layers and the depth the
depth of the network the number of neurons in network the type of layers and it's pretty it's pretty self-explanatory it's super easy in
terms of just tweaking little things and remember machine learning to a large part is an art at this point it's a more
perhaps than even you know more than a well understood theoretically bounded science which is one of the challenges
but it's also an opportunity deep traffic is a chance so we've all been stuck in traffic
there you go Americans spend 8 billion hours stuck in traffic every year that's our pitch for this competition so
deep neural networks can help and so you have a neural network that drives that little car with an MIT logo red one on
this highway and tries to weave in and out of traffic to get to his destination and trying to achieve a speed of 80
miles an hour which is the speed limit which is a physical speed limit of the car of course the actual speed limit of
the road is 65 miles an hour but we don't care about that we just want to get to work as quickly as possible at home so what the basic structure of this
game is and I want to explain this game a little bit and then tell you how incredibly popular it's gotten and how
incredibly powerful the networks that
people built from all over the world the community has built of this over a single month is incredible and this
happens for thousands of projects out there now another challenging
opportunity ok so you may have seen this this is kind of ethics most engineers most I don't like I love
the love philosophy but this kind of construction of ethics that's often presented here is one that is not
usually concerned to engineering so what is this question you know when you have a car you have a bunch of pedestrians do
you hit the larger group of pedestrians or the smaller group of pedestrians do you avoid the group of pedestrians but
put yourself into danger these kinds of ethical questions of an intelligent system it's a very interesting question
it's it's one that we can debate and there's really no good answer quite honestly but it's a problem that both
humans and machines struggle with and so it's not interesting on the engineering side we're interested with problems that
we can solve on the engineering side so the kind of problem that I am obsessed with and very interested in is the
real-world problem of controlling a vehicle through this space so there's it happens in in a few seconds here so this
is a Manhattan New York intersection right this is pedestrians walking perfectly
legally I think they have a green light of course there's a lot of jaywalking too as well well this car just slide
it's not part of the point but yes exactly there's an ambulance and so there's another car that starts making a
left turn in a little bit I may have missed it hopefully not so yeah and then there's another car after that too that
just illustrates when you design an algorithm that's supposed to move through the space like watch this car
the aggression it shows now this isn't a trivial example for those that try to build robots this is this is the real
question is how do you design a system that's able so you have to think you
have to put reward functions objective functions utility functions under which it performs the planning so a car like
that has several thousand candidate trajectories you can take that
intersection you can take a trajectory where it speeds up to 60 miles an hour it doesn't stop and just swerves and
hits everything okay that's a bad trajectory right then there is a trajectory which most companies take
which is most a Google self-driving car and every company that's is concerned about PR is whenever there's any kind of
obstacle any kind of risk that's it all reasonable that you can maybe even touch an
obstacle then you're not going to take that trajectory so what that means is you're going to navigate to this intersection at 10 miles an hour and you
let people abuse you by walking in front of you because they know you're not going to stop and so in the middle there
is hundreds thousands of trajectories that are ethically questionable in the
sense that you're putting other human beings at risk in order to safely and successfully navigate to an intersection
and the design of those objective functions is is the kind of question you
have to ask for intelligent systems fork for cars is there's no grandma and a few
children you have to choose who gets to die very very difficult problems of
course but the problem of when I'm very interested in in streets of Boston streets of New York is how to gently
nudge yourself through a crowd of pedestrians in the way we all actually do when we drive in New York in order to
be able to safely navigate these environments and these questions come up in healthcare these questions come up in Factory in robust in in armed and
humanoid robots that operate with other human beings and that's one of the big
challenges another sort of funny illustration that folks that openly I
use often to illustrate well let me just pause for a second the the gamified version of this there's a game called
coast runners and you're you're racing against other boats along this track and your job is
there's your score here at the bottom-left number of laps your time and you're trying to get to the destination
as quickly as possible while also collecting funky little things like there's these green these green little
things along the way okay so what they've done is the bill Denton system
the one the general-purpose one that we talked about last time that learns oops that learns how to navigate successfully
through the space so you're trying to maximize the reward and what this boat
learns to do is instead of finishing the race it learns to find a loop
it can keep going around and around collecting those green dots and it
learns the fact that they regenerate with time so learns to maximize this score by going around and round now
these are the kinds of things this is the big challenge of our award functions of designing systems of designing what
you want your system to achieve is not only is it difficult to the ethical
questions are difficult but just avoiding the pitfalls of local optima of
vet figuring out something really good that happens in the short-term the greedy what it is that those psychology
experiments of the kid eats the marshmallow and can't wait for you know can't delayed gratification this kind of
the idea of delayed gratification in the case of designing intelligent system was a huge actual serious problem and this
is a good illustration of that so we
flew through a few concepts here is there any is there any questions about
some of the compute and the algorithm side we talked about today yes so the question was yeah used you
highlighted some of the limitations of machine computer vision algorithms machine learning algorithms but you
haven't highlighted some of the limitations of human beings and if you put those in a column and you compare those it's our machines doing better
overall or is there any kind of way to compare those I mean that there's actually interesting work on image net
so image net is this categorization task of where you have to classify images and
you can ask the question when I present you images of cats and dogs where our machine is better than humans and when
when are they not so you can compare when machines do better what are the fail points and what are the fail points
for humans and there's a lot of interesting visual perception questions there I think overall it's certainly
true that machines fail differently than human beings but in order to make an
artificial intelligence system that's usable and could make you a lot of money
and people would want to use it has to be better for that particular task in
every single way in order in order for you to want to use a system
has to be it has to be superior to human performance and usually far superior to human performance so so it's on the
philosophical level it's an interesting thing to compare what are we good at what are not but if you're using Amazon
echo your voice recognition or any kind of natural language chatbots or a car
you're not gonna be well this car is not so good with pedestrians but I appreciate the fact that you can stay in
the lane fortunately you have a very high standard for every single thing that you're good at and it has to be
superior to that I I think maybe maybe that's unfair to the robots I'm more of
the nerd that makes the technology happen but it's certainly on the self-driving car aspect policy is
probably the biggest challenge and I don't think there's good answers there some of those ethical questions that
come up well it's it's it feels like so we work a lot with Tesla in Drive so I'm driving a Tesla round every day and
we're playing around with it and studying human behavior inside Tesla's and it seems like there's so much hunger
amongst the media to jump on something and it feels like a very shaky PR
terrain a very shaky policy terrain we're all walking because we have no idea how how we coexist with intelligent
systems and so and and then of course government is nervous because how to regulate the shaky terrain and
everybody's nervous and excited so I'm not sure there's no same kind of
question to Jason a moment thanks a lot legs for another great session [Applause]

----------

-----

--21--

-----
Date: 2017.12.13
Link: [# Sertac Karaman (MIT) on Motion Planning in a Complex World - MIT Self-Driving Cars](https://www.youtube.com/watch?v=0fLSf3NO0-s)
Transcription:

first we have shirts and we'll give those all tomorrow and Friday if you're
here for the shirts if you here for the knowledge today our speaker is cert at
Carmen he is a professor here at MIT in the aero-astro department he builds and
studies autonomous vehicles that move on land and in the air that includes ones
that have 18 wheels and two wheels and everything in between robots that move
fast and aggressively and robots that move slowly and safely he takes both the formal optimization
based approach and the data-driven deep learning approach to robotics he's a
mentor to me and many other researchers here at MIT and Beyond and while he is
one of the leading experts in the world and building autonomous vehicles for the
nerds out there he still programs he programs on a Kinesis keyboard uses
Emacs which is how you know he's legit so please thanks please give a warm
welcome to Suresh thank ya thanks a lot
thanks a lot like sight I really had the pleasure to work with Lex for some time and it seems like this
class is him and the TAS have put together some amazing class I'm really happy to be here thank you so much for
Presentation
joining he gave me this title past present future of motion planning or something hopefully that's not quite
exactly what you were expecting so I took a whole bunch of slides from different talks and put them together and I am hoping to just kind of go
through all you know as much as I can and to tell you some of the interesting things I think in a domain that's
happening and touch upon motion planning at some point may be a starting point would be to tell you a little bit about
my background it is exactly a decade probably today that I shook John
Boehner's hand who you've met before I shook John Boehner's hand as a graduate student and joined the dark urban
challenge team it's been exactly a decade off of it we worked through it
with a number of people some of them are in the audience I can count some and the at the time that we
were doing these kind of things back in the day it was an academic project you can look at the DARPA urban challenge teams and you'll recognize they're all
University teams at least all the finishers and it came from an academic project - the thing that's going to
change the world in ten years so I hope to give you a bit of a history and then some some thoughts on that as well okay
Background
let me start with my background so I started graduate school with this we built these beasts that I'm going to
talk to you about a little bit I wonder if John there talked at all but I'll give you some details
this was our entry to the DARPA urban challenge I was a Land Rover lr3 that we made autonomous that navigated through
that course and it was one of the six finishers a number of my friends you know went out and they did their own
careers with a number of others we stayed here at MIT we built a number of other autonomous vehicles let me show
you one thing that we have done that I was kind of doing that I was the motion
planning lead for was this autonomous forklift it was a forklift that you could literally take a megaphone and
speak to you could say forklift go to X Y Z and it would go to that location here is trying to go to receiving which
happens to be an area where trucks pull up with pallets on it so that you can kind of pick this pallets up and and you
can put a mouse back so it's going to go there it has a front camera it looks through that camera it beams that camera
image to a handheld tablet device made by Nokia back in the day there was a company called Nokia they would make
these phones and handheld devices so you could see what it's seeing you would circle so you didn't have tapping back
then but you kept these pan gestures you could circle something and the thing would scan it and take a look at it you
could so you know we don't let me just
kind of go through this because it's kind of a bit slow so it'll scan through the pallet it'll pick it up but one thing I would like to show you guys is
that once that's done you can you can also talk to a tablet the tablet would
recognize your voice and then it would command the robot to do that kind of thing this was before autonomous cars
before iPhone before Alexa before Siri and things like that
so I spent like a couple years kind of doing this type of project that really shaped up my PhD thesis and later when I
started as a faculty I also worked on a number of things so let me show you one we built like autonomous golf carts and
in Singapore's and US National University Singapore campuses to go
there and do mobility on demand and so on the one thing that I ended up doing there was throughout these projects I
focus mainly on motion planning that you are expecting the one algorithm that I was working on was called rapidly
exploring random tree the idea is quite simple so you're starting in the middle of off so this is the area that you're
looking at there's that orange dot that you're starting from you want to go to the magenta goal region there's this red
obstacles you want to find a path that starts from the initial condition goes to the goal that's the very basic motion
planning problem turns out this problem is computationally pretty challenging especially as the number of dimensions
of this province is two-dimensional but if you increase the number of dimensions you can prove that any complete
algorithm meaning any algum that we towards a solution lamina exists and returns fail or otherwise will scale
exponential it's computation time so at some point you're going to run out of memory or time to do these things the
album that I was working on was called rapidly exploring random 3 the idea is simple you just land on a bunch of
samples every time you put like a random sample you connect it to it the nearest node in a tree of trajectories that
you're building and in this way you sort of rapidly explore the state space to find a whole bunch of paths some of
these paths may reach the ball so those that's the path that you pick so it's going to run in a second as you can see it's just sampling the
environment trying to build this set of trajectories that don't collide the obstacles if your trajectory Kleist but
an obstacle you just kind of delete it and you move on with other samples and then you would build this kind of a tree ok it's an algorithm that's kind of
pretty widely used and and it goes well beyond these kind of simple cases for example in our urban challenge kind of
entry we were using this algorithm so here you're seeing the algorithm in action so we're trying to park at a
location during what DARPA call the enqueue event so you can see a whole
bunch of cars that our vehicle is seeing generating this map read our obstacles black is a drivable
region it's going to try to park into it and then it's going to unpark you're seeing something hairy here so that's a
set of trajectories that are generated by the robot by the RT algorithm so it's trying to unpark now go there so as you
can see that trajectories are going back and then going towards that obstacles it's generating trajectory is picking
the best one so we've used the solder and throughout the race it worked okay so you can see the performance as it's
running so this is a media that video that's made about 30 times faster kind of showing you how the thing works when
Forklift
we switch to the forklift kind of algorithm forklift platform I started
working on this and the one thing that we realized is that you know the the forklift tries to go here to park in
front our truck and it finds this trajectory at some point it discovers there's an obstacle here and it finds
this looping trajectory and and it never gets out of that loop you would think that it's trying to minimize the path
length so you would think that it would be easier to come up with something that just kind of turns left and aligns but
it turns out that once you have that loop even if you add more samples to it you're stuck with that loop and so you
would never improve this type of trajectory so back in the day professor
said teller who passed away unfortunately a couple of years ago but he really pushed me he was telling me this doesn't work and every time it just
makes this loop right in front of the army generals who are the sponsor and it just looks ridiculous you need to fix
this kind of thing and try and find the fix for it we realized that the algorithm actually has some fundamental
flaws in it so specifically we were able to kind of write down a formal proof that the rrt
algorithm actually fails to converge the optimal solutions is this kind of something interesting so you would think that if you add more samples you will
get better and better trajectories but it turns out that the first few trajectories that you found it just
constrains you so it closes the the space that you want to search and you're
stuck with bad trajectories and this almost always happens sometimes you're lucky your bad trajectory is kind of
good enough but most of the time it's pretty bad we were able to come up with another album that we called our arty
star which just does a little bit more work but guarantees asymptotic
optimality meaning it will always converge to optimum solutions and the difference computational difference between the two
is very little if you were to run them side by side our artists our tree would look like this what it's doing is it's
it's just looking at the pads locally and it's just kind of correcting I'm locally just a little bit and that little bit correction is enough to
converge to below the optimal trajectory so that turned out to be my doctoral thesis back in 2011 and we applied to a
number of things let me show you one simulation scenario imagine a race car coming into like a turn we also turn
very quickly generates these trajectories so the right thing to do is to kind of slow down a little bit start
skinning hit one end of the road now start speeding up and go as fast as possible so that you hit the other end
the road and you complete the turn these kind of things would come out just naturally from the algorithm okay you
don't have to program you have to do these kind of things but you just run the algorithm and these are that this is the best rejected finds it would be it'd
be impossible to get something like this from an IRT we applied at a number of
other robots as well I don't know like PR to type robots or this autonomous
forklifts and got good results out of it so that kind of maybe gives you a bit of an idea of my background meaning like my
Autonomous Vehicles
graduate school experience a little bit and the PhD let me kind of tell you a bit quickly what my research group does
so I always say sort of so we do a lot of things in a fortunate and unfortunate
way so it's hard to find the focus sometimes admittedly but I usually tell people that we work on autonomous
vehicles the problem is quite interesting both at the vehicle level meaning how are you going to build these autonomous vehicles individually and
also interesting other systems that when you think about it most of the autonomous vehicle is most valuable if you put them into a system that they can
work let me give you some examples so a system the autonomous vehicles would be for example this Kibo system scenario
you know nowadays you buy something from Amazon the way it's you'd buy two books the way it's packed is that books are
brought by robots to a picker and the picker just puts them into the same box and sends it to you so this is done by
500 autonomous vehicles for example there would be a good example of a system another one is that there
ports are on Dyer in the world you know that are working just completely with autonomous vehicles and cranes if you
project a little bit forward you can think maybe you know you can have drawn delivery systems and and they maybe
don't have enough battery so they have to relay packages to one another so you need to build a system or some vehicles or if you have I don't know like
autonomous cars maybe it's best to use them in like an uber like scenario so
you can autonomous taxis that they can work together and such so let me tell you a bit more on the vehicle level
Vehicle Level Challenges
problems and the system level problems some of the crazy things that we try to do on the vehicle level we're interested
in all aspects about perception and planning usually challenges are sort of either complexity or either
computational complexity so you it's very hard just computationally so you really need to know or it's just the
system becomes very complex so we need to figure that out we're for example recently motivated by
really fast and agile kind of vehicles how we can build that like one thing that we were motivated for example is
sort of like imagine there's a drone flying and you want to you want to catch
it in the fly I wonder if this is gonna play so you know turns out that
Netherlands police is some people fly UAVs around and you somehow want to take it down it's not like you can shoot at it so
people train Eagles and things like that so we thought it would be great to actually build these types of robots that we try to in our group so you can
once you start to do these kind of things you wonder like how much I can push the boundaries of very very agile
vehicles and systems so here you're going to see a falcon diving for a prey
you're going to see a goose right at the last like a split-second so if you look at the scene from a 20 Hertz camera this
is what you would see so they are definitely much faster they do very complicated you know planning and
maneuvering to be able to do these kind of things so you know in the research group we look at a number of different perception problems where you're
High Performance Computing
multi-agency have ultra high rate cameras like for example we have drones with 200 Hertz cameras on and so you're
trying to understand the person that you're tracking its dynamics its intentions on the control level you're
trying to pull off really complicated maneuvers like the one that you've seen the race car now you want to do it in real time at like a kilohertz probably
so how can you do these types of things we use a lot high-performance computing so for example the drones that we have
actually have GPUs on them they fly GPUs they fly like teraflop computers to be able to do these kind of things we also
use them offline like the deep learning computers that you would use normally you have access to things like DG x1 and
so on that we use that to compute controllers for example here's an
Controllers
example of I don't know like one GPU drawn just kind of passing through a window this is from a long time ago but
these are the controllers that we would compute on supercomputers and we would deploy and on the perception side for
example we're looking at things where like you can use visual Arama tree you can just have a camera and just look
through the world from the camera and try to understand your own position so we have certain algorithms to pick the
features just right so that you can do these things with just like 10 features or something like that so they're just computationally very
efficient on the system's aspects of things and when you put them together yeah so this is maybe kind of yeah so
Computing Controllers
the question was what do you mean by sort of computing the controllers would you want to find the best constants so
controllers are actually pretty complicated objects so you have a drone it has suppose it has 16 there's
actually 12 degrees of freedom but suppose there's six degrees of freedom it's a six dimensional space six
dimensional space is very very large suppose you discretize every dimension
with 200 points so six dimensional position and orientation 200 points 200
to the six would be thousands of trillions if you were to write one byte
for every point in the States are you looking at the state space where every point in the state space what's the action that I'm going to do if I end up
at that position and orientation what action should I do if you use one byte to write it in the memory it would make
2.5 petabytes of this controller it's pretty large when you think about it you
don't really need it would be very surprising if that menu were really to be able to describe it like an
information theoretic terms to be able describe it it'd be very surprising if it requires thousands of trillions of
parameters I mean how complicated is it really so millions maybe but trillions seriously so what we do is to be able to
compute these things we take very simple controllers like for example zero don't do anything we compress them like isn't
data compression and then we work on the compressed versions and then that compressed version grows at to a level
that comes down to something like two megabytes that's probably essentially what you
would need rather than three terabytes for example we use kind of you know
singular value decomposition type techniques to do compression you may have done the same thing using images
for example if you compress an image JPEG you save an order-of-magnitude no
surprise right if you compress video you save to three orders of magnitude because video is three-dimensional as
you increase the dimensions there's more to compress so when you compress this way this saves ten orders of magnitude
which honestly is no surprise when you think about a delivery so those are the control like the planning and control
items that we use these viral supercomputers stole so we compute them in I don't know five minutes that gives
you a lookup table that's two megabytes you put in so that you can quickly execute it then look up tables
essentially do you want to kilo Hertz control you won't be able to compute a trajectory of technique okay that
question came in and that's the whole talk in terms of present of motion planning and I can show you some other
Agility
stuff and there's a lot to do especially in terms of agility on the systems domain as well like I don't know I
pulled up this is not the kind of stuff that only stuff that we do but I pulled up the most interesting thing I think
maybe the most crazy thing off of my hard disk imagine you have a whole bunch of vehicles coming to an intersection suppose they're fully autonomous how
would you make it so that they would pass through the intersection as fast as possible okay so if you were to really
utilize algorithms that will do that here is what I would look like so you would have vehicles coming in and you
could it looks like so you probably don't want to sit in this vehicle just sort of like just to understand the
fundamental limit sort of situation just to understand how far you can push these things you can see
looks like they're getting very lucky but really what's happening is that they're just speeding and slowing down just so little so that they could avoid
one another so you can actually sit down and do some math and try to understand you know given the dynamics like your
acceleration deceleration limits how fast you can push these things maybe it doesn't immediately apply to
self-driving cars but certainly you can use it in their houses and things like that which would actually improve operations quite a bit I wonder if any
of you have seen kiba systems where houses you look at it most of the robots are stopped they're just sitting there
yes so the question is is there anyone sort of working on robustness aspects of distributed control so that's a good
point it's it's very right we have looked at things like from the theoretical perspective it turns out
that like even in this case there's something like a critical density of
these things so below the critical density things are very simple you're going to be robust you're going to be
able to find Pat's and you're going to be able to execute above the critical density things are very hard it's very
fairchild like if something fails just kind of the whole system will crash into one another and this is no surprise
either like this is kind of the physics of many you know just like you see it everywhere I mean it's the same thing as
I don't know you heat this thing there's the critical temperature above it it looks different below it it looks like a
liquid you can use the same kind of thinking or theoretical arguments to
come up with these types of things and I know that a lot of people work on specific controllers for vehicle level
to guarantee robustness and so on probably those are the kind of things that one needs to do before implementing
these types of algorithms sort of like in the current existing like multi
vehicle setups like Kiva systems or ports and things like that we are far
away from this kind of thing the main problem some of it is control
like we don't understand the control aspects but we also don't trust our sensors and things like that so that's another big problem
so probably the more of the research is only not research for implementations on the sensor side I'd say okay so yeah so
Other projects
we have been doing a number of other projects currently as well on autonomous vehicles if you're interested in any one
of them let me know I'm not gonna show you videos but let me just kind of tell you with one slide and a few pictures
this was several slides but I felt really bad so um so we have an autonomous tricycle that may sound funny
but it's actually pretty hard to test with autonomous vehicles so we currently have five of these and
we're hoping to build 30 so that we can put them in and they're currently in a little robotic enclosed area and Taiwan
and they're just driving around collecting data so that we can for example you can pay them into deep learning algorithms we also have in a B
eyes warehouses we have these we have one of these robots it's a very house robot and supposed to be kind of like
you know I'm sure you know what we think robotics like they make this robot on it's supposed to be very easy you can
interact with so imagine a warehouse robot that way you can just talk to it you can tell it's tough to do when it
can do that you can show it you can hop on it you can do it yourself type of thing I am also a epi together with sort
of I'm working with Daniella ruse on mi t--'s effort with Stanford and Toyota to
build safer vehicles and finally I'm still API on the MIT Singapore
partnership right now from golf carts we've moved into doing these electric vehicles and and we're working on
basically integrating a lot of electric vehicles together to make them kind of work nicer we've also kind of not
looking into an autonomous kind of wheelchair that's also in that project that I didn't show him so my group works
on like a number of other projects in this domain admittedly my group is a bit more on the theory side as well so maybe
like half the group is a bit your theory oriented the other half is more experimental I usually say we have quite
a spectrum in the group so we would have mathematicians like I would have people who don't have any engineering degrees
like for example we have one post type who is a mathematician by training is a post doctoral scholar here we have
undergrad to undergraduates to graduate students whose undergraduate degrees are from mathematics on the other hand we
have sort of mechanical engineers and so on who would actually build these things throughout the group and we were funded
by a number of people throughout so okay um there was supposed to be like a quick
DARPA Urban Challenge
summary and entrance into what I was going to talk about so let me kind of tell you maybe our DARPA urban challenge
effort so that I can tell you a little bit more about how we implemented his motion planning algorithms if time
allows I could talk more broadly about motion planning algorithms but I don't think we'll get a chance to okay so I'm
going to start with this effort the darpur every challenge I'm sure many of you have heard people usually believe
that it kind of just kick-started of all these autonomous vehicles type what
answer that's been going on let me introduce to you a little bit so this is was DARPA did things called DARPA Grand
Challenge one and two I'll tell you in a second what they are but this is the third one essentially the idea is that
you would take a street-legal vehicle you would instrument it with sensors and computers and you would enter this race
to drive 60 miles in under six hours in an urban traffic right there's other vehicles driving around as well so the I
proposed is back in 2006 stated that race in November 2007 the it was pretty
hard you know you would have to do a lot of different things like u-turn skate pointers you'd have to be careful with
stop signs and so on it's pretty complicated but if you win it they would give you two million dollars there's good incentive 89 teams entered the race
we usually say it's a mighty spur Series entry but MIT is non serious entry was I
guess the team that later turned into cruise automation which GM ended up
buying for a billion dollars so this is the serious one of our entries they just want there to have fun
I think and then later they continued their interest into autonomous cars and and built cruise automation did a great
job we went after we were not directly connected to it that team our team had
Team
mainly MIT faculty postdocs and students so we had eight full-time graduate students kind of roughly I was one of
them you can see me right here I looked different back then and we had a lot of
support from Draper laboratory mainly on the sort of system integration vehicle integration and support some of them are
in the audience and we also had some vehicle engineering support from Olin
College we had a first version of the vehicle where cables were coming out and then Olin College came in and they
packaged it nicely we built a vehicle it looked like this we took a Land Rover lr3 line
Vehicle
one of the sponsors but also it was nice that the vehicle was pretty big we put
an EMC driver wire system to it so this is kind of a driver wire system for people who are disabled like for example
if you can't use your legs they would give you like a little joystick type device so that you can actuate you know
gas and brake so it came very handy we used it to make our vehicle driver wire we needed to put a lot of sensors on it
so I'm going to say as I wish this wasn't recorded but hey so I think our
situation was the following there was a lot of other teams out there and they were very experienced they had done the
other other Grand Challenges before and so on we were not as experienced I would
say that our team was talented but not experienced and we had a lot of sponsors so we had a lot of money so our strategy
turned into if it fits on the vehicle let's put it on the vehicle and we'll figure out a way to use it if we don't
use it it's dead weight we'll just kind of carry it so with that mindset we ended up with five cameras sixteen
radars twelve planar laser scanners one 3d laser scanner and one GPS a new unit
this was a lot of sensors they generated a lot of data you had to process it so
we had to buy a 40 CPU 40 gigs of ram quanta computer that normally at that
time would run on like a Google server type thing it was a server rack 10 computers essentially that we had to put
in so yeah we used to joke that this was like the fastest mobile computer on
campus or something like both in terms of speed and compute power now this requires a lot of energy so we put on an
internal amount of generator now if this generates a lot of heat so we put an air conditioner on top you can kind of see
it here so that became our vehicle one thing to note though is that we just had the number of sensors was or a number of
computers was large but but the sensor suit was very similar to the other people who have finished one important
sensor was this 3d laser scanner that I'm going to show you in a second so this is the thing that sits on top of
Laser Scanner
the vehicle looks like that Kentucky Fried Chicken type of bucket and essentially what it has is that probably
a lot of people here are familiar but it has for lasers that measure range and those
sixty-four lasers are stacked up on a vertical plane and that plane will turn and 15 Hertz so it will give you a 3d
point cloud if you drive with it in Harvard Square here is what the raw data will look like this is colored by height
you're just looking at raw data and you can you know easily pick up I don't know bus here another building may be a
person a bunch of others so that gives you a great data already like you could work with this right so be taught so
other teams thought this sensor is made by a company called Melodyne it came
pretty much just in time for the urban challenge my guess is that if you didn't
have this 3d point cloud it would be pretty hard to complete that challenge there was only one team that didn't have
it and complete it and they had a 2d laser scanner that was kind of turning like they essentially build their own Melodyne okay so we had also this sort
of 12 planar laser scanners you would need these kind of things to cover the blind spots of the vehicle the thing is
on top so you're not seeing kind of area nearby we had five from the push rooms looking down and seven on the skirts so
this is kind of what it would look like so you're seeing the curves here and you know a bunch of other things and the vehicles are when the vehicles are very
close to you can still see them we had 16 radars radars are great they can see
very far like laser scanners would see 70 meters radars would see twice as much the problem is that they have a very
narrow field of view so we needed 16 of them to cover 27 degrees around the vehicle 207 degrees around the vehicle
270 degrees so you know you can park somewhere and you can see this is meters per second you can see a whole bunch of
other vehicles kind of coming through helps quite a bit and finally we had five cameras in this configuration we
Cameras
were using cameras to actually look at lane markings I think actually you are the only finishing team that was using
cameras for any purpose of any kind the other vehicles were just kind of working with the laser scanner and we were
mainly working with laser scanner but we were picking up lane markings with this and we bought this GPS em unit there was
an expensive thing but it would give you your position you the algorithmic stack it gets pretty
Algorithmic Stack
complicated I think by the end of the race we would probably have like the
active code that was running could be order hundreds of thousands of lines of
C code so maybe like two hundred thousand good I remember the forklift and there was about half a million lines of code I
think this was a bit less we head around like a hundred processes that are running sending messages to one another
on that forty core system that you've seen so that would generate a huge
software diagram so I simplified it for you it turned into this you have some
sensors you get that data you process it through perception algorithms you generate a map of the environment close
to the robot and you have this three-tier stack you have a navigator much like your Google Maps it would
compute a map to get to your next goal which may be kilometres away and it would also give you the right the next
Waypoint that you should hit that would hopefully be within your grid map and there's a motion planner that looks at
the map sees all the obstacles and everything sees the goal point and finds that path to get to the goal point using
the RT and then once that trajectory is computer it was passed to a controller that actually steers the vehicle that
Motion Planner
way so I've already shown you how the motion planner works it just kind of computes these things so here's the goal
point our car finds the path to get there and you can run these things
together to get like a good behavior it doesn't always go well let me show you
Simulation
what doesn't work in the sky rakia
yes so we have like um honestly so so here are a couple of things so we had one thing is that we had a pretty good
simulation system going for motion planning and things like that it helped a lot like on the day of the on the sort
of like that was the day before the race my 24/7 job was to keep simulating our
algorithms like I had two computers kind of start simulation here start look at it if one fails log it and and send it
out so simulation really helped we had done some testing but I don't think we
actually I think the race itself was the farthest that we had driven without any human intervention like before then we
hadn't done that much I think this was like 60 miles if I remember this correctly we had done like a 20 mile stretch or something like that but we
hadn't done as many so admittedly we didn't have too much on the testing from
going the only reason why was because it's just we didn't have time to do this
kind of thing we so I mean we started maybe a year before that we put together
some of the infrastructure like this message sending and things like that but
the vehicle itself to test it in reality the vehicle I think the race was in November we probably got this vehicle I
mean here another vehicle before but we got this one clean I think it was April and then we put the sensors on or
something like that so really it was just the summer time that we had to test and admittedly we couldn't test much and
Draper laboratory helped out a lot with the testing if we didn't have them you probably wouldn't test any so we're
probably just kind of failed outright or something in this kind of thing testing is very important it'll be very
important for future as well simulation will be very important simulation has come a long way actually like nowadays you can I mean you guys
are working with simulator as you can see but there's a lot of other things that people are going to put out in the
next year or two and and you know like we can nowadays ran there things that you can show it to people and it's very
hard to like people don't cigarette surrendering uh always wasn't
back then I think that would be probably the right thing to do right now but back then we had this one platform that you
know you could just run the whole software stack but if you start up a simulator it would actually simulate all
the sensor data and everything if you don't start a simulator then the processes will be waiting for the data
to come in so you could put it on a real vehicle or something so back then we thought that would be the best thing to do the question was was your simulated
environment and your development environment separate or integrate they were very integrated right now I think
you would do things differently yeah there's kind of a lot to talk about
so I thought that it would be just kind of great to give you guys some ideas given the the courses on autonomous
vehicles so here's an example of a case
that we got into so what's happening here is we arrive at an intersection and
there's another car it's Cornell's car and they're just sitting right in the middle of the intersection and they
don't seem to be moving I think they've been sitting there for a few minutes before we even arrived so DARPA decided
that they should let us go and we're probably going to take over and we'll do great and it's going to be an important
moment in robotics history that for the first time you know a robot takes or another robot while the other robot is
stuck and it's going to be great so they decide to go forward with this so here's how we're seeing things from inside our
car our car is right here wants to go there or our T generates trajectories there's an object here that's the car
that we're seeing we're not seeing all of it but we're seeing in a fraction of it so we're going to play it a little
bit so you know like we were actually able to turn around it so I think I need
to stop it somewhere but now let's look at here so we seen the whole car the new
goal point is further away regenerating this trajectories looks great it turns that this car is just somehow stuck for
some reason so we wrote a paper together with them it's not I'm clear to them either but my understanding is that they
think that the obstacle is on top of the car and the way the algorithm is written is it just kind of generates a
trajectory and asks if the trajectory is collision-free or not right the collision checker doesn't say this part
of the trajectory is in collision it's just every time it passes a trajectory because the route is in collision it
just says you know there's nothing that they have another little piece where it just updates the map every time there's
no information from the sensors if there's no new information there's no need to update so they ended up getting
stuck on this obstacle and they're not refreshing their map because nothing is moving up until we move right next to
them they refresh again and they say oh I'm actually not sitting around obstacle that was an error so next time the path
comes going forward it says this is a great path go forward with it that happens right when we're passing so
if you look at this blob right now as I play it the blob starts to move so they
are going in a direction that we are going a quick thing will happen so if our car if our car at some point
realizes that there's no paths a collision is imminent and there's nothing to do about it it generates
shows that wide circle around it and that basically means that we are headed
to a crash there's nothing we can do about it we're just going to slam the brakes and hope not to bad things happen
so it starts to do that I think at this time this camera is more fun to look at
you can kind of take a look at it and sort of see what happened and so this kind of like collision happens we
collide with the car DARPA what they did is that they actually pulled the Cornell
DARPA
car back they started us we finished they finished as well so both of the teams finished well you can see some of
the things that are a little bit hard for example if you yourself were deriving our intersection that there's a car that's sitting there you probably
would stop your car take out go and ask if there's anything wrong even if you don't do that suppose you're not very
decent of a human being you don't decide not to do that you would still steer away from the car you probably wouldn't
get as close to this car as we do so there are some problems that are at the inference level that we do without even
thinking and it's actually kind of hard things for these types of cars to do
especially if you're going fast you're in a complicated environment you're not expecting things and you might collide
into things we do different kinds of inference that we can't do a name but you know you look at the way a person
walks on the sidewalk and you can say well this person is kind of dangerous or maybe we will walk into the street or
not you know you make that decision and it's actually pretty complicated thing for a robot to do okay so you know this
Race Results
is kind of like the results of the race I'm not gonna go too much into it basically the idea is that 89 people
started six finished we were one of the finishers CMU came first so they got the 2 million dollar check I believe
Stanford came second they got a 1 million dollar check Virginia Tech came third they got half a million we came
fourth we didn't get anybody but you know we got a lot of experience it was great to be a part of it I think one
Google Color
note is that the Google car that you may have heard a lot was essentially sort of like a spinoff from this race so if you
look at the Google color you will see that the sensing package is very similar it's very laser scanner oriented has a
couple of radars on it that it could utilize and is working somewhat with the cameras but not so much essentially
Google engineered this thing that we built or all the other teams built independently they engineered it for ten
years and that's the kind of thing that they utilize nowadays there's also like this whole Tesla brand of camera based
cars or deep learning and so on that's coming in and just very recently back ten years ago you know we knew about
people learning and so on but it just it just didn't work the moment somebody figured out doing it on a GPU it started
working pretty well okay so there's a lot I can tell you about path planning
Challenges
but I think here is kind of maybe what I should do if you if you do not mind
rather than I'm telling you about our RTS and making this into a lecture that I'm not sure if you're going to like it
let me talk maybe a little bit more about south driving vehicles and I think that's something that you might enjoy
better
so the question is sort of building it from scratch what was the biggest challenge so I'm going to say admittedly
I was a junior student back time so my challenge was to get these controllers and some parts of the rrt working and I
had simulation systems and things like that and life was good for me I would think that I mean we ended up building
pretty complicated hardware so that was one of the challenges and that probably
all in college Draper you know they did all of that that was great the other challenge that we had is that
nowadays there's like maybe you guys use it like robot operating system and so on that infrastructure software we had none
of that so we ended up building our own I don't know if anybody uses but there is this thing called lightweight
communications and marshalling LCN so that ended up being built for this and it just kind of got spun out there was
another big challenge that we actually faced so LCM nowadays is utilized throughout the industry like for example
for autonomous cars we'll use it Toyota will use it no Donna mean uses it
so it ended up coming out of this this challenge and it was probably like the
first you know I would say the first six seven months was devoted to it and and
for necessity I mean we just we wanted to do other things but we just couldn't because you needed something like this there was another big challenge I would
say testing was a big challenge things like that
pretty collaborative as far as where I was because probably papers published
paper with other team things like that and I've seen like my aren't people
founded becoming much more isolated like
yeah wrong I guess it's good and bad it's kinda hard to assess so competition
is always good so the the the question was that you know back in the day we
were really collaborative like it's very interesting that we actually wrote a paper with Cornell about our collision
just to teach the whole community why these kind of things happen but nowadays like everybody is just kind of doing
their own thing and there's no kind of going out so there's there's a quick question is a quick answer for that and
there's a kind of broader answer so the quick answer is that yeah I mean it became important there's a lot of you
know sort of people invested a lot of money and they are expecting returns and things like that and that affects the
environment that definitely drove it I think we're still you know trying to work on it in academia and trying to
publish papers but a lot of people are you know worried about competing with these huge companies and things like
that which I think it's not a big war because there's a lot to do still sobani when you look at the industry
there's little competition but that for some reason the broader answer is that that became a norm so back 50 years ago
you would look at the top company of the day this is like starting from a century ago like with bowel for example they
would form labs and they will publish in there to science and things like that will be very open and novel day is the
big companies of the day they kind of rather prefer secretive labs and things like that so that I think Microsoft was
the last big company of the day to do that nowadays googles and apples and
things like that they don't do that anymore there's a bit of that as well good or bad but it became that way and sometimes
competition is good honestly it's a good thing that people feel like you don't
know what the others are doing and you want to compete so that makes you better
and better even though the others maybe I don't know ok any other questions yeah
maybe a vision only a challenge or or something that races
I'm not sure I don't think it's purely an industry problem because it's it's still kind of it's it's quite
complicated honestly so there may be things that people can do but i i i am
wondering if DARPA would be interested in doing a challenge so let's set DARPA aside differently and research otherwise
like when you think about DARPA dark ways a defense agency and when they talk
about the challenge they had honestly defense problems in mind so for example they didn't allow you to go around and
drive in the area with your sensors the idea was that they would give you a map of the environment 24 hours in advance
and then five minutes before they would give you a mission like hit this waypoint hit that way point and so on so
that's a military setting they were really it really the whole thing started with the US Congress mandate to get you
know one third of combat vehicles autonomous by 2015 which didn't happen but it was a war military setting so
DARPA is usually sort of that minded and they did the DARPA Robotics
so the idea is to build a quadcopter that can fly here 20 meters a second
like 40 miles an hour in indoor environments type of thing I think they'll do that but there may be other
things like there may be other you know people kind of coming in pushing the boundary of research like something for
example just with cameras would be very interesting and I think we are just in it may be a couple years away from doing
that very well and probably neat learning would be a lot of it ok so I
don't know much time and I don't want to hold you here but sort of you know let
me tell you a few things about autonomous cars in general and let's see if we can you know in like 10 minutes we
can fit something interesting transportations is a very interesting thing it actually defines how you live
Transportation
quite a bit so if you look at for example the kind of cities that you know you know you may be living in today they
look like this and they are produced thanks to one invention that was the affordable car which was about as
you go if you look at it you know throughout the last century like in 1950s cars were big and and you would
Transportation in 1950s
find you know that everywhere these kind of subways were being constructed for the first time the reason was cities were dirty they
were deemed diseased prone so now he had the car you could move way into a better living lifestyle and it would improve it
and that was the 20th century invention that you had it also changed the cities
quite a bit I mean like for example this is Boston's sort of central artery that was built in you know 50s that around
that time to kind of service the colors coming in and out of the city the cars
Suburban Sprawl
kind of generated this kind of thing you know in some places at the extreme like if you go to places like Los Angeles in
the United States you will see the suburban sprawl it's very different in other places so places that didn't have
the time to expand that didn't have the resources to expand or just didn't have the place to expand it caused many
problems like here's the suburbia and in Mexico City you can see the dirt that it generates in the distance even if you're
Rich Countries
rich it doesn't really matter you know even in in rich countries this quick expansion it just doesn't work and it
creates if anything just ugly environments and in some places it
Ugly environments
creates like you need to be dense and you need to be big and so you have the cars but you just have to build you know
big buildings that you cannot even serve with cars so you generates these type of things where you know like there's a I think
it's probably my just I was just gonna say only let the congestion and pollution in the rest of the world but it generated these kind of things where
China traffic jam
I don't know if you heard there was a traffic jam in China it lasted like nine days and it was a hundred miles long so
it generated this kind of thing is just a quick introduction of the affordable car sort of what it did to the
environment in the cities there so pollution is one problem and so on but
Pollution
if you look through it it's actually pollution and energy consumption wise a lot of it comes from the cars especially
inside the cities an interesting point is that if you look through the cars the
cars are actually pretty inefficient the way they sort of sit currently
if you look true for example BMWs over the years you would see that they get heavier and they get faster this is very
correlated if you get faster you have to become heavier because you have to pass crash tests and things like that so you
know you're you know just to be faster so in order to pasture has two crash
tests you build structure and things like that and that makes the vehicle heavier ultimately so like a BMW that
you would buy in the 70s would weigh something like you know twenty five hundred pounds nowadays it's like you
know like four thousand pounds roughly so it would you know if you look at the
average passenger weight that it's carrying it's about 25 times the weight of the passengers and the size as well
Average Passenger Weight
you know it's about ten times the size of the passengers that it carries in terms of parking spots if you look
Parking Spots
through the cities there are places in the you know usually what we have in the United States is that for every car we
have two parking spots so roughly that's the number in some places parking spots take up like half to sea
so for example in a way on average it's about one third so you might ask the
City Environment
question like this is the kind of thing this is the kind of environment that city is created and do you really want
to live in this type of environment and it's to kind of give you the idea I mean if you if you walk out a lot of the
infrastructure a lot of the things that you see are made by cars like for instance and it really kind of
interferes with your thinking as well so for instance we never walk on the street nowadays like nobody jaywalks
streets are for cars my cars go on the streets and we go on the sidewalk it wasn't like that a hundred years ago you
could walk on the streets however you wanted cars came in and they took it over and so they changed the urban
landscape quite a bit the point is that it seems like there's a there's an
Opportunities
opportunity today to actually kind of use 21st century technologies this could
be robotics but a number of other things like online services new business models and things like that and so on maybe
high-performance computer whatever and to kind of service the needs of people in the cities
I'm not sure I don't think that the kind of the service aspects of it goes away so you know you will need to prop my
guess what would happen is that I think people could be more mobile so I think they want to be more mobile but they're
just not if it was very accessible very easy I think they would be so there be
increase in being mobile but at the same time that's a you know resources are
spent on it you need to pay for it somehow so you would still generate
economic activity off of that in fact you would probably generate more economic activity for example if the
moment you change people's behavior this the way that you generate like a new economic activity so if there's a way
for example transportation is more available more affordable and it changes their behavior it makes you more mobile
like for example you're fine with having a class here and then 20 minutes later
having a class at Harvard nobody would do that nowadays but if it was that easy to get there you would probably do it
and so that would make you more mobile and that's the way ultimately would generate more economic activity rather
than buying cars we the service is still there you need to pay for it somehow any
other questions yes what the point is that you know you can use these type of technologies to do for example like
either maybe like mobility on the man you know whenever you need to be mobile you can be mobile or deliver things and so on and I think that let me just kind
Mobility
of I was gonna tell you a bit the
history but I think that I'm just going to pass it in and tell you a few things so autonomous vehicles are sort of one
thing that you can utilize and you can actually do these types of things I think you can make this even better like
Integration
for example you can integrate a few things into it one thing you can integrate sharing like so you can make
Internet user type scenario you can use autonomy as well and finally like
electrification especially if you're going a little bit slower so you don't have to pass - crash crash tests and
things like that you could really reduce the cost of transportation like to the point where you could imagine things
like like you could go for anywhere to anywhere else for $0.99 in Boston with like five-minute wait time
if you want to share your ride it could be 50 cents if you want to admit to like
one stop a lot of us do one stop you know you can take a subway and then take a bus one stop makes your transportation
much cheaper if you were to take an airplane suppose if you wanted to take one stop you could pay 30 cents and you
could go anywhere to anywhere else in Boston I think there's a good opportunity to kind of you know push for
things and utilize technology to bring the cost of transportation to a point or
availability of transportation to a point to like really just change a lot of things it's not very easy the way I
Speed vs Complexity
usually look at the technological landscape is that you can imagine sort of speed versus complexity speed is the
speed of the vehicle that's being involved it's involved in this and and maybe complexity is the complexity of
the environment that you're dealing with like you can have high speed low complexity environments like highways
Complex Environments
they're actually easy to work with we might actually conquer them like in the next I don't know three years or
something like that another thing would be like for example parks or university campus or something much slower but much
more complex like people walking around and and things like that fully autonomous driving is probably pretty
far but there is some opportunity to do some interesting things elsewhere very quickly the one of the problems is that
this is not just an technology problem to be honest as you have seen earlier
there's a lot of enrollment in like for example architecture like how do you actually utilize the city the best and
so on but one of the biggest problems ends up being this law and insurance and
regulations aspects there are good or bad things like for example sometimes you allow by the law to be able to do
certain things but then is it really like is it a safety hazard is it of an
ethical the kind of a lot of people to just kind of test stuff around so it's a bit of a question like whether or not
this is the kind of thing I think sort of going forward if I could say one thing to you guys is that this is this
Is it ethical
is just not like a just a problem in sort of technology but it's also like a problem
and technology sort of society policy architecture law insurance and business
as well like you may need new business models and so on so I personally think that the it's it's
right out there but I think that we still need just a bit of more like a better thinking to do to be able to
attack this problem and to really kind of enable it so that you can kind of do
good and interesting things with it I might I could close with a couple things one thing is that I was going to talk a
Sertacs new company Optimist
little bit more but maybe I'll just kind of pass with one slide I am a part of a
new company I've got a few companies outside so this is the latest thing that we've been working on it's called optimist right it's working
on autonomous vehicles it's currently in stock no it just raised like a little more than five million dollars in seed
round to kind of start to see operations I am joined the founding team includes a
number of sort of friends Ryan chin for example I don't know if you guys have heard of the MIT city car the Spalding
car that was his doctoral thesis he's been an MIT PI for a while he joined
Optimus Albert Wong is a friend of mine who we worked together in the urban challenge he was later a sort of a chief
architect Software Architect at rethink robotics then the lead perception engineer at Google X were project wing and then he
joined Optimus ramiro Romania is a sort of a designer so he's a layup fellow
from the Harvard Graduate School of Design as his fellowship they would invite eight mid-career you know best
mid-career designers so he has that kind of a background he also built Kito's subway system raised two billion dollars
for it Jaynee Larios Berlin is also a joint MBA and an urban planning master's
from MIT she was the managing director of university campus operations of Zipcar
so we kind of started this kind of thing and thinking about these types of problems if you're interested send me an
email would be happy to talk to you more about it I also will tell you one more thing I am advising a team
Formula SAE
it's trying to do Formula SAE autonomously they're doing it for the first time this year they're actually
using a lot of deep learning type algorithm so we're not I was telling them I'm not really sure if we're deep
learning you're gonna write a little wave in it because people might come with all the heuristics and things like that but I think you know you may VIN it
at people's hearts just say that you're on the algorithm is deep learning or something like that so they're doing
FSA
that if you're interested please send an email to autonomous dash F Formula SAE FSA that I might tell you and they're
working on a number of things you're more than welcome to join them thank you so much that's all I have it's exactly
one hour yeah I'm here yep so maybe a
few questions if anybody has questions so that a lot of this classes of bought deep learning and in terms of autonomous
vehicles deep learning is mostly focused on the vision sensor or cameras so how
far away away from a car that safely navigates the streets of Boston without
lidar and without any mapping so purely on the sensors using the sensors and
perception so it's a bit of a guess game to be honest I it wasn't some what the
Computer Vision
slides that I kind of passed through but I am a big believer in computer vision
and I I do not think it's too far away it just ends up being a bit of a guest
game but it's not like I don't know how many of you have worked with cameras but
deep learning is one approach you can also use geometric approaches like you can use a single camera and the motion
of the car to build a 3d map of an environment these are not too far away cameras are actually pretty good sensors
the only problem with cameras is that they is just a lot of data and there's little information and if you need to
fish it out so you need computers to accompany it it seems like the computers are coming out so it's still hard to
know but I like I would be surprised if in ten years you can't build a car that just has a bunch of cameras and
navigates with cameras period they will be very surprising to me it'd be also surprising if it happens
next year like some people are saying but in between these I you know I would
think you would be able to so once you like what I would suggest is if any of you is working with cameras
I would suggest deep learning is an excellent technique so whilst you I think you're kind of using it here and
I'm sure you're being surprised as as as it gives you the kind of information that you need try out model-based
techniques as well they're also coming along pretty well so probably a solution that just integrates them as best as
possible would be viable I would guess in three to five years I'd be surprised otherwise it's optimistic
okay anybody have questions this is the question was an autonomous intersections
what role the communication plays if you wanted to do crazy things that like I've shown you you need to make sure
everything communicates but everything else that would break pretty badly if you don't do it I would actually imagine
that like one interesting things to quickly do would be to have cars communicate with each other to do some
interesting things like not just maybe intersection but lane following and things like that like there are a few
things that you may see pretty quickly with autonomous cars back curriculum in 25 years so this could be either read to
be related so communicate with other vehicles vehicle to infrastructure related I mean you could like the deep
learning and things like that you could put up a camera on our infrastructure and people could tune into it the
biggest problems are cybersecurity to be honest to deploy these things and on the autonomous vehicles and you could see
things like maybe not with the communication you could see either sharing like you know you have a button you press your timeshare or you can have
sharing with you know like for example you can use autonomy technology for
safety so that's a different type of sharing or you can find autonomous vehicles in isolated environments so
this stuff that you can do with communication I think you can quickly see Lane following and maybe at
intersections but things like that and with autonomy there are certain things that we might see but they don't involve communication at all
all right let's get start to ask one more time thank you

----------

-----

--20--

-----
Date: 2017.12.06
Link: [# Chris Gerdes (Stanford) on Technology, Policy and Vehicle Safety - MIT Self-Driving Cars](https://www.youtube.com/watch?v=LDprUza7yT4)
Transcription:

so today we have Chris Gertie's with us he's a professor at Stanford University
where he studies how to build autonomous cars that perform at or beyond human
levels both on the racetrack and on public roads so that includes a race car
that goes 120 miles an hour autonomously on the racetrack this is awesome he
spent most of 2016 as the chief innovation officer at the United States
Department of Transportation and was part of the team that developed a federal automated vehicle policy so he
deeply cares about the role that artificial intelligence plays in our society both from the technology side
and the policy perspective so he is now I guess you could say a policy wonk
world renowned engineer and I think Oh was a car guy yes
so he told me that he did a Q&A session with a group of three graders through great third graders last week and he
answered all of their heart hitting questions so I encourage you guys to continue on that thread and ask Chris
questions after his talk so please give a warm welcome to Chris
great Lex thanks for that great introduction and thanks for having me here to talk to everybody today so this
Chris Gerdes
is this is sort of my first week back in a civilian role I wrapped up at USDOT
last week so I'm gonna no longer speaking and officially representing the department although some of the slides
are very similar to things that I used to speak and represent the department so I think as of Friday this was still
fairly current but I am sort of talking in my own capacity here so I wanted to
talk about both the technology side and the policy side of automated vehicles and in particular how some of the
techniques that you're learning in this class around deep learning and neural networks really place some challenges on
regulators and policymakers attempting to ensure vehicle safety so just a bit
about some of the the cars in my background I am a car guy and I've gotten a chance to work on a lot of cool
ones I actually have been working in automated vehicles since 1992 in the Lincoln Town Cars in the upper corner
are part of an automated highway project I worked on as a PhD student at Berkeley I then went to freight lidar heavy
trucks in daimler-benz and worked with suspensions on heavy trucks before coming to Stanford and doing things like
building p1 in the upper right corner there that's an entirely student built
electric steer by wire drive by wire vehicle we've also instrumented vintage racecars
electrified a DeLorean which I'll show a little bit later and worked as Lex
mentioned with Shelley which is our self-driving Audi TT which is an automated race car in addition to the
Stanford work I was a co-founder of peloton technology which is a truck platooning firm looking at bringing
platooning technology so vehicle to vehicle communication which allows for shorter following distance out on the
highway so these are some of the things i've had a chance to work with to give you a little bit of a sense this is
shelley going around the racetrack at Thunderhill she can actually go up to about 120 miles an hour or so on that
track it's really just limited by the length of the straight it's kind of fun to watch from the outside a little
disconcerting occasionally as you see there's nobody in the car although from inside it actually looks all
pretty chill so Shelly we've been working with her for a while out on the
track she's able to get performance now which exceeds the capability of anybody on the
development team I'll even many of us are amateur racers in fact actually most of my PhD students
have their novice racing license we make sure that they get that license before going out on the track and testing so
Shelly could be in anybody in the research group she actually can beat the president of the track david Vaadin now
and we've had the opportunity to work recently with Junior Hildebrandt the IndyCar driver who finished six this
last year in the Indy 500 he's faster but but he's actually only about a
second or so faster on a minute and 25 second lap so we're approaching his
performance and he's actually helping us get there now the interesting thing about this is that we've approached this
problem really from one of physics force equals mass times acceleration so the car is really out there calculating what
it needs to do to break down into the next corner how much grip that it thinks it has and so forth as it's going around the track
it's not actually a learning approach at its core although we've added on top a
number of algorithms for learning because it turns out that the difference between the cars performance and the
human performance really getting that last little bit of capability out of the tires
humans drive instinctively in a way the best of humans at any rate drive instinctively in a way which is
constantly pushing to the limits of the cars capability and so if you sort of prejudge what those limits are you're
not going to be quite as fast and so that's one of the things we've actually been working with learning algorithms on
is to try to figure out well how much friction do I have in this particular corner and how is that changing as the
tires warm up and as a track warms up from the course of the morning till the afternoon these are the things that we
need to be fast on the racetrack but they're also the things that you need to take into account to be safe in the real
world because what we're trying to do with this project is understand how the car can drive at the maximum capability
of the limits of the friction between the tire and the road now racecar drivers do that to be fast as they say
in racing if you want to finish first you have to finish so it's important
that they actually be fast but also accident free so we're trying to learn the same things so that on the road when
you may have unknown conditions ahead of you the car can make the safest maneuver that's using all the friction in between
the tire in the road to avoid ultimately any accident that the car would be physically capable of avoiding that's
our goal with that so we've had a lot of fun with Shelley we've gotten to drive the car up Pikes Peak in the Bonneville
Salt Flats actually Shelley appeared in an Audi commercial with Zach Quinto and
Leonard Nimoy and so at the end of the commercial they both look at each other and declare it fascinating so if you're
as big of a science fiction fan as I am you realize that once your work has been declared fascinating by two Spock's
there's nowhere to go so I had to take a stint and try something different in
government and so I spent the last year as the first chief innovation officer at the US Department of Transportation
which I think honestly was the coolest gig in the federal government because I really didn't have any assigned
day-to-day responsibilities but I got to kind of dive in and help with all manner of really cool projects including the
development of the first federal automated vehicle policy so it's a really great opportunity to sort of see
things from a different perspective and so what I wanted to do was you know kind of coming into this from an engineer give you a perspective of what is it
like from somebody looking at the regulatory side on vehicle safety and how are they thinking about the technologies you're developing and where
does that actually leave some opportunities for engineers to make some big contributions to society so let's
What is vehicle safety
start with with what vehicle safety is like today so today we have a system of
federal motor vehicle safety standards so these are rules they're minimum performance requirements and each of
them must have associated with it an objective test so you can tell does the vehicle meet this requirement or does it
not meet this requirement now interestingly there is no federal agency that is testing vehicles before they are
sold we rely in this country on a system of manufacturers self certification so the
government puts these rules out there and manufacturers go we got this we can meet this and then they sell
certify and put the vehicles out on the market the National Highway Traffic Safety Administration can then purchase
vehicles and test them and make sure that they comply but we rely on manufacturers self-certification this is
a different system than in most of the rest of the world which actually has pre market certification where before you
can sell it the government agency has to say yes we've checked it and it meets all the requirements Aviation in this
country for instance has that aircraft require certification before they can be sold cars do not now where did that
system come from so a little quick history lesson in 1965 Ralph Nader released a book entitled unsafe at any
speed and this is often thought of as a book about the Corvair it's it's not the
Corvair featured prominently in there as an example of a design that Nader considered to be unsafe what was very
interesting about this this book was that he was actually advocating for things like airbags and anti-lock brakes
back in 1965 these technologies didn't come along until much later his argument
was that the auto industry had failed it wasn't a failure of engineering but it
was a failure of imagination and if you're interested in vehicle safety I would really recommend you read this book because it's fascinating they have
quotes from people in the 1960s basically saying that we believe that any collision more than about forty or
forty-five miles an hour is not survivable therefore there's no reason for seatbelts there's no reason for
collapsible steering wheels in fact there's a quote from somebody who made great advances in Road Safety saying I
can't conceive of what help a seatbelt would give you beyond like firmly bracing yourself with your hands those
of you who have studied physics know that's kind of patently ridiculous but there was a common feeling that there
was no sense of doing anything about vehicle crash worthiness because once you got above a certain speed it was
inherently unsurvivable and I think it's interesting to look at that today because if we were to be in a collision
I think if any of us were to be in a collision in around about 40 miles an hour in a in a modern automobile we'd
probably expect to walk away you know we wouldn't really be thinking about our survival and so what this did is it led
to a lot of public outcry and ultimately the National traffic and Motor Vehicle Safety Act in 1966 which established
nitzan established this set of federal motor vehicle safety standards now the process to get a new standard
made which is a rulemaking process in government is very time-consuming optimistically about the minimum time it
can possibly take is two years realistically it's more like seven and
so if you think about going through this process that's really problematic I mean
think about what we were talking about with automated vehicles two years ago or seven years ago I think about trying to
start seven years ago and make laws they're gonna determine how those vehicles operate on the road today it's
crazy right there's really no way to do that and the other thing is is that if you think about it our system evolved
from really this sense of failure of imagination that the government needs to say hey industry do this stop slacking
off these are the requirements get there but I think it's hard to argue today with all the advances in automation that
there is any failure of imagination on the part of industry people are coming up with all sorts of ideas and concepts
for new transportation and automation tech companies startup companies large OEMs there's all sorts of concepts being
tested out on the road it's hard to argue that there's still any lack of imagination now the question is are
things like this legal it's an interesting question right can I actually legally do this well from the
federal level there's an interesting report that came out about ten months ago from the folks across the street at
Federal motor vehicle safety standards
Volpe who did scan and said well what are the things that might prevent you based on the current federal motor
vehicle safety standards from putting an automated vehicle out on the road and the answer was honestly not much if you
have a vehicle if you start and you automate a vehicle that is currently meeting all the standards because there
are no standards that relate specifically to automation you can certify your vehicle as meeting the
federal motor vehicle safety standards therefore there's nothing at the federal level that prevents in general an
automated vehicle from being put on the road so it makes sense so if there isn't a safety standard
that you have to meet then you can put a vehicle out on the road that meets all the existing ones and does something new
and there's no federal barrier to that now there are a couple of exceptions there were a few points in there that
referenced a driver and in fact Nitsa gave a an interpretation of the rule
which is one of the things that they can do is to say well we're going to give an interpretation it's not making a new rule but basically interpreting the ones
that we have and they said that actually these references to the driver could in fact refer to the AI system and so that
actually is now a policy statement from from the department that many of the
references to driver in the federal motor vehicle safety standards can be replaced with your self-driving aai
system and the rules applied accordingly so in fact there's very little that prevents you from putting a vehicle out
on the road if it meets the current standards so if it's a modern production car automated federal motor vehicle
safety standards don't stop that now a lot of the designs that I showed though things that wouldn't have a steering wheel or other things are actually not
compliant because there are requirements that you have a steering wheel that you have pedals again these are best
practices that evolved in the days of course when people were not thinking of cars that could drive themselves and so
these things would require an exemption by Nitsa a process of saying that okay
this vehicle is allowed on the road even though it doesn't meet the current standards because it meets some equivalent and studying that equivalent
can be a bit of a challenge okay so the question then is well alright if the federal government is responsible and
that's by the traffic safety act is responsible for safety on the roads but it can't prevent people from putting
anything out what do you do right one approach is to say well let's get some federal motor vehicle safety standards
out there but as we already said that's probably about a seven year process and if you were to start setting in best
practices now what would that look like so we've got this challenge we want to encourage this technology to come out
Setting in best practices
onto the roads and be tested because that's the way you're gonna learn to get
the real-world data to get the real-world experience at the same time the federal government is responsible for
safety on the nation's roads it can recall things that don't work so if you do put your automated system out on the
highway and it's deemed to present an unreasonable risk to safety even if you're an aftermarket
manufacturer the government can tell you to take that off the road but the question is how can you do better how
can you be proactive to try to have a discussion here so we know standards are
maybe not the best way of doing that because they're too slow we'd like to make sure the public is protected but
this technology gets tested and so the approach taken to sort of provide some encouragement for this innovation while
at the same time looking at safety was the federal automated vehicle policy which rolled out in September so this
Federal Automated Vehicle Policy
was an attempt to really say okay let's put out a different framework from the
federal motor vehicle safety standards let's actually put out a system of voluntary guidance so what Anisa is
doing is to ask manufacturers to voluntarily follow certain guidance and
submit to the agency a letter that they have followed a certain safety assessment now the interesting thing is
is that the way that this is set up is not to tell manufacturers how to do something but really to say these are
the things that we want you to address and we want you to come to us to explain how you've addressed them with the idea
that from this best practices will emerge we'll be able to figure out in the future what really is the best way
of ensuring some of these safety items so this rolled out in September we've
got the BMI t car here on the side so you see you've got the Massachusetts
license plate so thanks to Brian for for bringing that if you do put gaudy stickers on your card then you get
closer to the center so that's something to consider for for for future future reference but this was was rolled out in
Washington Washington DC by the secretary and consists largely of of
Safety Assessment
multiple parts but I think the most relevant to vehicle design is this 15 point safety assessment so these are the
15 points that that are assessed and I'd like to kind of talk about a few of these in some more detail and it starts
with this concept of an operational design domain and minimal risk or fallback conditions and what
that means is instead of trying to put a taxonomy on here and say well your
automation system could be an adaptive cruise control that works on the highway or it could be fully self-driving or it
Operational Design Domain
might be something that operates a low-speed shuttle the guidance asked the manufacturers to define this and the
definition is known as operational design domain so in other words you tell us where your system is supposed to work
is it supposed to work on the highway is it supposed to work in restricted areas
can it work in all-weather or is this sort of something that operates only in
daylight hours in the sunshine in this area of South Florida all of those are fine but the it's incumbent upon the
manufacturer developer to define the operational design domain and then once you've defined where the system operates
you need to define how you make sure that it is only operating in those conditions how do you make sure the
system stays there and what's your fallback in case it doesn't and that fallback can be different
obviously if this is a car which is normally human driven as you see here from the volvo drive me experiment it
might be reasonable to say we're gonna ask the human driver to retake control whereas clearly if you're going to
enable blind passengers or you are going to have a vehicle that has no steering
wheel you need a different fallback system and so within the the guidance it
really allows manufacturers to have a lot of different concepts of what they want their automation to be so long as
they can define where it works what the fallback is in the event that it doesn't work and how you have educated the
consumer about what your technology does and what it doesn't do so that people
have a good understanding of the system performance a few things if we go down you see also validation methods and
ethical considerations are our aspects that are brought up here as well and so validation methods are really
Validation Methods
interesting as it applies to AI so really the idea is that there's lots of
different ways that you might tell an automated vehicle you might go out on the test track and run it through a
series of standard maneuvers you may develop a certain number of miles of experience driving in real-world traffic
and figure out how does the vehicle behave in a limited environment there's questions about a test track obviously
because you don't have the sort of unknowns that can happen in the real-world environment but if you test
in one real-world environment you also have a question of is this transferable information so if I've driven a certain
number of miles in Mountain View California does that tell me anything about how the vehicle is likely to
behave in Cambridge Massachusetts maybe maybe not it's a little bit hard to extrapolate
sometimes and then finally there's also the idea of simulation and analysis so if I can record these situations if I
can actually create a virtual environment of the sorts of things that I see on the road maybe I can actually
run the vehicle through many many of these scenarios perturbed in some way and actually test the system much more
robustly in simulation than I can ever actually do out on the road so the guidance is actually neutral on which of
these techniques manufacturers take and allow manufacturers to approach it in different ways and I think you know
based upon conversations when you think about the way customers are companies develop this they do take all these
different approaches a company like Tesla for instance which is recording all the data streams from all their
vehicles basically is able to run ideas or technologies silently in their
vehicle they can actually test systems out get real-world data and then decide whether or not to make that system
active companies that don't have that access to data really can't use that sort of development method and may rely
much more heavily on simulation or test track experience so the guidance really doesn't have this particular blend of
this and in fact it does envision that you might have over-the-air software updates in the in the future so it is
interesting though to think about whether you have data driven approaches things like artificial neural networks
or whether you actually start to program in hard and fast rules because as you
start to think about requirements on a system how do you actually set require on a system which has learned its
behavior and you don't necessarily know what the internal workings or our algorithms look like there's another one
Ethical Considerations
that that comes up which is the ethical consideration so I'm gonna pick on MIT for a moment here so this is an area
that I actually did a lot of work on with Stanford together with with some philosophers who join joined our group
and so when people hear ethical considerations in automated vehicles it often conjures up the trolley car
problem and and so this sort of classic formulation here about the fact that you
have a self-driving car which is heading towards a group of 10 people and it can either plow in and kill those 10 people
or it can divert and kill the driver what do you do and these are classic questions in philosophy you actually
look in fact at at the trolley car problem which is I have a runaway trolley car and I need to either divert
it to another track where it will kill somebody who's wandering across that track or the five people on the trolley car are killed what do I do well in fact
it's this article points out it's like you know before they the automated vehicles can become widespread car
makers must solve an impossible ethical dilemma of algorithmic morality so if all this wasn't hard enough I mean your
understanding how tough the technology is to actually program this stuff and then you have to get the regulations
right and now we actually have to solve impossible philosophical questions well
I don't think that's actually true and I think you know it's good for engineers to work with philosophers but not to be
so literal about this this is a question that philosophers can ask but engineers
might ask a number of different questions like who's responsible for the brakes on this trolley why wasn't there
a backup system I mean why am I headed into a group of 10 people without any
capability to stop so an engineer would in fact have to answer this question but
might approach it much differently so if I look at the trolley car problem I might say ok let's see my options are
I've got a trolley car which is out of control first of all I'd like to have an emergency braking system let's make sure
that I have that well there's a chance that that could break as well so my emergency if my base breaking system
goes and my emergency braking system goes my next option would be to divert it to this sidetrack well knowing that
that's my option I should probably put up a fence with a warning sign that says do not cross runaway trolley track okay
now let's say that I've done all of that the brakes fail the big emergency brakes
fail I have to divert the trolley and somebody has ignored my sign and crossed over the fence and now he's hit by the
trolley do I feel a little differently about this whole scenario and then I did at the beginning of just trying to
decide who lived and who died the solution was made but by thinking of it as an engineer trying to reduce risk and
not by thinking of levels of morality and who deserves to live or die and so I
think this is a very important issue and the reason it's in the guidance is not to get basically have everybody solve
trolley car problems but to try to think about these larger issues and so I think
ethics is is not just about these sorts of situations which actually will be in automated vehicles I think addressed
much more by engineering principles than by trying to figure out from philosophical merits who deserves to
live and die but there's broader issues here just any time that you have concern for human safety how close do I get to
pedestrians how close do I get to bicycles how much care should I put in
to other people in the environment that's very much an ethical question and
it's an ethical question that manufacturers are actually already addressing today if you look at the
automatic emergency braking systems that most manufacturers are putting on their vehicles they will actually use a
different algorithm depending upon whether that obstacle in front of it is a vehicle or a human so they're already
detecting and making a decision that the impact of this vehicle with the human could be far worse than the impact in
this vehicle with a vehicle and so they're choosing to brake a little bit more heavily in that case that's
actually where these ethical considerations come in and the idea of the guidance is to begin to share and have a discussion openly about how
manufacturers are approaching this with the idea of getting to a best practice where not only the people in
automated vehicles but other road users feel that there's an appropriate level of care taken for their well-being
that's one of the areas where ethics is important the other area where ethics is important is that we have different
objectives as we drive down the road we have objectives for safety we'd like to get there we have objectives for
mobility we'd like you to get there probably pretty quickly and we also have the idea of legality we'd like to follow
the rules but sometimes these things come into conflict with each other so let's say you're driving down the
Double Yellow Line
road and there's a van that's parked where it has absolutely no business parking you've got a double yellow line
is it okay to cross well at least in California there's no exception to the
double yellow line representing the lane boundary for a vehicle that's parked where it has no business being parked so
according to the vehicle code you're supposed to kind of come to a stop here I don't think any of us would right in
fact actually when you're in California and you're riding through the hills and you come upon a cyclist virtually every
vehicle on the road is deviating across the double yellow line to give extra room to the cyclists that's also not
what you're supposed to do by the vehicle code you're supposed to stay on your side of the double yellow line but slow to an appropriate speed to pass
right so there's behaviors where our desire for mobility or our desire for
safety are outweighing our desire for legality this becomes a challenge if you think about how do I program the
self-driving car should it be based on the way that humans drive or should it be based on the way that the legal code
tells me to drive of course the legal code was never actually anticipating a self-driving car from a human standpoint
that double yellow line is a great shorthand that says maybe there's something coming up here where you don't want to be in this other Lane but if I
actually have a car with the sensing capability to make that determination itself this is a double yellow line
actually all that meaningful anymore these are things that have to be sorted out speed limits being another one you
Speed Limits
know if we're out on the highway it's usually a little bit flexible do we give that same flexibility to the automated
vehicle or do we create this wonderful automated vehicle roadblocks of vehicles going to the
speed limit when nobody else around them is do we allow them to accelerate a
little bit to merge into the flow of traffic do we allow vehicles to speed if they could avoid an accident is our
desire for safety greater than our desire for legality these are the sort of ethical questions then I think are
really important these are things that need to be talked through because I believe if we actually have vehicles
that follow the law nobody will want to drive with them and so we need to think about either ways of giving flexibility
to the vehicles or to the law in the sense that vehicles can drive like humans do so this brings up some really
Learning and Programming
interesting areas I think with respect to learning and programming and so the question is you know should our
automated vehicles drive like humans and exhibit the same behavior that humans do or should they drive like robots and
actually execute the way that the law tells them that they should drive
obviously fixed rules can be one solution to this behavior learned from
human drivers could be another solution to this we might have some sort of balance of different objectives that we
do more analytically in terms of how much we want to obey the double yellow line when there are other things
influencing it in the environment now what's interesting is that is you start to think about this there's limits to
any of these approaches in the extreme you know as we found with our self-driving racecar if you're not
learning from experience you're not making use of all the data you're not gonna do as well and there's
no way that you can possibly pre program an automated vehicle for every scenario it's going to encounter somehow you have
to think about interpolating somehow you have to think about learning at the same time you can say well why don't we just
measure humans well human error is actually the the cause or a factor the
primary factor in 94 percent of accidents it's either a lack of judgment or lack of perception on the part of the
human so if we're simply following humans we're actually only learning how well humans can do things and we're
leaving a lot on the table in terms of the potential of the car and so this is a really interesting discussion that I
think will continue to be both in the development side of these vehicles in the policy side what is the
right balance what do I want to learn versus what do I want a program how do I avoid leaving anything on the table here
so because it's the point where you know I've had a bunch of slides with words here I want to give people a little bit
of a sense for what you could be leaving on the table if in fact you don't adapt
Marty Marty
this is Marty marty is a DeLorean that we've been working with in my lab now DeLoreans are
really fantastic cars unless you want to accelerate brake or turn it really
didn't do any of those things terribly well there's no power steering there's an underpowered engine and and very
small brakes all of these things are fixable in fact what's nice about the DeLorean is it separates quite nicely
the whole fiberglass tub comes up you can take out the engine you can take out
the brakes you can make some modifications to the frame stiffen the suspension work with renova motors start
up in Silicon Valley to put in a new electric drivetrain and put it all back
together and when you do you come up with a car that's actually pretty darn fun and when we've programmed to drive
itself this is Adam Savage from Mythbusters going along for a drive
[Music]
what do you see is Marnie doing something at a level of precision that we're pretty sure no human driver can
meet Junior said there's no way he can do this you see it's going into a perfect drift doing a perfect doughnut
around this cone and then it launches itself through the next gate sideways
into the next cone now it's doing this you see it shoots through the gate missing those cones and then launches
into a tight circle around the next cone it's actually doing this as sort of an algorithm similar to orbital mechanics
if you think about how it's how it's actually orbiting these different points as it sets the trajectory now the limit
on this as tires as you can see as it comes around here the tires disintegrate into many chunks flying at the camera as
we do this but the the ability of the car to really continue even as the tires
heat up to execute this pretty pretty nice trajectory here you see it going through the gates again and launching
into a stable equilibrium putting pretty much the tire tracks right over where they were in the previous run and then
finally ending so this is a sort of thing that I think is possible as you
The Potential
look at these vehicles there's a huge potential out there for these things to not drive about as well as an average
human but to far exceed human performance in their abilities to use
all the capabilities of the tires to do some amazing things so maybe that's not the way that you want your your daily
drive to go although when we first posted some of this some of this video one of the commenters was like I want
this car that way I can like go into the store to buy donuts while it sits in the parking lot doing donuts wasn't a use
case that I had thought of but that's one of one of the things that we thought of this really how if you limit yourself
to only thinking about what the tires can do before they get to the saturation
of the friction in the road you're only taking to account one class of trajectories there's a lot more beyond
that that could be very advantageous in some emergency situations would it be great if the car had access to that now
that's not a way that we're going to get if we only sort of monitor day to day driving we're not going to get that
capability in our cars so one other aspect that came through in the in the
Data Sharing
policy which I think is extremely important as we think about neural networks and learning is this idea of
data sharing and there's a huge potential to accelerate the development of automated vehicles if we can share
some information about edge case scenarios in particular so if you think
about trying to train a neural network to handle some extreme situations that's really much easier if your set of
training data contains those extreme situations right so if you think about the weird things that can happen out on
the road if you had a database of those and those comprised your training set you'd have a head start in terms of
being able to get a neural net where I can begin to validate that it would work in these situations so the question is
you know is there a way for the ecosystem around self-driving cars to actually share some of this information so that different players can actually
share some information about the critical situations and be able to make sure that if you learn something that
yes you can make your cars safer but actually all the cars out on the road gets safer now clearly you need to
balance this with some other considerations there's there's the intellectual property concerns of the company there's privacy concerns of any
individuals who might be involved but it does seem to me that there's a big potential here to think about ways of
sharing certain data that can contribute to safety and this is a discussion
that's going to be ongoing and I think academia can do a lot to sort of help broker this discussion because you know
the first level people say you know data sharing I don't know companies aren't going to share we're not going to get the
information we need but most of the time people stay in the abstract as opposed to saying well what information would be
most helpful what information it's really going to give people confidence in the safety of these cars it's gonna
let regulators understand how they operate and at the same time is going to protect the amount of development effort
that companies put in there I think there is a solution here and in fact if you look at aviation there's a really
good example that already exists it's known as the Esaias system it's started with only four Airlines
that decided to share safety information with each other and this goes through mitre which is a federally funded R&D
center and it's actually now up to 40 Airlines and if companies get kicked out
of the mitre a project they really try very hard to get back in now this is anonymized data its anonymized data so
that you know companies actually get a assessment of what their safety record
is like and they can compare it to other airlines in the abstract but they can't compare it to any identifiable airline
so there's no ranking of this it's not used for any enforcement techniques and
it took people a long time to kind of build up and begin to share that but now there's a huge amount of trust and
they're sharing more and more data and looking at ways that they can perhaps actually start to code in things like
weather and time of day which had been removed for anonymization purposes and the original version of the system so I
think there's some good examples out there and this is something that's very important to think about for automated
vehicles and I think as this discussion goes forward those of you who are interested in developing these vehicles
using techniques that rely on data are going to be an important voice for the
importance of data sharing I think there's a there's a large role here to kind of make people aware that this
actually does have value in the larger ecosystem so this is something that I
was able to work on more broadly as well so I was part now is the d-o-t representative on the National Science
and Technology Committee's Subcommittee on machine learning and artificial
intelligence and this was one of the recommendations that was really pushed forward as well because AI has tended to
really make great advances with the availability of good datasets and in order to make those sort of good
advances in transportation this group is also advocating that those datasets need
to be made broadly available so this is a little bit about the vision behind the
Automated Vehicle Policy
the automated vehicle policy what the goal was to really achieve here the idea
of trying to move towards a proactive safety culture not to necessarily put in regulations prematurely and try to set
standards honestly we don't know the best way to develop automated vehicles but to allow the government to kind of get involved
in discussions with manufacturers early and be comfortable with what's going out on the roadway and actually to kind of
help the u.s. to continue to play a leading role in this obviously if vehicles are going to be banned from the
roads it would be very difficult for the country to continue to be a place where
people could could test and develop this technology and then the belief really that there can be an acceleration of the
safety benefits of this through data sharing so each car doesn't have to encounter all the weird situations
itself but in fact can learn from what other vehicles experience and the idea
is that really this is meant to be an evolving framework so it comes out as guidance it really generates
conversations it generates best practices which can eventually evolved into standards and law and there's a
huge opportunity here because the belief isn't that the National Highway Traffic Safety Administration will be doing all
of the development of these best practices but that that'll really evolve from what companies do and what all of
us at universities are able to do to sort of generate ways to solve these problems in creative manners ways to
actually keep the innovation going but ensure that we have safety so as you
start to think about all of the AI systems that you're developing and you start to flip around a little bit and think about how does a regulator gonna
get comfortable that it's not going to do something weird these are great research questions I think these are
great practical questions and these are things that will need to be worked out going forward so I you with that as a
challenge to think about to think as you take this course not only about the technology that you're learning but how
do you communicate that to other people and where are the gaps that need to be
filled because I think you'll find some great opportunities for for research startup companies and ultimately work
with policy and government there so thanks for the opportunity to talk to all of you and I want to stop there
because probably the things that you want to talk about are more interesting than the things that I wanted to talk about so I'm happy to take questions
along there
good we had a quick hand here yeah
Safety Requirements
accidents were part of our economies the excess rates are extremely low do you
think some of these safety requirements may roll back like I do I think that's a
great question and okay so the question thanks for reminding me so the question was whether in the future when you have
all vehicles automated would we be able to actually roll back things like
airbags and seatbelts and other things that we have on there what we might know is as passive safety devices in vehicles
I believe that we will in fact actually one of the things that I think is most extraordinary if you think about this
from a sustainability standpoint when you look at the average sort of mass of vehicles and average occupancy of
vehicles in the u.s. you know with single with passenger cars we're using maybe about ninety percent of the energy
to move the vehicle as opposed to moving the people inside and one of the reasons for that is crashworthiness standards
which are great because that's what's enabled us to be surviving these crashes at 40 miles an hour but if we do have
vehicles that are not going to crash or if they are going to have certain modes which might be designed with very
carefully design you know crush areas or things like this we could potentially
take a lot of that mass out particularly if these are low-speed vehicles which are designed only for the urban environment and they're not going to to
crash because they're going to drive you know somewhat conservatively or in some ways separated from pedestrians then I
think you can get a lot of the mass out and then you start to actually have transportation options which you know
from an environmental standpoint are comparable to cycling so so I think I think that's actually a really really
good goal to strive for although we either have to kind of limit the environment or think in the far future
with some of those techniques
Learning from Humans
to apply it which you guys learn
good yeah that's a great question so what are we what are we doing with Shelly is our mission really just to
drive as fast as possible and faster than a human or are we trying to learn from this something that we can apply to
other automated vehicles it really is a desire to learn from other automated you
know for the development of other automated vehicles and we've often said that at the point where you know the
difference between Shelly's performance in the human driver you know starts to be really mundane things like you know
our shift pattern or something which isn't applicable we kind of lose interest at that however you know up to
this point every insight that we've gotten from Shelly has been directly transferable and we've programmed the
car to do some emergency lane changes in situations where you don't have enough room to brake and we've actually been
demonstrating in some cases that the car can can do this much faster than a human
even an expert humans response can be so there's certain scenarios that we've done like that and I would say from the
bigger picture what's really fascinating is that we originally started out with this idea of let's find the best path
around the track and track it as close as we can but in fact when you look at human race car drivers what they're
doing is actually very different they're pushing the car to the limits and then sort of seeing what paths that opens up
to them and it flips the problem a bit on its head in a way that I think is actually very applicable for developing
safety systems out on the road but it's not a way that people have looked at it to the best of my knowledge up to this
point and so you know that's really what we're hoping is that the inspiration in trying to reproduce human performance
there leads us to better safety algorithms so long you know so far that's been the case and when that
ceases to be the case I think we are definitely much less interested
yeah so so liability is a good question so what what who is liable if I can can
Liability
sort of rephrase you know for an accident in an automated vehicle on the
one hand that's kind of an open question on the other hand we do have a court system and so whenever there are new
technologies these things are actually generally figured out in the courts and it can be different from state to state
so this is one aspect where you know potentially some discussions so that manufacturers aren't subject to
different conditions in different states would be helpful but the way that it works now is that it's it's usually not
binary we have in the US a sense of joint and several liability and so you
can actually assign different portions of responsibility to different players in the game you have had companies like
Volvo and in fact Google make statements that if there are vehicles are involved in accidents then they would expect to
be liable for it so people have often talked about needing something really
new for liability but I'm not sure that's the case we do have a court system that can ultimately figure out
who is liable with new technologies and we have some manufacturers that are starting to make some statements about
assuming product liability for that the one thing that really could be helpful as I mentioned is perhaps some
harmonization because right now insurance is something that is set state-by-state and so the rules in one
state as to who's at fault for an accident may be very different in another state
Safety
okay so what what if companies you know as they send in the safety letters are are using criteria to set safety that
that may not be broadly acceptable to the to the public whether the public would like these vehicles to have
greater safety I think you know the the nice thing about this process is first of all we would know that right so we
would have a sense that companies are developing with certain measures of
safety in mind and there could actually be a discussion as to you know whether that is setting an acceptable level it's
it's a difficult question because it's it's not clear that people really know what an acceptable level is is it does
it have to be safer than then humans drive now you know my personal feeling I would say yes and does it have to be
much much safer well that that's hard to say you know you start to then get into
the situation of we're comfortable to a certain extent with our existing legal system and with the fact that humans
could cause errors that have fatal consequences do we feel the same way about machines right you know we tend to
think the machines really should to have a higher level of perfection so we may as a society be less tolerant people
will often say well so long as the overall national figures go down that would be good but that's really not
going to matter much to the families who are impacted by an automated vehicle particularly if it's a if it's a
scenario with very very bad optics and what do I mean by that it's if you think
about the failures of mechanical systems because they're different than the failures of human beings they can often
like look really bad right if you sort of think about a vehicle that doesn't detect something and then just continues
to plow ahead you know visually that's that's really striking and that's the
sort of thing that you know we'd get replayed and be in people's consciousness and raise some fears and so you
I think that's that's an issue that's going to have to be have to be sorted out these are average being different
Policy
you know between research in other parts of the world to exchange technologies
yes so that's that's a good question what's being done really from a global standpoint to sort of share ideas to
share research and to kind of work through some of these things particularly on the policy side so most of the auto manufacturers are global
corporations and so a lot of the research in this is done in very different parts of the world so
renault-nissan for instance is doing a lot in Silicon Valley in Europe and and in Japan and I think you see a lot of
that with the different manufacturers one of the cool things that I got to do as part of my role was to go with the
Secretary of Transportation to the g7 transportation ministers meeting in Japan and address the ministers about
sort of the the u.s. policy on on automated vehicles and one of the parts
of that discussion was well the US has a very different set of rules so we have
this manufacturer self certification as opposed to pre market certification but testing for instance is something that
has to be done regardless so either it's testing that's done by a manufacturer or it's testing that's done by for instance
in you know in Germany the the the tooth and other agencies that are responsible
for for road safety and so the idea is maybe we should be sharing best
practices on testing so we have a set of standard tests and then manufacturers across the globe could test to a certain
set of standards that might be translated differently according to the policies and regulate or e environments
in different countries so that was that was part of the idea that we advanced at the g7 and it seemed to kick off really
well I never had a conscious decision on
this I actually got a call from the White House one day you know and and you know I got this message just or this
email you know I'm reaching out for the White House when you give my call you know give me a call back so of course I called back immediately and Pam Coleman
on the other end of the line it's like I love doing that she's like you know when you're calling for the White House everybody returns your call and and so
honestly you know the she said here's the situation we're looking at a lot of these areas in the Department of
Transportation that seem to hit upon your areas of expertise we want to talk about where with you in some way the holy grail
would be for you to come out and work in DC for a while and then I got a call from the Department of Transportation
and they're like well we know you wouldn't want to come out to DC for a while oh my god try me could I do you no could I do cool
stuff and could I make an impact and then you know I met with the Secretary of Transportation out in San Francisco
and you know he assured me he's like you would be surprised you would be very surprised at how much of an impact you
could have and this ended up being really true a lot of times this stuff
moves quickly and people who are involved in policymaking may or may not have a technical background in this they may have come through the campaign for
instance and then ended up in political roles yet the folks that I worked with we're really trying to get good
information and make good decisions and so I just kept getting called in for advice on all sorts of things and I
found that people actually really wanted to have that technical information and then used it so so that that's the way
it happened it seemed like it was an opportunity to take things that I've worked on as I mentioned you know automated vehicles since 1992 and then
to be part of this policy development which went really quickly it was a one-page outline when I arrived in
February and then in September it rolled out and along the way it was all sorts of editing and negotiations the White
House and other agencies fascinating fascinating process so so I kind of fell
into this but you know as Lex mentioned I think I'm emerging as a policy wonk here because it was a it was a very fun
experience you have a lot of companies
Sharing data
that have somewhat of a monopoly on a lot of data especially like Google has so much more data available yeah a lot
of the smaller startups how do you incentivize companies actually share their data good
companies to share their data when they have an awful lot in invested in them in
that in the gathering of that data and being able to process that data and I think the answer is to start small and
to try to say are there certain high value things they could again make the public comfortable make policymakers
comfortable that really aren't going to be a burden on the company you know so so one of the you know one of the things
that from the peloton standpoint that was bounced around at one points are our trucks actually use vehicle-to-vehicle
communications as part of their link well when you do that you discover that there's actually an awful lot of places
where that drops out because cell phone towers which are not supposed to be broadcasting on that frequency seem to
create an awful lot of interference there well that can be very interesting from a public policy perspective to know
you know where are you know we were sort of monitoring for incursions in that in that frequency range everywhere we go
that for instance might be very useful piece of information to share with policymakers that wouldn't be any real
proprietary issue to share from the company's perspective and so I think
that the trick is to start small and find what are the high-value data where there isn't a big issue of sharing I
mean if you go to Google and say all right Google what will it take for you to share all of the data you're
acquiring from your entire self-driving car program I guess way mo now I think that would be a very big number and so I
don't think that's the starting point I think you start with you know what is the high value data data that's of high value for the public policy sense and
really minimal hassle to the to the companies I don't know how much longer
I'm happy to stay in and and answer it answer as many questions but I know you
have a class to run how are we okay good yes
Accident data simulations
[Music] no standards for sharing that data accident data simulations good is there
any effort underway for for sharing map data some of the edge case accident data
simulation capabilities and things like that this is one of the next steps that MIT se outlined in the policy and so
there are people at admits actually working on taking some of these next steps again is sort of a pilot or
prototype mode so so that's something that's that's currently being worked on in the in the department you could
probably expect to hear more from in the not so distant future
Testing in urban and rural environments
but executing our production our to be happy
okay so the question is testing in urban and rural environments or even driving in urban and rural environments are very
different in should that the government actually come up with a standard set of data that all companies have to attest
to I think one of the reasons that the policy was designed the way it was was
to make sure we have this concept of operational design domain so in fact if
the only area that I've mapped and the only area that I want to drive is say in
a campus environment or in one quarter square mile then then the idea is that
we would like the companies to explain how they handle the eventualities in that one quarter square mile but they
should really have no reason to handle other situations right because their vehicle won't encounter that so long as
it's been designed to stay within its operational design domain so I think in the short term you know what you see is
people often looking at hyperlocal solutions or kind of the low-hanging fruit for for a lot of automation and
even if you think about offering mobility as a service if I'm gonna offer a sort of a an automated taxi I'm
probably going to do that in a limited environment to start with and so if I'm only doing this in Cambridge does it
really matter if I can drive in Mountain View or not and so you know I think the idea is to start with the definition of
the operational design domain with a data set that is appropriate for that operational design domain and then as
people's design domains start to expand nationwide then I think you know the idea of common data sets starts to be
starts to be interesting although you know there is a sense that no finite data set is really going to capture
every eventualities and so you know people will be able to develop or sort of you know design to
the test in some ways is that sufficient I think it'll make people feel better but I I personally wonder how much value
there is you know it seemed it with test track testing I could think of 20 different tests that automated vehicles
will have to pass and people will design ways to pass all 20 of those tests it may make some people more comfortable
but it doesn't make me all that much more comfortable that they'd be able to handle a real-world situation
all right let's see could you could you
Opensource cars
make an open-source car under okay so the question is could you make an open-source car under the the guidance
provided by us do t the question would
be you know this from from a practical question you're supposed to submit a safety assessment letter which is
supposed to be signed by somebody responsible for that and so an issue if
you were to open source would be you know do I use this module and who is actually signing signing off on out what
I feel comfortable signing off on something which I then allowed to be open source I you know not a lawyer but
I would think that you know I don't think there would be anything that would prevent that if you had a development
team that was doing that and people who are willing to sign off on whatever version of the software was actually
used in an open source car you know I will say that the the guidance does
apply to universities or to or to other groups that would be putting a car out
on the road and I think if you look through the 15 points they're not really meant to be overly restrictive in fact I
would argue that pretty much any group that is going to sort of put real people at risk by by putting an automated
vehicle out on the road should really have thought through these things so I don't think it's a I don't think it's a terribly high high burden to to meet I
think it would be you know it would be me double by a group it's just a question would be you know from the open source sense how do you sort of trace
who's responsible and who's signing off on that alright I think we gave those
third graders or run for their money yeah absolutely thank you so much let's give Chris a big hand
great thanks a lot [Applause]

----------

-----

--19--

-----
Date: 2017.02.18
Link: [# MIT 6.S094: Deep Learning for Human-Centered Semi-Autonomous Vehicles](https://www.youtube.com/watch?v=ByZF8_-OJNI)
Transcription:

The human side of AI, how do we turn this camera
back in on the human, we are talking about perception,
how to detect cats and dogs, pedestrians lanes,
how to steer a vehicle based on the external environment, the thing that's really fascinating and severely understudied,
is the human side, we talked about the Tesla, we have cameras in 17 Tesla's driving around Cambridge
because Tesla is one of the only vehicles allowing you
to experience in a real way, on the road, the interaction between the human
and the Machine, the thing that we don't have,
that deep learning needs on the human side of semi-autonomous vehicles and fully-autonomous vehicles
is video of drivers, that's what we're collecting, that's what my work is in, is looking at billions
of video frames, of human beings driving 60 miles an hour plus on the highway
in their semi-autonomous Tesla, what are the things that we want to know about the human?
If we were a deep learning therapist, we’d try to break apart
the different things we can detect from this raw set of pixels, we can look here, from the green to red
is a different detection problem, a different computer vision detection problem green means it's less challenging,
it's feasible, even under poor lighting conditions, variable pose, noisy environment, poor resolution,
red means it's really hard no matter what you do, that's starting on the left with face detection body pose,
one of the best studied and one of the easier computer vision problems, we have huge datasets for these,
then there is micro saccades, the slight tremors of the eye that happen at a rate of a thousand times a second.
All right let's look at— First, why do we even care
about the human in the car? One is trust, this trust part is a— If you think about it,
to build trust the car needs to have some awareness of the biological thing
it's carrying inside, the human inside, you assume the car knows about you, because you're sitting there controlling it,
but if you think about it, almost every single car on the road today, has no sensors
with which it's perceiving you, it knows, some cars have a pressure sensor on the steering wheel
and a pressure sensor or some kind of sensor detecting that you're sitting in the seat,
that's the only thing it knows about you, that's it, so how is the car supposed to—
this same car is driving 70 miles an hour, on the highway, autonomously, how is it supposed
to build trust with you if it doesn't perceive you? That's one of the critical things here,
so if I'm constantly advocating something, is that we should have a driver facing camera in every car,
despite the privacy concerns, you have a camera on your phone and you don't have as much
of a privacy concern there, but despite the privacy concerns, the safety benefits are huge, the trust benefits are huge.
Let's start with the easy one, detecting body pose, why do we care?
There is a seatbelt design, there are these dummies,
crash-test dummies, which we can use to design the passive safety systems of our cars,
and they make certain assumptions about body shapes, male, female, child, body shapes, but they also make assumptions
about the position of your body in the seat, they have the optimal position, the position they assume you take,
the reality is, in a Tesla, when the car is driving itself,
the variability, if you remember the deformable [unintelligible 00:04:44] you start doing a little bit more of that, you start to
reach back in the back seat, in your purse, your bag, for your cell phone, these kinds of things,
that's when the crashes happen, we to know how often that happens, the car needs to know that you're in that position,
that's critical for that very serious moment when the actual crash happens,
how do you do? This is deep learning class, this is deep learning to the rescue,
whenever you have these kinds of tasks, of detecting for example body poses, you're detecting points of the shoulders, points of the head,
five-ten points along the arms, the skeleton.
How do you do that? You have a CNN, convolutional neural network, that takes its input image and takes an output,
it's a regressor, it gives an XY position of whatever you're looking for, the left shoulder, right shoulder,
then you have a cascade of regressors they give you all of these points, they give you the shoulders, the arms and so on,
then you have— through time on every single frame you make that prediction
and then you optimize, you can make certain assumptions about physics,
your arm can't be in this place in one frame and then the next frame be over here, it moves smoothly
through space so under those constraints you can then minimize the error--
the temporal error from frame to frame or you can just dump all the frames,
as if there are different channels like RGB is three channels, you can think of those channels as in time,
you can dump all those frames together, and that's what I call 3D convolutional neural networks,
you've dumped them all together and then you estimate the body pose in all the frames at once.
There are some data sets for sports and we're building our own— I don't know who that guy is—
Let's fly through this a little bit, so what's called gaze classification,
gaze is another word for glance, it's a classification problem,
here's one of the TAs for this class, Not here because he's married, he had to be home,
I know were his priorities are at, this is on camera, he should be here, [chuckles]
There's five cameras, this is why we're recording in the Tesla. This is a Tesla vehicle, in the bottom right, there's a blue icon
that lights up automatically detected if it's operating under autopilot, that means the car is currently driving itself,
there's five cameras one on the forward roadway, one on the instrument cluster, one on the center stack, steering wheel, his face,
then it's a classification problem, you dump the raw pixels into a convolutional neural network, have six classes forward roadway,
you're predicting where the person is looking, forward roadway, left, right,
center stack, instrument cluster, rearview mirror, and you give millions of frames
for every class, simple. And It does incredibly well at predicting
where the driver is looking, the process is the same for majority of the driver state problems that have to do with the face,
the face has so much information, where are you looking, emotion, drowsiness, different degrees of frustration,
I'll fly through those as well, but the process is the same, there's some pre-processing, this is in the wild data,
there's a lot of crazy light going on, there's noises, vibration from the vehicle, so first you have to—
video stabilization you have to remove all that vibration, all that noise, as best as you can, there's a lot of algorithms,
non-neural network algorithms, boring but they work
for removing the noise, removing the effects of sudden light variations and vibrations of the vehicle,
there's the automated calibration, so you have to estimate the frame of the camera, the position of the camera,
and estimate the identity of the person you're looking at. The more you can specialize the network to the identity of the person
and the identity of the car the person is riding in, the better the performance for the different driver state classification.
So you personalize the network, you have a background model that works on everyorne and you specialize each individual,
this is transfer learning, you specialize each individual network to that one individual.
There is a face frontalization, fancy name for the fact that no matter where they're looking,
you want to transfer that face so the eyes, nose are the exact same position in the image, that way if you want to look at the eyes
and you want to study the subtle movement of the eyes the subtle blinking, the dynamics of the eyelid, the velocity of the eyelid,
it's always in the same place so you can really focus in remove all effects of any other motion of the head,
and then you just— it's the beauty of deep learning, there is some pre-processing, because this is real-world data,
but you just dump the raw pixels in, you dump the raw pixels in and predict whatever you need.
What do you need? One is emotion, You can have— I had a study where people
used a crappy and a good voice based navigation system, so the crappy one got them really frustrated,
and they self-reported it as the frustrating experience or not on scale one to 10, that gives us ground truth,
a bunch of people to used this system, they put themselves as frustrated or not,
so then we can predict, we can train a Convolutional neural network to predict is this person frustrated or not, I think we've seen a video of that,
turns out smiling is a strong indication of frustration, you can also predict drowsiness in this way,
gaze estimation in this way, cognitive load, I'll briefly look at that, the process is all the same,
you detect the face, you find the landmark points in the face, for the face alignment, face frontalization,
and then you dump the raw pixels in for classification, step five. You can use SVM's there
or you can use what everyone uses now, convolutional neural networks.
This is the one part where CNN's still struggle to compete, is the alignment problem,
this is why I talked about the Cascade regressors, is finding the landmarks on the eyebrows, the nose,
the jawline, the mouth, there are certain constraints there,
so algorithms that can utilize those constraints effectively can often perform better than end-to-end regressors
that just don't have any concept of what a face is shaped like. There are huge data sets and we're a part
of the awesome community that's building those data sets for face alignment.
This is the TA in its younger form,
this is live in the car, the real time system predicting where they're looking,
this is taking slow steps towards the exciting direction
that machine learning is headed, which is unsupervised learning, the less you have to have humans look to the data
and annotate that data, the more power these machine learning algorithms get,
currently supervised learning is what's needed, you need human beings to label a cat and label a dog,
if you can only have a human being label 1%, one tenth of a percent of a data set, only the hard cases,
so the machine can come to the human and be like, I don't know what I'm looking at in these pictures,
because of the partial light occlusions, we're not good at dealing with occlusions,
whether it's your own arm or because of light conditions, we're not good with crazy light drowning out the image,
this is what Google self-driving cars struggle with when they're trying to use their vision sensors, moving out of frame,
all kinds of occlusion They are really hard for computer vision algorithms,
and in those cases we want a machine to step in and say-- and pass that image on to the human, be like "help me out with this"
and the other corner case is, in driving for example 90 plus percent of the time all you're doing is
staring forward at the roadway the same way, that's where the Machine shines, that's where machine automated annotation shines,
because it's seen that face for hundreds of millions of frames already, in that exact position,
so it can do all the hard work of annotation for you, it's in the transition away from those positions
that it needs a little bit of help, just to make sure that this person just started looking away
from the road to the rear view, and you bring those points up, so you're-- there's a— using optical flow,
putting the optical flow in the convolutional neural network, you use that to predict when something has changed
when something has changed you bring that to the machine for annotation all of this is to build a giant—
Billions of frames annotated data set, our ground truth, on which you train your driver state algorithms,
in this way you can control, on the x-axis is the fraction of frames the human has to annotate,
zero percent on the Left, ten percent on the right, and then the accuracy trade-off, the more the human annotates,
the higher the accuracy, you approach 100% accuracy, but you can still do pretty good, this is for the gaze classification task,
With an 84-- 84 fold to almost towards the magnitude reduction in human annotation,
this is the future of machine learning, and hopefully one day no human annotation,
and the result is millions of images like these video frames,
same thing, driver frustration, this is what I was talking about, the frustrated driver is the one that's on the bottom,
so a lot of movement of the eyebrows and a lot of smiling, and that's true subject after the subject,
And they're Happy, the satisfied, I don't want to say happy, the satisfied driver is cold and stoic,
and that's true for subject after subject, because driving is a boring experience and you want it to stay that way
Yes, question.
Great, great question, they're not--
Absolutely, that's a great question So these cars owned by MIT, there is somebody in the back—
The comment was— my emotions then have nothing to do with the driving experience.
Yes, let me continue that comment, your emotions are often—
You're an actor on the stage for others with your emotion, when you're alone, you might not express emotion,
you're really expressing emotion oftentimes for others, your frustration is like "What the heck"
that's for the passenger, and that's absolutely right, so one of the cool things we're doing—
As I said, we now have over a billion video frames in the Tesla, We're starting to collected huge amounts of data in the Tesla,
emotion is a complex thing, in this case, we know the ground truth, how frustrated they were,
in naturalistic data, when it's just people driving around, we don't know how they're really feeling at the moment,
we're not asking to enter an app "how are you feeling right now?" but we do know certain things, we know that people sing a lot,
that has to be on paper at some point, it's awesome, people love singing,
so that doesn't happen in this kind of data, because there's somebody singing in the car, and I think the expression of frustration is also the same.
Yes. The question is— or the comment is that the solo data set is probably going to be very different
from a data set that's not solo, with a passenger, that's very true, the tricky thing about driving
this is why it's a huge challenge for self-driving cars for the external facing sensors and for the internal facing sensors analyzing human behavior,
is 99.9% of driving is the same thing, it's really boring.
So finding the interesting bits is actually pretty complicated, so that has to do with emotion, that has to do with—
so singing is easy to find, we can track the mouth pretty well, so when you're talking of singing we can find that,
but how do you find the subtle expressions of emotion? It's hard, when you're solo.
Cognitive load, that's a fascinating thing,
I mean, similar emotion it's a little more concrete in a sense that there's good science and ways to measure cognitive load,
cognitive workload, how occupied your mind is, mental workload is another term used,
the window to the soul, the cognitive workload soul is the eyes,
so pupil— first of all the eyes move in two different ways they move in a lot of ways but two major ways is saccades,
these are these ballistic movements, they jump around whenever you look around the room, they're actually just jumping around,
when you read the eyes are jumping around, Like if all of you just follow this bottle with your eyes,
your eyes are actually going to move smoothly, a smooth pursuit. Somebody actually told me today,
that probably has to do with our hunting background as animals,
I don't know how that helps, like frogs track flies really well, so you have to like— Anyway, the point is
there are smooth pursuit movements where the eyes move smoothly, and those are all indications of certain aspects of cognitive load,
and then there are these very subtle movements, which are almost imperceptible for computer vision and these are micro saccades, these are tremors of the eye,
a work from here, from Bill Freeman, magnifying those subtle movements, these are taken at 500 frames a second.
So cognitive load— when the pupil, that black dot in the middle,
in case you don't know what a pupil is, in the middle of the eye, when it gets larger that's an indicative of high cognitive load,
but it also gets larger when the light is dim. So there's this complex interplay,
so we can't rely in the wild outside, in the car, or just in general outdoors,
using the pupil size, even though pupil size has been used effectively in a lab to measure cognitive load, it can't be reliably used in the car,
the same with blinks, when there's a high cognitive load, your blink rate decreases and your blink duration shortens,
I think I'm just repeating the same thing over and over, but you can imagine how we can predict cognitive load,
We extract a video of the eye. Here is the primary eye of the person the system is observing,
happens to be the same TA once again.
We take the sequence of 100-- it's 90 images, that's six seconds,
16 frames a second, 15 frames a second, we dump that into a 3D convolutional neural network,
that means it's 90 channels, it's 90 frames, grayscale,
and then the prediction is one of three classes of cognitive load,
low cognitive load, medium cognitive load and high cognitive load, there's ground truth for that, because we have people--
over 500 different people do different tasks of various cognitive load, and after some frontalization again,
where you see the eyes are traced no matter where the person looking,
the image of the face is transposed in such a way that the corner of the eyes remain always in the same position,
after the frontalization, we find the eye, active appearance models, find 39 points of the eyelids, the iris,
and four points on the pupil.
Putting all of that into a 3D CNN model, they're positioned,eye sequence on the left, 3D CNN model in the middle,
cognitive load prediction on the right. This code by the way is freely available online.
All you have to do, dump a web-cam from the video stream, CNN runs faster than real-time,
predicts cognitive load. Same process as detecting the identity of the face,
same process as detecting where the driver is looking, same process as detecting emotion
and all of those require very little hyper parameter tuning on the convolutional neural networks,
they only require huge amounts of data.
Why do we care about detecting what the drivers doing? I think Eric has mentioned this is--
On the-- Oh man, this is the comeback of the slide, [laughter]
I was criticized for this being a very cheesy slide, in the past towards full automation,
we're likely to take gradual steps towards that.
I can't, it's enough of that, this is better— Especially given that— This is given today,
our new president, this is a pickup truck country,
this is a manually controlled vehicle country, for quite a little while, we like control
and control being given to somebody else, to the machine, will be a gradual process,
it's a gradual process of that machine earning trust, and through that process, the machine,
like the Tesla, like the BMW, like the Mercedes, the Volvo,
that's now playing with these ideas, it's going to need to see what the human is doing,
and for that, to see what the human is doing,
we have billions of miles of forward-facing data, what we need,
is billions of miles of driver facing data as well. We're in the process of collecting that,
this is a pitch for automakers and everybody to buy cars
that have a driver facing camera. And let me close--
I said we need a lot of data but I think this class has been—
through your own research you'll find that we're in the very early stages
of discovering the power of deep learning,
for example, recently, Jean [?] said
that it seems that the deeper the network, the better the results in a lot of really important cases,
even though the data is not increasing, why does the deeper network give better results?
This is a mysterious thing we don't understand, there's these hundreds of millions of parameters,
from them is emerging some kind of structure, some kind of representation of the knowledge that we're giving it.
One of my favorite examples of this emergent concept is the Conway's Game of Life.
For those of you who knows what this is, will probably criticize me for being as cheesy
as the stairway slide, but I think it's such a simple
and brilliant example of how-- Like a neuron in a neural network
is a really simple computational unit, and then incredible power emerges when you combine a lot of them
in a network, in the same way, this is called the cellular automata,
that's a weird pronunciation,
every single cells is operating under a simple rule, you can think of it as a cell living and dying,
it's filled in black when it's alive and white when it's dead, if it's alive
and it has two or three neighbors, it survives to the next time,
otherwise it dies, and if it has exactly three neighbors, and it's dead,
it comes back to life, if it has exactly three neighbors, that's a simple rule, whatever, you can just imagine, it's just simple—
All is doing, is operating under this very local process, same as a neuron.
It's a— or in the way we're currently training neural networks and there's this local gradient,
we're optimizing over a local gradient, the same local rules, and what happens if you run this system,
operating under really local rules, what you get on the right, it's not— Again, you have to go home,
hopefully no drugs involved, but you have to open up your mind [chuckles]
and see how amazing that is, because what happens is, it's a local computational unit,
that knows very little about the world, but somehow really complex patterns emerge
and we don't understand why, in fact under different rules, incredible patterns emerge, and it feels like
it's living creatures communicating, when you just watch it, not these examples, this is the original,
they get complex and interesting, but even in these examples, these complex geometric patterns that emerge,
it's incredible, we don't understand why, same with neural networks, we don't understand why, and we need to in order to see how these networks will be able to reason.
What's next? I encourage you to read the deep learning book,
it's available online, deeplearningbook.org. As I mentioned to a few people, you should--
Well, first there's a ton of amazing papers every day coming out on archive,
I'll put these links up, but there's a lot of good collections of strong papers,
lists of papers, there is the literally awesome list, the awesome deep learning papers on GitHub,
it's calling itself awesome, but it happens to be awesome, there is a lot of blogs, it's just amazing,
that's how I recommend you learn machine learning, on blogs, and if you're interested
in the application of deep learning in the automotive space, you can come and do research in our group,
just email me. Anyway, we have three winners,
Jeffrey Hu, Michael Gump how do you-- Are you here?
How do you say your name? No, that's not my name [laughter]
My name is Purna [?]
Oh, I see. [?]
Well, anyway here-- [applause]
He achieved the stunning speed of-- So this is kind of incredible,
I didn't know what kind of speed we were going to be able to achieve, I thought 73 was unbeatable, because we played with it for a while
and we couldn't achieve 73, we design a deterministic algorithm that was able to achieve 74 I believe,
meaning like it's cheating, with the cheating algorithm that got 74, folks have come up
with algorithms that have done— that had beaten 73 and then 74, so this is really incredible,
and the other two guys— all three of you get a free term at the Udacity self-driving car engineering degree,
Thanks to those guys for giving that award and bringing their army of brilliant—
So they have people who are obsessed about self-driving cars, and we've received
over 2,000 submissions for this competition, a lot of them from those guys, they're just brilliant,
it's really exciting to have such a big community of deep learning folks working in this field,
this is for the rest of eternity, we're going to change this up a little bit, but this is actually
the three neural networks, the three winning neural networks
running side by side, you can see the number of cars passed there, the first place is on the left,
second place, and third place, and in fact, the third place it's almost-- right now, second place is winning currently,
but that just tells you the random nature of competition,
sometimes you win, sometimes loose.
The actual evaluation process runs through a lot of iterations and takes the medium evaluation.
With that, let me thank you guys so much for— Wait, we have a question—
are the winning networks online? Yes.
All three guys wrote me a note about how their networks work, I did not read that note,
[chuckles] I'll post—This tells you how crazy this has been,
I'll post the winning networks online,
and I encourage you to continue competing and continue submitting networks. This will run for a while we're working on a journal paper
for this game. We're trying to find the optimal solutions.
Okay. This is the first time I've ever taught a class, and the first time obviously teaching this class,
so thank you so much for being a part of it. [Applause] Thank you to Eric,
if you didn't get a shirt please come back, please come down and get a shirt, just write your email on the note,
on the on the index note. Thank you.


----------

-----

--18-- 

-----
Date: 2017.02.01
Link: [# MIT 6.S094: Recurrent Neural Networks for Steering Through Time](https://www.youtube.com/watch?v=nFTQ7kHQWtc)
Transcription:

All right. So, we have talked about regular neural networks,
fully connected neural networks, we have talked about convolutional neural networks that work with images,
we have talked about Reinforcement, Deeper Reinforcement Learning, where we plug in a neural network
into a Reinforcement Learning Algorithm, when a system has to not only
perceive the world but also act in it, and collect a reward. And today we will talk about,
perhaps the least understood but the most exciting neural network out there,
flavor of neural networks, is Recurrent Neural Networks.
Administrative
But first, for administrative stuff, there’s a website. I don’t know if you heard,
cars.mit.edu, where you should create an account, if you’re a registered student, that’s one of the requirements.
You need to have an account if you want to get credit for this, you need to submit code
for DeepTrafficJS, and DeepTeslaJS, and for DeepTraffic,
you have to have a neural network that drives faster than 65mph. If you need help to achieve that speed
please e-mail us. We can give you some hints.
For those of you who are old school SNL fans, there’s the Deep Thoughts section now,
in the profile page, where we encourage you to talk about the kinds of things that you tried in DeepTraffic
or any of the other DeepTesla or any of the work you've done
as part of this class for DeepLearning. Okay,
we have talked about the Vanilla Neural Networks on the left. The Vanilla Neural Network
Flavors of Neural Networks
is the one where it's computing is approximating a function that maps from one input
to one output. An example is mapping images to the number that is shown in the image.
For ImageNet is mapping an image to what's the object in the image. It can be anything.
In fact, Convolutional Neural Networks can operate on audio, you can give it a chunk of audio, a five second audio clip,
that still counts as one input because it’s fixed-size. As long as the size of the input is fixed,
that's one chunk of input and as long as you have ground truth
that maps that chunk of input to some output ground truth, that’s the Vanilla Neural Network.
Whether there's a fully connected neural network or convolutional neural network.
Today we’ll talk about the amazing, the mysterious Recurrent Neural Networks.
They compute functions from one to many, from many to one,
from many to many.
Also bidirectional. What does that mean? They take its input sequences,
time series, audio, video, whenever there's a sequence of data,
and that temporal dynamics that connects the data is more important than the spatial
content of each individual frame. So, whenever there's a lot of information being conveyed in a sequence,
in a temporal change of whatever that type of data is, that's when you want to use Recurrent Neural Networks
like speech, natural language, audio
and the power of this is that for many of them, for a Recurrent Neural Network, where they really shine,
is when the size of the input is variable, so you don’t have a fixed chunk of data
that you're putting in is variable input. And the same goes for the output,
so you can give it a sequence of speech, several seconds of speech
and then the output is a single label of whether the speaker is male or female.
That’s many to one. You can also do
many to many. Translation. You can have natural language
put into the network in Spanish and the output is in English.
Machine translation. That's many to many. And that many to many doesn't have to be
mapped directly into same sized sequences. For video, the sequence size might be the same
you're labeling every single frame, you put in a five second clip
of somebody playing basketball and you can label every single frame counting the number of people in every single frame.
That's many to many when the size of the input and the size of the output is the same Yes, question?
The question was, are there are any models where there's feedback from output and input? That's exactly what Recurrent Neural Networks are.
It produces output, and it copies that output and loops it back in.
That's almost the definition of a Recurrent Neural Network. There's a loop in there that produces the output
and also takes that output as input once again.
There's also many to many where the sequences don't align. Like machine translation,
the size of the output sequence might be totally different than the input sequence. We will look on a lot of cool applications;
you can start a song, learn the audio of a particular song have the Recurrent Neural Network
to continue that song after a certain period of time. So it can learn to generate sequences
of audio, of natural language, of video. Okay.
Back to Basics: Backpropagation
I know I promised not many equations, but this is so beautifully simple
that we have to cover backpropagation. It's also the thing that, if you're a little bit lazy
and you go to the internet and start using the basic tutorials of TensorFlow, you ignore how backpropagation work.
At you peril. You kind of assume it just works. I give it some inputs, some outputs,
and it's like Lego pieces I can assemble them like you might have done with DeepTraffic A bunch of layers put in together
and then just press Train. backpropagation is the mechanism that neural networks currently--
The best mechanism we know of that is used for training. So you need to understand
the simple power of backpropagation, but also the dangers.
Summary, I put on the top of the slide, there's an input for the network that's an image,
there's a bunch of neurons, all with differentiable smooth activation functions on each neuron,
and then, as you pass through those activation functions,
take in an input, pass it through this net of differentiable compute nodes,
you produce an output. In that output you also have a ground truth,
the correct, the truth that you hope or you expect the network to produce.
And you can look at the differences between what the network actually produced and what you hoped it would produce,
and that's an error. And then you backward propagate that error, punishing or rewarding
the parameters of the network that resulted in that output
Let's start with a really simple example.
There's a function that takes its input up on top,
three variables, X, Y and Z. The function does two things: it adds X and Y
and then it multiplies that sum by Z. And then we can formulate that as a circuit,
circuit of gates, where there's a Plus gate, and a Multiplication gate.
Backpropagation: Forward Pass
Let's take some inputs, shown in blue. Let's say it's X is negative two,
Y is five and Z is negative four. And let's do a forward pass
through the circuit to produce the output. Negative two plus five equals three
q is that intermediate value, three.
This is so simple, and so important to understand that I just want to take my time for this
because everything else about neural networks just builds on these concepts
The add gate produces q, in this case, is three, and three times negative four is twelve.
That's the output. The output of the circuit of this network,
if you think of it as such, is negative twelve. The forward pass is shown in blue
the backward pass will be shown in red in a second here What we want to do, what would make us happy,
what would make f happy is for the output to be as high possible. Negative twelve, so-so, it could be better.
How do we teach it How do we adjust X, Y and Z,
to ensure it produces a higher f
makes f happier. Let's start backward,
The backward pass. We'll make the gradient on the output one,
meaning we want this to increase. We want f to increase. That's how we encode our happiness.
We want it to go up by one. In order to then propagate
Backpropagation: By Example
that fact that we want the f to go up by one, we have to look at
the gradient on each one of the gates. And what's a gradient?
It's a partial derivative
with respect to its inputs. The partial derivative of the output of the gate with respect to its inputs,
if you don't know what that means, is just
how much does the output change when I change the inputs a little bit. What is the slope of that change if I increase X
for the first function of addition, f of X, Y equals X plus Y. If I increase X by a little bit,
what happens to f? If I increase Y by a little bit, what happens to f? Taking a partial derivative of those
with respect to X and Y you just get a slope of one When you increase X,
f increases linearly. Same with Y. Multiplication is a little trickier.
When you increase X, f increases by Y.
Do the partial derivative of f with respect to X is Y, the partial derivative of f with respect to Y is X.
If you think about it, what happens is the gradients, when you change X,
the gradient of change doesn't care about X. It cares about Y.
Backpropagation: Backward Pass
It's flipped. So we can backpropagate that one, the indication of what makes X happy backward.
And that's done by computing the local gradient.
For q, the partial derivative of f with respect to q,
that intermediate value, that gradient would be negative four.
It will take the value of Z as I said it's the Multiplication gate, It'll take the value of Z
and assign it to the gradient. And the same for the partial derivative of f with respect to Z,
it will assign that to q. The value of the forward pass on the q. There's a three
and a negative four on the forward pass in blue and that's flipped. Negative four and three
on the backward pass. That's the gradient. And then we continue in the same exact process.
But wait. What makes all of this work,
is the Chain Rule. It's magical.
What it allows us to do is to compute the gradient,
the gradien of f with respect to the inputs X, Y, Z. We don't need to construct
the giant function that is the partial derivative of f with respect to X, Y and Z
analytically. We can do it step by step backpropagating the gradients. We can multiply the gradients together
Modular Magic: Chain Rule
as opposed to doing the partial derivative of f with respect to X. We have just the intermediate,
the local gradient of f with respect to q, and of q with respect to X,
and multiply them together. So, Instead of computing
gradient of that giant function X plus Y times Z,
in this case is not that giant, but it gets pretty giant with neural networks, we just go step by step.
Look at the first function, simple addition, q equals X plus Y, and the second function, multiplication,
f equals q times Z.
The gradient on X and Y, the partial derivative
of f with respect to X and Y is computed by multiplying
the gradient on the output, negative four, times the gradient on the inputs,
which as we talked about, when the operation is addition, that's just one.
It's negative four times one.
Interpreting Gradients
What does that mean? Let's interpret those numbers. You now have gradients on X, Y and Z
the partial derivatives of F with respect to X, Y, Z. That means,
for X and Y is negative four, for Z is three. That means, in order to make f happy,
we have to decrease the inputs that have a negative gradient
and increase the inputs that have a positive gradient. The negatives ones are X and Y,
the positive is Z.
Hopefully, I don't say the word “Beautiful” too many times in this presentation this is very simple. Beautifully simple.
Because this gradient is a local worker, it propagates for you;
it has no knowledge of the broader happiness of f.
It computes the greater between the output and the input. And it can propagate this gradient
based on, in this case f, a gradient of one but also the error.
Instead of one we can have on the output the error as the measure of happiness. And then we can propagate that error backwards.
These gates are important because we can break down almost every operation we can think of
that we work within neural networks into one or several gates like these.
The most popular are three, which is addition, multiplication and the Max operation.
For addition,
the process is you take a forward pass through the network, so we have a value on every single gate,
and then you take the backward pass. And through the backward pass you compute those gradients.
For an add gate, you equally distribute the gradients on the output to the input,
when the gradient on the output is negative four, you equally distribute it tonegative four.
And you ignore the forward pass value. That three is ignored when you backpropagate it.
On the Multiply gate, it's trickier. You switch the forward pass values,
if you look at f, that's a Multiply gate,
the forward pass values are switched and multiplied by the value of the gradient in the output.
If it's confusing, go through the slides slowly. It'll make a lot more sense.
Hopefully. One more gate. There's the Max gate, which takes the inputs
and produces as output the value that is larger.
When computing the gradient of the Max gate, it distributes the gradient
similarly to the Add gate, but to only one, to only one of the inputs;
the largest one. unlike the Add gate, pays attention to the input
the input values on the forward pass. All right.
Lots of numbers but the whole point here is, it's really simple;
Modularity Expanded: Sigmoid Activation Function
a neural network is just a simple collection of these gates. You take a forward pass,
you calculate some kind of function in the end, the gradient in the very end, and you propagate that back.
Usually, for neural networks, that's an Error function. A Loss function, Objective function,
a Cost function. All the same word. That's the Sigmoid function there
When you have three weights W zero, W one, W two and X, two inputs, X0, X1,
that's going to be the Sigmoid function. That's how you compute the output
of the neuron. But then you can decompose that neuron you can separate it all into
just a set of gates like this Addition, multiplication, there's an exponential in there and division
but all very similar. And you repeat the exact same process.
there's five inputs, there's three weights and two inputs. X zero, X one.
You take a forward pass through this circuit,
in this case again, you want it to increase so that the gradient of the output is one
and you backpropagate that gradient of one, to the inputs.
Now in neural networks, there's a bunch of parameters that you're trying through this process, modify.
And you don't get to modify the inputs You get to modify the weights along the way,
and the biases. The inputs are fixed, the outputs are fixed, the outputs that you hope
the network will produce. What you're modifying is the weights. So I get to try to adjust those weights
in the direction of the gradient.
Learning with Backpropagation
That's the task of backpropagation.  The main way that neural networks learn.
As we update the weights and the biases to decrease the loss function.
The lower the loss function the better. In this case, you have
three inputs on the top left. A simple network, three inputs.
Three weights on each of the inputs. There's a bias on the node, b and produces an output
a, and that little symbol is indicating a Sigmoid function.
And the loss is computed as Y minus A squared,
divided by two, where Y is the ground truth,
the output that you want the network to produce. And that loss function is backpropagating
in exactly the same way that we described before. The subtasks involved in this update of weights and biases
is that the forward pass computes the network output at every neuron, and finally, the output layer,
computes the error, the difference between a and b, and then
backward propagates the gradients. Instead of one on the output, it will be the error on the output and you backpropagated.
And then, once you know the gradient, you adjust the weights and the biases in the direction of the gradient.
Actually, the opposite of the direction of the gradient, because you want the loss to decrease.
And the amount by which you make that adjustment is called the Learning Rate.
The learning rate can be the same across the entire network or can be individual through every weight.
And the process of adjusting the weights and biases is just optimization.
Learning is an Optimization problem. You have an objective function, and you're trying to minimize it.
And your variables are the parameters, the weights and biases. Neural networks just happen to have
tens, hundreds of thousands, millions of those parameters.
So the function that you're trying to minimize is highly non-linear. But it boils down to something like this, you have
two weights, two plots-- or actually one weight
and as you adjust it, the cost
you adjust in such a way that minimizes the output cost.
And there's a bunch of optimization methods for doing this. this is a convex function,
You can find the local minimum. If you know about these kinds of terminologies,
the local minimum is the same as the global minimum, it's not a weirdly hilly terrain
where you can get stuck in. Your goal is to get to the bottom of this thing and if it's really complex terrain,
it will be hard to get to the bottom of it.
This general approach is gradient descent, and there's a lot of different ways to do a gradient descent.
Various ways of adding randomness into the process, so you don't get stuck into the weird
crevices of the terrain. But it's messy.
You have to be really careful. This is the part you have to be aware of, when you design a network for DeepTraffic
and nothing is happening this might be what's happening:
vanishing gradients or exploding gradients.
When the partial derivatives are small, so you take the Sigmoid function,
the most popular for a while, activation function, the derivative is zero at the tails.
When the input to the Sigmoid functions is really high or really low,
that derivative is going to be zero.
Gradient tells on how much I want to adjust the weights. The gradient might be zero,
and so you backpropagate that zero, a very low number, and it gets less and less
as you backpropagate and so the result is that
you think you don't need to adjust the weights at all. And when a large fraction of the network weights don't need to be adjusted,
they don't adjust the weights. And you are not doing any learning So the learning is slow.
Optimization is Hard: Dying ReLUS
There are some fixes to this, there are different types of functions.
There's a piece, the ReLUs function which is the most popular activation function.
But again, if the neurons are initialized poorly,
this function might not fire. it might be zero gradient
for the entire data set. Nothing that you produce as input,
you run all your thousands of images of cats, and none of them fire at all.
That's the danger here. So you have to pick
Optimization is Hard: Saddle Point
both the optimization engine, the solver that you use
and the activation functions carefully. You can't just plug and play like they're Lego's
You have to be aware of the function. SGD, Stochastic Gradient Descent,
that's the Vanilla optimization algorithm for gradient descent.
For optimizing the loss function over the gradients And what's visualized here is,
again, if you have done any numerical optimization, and non-linear optimization,
there's the famous saddle point, that's tricky for these algorithms to deal with.
What happens is, it's easy for them to oscillate, get stuck in that saddle and oscillating back and forth
as opposed to what they want to do which is go down into-- You get so happy that you found this
low point that you forget there's a much lower point. So you get stuck with the gradient.
The momentum of the gradient keeps rocking it back and forth without you going to a much greater global minimum.
And there's a lot of clever ways to solving that, the Atom optimizer is one of those.
Learning is an Optimization Problem
But in this case, as long as the gradients don't vanish
SGD, the Stochastic Gradient Descent, one of these algorithms will get you there It might take a little while, but it will get you there
Yes, question. The question was,
you're dealing with a function that is not convex, how do we ensure anything about
converging to anything that's reasonably good, the local optimum converges to--
The answer is, you can't. This isn't only a non-linear function
it's a highly non-function The power and the beauty of neural networks
is that it can represent these arbitrarily complex functions.
It's incredible. And it can learn these functions from data
But the reason people are referring to neural networks training as art
is you're trying to play with parameters that don't get stuck in these local optimal.
For stupid reasons and for clever reasons. Yes, question.
The Question continues on the same thread.
The thing is, we're dealing with functions where we don't know what the global optimal is.
That's the crocs of it. Everything we talked about,
interpreting text, interpreting video, even driving.
What's the optimal for driving? Never crashing?
It sounds easy to say that, you actually have to formulate the world under which it defines all of those things and it becomes a really
non-linear objective function for which you don't know what the optimal is.
That's why you keep trying and get impressed every time it gets better. It is essentially the process.
And you can also compare, you can compare with human-level performance. For ImageNet,
who can tell the difference between cats and dogs, and top five categories,
96% of the time accuracy, and then you get impressed when a machine can do better than that.
But you don't know what the best is.
These videos can be watched for hours, I won't play it until I explain this slide.
Let's pause to reflect on backpropagation before I go on to Recurrent Neural Networks. Yes, question.
In this practical manner, how can you tell when you're actually creating a net whether you're facing the management gradient problem
or you need to change your optimizer
or you've reached a local minimum? The question was,
how do you practically know when you hit the vanishing gradient problem?
The vanishing gradient could be--
Optimization is Hard: Vanishing Gradients
The derivative being zero on the gradient, happens when the activation is exploding,
like really high values and really low values. To really high values is easy. Your network has just gone crazy.
It produces very large values. And you can fix a lot of those things by just capping the activations.
The values being really low, resulting in a vanishing gradient, are really hard to detect
There's a lot of research in trying to figure out how to detect these things.
If you're not careful, often times you can find that,
and this isn't hard to do, we're like 40 or 50 percent of the network, of the neurons,
are dead. We will call it, for ReLU, they're dead ReLU
They're not firing at all. How do you detect that? That's part of learning
If they never fire you can detect that by running it through the entire training set. There are a lot of tricks. But that's the problem.
You try to learn and then you look at the loss function and it's not
converging to anything reasonable. They are going all over the place, or just converging very slowly.
And that's an indication that something is wrong That something could be the loss function is bad, that something could be you already found the optimal,
or that something could be the vanishing gradient. And again, that's why it's an art.
Certainly, at least some fraction of the neurons needs to be firing.
Otherwise, initialization is really poorly done. Okay, to reflect on the
Reflections on Backpropagation
simplicity of backpropagation and the power of it,
this kind of step of backpropagating the loss function to the gradients locally,
is the way neural networks learn. It's really the only way
that we have effectively been able to to train a neural network
network to learn a function. To adjusting the weights and biases, the huge number of weights and biases, the parameters
It's just through this optimization. It's backpropagating the error, where you have the supervised ground truth.
the question is whether this process, of fitting,
adjusting the parameters of a highly non-linear function to minimize a single objective,
is the way you achieve intelligence.
Human-level intelligence. That's something to think about. You have to think about, for driving purposes,
what is the limitation of this approach? What's not happening? The neural network designed, the architecture
is not being adjusted. any of the edges, the layers, nothing is being evolved
There are other optimization approaches that I think are more
interesting and inspiring than effective. For example, this is
using soft cubes to-- This is falling out of the field
of evolutionary robotics. Where you evolve
the dynamics of a robot using genetic algorithms and that's
These robots have been taught to, in simulation, obviously,
to walk and to swim. That one is swimming.
The nice thing here is that dynamics that highly non- linear space as well,
that controls the dynamics of this weird shaped robot with a lot of degrees of freedom,
it's the same kind of thing as the neural network. In fact, people have applied generic algorithms,
ant colony optimization, all kinds of sort of nature inspire algorithms for automatizing the weights and the biases
but they don't seem to currently work that well. It's a cool idea to be using
nature-type evolutionary algorithms to evolve something that's already nature inspired which is neural networks.
But, something to think about the backpropagation, while really simple
it's kind of dumb and the question is whether general intelligence reasoning can be achieved with this process.
All right, Recurrent Neural Networks, on the left there's an input X
Unrolling a Recurrent Neural Network
with weights on the input, U, there's a hidden state, hidden layer S,
with weights on
the edge connecting the hidden states to each other and then more weights, V, the on the output O.
It's a really simple network, there's inputs, there's hidden states,
the memory of this network and there's outputs.
But the fact that there's this loop where the hidden states are connected to each other
means that as opposed to producing a single input, the network takes arbitrary numbers of inputs,
it just keeps taking X, one at a time and produces a sequence of Xs
through time. Depending on
the duration of the sequence you're interested in, you can think of this network in its unrolled state.
You can unroll this neural network where the inputs are in the bottom, Xt-1, Xt, Xt+1,
and same with the outputs, Ot-1, Ot, Ot+1,
and it becomes like a regular neural network, unrolled some arbitrary number of times.
RNN Observations
The parameters, again, there's weights, there's biases, similar to CNNs,
convolutional neural networks and just like convolutional neural networks make certain spatial consistency assumptions,
the recurrent neural network assume temporal consistency amongst the parameters,
shares the parameters. That W, that U, that V, is the same for every single time step.
You're learning the same parameter, no matter the duration of the sequence
and that allows you to look at arbitrary long sequences
without having an explosion of parameters. 
This process is the same exact process that's repeated base on the different variants that we talk about before,
in terms of inputs and outputs, one to many, many to one, many to many.
Backpropagation Through Time (BPTT)
The backpropagation process is exactly the same as for regular neural networks.
It's a fancy name of backpropagation through time, BPTT,
but it's just backpropagation through an unrolled
recurrent neural network, where the errors are on the computed on the outputs,
the gradients are computed, backpropagated
and computed on the inputs, again, suffering for the same exact problem
of vanishing gradients. The problem is that the depth of these networks can be arbitrary long
if at any point the gradients hits a lower number, zero,
becomes, that neural becomes saturated. That gradient, let's call it saturated,
that gradient gets-- drives all the earlier layer to zero,
so is easy to run to a problem where you're really ignoring the majority of the sequence.
This is just another Python weight, sudo-called weight to look at it.
Is you have the same w, remember you're sharing the weights and all the parameters from time to time,
so if the weights are such WHH,
if the weights are such that they produce [unintelligible]
they have a negative value that results in the gradient that goes to zero,
that propagates through the rest. That's the sudo-call for backpropagation,
pass to the RNN, that WHH propagates back.
Gradients Can Explode or Vanish Geometric Interpretation
You get this things with exploding and vanishing gradients
for example, error surfaces for a single hidden unit RNN, this is visualizing the gradient,
the value of the weight, the value of the bias and the error, the error could be really flat or could explode,
both are going to lead to you not making--
either making steps that are too gradual or too big. It's the geometric interpretation.
RNN Variants: Bidirectional RNNS
Okay. What other variants that we look at, a little bit? are they [unintelligible 00:41:13]? It doesn't have to be only one way,
it can be bi-directional, that could be edges going forward and edges going back
What that's needed for is things like filling in missing, whatever the data is,
filling in missing elements of that data, whether that's images, or words, or audio.
Generally, as always is the case in neural network, the deeper it goes, the better.
That deep referring to the number of layers in a single temporal instance.
On the right of the slide we're stacking
node in the temporal domain. Each of those layers has its own set of weights,
its own set of biases. These things are awesome but they need a lot of data
Long-Term Dependency
when you add extra layers in this way. The problem is, while recurrent neural network,
in theory, is supposed to be able to learn any kind of sequence, the reality is they're not really good at remembering
what happened a while ago, the long-term dependency. Here's a silly example,
let's think of a story about Bob, Bob is eating an apple.
The apple part is generated by the recurrent neural network.
Your recurrent neural networks can learn to generate "apple" because it's seen in a lot of sentences, with "Bob" and "eating"
and it can generate the word apple. For a longer sentence, like
"Bob likes apples, he's hungry and decided to have a snack, so now he's eating an apple",
you have to maintain the state that we're talking about Bob and we're talking about apples,
through several discreet semantic
sentences. That kind of long-term memory is not--
because of different effects, but vanishing gradients,
it's difficult to propagate the important stuff that happened a while ago in order to maintain that context
in generating "apple", or classifying some concept that happened way down the line. 
When people talk about recurrent neural networks
Long Short Term Memory (LSTM) Networks
these days, they're talking about LSTMs, long-short-term memory networks
so all the impressive results results on time series and audio and video and all that, that requires LSTMs.
Again, vanilla RNNs are on top of the slide,
each cell is simple, there are some hidden units, there's an input, and there's an output.
Here, we used TANH as activation function,
it's just another popular Sigmoid type activation function.
LSTMs are more complicated, or they look more complicated but
in some ways, they're more intuitive for us to understand. There's a bunch of gates in each cell,
we'll go through those. In yellow are different neural network layers,
Sigmoid and TANH, are just different types of activation functions.
TANH is an activation function that squishes the input into the range of negative one to one.
Sigmoid function squishes it between zero and one and that serve different purposes.
There's some pointwise operations, addition, multiplication,
and there's connections, data being passed from layer to layer,
shown by the arrows. There's concatenation and there's a copy operation on the output
We copy, the output of each cell it's copied to the next cell and to the output.
LSTM: Gates Regulate
Let me try to make it, clarified,
LSTM: Pick What to Forget and What To Remember
clarify a little bit. There's this conveyer belt
going through inside of each individual cell and they all have, there's really three steps in the conveyer belt.
The first is, there is a Sigmoid function
that's responsible for deciding
what to forget and what to ignore, it's responsible for
taking in the input, the new input, x(t), taking in the state of the previous,
the output of the previous cell, previous time step and deciding "do I want to keep that in my memory or not?"
and "do I want to integrate the new input into my memory or not?" This allows you to
selective about the information which you learn. For example, there's that sentence "Bob and Alice are having lunch,
Bob likes apples, Alice like oranges, she is eating an orange".
Bob and Alice are having lunch, Bob likes apples, right now, if you had said you have a hidden state,
keeping track of the gender of the person we're talking about
you might say that there's both genders on the first sentence, there's male in the second sentence,
female in the third sentence, and that way when you have to generate a sentence about who's eating what,
you'll know- you keep the gender information in order to make an accurate generation of text
corresponding to the proper person. You have to forget certain things,
like forget that Bob existed at that moment, you have to forget Bob likes apples
but you have to remember that Alice likes oranges so you have to selectively remember and forget certain things
that's LSTM in a nutshell. You decided what to forget, decided what to remember
and decided what to output in that cell.
LSTM Conveyer Belt
Zoom in a little bit, because this is pretty cool There's a state running through the cell,
this conveyer belt, previous state like the gender
that we're currently talking about, that's the state that you're keeping track of
and that's running through the cell. Then there's three Sigmoid layers
outputting one, a number between the zero and one,
one when you want that information to go through and zero when you don't want it to go through,
the conveyer belt that maintains the state.
First, Sigmoid function is, we decided what to forget and what to ignore,
that's the first one, we take the input from the previous time step, the input to the network
on the current time step and decided, do I want to forget or do I want to ignore those?
Then we decided which part of the state to update,
what part of our memory do we have to update with this information and what values to insert in that update.
Third step is, we perform the actual update and perform the actual forgetting,
that's why you have the Sigmoid function, you just multiply it,
when is zero is forgetting, when is one that information passes through.
Finally, we produce an output from the cell,
if its translation is producing an output in the English language
where the input was in Spanish language and then that same output
it's copied to the next cell.
Application: Machine Translation
What can we get done with this kind of approach? We can look at machine translation.
I guess what I'm trying to-- question. what is your representation of this state?
Is it like a floating point or is it like a vector or what is it, exactly?
The state is the activation
multiplied by the weight, it's the output of the Sigmoid or the TANH activations.
There's a bunch of neurons and they're firing a number between negative one or one, or between zero and one,
that whole's a state. It just that calling it a state it's sort of simplifying, but the point is that there's
a bunch of numbers been constantly modified by the weights and the biases,
those numbers hold the state and the modification of those numbers
is controlled by the weights and then once all of that is done,
the resulting output of the recurrent neural network it's compared to the desired output
and the errors are backpropagated to the weights.
Hopefully, that makes sense.  So, machine translation is one popular application
all of it is the same, all of these networks that I've talked about,
they're really similar constructs. You have some inputs,
whatever language that is again, German maybe, I think everything is German,
and the output. The inputs are in one language, a set of characters
composed a word in one language, there's a state being propagated and once that sentence is over,
you start, as opposed to collecting inputs, start producing outputs and you can output in the English language.
Application: Handwriting Generation from Text
There's a ton of great work on machine translations. It's what Google is supposedly using for their translator,
same thing. I've show this previously but now you all know how it works,
same exact thing, LSTMs generating handwritten characters,
handwriting in arbitrary styles, controlling the drawing,
where the input is text and the output is handwriting. Is again, the same kind of
network with some depths here, the input is the text,
the output is the control of the writing. Character-level text generation,
Application: Character-Level Text Generation
this is the thing that taught us about life, the meaning of life,
literary recognition and the tradition of ancient human reproduction. That's again, the same process,
input one character at the time, what we see there is the encoding of the characters on the input layer,
there's a hidden state, hidden layer that is keeping track of those activations,
the outputs of the activation functions and every single
time it's outputting its best prediction
of the next character that follows. Now, on a lot of these applications you want to ignore the output
until the input sentence is over and then you start listening to the output,
but the point is that it just keeps generating text, whether is given an input or not, so you producing input
is just adding, steering the recurrent neural network. You can answer questions
Application: Image Question Answering
about an image, the input you get there, you could almost arbitrary stack things together,
you take an image as your input, bottom left there, put it in your convolutional neural network,
and take the question. There's something call word embeddings,
it's to broaden the representative meaning of the words. "How many books?" is the question.
You want to take the word embeddings and the image and produce your best estimate of the answer.
For question of "what color is the cat?" it could be gray or black, it's the different LSTM flavors
producing that answer. Same with counting chairs you can give an image of a chair
and as the question "how many chairs are there?" And it can produce an answer of "three".
I should say this is really hard, arbitrary question asks an arbitrary image,
you are both interpreting-- you are doing natural languages processing and you're doing computer vision, all in one network.
Application: Image Caption Generation
Same thing with the image capture generation, you can detect
the different objects in the scene, generate those words, stitch them together in syntactically correct sentences
and rearrange the sentences. All of those are LSTMs, the second and the third step,
the first is computer vision detecting the objects, segmenting the image and detecting the objects,
that way you can generate a caption that says "a man is sitting in a chair with a dog in his lap".
Application: Video Description Generation
Again, LSTMs for video. Caption generation for video,
the input, and every frame it's an image that goes into the LSTM,
the input is an image and the output is a set of characters.
First, you load in the video, in this case the output is on top, you encode
the video into a representation inside the network and then you start generating words
about that video. First comes the input, the encoding stage, then the decoding stage.
Take in the video, say a man is taking, talking, whatever
and because the input and the output are arbitrary, there also has to be indicators of the beginnings and
the ends of a sentence, in this case, end of sentences. You want to know when you stop
Application: Modeling Attention Steering
in order to generate syntactically correct sentences. that indicates the end of a sentence. You want also to be able to generate a period
You can also, again, recurrent neural networks, LSTMs here, controlling
the steering of a sliding window on an image
that is used to classify what is contained in that image. Here, a CNN being steered by a recurrent neural network
in order to convert this imagen into the number that's associated with a house number,
Application: Drawing with Selective Attention Writing
it's called visual attention. That visual attention can be used to steer for the perception side
and it can be used to steer a network for the generation. On the right, we can generate an image as--
So the output of the network-- it's a LSTM where the output on every time step
is visual, and this way you can draw numbers.
Application: Adding Audio to Silent Film
Here, I mention this before,
is taking in as input silent video, sequence of images
and producing audio. This is
an LSTM that has convolutional layers for every single frame,
takes images as input and produces
a spectrogram, audio as output.
The training set is a person hitting an object with a drumstick and your task is to generate, given a silent video,
generate the sound that the drumstick will make when in contact with that object.
Application: Medical Diagnosis
Medical diagnosis, that's actually-- I've listed some places where it has been really successful
and pretty cool, but it's also beginning to be applied in places where
can actually really help
civilization, in medical applications. For medical diagnosis
there's the highly spars and
variable lengths sequence of information in the form of,
for example, patient electronic health records. So, Every time you visit a doctor, there's a test being done, that information is there
and you can look it as a sequence over a period of time and then given that data, that's the input,
the output is the diagnosis, a medical diagnosis,
in this case, we can look at predicting diabetes, scoliosis, asthma and so on,
with pretty good accuracy. There's something that
all of us wish we could do, is stock market prediction.
You can input, for example, well first of all, you can input the raw stock data,
[unintelligible 01:00:30] books and so on, financial data, but you can also look at news articles from all over the web
and take those as input as shown here, on the X axis is time, articles from different days,
LSTM, once again, and produce an output of your prediction,
binary prediction, whether the stock would go up or down. Nobody has been able to really successfully do this
but there is a bunch of results and trying to perform above random
which is how you make money, significantly above random
on the prediction of it's going up or down? So you could buy or sell and especially
when there is-- in the cases when there was crashes it's easier to predict,
so you can predict an encroaching crash. These are shown in the table, the error rates from different stocks,
automotive stocks. You can also generate audio,
is the exact same process as it generates language, you generate audio. Here's trained on
a single speaker, a few hours epics
of them speaking and you just learn, that's raw audio of the speaker
and it's learning slowly to generate [audio]
Obviously, they were reading numbers.
this is incredible, this is trained on a compress spectrogram of the audio, raw audio
and is producing something that over just a few epics is producing something that sounds like words,
it could do this lecture for me, I wish.
This is amazing, this is raw input, raw output,
all again, LSTMs, and there's a lot of work in voice recognition,
audio recognition. You're mapping--
let me turn it up. You are mapping any kind of audio to a classification,
you can take the audio of the road
and that's the spectrogram on the bottom there, being shown you could detect whether the road is wet
is wet or the road is dry.
you could do the same thing for recognizing the gender of the speaker
or recognizing many to many map of the actual words being spoken,
speech recognition. This is about driving, so let's see where recurrent neural| networks apply in driving.
We talked about the NVIDIA approach, the thing that actually powers DeepTeslaJS,
it is a simple convolutional neural network, there's five convolutional layers
in their approach, three fully connected layers, you can add as many layers as you want in DeepTesla,
that's a quarter of million parameters to optimize
all you are taking is a single image, no temporal information, single image and producing the steering angle, that's the approach,
that's the DeepTesla way,
taking a single imagen image and learning a regression of the steering angle.
One of the prizes for the competition is the Udacity, self-driving
car engineer nanodegree for free, this thing is awesome,
I encourage everyone to check it out, but they did a competition
that's very similar to ours, but a very large group of obsessed people,
they were very clever, they went beyond convolutional neural networks of predicting steering,
taking a sequence of images and predicting steering, what they did is, the winners,
at least the first and I'll talk about the second place winner tomorrow,
on 3D convolutional neural networks, the first and the third place winners used RNNs,
used LSTMs, recurrent neural networks and map a sequence of images
to a sequence of steering angles. For anyone, statistically speaking,
anybody here who is not a computer vision person, most likely what'd you want to use, for whatever application
you're interested in, is RNNs, the world is full of time series data,
very few of us are working on data that is no time series data,
in fact, whenever it's just snapshots, you're really just reducing the problem to
the size that you can handle but most data in the world is time series data.
This is the approach you end up using if you want to apply it in your own research,
RNNs is the way to go.
Again, what are they doing? How do you put images
into a recurrent neural network? it's the same thing, you take,
you have to convert an image into numbers in some kind of way, a powerful way of doing that is convolutional neural networks,
so you can take either 3D convolutional neural networks
or 2D convolutional neural networks once it takes time into consideration and whatnot,
process that image to extract a representation of that image and that becomes the input to the LSTM
and the output at every single cell, at every single timestep, is a predicted steering angle,
the speed of the vehicle and the torque that's what the first place winner did, they didn't just do the steering angle,
also did the speed and torque and the sequence length that they were using
for training and for testing, for the input and the output, is a sequence length of 10 
did they used supervised learning or did they used reinforcement learning? The question was, did they used supervised learning?
Yes, they were given the same thing as in DeepTesla, a sequence of frames where the have a sequence of
steering angles, speed and torque, I think there's other information too available,
there's no reinforcement learning here. Question.  Do you have a sense of how much information
is being passed, how many LSTM gates are there in this problem?
The question was, how many LSTM gates are in this problem?
This network,
it's true that this diagrams kind of hide the number of parameters here, but it's arbitrary
just like convolutional neural networks are arbitrary, the size of the input is arbitrary,
the size of Sigmoid function, TANH is arbitrary, so you can make it as large as you want, as deep as you want
and the deeper and larger, the better.  What these folks actually used--
the way these competitions work and I encourage you, if you're interested in machine learning
to participate in Kaggle, I don't know how to pronounce it, competitions
where basically everyone is doing the same thing, you're using LSTMs or if it's one- on-one mapping,
using convolutional neural network fully connecting networks with some clever pre-processing
and the whole job is that takes months and you probably, if you're a researcher, that's what you'd be doing your own research,
playing with parameters, playing with pre-processing of the data, playing with the different parameter that controls the size of the network
the learning rate, I've mentioned, this type of optimizer, all these kinds of things, that's what you're playing with,
using your own human intuition and you're using your--
whatever probing you can do in monitoring the performansce of the network through time.
Yes?
The question was, you said that there's a
memory of tenth in this LCM, and I thought RNNs are supposed to be arbitrary.
It has to do with the training, how the network is trained.
It's trained with sequences of 10. The structure is still the same, you only have one cell that's looping onto each other.
But the question is, in what chunks, what is the size of the sequence
that we should do in the training and then the testing. It can be arbitrary length.
It's just usually better to be consistent and have a fixed length.
You're not stacking 10 cells together. It's just a single cell still.
The third-place winner, Team Chauffeur,
used something called transfer learning and it's something I don't think I mentioned
but it's kind of implied, the amazing power of neural networks.
First, you need a lot of data to do anything. That's the cost, that's the limitation in neural networks.
But what you could do is, there's
neural networks that have been trained on very large data sets. ImageNet,
Vdg Net, AlexNet, ResNet, all these networks are trained on a huge amount of data.
Those networks are trained to tell the differences between a cat and dog Specific optical recognition
of single images. How do I then take that network and apply it to my problem,
say of driving or length detection, or medical diagnosis, or cancer or not?
The beauty of neural networks,
the promise of transfer learning, is that you can just take that network, chop off the final layer,
the fully connected layer that maps from all those cool high-dimensional features that you have learned about visual space,
and as opposed to predicting cat vs. dog, you teach it to predict cancer or no cancer.
You teach it to predict lane or no lane, truck or no truck.
As long as the visual space under which that network operates is similar or the data like if it's audio or whatever
if it's similar, if the features are useful then you learn, in studying the problem of cat vs dog deeply,
you have learned actually how to see the world. As you're going to apply that visual knowledge,
you can transfer that learning to another domain. That's the beautiful power of neural networks
it's that they're transferable. What they did here is--
I didn't spend enough time looking through the code I'm not sure which of the giant nework they took
but they took a giant convolutional neural network, they chopped off
the end layer, which produced 3000 features, and they took those 3000 features
to every single image frame, and that's the Xt. They gave that as the input to LSTM.
And the sequence length, in that case, was 50. This process is pretty
similar across domains. That's the beauty of it. The art of neural networks is in the--
Well that's a good sign [chuckles], I guess I should warp it up--
The art of the neural networks is in the proper parameter tuning.  That's the tricky part, and that's the part you can't be taught.
That's experience, sadly enough. That's why they talk about
Stochastic Gradient Descent SGD, That's what Geoffrey Hinton
refers to as Stochastic Graduate Student Descent,
meaning you just keep hiring graduate students to play with the hyperparameters until the problem is solved
[laughter].
I have about 100+ slides on driver state, which is the thing that I'm most passionate about,
and I think will save the best for last. I'll talk about that tomorrow. We have a guest speaker
from the White House, will talk about the future of Artificial Intelligence from the perspective of policy,
and what I would like you to do first off you registered students is submit the two tutorial assignments,
and pick up can we just set the boxes right here or something?
Just stop by and pick up a shirt. And give us a card on the way.
Thanks guys. [Applause]

----------

-----

--17--

-----
Date: 2017.01.25
Link: [# MIT 6.S094: Convolutional Neural Networks for End-to-End Learning of the Driving Task](https://www.youtube.com/watch?v=U1toUkZw6VI)
Transcription:

Alright, welcome back everyone. Sound okay? Alright.
So today we will- We talked a little bit about neural networks, started to talk about neural networks yesterday.
Today we'll continue to talk about neural networks that work with images, convolutional neural networks,
and see how those types of networks can help us drive a car. If we have time we'll cover a simple illustrative case study
Illustrative Case Study: Traffic Light Detection
of detecting traffic lights. The problem of detecting green, yellow, red. If we can't teach our neural networks to do that, we're in trouble,
but it's a good, clear, illustrative case study of a three-class classification problem. Okay, next there's
Deep Tesla: End-to-End Learning from Human and Autopilot Driving
DeepTesla here looped over and over in a very short GIF. This is actually running live in a website right now.
We'll show it towards the end of the lecture, this once again just like DeepTraffic is a neural network that learns to
steer a vehicle based on the video of the forward road way. And once again, doing all of that in the browser using javascript.
So you'll be able to train your own very network to drive using real world data.
I'll explain how. We will also have a tutorial and code. Briefly described today at the end of the lecture,
if there's time how to do the same thing in TensorFlow. So if you want to build a network that's bigger, deeper and you want to utilize GPUs to train that network,
you want to not do it in your browser, you want to do it offline using TensorFlow
and having a powerful GPU on your computer and we'll explain how to do that. Computer vision.
Computer Vision is Machine Learning
So we talked about vanilla machine learning where there's no- Where the size, yesterday,
where the size of the input is small for the most part. The number of neurons, in the case the neural networks, is on the order of 10, 100, 1,000.
When you think of images, images are a collection of pixels, one of the most iconic images from computer vision
on the bottom left there is Lenna. I encourage you to Google it and figure out the story behind that image. It's quite shocking when I found out recently.
So once again, computer vision is, these days, dominated by data driven approaches by machine learning
where all of the same methods that are used on other types of data are used on images where the input is just
a collection of pixels and pixels are numbers from 0 to 255 discrete values.
So we can think exactly what we've talked about previously, you could think of images in the same exact way. It's just numbers
and so we can do the same kind of thing. We could do supervised learning where you have an input image
and output label. The input image here is a picture of a woman; the label might be "woman".
On supervised learning, same thing. We'll look at that briefly as well as clustering images into categories.
Again semi-supervised and reinforcement learning. In fact, the Atari games that talked about yesterday.
do some pre-processing on the images. They're doing computer vision; they're using convolutional neural networks as we'll discuss today
and the pipeline for supervised learning is again the same: there's raw data in the form of images,
there's labels on those images. We perform a machine learning algorithm, performs feature extraction,
it trains given the inputs and outputs on the images and the labels of those images, constructs the model
and then test that model. And we get a metric and accuracy. Accuracy is the term that's used to often describe how well the model performs.
The percentage.
Images are Numbers
I apologise for the constant presence of cats throughout this course. I assure you this course is about driving, not cats.
but images are numbers. So for us we take it for granted.
We're really good at looking and converting visual perception as human beings, converting visual perception, into semantics.
We see this image and we know it's a cat but a computer only sees numbers: RGB values for a color image.
There's three values for every single pixel from 0 to 255.
And so given that image, we can think of two problems: one is regression and the other is classification. Regression is when given an image
we want to produce a real value of output put back. So if we have an image of the four roadway,
we want to produce a value for the steering wheel angle and if you have an algorithm that's really smart,
It can take any image of the forward roadway and produce the perfectly correct steering angle that drives the car safely across the United States.
We'll talk about how to do that and where that fails. Classification is when the input again is an image
and the output is a class label, a discrete class label. Underneath it though often is still a regression problem
and once produced is a probability that this particular image belongs to a particular category.
And we use a threshold to chop off the outputs associated with low probabilities
and take the labels associated with high probabilities and convert it into a discrete classification.
Computer Vision is Hard
I mentioned this yesterday but it bears saying again, computer vision is hard.
We, once again, take it for granted. As human beings, we're really good at dealing with all these problems.
There's viewpoint variation: the object looks wholly different in terms of the numbers behind the images
in terms of the pixels when viewed from a different angle. Viewpoint variation: objects when you're standing far away from them or up close are totally different size.
We're good at detecting that there are different size. It's still the same object as human beings but that's still a really hard problem because those sizes can vary drastically.
We talked about occlusions and deformations with cats; well understood problem. There's background clutter.
You have to separate the object of interest from the background and given the three dimensional structure of our world.
There's a lot of stuff often going on in the background: the clutter, their inter-class variation.
That's often greater than inter-class variation; meaning objects of the same type often have more variation
than the objects that you're trying to separate them from. There is the hard one for driving: illumination.
Light is the way we perceive things; the reflection of light off the surface
and the source of that light changes the way that object appears and we have to be robust to all of that.
Image Classification Pipeline
So the image classification pipeline is the same as I mentioned. There are categories,
It's the classification problems for those categories of cat, dog, mug, hat.
You have a bunch of examples, image examples of each of those categories and so the input is just those images paired with the category.
And you train to map, to estimate a function that maps from the images to the categories.
Famous Computer Vision Datasets
For all of that you need data; a lot of it. There is, unfortunately, a growing number of data sets but there are still relatively small.
We get excited. There are millions of images but they're not billions or trillions of images and these are,
the data sets that you will see if you read academic literature most often. Mnist, the one that's been beaten to death.
And then we use as well in this course the data set of handwritten digits where the categories are 0 to 9.
ImageNet, one of the largest image data sets; fully labeled image data sets in the world has images with a hierarchy of categories from Word Net.
And what you see there is a labeling of what image is associated with which words are present in the data set.
CIFAR-10 and CIFAR-100 are tiny images that are used to prove in a very efficient and quick way
offhand that your algorithm that you're trying to publish on, or trying to impress the world with, works well.
It's small, it's a small data set: CIFAR-10 means there's 10 categories.
And places is a data set of natural scenes: woods, nature, city, and so on.
Let's Build an Image Classifier for CIFAR-10
So let's look at CIFAR-10 as a data set of 10 categories: airplane, automobile, bird, cat, and so on.
They're shown there with sample images as the rose. And so let's build a classifier that's able to take images from one of these 10 categories and tell us what
is shown in the image. So how do we do that? Once again, all the algorithm sees is numbers.
So we have to try to have at the very core, we have to have an operator for comparing two images.
So given an image and I want to save it as a cat or dog. I want to compare it to images of cats and compare it to images of dogs and see which one matches better.
So there has to be a comparative operator. Okay so one way to do that is take the absolute difference between the two images
pixel by pixel, take the difference between each individual pixel shown on the bottom of the slide for a 4x4 image. And then we sum that pixel-wise
pixel-wise absolute difference into a single number. So if the image is totally different pixel-wise,
that will be a high number. If it's the same image, the number will be 0. Oh, it's the absolute value too of the difference.
And that's called L1 distance. It doesn't matter. When we speak of distance, we usually mean L2 distance.
And so, if we try to- So we can build the classifier that just uses this operator to compare it to every single image in the data set
and say I'm going to pick the, I'm going to pick the category
that's the closest using this comparative operator. I'm going to find- I have a picture of a cat
and I'm going to look through the dataset and find the image that's the closest to this picture
and say that is the category that this picture belongs to. So if we just flip the coin and randomly pick which category an image belongs to get that accuracy,
would be on average 10%. It's random. The accuracy with which our brilliant image difference algorithm that just goes through the data set
and finds the closest one is 38% which is pretty good, it's way above 10%.
K-Nearest Neighbors: Generalizing the Image-Diff Classifier
So you can think about this operation of look into the base and finding the closest image as what's called K-Nearest Neighbors
or K in that case. Meaning you find the one closest neighbor to this image that you're asking questions about
and accept the label from that image. You could do the same thing increasing K.
Increasing K to 2 means you take the two nearest neighbors. You find the two closest in terms of pixel-wise image difference through this particular query image
and find which categories did those belong to. What's shown up top on the left is the data set we're working with: red, green, blue.
What's shown in the middle is the one nearest neighbor classifier, meaning
this is how you segment the entire space of different things that you can compare.
And if a point falls into any of these regions, it will be immediately associated with the nearest neighbor algorithm to belong to that image, to that region.
With the five nearest neighbors, there's immediately an issue. The issue is that there is white regions.
There's tie breakers where your five closest neighbors are from various categories. So it's unclear where you belong to.
So this is a good example of parameter tuning. You have one parameter: K.
And your task as a teacher of machine learning, you have to teach this algorithm how to do your learning for you,
is to figure out that parameter. That's called "parameter tuning" or "hyper-parameter tuning" as it's called in neural networks.
And so on the bottom right of the slide on the x-axis is K. As we increase it from 0 to 100 and
the y-axis is classification accuracy. It turns out that the best K for this data set is 7, 7 years neighbors.
With that we get a performance of 30% human level performance
and I should say that the way we get that number as we do with a lot of the machine learning pipeline
process is you separate the data into the parts of days that you use for training
and another part they use for testing. You're not allowed to touch the testing part. That's cheating.
You construct your model of the world on the training data set and you use what's called cross validation
where you take a small part of the training data shown "fold five" there in yellow to leave that part out from
the training and then use it as part of the hyper-parameter tuning. As you train, figure out with that yellow part fold five
how well you're doing and then you choose a different fold and see how well you're doing
And keep playing with parameters never touching the test part. And when you're ready, you run the algorithm on a test data to see how well you really do. How will it really generalizes. Yes, question.
(INAUDIBLE QUESTION) So, the question was: "is there a good way to-
Is any good intuition behind what a good K is?" There are general rules for different data sets
but usually you just have to run through it. Grid search, brute force. Yes, question.
(INAUDIBLE QUESTION) (CHUCKLING) Good question. Yes. (INAUDIBLE QUESTION)
Yes, the question was: "is each pixel 1 number or 3 numbers?" For majority of computer vision throughout its history used grayscale images so it's 1 number but RGB
is 3 numbers and there's sometimes a depth value too, so it's 4 numbers. So it's-
If you have a stereo vision camera that gives you the depth information of the pixels, that's a fourth and then if you stack two images together there could be 6. In general,
everything we work with will be 3 numbers for a pixel.
Yes, so the question: "as to the absolute value is just one number?" Exactly right. So in that case, those are grayscale images.
So it's not RGB images. So, you know, this algorithm is pretty good if we use the best.
We optimize the hyper-parameters of this algorithm, choose K of 7,
seems to work well for this particular CIFAR-10 data set. Okay, we get 30% accuracy.
It's impressive, higher than 10%. Human beings perform at about 94, slightly above 94%
accuracy for CIFAR-10. So given an image and it's a tiny image. I should clarify it, it's like a little icon.
Given that image, human beings are able to determine accurately one of the 10 categories with 94% accuracy.
And the currently state-of-the-art convolutional neural networks is ninety five, it's 95.4% accuracy and, believe it or not, it's a heated battle
but the most important, the critical fact here, is it's recently surpassed humans.
And certainly surpass the k-nearest neighbors algorithm. So,how does this work? Let's briefly look back.
Reminder: Weighing the Evidence
It all still boils down to this little guy: the neuron, that sums the weights of its inputs, adds a bias, produces an output based on an activation, a smooth activation function.
Yes, question. (INAUDIBLE QUESTION)
Reminder Classify and Image of a Number
The question was: "do you take a picture of Cassie, you know it's a cat, but that's not encoded anywhere, like you have to write that down somewhere.
So you have to write as a caption: "This is my cat." And then the unfortunate thing, given the internet and how woody it is, you can't trust the captions on images.
because maybe you're just being clever and it's not a cat all, it's a dog dressed as a cat. Yes, question.
(INAUDIBLE QUESTION) Sorry. Seen as do better than what?
Yes, so the question was: "do convolutional neural networks generally do better than nearest neighbors? There's very few problems on which neural networks don't do better, yes ,they almost always do better
except when you have almost no data. So you need data. And convolutional neural networks isn't some special magical thing.
It's just neural networks with some cheating up front that I'll explain, some tricks to try to reduce the size
and make it capable to deal with images. So again. Yes, the input is, in this case that we looked at classifying an image of a number,
as opposed to doing some fancy convolutional tricks. We just take the the entire 28x28
pixel image that's 784 pixels as the input.
That's 784 neurons in the input, 15 neurons on the hidden layer and 10 neurons in the output.
Now everything we'll talk about has the same exact structure. Nothing fancy.
Reminder: "Learning" is Optimization of a Function
There is a forward pass through the network where you take an input image and produce an output classification
and there's a backward pass through the network for Back Propagation where you adjust the weights
when your prediction doesn't match the Ground Truth output.
And learning just boils down to optimization; it's just optimizing a smooth function.
Differentiable function; that's defined as the lost function.
That's usually as simple as a squared error between the true output
and the one you actually got. So what's the difference? What are convolutional neural networks?
Convolutional neural networks take inputs that have some spatial consistency, have some meaning to the spatial-
Has some spatial meaning in them like images. There's other things, you can think of the dimension of time.
And you can input audio signal into a convolutional neural network. And so the input is, usually for every single layer,
that's a convolutional layer, the input is a 3D volume and the output is a 3D volume.
I'm simplifying because you can call it 4D too but it's 3D. There's height, width and depth.
So that's an image. The height and the width is the width and the height of the image. And then the depth for grayscale image is 1; for an RGB image is 3;
for a ten-frame video of greyscale images the depth is 10.
It's just a volume, a three-dimensional matrix of numbers. And everything-
The only thing that a convolutional layer does is take a 3D volume's input, produce a 3D volume as output
and has some smooth function. Operating on the inputs, on the sum of the inputs,
that may or may not be a parameter that you tune, that you try to optimize. That's it.
Convolutional Neural Networks: Layers
So Lego pieces that you stack together in the same way as we talked about before.
So what are the types of layers that a convolutional neural networks have? There's inputs. So for example a color image of 32x32 will be a volume of 32x32x3.
A convolutional layer takes advantage of the spatial relationships of the input neurons and a convolutional layer,
Dealing with Images: Local Connectivity
it's the same exact neuron as for fully connected network, the regular we talked about before.
But it has a narrower receptive field, it's more focused, the inputs to a neuron on the convolutional layer
come from a specific region from the previous layer. And the parameters on each filter, you can think of this as a filter, because you slide it across the entire image.
And those parameters are shared. So supposed you've taken the- If you think about two layers,
as opposed to connecting every single pixel in the first layer to every single neuron in the following layer.
You only connect the neurons in the input layer that are close to each other, to the output layer, and then you
enforce the weights to be tied together spatially.
And what that results in is a filter every single layer on the output,
you can think of as a filter, they get excited for example for an edge
and when it sees this particular kind of edge in the image, it will get excited. And it'll get excited in the top left of the image, on the top right, bottom left, bottom right.
The assumption there is that a powerful feature for detecting a cat
is just as important no matter where in the image it is. And this allows you to cut away a huge number of connections between neurons but it still boils down on the right,
as a neuron that sums a collection of inputs and applies weights to them. The spatial arrangement of the output volume relative to the input volume
ConvNets: Spatial Arrangement of Output Volume
is controlled by three things. The number of filters. So for every single "filter"
you get an extra layer on the output. So if the input,
let's talk about the very first layer, the input is 32x32x3. It's in RGB
image of 32x32. If the number of filters is 10,
then the resulting depth the resulting number of stacked channels in the output will be 10. Stride is given.
is the step size of the filter that you slide along the image. Often times as just 1 or 3
and that directly reduces the size, the spatial size the width and the height, of the output image.
and then there is a convenient thing that it's often done is padding. The image on the outside zeros.
So that the input and the output have the same height and width. So this is a visualization of convolution.
I encourage you to, kind of maybe offline, think about what's happening. It's similar to the way human vision works, crudely so, if there's any experts in the audience.
So the input here on the left is a collection of numbers: 0, 1, 2. And a filter
or there are two filters shown as W1- W0 and W1. Those filters shown in red, are the different weights applied in those filters.
And each of the filters have a certain depth; just like the input a depth of 3.
So there are three of them in each column and so,
so you slide death filter along the image keeping the weights the same.
this is the sharing of the weights and so your first filter you pick the weights, this is an optimization problem. you pick the weights in such a way
that it fires, it gets excited, for useful features and doesn't fire for not useful features.
And then there's a second filter that fires for useful features and not. And produces a signal on the output depending on a positive number, meaning there's a strong feature in that region,
and negative number if there isn't but the filter is the same. This allows for a drastic reduction in the parameters and so you can deal with
inputs. There are a thousand by thousand pixel image, for example, or video. There's a really powerful concept there.
ConvNets: Pooling
The spatial sharing of weights. That means there's a spatial invariance to the features you're detecting. It allows you to learn from arbitrary images
so you don't have to be concerned about pre-processing the images in some clever way,
you just give the raw image. There is another operation: pooling.
It's a way to reduce the size of the layers by, for example in this case,
it's max pooling for taking a collection of outputs and choose x1
and summarizing those collection of pixels such that the output of the pooling operation is much smaller than the input.
Because the justification there is that you don't need a high resolution.
Localization of which pixel is important in the image or according to, you know,
you don't need to know exactly which pixel is associated with the cat ear or a cat face.
As long as you, kind of, know it's around that part and that reduces a lot of complexity in the operations. Yes, question.
The question was: "when is too much pooling, when do you stop pooling?"
So pooling is a very crude operation that doesn't have any, one thing you need to know, is it doesn't have any
parameters that are learnable. So you can't learn anything clever about pooling. You're just picking, in this case
max pool, so you're picking the largest number. So you're reducing the resolution, you're losing a lot of information.
There's an argument that you're not, you know, losing that much information as long as you're not pooling the entire
image into a single value but you're gaining training efficiency, you're gaining the memory size, reducing the size of the network.
So, it's definitely a thing that people debate and it's a parameter that you play with to see what works for you.
Computer Vision: Object Recognition / Classification
Okay, so how does this thing look like as a whole, a convolutional neural network, the input is an image
there's usually a convolutional layer, there is a pooling operation, another convolutional layer, another pooling operation and so on.
At the very end, if the task is classification you have a stack of convolutional layers and pooling layers.
There are several fully connected layers. So, you go from those spatial convolutional operations to fully connecting every single neuron in a layer to the
following layer. And you do this so that by the end, you have a collection of neurons each one is associated with a particular class.
So in what we looked at yesterday is the input, is an image of a number 0 through 9.
The output here would be 10 neurons. So you blow down that image with a collection of convolutional layers,
with 1 or 2 or 3 fully connected layers at the end that all lead to 10 neurons
and each of those neuron's job is to get fired up
when it sees a particular number and for the other ones to produce a low probability. And so this kind of process
is how you have the 95 percentile accuracy on the CIFAR-10 problem.
This here is ImageNet data set that I mentioned. It's how you take this image of a leopard, of a container ship,
and produce a probability that that is a container ship or a leopard.
Also shown there are the outputs of the other nearest neurons in terms of their confidence.
Computer Vision: Segmentation
Now you can use the same exact operation by chopping off the fully connected layer at the end
and as opposed to mapping from image to a prediction of what's contained in the image, you map from the image to another image.
And you can train that image to be one that gets excited
spatially, meaning it gives you a high, close to one value, for areas of the image that contain the object of interest
and then a low number for areas of the image that are unlikely to contain that image.
And so from this you can go on the left, an original image of a woman on a horse, to a segmented image of knowing where the woman is and where the horse is
and where the background is. The same process can be done for detecting the object.
So you can segment the scene into a bunch of interesting objects, candidates for interesting objects and then go through those candidates one by one
and perform the same kind of classification as in the previous step where it's just an input as an image and the output as a classification.
And through this process of hopping around an image, you can figure out exactly where is the best way to segment the cow
out of the image. That's called object detection. Okay, so
How Can Convolutional Neural Networks Help Us Drive?
how can these magical convolutional neural networks help us in driving? This is a video of the forward road way from a
data set that we'll look at, that we've collected from a Tesla. But first let me look at driving.
Driving: The Numbers
Briefly, the general driving task from the human perspective. On average an American driver in the United States
drives 10,000 miles a year. A little more for rural, a little less for urban. There is about 30,000
fatal crashes and >32,000 sometimes as high as 38,000 fatalities a year.
This includes car occupants, pedestrians, bicyclists and motorcycle riders.
This may be a surprising fact but in a class on self-driving cars we should remember that.
So ignore the 59.9%, that's other. The most popular cars in the United States are pickup trucks: Ford F-1 Series,
Chevy Silverado, Ram. It's an important point that we're still married to our,
Human at the Center of Automation
to wanting to be in control and so one of the interesting cars that we look at
and the car that is the days that we provide to the class is collected from is a Tesla.
It's the one that comes at the intersection of the Ford F-150 and the cute, little Google self-driving car on the right. It's fast, it allows you to have a feeling of control
but it can also drive itself for hundreds of miles on the highway, if need be.
It allows you to press a button and the car takes over. It's a fascinating trade-off, of transferring control from the human to the car.
It's a transfer of trust and it's a chance for us to study the psychology of human beings as they relate to machines at >60 miles an hour.
Distracted Humans
In case you're not aware a little summary of human beings, where distracted things: would like to text, use the smartphone,
watch videos, groom, talk to passengers, eat, drink, texting.
169 billion texts were sent in the US every single month in 2014.
On average, 5 seconds our eyes spent off the road while texting - 5 seconds.
4 D's of Being Human: Drunk, Drugged, Distracted, Drowsy
That's the opportunity for automation to step in. More than that, there's what NHTSA refers to as the 4 D's: drunk, drugged,
distracted and drowsy. Each one of those opportunity is for automation to step in. Drunk driving stands to benefit significantly
In Context: Traffic Fatalities
from automation, perhaps. So the miles, let's look at the miles. The data. There's 3 trillion (3 million million)
3 million million miles driven every year and TESLA autopilot, our case study for this class,
and as human beings is driven on full auto-pilot mode.
So it's driving by itself 300 million miles as of December 2016
and the fatalities for human control vehicles is 1:90,000,000.
It's about >30,000 fatalities a year and currently under TESLA auto-pilot there's one fatality.
There's a lot of ways you could tear that statistic apart but it's one to think about. Already, perhaps automation
results in safer driving. The thing is, we don't understand automation,
because we don't have the data: we don't have the data on the forward roadway video, we don't have the data on the driver
and we just don't have that many cars on the road today that drive themselves. So we need a lot of data.
We'll provide some of it to you in the class and as part of our research at MIT were collecting huge amounts of it,
of cars driving themselves, and collecting that data is how we get to understanding.
So talking about the data and what we'll be doing training our algorithms on, here is a Tesla Model S, Model X
we've instrumented 17 of them, have collected over 5,000 hours and 70,000 miles.
And I'll talk about the cameras that we've put in them. We're collecting video of the forward road way.
This is a highlight of a trip from Boston to Florida of one of the people driving a Tesla. What's also shown in blue is the
amount of time that autopilot was engaged: currently 0 minutes and then it grows and grows.
For prolonged periods of time, so hundreds of miles, people engage autopilot. Out of 1.3 billion
miles driven a Tesla, 300,000,000 are on autopilot. You do the math whatever that is, 25%.
So we are collecting data of the forward roadway, of the driver. We have 2 cameras on the driver.
What we're providing with the class is epics of time of the forward roadway, for privacy considerations. Cameras used
Camera and Lens Selection
to record are your regular Webcam, the work horse of the computer vision community. The C920,
and we have some special lenses on top of it. Now what's special about these webcams? Nothing that costs $70 can be that good, right?
What's special about them is that they do onboard compression and allow you to collect huge amounts of data
and use reasonably sized storage capacity to store that data and train your algorithms on.
Semi-Autonomous Vehicle Components
So what on the self-driving side do we have to work with? How do we build a self-driving car?
There is these sensors: radar, lidar, vision,
audio - all looking outside helping you detect the objects in the external environment to localize yourself and so on.
And there's the sensors facing inside: visible light camera, audio again,
and infrared camera to help detect peoples. So we can decompose the self-driving car task into 4 steps: localization, answering where am I; scene understanding,
Self-Driving Car Tasks
using the texture of the information of the scene around, to interpret the identity of the different objects in the
scene and the semantic meaning of those objects, of their movement.
There's movement planning - once you figured all that out, found all the pedestrians, found all the other cars,
how do I navigate through this maze, a clutter of objects in a safe and legal way. And there's driver state,
how do I detect using video or other information.
The video of the driver detect information about their emotional state or their distraction level. Yes, question.
(INAUDIBLE QUESTION) Yes, that's the real-time figure from lidar. Lidars are sensors that provides you the 3D point cloud
of the external scene. So lidar is the technology used by
most folks working with self-driving cars to give you a strong Ground Truth of the objects. It's probably the best sensor we have
for getting 3D information, the least noisy 3D information about the external environment. Question.
The Data
So autopilot is always changing. One of the most amazing things about this vehicle is that the updates to autopilot come in
the form of software. So the amount of time it's available to changes has become more conservative with time.
But in this, this one of the earlier versions, and it shows, the second line in yellow, shows how often autopilot was available but not turned on.
So the total driving time was 10 hours, autopilot was available 7 hours and was engaged an hour.
This particular person is a responsible driver because what you see or
is a more cautious driver. What you see is it's raining, autopilot is still available
but- (INAUDIBLE QUESTION) the comment was that you shouldn't trust that one fatality number as an indication of safety because the drivers
elect to only engage the system when it's safe to do so. It's a totally open,
there's a lot bigger arguments for that number than just that one, the question is whether that's a bad
thing so maybe we can trust human beings to engage, you know,
despite the poorly filmed YouTube videos, despite the hype in the media, you're still a human being.
riding 60 miles an hour in a metal box with your life on the line. You won't engage the system unless you know it's completely safe unless you've built up a relationship with it.
It's not all the stuff you see where a person gets in the back of a Tesla and start sleeping or is playing chess,
or whatever. That's all for YouTube, the reality is when it's just you in the car
it's still your life on the line and so you're going to do the responsible thing unless perhaps you're a teenager and so on but that never changes no matter what you're in.
Question. (INAUDIBLE QUESTION) The question was: "what do you need to see
or sense about the external environment to be able to successfully drive? Do you need lane markings? Do you need other-
what are the landmarks based on which you do the localization and navigation?" And that depends on the sensors. So with the Google self-driving car in sunny California,
it depends on lidar in a high-resolution way, map the environment in order to be able to localize itself
based on lidar. And lidar, now I don't know the details of exactly where lidar fails,
but it's not good with rain, it's not good with snow, it's not good when the environment is changing. So what snow does is it changes the visual, the appearance, the reflective texture
of the surfaces around. Us human beings are still able to figure stuff out but a car that's relying heavily on lidar won't be able to localize itself using the landmarks
it previously has detected because they look different now with the snow. Computer vision can help us with lanes
or following a car. The two landmarks that we used in a lane is following the car in front of you
or staying between two lanes. That's the nice thing about our roadways it's they're designed for human eyes.
So you can use computer vision for lanes and for cars in front to follow them. And there is radar.
That's a crude but a reliable source of distance information that allows you to not collide with metal objects.
So all that together depending on what you want to rely on more gives you a lot of information.
The question is when its messy complexity of real life occurs,
how reliable it would be in the urban environment and so on. So localization- How can deep learning help?
So first, just a quick summary of visual odometry. It's using a monocular or stereo input of video images
to determine your orientation in the world. The orientation, in this case, of a vehicle in the frame of the world
and all you have to work with is a video of the forward roadway
and with stereo you get a little extra information of how far away different objects are.
SLAM: Simultaneous Localization and Mapping
And so this is where one of our speakers on Friday will talk about his expertise (SLAM) Simultaneous Localization and Mapping.
This is a very well-studied and understood problem of detecting unique features in the external scene
and localizing yourself based on the trajectory of those unique features.
When the number of features is high enough it becomes an optimization problem.
You know this particular lane moved a little bit from frame to frame you can track that information.
And fuse everything together in order to be able to estimate your trajectory through the three dimensional space.
You also have other sensors to help you out. You have GPS which is pretty accurate, not perfect but pretty accurate.
It's another signal to help you localize yourself. You also have IMU. Accelerometer
tells you your acceleration, from the gyroscope, the accelerometer, you have the six degree of freedom
of movement information about how the moving object, the car, is navigating through space.
Visual Odometry in Parts
So you can do that using the old school way of optimization.
Given a unique set of features, like sift features, and that step involves with stereo input understorting and
and rectifying the images. You have two images, from the two images compute the depth map but for every single pixel
computing the best estimate of the depth of that pixel, the three dimensional position, relative to the camera then you
compute, that's where you compute the disparity map, that's what that's called, from which you get the distance
then you detect unique, interesting features in the scene. Sift is a popular one.
It's a popular algorithm for detecting unique features and you, over time, track those features.
And that tracking is what allows you through the vision alone to get information about your trajectory
through three-dimensional space. You estimate that trajectory. There's a lot of assumptions, assumptions that bodies are rigid.
So you have to figure out if a large object passes right in front of you, you have to figure out what that was.
You have to figure out mobile objects in the scene. And those are the stationary.
End-to-End Visual Odometry
Or you can cheat or we'll talk about and do it using neural networks end-to-end.
Now what does end-to-end mean? And this will come up a bunch of times throughout this class and today. End-to-end means,
and I refer to it as cheating because it takes away a lot of the hard work of panageneric features. You take the raw input
of whatever sensors. In this case, it's taking stereo input from a stereo vision cameras so two images, a sequence of two
images coming from a stereo vision camera, and the output is a estimate of your trajectory through space.
So it's supposed to be doing the hard work of SLAM, of detecting unique features, of localizing yourself, of tracking those
features and figuring out where your trajectory is. You simply train the network.
With some Ground Truth, you have form a more accurate sensor like lidar,
and you train it on a set of inputs, the stereo vision inputs, and outputs is the trajectory through space. You have a separate convolutional neural networks for the velocity
and for the orientation. And this works pretty well. Unfortunately, not quite well
and John Leonard will talk about that. SLAM is one of the places were deep learning is not being able to outperform the
previous approaches. Where deep learning really helps is the scene understanding part. It's interpreting the objects in the scene.
It's detecting the various parts of the scene, segmenting them
and with optical flow determining their movement. So previous approaches for detecting objects
Object Detection
like the traffic signal, the classification of detection that we have the TensorFlow tutorial for
or to use car-like features or other types of features that are hard-engineered from the images.
Now we can use convolutional neural networks to replace the extraction of those features.
Full Driving Scene Segmentation
And there's TensorFlow implementation of SegNet which is taking the exact same neural network that I talked about. It's the same thing, the beauty is you just apply
similar types of networks to different problems and depending on the complexity of the problem, can get quite amazing performance. In this case, we convolutionize
network, meaning the output is an image, input is an image, a single monocular image. The output is a
segmented image where the colors indicate your best pixel-by-pixel estimate of what object is in that part.
This is not using any spatial information, it's not using any temporal information.
So it's processing every single frame separately and it's able to separate the road from the trees,
from the pedestrians, other cars, and so on.
This is intended to lie on top of a radar / lidar type of technology that's giving you the three dimensional
or stereo vision three-dimensional information about the scene. You're, sort of, painting that scene with the identity of
the objects that are in it, your best estimate of it. This is something I'll talk about tomorrow is recurring neural networks
Road Texture and Condition from Audio
and we can use recurring neural networks that work with temporal data to process video
and also process audio. In this case, we can process what's shown on the bottom is
a spectrogram of audio for a wet road and a dry road. You can look at that spectrogram as an image
and process it in a temporal way using recurring neural networks. Just slide it across and keep feeding it to a network.
And it does incredibly well on the simple tasks, certainly of dry road versus wet road. This is important,
a subtle, but very important task and there's many like it to know the road, the texture, the quality.,
the characteristics of the road, wetness being a critical one. When it's not raining but the road is still wet, that information is very important.
Okay, so for movement planning. The same kind of approach. On the right is work from one of our other speakers
Previous approaches: optimization-based control • Where deep learning can help: reinforcement leaming
Sertec Karaman. The same approach we're using to solve traffic through friendly competition
is the same that we can use for what Chris Gerdes does with his race cars for planning trajectories in high speed movement
along complex curve.
So we can solve that problem using optimization, solve the control problem using optimization,
or we can use it with reinforcement learning by running tens of millions, hundreds of millions of times through that simulation of taking that curve
and learning which trajectory doesn't both optimizes the speed at which you take the turn
and the safety of the vehicle. Exactly the same thing that you're using for traffic.
And for driver state, this is what will talk about next week. It's all the fun face stuff: eyes, face, emotion.
This is with video of the driver, video of the driver's body, video the driver's face. On the left is one of the TAs
in his younger days. Still looks the same. There he is. So in that particular case,
you're doing one of the easier problems which is one of detecting where the head and the eyes are positioned.
The head and eye pose. You know it determine what's called he gaze of the driver, where the driver's looking, glance. And so,
we'll talk about these problems. From the left to the right: on the left in green are the easier problems; on the red
are the harder from the computer vision aspect. So on the left is body pose, head pose. The larger the object the easier it is the detect
and the orientation of it is easier to detect. And then there is pupil diameter. Detecting the pupil, the characteristics, the position, the size of the pupil.
And there's micro saccade, things that happen at one millisecond frequency, the tremors of the eye. All important information to determine the state of the driver.
Some are possible computer vision, some are not. This is something that we'll talk about, I think, on Thursday.
Is the detection of where the driver's looking. So, this is a bunch of the cameras that we have in the Tesla. This is
This is Dan driving a Tesla and detecting exactly where of one of six regions
We've converted into a classification problem of left, right, rear view mirror instrument cluster center stack
or forward roadway. So we have to determine out of those six categories which direction is the driver looking at. This is important for driving. We don't care exactly the X, Y, Z
position of where the driver is looking at. We care that they're looking at the road or not. Are they looking at their cell phone in their lap or are they looking at the forward roadway?
And we'll be able to answer that pretty effectively using convolutional neural networks.
You can also look at emotion using CNNs to extract,
again converting emotion, the complex world of emotion, into a binary problem of frustrated versus satisfied.
This is the video of drivers interacting with a voice navigation system. If you've ever used one,
you know that may be a source of frustration from folks. And so this is self reported, this is one of the hard, you know, driver
emotion if you're in what's called "Effective Computing." It's the field of studying emotion from the computational side.
If you work in that field, you know that the annotation side of emotion is really challenging one.
So getting the Ground Truth of, well okay since this guy's smiling
so can I label that as happy or he's frowning because that mean he's sad. Most effective computing folks do just that.
In this case we self report ask people how frustrated they're were in a scale of 1 to 10.
Dan up top reported a "1" for not frustrated, he's satisfied with the interaction,
and the other driver reported as a "9" he was very frustrated with the interaction. And what you notice
is there is a very cold, stoic look on Dan's face which is an indication of happiness.
And in the case of frustration, the driver is smiling.
So this is a sort of a good reminder that we can't trust our own human instincts.
It's an engineering feature. Engineering the ground truth. We have to trust the data, trust the Ground Truth
that we believe is the closest reflection of the actual semantics of what's going on in the scene.
Okay, so end-to-end driving. Getting to the the project and the tutorial.
So if driving is like a conversation and, thank you for someone to clarifying, that this is the Arch of Triumph
in Paris in this video. If driving is like a natural language conversation, then we can think of end-to-end driving as skipping the entire Turing Test
components and treating it as an end-to-end natural language generation.
So what we do is we take as input the external sensors
and output, the control of the vehicle. And the magic happens in the middle.
We replace that entire step with a neural network.
TAs told me to not include this image because it's the cheesiest we've ever seen. I apologize. Thank you, thank you.
I regret nothing. So this is to show our path to self-driving cars
but it still explain a point that we have a large data set of Ground Truth.
If we were to formulate the driving task to simply taking external images
and producing steering commands, acceleration of braking commands, then we have a lot of Ground Truth.
We have a large number of drivers on the road every day driving
and, therefore, collecting our Ground Truth for us because they're an interested party in producing the steering commands
that keep them alive and, therefore, if we were to record that data it becomes Ground Truth.
So if it's possible to learn this, what we can do is we can collect data for the manually controlled vehicles
and use that data to train an algorithm to control a self-driving vehicle.
Okay, so one of the first folks who did this is Nvidia where they actually train in an external image, the image of the forward roadway.
and a neural network, a convolutional network, a simple vanilla convolutional neural network I'll briefly outline:
take an image in, produce a steering command out and they're able to successfully, to some degree, learn to navigate basic turns, curves and even stop
or make sharp turns at a keener section. So this this now work is simple.
There is input on the bottom, output up top. The input is a 66x200 pixel image, RGB.
Shown on the left is the raw input and then you crop it a little bit and resize it down
66x200. That's what we have in the code as well in the two versions of the code we'll provide to you.
Both that runs in the browser and in TensorFlow. It has a few layers. A few convolutional layers, a few fully connected layers.
And an output. This is a regression network. It's producing not a classification of cat versus dog, it's producing a steering command.
How do I turn the steering wheel? That's it. The rest is magic and we train it on a human input.
What we have here is a project, is an implementation of the system in ConvNetJS that runs in your browser.
This is the tutorial to follow and the project to take on. So unlike the DeepTraffic game, this is reality.
This is a real input from real vehicles. So you can go to this link. Demo went wonderfully yesterday so let's see, maybe two for two.
There's the tutorial and then the actual game, the actual simulation is on DeepTesla.JS, I apologize.
Everyone is going there now, aren't they? Does it work on a phone? It does, great.
Again similar structure up top is the visualization of the lost function as the network is learning
and it's always training.
Next is the input for the layout of the network, there's the specification of the input 200x66.
There's a convolutional layer. There's a pooling layer and the output is a regression layer. A single neuron.
This is a tiny version, DeepTiny, right? It's a tiny version of
the Nvidia architecture and then you can visualize the operation of this network on real video.
The actual wheel value that produced by the driver, by the autopilot system,
is in blue and the output of the network is in white.
And what's indicated by green is the cropping of the image that is then resized to produce the 66x200
input to the network. So once again, amazingly, this is running in your browser, training on real world video.
So you can get in your car today input it and maybe teach a neural network to drive like you.
We have the code in ConvNetJS and TensorFlow to do that and the tutorial. Well, let me briefly describe some of the work here.
So the input to the network as a single image. This is for DeepTesla.JS, single image and the output is a steering wheel value between -20 and 20.
That's in degrees. We record,
like I said, thousands of hours but we provide publicly 10 video clips of highway driving from a Tesla.
Half are driven by autopilot, half are driven by human. The wheel values extracted from a perfectly synchronized
CAN, we are collecting all of the messages from CAN, which contains steering wheel value and that's synchronized to the video. We crop, extract the window. The green one I mentioned.
And then provide that as input to the network. So this is a slight difference from DeepTraffic with the red car weaving through traffic because there is the messy
reality of real world lighting conditions. And your task for the most part, in this simple steering task, is to stay inside the lane,
inside the lane markings. In an end-to-end way, learn to do just that. So ConvNetJS
is a javascript implementation of CNNs, of convolutional neural networks. It supports really arbitrary networks.
I mean all neural networks are simple but because it runs in javascript it's not utilizing GPU.
The larger the network the more it's going to be weighed down computationally.
Now unlike DeepTraffic, this isn't a competition but if you are a student registered for the course you still do have to submit the code, you still have to submit your own
car as part of the class. Question. So the question was the amount of data that's needed.
Is there a general rules of thumb for the amount of data needed for a particular task in driving for example?
It's a good question. You generally have to, like I said, neural networks are good memorizers so you have to just have every case represented in the
training said that you're interested in. As much as possible, so that means, in general if you want a picture, if you want to
classify the difference between cats and dogs, you want to have at least a thousand cats and a thousand dogs
and they do really well. The problem with driving is twofold: one, is that most of the time driving looks the same.
And the stuff you really care about is when driving looks different. It's all the edge cases. So we're not good with neural networks is generalizing from the common case to the edge cases, to the outliers.
So avoiding a crash just because you can stand the highway for thousands of hours successfully doesn't mean you can avoid a crash with
somebody runs in front of you on the road and the other part with driving is the accuracy you have to achieve is really high. So for cat versus dog,
No, life doesn't depend on your error. On your ability to steer a car inside of the lane.
You better be very close to 100% accurate. There's a box for designing the network.
There's a visualization of the metrics measuring the performance of the network as it trains.
There is a visualization, layer visualization, of what features the network is extracting at every convolutional layer
and every fully connected layer. There is ability to restart the training.
Visualize the network performing on real video. There is the input layer, the convolutional layers.
The video visualization, an interesting tidbit on the bottom right is a barcode that Will has ingeniously designed.
How do I clearly explain why this is so cool? It's a way to through video synchronized multiple streams of data together,
so it's very easy for those who have worked with multi-modal data where there are several streams of data
for them to become unsynchronized especially when a big component of training a neural network is shuffling the data.
So you have to shuffle the data in clever ways so you're not overfitting any one little aspect of the video and yet maintain the data perfectly synchronized.
So what he did instead doing the hard work of connecting the steering wheel and in the video is actually putting the steering on top of the video as a barcode.
The final result is you can watch the network operate and over time it learns more and more to steer correctly.
I'll fly through this a little bit in the interest of time just kind of summarize some of the things that you can play with in terms of tutorials and let you guys go. This is the same kind of process end-to-end driving with
So we have code available on GetHub. You just put up on my GetHub and the DeepTesla.
That takes in a single video or an arbitrary number of videos trains on them
and produces a visualization that compares the steering wheel, the actual steering wheel and the predicted steering wheel.
The steering wheel, when it agrees with the human driver or the autopilot system lighting up as green
and when it disagrees, lighting up as red. Hopefully not too often.
Again, this is some of the details of how that's exactly done in TensorFlow.
This is vanilla convolution neural networks. Specifying a bunch of layers, convolutional layers, a fully connected layer, train the model, so you iterate over the batches of images.
Run the model over a test set of images and get this result. We have a tutorial
on iPython Notebook into the tutorial up on this. This is perhaps the best way to get started with convolutional neural networks in terms of our class. It's looking at the
simplest image classification problem, of traffic light classification. So we have these images of traffic lights.
We did the hard work of detecting them for you. So now you have to figure out, you have to build the convolutional network that gets
figures out the concept of color and gets excited when it sees red, yellow or green. If anyone has questions,
I'll welcome those. You can stay after class if you have any concerns with Docker,
with TensorFlow, with how to win DeepTraffic. Just stay after class or come by Friday, 5 to 7. See you guys tomorrow.

----------

-----

--16--

-----
Date: 2017.01.22
Link: [# MIT 6.S094: Deep Reinforcement Learning for Motion Planning](https://www.youtube.com/watch?v=QDzM8r3WgBw)
Transcription:

All right. Hello everybody. Welcome back. Glad you came back. Today,
we will unveil the first tutorial. The first project is DeepTraffic, code named "DeepTraffic,"
where your task is to solve the traffic problem using Deep Reinforcement Learning.
And I'll talk about what's involved in designing a network there. How you submit your own network and how you participate in the competition.
As I said the winner gets a very special prize, to be announced later.
What is machine learning? Several types. There's supervised learning, as I mentioned yesterday that's what it meant,
Types of machine learning
usually when you discuss about, you talk about, machine learning and talk about its successes.
Supervised learning requires a data set where you know the Ground Truth.
You know the inputs and the outputs. And you provide that to the machine learning algorithm
in order to learn the mapping between the inputs and the outputs in such a way that you can generalize to further examples in the future.
On supervised learning, it's the other side, when you know absolutely nothing about the outputs.
About the truth of the data that you're working with. All you get is data and you have to find underlying structure,
underlying representation of the data that's meaningful for you to accomplish certain tasks, whatever that is.
There is semi-supervised data, or only parts, usually a very small amount
is labeled as Ground Truth of available for just a small fraction of it
If you think of images that are out there on the Internet
and then you think about ImageNet, a data set where every image is labeled, the size of that ImageNet data set
is a tiny subset of all the images available online.
But that's the task we're dealing with as human beings, as people interested in doing machine learning
is how to expand the size of that,
of the part of our data that we know something confidently about.
And reinforcement learning sit somewhere in between. It's semi supervised learning where
there's an agent that has to exist in the world. And that agent know the inputs that the world provides
but knows very little about that world except through occasional time delayed rewards.
This is what it's like to be human. This is what life is about.
You don't know what's good and bad, you got to have to just live it and, every once in a while,
you find out that all that stuff you did last week was pretty bad idea. That's reinforcement learning.
That's semi-supervised, in the sense that only a small subset of the data
comes with some ground truth, some certainty, you have to, then extract knowledge from.
So first at the core of anything that works currently
in terms of, in the practical sense, there has to be some Ground Truth. There has to be some truth
that we can hold on to as we try to generalize. And that supervised learning.
Even as in Reinforcement Learning, the only thing we can count on is that truth that comes in the form of a reward.
So the standard supervised learning pipeline is you have some raw data,
the inputs. you have Ground Truth, the labels,
the outputs and matches to the inputs. You know of ground truth. Then you run any kind of algorithm, whether it's a neural network
or another pre-processing algorithm that extracts the features from that data set.
You can think of a picture of a face, that algorithm could extract
the nose, the eyes, the corners of the eyes, the pupil or even lower level features in that image.
After that we insert those features
into a model. A machine learning model. We train that model.
Then we, whatever that algorithm is as it passes through that training process, we then evaluate.
After we've seen this one particular example, how much better are we at other tasks?
And as we repeat this loop, the model learns to perform better and better
at generalizing from the raw data to the labels that we have. And finally, you get to release that model into the wild
to actually do prediction on data as never seen before that you don't know about.
And the task there is to predict the labels.
Perceptron: Weighing the Evidence
Okay. So neural networks is what this class is about.
It's one of the machine learning algorithms that has proven to be very successful.
And the computational building block of a neural network is a neuron.
A perceptron is a type of neuron. It's the original old school neuron
where the output is binary, a zero or one. It's not real valued.
And the process that a perceptron goes through is it has multiple inputs and a single output.
Each of the inputs have weights on them. Shown here on the left is 0.7, 0.6, 1.4.
Those weights are applied to the inputs. And a perceptron, the inputs are 1s or 0s -
binary. When those weights are applied
and then summed together a bias on each neuron
is then added on top and a threshold,
there's a test, whether that summed value plus the bias is below or above a threshold. If it's above a threshold, produces a 1;
below a threshold produces a 0. Simple. So one of the only things we understand about neural networks confidently,
we can prove a lot of things about this neuron.
Perceptron: Implement a NAND Gate
For example, what we know is that a neuron can approximate a NAND gate.
A NAND gate is a logical operation,
a logical function, that takes as input, has two inputs A and B,
here on the on the diagram in the left. And the table shows what that function is
when the inputs are 0s, 01, in any order, the output is a 1.
Otherwise, it's a 0. The cool thing about a NAND gate is that it's a universal gate
that you can build up any computer you have where you have your phone in your pocket today
can be built out of just NAND gates. So it's functionally complete.
You could build any logical function out of them. You stack them together in arbitrary ways.
The problem with NAND gates and computers. is they're built from the bottom up.
You have to design these circuits of NAND gates. So the cool thing here is the perceptron,
we can learn. This magical NAND gate, we can learn its function.
So let's go through how we can do that. How a perceptron can perform the NAND operation.
There's the four examples. If you put the weights of -2 on each of the inputs
and a bias of three on the neuron, snd if we perform that same operation
of summing the weights times the inputs. plus the bias, in the top left we get
when the inputs are 0s and there's sum to the bias, we get a 3.
That's a positive number which means the output of a perceptron will be a 1.
On the top right, when the input is a 0 and a 1, that sum is still a positive number, again produces a 1.
And so on. When the inputs are both 1s, then the output is a -1. Less than zero.
So while this is simple, it's really important to think about.
Perceptron NAND Gate
It's a sort of one basic computational truth you can hold on to
as we talk about some of the magical things neural networks can do
because if you compare a circuit of NAND gates
and a circuit of neurons the difference, while a circuit of neurons
which is what we think of as a neural network, can perform the same thing as a circuit of NAND gates.
What it can also do is it can learn; It can learn the arbitrary logical functions
that has arbitrary circuit of NAND gates can represent but it doesn't require the human designer.
We can evolve, if you will.
The Process of Learning Small Change in Weights → Small Change in Output
So one of the key aspects here, one of the key drawbacks of perceptron,
is it's not very smooth in it's output. As we change the weights on the inputs
and we change the bias, and we tweak it a little bit, it's very likely that when you get-
It it's very easy to make the neuron- I'll put a 0 instead of a 1, or 1 instead of a 0.
So when we start stacking many of these together, it's hard to control the output of the thing as a whole.
Now the essential step that makes the neural network work,
that a circuit perceptrons doesn't, Is if the output is made smooth,
it's made continuous with an activation function.
And so instead of using a step function like a perceptron does shown there on the left,
we use any kind of smooth function. Sigmoid, where the output can change gradually as you change the weights and the bias.
And this is a basic but critical step
and so learning is generally the process of adjusting those weights gradually
and seeing how it has an effect on the rest of the network. You just keep tweaking weights here and there
and seeing how much closer you get to the Ground Truth.
And if you get farther away, you just adjust the weights in the opposite direction.
That's neural networks in a nutshell.
Combining Neurons into Layers
What we'll mostly talk about today is feed forward neural network.
On the left, going from inputs to outputs. With no loops, there is also
these amazing things called recurrent neural networks. They're amazing because they have memory.
They have a memory of state; they remember the temporal dynamics of the data they went through.
But the painful thing is that they're really hard to train.
Today will talk about feed for neural networks. So let's look at this example,
Task: Classify and Image of a Number
an example of stacking a few of these neurons together. Let's think of the task,
the basic task now famous, using a classification of numbers.
You have an image of a number in red number and your task is given that image to say what number is in that image.
Now, what is an image? An image is a collection of pixels; in this case 28 X 28 pixels.
That's a total of 784 numbers; those numbers are from 0 to 255.
And on the left of the network, the size of that input, despite the diagram, is 784 neurons.
That's the input. Then comes the hidden layer.
It's called the hidden layer because it has no interaction with the input or the output.
It is simply a block used at the core of the computational power of neural networks,
is the hidden layer. It's tasked with forming a representation of the data
in such a way that it maps from the inputs to the outputs. In this case, there is fifteen neurons in the hidden layer.
There is ten values on the output.
corresponding to each of the numbers. There are several ways you can build this kind of network
and this is what the magic of neural networks as you can do in a lot of ways. You only really need 4 outputs to represent values 0 through 9.
But in practice, it seems that having 10 outputs works better. And how do these work?
Whenever the input is a 5, the output neuron in charge of the five gets really excited.
And I'll put a value that's close to 1, from 0 to 1, close to 1.
And then the other 1s, I'll put a value, hopefully, that is close to 0.
And when they don't, we adjust the weights in such a way that they get closer to zero
and closer to one depending on whether this is the correct neuron associated with a picture.
We'll talk about the details of this training process more tomorrow when it's more relevant
but what we've discussed just now is the forward pass through the network.
It's the pass when you take the inputs, apply the weights, sum them together, add the bias, produce the output,
and check which of the outputs produces the highest confidence of the number
then once those probabilities for each of the numbers is is provided,
we determine the gradient that's used
to punish or reward the weights that resulted in either the correct or the incorrect decision.
And that's called Back Propagation. We step backwards through the network applying those punishments or rewards
Because of the smoothness of the activation functions, that is a mathematically efficient operation.
That's where the GPU step in. So far examples of numbers the Ground Truth for number 6
looks like the following in the slides. Y of X equals to 10 dimensional vector
where only one of them the sixth values a 1, the rest are zero.
That's the Ground Truth that comes with the image. The lost function here, the basic lost function, is the squared error.
Y of X is the Ground Truth and A is the output of the neural network
resulting from the forward pass. So when you input that number of a 6 and outputs, whatever it outputs
that's "a", a 10 dimensional vector. And it's summed over the inputs to produce the squared error.
That's our lost function. The lost function, the objective function. That's was used to determine
how much to reward or punish the Back Propagated weights throughout the network.
And the basic operation of optimizing that loss function, of minimizing that loss function,
is done with various variants of gradient descent.
It's hopefully a somewhat smooth function but it's a highly non-linear function.
This is why we can't prove much about neural networks, is it's a highly, high dimensional, highly non-linear function that's hopefully smooth enough
where the gradient descent can find its way to a least a good solution.
And there has to be some stochastic element there that
that jumps around to ensure that it doesn't get stuck in a local minimum of this very complex function.
Philosophical Motivation for Reinforcement Learning
Okay, that's supervised learning: there's inputs, there's outputs. Ground Truth.
That's our comfort zone, we're pretty confident we know what's going on. All you have to do is just, you have this data set you train and,
you train a network on that data set and you can evaluate it. You can write a paper and try to beat a previous paper. It's great.
The problem is when you then use that neural network to create an intelligent system that you put out there in the world,
and now that system is no longer is working with your data set. It has to exist in this world that's
maybe very different from the Ground Truth. So the take away from supervised learning
is that a neural network's a great memorization but in the sort of philosophical way they might not be great at generalizing,
at reasoning beyond the specific flavor of data set that they were trained on.
The hope for reinforcement learning is that we can extend the knowledge we gain in a supervised way
to the huge world outside where we don't have
the Ground Truth of how to act, how good a certain state is,
or how barristers say it is, this is a kind of brute force reasoning. And I'll talk about, kind of what I mean there, but it feels like
Agent and Environment
it's closer to reasoning as opposed to memorization. That's a good way to think of supervised learning - is memorization.
You're just studying for an exam. And as many of you know, that doesn't mean you're going to be successful in life just because you get an A.
And so, a reinforcement learning agent or just any agent;
a human being or any machine existing in this world
can operate in the following way from the perspective of the agent. You can execute an action;
it can receive an observation resulting from that action
in a form of a new state and it can receive a reward or punishment.
You can break down our existence in this way, simplistic view,
but it's a convenient one on the computational side and from the environment side,
the environment receives the action amidst the observation. So your action changes the world, therefore, that world has to change
and then tell you about it and give you a reward or punishment for it.
So, again one of the most fascinating things
I'll try to convey while this is fascinating a little bit later on,
is the work of deep mind on Atari.
This is Atari Breakout a game were a paddle has to move around.
That's the world it's existing in, the agent is the paddle and there's a bouncing ball
and you're trying to move, your actions are right: move right, move left.
You are trying to move in such a way that the ball doesn't get past you.
And so, here is a human level performance of that agent. And so what does this paddle have to do?
That's to operate in this environment; that's to act: move left, move right.
Each action changes the state of the world. It may seem obvious but
moving right changes visually the state of the world. In fact what we're watching now on the slides
is the world changing before your eyes for this little guy.
And it get rewards or punishments. Rewards it gets in the form of points,
they're racking up points in the top left of the video.
And then when the ball gets past the paddle, it gets punished by "dying".
And that's the number of lives there's left. Going from 5 to 4 to 3, down to 0.
And so the goal is to select at any one moment the action that maximizes future reward.
Without any knowledge of what a reward is in the greater sense of the word,
all you have is an instantaneous reward or punishment, instantaneous response of the world to your actions
Markov Decision Process
and this can be model as a mark of decision process. Mark of decision process is a mathematically convenient construct.
It has no memory, all you get is you have a state that you're currently in.
You perform an action, you get a reward. And you find yourself in a new state. And that repeats over and over.
You start from state 0, you go to state 1. You once again repeat an action, get a reward for the next state.
OK that's the formulation that we're operating in. When you're in a certain state, you have no memory of what happened two states ago.
Major Components of an Rl Agent
Everything is operating on the instantaneous.
Instantaneously. And so what are the major components of a reinforcement learning agent?
There's a policy. The function broadly defined an agent's behavior.
That means that includes the knowledge of how, for any given state,
what is an action that I will take with some probability.
Value function is how good each state and action are in any particular state.
And there's a model. Now this is a subtle thing that is
actually the biggest problem with everything you'll see today, is the model as how we represent the environment.
And we'll see today some amazing things that neural networks can achieve on a relatively simplistic model of the world
and the question whether that model can extend to the real world where human lives are at stake in the case of driving.
Robot in a Room
So let's look at the simplistic world. A robot in a room.
You start at the bottom left, Your goal is to get to the top right.
Your possible actions are going up, down, left and right.
Now this world can be deterministic which means when you go up, you actually go up.
Or it could be non-deterministic as human life is is
because when you go up, sometimes you go right. So in this case if you choose to go up, you move up 80% of the time.
You move left 10% of the time and you move right 10% of the time. And when you get to the top right you get a reward of +1
and you get to the second block from that, for two you get -1. You get punished.
And every time you take a step you get a slight punishment, a -0.04.
Is this a solution?
Okay. So the question is, if you start at the bottom left, is this a good solution?
Is this a good policy by which you exist in the world?
And it is if the world is deterministic. If whenever you choose to go up, you go.
Whenever you choose to go right, you go right.
But if the actions are stochastic, that's not the case.
Optimal policy
In what I described previously with point eight up and probability of .1 going left and right.
This is the optimal policy. Now if we punish every single step with a -2 as opposed to a -0.04.
Reward for each step-2
So every time you take a step,it hurts. You're going to try to get through a positive block as quickly as possible
and that's what this policy says. I'll walk through a negative one if I have to as long as I stop getting a -2.
Reward for each step: +0.01
Now if the reward for each step is a -.1, you might choose to go around that -1 block,
slight detour to avoid the pain.
And then you might take an even longer detour as the reward for each step goes up or the punishment goes down, I guess.
And then if there is an actual positive reward for every step you take
you'll avoid going to the finish line. You'll just wander the world.
We saw that with the Coast Racer yesterday,
the boat that chose not to finish the race because it was having too much fun getting points in the middle.
Value Function
So let's look at the world that this agent is operating in as a value function.
Now value function depends on a reward, the reward that comes from the future
and that reward is discounted because the world is stochasted, we can't expect the reward to come along to us in the way that
we hope it does based on the policy, based on the way we choose to act.
And so there's a gamma there that over time, as the award is farther and farther into the future discounts that reward.
Diminishes the impact of that future reward in your evaluation of the current state.
And so your goal is to develop a strategy that maximizes the discounted future reward.
The sum, the discounted sum, and reinforcement learning
Q Learning
there is a lot of approaches for coming up with a good policy,
a near optimal, an optimal policy. There's a lot of fun math there.
You could try to construct a model that optimizes some estimate of this world.
You can try in the Monte Carlo way through just simulate that world and see how it unrolls.
And as it unrolls you try to compute the optimal policy. Or what we'll talk about today is Q learning.
It's an off policy approach, where the policy is estimated as we go along.
The policy is represented as a Q-Function.
The Q-Function shown there on the left is,
I apologize for the equations, I lied. There'll be some equations.
The input to the Q-Function is a state at time t, "st".
An action they choose to take and that state "at".
and your goal is in that state to choose an action which maximizes the reward in the next step.
And what Q-Learning does, and I'll describe the process, is it's able to approximate through experience the optimal Q-Function,
the optimal function that tells you how to act in any state of the world.
You just have to live it. You have to simulate this world.
You have to move about it. You have to explore in order to see every possible state,
try every different action, get rewarded, get punished,
and figure out what is the optimal thing to do. That's done using this Bellman equation.
On the left, the output, is the new state. The estimate, the Q-Function estimate of the new state, for new action.
And this is the update rule at the core of Q Learning. You take the estimate, the old estimate, and add
based on the learning rate alpha from 0 to 1,
they update the evaluation of that state based on your new reward that you received at that time.
So you've arrived in this certain state as "t". You tried to do an action
and then you got a certain reward and you update your estimate of that state and action pair based on this rule.
When the learning rate is 0, you don't learn when alpha is 0.
You never change your world view based on the new incoming evidence.
When alpha is 1, every time change your world evaluation based on the new evidence.
Exploration vs Exploitation
And that's the key ingredient to Reinforcement Learning. First you explore, then you exploit.
First, you explore in a non-greedy way and then you get greedy. You figure out what's good for you and you keep doing it.
So if you wanted to learn an Atari game, First you try every single action, every state, you screw up,
get punished, get rewarded and, eventually, you figure out what's actually the right thing to do and you just keep doing it.
And that's how you win against the greatest human players in the world
in a game of "Go" for example, as we'll talk about. And the way you do that is you have an "Epsilon Greedy Policy"
that over time with a probability of 1 - Epsilon,
you perform an optimal Greedy action. With a probability of Epsilon, you perform a random action.
Random action being explore. And so, as epsilon goes down from 1 to 0 you explore less and less.
Q-Learning: Value Iteration
So the algorithm here is really simple. On the bottom of the slide there is the algorithm version,
the pseudo code version of the equation. The Bellman equation update.
You initialize your estimate of state action pairs arbitrarily,
a random number. This is an important point. When you start playing or living or doing whatever you're doing
in whatever you're doing with Reinforcement Learning or driving, you have no preconceived notion of what's good and bad, it's random.
Or however you choose to initialize it. And the fact that it learns anything is amazing.
I want you to remember that. That's one of the amazing things about Q-Learning at all
and then the Deep neural network version of Q-Learning.
The algorithm repeats the following step. You step into the world, observe an initial state, you select an action "a"
so that action, if you're exploring, will be a random action; if you're greedily pursuing the best, actually you can,
it will be the action that maximizes the Q-Function. You observe a reward after you take the action,
and a new state that you find yourself in. And then you update your estimate of the previous day you are in
having taken that action using that Bellman Equation Update.
And repeat this over and over. And so there on the bottom of the slide is a summary of life.
Q-Learning: Representation Matters
Yes. (CHUCKLING) Q-Function? Yes, yes. Yeah, it's a single- The question was
is the Q-Function a single value? And yes, it's just a single continuous value.
So the question was: "how do you model the world?"
So the way you model, so let's start, is very simplistic world of Atari paddle.
You think you model it as a paddle that can move left and right and there's some blocks and you model the physics of the ball.
That requires a lot of expert knowledge in that particular game. So you sit there hand crafting this model.
That's hard to do even for a simplistic game. The other model you could take
is looking at this world in the way the humans do visually.
So take the model in as a set of pixels. Just the model is all the pixels of the world.
You know nothing about paddles or balls or physics or colors and points, they're just pixels coming in.
That seems like a ridiculous model of the world but it seems to work for Atari. It seems to work for human beings.
When you're born, you see there's light coming into your eyes
and you don't have any, as far as we know,
you don't come with an instruction when you're born. You know there's people in the world
then there is good guys and bad guys, and there's this is how you walk.
No, all you get is light, sound and the other sensors.
And you get to learn about every single thing you think of as
the way you model the world is a learned representation and we will talk about how a neural network does that.
It learns to represent the world but if we have to hand model the world,
it's an impossible task. That's the question and if we have to hand model the world,
then that world better be a simplistic one. Yeah.
That's a great question. And so the question was: "what is the robustness of this model
if the way you represent the world is at all, even slightly different, from the way you thought that world is.
That's not that well studied as far as I'm aware. I mean, it's already amazing that you keep constructing,
if you have a certain import of the world, If you have a certain model of the world that you can learn anything is already amazing.
The question is, and it's an important one, is we'll talk a little bit about it,
not about the world model but the reward function. If the reward function is slightly different.
the real reward function of life or driving or of coast runner
is different than what you expected it to be. What's the negative there?
Yes, it could be huge. (CHUCKLING)
There's another question or no? Oh, no. Yes. Sorry, can you ask that again?
Yes, you can change it over. So the question was: "do you change alpha value over time?" You certainly should change alpha value over time, yes.
So the question was: "what is the complex interplay of the Epsilon Function with the Q-Learning Update?"
That's 100% fine-tuned to the particular learning problem.
So you certainly wanted-
The more complex, the larger the number of states in the world
and the larger the number of actions, the longer you have to wait
before you decrease the Epsilon to 0 but you have to play with it. And it's one of the parameters you have to play with, unfortunately,
and there's quite a few of them which is why you can't just drop a Reinforcement Learning agent into the world.
Oh, the effect in that sense? No, no. It's just a coin flip. And if that Epsilon is 0.5,
half the time you're going to take a random action. So there's no specific- It's not like you'll take the best action
and then with some probability take the second best, and so on. I mean you can certainly do that but in the simple formulation that works if you just take a random action
because you don't wanted to have a preconceived notion of what's a good action to try when you're exploring.
The wjhole point is you try crazy stuff, if it's a simulation.
So, good question. So representation matters.
This is the question about how we represent the world. So we can think of this world of break up, for example,
of this Atari game as a paddle the moves left and right.
and the exact position of the different things you can hit to construct this complex model,
this expert driven model that has to fine tune it to this particular problem.
But in practice the more complex this model gets,
the worse that Bellman Equation Update, that value that's trying to construct a Q-Function
for every single combination of state and actions becomes too difficult because that function is too sparse and huge
so if you think of looking at this world in a general way,
in the way human beings would is a collection of pixels visually. If you just take in a pixel,
this game as a collection of 84 by 84 pixels, an image, an RGB image,
And then you look at not just the current image, but look at the temporal trajectory of those images
so like if there's a ball moving you want to know about that movement. So you look at 4 images; so, current image and 3 images back
and say, they're gray scale with 256 gray levels that size of the Q-Table
that the Q value function has to learn is
whatever that number is, but it's certainly larger than the number of atoms in the universe. That's a large number.
So you have to run the simulation long enough to touch at least a few times the most of the states in that Q-Table.
So as Elon Musk says you may need to run,
you know, we live in a simulation, and you may have to run a universe just to compute the Q-Function in this case.
Philosophical Motivation for Deep Reinforcement Learning
So that's where deep learning steps in as instead of modeling the world as a Q-Table
you estimate, you try to learn that function.
And so, the takeaway from supervised learning, if you remember, that it's good at memorizing or good at memorizing data.
The hope for reinforcement learning With a Q-Learning is that we can extend
the occasional rewards we get to generalize over the operation,
the actions you take in that world leading up to the rewards. And the hope for deep learning is that we can move this
Reinforcement learning system into a world that doesn't need to be, they can be defined arbitrarily.
It can include all the pixels of an Atari game, can include all the pixels sense by a drone, a robot or car
but still needs a formalized definition of that world which is much easier to do when you're able to take in sensors like an image
So Deep Q-Learning, deep version.
So instead of learning a Q-Table, a Q-Function, we try in estimating that Q-Prime.
We try to learn it using machine learning. It tries to learn some parameters, this huge complex function.
We try to learn it and the way we do that as we have a neural network
the same kind that showed that learned the numbers to map from an image to a classification of that image into a number.
The same kind of network is used to take in a state, an action and produce a Q-Value.
Now here's the amazing thing: that without knowing anything in the beginning,
Deep Q-Network: Atari
as I said, with a Q-Table it's initialized randomly. The Q-Function. this deep network, knows nothing in the beginning.
All it knows is, in the simulated world, their words you get
for a particular game, so you have to play time and time again and see the rewards you get for every single iteration of the game.
But in the beginning it knows nothing. And it's able to learn to play better than human beings.
This is a deep mind paper playing Atary with deep reinforcement learning from 2013.
There's one other key things that got everybody excited about the role of deep learning in artificial intelligence
is that using a convolutional neural work, which I'll talk about tomorrow,
but it's a vanilla network, like any other like I talk about earlier today, just a regular network
That takes the raw pixels, as I said, and estimates that Q-Function from the raw pixels as able to play on many of those games
better than a human being. And the lost function that I mentioned previously,
Deep Q-Network Training
so, again, very vanilla lost function,
very simple objective function. The first one you'll probably implement. We have a tutorial on TensorFlow.
Squared Error. So we take this Bellman Equation where the estimate is Q-
The Q-Function Estimate of state and action is the maximum reward you get for taking any of the actions
that take you to any of the future states. And you try to take that action, observe the result of that action,
and if the target is different that your learn target,
what the function is learned is the expected reward in that case, is different than what you actually got you adjust it.
You adjust the weights of the network. And this is exactly the process by which we learn
how to exist in this pixel world. So your mapping states and actions to a Q-Value,
the algorithm is as follows. This is how we train it. We're given a transition as current state action taken in that state
are the rewards you get, an S-Prime, as what the state you find yourself in.
And so we replace the basic of their rule, in the previous pseudo code,
by taking a forward pass through the network given that S-state.
We'll look at what the predicted Q-value is of that action.
We then do another forward pass through that network and see what we actually get.
And then if we're totally off, we punish,
we Back Propagate the weights in a way that. next time we'll make less of that mistake. And you repeat this process.
This is a simulation. You're learning against yourself.
And again, the same rule applies here. exploration versus exploitation.
You start out with an Epsilon of 0 or 1, you are mostly exploring.
And then you move towards an Epsilon of 0. And with Atari Breakout. this is the deep mind paper result
Atari Breakout
is Training Epochs on the x-axis, on the y-axis is the average action value
and the average reward per episode. I'll show why it's kind of a an amazing result but it's messy
because there's a lot of tricks involved. So it's not just putting in a bunch of pixels of a game
and getting an agent that knows how to win at that game. there's a lot of pre-processing and playing with the data required.
So which is unfortunate because the truth is messier than the hope
but one of the critical tricks needed is called experience replay.
So as opposed to letting an agent, So you're learning this big network that tries
to build a model of what's good to do in the world and what's not.
And you're learning as you go. With experience replay you're keeping a track
of all the things you did. And every once in a while, you look back into your memory and pull out some of those old experiences.
the good old times and trying on those again. As opposed to letting the agent run itself into some local optima
where it tries to learn a very subtle aspect of the game that actually in the global sense
doesn't get you farther to winning the game. Very much like life.
Deep Q-Learning Algorithm
So here's the algorithm, deep Q learning algorithm pseudo code.
We initialize the replay memory, again there's this little trick that's required.
Is keeping a track of stuff that's happened in the past, we initialize the action value function Q with random weights
and observe initial state, again same thing. Select an action with the probability Epsilon
explore, otherwise choose the best one based on the estimate provided by the neural network.
And then carry out the action, observe the reward and store that experience in the replay memory
and then sample random transition from replay memory.
So with a certain probability, you bring those old times back
to get yourself out of the local minima and then you train the Q-network
using the difference between what you actually got
and your estimate and you repeat this process over and over.
So here's what you can do after ten minutes of training on the left, so that's very little training, what you get is
a paddle that learns hardly anything and it just keeps dying.
It goes from 5 to 4 to 2 to 2 to 1, Those are the number of lives left.
Then after two hours of training in a single GPU,
it learns to win, you know, not die. Rack up points
and learns to avoid the ball from passing the paddle which is great.
That's human level performance really, better than some humans, you know, but it still dies sometimes so it's very human level.
And then after four hours it does something really amazing.
It figures out how to win the game in a very lazy way
which is drill a hole through the blocks up to the top
and get the ball stuck up there. And it does all the hard work for you. That minimizes the probability of the ball getting pas your paddle
because it's just stuck in the in the blocks up top.
So that might be something that you wouldn't even figure out to do yourself. And that's- I need to sort to pause here
to clearly explain what's happening. The input to this algorithm is just the pixels of the game.
It's the same thing that human beings take in when they take visual perception and it's able to learn
under this constrained definition of what is a reward and a punishment.
It's able to learn to get a high reward.
That's general artificial intelligence. A very small example of it but its general.
It's general purpose, it knows nothing about games and knows nothing about paddles or physics.
It's just take answer input of the game and they've did the same thing for a bunch of different games in Atari
And what's shown here in this plot on the x-axis is a bunch of different games from Atari
and on the y-axis is a percentile where 100% is about the best that human beings can do.
Meaning it's the score that human beings who get so everything about there in the middle, everything to the left of that
is far exceeding human low performance and below that is on par or worse than human performance.
So it can learn so many- Boxing, Pinball,
all of these games, and it doesn't know anything about any of the individual games, it's just taking in pixels.
It's just as if you put a human being. behind any of these games and
ask them to learn to be beat the game.
and there's been a lot of improvements in this algorithm recently. Yes, question.
No. So the question was: "do they customize the model for game, for a particular game?
And no, the point- You could, of course, but the point is it doesn't need to be customized for the game but
the important thing is that it's still only on Atari games.
Alright, so the question whether this is transferable to driving, Perhaps not.
Right, you play the game where you do. No, you don't have the- Well, yeah you play one step of the game.
So you take action in a state and then you observe that.
So you have that simulation. I mean, really that's one of the biggest problems here
is you require the simulation in order to get the Ground Truth.
So that's a great question or comment. The comment was that for a lot of these situations,
the reward function might not change at all depending on your actions. The rewards are really, most of the time, delayed
10, 20, 30 steps down the line which is why
It is amazing that this works at all. That it's learning locally.
and through that process of simulation of hundreds a thousand times runs through the game, It's able to learn what to do now such that I get a reward later.
It's if you just pause, look at the math of it. It's very simple math and look at the result, it's incredible.
So there's a lot of improvements, this one called the general reinforcement learning architecture Gorila.
The cool thing about this in the simulated world at least is that you can run deep reinforcement learning in a distributed way.
You could do both the simulation in a distributed way, you can do the learning in the distributed way,
you can generate experiences which is what this kind of diagram shows, you can, either from human beings or from simulation.
So for example, the way that Alpha Go the deep mind team
is beat the game of Go is they learn from both expert games and by playing itself.
So, you can do this in a distributed way and you could do the learning in a distributor way so you can scale.
And in this particular case, the Gorila has achieved
the better result than the DQN network and that's part of the their nature paper.
Okay, so let me now get to driving for a second here
where words of reinforcement learning,
where reinforcement learning can step in and help. So this is back to the open question they asked yesterday:
is driving closer to chess or to everyday conversation? Chess, meaning it can be formalized in a simplistic way
and if you could think about it as an obstacle avoidance problem and once the obstacle avoidance is solved,
you just navigate that constrained space you choose to move left, you choose to move right in a lane
you choose to speed up or slow down. Well, if it's a game like chess which we'll assume for today.
as opposed to for tomorrow, for today we're going to go with the one on the left
and we're going to look at DeepTraffic. Here is this game of simulation
where the goal is to achieve the highest average speed you can
on this seven lane highway full of cars.
And so, as a side note for students, the requirement is they have to follow the tutorial that I'll present a link for
at the end of this presentation. And what they have to do is achieve a speed,
build a network that achieves a speed of 65 miles an hour or higher.
There is a leaderboard and you get to submit the model you come up with with a simple click of a button.
So all of this runs in the browser which is also another amazing thing.
And then you immediately or relatively so, make your way up the leaderboard.
So let's look, let's zoom in. What is this world, two-dimensional world of traffic is,
what does it look like for the intelligent system?
We descritize that world into a grid shown here on the left. That's the representation of the state.
There are seven lanes and every single lane is broken up into blocks spatially.
And if there is a car in that block, the length of a car is about 3 blocks,
3 of those grid blocks, then that grid is seen as occupied.
and then the red car is you. That's the thing that's running in the intelligent agent.
There is on the left, is the current speed of the red car, actually says MIT on top.
And then you also have a count of how many cars you passed and if your network sucks then that number is going to get to be negative.
You can also change with a drop down the simulation speed from normal on the left to fast on the right.
So, you know, the fast speads up the replay of the simulation.
The one on the left, normal, it feels a little more like real driving.
There is a drop down for different display options. The default is non, in terms of stuff you show on the road.
Then there is the learning input which is the, while that whole space is descritized,
you can choose what your car sees
and that's you could choose how far ahead it sees behind, how far to the left and right It sees.
And so by choosing the learning input, to visualize learning input, you get to see what you set that input to be.
Then there is the safety system. This is a system that protects you from yourself.
The way we've made this game is they operates under something similar
if you have some intelligence in if you're driving you have adaptive cruise control in your car.
It operates in the same way. When he gets close to the car in front, It slows down for you It operates in the same way. When he gets close to the car in front, It slows down for you
and it doesn't let you run the car to the left of you, to the right of you, off the road.
So constrains the movement capabilities of your car
in such a way that you don't hit anybody because then it would have to simulate collisions and that would just be a mess.
So, it protects you from that and so you can choose to visualize that "safety system" with a visualization box.
And then you can also choose to visualize the full map. This is the full occupancy map that you get
if you would like to provide as input to the network.
Now that input for every single grid that it's a number. It's not just a 0, 1 whether there's a car in there.
It's the maximum speed limit which is 80 miles per hour.
Don't get crazy eighty miles an hour is the speed limit. That block when it's empty is set to the 85 miles eighty miles an hour.
And when it's occupied, it's set to the number that is the speed of the car.
And then, the blocks that the red car is occupying is set to the number, to a very large number
much higher than the speed limit.
So safety system, here shown in red, are the parts of the grid that your car can't move into.
Question. What's that?
Yes. Yes. The question was: "what was the third option I just mentioned and
t's you the red car itself, you yourself, the blocks underneath that car I set to really high number.
It's a way for the algorithm to know, for the learning algorithm to know that these blocks are special.
So safety system, shows read here, if
the car can't move into those blocks. So ,in terms of when it lights up red, it means
the car can't speed up anymore in front of it and when the blocks to the left or to the right light up as red
that means you can't change lanes to the left or right. On the right of the slide, you're free to go,
free to do whatever you want. That's what that indicates is all the blocks are yellow.
Safety system says you're free to choose any of the five actions. In the five actions are move left, move right,
same place, accelerate or slow down.
And those actions are given as input. That action was produced by the what's called here, the brain.
The brain takes in the current state as input, the last reward, and produces and learns and uses that reward
to train the network through backward function there,
back propagation, and then ask the brain given the current state,
to give it the next action with the forward pass, the forward function. You don't need to know the operation of this function in particular,
this is not something you need to worry about, but you can if you want, you can customize this learning step.
There's, by the way, what I'm describing now there's just a few lines of code right there in the browser
that you can change immediately with the press of a button
changes the simulation or the design of the network. You don't need to have any special hardware,
you dont' need to do anything special. And the tutorial cleanly outlines exactly all of these steps
but it's kind of amazing that you can design a deep neural network that's part of the reinforcement learning agent.
So it's a deep Q learning agent right there in the browser.
So you can choose the lane side variable which controls how many lanes to the side you see.
So in that value zero you only look forward. When their values 1, you have one lane to the left, one valid to the right.
It's really the lane the radius of your perception system. Patches ahead is how far ahead you look;
patches behind is how far behind you look. And so for example here, the lane side equals 2 that means
it looks to the left, to the right; obviously, if to the right, is off road.
It provides a value of 0 in those blocks.
If we set the patches behind to be 10, it looks 10 patches back behind starting at the 1 patch back is starting from the front of the car.
The scoring for the evaluation of the competition
is your average speed over a predefined period of time. And so the method we do we use to collect that speed
is we we run the agent 10 runs, about 30 simulated minutes of game each.
And take the median speed of the 10 runs. That's the score.
This is done server side and so given that we've gotten some
for this code recently gotten some publicity online unfortunately.
This might be a dangerous thing to say there's no cheating possible. But because it's done server side and this is javascript
and runs in the browser, it's hopefully a sandbox. So we can't do anything tricky but we dare you to try.
You can try it locally to get an estimate, you know, and there's a button that says evaluate and it gives you a score right back
of how well you're doing with the current network.
That button is: Start Evaluation Run; you press the button.
It does a progress bar and gives you the average speed
There's a code box where you modify all the variables I mentioned
and the tutorial describe this in detail. And then once you're ready, you modify a few things
you can press apply code it restarts, it kills all the training
that you've done up to this point or resets it and start the training again.
So save often and there's a save button. So the training is done a separate thread in Web Workers
which are exciting things that allow javascript to run
amazingly on multiple CPU Cores in a parallel way.
So the simulation that scores this or, sorry, the training is done a lot faster than real time, a thousand frames a second.
That's a thousand movement steps a second. This is all in javascript.
And the next they get shipped to the main simulation from time to time as the training goes on.
So all you have to do is press run training. And it trains and the car behaves better over time.
Maybe like I should show it in the browser.
Let's see if will work well, is this going to mess up? We're good.
What can possibly go wrong?
So there's the game. When it starts, this is running live in the browser.
Artificial intelligence, ladies and gentleman in the browser. a neural network.
So currently it's not very good, it's driving at 2 miles an hour and watching everybody pass.
So what's being shown live is the lost function which is pretty poor.
So in order to train, like I said, a thousand frames a second
you just press the "Run Training" button and pretty quickly it learns based on the network you specify in the code box, how to-
and based on the input and all the things that I mentioned, training finished. It learns how to do a little better.
We, on purpose. put in a network that's not very good in there. So right now I won't, on the average, be doing that well
but it does better than standing there in place and then you could do the start Evaluation Run
to simulate the network much faster than real time, to see how well it does
This is a similar evaluation step that we take when determining where you stand on the leaderboard
at the current current average speed. In that 10 run simulation is 56.56 miles per hour.
Now, I may be logged in, maybe not. If you're logged in, you click "Submit your code."
If you're not logged in, it says: "You're not logged in. Please log in to submit your code."
And then all you have to do is log in. This is the most flawless demo of my life.
And then you press "Submit Model" again and success. Oh man.
"Thank you for your submission." And so now my submission is entered as "Lex" in the leaderboard
and my 56.56, or whatever it was. So I dare all of you to try to beat that. So too.
As as you play around with stuff if you want to save the code
you could do so by pressing the "Save Code" button. That saves the various javascript configurations
and that saves the network layout to file. And you can load from files as well. the danger it overrides the code for you.
And you press the "Submit" button to submit the model to the competition. Make sure that you train the network, we don't train it for you.
You submit a model and you have to press "Train". And he gets evaluated the time it enters a queue to get evaluated.
This is public phasing so the queue can grow pretty big and it goes to that queue, evaluates it and then depending on where you stand
you get added to the leaderboard showing the top ten entries. You can resubmit often and only the highest score counts.
Okay, we're using code- Now implementation of neural networks done in just javascript
by Andrej Karpathy from Stanford now OpenAI. ConvNet.JS is a library and what's being visualized there
is also being visualized in the game is the inputs to the network. In this case it's 135 inputs. You can also specify not just the
how far ahead behind you're seeing to the left and to the right, you can specify how far back in time you look as well.
And so what's visualize there is the input to the network 135 neurons
and then the output, a regression, similar to the kind of opo we saw with numbers where there's 10 outputs saying
if it's a 0, 1 through 9, here the output is one of the five actions:
left, right, stay in place, speed up or slow down. The ConvNet.JS settings is you can select a number of inputs
if you want to mess with this stuff, this is all stuff you don't need to mess with because we already gave you the variables of lane side and patches ahead and so on.
You can select a number of actions, the temporal window and the network size.
So the network definition here is the-
This is the input, the size of the input. Again all this is in the tutorial just to give you a little outline.
There is the first fully connected layer has 10 neurons
with relu activation functions, same kind of smooth
function that we talked about before and the regression layer for the output.
And there's a bunch of other messy options you play with if you dare.
But those aren't, the ones I mentioned before is really the important ones. Selecting the number of layers, the size of those layers,
you get to build your own very neural network that drives. And the actual learning is done with a backward propagation
and then that returns the action by doing a forward pass to the network.
In case you're interested in this kind of stuff, there is an amazingly cool code editor.
That's the Monaco Editor. It just works, it does some auto-completions
so you get to play with it makes everything very convenient in terms of coding editing.
A lot of this visualization of the game and the simulation we'll talk about tomorrow
is done in the browser using HTML5 canvas. So here is a simple specification of a blue box with canvas
and this is very efficient and easy to work with.
And the thing that a lot of us are excited about, a very subtle one, but there you can, not just run.
So with the V8 Engine javascript has become super fast. You could train neural networks in the browser that's already amazing.
And then with Web Workers as long as you have Chrome, a modern browser.
You can run multiple processes in separate threads
so you could do a lot of stuff you can do visualization separately and you can train separate threads, very cool.
Okay. so the tutorial is cars.mit,edu/deeptraffic. We won't put these links on the website for a little bit because.
We got put on the front page of Hacker News which we don't want those to leak out
especially with the claims the you can't cheat.
And while it's pretty efficient in terms of running everything on your machine, client side,
it's still. you have to pull some images here and pull some of the code. So the tutorials on cars.mit,edu/deeptraffic and the simulation is deeptrafficjs
So cars.mit,edu/deeptrafficjs I encourage you to go there play with the network submit your code.
and win the very special prize and it is pretty cool one but we're still working on it.
There is a prize I swear. All right so let's take a pause and think about what we talked about today.
So the very best of deep reinforcement learning is the most exciting accomplishment,
I think, is when the game- When I first started as a freshman, took "Intro to Artificial Intelligence"
it was said that it's a game that's impossible for machines to beat because of the combinatorial complexity they just
the sheer number of options. it's so much more complex than chess and so the most amazing accomplishment of deep reinforcement learning
to me is the design of AlphaGo when for the first time the world champion in Go was beaten
by DeepMind AlphaGo and the way they did it
and this is, I think very relevant to driving is you start by creating first in a supervised way training a policy network.
So you take expert games to construct a network first so you look you don't play against yourself.
They agent doesn't play against itself but they learn from expert games, so there is some human Ground Truth.
This Human Ground Truth represents reality, so for driving this is important We have a- Well we're starting to get a lot of data were video of drivers is being recorded.
So we can learn on that data before would then run the agents through a simulation where it learns much larger magnitudes
of data sets through simulation. And they did just that. Now as a reminder that when you let an agent drive itself.
This is probably one of the favorite videos of all time but I just recently saw a cyclist and just watch this for hours.
but it's a reminder that you can't trust your first estimates of a reward function to be those that are safe
and productive for our society when you're talking about an intelligence system that gets to operate in the real world.
This is just as clear of a reminder of that as there is. So again all the references are available online.
For these slides. we'll put up the slides. I imagine you might have, if you want to come down and talk to us for questions for the either Docker
or javascript. Question. The question was: "What is the visualization you're seeing in deep traffic?"
You're seeing a car move about. Why is it moving? It's moving based on the latest snapshot of the network you trained, so it's just visualizing; for you, just for fun.
The network you train most recently. Okay so if people have questions, stick around afterwards. Just details on Docker and [CHUCKLING]- Yes. Do you want to do it offline?

----------

-----

--15--

-----
Date: 2017.01.16
Link: [# MIT 6.S094: Introduction to Deep Learning and Self-Driving Cars](https://www.youtube.com/watch?v=1L0TKZQcUtA)

Transcription:
Intro
Alright. Hello everybody. Hopefully you can hear me well. Yes?
Yes. Great! So, welcome to Course 6.S094.
Deep Learning for Self-Driving Cars. We will introduce to you the methods of deep learning,
of deep neural networks using the guiding case study of building self-driving cars.
My name is Lex Fridman. You get to listen to me for a majority of these lectures
and I am part of an amazing team with some brilliant TAs.
Would you say brilliant? (CHUCKLES) Dan Brown.
You guys want to stand up? They're in the front row. Spencer, William Angell.
Administrative
Spencer Dodd and all the way in the back. The smartest and the tallest person I know, Benedict Jenik.
Well you see there on the left of the slide is a visualization of one of the two projects that one of the two simulations, games that we'll get to go through.
We use it as a way to teach you about deep reinforcement learning but also as a way to excite you.
By challenging you to compete against others if you wish to in a special prize yet to be announced.
Super secret prize. So you can reach me and the TA's at deepcars@MIT.edu if you have any questions about the tutorials, about the lecture, about anything at all.
The website cars.mit.edu has the lecture content. Code tutorials, again like today, the lectures slides for today are already up in PDF form.
The slides themselves, if you want to see them just e-mail me but there are over a gigabyte in size because they're very heavy in videos so I'm just posting the PDS.
And there will be lecture videos available a few days after the lectures were given.
So speaking of which there is a camera in the back. This is being videotaped and recorded but for the most part the camera is just on the speaker.
So you shouldn't have to worry. If that kind of thing worries you then you could sit on the periphery of the classroom
or maybe I suggest sunglasses and a moustache, fake mustache, would be a good idea.
There is a competition for the game that you see on the left. I'll describe exactly what's involved
in order to get credit for the course you have to design a neural network that drives the car just above the speed limit sixty five miles an hour.
But if you want to win, we need to go a little faster than that.
So who's this class is for? You may be new to programming,
new to machine learning, new to robotics, or you're an expert in those fields but want to go back to the basics.
So what you will learn is an overview of deep reinforcement learning, of convolutional neural networks,
recurring neural networks and how these methods can help improve each of the components of autonomous driving -
perception, visual perception, localization, mapping, control planning and the detection of driver state.
Okay, two projects. Code named "DeepTraffic" is the first one.
Project: Deep Traffic
There is, in this particular formulation of it, there is seven lanes. It's a top view.
It looks like a game but I assure you it's very serious. It is the agent in red,
the car in red is being controlled by a neural network and we'll explain how you can control and design the various aspects, the various parameters of this neural network
and it learns in the browser. So this, we're using ConvNet.JS
which is a library that is programmed by Andrej Karpathy in javascript.
So amazingly we live in a world where you can train in a matter of minutes
a neural network in your browser. And we'll talk about how to do that. The reason we did this
is so that there is very few requirements to get you up and started with neural networks.
So in order to complete this project for the course, you don't need any requirements except to have a Chrome browser.
And to win the competition you don't need anything except the Chrome browser.
Project: DeepTesla
The second project code name "DeepTesla" or "Tesla"
is using data from a Tesla vehicle
of the forward road way and using end-to-end learning taking the image and putting into convolutional neural networks
that directly maps "or aggressor" that maps to a steering angle.
So all it takes is a single image and it predicts a steering angle for the car.
We have data for the car itself and you get to build a neural network that tries to do better,
tries to steer better or at least as good as the car. Okay.
Let's get started with the question,
with the thing that we understand so poorly at this time because it's so shot in mystery
but it fascinates many of us. And that is the question of: "What is intelligence?"
This is from a March 1996 Time magazine.
And the question: "Can machines think?" is answered below with, "they already do."
So what if anything is special about the human mind? It's a good question for 1996,
a good question for 2016, 2017 now, and the future.
And there's two ways to ask that question. One is the special purpose version.
Can an artificial intelligence system achieve a well defined,
specifically, formally defined finite set of goals? And this little diagram
Defining Artificial Intelligence
from a book that got me into artificial intelligence as a bright-eyed high school student
they are artificial intelligence to modern approach. This is a beautifully simple diagram of a system.
It exists in an environment. It has a set of sensors that do the perception.
It takes those sensors in. It does something magical. There's a question mark there. And with a set of affectors acts in the world, manipulates objects in that world,
and so special purpose. We can,
under this formulation, as long as the environment is formally defined, well defined; as long as a set of goals are well defined.
As long as the set of actions, sensors, and the ways that the perception carries itself out as well defined.
We have good algorithms which will talk about that can optimize for those goals.
The question is, if we inch along this path,
will we get closer to the general formulation, to the general purpose version of what artificial intelligence is?
Can it achieve poorly defined, unconstrained set of goals with an unconstrained, poorly defined set of actions
and unconstrained, poorly defined utility functions rewards.
This is what human life is about. This is what we do pretty well most days.
Exist in an undefined, full of uncertainty, world.
So, okay. We can separate tasks into three different, categories, formal tasks.
This is the easiest. It doesn't seem so, it didn't seem so at the birth of artificial intelligence
but that's in fact true if you think about it. The easiest is the formal tasks, playing board games, theory improving.
All the kind of mathematical logic problems that can be formally defined.
Then there is the expert tasks. So this is where a lot of the exciting breakthroughs have been happening
where machine learning methods, data driven methods, can help aid or improve on
the performance of our human experts. This means medical diagnosis, hardware design,
scheduling, and then there is the thing that we take for granted. The trivial thing.
The thing that we do so easily every day when we wake up in the morning.
The mundane tasks of everyday speech, of written language, of visual perception,
of walking which we'll talk about in today's lecture is a fascinatingly difficult task
on object manipulation. So the question is that we're asking here,
before we talk about deep learning, before we talk about the specific methods, we really want to dig in and try to see what is it about driving,
how difficult is driving. Is it more like chess which you see on the left there
How Hard is Driving?
where we can formally define a set of lanes, a set of actions and formulate it as there's five set of actions - you can change your lane,
you can avoid obstacles. You can formally define an obstacle. You can the formally define the rules of the road.
Or is there something about natural language, something similar to everyday conversation about driving
that requires a much higher degree of reasoning, of communication,
of learning, of existing in this under-actuated space. Is it a lot more than just left lane,
right lane, speed up, slow down? So let's look at it as a chess game.
Chess Pieces: Self-Driving Car Sensors
Here's the chess pieces. What are the sensors we get to work with on an autonomous vehicle?
And we get a lot more in-depth on this especially with the guest speakers who built many of these.
There's radar. There's the Rays sensors. Radar lidar. They give you information about the obstacles in their environment.
They'll help localize the obstacles in the environment. There's the visible light camera and stereo vision that gives you texture information,
that helps you figure out not just where the obstacles are but what they are, helps to classify those,
has to understand their subtle movements.
Then there is the information about the vehicle itself, about the trajectory and the movement of the vehicle that comes from the GPS
an IMU sensors. And there is the rich state of the vehicle itself.
What is it doing? What are all the individual systems doing that comes from the canned network.
And there is one of the less studied but fascinating to us on the research side is audio.
The sounds of the road that provide the rich context
of a wet road. The sound of a road that when it stop raining but it's still wet,
the sound that it makes. The screeching tire and honking.
These are all fascinating signals as well. And the focus of the research in our group,
the thing that's really much under-investigated
is the internal facing sensors. The driver, sensing the state of the driver,
were they looking? Are they sleepy? The emotional state. Are they in the seat at all?
And the same with audio. That comes from the visual information and the audio information.
Chess Pieces: Self-Driving Car Tasks
More than that. Here are the tasks. If you were to break into modules the tasks
of what it means to build a self-driving vehicle. First, you want to know where you are.
Where am I. Localization and mapping. You want to map the external environment.
Figure out where all the different obstacles are, all the entities are,
and use that estimate of the environment to then figure out where I am,
where the robot is. Then there is scene understanding.
It's understanding not just the positional aspects of the external environment and the dynamics of it
but also what those entities are. Is it a car? Is it a pedestrian? Is it a bird?
There is movement planning. Once you have kind of figured out to the best of your abilities
your position and the position of other entities in this world, it's figuring out a trajectory through that world.
And finally, once you've figured out how to move about safely and effectively through the world
it's figuring out what the human that's on board is doing because as I will talk about
the path to a self-driving vehicle and that is, hence, our focus on Tesla
may go through semi-autonomous vehicles.
Where the vehicle must not only drive itself
but effectively hand over control from the car to the human
and back. Ok, quick history. Well, there's a lot of fun stuff from the eighty's and ninety's but
DARPA Grand Challenge II (2006)
the big breakthroughs came in the second DARPA Grand Challenge
with Stanford Stanley, when they won the competition. One of five cars that finished.
This was an incredible accomplishment in a desert race.
A fully autonomous vehicle was able to complete the race in record time.
DARPA Urban Challenge (2007)
The DARPA Urban Challenge in 2007
where the task was no longer a race to the desert
but through an urban environment and CMU's "Boss" with GM won that race
Industry Takes on the Challenge
and a lot of that work went directly into the
acceptance and large major industry players
taking on the challenge of building these vehicles. Google, now "Waymo" self-driving car.
Tesla with its "Autopilot" system and now "Autopilot 2" system.
Uber with its testing in Pittsburgh. And there's many other companies
including one of the speakers for this course of nuTonomy that are driving the wonderful streets of Boston.
How Hard is it to Pass the Turing Test?
Ok. So let's take a step back. We have, if we think about the accomplishments in the DARPA Challenge,
and if you look at the accomplishments of the Google self-driving car
which essentially boils the world down into a chess game.
It uses incredibly accurate sensors to build a three dimensional map of the world,
localize itself effectively in that world and move about that world
in a very well-defined way.
Now, what if driving... The open question is: if driving is more like a conversation,
like in natural language conversation, how hard is it to pass the Turing Test?
The Turing Test, as the popular current formulation is, can a computer be mistaken for a human being
in more than thirty percent of the time? When a human is talking behind a veil,
having a conversation with their computer or a human, can they mistake the other side of that conversation
for being a human when it's in fact a computer.
And the way you would, in a natural language, build a system that has successfully passes the Turing Test is,
the natural language processing part to enable it to communicate successfully? So, general language and interpret language,
then you represent knowledge the state of the conversation transferred over time.
And the last piece and this is the hard piece, is the automated reasoning,
is reasoning. Can we teach machine learning methods to reason?
That is something that will propagate through our discussion because as I will talk about the various methods,
the various deep learning methods, neural networks are good at learning from data
but they're not yet, there is no good mechanism for reasoning. Now reasoning could be just something
that we tell ourselves we do to feel special. Better to feel like we're better than machines.
Reasoning may be simply something as simple as learning from data.
We just need a larger network. Or there could be a totally different mechanism required
and we'll talk about the possibilities there.
Yes. (Inaudible question from one of the attendees)
No, it's very difficult to find these kind of situations in the United States. So the question was,
for this video, is it in the United States or not? I believe it's in Tokyo.
So India, as is a few European countries, are much more towards the direction
of natural language versus chess.
In the United States, generally speaking, we follow rules more concretely.
The quality of roads is better. The marking on the roads is better. So there's less requirements there.
(Inaudible question from one of the attendees)
These cars are are driving on one side?
I see. I just- Okay, you're right. It is because, yeah-
So, but it's certainly not the United States.
I spent quite a bit of googling trying to find in the United States and it is difficult.
Neuron: Biological Inspiration for Computation
So let's talk about the recent breakthroughs in machine learning
and what is at the core of those breakthroughs is neural networks
that have been around for a long time and I will talk about what has changed.
What are the cool new things and what hasn't changed and what are its possibilities.
But first a neuron, crudely,
is a computational building block of the brain. I know there's a few folks here, neuroscience folks,
this is hardly a model. It is mostly an inspiration
and so the human neuron
has inspired the artificial neuron the computational building block of a neural network,
of an artificial neural network. I have to give you some context.
These neurons, for both artificial and human brains, are interconnected.
And the human brain, there's about, I believe 10,000 outgoing connections from every neuron
on average and they're interconnected to each other,
are the largest current, as far as I'm aware, artificial neural network, has 10 billion of those connections.
Synapses. Our human brain, to the best estimate that I'm aware of,
has 10,000X that.
So one hundred to one thousand trillion synapses.
Perceptron: Forward Pass
Now what is an artificial neuron?
That is the building block of a neural network. It takes a set of inputs.
It puts a weight on each of those inputs, sums them together,
applies a bias value on each neuron
and using an activation function that takes its input,
that sum plus the bias and it squishes it together
to produce a zero to one signal.
Perceptron Algorithm
And this allows us a single neuron to take a few inputs and produces an output
a classification for example, a zero one. And then we'll talk about, simply, it can
serve as a linear classifier so it can draw a line. It can learn to draw a line between, like what you'd seen here,
between the blue dots and the yellow dots. And that's exactly what we'll do in the iPython Notebook that I'll talk about
but the basic algorithm is you initialize the weights on the inputs and you compute the output.
You perform this previous operation I talked about sum up and compute the output.
And if the output does not match the ground truth,
The expected output, the output it should produce, the weights are punished accordingly
and will talk through a little bit of the math of that.
And this process is repeated until the perceptron does not make any more mistakes.
Neural Networks are Amazing
Now here's the amazing thing about neural networks.
There are several and I'll talk about them. One on the mathematical side is the universality of neural networks
with just a single layer if you stack them together, a single hidden layer,
the inputs on the left, the outputs on the right. And in the middle there is a single hidden layer,
it can closely approximate any function. Any function.
So this is an incredible property that with a single layer any function you could think of,
that you could think of driving as a function. It takes its input,
the world outside as output to control the vehicle.
There exists a neural network out there that can drive perfectly.
It's a fascinating mathematical fact.
Special Purpose Intelligence
So we can think of this then these functions as a special purpose function, special purpose intelligence.
You can take, say as input, the number of bedrooms, the square feet,
the type of neighborhood. Those are the three inputs.
It passes that value through to the hidden layer.
And then one more step. It produces the final price estimate for the house or for the residence.
And we can teach a network to do this pretty well in a supervised way. This is supervised learning.
You provide a lot of examples where you know the number of bedrooms, the square feet,
the type of neighborhood and then you also know the final price of the house or the residence.
And then you can, as I'll talk about through a process of back propagation, teach these networks to make this prediction pretty well.
General Purpose Intelligence
Now some of the exciting breakthroughs recently have been in the general purpose intelligence.
This is is from Andrej Karpathy who is now at OpenAI.
I would like to take a moment here to try to explain how amazing this is.
This is a game of "pong". If you're not familiar with "pong", there are two paddles
and you're trying to bounce the ball back and in such a way that prevents the other guy from bouncing the ball back at you.
The artificial intelligence agent is on the right in green and up top is the score 8-1.
Now this takes about three days to train on a regular computer, this network.
What is this network doing? It's called the Policy Network.
The input is the raw pixels. There's slightly a process and also you take the difference between two frames
but it's basically the raw pixel information. That's the input.
There's a few hidden layers and the output is the single probability of moving up.
That's it. That's the whole system and what it's doing is, it learns.
You don't know at any one moment,
you don't know what the right thing to do is. Is it to move up? Is it's moved down? You only know what the right thing to do is
by the fact that eventually you win or lose the game. So this is the amazing thing here is, there's no supervised learning.
There's no universal fact about anyone stay being good or bad.
And anyone actually being good or bad in the state but if you punish or reward every single action you took,
every single action you took, for an entire game based on the result. So no matter what you did, if you won the game,
the end justifies the means. If you won the game, every action you took in every every action state pair gets rewarded.
If you lost the game, it gets punished. And this process, with only two hundred thousand games
where the system just simulates the games, it can learn to beat the computer.
This system knows nothing about "pong", nothing about games,
this is general intelligence. Except for the fact, that it's just a game "pong".
And I will talk about how this can be extended further,
why this is so promising and why we should proceed with caution.
So again, there's a set of actions you take up, down, up, down, based on the output of the network.
There's a threshold given the probability of moving up, you move up or down based on the output of the network.
And you have a set of states and every single state action pair is rewarded if there's a win
and it's punished if there's a loss.
When when you go home, think about how amazing that is
and if you don't understand why that's amazing, spend some time on it.
It's incredible. (Inaudible question from one of the attendees)
Sure, sure thing. The question was: "What is supervised learning? What is unsupervised learning? What's the difference?"
So supervised learning is, when people talk about machine learning they mean supervised learning most of the time.
Supervised learning is
learning from data, is learning from example. When you have a set of inputs and a set of outputs that you know are correct or
called Ground Truth. So you need those examples, a large amount of them,
to train any of the machine learning algorithms to learn to then generalize that to future examples.
Actually, there's a third one called Reinforcement Learning where the Ground Truth is sparse.
The information about when something is good or not,
the ground truth only happens every once in a while, at the end of the game. Not every single frame.
And unsupervised learning is when you have no information about the outputs.
They are correct or incorrect. And it is the excitement of the deep learning community is unsupervised learning,
but it has achieved no major breakthroughs at this point. I'll talk about what the future of deep learning is
and a lot of the people that are working in t he field are excited by it. But right now, any interesting accomplishment has to do with supervised learning.
(Partially inaudible question from one of the attendees)
And the wrong one is just has the [00:33:29] (Inaudible) solution like looking at the philosophy.
So basically, the reinforcement learning here is learning from somebody who has certain hopes
and how can that be guaranteed that it would generalize to somebody else?
So the question was this:
the green paddle learns to play this game successfully against this specific one brown paddle operating under specific kinds of rules.
How do we know it can generalize to other games, other things and it can't.
But the mechanism by which it learns generalizes. So as long as you let it play,
as long as you let it play in whatever world you wanted it to succeed in long enough,
it will use the same approach to learn to succeed in that world.
The problem is this works for worlds you can simulate well.
Unfortunately, one of the big challenges of neural networks
is they're not currently efficient learners. We need a lot of data to learn anything.
Human beings need one example often times and they learn very efficiently from that one example.
And again I'll talk about that as well, it's a good question. So the drawbacks of neural networks.
So if you think about the way a human being would approach this game, this game of "pong", it would only need a simple set of instructions.
You're in control of a paddle and you can move it up and down.
And your task is to bounce the ball past the other player controlled by AI.
Now the human being would immediately, they may not win the game but they would immediately understand the game
and would be able to successfully play it well enough to pretty quickly learn to beat the game.
But they would need to have a concept of control. What it means to control a paddle, need to have a concept of a paddle,
need to have a concept of moving up and down and a ball and bouncing,
they have to know, they have to have at least a loose concept of real world physics
that they can then project that real world physics on to the two dimensional world. All of these concepts are concepts that you come to the table with.
That's knowledge. And the kind of way you transfer that knowledge from your previous experience,
from childhood to now when you come to this game, that something is called reasoning.
Whatever reasoning means. And the question is whether through this same kind of process,
you can see the entire world as a game of "pong"
and reasoning is simply the ability to simulate that game in your mind
and learn very efficiently, much more efficiently, than 200,000 innovations.
The other challenge of deep neural networks and machine learning broadly is you need big data and efficient learners as I said.
And that data also need to be supervised data. You need to have Ground Truth which is very costly for annotation.
A human being looking at a particular image, for example, and labeling that as something as a cat or dog,
whatever objects is in the image, that's very costly.
And particularly for neural networks there's a lot of parameters to tune.
There's a lot of hyper-parameters. You need to figure out the network structure first.
How does this network look, how many layers? How many hidden nodes?
What type of activation function for each node? There's a lot of hyper-parameters there
and then once you've built your network, there's parameters for how you teach that network.
There's learning rate, loss function - meaning bad size - number of training iterations, gradient updates moving
and selecting even the optimizer with which you solve the various differential equations involved.
It's a topic of many research paper, certainly it's rich enough for research papers, but it's also really challenging.
It means you can't just pop the network down it will solve the problem generally.
And defining a good lost function, or in the case of "pong" or games,
a good reward function is difficult. So here's a game, this is a recent result from OpenAI,
I'm teaching a network to play the game of coast runners.
And the goal of coast runners is you're in a boat the task is to go around the track
and successfully complete a race against other people you're racing against.
Now this network is an optimal one. And what is figured out that actually in the game,
it gets a lot of points for collecting certain objects along the path. So you see it's figured out to go in a circle and collect those those green turbo things.
And what is figured out is you don't need to complete the game to earn the award.
And despite being on fire and hitting the wall and going through this whole process, it's actually achieved at least the local optima
given the reward function of maximizing the number of points.
And so it's figured out a way to earn a higher reward
while ignoring the implied bigger picture goal of finishing the race which us as humans understand much better.
This raises, for self-driving cars, ethical questions.
Besides other quick questions. (CHUCKLING) We could watch this for hours and it will do that for hours and that's the point:
Deep Learning Breakthroughs: What Changed?
It's hard to teach, it's hard to encode the formally defined utility function under which
an intelligent system needs to operate. And that's made obvious even in a simple game.
And so what is - Yup, question. (Inaudible question from one of the attendees)
So the question was: "what's an example of a local optimum that an autonomous car,
similar to the cost racer, what would be the example in the real world for an autonomous vehicle?
And it's a touchy subject. But it would certainly have to be involved
the choices we make under near crashes and crashes. The choices a car makes want to avoid.
For example, if there's a crash imminent and there's no way you can stop
to prevent the crash, do you keep the driver safe or do you keep the other people safe.
And there has to be some, even if you don't choose to acknowledge it,
even if it's only in the data and the learning that you do, there's an implied reward function there.
And we need to be aware of that reward function is because it may find something. Until you actually see it, we won't know it.
Once we see it, we realize that oh that was a bad design
and that's the scary thing. It's hard to know ahead of time what that is.
So the recent breakthroughs from deep learning came several factors.
First is the compute, Moore's Law. CPUs are getting faster, hundred times faster, every decade.
Then there's GPU use. Also the ability to train neural networks and GPUs and now ASICs
has created a lot of capabilities in terms of energy efficiency
and being able to train larger networks more efficiently.
Well, first of all in the in the 21st Century there's digitized data. There's larger data sets of digital data
and now there is that data is becoming more organized, not just vaguely available data out there on the internet,
it's actual organized data sets like Imagenet. Certainly for natural languages there's large data sets.
There is the algorithm innovations, Backprop. Back propagation, Convolutional Neural Networks, LSTMs.
All these different architectures for dealing with specific types of domains and tasks.
There is the huge one, is infrastructure. It's on the software and the hardware side.
There's Git, Ability to Share and Open Source Way software. There are pieces of software that make robotics and make machine learning easier.
ROS, TensorFlow. There is Amazon Mechanical Turk
which allows for efficient, cheap annotation of large scale data sets.
As AWS and the cloud hosting, machine learning hosting the data and the compute.
And then there's a financial backing of large companies - Google, Facebook, Amazon.
But really nothing is changed. There really has not been any significant breakthroughs.
Convolutional networks have been around since the 90s, neural networks has been around since the 60s.
There's been a few improvements but the hope is, that's in terms of methodology,
the compute has really been the work horse. The ability to do the hundred fold improvement every decade,
holds promise and the question is whether that reasoning thing I talked about,
all you need is a larger network. That is the open question.
Useful Deep Learning Terms
Some terms for deep learning. First of all deep learning, is a PR term for neural networks.
It is a term for utilising deep neural networks
for neural networks to have many layers. It is symbolic term for the newly gained capabilities that compute has brought us.
That training on GPUs have brought us. So deep learning is a subset of machine learning.
There's many other methods that are still effective. The terms that will come up in this class is, first of all, Multilayer Perceptron (MLP)
Deep neural networks (DNN), Recurrent neural networks (RNN), LSTM (Long Short-Term Memory) Networks, CNN and ConvNet (Convolutional neural networks),
Deep Belief Networks. And the operational come up is Convolutional, Pooling, Activation functions and Backpropagation.
Yes, you've got a question?
(Inaudible question from one of the attendees)
So the question was, what is the purpose of the different layers in neural network? What is the need of one configuration versus another?
So a neural network, having several layers, it's the only thing you have an understanding of, is the inputs and the outputs.
You don't have a good understanding about what these layer does. They are mysterious things, neural networks.
So I'll talk about how, with every layer, it forms a higher level.
A higher order representation of the input. So it's not like the first layer does localization,
the second layer does path planning, the third layer does navigation - how you get from here to Florida -
or maybe it does, but we don't know. So we know we're beginning to visualize neural networks for simple tasks
like for ImageNet classifying cats versus dogs. We can tell what is the thing that the first layer does, the second layer, the third layer
and we look at that. But for driving, as the input provide just the images the output the steering.
It's still unclear what you learned partially because we don't have neural networks that drive successfully yet.
(Points to a member of the class) (Inaudible question)
So the question was, does a neural network generate layers over time, like does it grow it?
That's one of the challenges, that a neural network is pre-defined. The architecture, the number of nodes, the number of layers. That's all fixed.
Unlike the human brain where the neurons die and are born all the time. A neural Network is pre-specified, that's it.
That's all you get and if you want to change that, you have to change that and then retrain everything.
So it's fixed. So what I encourage you is to proceed with caution
Neural Networks: Proceed with Caution
because there's this feeling when you first teach a network with very little effort,
how to do some amazing tasks like classify a face versus non-face,
or your face versus other faces or cats versus dogs, its an incredible feeling.
And then there's definitely this feeling that I'm an expert
but what you realize is we don't actually understand how it works.
And getting it to perform well for more generalized task, for larger scale data sets, for more useful applications,
requires a lot of hyper-parameter tuning. Figuring out how to tweak little things here and there
and still in the end, you don't understand why it work so damn well.
Deep Learning is Representation Learning
So deep learning, these deep neural network architectures is representation learning.
This is the difference between traditional machine learning methods where,
for example, for the task of having an image here is the input.
The input to the network here is on the bottom, the output up on top, and the input is a single image of a person in this case.
And so the input, specifically, is all the pixels in that image.
RGB, the different colors of the pixels in the image. And over time, what a network does is build a multiverse solutional representation of this data.
The first layer learns the concept of edges, for example.
The second layer starts to learn composition of those edges, corners, contours.
Then it starts to learn about object parts. And finally, actually provide a label for the entities that are in the input.
And this is the difference in traditional machine learning methods where the concepts like edges and corners and contours
are manually pre-specified by human beings, human experts, for that particular domain.
Representation Matters
And representation matters because figuring out a line
for the Cartesian coordinates of this particular data set where you want to design a machine learning system
that tells the difference between green triangles and blue circles is difficult.
There is no line that separates them cleanly. And if you were to ask a human being, a human expert in the field.
to try to draw that line they would probably do a Ph. D. on it and still not succeed.
But a neural network can automatically figure out to remap that input into polar coordinates
where the representation is such that it's an easily, linearly separable data set.
And so, deep learning is a subset of representation learning, is a subset of machine learning and a key subset artificial intelligence.
Deep Learning: Scalable Machine Learning
Now, because of this, because of its ability to compute an arbitrary number of features
that are at the core of the representation. So if you are trying to detect a cat in an image,
you're not specifying 215 specific features of cat ears and whiskers and so on
that a human expert will specify you allow and you'll know it discover tens of thousands of such features,
which maybe for cats you are an expert but for a lot of objects you may never be able to sufficiently provide the features
which successfully will be used for identifying the object. And so, this kind of representation learning,
one is easy in the sense that all you have to provide is inputs and outputs.
All you need to provide is a data set the care about without [00:53:39] features.
And two, because of it's ability to construct arbitrarily sized representations,
deep neural networks are hungry for data. The more data we give them,
the more they are able to learn about this particular data set.
Applications: Object Classification in Images
So let's look at some applications.
First, some cool things that deep neural networks have been able to accomplish up to this point.
Let me go through them. First, the basic one.
AlexNet is for- ImageNet is a famous data set and a competition of classification,
localization where the task is given an image, identify what are the five most likely things in that image
and what is the most likely and you have to do so correctly. So on the right, there's an image of a leopard
and you have to correctly classify that that is in fact the leopard. So they're able to do this pretty well given a specific image.
Determine that it's a leopard. And we started, what's shown here on the x-axis is years
on the y-axis is error in classification. So starting from 2012 on the left with AlexNet and today
the errors decreased from 16% and 40% before then with traditional methods
have decreased to <4%. So human level performance, if I were to give you this picture of a leopard
is a 4% of those pictures of leopards you would not say it's a leopard.
That's human level performance. So for the first time in 2015, convolutional neural networks are performed human beings.
That in itself is incredible. That is something that seemed impossible. And now is because it's done is not as impressive.
illumination Variability
But I just want to get to why this is so impressive because computer vision is hard.
Now we as human beings have evolved visual perception over millions of years, hundreds of millions of years.
So we take it for granted but computer vision is really hard, visual perception is really hard.
There's illumination variability. So it's the same object. The only way we are telling you a thing is from the shade, the reflection of light from that surface.
It could be the same object with drastically, in terms of pixels, drastically different looking shapes and we still know it's the same object.
Pose Variability and Occlusions
There is post-variability in occlusion. Probably my favorite caption for an image
for a figure in a academic paper is deformable and truncated cat.
These are pictures, you know cats are famously deformable.
They can take a lot of different shapes. (LAUGHTER) Its arbitrary poses are possible so you have to have computer vision
to know it's still the same objects, still the same class of objects, given all the variability in the pose and occlusions is a huge problem.
We still know it's an object. We still know it's a cat even when parts of it are not visible.
And sometimes large parts of it are not visible. And then there's all the inter-class variability.
Inter-class, all of these on the top two rows are cats. Many of them look drastically different.
And the top bottom two rows are dogs also look drastically different.
And yet some of the dogs look like cats, some of the cats look like dogs.
And as human beings are pretty good at telling the difference and we want computer vision to do better than that.
It's hard. So how is this done? This is done with convolutional neural networks.
Pause: Object Recognition / Classification
The input to which is a raw image. Here's an input on the left of a number three
and I'll talk about through convolutional layers
that image is processed past through convolutional layers maintain spatial information.
On the output, in this case predicts which of the images
what number is shown in the image. 0, 1, 2 through 9.
And so, these networks, everybody's using the same kind of network to determine exactly that.
Input is an image, output is a number. And in the case of probability, that is a leopard. What is that number?
Then there is segmentation built on top of these convolution neural networks where you chop off the end and convolutionise the network.
You chop off the end where the output is a heat map. So you can have, instead of a detector for a cat, you can do a cat heat map
where it's the part of the image, the output heat map gets excited,
the neurons in that output get excited in the spatially excited, in the parts of the image that contain a tabby cat.
And this kind of process can be used to segment the image into different objects, a horse.
So the original input on the left is a woman on a horse and the output is a fully segmented image of knowing where is the woman, where is the horse.
Pouse Object Detection
And this kind of process can be used for object detection which is the task of detecting an object in an image.
Now the traditional method with convolutional neural networks and in general computer vision is the sliding window approach.
We have a detector, like the leopard detector, where you slide through the image to find where in that image is the leopard.
This, the segmenting approach, the R-CNN approach, is efficiently segmenting the image
in such a way that it can propose different parts of the image that are likely to have a leopard, or in this case a cowboy,
and that drastically reduces the computational requirements of the object detection task.
And so these networks, this is currently one of the best networks for the ImageNet task of localization
is the Deep residual networks. They're deep. So VGG-19 is one of the famous ones.
You started to get above twenty layers in many cases, thirty four layers is the rise in that one.
So the lesson there is, the deeper you go the more representation power you have,
the higher accuracy but you need more data.
Other applications, colorization of images. So this again, input is a single image and output is a single image.
So you can take a black and white video from a film, from an old film,
and recolor it. And all you need to do to train that network in the supervised way
is provide modern films and convert them to grayscale. So now you have arbitrarily sized data sets, data sets of gray scale to color.
And you're able to, with very little effort on top of it, to successfully
well, somewhat successful recolor images. Again, Google Translate does image translation in this way, image to image.
It first perceives, here in German I believe, famous German correct me if I'm wrong,
dark chocolate written in German on a box. So this can take this image, detect different letters convert them to text,
translate the text and then using the image to image mapping
map the letters, the translated letters, back onto the box and you could do this in real time on video.
So what we've talked about up to this point on the left are "vanilla" neural networks,
convolutional neural networks, that map a single input, a single output, a single image to a number, single image another image.
Then there is recurrent neural networks, the map. This is the more general formulation, they map a sequence of images
or a sequence of words or a sequence of any kind to another sequence.
And these networks are able to do incredible things with natural language,
with video, and any type of series of data. For example, you can convert text to hand written digits, with hand written text.
Here, you type in and you can do this online, type in deep learning for self-driving cars
and it will use an arbitrary handwriting style to generate the words "deep learning for self-driving cars".
This is done using recurring neural networks. We can also take Char-RNNs they're called, it's character level recurring neural networks
that train on a data set an arbitrary text data set and learn to generate text one character at a time.
So there is no preconceived syntactical semantic structure that's provided to the network.
It learns that structure. So for example, you can train it on Wikipedia articles like in this case.
And it's able to generate successfully not only text that makes some kind of grammatical sense at least
but also keep perfect syntactic structure for Wikipedia, for Markdown, editing,
for late tack editing and so on. This text as "naturalism and decision for the majority of Arab countries capitalide."
Whatever that means, "was grounded by the Irish language by John Clare," and so on. These are sentences. If you didn't know better, that might sound correct.
And it does so and you pause one character at a time so these aren't words being generated.
This is one character, you start with the beginning three letters "nat",
you generate "u" completely without knowing of the word naturalism.
This is incredible. You can do this to start a sentence and let the neural network complete that sentence.
So for example if you start the sentence with "life is" or "life is about" actually,
it will complete it with a lot of fun things. "The weather." "Life is about kids."
"Life is about the true love of Mr Mom", "is about the truth now."
And this is from [01:05:59], the last two, if you start with "the meaning of life," it can complete that with
"the meaning of life is literary recognition" may be true for some of us here.
Publish or perish. And "the meaning of life is the tradition of ancient human reproduction."
(LAUGHTER) Also true for some of us here. I'm sure.
Okay, so what else can you do? You can, this has been very exciting recently is image capture recognition. No, generation, I'm sorry.
Image capture generation is important for large data sets of images.
What we want to be able to determine what's going on inside those images. Specially for search, if you want to find a man sitting in a college with a dog,
you type it into Google and it's able to find that. So here shown in black text a man sitting on a couch with a dog is generated by the system.
A man sitting in a chair with a dog in his lap is generated by a human observer.
And again these annotations are done by detecting the different obstacles, the different objects in the scene.
So segmenting the scene detecting on the right there's a woman, a crowd, a cat, a camera, holding, purple.
All of these words are being detected then a syntactically correct sentence is generated,
a lot of them, and then you order which sentence is the most likely. And in this way you can generate very accurate labeling of the images,
captions for the images. And you can do the same kind of process for image question answering.
You can ask how many for quantity, how many chairs are there?
You can ask about location, where are the ripe bananas?
You can ask about the type of object. What is the object in the chair? It's a pillow.
And these are, again, using the recurring neural networks.
You could do the same thing with video captions generation,
video captions description generation. So looking at a sequence of images as opposed to just a single image.
What is the action going on in this situation? This is the difficult task. There's a lot of work in it, in this area.
On the left is correct descriptions of a man is do stunts on his bike or a herd a zebra are walking in the field and on the right,
there's a small bus running into a building. You know it's talking about relevant entities but just doing an incorrect description.
A man is cutting a piece of a pair of a paper.
So the words are correct. Perhaps, but so you're close, but mostly are.
One of the interesting things
you can do with a recurring neural networks is if you think about the way we look at images, human beings look at images,
is we only have a small phobia with which we focus in a scene.
So right now you're periphery is very distorted. The only thing, if you're looking at the slides, you're looking at me
that's the only thing that's in focus. Majority of everything else is out of focus.
So we can use the same kind of concept to try to teach a neural network to steer around the image. Both for perception and generation of those images.
This is important first on the general artificial intelligence point of it being just fascinating that we can selectively steer our attention
but also it's important for things like drones. They have to fly at high speeds in an environment
where three hundred plus frames a second, you have to make decisions. So you can't possibly localize yourself or perceive the world around yourself successfully
if you have to interpret the entire scene. So we can do is you can steer, for example here shown, is reading a house number
by steering around an image. You can do the same task for reading and for writing.
So reading numbers here, and this data set on the left, is reading numbers. We can also selectively steer a network around an image to generate that image
starting with a blurred image first and then getting more and more higher resolution
as the steering goes on. Work here at MIT is able to map video to audio.
So head stuff for the drumstick silent video and able to generate the sound
that would drumstick hitting that particular object makes. So you can get texture information from that impact.
So here is the video of a human soccer player playing soccer
and a state-of-the-art machine playing soccer.
And, well let me give it some time, to build up.
(LAUGHTER) Okay. So soccer, we take this for granted, but walking is hard.
Object manipulation is hard. Soccer is harder than chess for us to do much harder.
On your phone now, you can have a chess engine that beats the best players in the world.
And you have to internalize that because the question is, this is a painful video, the question is: where does driving fall?
Is it closer to chess or is it closer soccer? For those incredible, brilliant engineers that worked on the most recent DARPA challenge
this would be a very painful video to watch, I apologize.
This is a video from the DARPA Challenge (LAUGHTER) of robots struggling
with basic object manipulation and walking tasks.
So it's mostly a fully autonomous navigation task. (LAUGHTER)
Maybe I'll just let this play for a few moments to let it internalize how difficult this task is,
of balancing, of planning in an underactuated way. We don't have full control of everything.
When there is a delta between your perception of what you think the world is and what reality is.
So there, a robot was trying to turn an object that wasn't there.
And this is an MIT entry that actually successfully, I believe, gotten points for this because it got into that area
(LAUGHTER) but as a lot of the teams talked about the hardest part,
So one of the things the robot had to do is get into a car and drive it and get out of the car.
And there's a few other manipulation task like walking on unsteady ground, it had to drill a hole through a wall.
All these tasks and what a lot of teams said is the hardest part, the hardest task of all of them,
is getting out of the car. So it's not getting into the car, it's this very task you saw now is the robot getting out of the car.
These are things we take for granted. So in our evaluation of what is difficult about driving,
we have to remember that some of those things we may take for granted
in the same kind of way that we take walking for granted, this is more of X paradox.
Will Hans Moravec from CMU, let me just quickly read that quote: "Encoded in the large highly evolved sensory motor portions of the human brain
is billions of years of experience about the nature of the world and how to survive in it."
So this is data. This is big data. Billions of years and abstract thought which is reasoning.
The stuff we think is intelligence is perhaps less than one hundred thousand years of data old.
We haven't yet mastered it and so, I'm sorry I'm asserting my own statements in the middle of a quote,
but it's been very recent that we've learned how to think.
And so we respected perhaps more than the things we take for granted like walking, the visual perception and so on but those may be strictly a matter of data,
data and training time and network size.
So walking is hard. The question is how hard is driving?
And that's an important question because the margin of error is small.
One, there's 1 fatality per 100 million miles.
That's the number of people that die in car crashes every year, 1 fatality per 100 million miles.
That's a point 0.000001% margin of error.
That's through all the time you spend on the road, that is the error you get.
More impressed with ImageNet being able to classify a leopard, a cat or a dog
at above human level performance but this is the margin of error we get with driving.
And we have to be able to deal with snow, with heavy rain, with big open parking lots,
with parking garages, any pedestrians that behaves irresponsibly as rarely as that happens
or just some predictably, again especially in Boston, reflections.
The ones especially some things you don't think about: the lighting variations that blind the cameras.
(Inaudible question from one of the attendees)
The question was if that number changes, if you look at just crashes, the fatalities per crash.
So one of the big things is that cars have gotten really good at crashing and not hurting anybody.
So the number of crashes is much, much larger than the number of fatalities which is a great thing, we've built safer cars.
But still, you know even one fatality is too many.
So this is one that Google self-driving car team
is quite open about their performance since hitting public road,
this is from a report that shows the number of times the driver disengaged
the car gives up control, that it asked the driver to take control back
or the driver takes control back by force. Meaning that they're unhappy with the decision that the car was making
or it was putting the car or other pedestrians or other cars in unsafe situations. And so, if you see over time there's been a total
from 2014 to 2015 there's been a total of 341 times on beautiful San Francisco roads
and I say that seriously because the weather conditions are great there, 341 times that the driver had to elect to control back.
So it's a work in progress. And let me give you something to think about here.
This, with neural networks is a big open question.
The question of robustness. So this is an amazing paper, I encourage people to read it.
There's a couple of papers around this topic. Deep neural networks are easily fooled.
So here are 8 images where, if given to a neural network as input,
a convolutional neural network as input, the network with higher than 99.6% confidence says
that the image, for example the top left, as a robin. Next to is a cheetah, then an armadillo, a panda, an electric guitar,
a baseball, a starfish, a king penguin. All of these things are obviously not in the images.
So the networks can be fooled with noise. More importantly, practically for the real world, adding just a little bit of distortion,
a little bit of noise distortion to the image, can force the network to produce a totally wrong prediction.
So here's an example, there's 3 columns, correct image classification, the slight addition of distortion
and the resulting prediction of an ostrich for all three images on the left
and a prediction of an ostrich for all three images on the right.
This ability to fool networks easily brings up an important point.
And that point is that there has been a lot of excitement
about neural networks throughout their history. There's been a lot of excitement about artificial intelligence throughout its history
and not coupling that excitement, not granting that excitement, in the reality
the real challenges around that has resulted in in crashes, in A.I. winters when funding dried out
and people became hopeless in terms of the possibilities of artificial intelligence.
So here is the 1958 New York Times article that said the Navy revealed the embryo of an electronic computer today.
This is when the first perceptron that I talked about was implemented in hardware by Frank Rosenblatt.
It took 400 pixel image input and it provided a single output.
Weights were encoded in the hardware potentiometers and waves were updated with electric motors.
Now New York Times wrote, the Navy revealed the embryo vanilla electronic computer today
that expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.
Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory in Buffalo,
said perceptrons might be fired to the planets as mechanical space explorers.
This might seem ridiculous but this is the general opinion of the time.
And as we know now, perceptrons cannot even separate a non-linear function.
They're just linear classifiers. And so this led to 2 major A.I. winters in the 70s, in the late 80s and early 90s.
The Lighthill Report, in 1973 by the UK government, said there are no part of the field
of discoveries made so far produced the major impact that was promised. So if the hype builds beyond the capabilities of our research,
reports like this will come and they have the possibility of creating another A.I. winter.
So I want to pare the optimism, some of the cool things we'll talk about in this class,
with the reality of the challenges ahead of us.
The focus of the research community, this is some of the key players in deep learning,
what are the things that are next for deep learning, the five year vision?
We want to run on smaller, cheaper mobile devices. We want to explore more in the space of unsupervised learning as I mentioned
and reinforcement learning. We want to do things that explore the space of videos more,
the recurring neural networks, like being able to summarize videos or generate short videos.
One of the big efforts, especially in the companies we do in large data,
is multi-modal learning. Learning from multiple data sets with multiple sources of data.
And lastly, making money from these technologies. There's a lot of this despite the excitement.
There has been an inability for the most part to make serious money
from some of the more interesting parts of deep learning.
And while I got made fun of by the TAs for including this slide
because it's shown in so many sort of business type lectures, but it is true that we're at the peak of a hype cycle
and we have to make sure be given the large amount of hype and excited there is,
we proceed with caution.
One example of that, let me mention, is we already talked about spoofing the cameras.
Spoofing the cameras with a little bit of noise. So if you think about it, self-driving vehicles operate with a set of sensors
and they rely on those sensors to convey to accurately capture that information. And what happens, not only when the world itself produces noisy visual information,
but what if somebody actually tries to spoof that data. One of the fascinating things have been recently done is spoofing of LIDAR.
So these LIDAR is a range sense that gives a 3D-point cloud of the objects in the external environment.
And you're able to successfully do a replay attack where you have the car
see people in other cars around it when there's actually nothing around it.
In the same way that you can spoof a camera to see things that are not there.
A neural network. So let me run through some of the libraries that we'll work with
and they're out there that you my work with if you proceed with deep learning.
TensorFlow, that is the most popular one these days. It's heavily backed and developed by Google.
It's primarily a python interface and is very good at operating on multiple GPUs.
There's Keras and also TF Learn and TF Slim which are libraries that operate on top of TensorFlow
that make it slightly easier, slightly more user friendly interfaces, to get up and running.
Torch, if you're interested to get in at the lower level
tweaking of the different parameters of neural networks creating your own architectures. Torch is excellent for that with it's own Lua interface.
Lua's a programming language and heavily backed by Facebook.
There is the old school "theano" which is what I started on a lot of people early on, in deep learning started on, as one of the first libraries that supported
ahead came with GPU support. It definitely encourages lower level tinkering, has a python interface.
And many of these, if not all, rely on Nvidia's library
for doing some of the low level computations involved with training these neural networks on Nvidia GPUs.
"mxnet" heavily supported by Amazon and they have officially recently announced
that they're going to be, their AWS, is going to be all in on the mxnet.
Neon, recently bought by Intel, started out as a manufacturer of neural network chips
which is really exciting and it performs exceptionally well.
I hear good things. Caffe, started in Berkeley, also was very popular in Google before Tensorlow came out.
It's primarily designed for computer vision with ConvNet's but has now expanded to all of the domains.
There is CNTK, used to be known and now called the Microsoft Cognitive Toolkit. Nobody calls it that still I'm aware of.
It says multi GPU support, has its own brain script custom language
as well as other interfaces. And we'll get to play around in this class is, amazingly, deep learning in the browser, right.
Our favorite is ConvNetJS, what you use, built by Andrej Karpathy from Stanford now OpenAI.
It's good for explaining the basic concept of neural networks. It's fun to play around with. All you need is a browser and some very few requirements.
It can't leverage GPUs, unfortunately. But for a lot of things that we're doing, you don't need GPUs.
You'd be able to train a network with very little and relatively efficiently without the [01:30:15] GPUs.
It has full support for CNNs, RNNs and even deeper reinforcement learning.
Keras.js, which seems incredible, we try to use for this class.
It has GPU support so it runs in the browser with GPU support with Open GL or however it works magically
but we're able to accomplish a lot of things we need without the use of GPUs.
It's incredible to live in a day and age when it literally, as I'll show on the tutorials,
it takes just a few minutes to get started with building your own neural network that classifies images and a lot of these libraries are friendly in that way.
So all the references mentioned in this presentation are available at this link and the slides are available there as well.
So I think in the interest of time, let me wrap up. Thank you so much for coming in today and tomorrow I'll explain the deep reinforcement learning game
and the actual competition and how you can win. Thanks very much guys.

----------

-----
--14--

-----
Date:
Link: [# Foundations and Challenges of Deep Learning (Yoshua Bengio)](https://www.youtube.com/watch?v=11rsu_WwZTc)
Transcription:

Thank You Sammy so I'll tell you about
some very high-level stuff today no new
algorithm some of you already know about the book that Ian Goodfellow erinkoval
and I have written and it's now in presale by MIT press I think you can
find it on Amazon or something and paper
the actual shipping is going to be in December hopefully for nibs
so we've already heard that story at
least well from several people here at least from Andrew I think but it's good
to ponder a little bit some of these ingredients that seem to be important
for deep learning to succeed but in general for machine learning to succeed
to learn really complicated tasks of the kind we want to reach human level performance so if a machine is going to
be intelligent it's going to need to acquire a lot of information about the
world and the big success of machine learning for AI has been to show that we
can provide that information through data through examples but but really
think about it you know that that machine will need to know a huge amount of information about the world around us
this is not how we're doing it now because we're not able to train such big models but it will come one day and so
we'll need models that are much bigger than the ones we currently have of course that means machine learning
algorithms that can represent complicated functions that's you know one good thing about neural nets but
there are many other machine learning approaches that allow you in principle to represent very flexible forms like
nonparametric methods classical nonparametric methods or svms but
they're going to be missing 0.4 and potentially 0.5 depending on the methods
point 3 of course you you need enough computing power to train and use these big models and
point-five just says that it's not enough to be able to train the model you
have to be able to use it in a reasonably efficient way from a computational perspective this is not
always the case with some probabilistic models where inference in other words answering questions having the computer
do something can be intractable and then you need to do some approximations which could be efficient or or not now the
point I really want to talk about is the fourth one how do we defeat the curse of
dimensionality in other words if you don't assume much about the world it's
actually impossible to learn about it and and so I'm going to tell you a bit
about the assumptions that are behind a lot of deep learning algorithms which
make it possible to work as well as we are seeing in practice in the last few years something wrong Microsoft bug okay
so how do we bypass the curse of dimensionality the curse of dimensionality is about the
exponentially large number of configurations of the space variables that we want to model the number of
values that all of the variables that we observe can take is going to be
exponentially large in general because there's a compositional nature if if each pixel can take two values and you
got a million pixels then you got two to one million number of possible images so
the only way to beat an exponential is to use another exponential so we need to
make our models compositional we need to build our models in such a way that they
can represent functions that look very complicated but yet these models need to
have a reasonably small number of parameters reasonably small in the sense compared to the number of configurations
of the variables the number of parameters should be small and we can
achieve that by by composing little pieces together composing layers together it can put composing units on
the same layer together and that's essentially what's happening with deep learning so you actually have two kinds
of compositions there's the the compositions happening on the same layer this is the idea of distributed
representations which I'm going to try to explain a bit more this is what you get when you learn embeddings for
forwards or for images representations in general and then there's the idea of having multiple levels of representation
that's the notion of depth and there there is another kind of composition
takes place whereas the the first one is a kind of parallel composition I'm you know I can choose
the values of my different units separately and then they together represent an exponentially large number
of possible configurations in the second case there's a sequential composition where I take the output of one level and
and I combine them in new ways to build features for the next level and so on and so on right so so the reason deep
learning is working is because the world around us is better modeled by making
these assumptions it's not necessarily true that deep learning is going to work for any machine learning problem in fact
if if we consider the set of all possible distributions that we would like to work from deep learning is no
better than any other and that's this is basically what the no free lunch theorem is saying it's because we are incredibly
lucky that we live in this world which can be described by using composition that these algorithms are working so
well this is important to really understand this
so before I go a bit more into distributed representations let me say a
few words about non distributor presentations so if you're thinking about things like clustering engrams for
language modeling classical nearest neighbors SVM's with Gaussian kernels
classical nonparametric models with local kernels and decision trees all
these things the way these algorithms really work is actually pretty
straightforward if you you know cut the crap and hide the math and try to
understand what is going on they they look at the data in in data space and
they break that space into regions and they're going to use different free
parameters for each of those regions to figure out what the right answer should be the right answer it doesn't have to be supervised learning even an S
provides I think there's a right answer it might be the density or something like that okay and you might think that that's the
only way of solving a problem you know we consider all of the cases and we have an answer for each of the cases and we
can maybe interpolate between those cases that we've seen the problem with
this is somebody comes up with a new example which isn't in between two of
the examples we've seen something that a la requires us to extrapolate something that's you know non-trivial
generalization and and these algorithms just fail they don't they don't really have a recipe for saying something
meaningful away from the training examples there's another interesting
thing to note here which I would like to you to keep in mind before I show the next slide which is in red here which is
we can do a kind of simple counting to relate the number of parameters a number
of free parameters that can be learning and the number of regions in the data
space that we can distinguish so here we basically have linear relationship
between these two things right so for each region I'm going to need at least something like some kind of Center for
the region and maybe if I need to output something I'll lean an extra set of parameters to tell
me what the answer should be in that area so the number of parameters grows linearly with the number of regions that
I I'm going to be able to distinguish the good news is I can have any kind of
function right so I can break up the space in any way I want and then for each of those regions I can have any kind of output that I need so for
decision trees the regions would be you know splitting across axes and so on and for this is more like four nearest
neighbor or something like that now another bug I don't think I will
send this hope works this time oh I have
a another option sorry about this okay
so so here's the the point of view of
the suit representations for solving the same general machine learning problem we have a data space and we want to break
it down but we're going to break it down in a way that's not general we're going
to break it down in a way that makes assumptions about the data but it's
going to be compositional and it's going to allow us to you know be exponentially more efficient so how are we going to do
this so in the picture on the right what you see is a way to break the input
space by the intersection of half-planes and this is the kind of thing you would have with a what happens at the first
layer of a neural net so here imagine the input is 2-dimensional so I can plot it here and I have three binary hidden
units c1 c2 c3 so because they're binary you can think of them as little binary
classifiers and because it's only a one layer net you can think of what they're
doing is a linear classification and so those colored hyperplanes here are the decision surfaces for each of
them now these three bits there can take they can take eight values right
corresponding to you know whether each of them is on or off and and those
different configurations of those bits correspond to actually seven regions
here because there's one of the eight regions which does is not feasible so so
now you see that we're defining a number of regions which is corresponding to all of the possible intersections of the
corresponding half-planes and and now we can play the game of how many regions do
we get for how many parameters and what we see is that as if we played the game
of growing the number of dimensions features and also of inputs we can get
an exponentially large number of regions which are all of these intersections right there's an exponential number of these intersections corresponding to
different binary configurations yet the number of parameters grows linearly with the number of units so it looks like
we're able to express a function then on top of that I could imagine you have a linear classifier right that's that's
the one hidden layer new on that so so the number of parameters grows just linearly with the number of features but
the number of regions that the network can really provide a different answer to grows exponentially so this is very cool
and the reason it's very cool is that it allows those neural nets to generalize
because while we're learning about each of those features we can generalize to
regions we've never seen because we've learned enough about each of those features separately I'm going to give
you an example of this in a couple of slide actually it's let's do it first so
so think about those features so the input is an image of a person and think
of those features as things like I have a detector that says that the person wears glasses
and I have another unit that's detecting that the person is a female or male and
I have another unit that texts that the person is a child or not and you can imagine you know hundreds or thousands
of these things of course so so the good news is you could imagine learning about
each of these feature detectors these little classifiers separately in fact
you could do better than that you could share you know intermediate layers between the input and those features but
but let's you know take even the worst case and imagine we were to train those separately which is the case in the
linear model that I show before we have a separate set of parameters for each of
these detectors so if I have n features each of them say needs order of K
parameters then I need order of NK parameters and I need order of NK
examples and one thing you should know from you know which machine learning theory is that if you have order of P
parameters you need order of P examples to do a reasonable job of jaw's age of journalizing you can you can get around
that by regularizing and effectively having less degrees of freedom but but you know to keep things simple you need
about the same number of examples or maybe a hundred times more or ten times more as the number of really free
parameters so so now the relationship between the number of regions that I can
represent and the number of examples I need is quite nice because the number of
regions is going to be to to the number of features of these binary features so
you know a person could wear glasses or not be a female or a male or child or not and I could have a hundred of these things and I could probably recognize
reasonably well all of these two to the 100 configurations of people even though
I've obviously not seen all of those to do 100 configurations why is it that I'm able to do that I'm able to do that
because the the models can learn about each these binary features kind of independently in the sense that I don't
need to see every possible configuration of the other features to know about
wearing glasses like I can learn about wearing glasses even though I've never
seen somebody who was a female and a child and chubby and had you know yellow
shoes and and and I have seen enough examples of people wearing glasses I can
learn about wearing glasses in general I don't need to see all of the configurations of the other features to
learn about one feature okay and so so this is really what what you know why
this thing works is because we're making assumptions about the data that those
features are meaningful by themselves and you don't need to actually have data
for each of the regions the exponential number of regions in order to learn the
proper way of detecting or lore of discovering these these these intermediate features let me add
something here there were some experiments recently actually showing that this kind of thing is really
happening because the features I was talking about
not only I'm assuming that they exist but the the optimization methods or
training procedures discover them they can learn them and this is an experiment
that's been done in 2012 all Tour Alba's lab at MIT where they trained a usual
confidence to recognize places so the outputs of the net are just the types of
places like is this a beach scene or an office scene or street scene and so on but but then the the thing they've done
is they ask people to analyze the the hidden units to try to figure out what each hidden unit was doing and they found that there's a large proportion of
units that humans can find a pretty obvious interpretation for what those units like so so they see a bunch of
units which you know like people are different kinds of people or animals or buildings or
seedings or tables lighting and so on so it's like if indeed the those neural
nets are discovering semantic features they are semantic because actually people give them names as the
intermediate features you know in order to reach the final goal of here transpiring scenes and the reason
they're generalizing is because now you can combine those features in an exponentially large number of ways right you could have a scene that has a table
different kind of lighting some people you know maybe a pet and and you can say
something meaningful about the combinations of these things because the network is able to learn all of these
features without having to see all of the possible configurations of them so I
don't know if my explanation makes sense to you but now is the chance to ask me a question all clear usually it's not yeah
with decision trees right to some extent
so if the question is can't we do the same thing with a set of decision trees yeah in fact this is one of the reasons
why forests work better or bagged trees work better than single trees forests or
actually or Bank trees are like one layer one level deeper than a single trees but but they still don't have as
much of a sort of distributed aspect as neural nets so they be and and usually
they're not trained jointly I mean boosted trees are you know to some
extent in a greedy way but yeah any other question yeah cases where what non-conditional
non computer vision non compositional I
don't understand the question I mean I don't sound what you mean what do you mean non compositional yeah it's
everywhere around us I don't think I don't think that there are examples of neural nets that really work well where
the data doesn't have some kind of compositional structure in it but if you come up with an example I'd like to hear
about it okie s yes
to think about this issue in graphical model terms is is if it can be done but
you have to think about not feature detection like I've been doing here but
about generating an image or something like that right then it's easier to
think about it so so the same kinds of things happen if you think about how I could generate an image if you think
about underlying factors like which objects where they are what's their identity what's their size these are all
independent factors which you compose together in in funny ways if you were to
do a graphics engine you can see exactly what those ways are and it's much much
easier to represent that joint of distribution using this compositional structure then if you're trying to work
directly in the pixel space which is normally what you would do with a classical nonparametric method and it
wouldn't work but if you look at our best D generative models now for images for example like ganz or V AES they're
really you know we're not there yet but they're amazingly better than anything
that people could dream up just a few years ago in in machine learning okay
let me move on because of other things to talk about so this is all kind of
hand wavy but some people have done some math around these ideas and and so for
example there's one result from two years ago I clear where we study the
single layer case and we consider a network with rectifiers rellis and we
find that the the network of course computes a piecewise linear function and
so one way to quantify the richness of
the function that it can compute I was talking about regions here but well you can do the same thing here you can count how many pieces does does this
network have in its input to output function and and it turns out that is it
six potential in in the number of inputs
well it's a number of units to the power number of inputs so that's for a sort of
district representation there's this an exponential kicking in we also studied the the depth aspect so what you need to
know about depth is that there's a lot
of earlier theory that says that a single layer is sufficient to represent any function however that theory doesn't
specify how many units you get you might need and in fact you might need an especially large number of units so what
several results show is that there are functions that can be represented very
efficiently with few units so few parameters if you allow the network to
be deep enough so out of all the functions again it's a luckiness thing
right out of all the functions that exists there's a very very small fraction which happen to be very easy to
represent with a deep network and if you try to represent these these functions
with a shallow network you're screwed you're going to need an exponential number of parameters and so you're gonna
need an exponential number of examples to learn these things but again we're
incredibly lucky that the function we want to learn have this property but in
the sense it's not surprising I mean we use this kind of compositionality and depth everywhere we when we write a computer program we just don't have like
a single main we have you know functions and call functions and and we were able
to show similar things as what I was telling you about for the single layer case that as you increase depth for
these deep relu networks the number of pieces in the piecewise linear function
grows exponentially with the depth so so it's it's already exponentially large
with a single-layer but it gets exponentially even more with a deeper
net okay so so this this was a topic of representation of functions why why deep
learn deep architectures can can be very powerful if we're lucky and we seem to
be looking the other another topic I
want to mention that's kind of very much in the foundations is how is it that
we're able to train these neural nets in the first place in the 90s many people
decided to not do any more research on your nuts because there were 30 Korra's
ult's showing that there are really an exponentially large number of local minima in the training objective in of a
neural net so in other words the function we want to learn has many of
these holes and if we start at a random place well what's the chance we're going
to find the best one the the one that corresponds to a good cost and that was
one of the motivations for people who flocked into a very large area of
research in machine learning in the 90s and 2000's based on algorithms that
require on the convex optimization to Train because of course if we can do context optimization we eliminate this
problem if if the objective function is convex in the parameters then we know there's a single global minimum right so
let me show you a picture here you get a sense of if you look on the right hand top this is if you draw a random
function in 1d or 2d or 3d like here this is a kind of a random smooth
function in 2d you see that is going to have many ups and downs this is a local
minimum and but but the good news is
that in high dimension it's a totally different story so what are the dimensions here we're talking about the
parameters of the model and the vertical axis is the cost we're trying to
minimize and what happens in high dimension is that instead of having a huge number of
local minima on our way when we're trying to optimize what we encounter instead is a huge number of saddle
points so saddle point is like the thing on the bottom right in in 2d so you have
two parameters and y-axis is the cost you want to minimize and so what you see in a saddle point is yeah you have
dimensions or directions where the the objective function draws a a minimum so
there's like a curve that it curves up and in other directions it curves down
so we are you know saddle point has both a minimum in some direction and a maximum in other directions so this is
this is interesting because even though it's a these these points like saddle
points and many more are places where you could get stuck in principle if you're exactly at the subtle point you don't move but if you move a little bit
away from it you will go down the saddle right so what what our work in the other
paper other work from NYU tremonica and collaborators of Yann
Locker showed is that actually in very
high dimension not only you know it's it's the issue is more saddle points
than local minima but but the local minima are good so let me try to explain
what I mean by this so let me show you
actually first an experiment from from the NYU guys so they did an experiment
where they gradually change the size of the neural net and they they look at
what looks like local minima but they could be you know saddle points that are the lowest that they could obtain by
training and what you're looking at is a distribution of errors they get from
different initialization of their training and so what happens is that when the network is small like the
pink here on the right there's a widespread distribution of cost that you can get depending on where you you you
start and they're pretty high and if you increase the size of the network it's like all of the local minima that you
find concentrate around a particular costs so you don't get any of these bad
local minima that you would get with a small Network they're all kind of pretty good and if you increase even more the
size of network this is like a single hidden layer network you know not very complicated this phenomenon increases even more in
other words they all kind of converge to the same kind of costs so let me try to explain what's going on so if we go back
to the picture of the saddle point but instead of being in 2d imagine you are in a million D and in fact you know
people have billion D networks these days I'm sure andrew has even bigger
ones I'm not sure but so what happens in
this very high dimensional space of parameters is that if if things are not
really you know really bad for you so if you imagine a little bit of randomness
in the way the problem is set up and there it seems to be the case in order
to have a true local minimum you need to have the curvature going up like this in
all the you know billion directions so
if there is a certain probability of this event happening that all know that this particular directions is curving up
and this one is grabbing up the probability that all of them curve up becomes exponentially small so we we
tested that experimentally what you see in the bottom left is a curve that shows
the training error as a function of what's called the index of the critical
point which is just the fraction of the directions which are
curving down right so so 0% would mean
it's a local minimum a hundred percent would be it's a local maximum and
anything in between is a saddle point so what we find is that as training
progresses we're going close to a bunch of saddle points and these and none of
them are local minima otherwise we would be stuck and and in fact we never
encounter local minima until we reach the lowest possible cost that we were
able to get in addition there is a theory suggesting that so the the local
the low the the local minima will actually be close in cost to the global
minimum they will be above and they will concentrate in a little band above the global minimum but that band of local
minima will be close to the global minimum and and the larger 2-dimension the more this is going to be true so as
you go to go back to my analogy right at some point of course you will get local minima even though it's unlikely when
you're in the middle when you get close to the bottom well you can't go lower so you know it has to rise up in all the
directions but it's yeah so that's kind of good news I think in spite of this I
don't think that the optimization problem of neural nets is solved there are still many cases where we find
ourselves to be stuck and we still don't understand what the landscape looks like this set of beautiful experiments by in
Goodfellow that help us visualize a bit what's going on but I think one of the open problems of optimization for neural
nets is we know what does the landscape actually look like it's hard to visualize of course because it's very
high dimensional but for example we don't know what those saddle points
really look like when we actually measure the gradient near those when
we're approaching those saddle points is it's not close to zero so we never go to actually flat places this may be too due to the fact that
we're using SGD and it's kind of hovering above things there might be conditioning issues or even if you are
at a cell nearer saddle point you might be stuck even though it's not a local women because in many directions
it's still going up maybe you know 95% of the directions and and the other
directions are hard to reach because simply there's a lot more curvature in some directions and other directions and
that's you know the traditional ill conditioning problem we don't know exactly you know what what's making it
hard to try in some some networks usually continents are pretty easy to train but when you go into things like
machine translation or even worse reasoning tasks like with things like you know Turing machines and things like
that it gets really really hard to train these things and people have to use all kinds of tricks like curriculum learning which are essentially optimization
tricks to make the optimization easier so I don't want to tell you that all the
optimization problem of neural nets is easy it's done we don't need to worry about it but it's much easier and less
of a concern than what people thought in
the 90s ok so so was she learning I mean
deep learning is moving out of pattern recognition and into more complicated tasks for example including reasoning
and and and combining deep learning with reinforcement learning planning and things like that
you've heard about attention that's one of the tools that is really really
useful for many of these tasks we've sort of come up with attention
mechanisms as not a way to focus on what's going on in the outside will like
we usually think of attention like attention in the visual space but internal attention right in the space of
representations that have been built so that's what we do here in machine translation and it's been extremely
successful as quark said so I'm not going to show you any of these pictures
blah blah another so I'm getting more now into the domain of challenges a
challenge that I've been working on since I was a baby researcher as a PhD student is long-term dependencies and
recurrent Nets and although we've made a lot of progress this is still something
that we haven't completely cracked and it's connected to the optimization problem that I told you before but it's
a very particular kind of optimization problem so some of the ideas that we've
used to try to make the propagation of information and gradients easier include
using skip connections over time include using multiple time scales there's some
recent work in this direction from from my lab and other groups and even the
attention mechanism itself you can think of a way to help dealing with with long
term dependencies so the way to see this is to think of the place on which we're
putting attention as part of the state right so so imagine really you have a
recurrent net and it has two kinds of state it has the usual recurrent net
state but it has the content of the memory you know Kwok told you about memory nets and neural Cheng machines
and the full state really includes all of these things and and now we are able
to read or write from that memory I mean the little recurrent net is able to do that so what happens is that there are
memory elements which don't change or time maybe they're being written once
and and so the information that has been stored there it can stay for as much
time as you know they're not going to be overwritten so so that means that if you
consider the gradients back propagated through those cells they can go pretty much unhampered and there's no vanishing
gradient problem so this is something that to be that that view of the problem
of long-term dependence sieze with memory i think is could be very useful all right
in the last part of my presentation I want to tell you about what I think is the biggest challenge ahead of us which
is unsupervised learning any question about attention and memory before I move
on to and provides learning ok so why do
we care about unsupervised learning it's not working well actually it's working a
lot better than it was but it's still not something you find in industrial products at least not in an obvious way
there are less obvious ways where unsupervised learning is actually already extremely successful so for
example when you train word embeddings with word to Veck or any other model and you use that to pre train like we did
our machine translation systems or other kinds of NLP tasks you're you're exploiting as provides learning even
when you train a language model that you're going to stick in some other thing or pre train something with that
you're also doing unsupervised learning but I think the potential of and the
importance of ents provides learning is is usually underrated so why do we care
first of all the idea of ins provides learning is that we can train we can we can learn something from large
quantities of unlabeled data that humans have not curated and we have lots of
that humans are very good at learning
from unlabeled data I have an example
that I used often that is makes it very very clear that for example children can
learn all kinds of things about the world even though no one no no no adult
ever tells them anything about it until much later when is too late
physics so you know a two or three year old understands physics you know if she
has a ball she knows what's gonna happen when she drops the ball she knows you know how liquids behave she knows all
kinds of things about objects and an ordinary Newtonian physics even though
she doesn't have explicit equations and a way to destroy them with words but she can predict what's going to happen next
right and the parents don't tell the children you know force equals mass
times acceleration right so this is
purely unsupervised and it's very powerful we don't even have that right now we don't have computers that can
understand the kinds of physics that children can understand so it looks like
it's a skill that humans have and that's very important for humans to make sense
of the world around us but we haven't really yet succeeded to put in machines
let me tell you other reasons that are connected to this why unsupervised
learning to be useful when you do supervised learning essentially the way you train your system as you you you you
focus on a particular task those here's the inputs and here's the the input variables and here's an output variable
that I would like you to predict given the input your learning P of Y given X but if you're doing as provides learning
essentially you're learning about all the possible questions that could be asked about the data of your observe so
it's not that you know there's X 1 X 2 X 3 and Y everything is an X and you can
predict any of the X given any of the other X right if I give you a picture and I had a part of it you can guess
what's missing if I hide if I hide the you know the caption you can generate
the caption given the image if I hide hide the image and I give you the caption you can you can you know guess
what the image would be or draw it or figure out you know from examples which one is the most appropriate so you can
answer any questions about the data when you have captured the Joint Distribution between them essentially so that's that
could be useful another practical thing that ins
provides learning has been used in fact this is how the whole deep learning thing started is that it could be used
as a regular Iser because in addition to telling our model
that we want to predict Y given X we're saying find representations of X that
both predict Y and somehow capture something about the distribution of X
know the leading factors the explanatory factors of X and this again is making an
assumption about the data so we can use that as a regular Iser if the assumption is valid that the essentially the
assumption is that the factor Y that we're trying to predict is one of the
factors that explain X and that by doing this provides learning to discover factors that explain X we're going to
pick Y among the other factors and so it's going to be much easier now to do
supervised learning of course this is also the reason why transfer learning
works because there are underlying factors that explain the inputs for a
bunch of tasks and maybe a different subset of factors explained are relevant for one task and another subset of
factors is relevant for another task but if these factors overlap then there's a potential for synergy you know by doing
multi task learning so the reason multi task learning is working is because unsupervised learning is working is
because there are representations and factors that explain the data that can
be useful for our supervised learning tasks of interest that also could be
used for domain adaptation for the same reason um the other thing that people
don't talk about as much about unsupervised learning and I think it was
part of the initial success that we had with stacking auto-encoders and rbms is that you can actually make the
optimization problem of training deep nets easier because if you're gonna
you know for the most part if you're gonna train a bunch of RBMS or a bunch
of voto encoders and I'm not saying this is the right way of doing it but you know it captures some of the spirit of
what ins provides learning does a lot of the learning can be done locally you're trying to extract some information you're trying to discover some
dependencies that's that's a local thing once you have a slightly better representation we can again tweak it to extract better more independence or
something of that so so there's a sense in which the optimization problem might be easier if you have a very deep net
another reason why we should care about unsupervised learning even if our ultimate goal is to do supervised
learning is because sometimes the output variables are complicated
they are compositional they have a Joint Distribution so in machine translation which we talked about the output is a
sentence the sentence is a set of as a couple of words that have a complicated Joint Distribution given the input in
the other language and so it turns out that many of the things we discover by exploring unsupervised learning which is
essentially about capturing joint distributions can be often used to deal
with these structured output problems where you you have many outputs that form a you know compositional
complicated distribution there's another reason why unsupervised learning I think
is going to be really necessary for AI model-based reinforcement learning so I
think I have another slide just for this
let's think about self-driving cars is very popular topic these days how did I
learn that I shouldn't do some things with the wheel that will kill myself
right when I'm driving because I haven't experienced these states where I get
killed and I simply haven't done it like a thousand times to get learn how to avoid it
so supervised learning where we're our rather you know traditional
reinforcement learning like and policy learning kind of thing or
actor critic or things like that won't work because I need to generalize about
situations that I'm never going to encounter because otherwise if I did I would die so these are like dangerous
states that I need to generalize about these states but I you know can't have
enough data for them and and I'm sure there are lots of machine learning applications where we would be in that
situation I remember a couple of decades ago I you know I've got some data from
nuclear plant and so you know they wanted to predict that you know when it's gonna blow up to avoid it so I said
how many how many yeah it's at zero
right so you see sometimes it's hard to do supervised learning because the data
you would like to have you can't have it's it's it's data that you know situations that are very rare or you
know so how can we possibly solve this problem well the only solution I can see
is that we learn enough about the world that we can predict how things would
unfold right when I'm driving you know I have a kind of mental model of physics
and how cars behave that I can figure out you know if I turned right at this point I'm going to end up on the wall
and it's going to be very bad for me and I don't need to actually experience that to know that it's bad I can make a
mental simulation of what would happen so I need a kind of generative model of
how the world would unfold if I do such and such actions and unsupervised
learning is sort of the ideal thing to do that but of course it's going to be hard because we're going to have to
train models that capture a lot of aspects of the world in order to be able
to learn to generalize properly in those situations even though they don't see
any data of it so that's that's one reason why I think
reinforcement learning needs to be worked on more so I have a little thing
here I think people who have been doing deep learning can collaborate with
people who are doing reinforcement learning and not just by providing a black box that they can use in their
usual algorithms I think there are things that we do in supervised deep
learning that orange provides deep learning that can be useful in sort of
rethinking our enforcement learning so so one example also so well one thing I
really like to think about is credit assignment in other words how do
different machine learning algorithms figure out what the hidden units are supposed to do what the intermediate computations or the intermediate actions
should be this is what credit assignment is about and that prop is the best
recipe we currently have for doing credit assignment it tells the you know parameters of some intermediary should
change so that the costs much much later you know hundred steps later if it's a recurrent net should be reduced so we
could probably use some inspiration from backrub and how it's used to improve
reinforcement learning and one such cue is how when we do supervised backprop
say we don't predict the expected loss
that we're going to have and then try to minimize it where the expectation would
be over the different realizations of the correct class that's not what we do but this is what people do in RL they
they will learn a critic or a cue function which is the expected learning
the expected value of the future reward or the future loss in our case that might be you know minus log probability
of the correct answer given the input and then they will backdrop
through this or use it to estimate the gradient on the actions instead when we
when we do supervised learning we're going to do credit assignment where we
use the particular observations of the correct class that actually happened for this X right we have X we have Y and we
use the Y to figure out what how to change our prediction or action so it
looks like this is something that should be done for our L and in fact we we have
a paper on something like this for a sequence prediction this is this is the
kind of work which is at the intersection of dealing with structured outputs reinforcement learning and
service learning so I think there's a lot of potential benefit of changing the
frame of thinking that people in the RL have had for many decades people in RL I mean not thinking about the world in
with the same eyes as people doing your net they've been thinking about the world in terms of discrete states that
could be enumerated and proving theorems about these algorithms that depend on
essentially you know collecting enough data to fill all the possible configurations of the state and their
you know the corresponding effects on the reward when you start thinking in
terms of neural nets and deep learning the way to approach problems is very very different okay let me continue
about as provides learning and why this is so important if you look at the kinds
of mistakes that our current machine learning algorithms make you find that
our our neural nets are just cheating they're using the wrong cues to try to
produce the answers and sometimes it works sometimes it doesn't work so how can we make our our models be you know
smarter make less mistakes well
the only solution is to make sure that those models really understand how the
world works at least at the level of humans to get human level accuracy human level performance it may be not
necessary to do this for a particular problem you're trying to solve so maybe we can you know get away with doing
speech recognition without really understanding of the meaning of the words probably that's going to be okay
but for other tasks especially those involving language I think having models
that actually understand how the world tix is going to be very very important
to so how could we have machines that understand how the world works well one
of the ideas that I've been talking a lot about in the last decade is that of
disentangling factors of variation this is related to a very old idea in pattern
recognition computer vision called invariance the idea of invariance was that we would like to compute or design
initially design and now learn features say of the image that are invariant to
the things we don't care about maybe we want to do object recognition so we don't care about position or orientation
so we would like to have features that are translation invariant rotation invariant scaling invariant whatever so
this is what invariance is about but when you're in the business of doing ends provides learning of trying to figure out how the world works it's not
good enough to do two extracting variant features what we actually want to do is to extract all of the factors that
explain the data so if we're doing speech recognition we want not only to extract the phonemes but we also want to
figure out you know what kind of voice is that maybe who is it what kind of
recording conditions or what kind of microphone is it in a car is it outside all that information which you're trying
to get rid of normally you actually want to learn about so that you'll be able to
generalize even to new tasks for example maybe the next day I'm not going to ask you to recognize phonemes but recognize who's speaking more generally if we're
able to disentangle these that explained how the data varies everything becomes easy especially if
those factors now can be generated in an independent way and to generate the data
we we can for example we can learn to
answer a question that only depends on one or two factors and basically we eliminate all the other ones because we've separated them so a lot of things
become much easier so that's one notion right we can design tangle factors
there's another notion which is the notion of multiple levels of abstraction which is of course at the heart of what
we're trying to do with deep learning and the idea is that we can have
representations of the world representation of the data as you know
description that involves factors are features and we can do that at multiple
levels and there are more abstract levels so if I'm looking at a document
you know there's the level of the pixels the level of the strokes the level of the characters the level of the words
and maybe the level of the meaning of individual words and we actually have you know systems that will recognize
from a scanned document all of these levels when we go higher up we're not
sure what the right levels are but clearly there must be representations of the meaning not just of single words but
of you know sequences of words and the whole paragraph what's the story and why is it important to represent things in
that way because higher levels of abstraction are representations from
which it is much easier to do things to answer questions so the the more
semantic levels mean basically we can very easily act on the information when it's represented that way if you think
about the level of words it's much easier to check whether a particular word is in the document if I have the words extracted then if I have to do it
from the pixels and if I have to answer a complicated question about you know the intention of the person working at
level of words is not high enough it's not abstract enough I need to work at a more abstract level which in which maybe the
same notion could be represented with many different types of words where many
different sentences could express the same meaning and I want to be able to capture that meaning so the last slide I
have is something that I've been working on in the last couple of years which is
trying to which is connected to ants provides learning but more generally to
the relationship between how we can build intelligent machines and and the
intelligence of humans or animals and as you may know this was one of the key
motivations for doing neural nets in the first place the intuition is this that
we are hoping that there are a few simple key principles that explain you
know what allows us to be intelligent and that if we can discover these principles of course we can also build
machines that are intelligent that's why the neural nets were you know inspired
by things we know from the brain in the first place we don't know this is true
but if it is then you know it's it's it's great and I mean this would make it
much easier to understand how brains work as well as building AI so in in
trying to bridge this gap because right now our best neural nets are very very different from what's going on in brains
as far as you know we can tell by talking to neuro scientists in
particular backprop although it's it's kicking
Assam from a machine learning point of view it's not clear at all how something like this would be implemented in brains
so I've been trying to explore that and and also trying to see how we could
generalize those credit assignment principles that would come out in order
to also do once provide learning so we've we've made a little bit of
progress a couple of years ago I came up with an idea called target prop which is
a way of generalizing back prop 2 propagating targets for each layer of
course this idea has a long history more
recently we've been looking at ways to
implement gradient estimation in deep recurrent networks that perform some
computation that turn out to end up with
parameter updates corresponding to gradient descent in the prediction error that looked like something that
neuroscientists have been observing and and don't completely understand called SCDP spike timing-dependent plasticity
so I don't really have time to go into this but I think this whole area of
reconnecting neuroscience with machine learning and neural nets is something
that has been kind of forgotten by the the machining community because we're all so busy you know building self-driving cars but I think over the
long term it's a it's a very exciting prospect thank you very much
yes questions yeah
to begin with great talk my question is regarding you know the lack of interlab
between the results in the study of complex networks like when they study
the brain networks right there lot of publications which that talk about the emergence of hubs and especially a lot
of publications on the degree distribution of the inter neuron Network right but then when you look at the
degree distribution of the so-called neurons in deep Nets you don't get to
see the emergence of the hub behavior so right why do you think that there's such lack of overlap between like because I
think the hop story is maybe not that important first of all I really think
that in order to understand the brain we have to understand learning in the brain and if we look at our experience in
machine learning and deep learning although the architecture does matter you know what matters even more is the
general principles that allow us to train these these things so I think the
the study of the connectivity makes sense you can't have a you know fully
connected thing and having a way to have a short number of hops to go from anywhere to anywhere is a reasonable
idea but it's it I don't think it really
explains that much that the the central question is how does the brain learn
complicated things and it does it better than then our current machines yet we we
don't know even a simple way of training brains that that at least fits the
biology reasonably yeah there are any cases with real war examples where the
cursive of dimensionality is still a problem for neural nets yeah any time it
doesn't work I mean from a generalisation point of view so Andrew told us yesterday that we
can just add more data and computing power and for some problems this may work but sometimes the amount of data
you would need is just you know too large with our current techniques and
you know we'll need also to develop you know the how did you call it the Hail
Mary all right we also need to do some research on the algorithms and the
architectures to be able to learn about
how the world is organized so that we can generalize in much more powerful ways and that is needed because the the
kind of tasks we want to solve involved in many many variables that have an explanation umber of possible values and
that's the curse of dimensionality essentially so it's facing you know pretty much all of the AI problems
around us all right the question on multi-agent reinforcement learning yeah
if you assume all cars can never predict all possible potential accidents what
about the potential for transfer learning and things like that yeah so so
I was giving an example of a single human learning how to drive we might be
able to use you know the millions of people's you know using self-driving cars correcting and some of them making
accidents to actually make some progress without actually solving the hard problems and this is probably going to
be doing for a while but and we should do it we should definitely use all the data we have currently if you look at
the amount of data were using for speech recognition or language modeling it's hugely more than what any human you know
actually sees in their lifetime so we're doing something wrong and we could do
better with less data and babies and kids you know can do it yes well there's
quite a bit of work on video these days it's mostly a computational bottleneck
yeah well keep in mind we're doing em this just a couple of years ago yeah
absolutely yeah I don't think it's a fundamental issue if if we're able to do it well on
static images the same principles will you know allow us to do sequences we're
already doing you know sequential things for example an interesting project is
speech synthesis with recurrent nets and stuff like that or convolutional nets
whatever so it's more like we're not sure how to train them well and how to
discover these explanatory factors and so on that's my cue
yeah I have a question maybe non-technical so we have seen the human error rates and then the versus the our
algorithms error rates for things that are we are used to like image recognition speech recognition right
right those are any beena experiments where we try to train humans for things that we are not used to right I'm not
trained the machine at the same time see right so this how capable are algorithms
you're asking if these experiments have been done yeah I don't know but I'm I'm
sure the humans would beat the hell out of the machines for now for this kind of thing humans are able to learn a new
task or new concepts from very few examples and we know that in order for
machines to do to do as well they they just need more sort of common sense right more general knowledge of the
world this is what allows humans to learn so quickly on on a few examples yeah you presented experimental data
very showed that lots of local minimum for these parameters or maybe saddle saddle points
have similar performance yeah are these local minima that's there locally right are these local minima separated widely
in parameter space are they close by that's a good question I could I guess a related question is once you claim the
network if there are lots of local minima does that suggest that you could compress the network and represent it
with far fewer parameters maybe so for your first question we have
some experiments dating from 2009 where we try to visualize in 2d the
trajectories of training so this is a paper first author is dumitru Aaron former PhD students with me where we we
wanted to see how different depending on where you start you know where do you end up dude different trajectories end
up in the same place or do they all go in a different place it turns out they all go in a different place and so the
number of local minima is much larger than the number of trajectories that we tried like 500 or a thousand it's so
much larger that you know no two random see initial seeds end up near each other
so it looks like there's a huge number of local minimum which is in agreement with the theory that there's an
exponential number of them but the good news is they're all kind of equivalent in terms of cost if you have a large
network I'm not sure I'm sure there are
many ways to compress these networks there's a lot of redundancy in many ways
there are there are redundancies due to
the numbering like you could flip all you know take that unit put it here to
get you and put it here and so on but I don't think you're going to gain a lot of bits from that so we've talked
about that one of the main advantages of deep learning is that they it can work with lots of data and but you were
mentioning before that we need also to capture the ability of humans of working
with a few data but the reason we're able to work with fewer data is because we have first
learned from a lot of data about you know the general knowledge of the world
right so how can we adapt neural networks to bring us to this new fuel
data paradigm we have to do a lot better add-ons provides learning and of the
kind that really discovers sort of explanations about the world that's what I think let's say thank you again so
before we stop this workshop first an announcement
you might remember yesterday Carl invited all the women here for an
informal dinner it's going to be right outside right now after we close so
before we close actually I'd like to thank all the the speaker today and yesterday I think everybody appreciated
their talk so thanks again all of you
and thanks to all the attendants I think it was a very nice weekend hope you enjoyed

----------

-----

--13--

-----
Date: 2016.09.27
Link: [# Deep Learning for Computer Vision (Andrej Karpathy, OpenAI)](https://www.youtube.com/watch?v=u6aEYuemt0M)
Transcription:


Deep Learning for Computer Vision
yeah so thank you very much for the introduction so today I'll speak about deep learning especially in the context
of computer vision so you saw in the previous talk is neural networks so you saw the neural networks are organized
into these layers fully connected layers where neurons in one layer are not connected but they're connected fully to
all the neurons in the previous layer and we saw that basically we have this layer wise structure from input until
output and there are neurons and nonlinearities etc now so far we have
not made too many assumptions about the inputs so in particular here we just assume that an input is some kind of a
vector of numbers that we plug into this neural network so that both a bug and a
feature to some extent because in most in most real-world applications we actually can make some assumptions about
the input that make learning much more efficient learning much more efficient
so in particular usually we don't just want to plug in into neural networks vectors of numbers but they actually
have some kind of a structure so we don't have vectors of numbers but these numbers are arranged in some kind of a layout like an N dimensional array of
numbers so for example spectrograms are two dimensional arrays of numbers images are three dimensional arrays of numbers videos would be four dimensional arrays
of numbers text you could treat as one dimensional array of numbers and so whenever you have this kind of local
connectivity structure in your data then you'd like to take advantage of it and convolutional neural networks allow you
to do that so before I dive into commercial neural networks and all the details of the architectures I'd like to briefly talk
about a bit of the history of how this field evolved over time so I like to start off usually with talking about
Hubble and Wiesel and the experiments that they performed in 1960s so what they were doing is trying to study the
computations that happen in the early visual cortex areas of a cat and so they
had cat and they plugged in electrodes that could record from the different neurons and then they showed the cat
different patterns of light and they were trying to debug a neurons effectively and try to show them different patterns and see what they
responded to and a lot of these experiments inspired some of the modeling that came in afterwards so in
particular one of the early models that try to take advantage of some of the results of these experiments where the
was the model called Newark cockney truant from Fukushima in 1980s and so what you saw here was these this
architecture that again is layer wise similar to what you see in the cortex where you have these simple and complex
cells where the simple cells detect small things in the visual field and then you have this local connectivity
pattern and the simple and complex cells alternate in this layered architecture throughout and so this was this looks a
bit like a comm net because you have some of its features like say the local connectivity but at the time this was not trained with backpropagation these
were specific heuristic Allah chose in' updates that and this was unsupervised
learning back then so the first time that we've actually used back propagation to train some of these networks was an experiment of a young
lagoon in the 1990s and so this is an example of one of the networks that was
developed back then in 1990s by anne lagoon as lina at five and this is what you would recognize today as a convolutional neural network so it has a
lot of the very simple computational layers and it's alternating and it's a similar kind of design to what you would
see in the Fukushima's new york cognate Ron but this was actually trained with backpropagation and to end using
supervised learning now so this happened in roughly 1990s and we're here in 2016
basically about 20 years later now computer vision has has for a long time
kind of worked here on larger images and a lot of these models back then were applied to very small kind of settings
like say recognizing digits in zip codes and things like that and they were very successful in those
domains but back at least when I entered computer vision roughly 2011 it was thought that a lot of people were aware
of these models but it was thought that they would not scale up naively into large complex images that they would be
constrained to these toy tasks for a long time or I shouldn't say toy because these were very important tasks but certainly like smaller visual
recognition problems and so in computer vision in roughly 2011 it was much more common to use a kind of these feature
based approaches at the time and they didn't work essentially that well so when I entered my PhD in 2011 working on
computer vision you would run a state of the art object detector on this image and you might get something like this
Computer Vision 2011
where cars were detected in trees and you would kind of just shrug your shoulders and say well that just happens sometimes you kind of just accept it as
a as a something that would just happen and of course this is a caricature things actually worked like relatively
decent I should say but definitely there were many mistakes that you would not see today about four years nian 2016
five years later and so a lot of computer vision kind of looked much more like this when you look into a paper of
trying that try to do image classification you would find this section in the paper on the features that they used so this is one page of
features and so they would use yeah a gist hog etc and then the second page of
features and all their hyper parameters so all kinds of different histograms and you would extract this kitchen sink of features and a third page here and so
you end up with this very large complex code base because some of these feature types are implemented in MATLAB some of
them in Python some of them in C++ and you end up with this large code base of extracting all these features caching them and then eventually plugging them
into linear classifiers to do some kind of visual recognition tasks so it was quite unwieldy but it worked to some
extent but they were definitely a room for improvement and so a lot of this change in computer vision in 2012 with
this paper from Astrid chef Sookie Ilya sutskever and Geoff Hinton so this is the first time that someone
took a convolutional neural network that is very similar to the one that you saw in from 1998 from Jana Kuhn and I'll go
into details of how they defer exactly but they took that kind of network they scaled it up they made it much bigger
and they trained it on a much bigger data set on GPUs and things basically ended up working extremely well and this
is the first time the computer vision community has really noticed these models and adopted them to work on
larger images so we saw that the performance of these models has improved
drastically here we are looking at the image net eyeless VRC visual recognition
challenge over the years and we're looking at the top 5 error so low is good and you can see that from 2010 in
the beginning these were feature based methods and then in 2012 we had this huge jump in performance and that was
due to the first kind of convolutional neural network in 2012 and then we've managed to push that over time and now
we're down to about 3.5 7% I think the results for image 2 thousand imagenet challenge 2016 are
actually due to come out today but I don't think that actually they've come out yet I have this second tab here
opened I was waiting for the result but I don't think this is a Pia tiah okay no
nothing alright well we'll get to find out very soon what happens right here so I'm very
excited to see that just to put this in context by the way because you're just looking at numbers like three point five
seven how good is that that's actually really really good so what something that I did about two years ago now now is that I try to
measure the human accuracy on this data set and so what I did for that is I developed this web interface where I
would show myself image net images from the test set and then I had this interface here where I would have all
the different classes of image net there's 1,000 of them and some example images and then basically you go down
this list and you scroll for a long time and you find what class you think that image might be and then I competed
against the ComNet at the time and this was Google net in 2000 in 2014 and so
hot dog is a very simple class you can do that quite easily but why is the accuracy not 0% it well some of the
things like hot dog seems very easy why isn't it trivial for humans to see well it turns out that some of the images in
a test set of image net are actually mislabeled but also some of the images are just very difficult to guess so in
particular if you have this Terrier there's 50 different types of terriers and it turns out to be very difficult task to find exactly which type of
Terrier that is you can spend minutes trying to find it turns out that good convolutional neural networks are
actually extremely good at this and so this is where I would lose points compared to ComNet so I estimate that
human accuracy based on this is roughly 2 to 5 percent range depending on how much time you have and how much
expertise you have and how many people you involve and how much they really want to do this which is not too much and so really we're doing extremely well
and so we're down to 3 percent and I think the error rate if I remember correctly was about 1.5 percent so if we
get below 1.5 percent I would be extremely suspicious on image net that seems wrong so to summarize basically
what we've done is before 2012 computer somewhat like this where we had these
feature extractors and then we trained a small portion at the end of the feature extractor extraction step and so we only
trained this last piece on top of these features that were fixed and we basically replaced the feature extractor in step with a single convolutional
neural network and now we trained everything completely end-to-end and this turns out to work quite nicely so I'm going to go into details of how this
works in a bit also in terms of code complexity we kind of went from a setup
that looks whoops way ahead okay we went from a setup that looks something like that and papers to
something like you know instead of extracting all these things we just say applied 20 layers with three by three
column or something like that and things work quite well this is of course an over-exaggeration but I think it's a correct first order statement to make is
that we've definitely seen that we've reduced code complexity quite a lot because these architectures are so
homogeneous compared to what we've done before so it's also remarkable that so
we had this reduction in complexity we had this amazing performance on imagenet one other thing that was quite amazing
about the results in 2012 that is also a separate thing that did not have to be the case is that the features that you
Transfer Learning
learn by training on image that turned out to be quite generic and you can apply them in different settings so in
other words this transfer learning works extremely well and of course I didn't go into details of convolutional networks
yet but we start with an image and we have a sequence of layers just like in a normal neural network and at the end we
have a classifier and when you pre train this network on image net then it turns out that the features that you learn in
the middle are actually transferable and you can use them on different data sets and that this works extremely well and
so that didn't have to be the case you might imagine that you could have a convolutional network that works extremely well on image net but when you
try to run it on some something else like birds data set or something that it might just not work well but that is not the case and that's a very interesting
finding in my opinion so people notice this back in roughly 2013 after the
first convolution networks they noticed that you can actually take many computer vision datasets and it used to be that
you would compete on all of these kind of separately and design features maybe for some of these separately and you can just shortcut all those steps that we
had designed and you can just take these pre trained features that you get from imagenet and you can just train a linear
classifier on every single data set on top of those features and you up many state-of-the-art results across many different data sets and so this was
quite a remarkable finding back then I believe so things worked very well an image net Thanks transferred very well
and the code complexity of course got much much more manageable so now all
The power is easily accessible.
this power is actually available to you with very few lines of code if you want to just use a convolutional network on
images it turns out to be only a few lines of code if you use for example Karis is one of the deep learning libraries that I'm going to go into and
I'll mention again later in the talk but basically just load a state-of-the-art complex all neural network you take an
image you load it and you compute your predictions and it tells you that this is an African elephant inside that image
and this took a couple couple hundred or a couple ten milliseconds if you have a GPU and so everything does much faster
much simpler works really well transfers really well so this was really a huge advance in computer vision and so as a
result of all these nice properties commnets today are everywhere so here's a collection of some of the some of the
ConvNets are everywhere...
things I try to find across across different applications so for example you can search google photos for
different types of categories like in this case rubik's cube you can find
house numbers very efficiently you can of course this is very relevant in self-driving cars and we're doing perception in the cars accomplishable
networks are very relevant they're medical image diagnosis recognizing Chinese characters doing all kinds of
medical segmentation tasks quite random tasks like wail recognition and more
generally many tackle challenges satellite image analysis recognizing different types of galaxies you may have
seen recently that a wave net from deepmind also very interesting paper that they generate music and they
generate speech and so this is a generative model and that's also just a comm that is doing most of the heavy lifting here so it's a convolutional
network on top of sound and other tasks like image captioning in the context of
reinforcement learning and agent in environment interactions we've also seen a lot of advances of using commnets as
the core computational building block so when you want to play Atari games or you want to play alphago or doom or
Starcraft or if you want to get robots to perform interesting manipulation tasks all of this users come that's as a
core computational block to do very impressive things not
only are we using it for a lot of different application we're also finding uses in art so so here are some examples
from deep dreams so you can basically simulate what it looks like what it feels like maybe to be on some drugs so
you can take images and you can just loosen it features these income that's or you might be familiar with neural style which allows you to take arbitrary
images and transfer arbitrary styles of different paintings like Van Gogh on top of them and this is all using
convolutional networks the last thing I'd like to note that I find also interesting is that in the process of
trying to develop better computer vision architectures and trying to basically optimize for performance on the image
net challenge we've actually ended up converging to something that potentially might function something like your visual cortex in some ways and so these
are some of the experiments that I find interesting where they've studied macaque monkeys and they record from a
subpopulation of the of the i.t cortex this is the part that does a lot of object recognition and so they record so
basically they take a monkey and they take a ComNet and they show them images and then you look at what those images are represented at the end of this
network so inside the monkey's brain or on top of your convolutional network as we look at representations of different images and then it turns out that
there's a mapping between those two spaces that actually seems to indicate to some extent that some of the things
we're doing somehow ended up converging to something that the brain could be doing as well in the visual cortex so
that's just some intro I'm now going to dive into convolutional networks and try to explain the briefly how these
networks work of course there's an entire class on this that I taught which is a convolutional networks class and so
I'm going to distill some of you know those 13 lectures into one lecture so we'll see how that goes I won't cover
everything of course okay so convolutional neural network is really just a single function it goes
from it's a function from the raw pixels of some kind of an image so we take 224 by 224 by 3 image so 3 here is for the
color channels RGB you take the raw pixels you put it through this function and you get 1000 numbers at the end in
the case of image classification if you're trying to categorize images into 1000 different classes and really
functionally all that's happening in a convolutional net work is just dot products and max operations that's everything but
they're wired up together in interesting ways so that you are basically doing visual recognition and in particular the
this function f has a lot of knobs in it so these w's here that participate in these dot products and in these
convolutions and fully connected layers and so on these WS are all parameters of this network so normally you might have
about on the order of 10 million parameters and those are basically knobs that change this function and so we'd
like to change those knobs of course so that when you put images through that function you get probabilities that are
consistent with your training data and so that gives us a lot to tune and turns out that we can do that tuning
automatically with back propagation through that search process now more concretely accomplish on your network is
made up of a sequence of layers just as in a case of normal neural networks but we have different types of layers that
we play with so we have convolutional layers here I'm using rectified linear unit relu for short as a non-linearity
so I'm making that and explicit its own layer pooling layers and fully connected
layers the core computational building block of a convolutional network though is this convolutional layer and we have
nonlinearities interspersed we are probably getting rid of things like pooling layers we might see them slightly going away over time and fully
connected layers can actually be represented there are basically equivalent to convolutional layers as well and so really it's just a sequence
of complex in the simplest case so let me explain convolutional layer because that's the core computational building
block here that does all the heavy lifting so the entire comm that is this
Convolution Layer
collection of layers and these layers don't function over vectors so they don't transform vectors as a normal
neural network but they function over volumes so a layer will take a volume a three-dimensional volume of numbers an
array in this case for example we have a 32 by 32 by 3 image so those three dimensions are the width height and I'll
refer to the third dimension as depth we have three channels that's not to be confused with the depth of a network
which is the number of layers in that network so this is just depth of a volume so this complex layer accepts a
three dimensional volume and it produces a three dimensional volume using some weights so the way it actually produces
this output volume is as follows we're going to have these filters in a convolutional layer so these filters are always small
patiently like say for example five by five filter but their depth extends always through the input depth of the
input volume so since the input volume has three channels the depth is 3 then
our filters will always match that number so we have depth of 3 in our filters as well and then we can take
those filters and we can basically convolve them with the input volume so what that amounts to is we take this
filter oh yeah so that's just the point that the channels here must match we take that filter and we slide it through
all spatial positions of the input volume and along the way as we're sliding this filter we're computing dot products so W transpose X plus B where W
are the filters and X is a small piece of the input volume and B is offset and so this is basically the convolutional
operation you're taking this filter and you're sliding it through at all spatial positions and you're computing that products so when you do this you end up
with this activation map so in this case we get a 28 by 28 activate activation
map 28 comes from the fact that there are 28 unique positions to place this 5x5 filter into this 3 32 by 32 space so
there are 28 by 28 unique positions you can place that filter in and every one of those you're going to get a single number of how well that filter alikes
that part of the input so that carves out a single activation map and now in a
compositional layer we don't just have a single filter but we're going to have an entire set of filters so here's another filter a green filter we're going to
slide it through the input volume it has its own parameters so these there are 75 numbers here that basically make up a
filter there are different 75 numbers we convolve them through get a new activation map and we continue doing
this for all the filters in that convolutional layer so for example if we had six filters in this convolutional
For example, if we had 6 5x5 filters, we'll get 6 separate activation maps
layer then we might end up with 28 by 28 activation maps six times and we stock
them along the depth dimension to arrive at the output volume of 28 by 28 by 6 and so really what we've done is we've
we represented the original image which is 32 by 32 by 3 into a kind of a new image that is 28 by 28 by 6 where this
image basically has these 6 channels that tell you how well every filter matches or likes every part of the input
so let's compare this operation to say using fully connected layer as you would in a normal neural network
so in particular we saw that we process the 32 by 32 by 3 volume into 28 by 28
by 6 volume and one question might want to ask is how many parameters would this
require if we wanted a fully connected layer of the same number of output neurons here so we wanted 28 by 28 by 6
or times 20 times when it's 12 times 28 times 6 number of neurons fully
connected how many parameters would that be turns out that that would be quite a few parameters right because every
single neuron in the output volume would be fully connected to all of the 32 by 32 by 3 numbers here so basically every
one of those - 28 by 28 by 6 now Newell's is connected to 32 by 3 2 by 3 turns out to be about 15 million
parameters and also on that order of number of multiplies so you're doing a lot of compute and you're introducing a
huge amount of parameters into your network now since we're doing convolution instead you'll notice that
think about a number of parameters that we've introduced with this example convolutional layer so we've used we had
6 filters and every one of them was a 5 by 5 by 3 filter so basically we just
have 5 by 5 by 3 filters we have 6 of them if you just multiply that out we have 450 parameters and in this I'm not
counting the biases I'm just counting the raw weights so compared to 15 million we've only introduced very few
parameters also how many multiplies have we done so computationally how many flops are we doing well we have twenty by
twenty eight by six outputs to produce and every one of these numbers is a function of a five by five by three
region in the original image so basically we have 20 by 20 by 6 and then
there's every one of them is computed by doing 5 times 5 times 3 multiplies so you end up with only on the order of 350,000 multiplies so we've reduced from
15 million to quite a few so we're doing less flops and we're using fewer parameters and really what we've done
here is we've made assumptions right so we've made the assumption that because the fully connected layer if this wasn't
fully connected layer could compute the exact same thing but it would so specific setting of those 15 million
parameters would actually produce the exact output of this convolutional layer but we've done it much more efficiently we've done that by
reducing these biases so in particular we've made assumptions we've assumed for
example that since we have these fixed filters that we're sliding across space we've assumed that if there's some interesting feature that you'd like to
detect in one part of the image like say top left then that feature will also be useful somewhere else like on the bottom right because we fix these filters and
apply them at all the spatial positions equally you might notice that this is not always something that you might want
for example if you're getting inputs that are centered face images and you're doing some kind of a face recognition isn't like that then you might expect
that you might want different filters at different spatial positions like say for I region so you might want to have some
I like filters and for math region you might want to have mouth specific features and so on and so in that case you might not want to use convolutional
layer because those features have to be shared across all spatial positions and the second assumptions that we made is
that these filters are small locally and so we don't have global connectivity we have this local connectivity but that's
okay because we end up stacking up these convolutional layers in sequence and so this the neurons at the end of the
ComNet will grow their receptive field as you stack these convolutional layers on top of each other so at the end of
the combat those neurons end up being a function of the entire image eventually so just to give an idea about what these
activation maps look like concretely here's an example of an image on the top left this is a part of a car I believe
and we have these different filters at we have 32 different small filters here and so if we were to convolve these
filters with this image we end up with these activation labs so this filter if you convolve it you get this activation
lab and so on so this one for example has some orange stuff in it so when we convolve with this image you see that
this white here is denying the fact that that filter matches that part of the image quite well and so we get these
activation maps you stack them up and then that goes into the next convolutional layer so the way this
looks then looks like then is that we processed this with some kind of a convolutional layer we get some output
we apply a rectified linear units some kind of a non-linearity as normal and then we would just repeat that operation
so we keep plugging these values into the next convolutional layer and so they
plug into each other in sequence okay and so we end up processing the image over time so that's the convolutional
layer and you'll notice that there are a few more layers so in particular the pooling layer i'll explain very briefly pooling layer is quite simple if
you've used Photoshop or something like that you've taken a large image and you've resized it you downsampled the
image well pulling layers do basically something exactly like that but they're doing it on every single channel
independently so for every one of these channels independently in a input volume will pluck out that activation lab will
down sample it and that becomes a channel in the output volume so it's really down sampling operation on these
volumes so for example one of the common ways of doing this in the context of neural networks especially is to use
MAX POOLING
maximum operation so in this case it would be common to say for example use two by two filters stride to so and do
max operation so if this is an input channel in a volume then we're basically what that amounts to is we're truncating
it into these two by two regions and we're taking a max over four numbers to produce one piece of the output okay so
this is a very cheap operation that down samples your volumes it's really a way to control the capacity of the network so you don't want too many numbers you
don't want things to be too computationally expensive it turns out that a pooling layer allows you to down sample your volumes you're going to end
up doing less computation and it turns out to not hurt the performance too much so we use them basically as a way of
controlling the capacity of these networks and the last layer that I want to briefly mention of course is the
fully connected layer which is exactly as what you're familiar with so we have these volumes throughout as we process
the image at the end you're left with this volume and now you'd like to predict some classes so we do is we just take that volume we stretch it out into
a single column and then we apply for the connected layer which is really amounts to just a matrix multiplication and then that gives us probabilities
after applying like a soft Max or something like that so let me now show you briefly a demo of
what the convolutional Network looks like so this is common nsj this is a
deep learning library for training convolutional neural networks that I've that is implemented in JavaScript I wrote this maybe two years ago at this
point so here what we're doing is we're training a convolutional network on the c 410 dataset see 410 is a data set of
50,000 images each image is 32 by 32 by 3 and there are different ten different
classes so here we are training this network in the browser and you can the loss is decreasing which means that
we're better classifying these inputs and so here's the network specification
which you can play with because this is all done in the browser so you can just change this and play with this so this
is an input image and this convolutional network I'm showing here all the intermediate activations and all the
intermediate basically activation maps that we're producing so here we have a set of filters
we're convolving them with the image and getting all these activation maps I'm also showing the gradients but I don't
want to dwell on that too much then your threshold so rel will do anything below
zero gets clamped at zero and then you pull so this is just down sampling operation and then another convolution
relu pool compre loophole etc until at the end we have a fully connected layer and then we have our soft max so that we
get probabilities out and then we apply a loss to those probabilities and back propagate and so here we see that I've
been training in this tab for the last maybe 30 seconds or one minute and we're already getting about 30 percent
accuracy on C for ten so this these are test images from C for ten and these are the outputs of this compositional
network and you can see that it learned that this is already a car or something like that so this trains pretty quickly in JavaScript so you can play with this
and continue the architecture and so on another thing I'd like to show you is this video because it gives you again
this like very intuitive visceral feeling of exactly what this is computing is there's a very good video by Jason Kaczynski from recent advance
I'm going to play this in a bit this is from the deep visualization tool box so you can download this code and you can
play with this it's this interactive convolutional network demo this is neural networks have enabled computers
to better see and understand the world they can recognize good buses and zip top left corner we showed you in this
case kappa hi Daddy so what we're seeing here is these are activation laps in some particular shown in real time as
this demo is running so these are for the calm one layer of an Alex net which we're going to go into in much more
detail but these are the different activation maps that are being produced at this point neural network called Alex
net running in cafe by interacting with the network we can see what some of the neurons
for example on this first leg the unit in the center responds strongly to light to dark edges its neighbor one neuron
over responds to edges in the opposite direction dark to light using
optimization we can synthetically produce images that light up each neuron on this layer to see what each neuron is
looking for we can scroll through every layer in the network to see what it does including convolution pooling and
normalization layers we can switch back and forth between showing the actual activations and showing images
synthesized to produce high activation but the time you get to the fifth
convolutional layer the features being computed represent abstract concepts for
example this neuron seems to respond to phases we can further investigate this neuron by showing a few different types
of information first we can artificially create optimized images using new regularization techniques that are
described in our paper these synthetic images show that this neuron fire is in response to a face and shoulders we can
also plot the images from the training set that activate this neuron the most as well as pixels from those images most
responsible for the high activations computed via the D combination technique this feature responds to multiple faces
in different locations and by looking at the D cons we can see that it would
respond more strongly if we had even darker eyes and rosy lips we can also confirm that it cares about the head and
shoulders that ignores the arms and torso we can even see that it fires to some
extent for cat faces using back prop or decom we can see that this unit depends
most strongly on a couple units in the previous layer con four and on about a dozen or so in con 3 now let's look at
another neuron on this layer so what's this unit doing from the top 9 images we
might conclude that it fires 4 different types of clothing but examining the synthetic images shows that it may be
detecting not clothing say but wrinkles in the live plot we can see that it's activated by my shirt and
smoothing out half of my shirt causes that hack of the activations to decrease
finally here's another interesting memo this one has learned to look for printed
text in a variety of sizes colors and fonts this is pretty cool because we
never asked the network to look for wrinkles or text or faces the only papers were provided were at the very
last layer so the only reason the network learned features like text and faces in the middle was to support final
decisions at that last layer for example the text detector may provide good evidence that a rectangle is in fact a
book seen on edge and detecting many books next to each other might be a good way of detecting a bookcase which was
one of the categories we trained the net to recognize in this video we've shown
some of the features of the deep is toolbox okay so I encourage you to play with that it's really fun so I hope that
gives you an idea about exactly what's going on there at these convolutional layers we downsample them from what from time to time there's usually some fully
connected layers at the end but mostly it's just these convolutional operations stacked on top of each other so what I'd
like to do now is I'll dive into some details of how these architectures are actually put together the way I'll do
this is I'll go over all the winners of the imagenet challenges and I'll tell you about the architectures how they came about how they differ and so you'll
get a concrete idea about what these architectures look like in practice so we'll start off with the Alex net in 2012 so the Alex net just to give you an
idea about the sizes of these networks and the images that they process it took to 27 by 220 7 by 3 images and the first
Case Study: AlexNet NELA
layer of an Alex net for example was a completion layer that had 11 by 11 filters applied with a stride of four
and there are 96 of them stride of four I didn't fully explain because I wanted to save some time but intuitively it
just means that as you're sliding this filter across the input you don't have to slide in one pixel at a time but you can actually jump a few pixels at a time
so we have 11 by 11 filters with a stride a skip of four and we have 96 of
them you can try to compute for example what is the output volume if you apply this this sort of convolutional layer on
top of this volume and I didn't go into details of how you compute that but basically there are formulas for this and you can look into details in
the class but you arrive at 55 by 55 by 96 volume as output the total number of
parameters in this layer we have 96 filters every one of them is 11 by 11 by
3 because that's the input depth of these images so basically just amounts
to 11 but times 11 times 3 and then you have 96 filters so about 35,000 parameters in this very first layer then
the second layer of an Alex net is a pooling layer so we apply three by three filters at Stride of two and they do max
pooling so you can again compute the output volume size of that after applying this to that volume and you
arrive if you do some very simple arithmetic there you arrive at 27 by 27 by 96 so this is the down sampling
operation you can think about what is the number of parameters and this pooling layer and of course it's zero so
pooling layers compute a fixed function fixed down sampling operation there are no parameters involved in pulling a
layer all the parameters are in convolutional layers and the fully connected layers which are some extent equivalent to convolutional layers so
you can go ahead and just basically based on the description in the paper although is non-trivial I think based on
the description of this particular paper but you can go ahead and decipher what the volumes are throughout you can look
at the kind of patterns that emerge in terms of how you actually increase number of filters in higher
convolutional layers so we started off with 96 then we go to 256 filters then to 384 and eventually 4096 units click
on layers you'll see also normalization layers here which have since become slightly deprecated it's not very common
to use the normalization layers that were used at the time for the election architecture what's interesting to note
is how this differs from the 1998 Iyanla cool network so in particular I usually like to think about for things
that hold back progress so at least in a deep learning so the data is a
constraint compute and then I like to differentially differentiate between algorithms and infrastructure algorithms
being something that feels like research and infrastructure being something that feels like a lot of engineering has to happen and so in particular we've had
progress in all those four fronts so we see that in 1998 the data you could get ahold of maybe
would be on the order of a few thousand whereas now we have a few million so we had three orders of magnitude of increase in number of data compute GPUs
have become available and we use them to train these networks they are about say roughly 20 times faster than CPUs and
then of course CPUs we have today are much much faster than CPUs that they have back in 1998 so I don't know
exactly to what that works out to but I wouldn't be surprised if it's again on the order of three orders of magnitude of improvement again I'd like to
actually skip over algorithm and talk about infrastructure so in this case we're talking about Nvidia releasing the
cuda library that allows you to efficiently create all these matrix vector operations and apply them on arrays of numbers so that's a piece of
software that you rely on and that we take advantage of that wasn't available before and finally algorithms is kind of
an interesting one because there's been in those 20 years there's been much less improvement in an algorithms than all
these other three pieces so in particular what we've done with the 1998 network is we've made it bigger so you
have more channels you have more layers by bit and the two really new things algorithmically are dropout and
rectified linear units so dropout is a regularization technique developed by
geoff hinton and colleagues and rectified linear units are these nonlinearities that train much faster
than sigmoids and ten HS and this paper actually had a plot that showed that the
rectified linear units trained a bit faster than sigmoids and that's intuitively because of the vanishing gradient problems and when you have very
deep networks with sigmoids those gradients banish as Hugh was talking about in last lecture so what's
interesting also to note by the way is that both drop out and relu are basically like one line or two lines of
code to change so it's about two line diff total in those twenty years and both of them consist of setting things
to zero so with the relevance of things to zero when they're lower than zero and with dropout you set things to zero at
random so it's a good idea to set things to zero apparently that's what we learned so if you try to find a new cool
algorithm look for one line dips that set something to zero probably will work better and we could add you here to this
list now some of the newest things that happened some of the
comparing it again and giving you an idea about the hyper parameters that are in this architecture it was the first
use of rectified linear units we haven't seen that as much before this network using the normalization layers which are
not used anymore at least in a specific way that they use them in this paper they used heavy data
augmentation so you don't only put in you don't only pipe these images into the networks exactly as they come from
the data set but you jitter them spatially around a bit and you work them and you change the colors a bit and you just do this randomly because you're
trying to build in some invariances to these small perturbations and you're basically hallucinating additional data it was the first real use of drop out
and roughly you see standard hyper parameters like say batch sizes of roughly 128 using stochastic gradient
descent with momentum usually point nine in the momentum learning rates of 1e
negative two you reduce them in normal ways so you're reduced roughly by factor of ten whenever validation stops
improving and weight decay of just a bit five you negative four and ensemble
so you train seven independent commercial networks separately and then you just average their predictions
always gives you additional 2% improvement so this is Alex net the winner of 2012 in 2013 the winner was
the Z F net this was developed by Matthew Siler and Rob progress in 2013
and this was an improvement on top of Alex net architecture in particular one of the bigger differences here where
that the convolutional layer the first convolutional layer they went from 11 by 11 stride four to seven by seven strike
two so if slightly smaller filters and you apply them more densely and then also they notice that these
convolutional layers in the middle if you make them larger if you scale them up then you actually gain performance so
they managed to improve a tiny bit matthew Zeiler then went he became the founder of clarify and he worked on this
a bit more inside clarify and he managed to push the performance to 11% which was the winning entry at the time but we
don't actually know what gets you from 14% to 11% because Matthew never disclosed the full details of what
happened there but he did say that it was more tweaking of these hyper parameters and optimizing that a bit so
that was 2013 winner in 2014 we saw a slightly bigger to this so one of the networks that was
introduced then was a vgg net from Karen Simonian and andrew zisserman what's beautiful about vgg net and they
explored a few architectures here and the one that ended up working best was this D column which is what I'm highlighting it was beautiful about the
vgg net is that it's so simple so you might have noticed in these previous in these previous networks you have these
different filter sizes different layers and you do different amount of strides and everything kind of looks a bit hairy and you're not sure where these hyper
parameters are coming from VG's unit is extremely uniform all you do is 3x3 convolutions with stride one pad one and
you do two by two Macs Bowling's with stride two and you do this throughout completely homogeneous architecture and
you just alternate a few columns and a few pool layers and you get top top performance so they managed to reduce
the air down to 7.3% in the vdg net just with a very simple item Oh genius
architecture so it's I've also here written out this a D architecture it's just so you can
see I'm not I'm not sure how instructed this is because it's kind of dense but you can definitely see and you can look
at this outline perhaps but you can see how these volumes develop and you can see the kinds of sizes of these filters
so they're always three by three but the number of filters again grows so we started off with 64 and then we go to
128 256 512 so we're just doubling it over time I also have a few numbers here
just to give you an idea of the scale at which these networks normally operate so we have on the order 140 million
parameters this is actually quite a lot I'll show you in a bit that this can be about five or ten million parameters and
works just as well and it's about hundred megabytes for image in terms of
memory in the forward pass and then the backward pass also needs roughly on that order so that's roughly the numbers that
were we're working with here also you can note that most of the and this is true mostly in convolutional networks is
that most of the memory is in the early convolutional layers most of the parameters at least in the case where you use these giant fully connected
layers at the top would be here so the winner actually in 2014 was not the VG
net I only present it because it's such a simple architecture but the winner was actually Google net with a slightly
hairier architecture we should say so it's still a sequence of things but in this case they've put inception modules
in sequence and this is an example inception module I don't know then too much time to go into the details but you can see that it consists
basically of convolutions and different kinds of strides and so on so the Google
net is look slightly a hairier but it turns out to be more efficient in
several respects so for example it works a bit better than vgg net at least at the time it only has 5 million
parameters compared to VG nets 140 million parameters so a huge reduction and you do that by the way by just
throwing away fully connected layers so you'll notice in this breakdown I did these poly connected layers here have 100 million parameters and 16 million
parameters turns out you don't actually need that so if you take them away that actually doesn't hurt the performance too much so you can get a huge reduction
of parameters and it was it was slightly we can also compare to the original
Alex net so compared to the original Alex net we have fewer parameters a bit more compute and a much better performance so Google net was really
optimized to have a low footprint both memory wise both computation wise and both parameter wise but it looks a bit
uglier and VG net is a very beautiful homogeneous architecture but there are some inefficiencies in it okay so that's
a 2014 now in 2015 we had a slightly bigger Delta on top of the architectures
so right now these architectures if you on laocoon looked at them maybe in 1998 he would still recognize everything so everything looks very like simple you've
just played with had parameters so one of the first kind of bigger departures I would argue was in 2015 with the
introduction of residual networks and so this has worked from kamini Hey and colleagues in Microsoft Research Asia
and so they did not only win the image net challenge in 2015 but they want a whole bunch of challenges and this was
all just by applying these residual networks that were trained on image net and then fine-tuned on all these
different tasks and you basically can crush lots of different tasks whenever you get a new awesome Kombat so at this
time the performance was basically 3.5 7% from these residual networks so this is 2015 also this paper try to argue
that if you look at the number of layers it goes up and then it they made the point that with residual
networks as well see in a bit you can introduce many more layers and they and that that correlates strongly with
performance we've since found that in fact you can make these residual works quite shop quite a lot shallower
like say on the order of 20 or 30 layers and they work just as fine just as well so it's not necessarily the depth here
but I'll go into that in a bit but you get a much better performance what's interesting about this paper is this this plot here where they compare
these residual networks and I'll go into details of how they work in a bit and these what they call plane networks which is everything I've explained until
now and the problem with plane networks is that when you try to scale them up and introduce additional layers they
don't get monotonically better so if you take a 20 layer model and on this is on
C far ten experiments if you take a 20 layer model and you run it and then you take a 56 layer model you'll see that
the 56 layer model performs worse and this is not just on the test data so it's not just an overfitting issue this
is on the training data the 56 layer model performs worse on the training data than the 20 layer model even though
the 56 layer model can imitate 20 layer model by setting 36 layers to compute identities so basically it's an
optimization problem that you can't find the solution once your problem size grows that much bigger in this plane net
architecture so in the residual networks that they proposed they found that when you wire them up in a slightly different
way you monotonically get a better performance as you add more layers so more layers always strictly better and
you don't run into these optimization issues so comparing residual networks to plane networks in plane networks as I've
explained already you have this sequence of convolutional layers where every convolutional layer operates over volume
before and produces volume in residual networks we have this first convolutional layer on top of the raw
image then there's a pooling layer so at this point we've reduced to 56 by 56 by
64 the original image and then from here on they have these residual blocks with these funny skipped connections and this
turns out to be quite important so let me show you what these look like
so the original climbing paper had this architecture here shown under original so on the left you see original residual
networks design since then they had an additional paper that played with the architecture and found that there's a better arrangement of layers inside this
block that works better empirically and so the way this works so concentrate on the proposed one in the middle since
that works so well you have this pathway where you have this representation of the image X and
then instead of transforming that representation X to get a new X to plug in later we end up having this X we go
off and we do some compute on the side so that's that residual block doing some computation and then you add your result
on top of X so you have this addition operation here going to the next residual block so you have this X and
you always compute deltas to it and I think this it's not intuitive that this should work much better or why that
works much better I think it becomes a bit more intuitively clear if you actually understand the backpropagation dynamics and how backprop works and this
is why I always urge people also to implement back rub themselves to get an intuition for how it works what it's computing and so on because if you
understand back rub you'll see that addition operation is a gradient distributor so you get a gradient from
the top and this gradient will flow equally to all the children that participated in that addition so you have gradient flowing here from the
supervision so you have supervision at the very bottom here in this diagram and it kind of flows upwards and it flows
through these residual blocks and then gets added to this stream and so you end up with but this addition distributes
that gradient always identically through so what you end up with is this kind of a gradient superhighway as I like to
call it where these gradients from your supervision go directly to the original convolutional layer and then on top of
that you get these deltas from all the residual blocks so these block can come on online and can help out that original
stream of information this is also related to I think why LST MS along short-term memory networks work better
than recurrent neural networks because they also have these kind of additional addition operations in the lsdm and it
just makes the gradients flow significantly better then there were some results on top of residual networks
that I thought were quite amusing so recently for example we had this result on deep networks with stochastic depth the idea here was that the authors
of this paper noticed that you have these residual blocks that compute Delta's on top of your string and you
can basically randomly throw out layers so you have these say hundred blocks 100 residual box and you can randomly drop
them out and at test time similar to drop out you introduce all of them and they all work at the same time but you
have to scale things and it just like with dropout but basically it's kind of a unintuitive result because you can throw out layers
at random and I think it breaks the original notion of what we had of commnets of as like these these feature
transformers we compute more and more complex features over time or something like that and I think it seems much more
intuitive to think about these residual networks at least to me as some kinds of dynamical systems where you have this
original representation of the image X and then every single residual block is kind of like a vector field that because
it computes in a delta on top of your signal and so these vector fields nudge your original representation X towards a
space where you can decode the answer Y of like the class of that X and so if
you drop off some of these residual blocks at random then if you haven't applied one of these vector fields then the other vector fields that come later
can kind of make up for it and they nudge they basically nudge the they pick
up the slack and they nudge along anyways and so that's possibly why this the image I currently have in mind of
how these things work so much more like dynamical systems in fact another experiments that people are playing with
that I also find interesting is you don't have you can share these residual blocks so it starts to look more like a
recurrent neural network so these residual blocks would have shared connectivity and then you have this dynamical system really where you're
just running a single RNN a single vector field did you keep iterating over and over and then your fixed point gives you the answer so it's kind of
interesting what's happening it looks very funny ok we've had many
more interesting results that so people are playing a lot with these residual networks and improving on them in
various ways so as I mentioned already it turns out that you can make these residual networks much shallower and
make them wider so you introduce more channels and that can work just as well if not better so it's not necessarily
the depth that is giving you a lot of the performance it's you can scale down the depth and if you increase the width
that can actually work better and they're also more efficient if you do it that way there's more funny
regularization techniques here swap-out is a funny regularization technique that actually interpolates between plane nets
rez nets and dropout so that's also a funny paper with fractal nets we
actually have many more different types of nets and so people have really experimented with this a lot I'm really eager to see what the winning
we'll be in 2016 as a result of a lot of this one of the things that has really enabled this rapid experimentation in
the community is that somehow we've developed luckily this culture of sharing a lot of code among ourselves so
for example Facebook has released just as an example Facebook has released residual networks code and torch that is
really good that a lot of these papers I believe have adopted and worked on top of and that allowed them to actually really scale up their experiments and
and it explore different architectures so it's great that this has happened unfortunately a lot of these papers are
come kind of on archive and it's kind of a chaos as these are being uploaded so at this point I think this is a natural point to plug very briefly in my archive
sanity calm so this is the best website ever and what it does is it crawls
archive and it takes all the papers and it analyzes all the papers the full-text
of the papers and creates tf-idf bag-of-words features for all the papers and then you can do things like you can
search a particular paper like residual networks paper here and you can look for similar papers on archive and so this is
a sorted list of basically all the residual networks papers that are most related to that paper or you can also
create user accounts and you can create a library of papers that you like and then archive Sanofi will train a support vector machine for you and basically you
can look at what our archive papers over the last month that I would enjoy the most and that's just computed by archive
sanity and so it's like a curated feed specifically for you so I use this quite a bit and I find it in useful so I hope
that other people do as well okay so we saw convolutional neural networks I
explained how they work I explained some of the background context I've given you an idea of what they look like in practice and we went through case
studies of the winning architectures over time but so far we've only looked at image classification specifically so
we're categorizing images into some number of bins so I'd like to briefly talk about addressing other tasks in
computer vision and how you might go about doing that so the way to think about doing other
tasks in computer vision is that really what we have is you can think of this computational convolutional neural network as this block of compute that
Addressing other tasks...
has a few million parameters in it and it can do basically arbitrary functions that are very nice over images and so
takes an image gives you some kind of features and now different tasks will basically look as follows you want to
picked some kind of a thing and different tasks there will be different things and you always have a desired thing and then you want to make the
predicted thing much more closer to the desired thing and you back propagate so this is the only part usually that
changes from task to task you'll see that these comments don't change too much what changes is your last function at the very end and that's what actually
helps you really transfer a lot of these winning architectures they usually use these pre trained networks and you don't
worry too much about the details of that architecture because you're only worried about you know adding a small piece at the top or changing the last function or
substituting a new data set and so on so just to make this slightly more concrete in image classification we apply this
Image Classification thing = a vector of probabilities for different classes
compute block we get these features and then if I want to do classification I would basically predict 1,000 numbers
that give me the LOC probabilities of different classes and then I have a predicted thing a desired thing
particular class and I can back prop if I'm doing image captioning the it also looks very similar instead of predicting
just a vector of 1,000 numbers I now have for example at ten thousand ten thousand words in some kind of
vocabulary and I'd be predicting ten thousand numbers and a sequence of them and so I can use a recurrent neural
network which you will hear much more about I think in Richards lecture just after this and so I produce a sequence
of ten thousand dimensional vectors and that's just a description and they indicate the probabilities of different words to be emitted at different time
steps or for example if you want to do localization again most of the block stays unchanged but now we also want
Localization
some kind of a extent in the image so suppose we want to classify we don't only just want to classify this as an
airplane but we want to localize it with X Y width height bounding box coordinates and if we make a specific
assumption as well that there's always a single one thing in the image like a single airplane in every image then you
can just afford to just predict that so we predict these softmax scores just like before and apply the cross-entropy
loss and then we can predict X Y width height on top of that and we use alloc and l2 loss or a Hooper loss or
something like that so you just have a predicted thing a desired thing and you just back drop if you want to do
Reinforcement Learning
reinforcement learning because you want to play different games then again the setup is you just predict some different thing and it has some different
semantics so in this case we will be for example predicting eight numbers that give us the probabilities of taking
different actions for example there are eight discrete actions in Atari then we just predict eight numbers and then
we trained us with a slightly different manner because in the case of reinforcement learning you don't actually have a you don't actually know
what the correct action is to take at any point in time but you can still get a desired thing eventually because you
just run these rollouts over time and you just see what what happens and then
that helps you that helps inform exactly what the correct answer should have been or what the desired thing should have
been in any one of those rollouts in any point in time I don't want to dwell on this too much in this lecture though it's outside of the scope you'll hear
much more about reinforcement learning in the in a later lecture if you wanted to do segmentation for example then you
Segmentation
don't want to predict a single vector of numbers for a single for single image but every single pixel has its own
category that you'd like to predict so data set will actually be colored like this and you have different classes different areas and then instead of
predicting a single vector of classes you predict an entire array of 224 by 224 since that's the extent of the
original image for example times 20 if you have 20 different classes and then you basically have 2 24 by 2 24
independent soft maxes here that's one way you could pose this and then you back propagate this would here would be
slightly more difficult because you see here I have a decom players mentioned here and I didn't explain the
convolutional layers they're related to convolutional layers they do a very similar operation but kind of backwards
in some way so a compilation layer kind of does these down sampling operations as it computes a decon layer does these
kind of up sampling operations as it computes these convolutions but in fact you can implement a decomp layer using
accomplish so what you do is you decom forward pass is the cobbler backward pass and the decom backward pass is the
complex basically so they're basically an identical operation but just are you up sampling we're down sampling kind of
so you can use decomp layers or you can use hyper columns and there are different things that people do in
segmentation literature but that's just the rough idea as you're just changing to loss function at the end if you
wanted to do auto-encoders so you want to do some surprise landing or something like that well you're just trying to predict the original image so you're
trying to get the convolutional network to implement the identity transformation and the trick of course it makes it
non-trivial is that you're forcing the representation to go through this representational bottleneck of 7 by 7 by
512 so the network must find an efficient represent of the original image so that it can decode it later so that would be a auto
encoder you again have an l2 loss at the end and your backdrop or if you want to do variational auto-encoders you have to
Variational Autoencoders
introduce a repair motorisation layer and you have to append an additional small loss that makes your posterior
beer prior but it's just like an additional layer and then you have an entire generative model and you can actually like sample images as well if
you wanted to do detection things get a little more hairy perhaps a compared to
Detection
localization or something like that so one of my favorite detectors perhaps to explain as the yellow detector because it's perhaps the simplest one it doesn't
work the best but it's the simplest one to explain and has the core idea of how people do detection in computer vision
and so the way this works is we reduced the original image to a seven by seven
by 512 feature so really there are these 49 discrete locations that we have and
at every single one of these 49 locations we're going to predict in yellow we're going to predict a class so
that's shown here on the top right so every single one of these forty-nine will be some kind of a soft Max and then
additionally at every single position we're going to predict some number of bounding boxes and so there's going to
be a B number of bounding boxes say B is 10 so we're going to be predicting 50
numbers and the the 5 comes from the fact that every bounding box will have five numbers associated with it so you have to describe the XY the width and
the height and you have to also indicate some kind of a confidence of that bounding box so that's the fifth number
is some kind of a confidence measure so you basically end up predicting these bounding boxes they have positions they
have class they have confidence and then you have some true bounding boxes in the image so you know that there are certain
true boxes and they have certain class and what you do then is you match up the
desired thing with the predicted thing and whatever so say for example you had one bounding box of a cat then you would
find the closest predicted bounding box and you would mark it as a positive and you would try to make that associated
grid cell predict cat and you would nudge the prediction to be slightly more towards the cat the box and so all this
can be done with simple losses and you just back propagate that and then you have a detector or if you want to get much more fancy you you could do dense
Dense Image Captioning
image captioning so in this case this is a combination of detection and image captioning this is a paper with my equal quality in Johnson and
Feifei Lee from last year and so what we did here is image comes in and it becomes much more complex I don't maybe want to go into it as much
but the first order approximation is that instead it's basically a detection but instead of predicting fixed classes
we instead predict a sequence of words so we use a recurrent neural network there but basically I can take an image
then and you can predict you can both detect and predict and describe everything in a complex visual scene so
that's just some overview of different tasks that people care about most of them consist of just changing this top
part you put different loss function a different data set but you'll see that this computational block stays
relatively unchanged from time to time and that's why as I mentioned when you do transfer learning you just want to
kind of take these blue train networks and you mostly want to use whatever works well on imagenet because a lot of that does not change too much okay so in
the last part of the talk I'd like to just make sure we're good on time okay we're good so in the last part of the
talk I just wanted to give some hints of some practical considerations when you want to apply convolutional net works in
practice so first consideration you might have if you want to run these networks is what hardware do I use so some of the options
that I think are available to you well first of all you can just buy a machine so for example and Vidya has these
digits dev boxes that you can buy they have Titan X GPUs which are strong GPUs you can also if you're much more
ambitious you can buy dgx one which has the newest Pascal P 100 GPS unfortunately the dgx one is about a
hundred and thirty thousand dollars so this is kind of an expensive supercomputer but the digits death box I
think is more accessible and so that's one option we can go with alternatively you can look at the specs of a dev box
and those specs are there good specs and then you can buy all the components yourself and assemble it like Lego
unfortunately you that's prone to mistakes of course but you can definitely reduce the price maybe by
fracture like to it compared to the Nvidia machine but of course Nvidia
machine would just come with all the software installed all the hardware is ready and you can just do work there are a few GPU offerings in the cloud but
unfortunately it's actually not at a good place right now it's actually quite difficult to get GPUs in the cloud good
GPUs at least so Amazon AWS has these great k5 five 20s they're not very good GPUs
they're not fast they don't have too much memory it's actually kind of a problem Microsoft Azure is coming up
Azura is coming up with its own offering soon so I think they've announced it and it's in some kind of a beta stage if I
remember correctly and so those are powerful GPUs K 80s that would be available to at open the eye for example
you use Sarah scale so seer scale is much more a slightly different model you can't spin up GPUs on demand but they
allow you to rent a box in the cloud so what that amounts to is that we have these boxes somewhere in the cloud I have just the DNA I just have the URL is
sh2 it it's a it's a Titan X boxes in the machine and so you can just do work that way so these options are available
to hardware wise in terms of software there are many different frameworks of course that you could use for deep
learning so these are some of the more common ones that you might see in practice so different people have
different recommendations on this I would my personal recommendation right now to most people if you just want to apply this in practical settings 90% of
the use cases are probably addressable with things like Harris so Karis would I go to number one thing to look at Karis
is a layer over tensorflow or Theano and basically just a higher-level
API over either of those so for example I usually use Karis on top of tensorflow and it's a much more higher level
language than raw tensorflow so you can also work in raw tensorflow but you'll have to do a lot of low level
stuff if you need all that freedom then that's great because that allows you to have much more freedom in terms of how you design everything but it can be
slightly more worthy for example you have to assign every single weight you have to assign a name stuff like that and so it's just much more wordy but you
can work at that level or for most applications I think Karis would be sufficient and I've used torch for a long time I still really like torch it's
very lightweight interpretable it works just just fine so those are the options that I would currently consider at least another
practical consideration you might be wondering what architecture what architecture do I use in my problem so my answer here and I've already hinted
at this is don't be a hero don't go crazy don't design your own neural
networks and convolutional layers and don't probably don't you don't to do that probably so the algorithm is
actually very simple look at whatever is currently the latest released thing that works really well in iOS VRC you
download that pre-trained model and then you potentially add or delete some layers on top because you want to do
some other tasks so that usually requires some tinkering at the top or something like that and then you fine-tune it on your application so
actually a very straightforward process the first degree I think to most applications would be don't tinker with
it too much you're going to break it but of course you can also take two 2:31 end and then you might become much better at
at tinkering with these architectures second is how do I choose the parameters
and my answer here again would be don't be a hero look into papers look what
happens they use for the most part you'll see that all papers use the same hyper parameters they look very similar so Adam when you add them for
optimization it's always learning rate one in negative three or one integrate four so four you can also use sed
momentum it's always the similar kinds of learning rates so don't go too crazy designing this one of the things you probably want to play with the most is
the regularization so and in particular not the l2 regularization but the dropout rates is something I would
advise instead and so because you might have it smaller or a much larger data
set if you have a much smaller data set and overfitting is a concern so you want to make sure that you regular eyes properly with dropout and then you might
want to as a second degree consideration may be the learning rate you want to tune that a tiny bit but that yeah
that's usually doesn't as much of an effect so really there's like two hyper parameters and you take a pre train
network and this is 90% of the use cases I would say yeah so compared to when
computer version 2011 where you might have hundreds of high parameters so yeah
okay and in terms of distributed training so if you want to work at scale
because if you want to Train imagenet or some large scale data sets you might want to train across multiple GPUs so
just to give an idea most of these state-of-the-art networks are trained on the order of a few weeks across multiple GPUs usually four or
eight GPUs and these GPS are roughly on the order of one thousand dollars each but then you also have to house them so
of course that has a different price but you almost always want to train on multiple GPUs if possible usually you
don't end up training across machines that's much more rare I think to train across machines what's much more common is you have a single machine and it has eight
Titan exes or something like that and you do distributor training on those eight titan axis there are different
ways to distribute a training so if you're very if you're feeling fancy you can try to do some model parallelism
where you split your network across multiple GPUs I would instead advise some kind of a data parallelism
architecture so usually what you see in practice is you have a GPUs so I take my batch of 256 images or something like
that I split it and I split it equally across the GPUs I do forward pass on those GPUs and then I basically just add
up all the gradients and I propagate that through so you're just distributing this batch and you're doing mathematical you're
doing the exact same thing as if you had a giant GPU but you're just splitting up that batch across different GPUs but
you're still doing synchronous training with SGD as normal so that's what you'll see most in practice which i think is the best thing to do right now for most
normal applications and other kind of considerations that sometimes enter that you could may be worried about is that
there are these bottlenecks to be aware of some particular CPU to disk bottleneck this means that you have a giant data set it's somewhere on some
disk you want that disk to probably be an SSD because you want this loading to be quick because these GPUs process data
very quickly and that might actually be a Balan like like loading the data could be a bomb like so many applications you might want to pre process your data make
sure that it's read out contiguously and very raw form from something like an HD f5 file or some kind of other binary
format and another bottleneck to be aware of is the CPU GPU bottleneck so
the GPU is doing a lot of heavy lifting of the neural network and the CPU is loading the data and you might want to use things like prefetching threads
where the CPU while the networks are doing forward backward on the GPU your CPU is busy loading the data from the
disk and maybe doing some pre-processing and making sure that it can ship it off to the GPU at the next time step so
those are some of the practical considerations I could come up with for this lecture if you wanted to learn much more about convolutional neural networks
and a lot of what I've been talking about then I encourage you to check out CS 231 n we have lecture videos
available we have notes slides and assignments everything is up and available so you're welcome to check it
out and that's it thank you
so I guess I can take some questions yeah
hello hello hi I'm Kyle afar from Luna
I'm using a lot of convolutional nets for genomics when the problems that we see is that our genomic sequence tends
to be arbitrary length so right now we're pattern for a lot of zeros but we're curious as to what your thoughts
are on using CN NS for things of arbitrary size where we can't just down sample to 277 by 277 yep
so is this lecture genomic sequence of like a TCG like that kind of sequence exactly yeah so some of the options
would be so recurrent neural networks might be a good fit because they allow arbitrarily sized contexts another
option I would say is if you look at the wave net paper from deep mind they have audio and they're using convolutional
networks for processing it and I would basically adopt that kind of an architecture they have this clever way of doing what's called a truce or
dilated convolutions and so that allows you to capture a lot of context with few layers and so let's call dilated
convolutions and the wavelet paper has some details and there's an efficient implementation of it that you should be aware of on github and so you might be
able to just drag and drop the fast wave net code into that application and so you have much larger context but it's of
course not infinite context as you might have with a recurrent Network yeah we're definitely checking those out we also tried our n ends they're quite slow for
these things our main problems that the genes can be very short or very long but the whole sequence matters so I think
that's one of the challenges that we're looking at with this type of problem interesting yeah so those would be the
two options that I would play with basically I think those are the two demo where thank you
thanks for a great lecture so my question is that is there a clear mathematical or conceptual understanding
when people decide how many hidden layers have to be part of their architecture yeah so the answer with a
lot of this is there a mathematical understanding will likely be no because we are in very early phases of just
doing a lot of empirical and I'll guess and check kind of work and so theory is
in some some ways like lagging behind a bit I would say that was residual networks you want to have more layers
usually works better and so you can take these layers outdoor you can put them in and it's just mostly computational
consideration of how much can you fit in so our consideration is usually is you have a GPU it has maybe 16 gigs of ram
or 12 gigs of ram or something I want certain batch size and I have these considerations and that upper
bounds the amount of like layers or how big they could be and so I use the biggest thing that fits in my GPU and
that's mostly what the way you choose this and then you regularize it very strongly so if you have a very small
data set then you might end up with a pretty big Network for your data set so you might want to make sure that you are tuning those dropout rates properly and
so you're not overfitting I have
question my understanding is that the recent convolution that doesn't use polling layers right so the question is
why you know why don't they use fungal areas so you know is there still a place
for puli yeah yeah so certainly so if you saw for example the residual Network at the end there was a single pooling
layer at the very beginning but mostly they went away you're right so took her I wonder if I can find the slide I
wonder if this is a good idea to try to find the slide that's bro okay let me
just find this okay so this was the residual network architecture so you see
that they do a first comm and then there's a single pool right there but certainly the trend has been to throw
them away over time and there's a paper also it's called striving for simplicity the all convolutional neural network and the
point in that paper is look you can actually do stranded convolutions you can throw away pulling layers all together or it's just as well so pulling
layers are kind of I would say this kind of a bit of a historical vestige of they needed things to be efficient then they
need to control Bastian downsample things quite a lot and so we're kind of throwing them away over time and yeah they're not doing
anything like super useful they're doing this fixed operation and you want to learn as much as possible so maybe you
don't actually want to get rid of that information so it's always more appealing to it's probably more
appealing I would say to throw them away well you mentioned there is a sort of cognitive or brain analogy that the
brain is doing polling so yeah so I think that analogy is stretched by a lot so the brain I'm not sure every brain is
doing pulling yeah about image
compression not for justification about the usage of neural networks for image
compression do we have any examples sorry I couldn't hear the question it's of classification for images can we use
the neural networks for image compression image compression yeah I think there's actually a really exciting
work in this area so one that I'm aware of for example as a recent work from Google where they're using commercial
networks and recurrent networks to come up with variably sized codes for images so certainly a lot of these generative
models I mean they are very related to compression so definitely a lot of work in the area of them that I'm excited
about also for example super resolution networks so you saw the recent acquisition of magic pony by Twitter so
they were also doing something that basically allows you to compress you can send low resolution strings because you can up sample it on the client and so a
lot of work in that area yeah I had we should patent it after you I can't
please comment on scalability regarding number of classes so what does it take
if we go up to 10,000 or 100,000 classes hmm yes so if you have a lot of classes
then of course you can grow your softmax but that becomes inefficient at some point because you're doing a giant matrix multiply so some of the ways that
people are addressing this in practice I believe is you use of like hierarchical softmax and things like that so you you
decompose your classes into groups and then you kind of predict one group at a time and you kind of converge that way
so I'm not I see these papers but I don't I'm not an expert on exactly how this works but I do know that they are
called softmax is something that people thing especially for example in language models this is often used because you have a huge amount of words and you
still need to predict them somehow so I believe Thomas Mikhailov for example he has some papers on using hierarchical softmax in this context would you could
you talk a little bit about the convolutional functions like what what considerations you should make in
selecting the functions that are used in the convolutional filters selecting the functions that are used in the
convolutional filters so these filters are just parameters right so we train those filters they're just numbers that
we trained with backpropagation okay are you talking about the nonlinearities perhaps or yeah I'm just wondering about
when you're selecting those the features or when you're getting the when you're trying to train to just understand
different features with an image what what are those filters actually doing well I see you're talking about
understanding exactly what those filters are looking for in the engine somewhat so a lot of interesting work especially for example so Jason your Sinskey he has
this deepest toolbox and I've shown you that you can kind of debug it that way a bit there's an entire lecture to encourage you to watch in CS 231 and on
visualizing understanding accomplish all networks so people use things like a decom or guided or guided back
propagation or you back propagate to image and you try to find the stimulus that maximally activates any arbitrary
neuron so different ways of probing it and different ways have been developed and there's a lecture about it so I
would I would check that out great thanks I had a question regarding the size of fine-tuning data set for
example is there a ballpark game number if you are trying to do classification how many do you put you need for
fine-tuning it to your sample set so how many how many data points do you need to
get good performance since the question okay so so okay so this is like the most
boring answer I think because the more the better always and it's really hard to say actually the company you need so
usually one way one way to look at it as one heuristic that people sometimes follow is you look at a number of
parameters and you want the number of examples to be on the order of number of parameters that's one way people sometimes break it down right for
fine-tuning because we will have an image net model so I was hoping that most of the things
would be taken care or there and then you're just fine-tuning so you you might need a lower order I say so when you're
saying fine-tuning are you finding the whole network or you're using some of it or just the top classifier just the top classifier yeah so one another way to
look at it is you have some number of parameters and you can estimate the number of bits that you think every
parameter has and then you count the number of bits in your data so that's kind of like comparisons you would do but really uh yeah I have no good answer
so the more the better and you have to try and you have to regularize and you have to cross validate that and you have to see what performance you get over time because it's to task it and then
for me to say something stronger hi I would like to know how do you think the
Covenant will work in this rady case like is they just a simple extension of the 2d case oh do we need some extra
tweak about in 3d case so you're talking specifically about say videos or some 3d
accurate talking about the image that has the depth information oh I see so
say you have like RGB D input and things like that yeah so I'm not too familiar with people do but I do know for example that people
try to have for example one thing he can do is just treat it as a fourth Channel or maybe you want the separate ComNet on
top of the depth channel and do some fusion later so I don't know exactly what the state-of-the-art in treating that depth channel is right now so I
don't exactly how they do what I do right now oh so maybe just one more question just how do you think the 3d
object great condition a 3d object yeah recognition so what is the output that
you'd like the oppo is still the class probability but we are not treating the
2d image but the 3d representation of the art I say so do you have a mesh or point cloud yeah I see yeah so also not
not exactly my area for currently but so the problem with these meshes and so on is that there's just like a rotational
degree of freedom that I'm not sure what people do about honestly so the yeah so
I'm actually not an expert on this so I don't want to comment there are some obvious things you might want to try like you might want to plug in all the possible ways you could orient this and
then a test time averaged over them so there would be some of the obvious things to play with but I don't I'm not actually sure what the state of the art
is okay thank you so coming back to the distributed
training is it possible to do even the classification a distributed way or my questions in future can I imagine my our
cellphones do these things together for one inquiry our cellphones oh I see
you're trying to get cell phones distributed training yes it's a train it's arrived quite a fun very radical
idea so related thoughts I had recently was so I had come the jas in the browser and I was thinking of basically this
trains narrow networks and I was thinking about similar questions because you could imagine shipping this off as an ad equivalent like the people just
include this in the JavaScript and then everyone's browsers are kind of like training a small network so I think
that's a related question do you think there's like too much communication overhead or it could be actually really disturbed in an efficient way
yes so the problem with distributing it a lot is actually a stale gradients problem so when you look at some of the
papers that Google has put out about distributed training as you look at the number of workers when you do
asynchronous SGD number of workers and the the performance improvement you get it kind of like plateaus quite quickly
after like eight workers or something quite small so I'm not sure if there are ways of dealing with thousands of
workers the issue is that you have a distributed every worker has this like specific snapshot of the weights that
are currently I have to pull you pull from the master and now you have a set
of ways that you're using and do forward backward and you send an update but by the time you send an update and you down your forward backward the parameters
server has now done like lots of updates from like thousands of other things and so you're grading the scale you've
evaluated it every wrong an old location and so it's an incorrect direction now
and everything breaks so that's the challenge and I'm not sure what people are doing about this yeah I was
wondering about applications of convolutional nets to two inputs at a
time so let's say you have two pictures of jigsaw puzzles puzzles these are pieces they're trying to
figure out if they fit together or whether one object compares to the other in a specific way have you heard of any
implementation of this kind yes so you have two inputs instead of one yeah so the common way
dealing with that as you put a comment on each and then you do some kind of a fusion eventually to to merge the information right I see and same for
recurrent neural networks if you have like variable input so for example in the context the videos where you have
frames coming in yeah then yeah so some of the approaches are you have accomplished all Network on the frame and then at the top you tie it in with
the recurrent neural network so you have these you reduce the image to some kind of a lower dimensional representation
and then that get that's an input to a recurrent neural network at the top there are other ways to play with this
for example you can actually make the recurrent you can make every single neuron in the calm that recurrent that's also one funny way of doing this so
right now when a neuron computes its output it's only a function of a local neighborhood and below it but you can
also make it in addition a function of that same local neighborhood or like its own activation perhaps in the previous
time step if that makes sense so so this so this neuron is not just computing a
dot product with the with the current patch but it's also incorporating a dot product of its own and maybe it's
neighborhoods activations at the previous time step of the frame so that's kind of like a small or an update hidden inside every single neuron so
those are the things that I think people play with when I'm not familiar with what currently is working best in this area pretty awesome thank you yeah yeah
thanks for the great talk final question regarding the latency for
the models that are trained using multiple layers so especially at the prediction time you know as we add more
more layers for the forward pass it will take some time you know it'll increase in the latency right for the prediction
so what are the numbers that we have seen you know you know presently that
you know that you know if you can share that you know the prediction time or the you know the latency at the the forward
pass so you're worried for example you're some you want to run a friction very quickly would it be on an embedded
device or is this in the cloud uh you're suppose you know it's a cell phone you know you have your you know identifying
the objects or you know you're you're doing some you know image analysis or something yeah so there's definitely a
lot of work on this so one way you would approach this actually is you have this network that you've trained using floating point arithmetic 32 bits say
and so there's a lot of work on taking that Network and discretizing all
into like intz and making it much smaller and pruning connections so one of the works I'm related to this for
example is someone here at Stanford has few papers on getting rid of spurious connections and reducing the network as
much as possible and then making everything very efficient with integer arithmetic so basically you achieve this
by discretizing all the weights and all the activations and throwing away and
pruning the network so there are some tricks like that that people play that's mostly what you would do in an embedded
device and then the challenge of course is you've changed the network and now you just kind of are crossing your
fingers that it works well and so I think what's interesting for Reese from research standpoint is he'd like to do
you'd like your test time to exactly match your training time right so then you get the best performance and so the
question is how do we train with low precision arithmetic and there's a lot of work on this as well so say from your show up in Joe's lab as well and so
that's exciting directions of how you train in low precision regime do you have any numbers I mean that you can
share for the new state of the art how much time does it yes I see the papers
but I'm not sure if I remember the exact reductions it's on the order of okay I don't want to say because it's go no
thanks I don't want to try to guess this thank you all right we're out of time
let's thank Andrew
lunch is outside and will restart at 12:45

----------

-----

--12--

-----
Date:  2016.09.27
Link: [# Foundations of Unsupervised Deep Learning (Ruslan Salakhutdinov, CMU)](https://www.youtube.com/watch?v=rK6bchqeaN8)
Transcription:


Deep Unsupervised Learning
sound is good okay great so I wanted to talk to you about unsupervised learning and that's the area where there's been a
lot of research but compared to supervised learning that you've heard about today like convolutional networks
you know unsupervised learning is not very yet alright so I'm going to show you lots of lots of areas parts of the
talk are going to be a little bit more mathematical I apologize for that but I'll try to give you gist off of the
foundations the math behind these models as well as try to highlight some some of the application areas okay what's the
motivation well the motivation is that you know the space of data that we have today is is just growing right you know
if you look at the space of images you know speech if you look at social network data if you look at scientific
data I would argue that most of the data that we see today is unlabeled right so
how can we develop statistical models models that can discover interesting kind of structure in unsupervised way or
semi-supervised way and that's what I'm interested in as well as how can we sort
of apply these models across multiple different multiple different domains and one particular framework of doing that
is the framework of deep learning where you're trying to learn hierarchical representations of data and and again as
we go as I go through the talk I'm going to show you some some examples I've tried so here's here's one example you
Deep Autoencoder Model
know you can take a simple bag of words representation of an article or a newspaper you can use something that's
called an autoencoder just multiple levels you extract some latent code and
then you get some representation out of it right and this is done completely in unsupervised way you don't provide any
labels and if you look at the kind of structure that the model discovering you know it could be useful for visualization for example to see what's
what kind of structure you you see in your data this was done on the on the Reuters data set I've tried to kind of
cluster together lots of different a supervised learning techniques and I'll touch on some of them it's a little bit
you know it's it's not full set but the way that I typically think about these models is that there
is a class of what I would call non probabilistic models you know models like sparse coding auto-encoders
clustering based methods and these are all very very powerful powerful
techniques and I'll cover some of them in that talk as well and then there is sort of a space of probabilistic models
and within probably stick models you have tractable models you know things like fully observed belief networks
there's a beautiful class of models called neural auto regressive density estimators more recently we've seen some
successes of so-called pixel recurrent neural network models or and I'll show
you some examples of that there is a class of so called intractable models where you know you are looking at models
like Boltzmann machines and models like variation water encoders something that's been quite there's been a lot of
development in our community and deep learning community in that space Helmholtz machines I'll tell you a
little bit about what these models are and a whole bunch of others as well right one particular structure within
these models is that when you're building these generative models or of data you typically have to specify what
the distributions you're looking at so you have to specify what the probability of the data and generally doing some
kind of approximate maximum likelihood estimation and then more recently you know we've seen some very exciting
models coming out these are generative adversarial networks moment matching networks and
this is sort of a slightly different class of models where you don't really have to specify what the density is you
just need to be able to sample from those models and I'm going to show you some some examples of that okay so my
Talk Roadmap
talk is going to be sort of structured though I'd like to introduce you to the basic building blocks models like sparse
coding models because I think that is a very important class of models particularly for folks who are working
in in industry and looking for simpler models autoencoder is a beautiful class
of models and then the second part of the talk I'll focus more on on generative models
I'll give you an introduction on into restricted Boltzmann machines and deep both machines these are sort of model statistical models that can model
so complicated complicated data and I'll spend some time showing you some
examples some recent developments in our community specifically in the case of variation autoencoders which is I view
them as a subclass of Helmholtz machines and I'll finish off by giving you an intuition about you know a slightly
different class of models which would be these generative adversarial networks okay so let's let's jump into the first
part but before I do that let me just sort of give you a little bit of motivation and know Angie's done a great
Learning Feature Representations
job and Richard sort of alluded to that as well but the idea is you know if I'm
trying to classify a particularly image right and if I say well you know if I'm looking specific pixel representation
might be difficult for me to classify what I'm seeing right on the other hand if I can find the right representations
right the right representations for these images and then I sort of get the right features so get the right
structure from the data that it might be easier for me to you know see what's what's going on with my data right so
how do I find these representations and this is this is sort of one of
Traditional Approaches
traditional approaches that we've seen for a long time is that you know you have a data you're creating some
features and then you run in your learning algorithm and for the longest time an object recognition or an audio
classification you typically use some kind of hand design features and then you start classifying what you have and
Computer Vision Features
you know like Andre was saying in the space of vision it's been a lot of different features designs of what's the
right structure we should see in the data in the space of audio same thing is
Audio Features
happening how can you find these right representations for your for your data
and the idea behind their presentation learning in particular in deep learning
is can we actually learn these representations automatically right and more importantly can we actually learn
these representations in unsupervised way right by just seeing lots and lots of unlabeled can we achieve that and you know there's
been a lot of work done in that space but we're not there yet so I wanted to sort of lower your expectations as as I
show you some some of the results ok sparse coding this is one of the models
that I think that everybody should know what it is it was actually you know
first has its roots in 96 and it was originally developed to explain early
visual processing in the brain sort of I think of it as an edge detector and the objective here is the following well if
I give you set of data points x1 up to xn you'd want to learn a dictionary of basis Phi 1 up to Phi K right so that
every single data point can be written as a linear combination of the basis that's fairly simple right there is one
constraint in that you'd want your coefficients to be sparse you'd want
them to be mostly 0 right so every data point is represented as a sparse linear
combination of bases right so this is if
you apply sparse coding to natural images right and this says this was
originally it's been a lot of work developed at Stanford with n doings group so if you apply sparse coding to
you know take little patches of images and it learn these bases these dictionaries this is how they look like
and it's they look really nice in terms of you know finding the edge edge like structure so if you've given a new
example I can say well this new example can be written as a linear combination of a few of these bases right and taking
that representation it turns out that particular representation is sparse representation is quite useful as a
feature representation of your data right so it's quite useful to have it and in general helps how do we how do we
fit these models well if I give you a whole bunch of
Sparse Coding: Training
image patches but these don't necessarily have to be image patches this could be you know little speech signals or any kind of data you're
working with you'd want to learn in a dictionary basis you have to form you have to solve this optimization problem right so the first term here
you can think of it as a reconstruction error which is to say well I take a linear combination of my basis I want
them to match my data and that is the second term which is you can think of it
as a sparse penalty term which essentially says you know try to penalize my coefficients so that most of
them are zero right that way every single data point can be written as just the linear combination sparse linear
combination of the basis and it turns out there is an easy optimization for
doing that if you fix your dictionary of bases right by one up to five SK and you solve
for the activations that becomes a standard lasso problem right there's a lot of solvers for for solving that
particular problem that's a general very you know it's it's it's a su problem
which is fairly easy to to optimize and then if you fix the activations and you optimized for dictionary basis then it's
a well-known quadratic programming problem right each problem is convex so you can sort
of alternate between finding coefficients finding bases and so forth so you can optimize this function and there's been a lot of recent work in the
last ten years of doing these things online and doing it more efficiently and so forth right at test time given a new
input or a new image patch and given a set of learned basis once you have your dictionary you can then just solve a la
Sparse Coding: Testing Time
soupe problem to find the right coefficients right so in this case given a test sample or test patch you can find
well it's written by as a linear combination of subsets of the bases
right and it turns out again that that particular representation is very useful particularly if you're interested in
classifying what you see in images and this is done in completely unsupervised way right there is no class labels there
is no specific supervisory signal that's that's here so back in 2006 there was
Image Classification Evaluated on Caltech101 object category dataset
work done again at Stanford that
basically showed a very interesting result so if I give you an input like this and these are my learned bases remember
these little edges what happens is that you just control these bases you can get these different
feature Maps much like you know the future maps that we've seen in convolutional neural networks and then
you take these feature maps and you can just do a classification right and this was done on a one of the older data sets
the Caltech 101 which is sort of a data set that predates imagenet and if you
look at you know some of the competing algorithms if you do a simple logistic regression versus if you do PCA and then
do logistic regression versus finding these features using sparse coding you
can get substantial improvements right so that's again that's that's and you
see sparks coding popping up in a lot of different areas not just in deep learning but folks who are using looking
at medical imaging domain in neuroscience these are very popular models because they're easily they're
easy to fit they're easy to to deal with so what's the interpretation of the
Interpreting Sparse Coding
sparse coding well look let's look at this equation again and we can think of sparse coding as finding and over
complete representation of your data right now the encoding function we can
think of this encoding function which is well I give you an input find me the features or sparse coefficients or bases
that make up my image we can think of encoding as an implicit and very nonlinear function of X right but it's
an implicit function we don't really specify it and the decoder or the reconstruction is just a seem simple
linear function and it's and it's very explicit just take your coefficients and
then multiply it by the you know find the right basis and get back get back
the image or the data right and that sort of flows naturally into the ideas
of autoencoders right the auto encoder is the general framework where if I give you an input data let's say it's an
input image you encode it you get some representation some feature representation and then you have a
decoder given that representation you're decoding it back into the image so you can think of encoding as a
as a feed-forward bottom-up pass right much like in convolutional neural
network given the image you're doing a forward pass and then there is also feedback and generative or top-down pass
right given features you're reconstructing back back the input image in the details is what's going inside
the encoder decoder they matter a lot and obviously you need some form of constraints you need some of constraints
to avoid learning an identity right because if you don't put these constraints what you could do is just take your input copy it to your features
and then reconstruct back right and that would be a trivial solution so we need to introduce some some additional
constraints if you're dealing with binary features if you want extract
binary features for example I'm going to show you later why you'd want to do that you can pass your your encoder through a
sigmoid non-linearity much like in the neural network and then you have a have a linear decoder that we can strike back
the input and the way we optimize these little building blocks or these little blocks is we can just have an encoder
right which takes your input takes a linear combination passes it through some non-linearity the sigmoid
non-linearity or could be rectified linear units could be 10h non-linearity and then there is a decoder where you
reconstruct back your original input right so this is nothing more than a neural network with one hidden layer and
typically that hidden layer would have a small dimensionality than the input so we can think of it as a bottleneck layer
right and we can determine the network parameters you know the parameters of the encoding the parameters of the
decoder by writing down the reconstruction error and that's what the reconstruction would look like you know
given the input in code decode and make sure whatever you decoding is as close as possible to to the original to the
original input all right then we can use back propagation algorithm to to to
Train there is an interesting sort of relationship between all encoders and property and principle component
analysis many of you have probably heard about pca as a practitioner you know if you're
dealing with large data and you want to see what's going on PCA is the first thing to use right much like what you seek regression
so and the idea here is that if the parameters of encoder and decoder are shared and you actually have the hidden
layer which is a linear layer so you don't use any nonlinearities then it turns out that the space the latent
space that the model will discover is going to be the same space as the space discovered by PCA it effectively will
collapse the principal component analysis right you're doing PCA which is sort of a nice connection because it
basically says that all encoders you can think of them as nonlinear extensions of PCA all right so you can learn a little
richer features if if you are using
autoencoders okay so here's another model if you're dealing with binary input sometimes we're dealing with like
Another Autoencoder Model
Amnesty for example again your encoder and decoder could use sigmoid nonlinearities so given an input you
extract some binary features binary features you reconstruct back the binary input and that's actually you know
relates to a model called restricted both machines something that I'm going to tell you about later in the talk okay
Predictive Sparse Decomposition
there is also other classes of models where you can say well I can also introduce some sparsity much like in
sparse coding to say that you know I need to constrain my latent features on my latent space to be sparse and that
actually allows you to learn quite reasonable features nice features here's
one particular model called predict expires decomposition where you effectively you know if you look at the
first part of the equation here the decoder part that pretty much looks like a sparse coding model right but in
addition you have an encoding part that essentially says train an encoder such
that it actually approximates what my latent code should be right so
effectively you can think of this model is that is in coder there is a decoder but then you put the sparsity constraint
on your latent representation and you can optimize for for that model and
obviously the other thing that we've been doing in the last you know seven eight and ten years is well what you can
Stacked Autoencoders
do is you can actually stack these things together right so you can learn low-level features
try to learn high-level features and so forth so just building these blocks and
perhaps at the top level if you try to solve a classification problem you can do that or and this is sometimes known
as a greedy greedy lair wise learning and this is sometimes useful whenever you have lots and lots of unlabeled data
and when you have a little label data right a small sample of label data
typically these models help you find meaningful representations such that you don't need a lot of label data to solve
the particular task that you're trying to solve right and this is again you can remove the decoding part and then you
end up with a standard or convolutional architecture again your encoder and decoder could use could be convolutional
and it's it depends on what problem you tackling and typically you know you can
stack these things together and optimize for particular tasks that you're trying to solve okay here's an example of just
Deep Autoencoders
wanted to show you some examples some early examples back in 2006 this was a way of trying to build these nonlinear
autoencoders and you can sort of pre train these models using restricted Boltzmann's or auto-encoders generally
and then you know you can stitch them together into this deep autoencoder and
back propagate through reconstruction laws right one thing I want to point out is that here's one particular example
you know the top row I show you real faces the second row you're seeing faces
reconstructed from a bottleneck of of 30 dimensional real valid bottlenecks you
can think of it as just a compression mechanism given the data high dimensional data you're compressing it down to 30 dimensional code and then
from that 30 dimensional code you're reconstructing back the original data right so if you look at the first row
this is the data the second row shows you reconstructed data and the last row shows you PCA solution right one thing I
want to point out is that you know the solution here you have a much Sharpe representation which means that it's
capturing a little bit more structure in the data it's so kind of interesting to see that sometimes these models tend to
how should I say they tend to regularize your data right like for example if you see this person with glasses removes the
glasses and that genuinely has to do with the fact that there is only one person with glasses so the model just basically said that's noise get rid of
it oh it sort of gets rid of moustaches right like if you see this there's no mustache right and then again that has
to do with the fact that there's enough capacity so the model might think that that's just a noise and you know if
Information Retrieval
you're dealing with text type of data this was done using a Reuters data set
you have about eight hundred thousand stories you take bag of words representation something very simple you
can press it down to two dimensional space and then you see what that space looks like right and I always like to
joke that you know the model basically discovers that European community economic policies that just next
disasters and accidents right this is done this was back in I think they was
collecting ninety six right I think today is probably going to become closer those difference but again this is just
a way typically autoencoders a way of compression or trying to do dimensionality reduction but we'll see
later that they don't have to be okay there is another class of algorithm called semantic hashing which is to say
Semantic Hashing
well what if you take your data and compress it down to binary representation wouldn't that be nice
because if you have binary representation you can search in the binary space very efficiently right in
fact if you can can compress your data down to twenty dimension 20 dimensional
binary code to to the twenty is about four gigabytes so you can just store everything in memory and you can look at
the you know just do memory lookups without actually doing any search at all
right so this sort of representation sometimes have been used successful in computer vision where you take your
images and then you learn these binary representations you know thirty
dimensional codes two hundred dimensional codes and it turns out it's very efficient to search through large
volumes of data using binary representation so you can you know takes a fraction of a millisecond to retrieve
images from you know a set of millions and millions of just and again this is also an active
area of research right now because people are trying to figure out we have these large databases how can you search through them
efficiently and sort of learning a semantic hashing function that maps your data to the binary presentation turns
out to be quite useful okay now let's step back a little bit and say let's now
look at generative models let's look at probabilistic models and how different they are and I'm going to show you some
examples of where they applicable here's one example of a simple model trying to
Deep Generative Model
learn a distribution of these handwritten characters so we have you know we have Sanskrit we have Arabic we
have Syria like and now we can build a model that says well can you actually
generate me what a Sanskrit should look like the flickering you see at the top
these are you know a neurons you can think of them as neurons firing and what you're seeing at the bottom is you're
seeing what the model generates what it beliefs ask it should look like right so
in some sense when you think about generative models you think about models that can generate or they can sample the
distribution or they can sample the data this is a fairly simple model we have about 25,000 characters you know coming
from 50 different alphabets about around the world you have about two million parameters is one of the older models but this is you know what the model is a
scree should look like and I think that I've asked couple of people to say that is that does that really look like
Sanskrit okay great which can mean two things it can mean
that the model is red actually generalizing or the model is overfitting right meaning that is just memorizing
what the training data looks like and I'm just showing you examples from the training data we'll come back to that point as we go through the talk here's
you know you can also do conditional simulation you know given half of the image can you complete the remaining
half right and more recently there's been a lot of advances it's actually the
last couple of years for the conditional generations and it's pretty amazing what you can do in terms of in painting given
half of the image but the other half of Lima should look like this is sort of a simple example but it does show you that it's
trying to you know be consistent with what different strokes look like right
so why is it so difficult in the space of so-called undirected graphical models
of Boltzmann machines the difficulty really comes from the following fact if I show you this image which is a 28 by
28 image it's a binary image right so some pixels are on some pixels are off there are 2 to the 28 by 28 possible
images so in fact there are 2 to the 784 possible configurations right and that space is exponential so how can you
build models that figure out in the space of characters there's only a little tiny subspace in that space right
if you start genuinely generating you know 200 by 200 images you know that
space is huge in the space of real images is really really tiny right so
how do you find that space how do we generalize to new images that's that's a very difficult question in general to to
answer one class of models is so-called fully observed models right there's sort
of been a stream of learning generative models that are tractable and they have
very nice properties like you can compute the probabilities you can do can do maximum likelihood estimation here's one example where I can if I try to
model the image I can write it down as you know taking the first pixel more than the first pixel then modeling the
second pixel given the first pixel and just just writing it down in terms of conditional project of the conditional
probabilities an inch conditional probability can take a very complicated form right it could be a complicated
neural network and oh sorry so there's
been a number of successful models one of the early models called neural auto
regressive density estimator actually developed by Hugo real-valued extension
of these models and more recently we start seeing these flavors of models there were a couple of papers popped up
actually this year from deep mind where they sort of make these conditionals to
be you know sophisticated RNN so STM's or convolutional models and they can actually generate remarkable images
and so this is just a pixel CNN generating I guess elephants yeah and
actually looks pretty pretty interesting right the drawback of these models is that we yet have to see how good of
representations these models are learning so that we could use these representations for other tasks like
classifying images or find similar images and such right now let me jump
into a class of models called restricted Boltzmann so this is the class of models where we're actually trying to learn
some latent structures some latent representation these models belong to the class of so-called graphical models
and graphical models very powerful framework for representing dependency structure between random variables this
is an example where we have you can think of this particular model you have
some pixels this is stochastic binary so called visible variables you can think of pixels in your image and you have
stochastic binary hidden variables you can think of them as feature detectors so detecting certain patterns that you see in the data
much like sparse coding models she has a bipartite structure you can write down the probability the Joint Distribution
over all of these variables you sort of have pairwise term you have Union return
but it's not really important what they look like the important thing here is that if I look at this conditional probability of the data given given the
features I can actually write down explicitly what it looks like and what does that mean that basically means that
if you tell me what features you see in the image I can generate the data for you right I can generate the
corresponding input in terms of learning features so what do these models learn they stop learn something similar that
Learning Features
we've seen in sparse coding right it's and so these classes of models are very similar to each other so given a new
image I can say well this new image is made up by some combination of these learned weights of these learned bases
and the numbers here are given by the probabilities that each particular edge is present in the data in terms of how
we learn these models one thing I want to make another point I should make here
is that given an input I can actually quickly infer what teachers I'm seeing in the image so that
operation is very easy to do unlike in sparse coding models it's it's a bit more closer to Northern Quarter given
the data I can actually tell you what features are present in my in my input which is very important for things like
information retrieval or classifying images because you need to do it you need to do it fast how do we learn these
Model Learning
models let me just give you an intuition maybe a little bit of math behind how we learn these models if I give you set of
training examples and I want to learn model parameters I can maximize the log-likelihood objective right and
you've probably seen that in these tutorials max and while objective is essentially nothing more than saying I
want to make sure that the probability of observing these images is as high as possible right so finally the parameters
of the probability of observing what I'm seeing is high and that's why you're maximizing the the likelihood objective
or the log of the likelihood objection would just you know take a product into the sum you take the derivative there's
a little bit of algebra I promise you it's not it's not very difficult like you know second-year college algebra you
differentiate and you basically have this learning rule which is the difference between two terms the first
term you can think of it as looking at sufficient statistic so cost official
statistics driven by the data and the second term is the sufficient statistics driven by the model right maybe I can
parse it out what does that mean intuitively what that means is that you look at the correlations you see in the
data right and then you look at the correlations that the model is telling you it should be and you're trying to
match the two that's what the learning is trying to do right it's trying to match the correlations that you see in
the data right so the model is actually respecting the statistics that you see in the data but it turns out that the
second term is very difficult to compute and it's precisely because the space of all possible images is so high
dimensional that you need to figure out or use some kind of approximate learning algorithms to do that
all right so you have these difference between these two terms the first term is easy to compute it turns out because
of a particular structure of the model right and we can actually do it do it
explicitly the second term is the difficult difficult one to compute right so it sort of requires you know summing
over all possible configurations all possible images that that that you could possibly see so it's this term is
intractable and what a lot of different algorithms are doing and we'll see that over and over again is using so-called
Monte Carlo sampling or Markov chain Monte Carlo sampling a Monte Carlo estimation right so let me give you an
intuition what what this term is doing that's a general trick for you know approximating exponential sums right the
whole subfield in in statistics that's basically dedicated to how do we
approximate exponential sums in fact if you could do that if you could solve that problem you could solve a lot of
problems in machine learning and the idea is very simple actually the idea is
to say well you're going to be replacing the average by sampling and there's
something that's called a Gibbs sampling Markov chain Monte Carlo which is essentially does something very simple
it basically says well start with a data sample the states of the latent
variables you know sample the data sample the states of the way through then sample the data from these conditional distributions something that
you can compute explicitly right and that's a general trick you know much like in sparse coding we you know we're
optimizing for the basis when we're optimizing for the coefficients here you're inferring the coefficients then
you you know in vary what the data should look like and so forth and then you can just run a Markov chain and sort
of approximate approximate you know this exponential sum so you start with the
data you sample the states of the hidden variables you resample the data and so forth and the only problem with a lot of
these methods is that you know you need to run them up to infinity to guarantee
that you're sort of getting the right thing and so obviously you know you will never run them you know infinite you
don't have time to do that so there's a very clever algorithm that contrastive divergence algorithm that was developed
Contrastive Divergence
by Hinton back in 2002 and it was very clever it basically said well instead of
this thing up to infinity run it for one step right and so you're just running it
for one step you start with a training vector you you update the hidden units you update all the visible units again
so that's your reconstruction much like an autoencoder you reconstruct your data you update the hidden units again and
then you just update the model parameter which is just looking at you know empirically the statistics between the data and the model right very similar to
what the auto encoder is doing but slight slight differences and implementation is basically takes about
like penalize of MATLAB code I suspect is going to be you know two lines intensive flow although I don't think
terms of flow folks implemented Boltzmann machines yet that would be my request but you can extend these models
to dealing with real valued data right so whenever you're dealing with images for example and it's just a little
change to the definition of the model and your conditional probabilities hedge is going to be bunch of gaussians so
that basically means that given the features sample me the space of images and i can sample you give you you know
real real valued images the structure of the model remains the same if you train
this model on you know the these images you sort of tend to find edges something
similar again to what you'd see in sparse coding and I see in depending upon analysis model auto-encoders and
such and again you can sort of say well every single image is made up by some some linear combination of these basis
functions you can also extend these models to dealing with count data right if you're dealing with documents in this
RBMs for Word Counts
case again it's slight change to the model K here denotes your vocabulary
size and DK the knots number of words that you're seeing in your document right so if you you know it's it's a bag
of words representation and the conditional here is given by so called softmax distribution much like what
you've seen in in the previous classes when we you know the distribution of possible words right and the parameters
here double use you can think of them as you know something similar to as what the back embedding would do and so if
you apply to in again some some of datasets you know you tend to find
reasonable features right so can to find you know features about Russia about us
about computers and so forth right so much like you found these representations little edges every image
is made up by some combination of these edges in case of documents or webpages
you're saying the same thing it's just made up cyma linear combination of of these learned topics every single
document is made up by some combination of these topics right you can also look at one-step reconstruction so you can
basically say well how can I find similarity between the words so if I show you chocolate cake and further
states of hidden units and then I reconstruct back the distribution of possible words you know it tells me you
know chocolate cake cake chocolate sweet dessert cupcake food sugar and so forth right I particularly like the one about
the flour hi and then there is a Japanese sign the model sort of generates flour Japan Sakura blossom
Tokyo all right so it sort of picks up again on low-level correlations that you see in your data you can also apply
Collaborative Filtering
these kinds of models to collaborative filtering where every single observed variable you can model you know can
represent a user rating for a particular movie right so every single user would
rate a certain subset of movies and so you can represent it as the state of visible via your hidden states can
represent user preferences what they are and on the netflix data set if you look
at the latent space that the model is learning you know some of these hidden variables are capturing specific movie
genre right so for example there is this is actually one hidden union dedicated
to michael michael moore's movies rights instead of like very strong i think it's sort of you know either people like it
or hate it so there are a few hidden specifically dedicated to that but it also finds interesting things like you
know action movies and so forth right so it finds that particular structure in the data so you can model different
kinds of modality real-valued data can model count data a multinomial x' and it's very easy to
infer the states of the hidden variables so that's given just the product off of logistic functions and that's very important in a lot of different
applications given the input that can quickly tell you what topics I see in the data right one thing that I want to
Product of Experts
point out that's an important point is a lot of these models can be viewed as product models sometimes people call
them product of experts and this is because of the following the following
intuition if I write down the Joint Distribution of my hidden observed variables I can write it down in this
sort of log-linear form right but if I sum out or integrate out the states of
the hidden variables I have a bunch of product of a whole bunch of functions right so what is what does it mean what
what's the intuition here so let me show you an example suppose the model finds these specific topics right and suppose
I'm going to be telling you that the document contains topic government corruption in mafia then the word silvio
berlusconi will have very high probability right I guess does anybody know you know everybody knows who Celia
Celia Berlusconi right he's he had like you know he's in head of the government he's connected to mafia he is his very
corrupt was corrupt and I guess I should add like a bunker bunker parties here right then it will become completely
clear what I'm talking about but then you know one point I want to make here is that it's it's you know you
can think of these models as a product each hidden variable defines a distribution over possible words over
possible topics and once you take the intersection of these distributions you can be very precise about what is it
that you modeling right so that's unlike generally topic models or let Indian
education models models where you're actually using mixture like a approach
and then typically these models do perform far better than traditional mixture based models and this comes to
Local vs. Distributed Representations
the point of local versus global versus distributed representations right in in
a lot of different algorithms you know even the supervised learning algorithm such as clustering you typically have some your
partitioning the space and you're finding local prototypes right and the
number of parameters for which you have basically you know parameters for each region the number of regions typically
grow with linearly with a number of parameters but in models like factor
models PCA restricted Boltzmann machines deep models you typically have distributed representations right what's
the idea here the idea here is that if I show you the two inputs right each particular neuron can you know
differentiate between two parts of the plane given the second one you know I can partition it again given the third
hidden variable you can partition it again so you can see that every single neuron will be affecting lots of
different regions and that's the idea behind distribute representations because every single parameter is
affecting many many widgets not just the local region and so the number of regions grow roughly exponentially with
the number of parameters right so that's the differences between these these two
classes of models important to know about them now let me jump and quickly tell you a little bit of inspiration
behind what what can we build with these models right as we've seen with convolutional networks the first layer
Deep Boltzmann Machines
we typically learn some low-level features like edges or you know if you're working with the word word table
typically learn some low-level structure and the hope is that the higher-level features will start picking up some
higher-level structure as as you are building and these kinds of models can
be built in completely unsupervised way because what you're trying to do is you're trying to model the data you try to model the distribution of of the data
Model Formulation
you can write down the probability distribution for this models known as a
Boltzmann machine model you have dependencies between hidden variables so now introducing some extra you know some
extra layers and dependencies between those layers and if we look at the equation the first part of the equation
is basically the same as what we had with restricted Boltzmann and then the second and third part of the equation
essentially modeling dependencies between you know the first and the second hidden layer and the second
hidden layer third in there right there is also a very natural notion of bottom-up and top-down so if I want to see what's the
probability of a particular Union being taking value 1 it's really depend on
what's coming from below what's coming from above so there has to be some consensus in the model to say ah yes
what I'm seeing in the image and what my model believes the overall structure should be should be an agreement right
and so in this case of course in this case hidden variables become dependent even when you condition on on the data
so these kinds of models we'll see a lot is you introducing more flexibility you're introducing more structure but
then learning becomes much more difficult right you have to deal you know how do you influence in these
models right now let me give you an intuition of what how can we learn this
model what's the maximum likelihood estimator doing here well if I differentiate this model with respect to
parameter basically run into the same learning rule and it's the same one you know you see whatever you're working with undirected graphical models factor
graphs conditional random fields you might have heard about those those ones it really is just trying to look at the
statistics driven by the data correlations that you see in the data and the correlations that the model is telling you it's seeing in the data and
you just try to match the two right that's exactly what's happening in that particular equation right but the first
term is no longer factorial so you know you have to do some approximation with these models let me give you an
intuition watch what each term is doing so far as I have some data right and I get to observe these characters well
what I can do is I really want to tell the model this is real right these are
real characters so I want to put some probability mass around them and say these are real and then there is some
sort of a data point that looks like this just bunch of pixels on and off and I really want to tell my model that you
know put all the zero probability on this this is not real right and so the
first term is exactly trying to do that the first term is just trying to say put the probability max where you see the
data and the second term is effectively trying to say well look at this entire exponential space and just say no
everything else is not real it's just the real thing is what I'm seeing in my data and so you can use sort of
advanced techniques for doing that it's a class of algorithms called variational inference it's something that's called
stochastic approximation which is Monte Carlo based inference I'm not going to go into these techniques but in general
you can you can train these models so one question is how good are they all
Good Generative Model?
right because a lot of proximation that go into these models so what I'm going to do is if you have if you haven't seen
it I'm going to show you two panels on one panel you will see the real data or
another panel you'll see data simulated by the model or the fake data and you have to tell me which one is which okay
so again these are handwritten characters coming from you know alphabets around the world how many of
you think this is simulated and the other part was real honestly okay some
what about the other way around I get half and half which is great if you look
at these images a little bit more carefully you will see the difference right so you will see that this is
simulated and this is real right because if you look at the real data it's much
crisper there is more diversity when you're simulating the data it's a lot of structure in the simulated characters
but some you know sometimes a little bit files it isn't as much diversity right and I've learned that trick from from my
neuroscience friends if I show you quickly enough you won't see the difference and and you know if you're
using these models for for for classifying you know you can do proper analysis which is to say given a new
character you find further states of the latent variables hidden variables if I classify based on that how good are they
and and they are they're you know they're much better than some of the existing techniques this is another
Generative Model of 3-D Objects
example you know trying to generate 3d objects this is sort of a toys data sets and later on I'll show you some you know
bigger advances that's been happening in the last few years this was done a few years ago you know if you look at the
space of generated samples they you know they sort of you know you obviously you
can see the difference here's here's paid look at this particular image right this image looks like car with wings
don't you think right so there's sometimes it can sort of simulate things that are not
necessarily realistic and for some reason it just doesn't generate donkeys and elephants too often right but it
generates people with guns more often like if you look at here and here and here and that again has to do with the
fact that you know you exploring this exponential space of possible images and
it's sometimes it's very hard to assign the right probabilities the different parts of the space right and then
3-D Object Recognition
obviously you can do things like pattern completion so given half of the image can you complete the remaining half so
the second one shows what the completions look like and the last one is what the truth is so you can do you can do these things so where else can we
use these models these are sort of toy examples but where else let me show you one example where these models can
Data - Collection of Modalities
potentially succeed which is trying to model the space of the multi model space
which is the space of you know images and texts or you know generally if you
look at the data it's not just single source it's a collection of different modalities alright so how can we take
all of these modalities into account and this is really just the idea of you know given images and texts can you actually
find a concept that relates these two different sources of sources of data and
Challenges - 11
there are a few challenges and that's why you know models like generative models sometimes probablistic models
could be useful general one of the biggest challenge we've seen is that typically when you're working with
images and text these are very different modalities right if you think about images in pixel representation they're
very dense if you're looking at text it's typically very sparse right so it's very difficult to learn these cross
model features from low-level representation perhaps a big challenge is that a lot of
times we see data that's very noisy right sometimes it's just non-existent giving an image there is no text or if
you look at the first image you know a lot of the tags about is what kind of camera was used to to describe that
particular image which doesn't really tell us anything about the image itself right and these are this would be the
text generated by a version of a Boltzmann machine model sort of does you know samples what what
should look like and this is the the idea again is very simple if you just build a simple representation given
A Simple Multimodal Model
images and given text you just try to find what the common representation is it's very difficult to learn these cross
model features but if you actually build a hierarchical model so you start with
representation you know you can build a Gaussian model replicate itself max molecule so build up that representation
then it turns out it's much more it gives you much richer representation is
also when if a notion of bottom-up and top-down which means that you know low level or images or tags can effectively
effect low level representation of images and the other way around so information flows between images and
texts sort of gets into some stable state and this is what you know the text
Text Generated from Images
generated from images looks like some of the examples you know a lot of them a lot of them look reasonable but more
recently with the advances of cornets this is probably not that surprising
here's some examples of the model that's not quite doing the right thing right I
particularly like the second one for some reason it sort of correlates with Barack Obama and such and we've sort of
the features when we were using this model we didn't have at that time sort of image that features right now I don't
think we would be making these mistakes but generally speaking you know what we found in a lot of the data is that there aren't a lot of images of animals right
which brings us to the next problem is that if you don't see images of animals then the mall is confused because it sees a lot of Obama signs and these are
black and also white and and blue sort of signs that appearing a lot you can
also do images from text given text or tags can retrieve relevant images so you
know this is the data set itself at about million images it's a nice nice data set and you have you know very noisy tags and the question is can you
actually learn some representation from from those images one thing that I want to highlight here is you know we've
tried you know this is 25,000 labeled image somebody went and label what's going on in those images what classes we
see in those images and you get some numbers which is main average precision but what's important here is that we
found that if we actually use label data and we pre train these channels separately using a million
label data points then we can actually get some performance improvement so at least that was a little bit of happy
sign for us to say that you know unlabeled data can help in the situations where you don't have a lot of
labeled examples so here was helping us it was helping us a lot and then once
Multimodal Linguistic Regularities
you get into this sort of representations dealing with text and images this is one particular thing you
can do and I think Richard pointed out you know what happens in the space of linguistic regularities you can do the
same thing with images just kind of fun to do they they sometimes work they don't work all the time but here's one
example if I take that particularly image at the top and I say get the representation of this image subtract
the representation of day add the night and then find closes images you get these images right and then you can do
some interesting things like take these kittens and say - ball + box to get kittens in the box right if you take
this particular image and say - box + ball get kittens in the ball right except for this thing that's a duck so
you know that's you can sort of get these interesting interesting representations of course these are all
sort of fun things to look at but they don't really mean much because we're not specifically optimizing for those things
right now let me spend some time also
talking about another class of models these are known as Helmholtz machines and variational tinker's these are the
models that have been sort of popping up in our community in the last two years right so what is a Helmholtz machine a
hell-house machine was developed back in 95 and it was developed by Hinton and
Peter Dayan and Brandon Frey and Radford Neal and it has this particular
architecture you have a generative process given some latent state you just
it's a neural net with a stochastic neural network that generates the input data right and then you have so-called
approximate inference step which is to say given the data infer approximately
what the latent States should look like right and again it was
developed in 95 there's something is called waste sleep algorithm and it never worked basically people just said
it just doesn't work and you know then we started looking at restricted boltzmann shades on both machines
because they were working a little bit better and then two years ago people figure out how to make them work and so
now 10 years later I'm going to show you the trick now these models actually working pretty well the difference
between Helmholtz machines and deep Boltzmann chains is very subtle they almost look identical the big
difference between the two is that in hell most machines you have a generative process that generates the data and you
Helmholtz Machines vs. DBMS
have a separate recognition model that tries to recognize what you see in the data so you can think of this cue
function as a convolutional neural network given the data tries to figure out what the feature should look like and then there is a generative model
given the features it generates the data Boltzmann machine is sort of similar class of models but it has undirected
connection so you can think of it as generative and recognition connections are the same so it's sort of a system
that tries to know which some equilibrium state when you're running it
so it's a little bit the semantics is a little bit different between these two models so what is the variation water
encoder variational core is is a Helmholtz machine it defines a generative process in terms of sampling
Variational Autoencoders (VAE) The VAE defines a generative process in terms of ancestral sampling through a cascade of hidden stochastic layers
through cascades of stochastic layers and it's if you look at it there's just bunch of conditional probability
distributions that you're defining so you can generate the data so theta here will denote the parameters of the
variation auto-encoders you have a number of stochastic layers and sampling
from you know this conditional probability distributions hallam you know we're assuming that we can do it it's a tractable it has to be tractable
but the innovation here is that every single conditional probability can
actually be you know it can be very complicated function in keynote you know a nonlinear you can model nonlinear
relationships it can be a multi-lane only a neural network deterministic neural network right so it becomes
fairly fairly powerful he's here's an example of I have a stochastic layer you have a deterministic way have a
stochastic way and then you generate generate the data right so you can introduce these nonlinearities
into these models and this conditional probability we didn't know the one layer
neural network right now I'll show you some examples but maybe I can just give
you a little intuition behind what these equations do and a lot of these kinds of
models learning is very hard to do and there is a class of models called variational learning and what the
variational learning is trying to do is basically trying to do the phone but I want to maximize the probability of the data that I observe but I cannot do it
directly so instead what I'm going to do is I'm going to maximize the so called variational Lobot which is this term
here right and it's effectively saying well if I take the log of expectation I
can take the log and push it inside right and it turns out just logistically
working in this representation is much easier than working in this representation right if you go a little
bit through the math turns out that you can actually you know optimize this variation above but you can't really
optimize this particular likelihood objective it's a little bit surprising
for those of you who haven't seen variation of learning how it's done you know but this one little check this one
little so-called Jensen's inequality actually allows you to solve a lot of problems right and the other way to
write the lower bound is to say well there is a log likelihood function and something is called KL divergence which
is the distance between your approximating distribution Q which is your recognition model and the truth the
truth in these models would be the true posterior cording to your to your model and it's hard to optimize these kinds of
models in general you know you're trying to optimize your generative model you try to optimize the recognition model
and back in 88 back in 95 Hinton and his students basically they developed this
wake-sleep algorithm that was a bunch of different things put together but it was never quite the right algorithm because
it wasn't really optimizing anything it was just bunch of things alternating but
in 2014 there was a beautiful trick introduced by kingman Welling and there was a few other groups that came up with
the same trick called recanalization trick right so let me show you what repolarization trick does intuitively
so let's say your recognition distribution is a Gaussian right so a Gaussian I can write it as you know I
mean in the variance so this is the mean this is the variance notice that my mean depends on the layer below could be very
nonlinear function the variance also depends on the layer below so it could also be a nonlinear function but what I
can do is I can actually do the following I can express this particular Gaussian in terms of Xillia variables so
I can say well if I sample this epsilon from normal 0 1 a Gaussian distribution then I can write this particular H right
my-my-my state in a deterministic way it's just mean plus essentially standard
deviation or variance square root of the variance times this epsilon right so
this is just a simple parameterization of the gaussians right and just pulling out the mean and the variance there's no
sort of surprises here so I can write my recognition model as this Gaussian or I
can write it in terms of noise plus the deterministic part right so the recognition distribution can be
represented as a deterministic mapping and that's that's the beauty because it turns out that you can collapse these
complicated models effectively into auto-encoders right and we know how to deal with auto-encoders we can back
propagate through the entire through the entire model so we have a deterministic encoder and then the distribution of
these auxiliary variables really don't depend on parameters right so we sort of it's almost like taking a stochastic
system and separating the stochastic part and deterministic part in the terminus tic part you can do back
propagation so you can do learning and the stochastic Park you can do sampling right so just think of it as a separation between the two the two
pieces so now if I take the gradient of the variational bound or variational objective with respect to parameters
this is something that we couldn't do back in 95 and we couldn't do it in the last 10 years people tried using
reinforced algorithm or some approximations that never worked but here what we can do is we can do the
following we can say well I can write this expression because it's a Gaussian a sampling bunch of these axillary
variables and then this log I can just inject the noise in here the whole thing here
becomes deterministic and that's that's where the beauty comes in you take these gradient here and you push it inside the
expectation right so before if you take the gradient of expectation it's like
taking the gradient of averages like you compute bunch of averages in you're taking the gradient what you're doing
now with reprimands a ssin trick is you're taking the gradients and then taking the average right it turns out
that huge it reduces the variance in your training and it actually allows you to learn these models quite quite
efficiently so the mapping edge here is is completely deterministic and gradients here can be computed by back
propagation is a deterministic system and you can think of this thing inside it's just an autoencoder that that you
are that you are optimizing and obviously there are other extensions of these models that we've looked at and a
bunch of other teams looked at where you can say well maybe we can improve these models by drawing multiple samples these
are so-called K samples importance weighting bounce and so if you can make them a little bit better a little bit
more precise you can model a little bit more complicated distributions over the over the posterior but now let me sort
of step back a little bit and say why am I telling you about this what's the point there's a bunch of equations you injecting noise why do we need noise why
do we need stochastic scene systems in general right here's a motivating
example we wanted to build a model that given captions we want to generate the
image right and my student was very ambitious and basically said I want to be able to just tell give you any
sentence and and I want to be able to generate image like kind of like an artificial pain I want to paint what
what's in my what's in my caption in the most general way right so this is one
example of a Helmholtz machine where you have a generative model which is a stochastic recurrent network is just a change sequence of a variational
auto-encoders and there's a recognition model which is you can think of a deterministic system like a
convolutional system that tries to approximate what the latency states are but why do I need why do I need to the
caste city here why do I need very short encoders here and the reasons very simple suppose I
you know I give you the following tasks right I say a stop sign is flying in blue skies okay
now if you were using a deterministic system like an auto encoder you would generate one image right because it's a
deterministic system give an input I give you you know I'll give you output once you have stochastic system you
inject this noise this latent noise that allows it to actually generate a whole space of possible images right so for
example it tends to generate like this stop sign and this stop sign they look very different right and there's a car
here so maybe it's not really flying is just can't draw the pole here this one
looks like they're clouds here's this yellow school buses flying in those guys right so here we wanted to test the
system to see does it understand something about what's what's in the sentence here's a herd of elephants is
flying in blue skies now we cannot generate elephants although there are no techniques that are getting better but
you know sometimes it generates two of them right and the commercial plane flying in blue skies but this is where
we need stochastic because we want to be able to generate the whole distribution of possible outcomes not necessarily
just one particular point right here's you know we can basically do things like
you know a yellow school bus parked in the parking lot versus a red school bus parked in the parking lot versus a green school bus park in the
parking lots it's sort of the blue school bus rights it's sort of we can't quite generate blue school buses but
we've seen blue cars and we've seen blue buses so it can sort of make an association to to draw these different
things they look a little bit fuzzy but you know in terms of comparing two
different models if I give you a group of people on the beach with surfboards this is what we can generate there is
another model called webcam model which is a model based on that the cellular networks something out I'll talk last
part of this talk and there is these models convolutional deconvolution all the ocean water encoders which is again
convolutional deconvolution 'l auto-encoders just with with some noise and you can certainly see that you know
it's generally we found it's very hard to be able to generate scenes with arbitrary inputs as a text right here's
here's my favorite one a toilet it's it's open in the bathroom all right I don't know if you can see a
toilet sits here maybe but you can say toilets it's it's open in the grass field that was a little bit better at
least the colors were quite right and when we put this paper on archive one of
one of the students basically came to me and said well this is really bad because
you can always ask Google right and if you if you type that particular query into Google search it gives you that all
right which was a little bit disappointing but now if you actually
Google or if you actually put this query into Google this image comes before this
image and generally because what's happening is that people are just
clicking on that image all the time to figure out what's going on in that image so we got bumped up before before that
other means so so now I can say that according to Google this is a much better representation for that sentence
now than listen here's another here's another sort of interesting model which
is a model where you're trying to build a recurrent neural network again it's a
generative model but it's a generative model of text this was this model was trained on about 7,000 romance novels
and you take a caption model and you hook it up to the to the caption
generation system so you're basically saying the model here's an image generate me you know in the style of
romantic books what what you'd see here and you know it generates generates
something interesting we barely were able to catch the breeze on the beach and so forth she's beautiful but the
truth is I don't know what to do the Sun was just starting to fade away leaving
people scattered around the Atlantic Ocean so and there are a bunch of different things that you can do
obviously you know we're not there yet in terms of generating romantic stories but here's a one example where it's a
generative model it seems like syntactically we can actually generate you know reasonable things semantically
we're not there yet right and actually that particular work was inspired a little bit by by actually by by deuce
system that would give image it would I think of generate poems right but the points were predefined so
it was mostly the selecting the right point for the image here we actually were trying to you know generate
something something so there's still a lot of work to do in that space because you know syntactically we can get there
semantically we are nowhere near you know getting getting the right structure here is another last example that I want
to show you this was done in the case of one shot warning which is can you build
generative model of characters right that's a very defined domain very well
defined domain it's a very simple domain but it's also very hard right here's one example we've shown this example to
people and to the algorithm and we can say well can you draw me this this example and you know on one panel humans
would draw you know how they believe these this example should look like and then on the other panel we have machines
drawing it right this is it really just a generative model of based on a single
example showing you example and try to generate what it is and so question for you how many of you think this was a
machine generated and this was human generated ah what about the other way
around more MORE aha so there is a vote what this is what about this one this is
the how many do you think this machine generated is a human generated a few what about that aware it around ah great
great well the truth is I don't really know which one was genuine about this machine because that was done I should
actually ask Brandon Lake who designed the experiments for this particular model but I can tell you that I can tell
you that you know there's been a lot of studies he's done a lot of studies and it's about you know it's almost 50/50 so
in sort of this kind of small carve domain we can actually compete with people you know trying to generate these
these characters now let me step back a little bit and tell you about a
different class of models these are models known as generative adversarial
networks and they've been gaining a lot of attraction in in our community
because they seem to produce remarkable results so here's here's the idea we're not
going to be really defining explicitly the density but we need to be able to sample from the model right and the
interesting thing is that there's no variation learning there is no maximum likelihood estimation there is no Markov chain Monte Carlo there's no sampling
how do you do that how do you learn these models and it turns out that you can learn these models by playing a game
and that's a very clever strategy and the idea is the following you're going
to be setting up a game between two players you're going to have a discriminator do you think of it as a
convolutional network convolutional neural network and then you're going to have a generator gee maybe you can think
of it as as a variational tank or a Helmholtz machine or something that gives you samples from the data the
discriminated D is going to be discriminating between a sample from the data distribution and a sample from the
generator so the goal of the discriminate is to is to basically say is this a fake sample or is this a real
sample right fake sample the sample generated by the model real sample is
what you see in your data right can you tell the difference between the two right and the generator is going to be
trying to fool the discriminator by trying to generate samples that are hard
for discriminator to discriminate so my goal is a generator would be to generate really nice-looking digits so that the
discriminator won't be able to tell the difference between you know simulate it and the real right that's the key idea
and so here is intuitively what what
that looks like let's say you have you have some data so images of faces give
you an image your face and now I have a discriminated basically Tazewell if I get a real face I push it through some
function some differentiable function think of it as a convolutional neural network or another differentiable function and here I'm outputting one
right so I want to output one if it's a real sample right then you have a generator right and generator is you
have some noise so input noise think of it as a Gaussian distribution thinking about Helmholtz machines given some
noise I go through differentiable function which is your generator and January's sample this is my design my
sample might look like right and then on top of it I take this sample I put it
into my discriminator and I say for my discriminator I want to output 0 right
because my discriminator will have to say well this is fake and this is real
right that's the goal and the generator basically says well how can I get a sample such that my discriminate is
going to be confused such that the discriminator always outputs 1 here right because it believes it's a true
sample believe is it coming from the truth data right so now you have these
systems so what's what's the objective the objective is a min Max value
function it's a very intuitive objective function that has the following
structure you have a discriminator that says well this is an expectation with respect to distribution data
distribution so this is basically saying I want to classify any data points that I get from my data as being real right
so I want this output to be 1 because if it's 1 the whole thing is going to be 0
if it's less than 1 it's going to be negative and I really want to maximize it and then discriminator says well any
time I generate a sample whatever samples comes out from my generator you
know I want to classify it as being fake right that's the goal of the discriminator and then there is a
generator the generator is sort of the other you know you try to minimize this function which essentially says well
generate samples that discriminate it would classify as real so I really want to try to imagine you know change the
parameters of my generator such that this would produce 0 right so also so
the discriminant would produce 1 right so trying to full full the discriminator
right and it turns out the optimal strategy for discriminate is this this ratio which is probability of the data
divided probability of the data by plus probability of the model and in general if you succeed in building a good
generative model then probability of the data would be the same as probability of the models so discriminator will always be confused still 1/2
right and here's one particular it seems like a simple idea but it turns out that work remarkably well here's an
architecture called D convolutional generative adversarial network architecture that takes the code this is
a random code it's a Gaussian code it passes through a sequence of convolutions also a sequence of
deconvolution so given the code you sort of deconvolve it back to high dimensional image and you train it using
at the settle setting right this is your sampling you generate the image and then
there is a discriminator which is just a convolutional neural net what is trying to say is that the real is that a fake and if you train these models on
bedrooms these are called L some data sets a bunch of bedrooms this is how
samples from the model would look like which is pretty impressive in fact when I look at these samples I'm
also sort of maybe the models memorizing the data because these samples look
remarkably impressive then there was a follow-up work these are samples from
the CFR data set so here you seeing training samples and here you're seeing
samples generated from the model which is again very impressive if you look at
the structure in these samples it's quite remarkable that you can generate
you know samples that look very realistic actually this is what's done
again this was done by team team Shannon and his collaborators if you look at the
image net and you look at the training data on the image net and looking at the samples again you look live the horse
this is like there is some animal there is an airplane and so forth is like some
kind of a truck and such right so it looks you know when I look at these images and I was very impressed by the
quality of these image because Jo is very very hard to generate realistic looking images and the last thing I want
to point out this was picked up by Ian good fellow if we cherry pick some of
the examples this is what generated images look like alright so you can sort
of like see there is a little bit of interesting structure that you're seeing in these samples right and one question
still remains with these models is how can we evaluate these models properly
right is the model really learning a space of all possible images and how
images what's the coherency in those images or is the model mostly kind of like blurring things around and just
making some small changes to the data so the question that I would really want would like to answer to be you know to
get an answer to is that if I showing you a new example a new test image a new kind of a horse would the model say yes
this is this is a likely image this is this is very probable images I've seen you know similar images before or
something like that or not so that still remains an open question but again this is the class of models which steps away
from maximum likelihood estimations sort of sets it up in the game theoretic framework which is which is a really
nice set of work and in computer vision community a lot of people are shown a lot of progress and using these kinds of
models because they tend to generate much more realistic looking images so
let me just summarize to say that you know I've shown you hopefully a set of learning algorithms for deep
unsupervised models you know there's a lot of space in these models a lot of excitement in that space and just wanted
to point out that these models the deep models they improve upon current state of the art and a lot of different application domains and as I mentioned
before there's been a lot of progress in discriminative models convolutional models using recurrent neural networks
for solving you know action recognition models dealing with videos and unsupervised learning it still remains
sort of a field where we've made some progress but there's still a lot of
progress to be made and let me let me stop there so thank you
do the mics oh sorry so as a Bayesian
guy I'm pretty depressed by the fact that can can generate clearer image than the variational in total encoder so my
question is do you think there could be a energy based framework or probabilistic interpretation of why
again is so successful other than it's just a me max game I think that generally you know if you look at I sort
of go back and forth between variational - encoders because you know some of my friends at Open AI saying that they can
actually generate really nice-looking images using variational encoders I'm
looking at Peter here but you know what I think that one of the problems with
image generation today is that with variation autoencoders there is this notion of Gaussian loss function right
and what it does is it basically says well never produce you know crystal-clear images because if you're
wrong if you put at the edge in the wrong place you're going to be penalized a lot because of the l2 loss function
right what the gans are doing ganz are basically saying well I don't really
care where I put the edge as long as it looks realistic so that I can fool my classifier so what tends to happen in
practice and a lot of times if you actually look at the images generated by Ganz sometimes they have a lot of
artifacts like you know these specific things that that pop up right whereas in
variation think odors you don't see that but again the problem variational thinker is they tend to produce images that are much more diffused or you know
not as short or not as clear as what ganz is doing and there's been some work on you know trying to sharpen the images
which is using variational encoders to generate you the globally coherent scene and then you're using generative slls to
maybe sharpen it again it's it's it depends what loss function you're using
and again seem to be able to deal with that problem implicitly right because they don't really care whether
you get the edge quite right or not as long as its Falls your classifier thank
you hi thank you very much for the interesting talk I have a question about
the evaporation auto-encoder for the Marshall engine data set like the Street
View house number I noticed that many implementation they use a PCA to
pre-process the data before the trainer model why is your thought on that pea processing step why is necessary to do
that right why don't we just learn from the raw pixel I actually don't know my
experience has been that we don't really do a lot of pre-processing I mean what you can do is you can do CCA pre-processing is you can take the mean
you can take the sort of the second-order covariance structure from the data that sometimes helps sometimes
it doesn't but I don't see any particular reason why you'd want to do PCA Prasad pre-processing right I mean it's just one of just like you know
we've seen a lot in our field people just doing X Y and then later on they figure out that they don't really need x
and y right so it's maybe it was working better for their implementation for
their particular task but generally I haven't seen people doing a lot of pre-processing using PCA for training
you know variational - encoders
any more question yes there's one where
is regarding binary rbms so if you look at the literature for let us say
estimation of the partition function for easing models right you will see that the literature is lot more rich compared
to the variational inference literature for restricted Boltzmann machines especially in the binary context is
there like a cultural reason for this because specifically you know like you have for the strictly ferromagnetic case
you have a fully polynomial time approximation scheme for estimating the
log partition function right so but then I don't see usage of these F press kind
of algorithms in the RBM space so when you kind of juxtapose with the literature for the easing models
compared to binary rpms you'll find like a very stark asymmetry is there like a reason for this yeah so they think the
thing about easing models is that you know here like in ferromagnetic case or if you are you know you have certain
particular structure to the easing models you can use a lot of techniques like even if use techniques like coupling from the paths you can draw
exact samples from the models right you can compute the log partition function the polynomial convey a specific structure they think about rbms is that
generally those assumptions don't apply like you cannot learn them all which is this ferromagnetic model with RBA it's
just way all your weights are positive right that's a lot of constraints to put on on these class of models so that's
why you know and once you get outside of these assumptions then the problem
becomes np-hard right for estimating the partition function and obviously for learning these systems you need the
gradient of the log of the partition function right and that's where all the problems come in I don't think there is there is a solution for that and
unfortunately variational methods are also not working as well as you know
approximations like contrastive divergence or something based on based on sampling people have looked at better
approximations and using sort of more sophisticated techniques but it's it hasn't it hasn't really popped up yet
practically it just doesn't work as well but it's a good question no my question
is about using auto coder with a to get
semantic hash especially in text do we need to any
special representation text text representation like word to vector as
input for the for our text sequence so you know I've talked about them all
which is very simple knowledge is modeling bag of words yes right obviously you can take word to Veck and initialize the model right because it's
a way of just taking your words and projecting them into the semantic space yeah right there is been a lot of
technique recent techniques using like richard was mentioning gr use as a way you know if you want if you want to work
with sentences or if you want to embed the entire document into the semantic space if you want to make it binary you
know you can use gr use bi-directional gr use sort of get the representation of the document I think that would probably
work better than using word to back and then just adding things up and then based on that you can learn a hashing function that map's that particular
representation to the binary space right in which case you can you can do searching fairly efficiently so as an
input representation a lots of choices you can use bi-directional gr use which is the you know the the the the method
of choice right now you can use glove or you can use work the rack can be you
know some them sum up the representations of the words okay so using only back of word we use only
normal needs work neural network that is no records which were or yeah yeah that's right that's simple it's just right but again
you're doing your representation can be whatever that representation is as long as differentiable right okay so in this case you can you can sort of back
propagate through the bi-directional gr use and get rip you know learn what
there is what this game isn't a Shashank you so much okay let's thank Russ again

----------

-----

--11--

-----
Date: 2016.09.27
Link:  [# Deep Learning for Natural Language Processing (Richard Socher, Salesforce)](https://www.youtube.com/watch?v=oGk1v1jQITw)
Transcription:

thank you everybody thanks for coming back very soon after lunch I'll try to make it entertaining to avoid some post
food coma so I actually have a lot - OH - being here - Andrew and Chris and my
PhD at Stanford here it's it's really it's always fun to be back I figured
there's a going to be a broad range of capabilities in the room so I'm sorry I
will probably bore some of you for the first two-thirds of the talk because I'll go over the basics of what's NLP
when natural language processing what's deep learning and what's really at the intersection of the two and then the
last third I will talk a little bit about some exciting new research that's happening right now so let's get started
with what is natural language processing it's really a feel at the intersection of computer science AI and linguistics
and you could define a lot of goals and a lot of these statements here we could really talk and philosophize a lot about
but I'll move through them pretty quickly for me the goal of natural
language processing is for computers to process or scare quotes understand natural language in order to perform
tasks that are actually useful for people such as question answering the
caveat here is that really fully understanding and representing the meaning of language or even defining it
is quite an elusive goal so whenever I say the model understands I'm sorry I
shouldn't say that really these models don't understand in the sense that we understand language anything so whenever somebody says they
can read or represent the full meaning and its entire glory it's it's usually
not quite true really perfect language understanding is in some sense AI
complete in the sense that you need to understand all of visual inputs and thought and and a lot of other complex
things so a little more concretely as we try to tackle this overall problem of
understanding language what are sort of the different levels that we often look at it often and for many people starts
at speech and then once you have speech you might say alright now I know what phonemes are smaller parts of words I
understand words form Nets morphology or morphological analysis once I know what
the meaning of words are I might try to understand how they're put together in grammatical ways such that the sentences
are understandable or at least grammatically correct too a lot of speakers of the language once we go and
we understand the structure we actually want to get to the meaning and that's really where I think most of the interesting most of my interests lies
and semantic interpretation actually trying to get to the meaning in some useful capacity and then after that we
might say well if we understand now the meaning of the whole sentence what's how do we actually interact what's the discourse how do we have you
know spoken dialogue system and things like that where deep learning has really improved the state of the art
significantly is really in speech recognition and syntax and semantics and
the interesting thing is that we're kind of actually skipping some of these levels deep learning doesn't require
often morphological analysis to create very useful systems and in some cases
actually skips syntactic analysis entirely as well it doesn't have to know about the grammar it doesn't have to be
taught about what mound phrases are prepositional phrases it can actually get straight to some semantically useful
tasks right away and that's going to be one of the sort of advantages that we
don't have to actually be as inspired by linguistics as traditional natural language processing had to be so why is
NLP hard well there's a lot of complexity in representing and learning
and especially using linguistics situational world and visual knowledge really all of these are connected when
it gets to the meaning of language to really understand what red means can you do that without visual understanding for
instance if you have for instance this sentence here Jane hit June and then she
fell or and then she ran depending on which verb comes after she the
definition the meaning of she actually changes and this is one subtask you might look at so called an F or a
resolution or cor efference resolution in general where you try to understand who does she actually refer to and it
really depends on the meaning again somewhat scare quotes here of the verb that follows this pronoun
similarly there's a lot of ambiguity so here we have a very simple sentence for words
I made her duck now that simple sentence can actually have at least four
different meanings if you can think about it for a little bit right you made her a duck that she loves for Christmas
as for dinner you made her dock like me just now and so on there are actually four different
meanings and to know which one requires in some sense situational awareness or
knowledge to really disambiguate what what is meant here so that's sort of the
high level of NLP now where does it actually become useful in terms of applications well they actually range
from very simple things that we kind of assume or you're given now we use them all the time every day to more and more
complex and then also more in the realm of research the simple ones are things like spell checking or key word search
and finding synonyms and ophisaurus then the meaty medium sort of difficulty ones
are the extract information from websites trying to extract sort of product prices or dates and locations
people or company names are called named entity recognition you can go a little bit above that and try to classify sort
of reading levels for school text for instance or do sentiment analysis that can be helpful if you have a lot of
customer emails that come in and you want to prioritize highly the ones of customers for really really review right
now and then the really hard ones and I think in some sense the most interesting ones are machine translation trying to
actually be able to translate between all the different languages in the world question answering clearly something
that is a very exciting and useful piece of technology especially over very large
complex domains can be used to automated for automated email replies I know pretty much everybody here would love to
have some simple automated email reply system and then spoken dialogue systems
bots are very hip right now these are all sort of complex things that are still in the realm of research to do
them really well we're making huge progress with deep learning on these three but there's still nowhere near human
accuracy so let's look at the
representations I mention you know we have morphology and words and syntax and
semantics and so on we can look at one example a namely machine translation and
look at how did people try to solve this problem of machine translation well it
turns out they actually tried all these different levels with varying degrees of success you can try to have a direct
translation of words to other words the problem is that is often a very tricky mapping one the meaning of one word in
English might have three different words in German and vice versa you can have three of the same words in
English meaning all this single same word in German for instance so then people said well let's try to maybe do
some tactic transfer where we have whole phrases like to kick the bucket just means stab them in German okay not a fun
example and then semantic transfer might be well let's try to find a logical representation of the whole sentence the
actual meaning in some human understandable form and and try to just find another surface representation of
that now of course that will also get rid of a lot of the subtleties of language and so they're tricky problems
in all these kinds of representations now the question is what does deep learning do you've already saw at least
two methods standard neural networks before and convolutional neural networks
for vision and in some sense there's going to be a huge similarity here to
these methods because just like images that are essentially a long list of
numbers the vector and standard neural networks where the hidden state is also
just a vector or a list of numbers that is also going to be the main representation that we will use
throughout for characters for words for short phrases for sentences and in some
cases for entire documents they will all be vectors and with that we are sort of
finishing up the whirlwind of what's NLP of course you could give an entire lecture on all like almost every single
slide I just gave we're very a very high level but we'll continue at that speed to try to squeeze
this complex deep learning for NLP subject area into an hour and a half I think there are two most two of the most
important basic Lego blocks that you nowadays want to know in order to be able to sort of creatively play around
with more complex models and those are going to be word vectors and sequence
models namely recurrent neural networks and I kind of split this into words
sentences and multiple sentences but really you could use recurrent neural networks for shorter phrases as well as
multiple sentences but in many cases we'll see that they have some limitations as you move to longer and
longer sequences and just use the default neural network sequence models
alright so let's start with words and maybe one last blast from the past here
to represent the meaning of words we actually used to use a taxonomy like
word net that kind of defines each word in relationship to lots of other ones so
you can for instance define hyper names and is a relationships you might say the word Panda for instance in its first
meaning as a noun basically goes through this complex tags directed acyclic graph
most of it is roughly just a tree and in the end like everything it is an entity but it's actually a physical entity a
type of object it's a whole object it's a living thing it's an organism animal and so on so you basically can define a
word like this and another way at each node of this tree you actually have so called sunset so synonym sets here's an
example for the synonym set of the word good good can have a lot of different
meanings can actually be both an adjective and as well as an adverb as
well as a noun now what are the problems with this kind of discrete representation well they can be great as
a resource of your human you want to find synonyms but they're ever they're never going to be quite sufficient to
capture all the nuances that we have in language so for instance the synonyms
here for good were adapt Axford practice proficient and skillful but of course
you would use these words in slightly different contexts you would not use the
word expert in exactly this all the same context as you would use the meaning of good or the word good likewise it will
be missing a lot of new words language is this interesting living organism we change it all the time you might have
some kids they say Yolo and all of a sudden you know you need to update your dictionary likewise maybe in Silicon
Valley you might see ninja a lot and now you need to update your dictionary again and that is basically going to be a
Sisyphus job right nobody will ever be able to really capture all the meanings and and this living breathing organism
that languages so it's also very subjective some people might think ninja
should just be deleted from the dictionary and I don't want to include it I'll just think nifty or badass is
kind of a silly word and should not be included in a proper dictionary but it's being used in real language and so on it
requires human labor as soon as you change your domain you have to ask people to update it and it's also hard
to compute accurate word similarities some of these words are subtly different and it's really a continuum in which we
can measure their similarities so instead what we're going to use and what
is also the first step for deep learning will actually realize it's not quite deep learning in many cases but it is
sort of the first step to use deep learning and NLP is we will use distributional similarities so what does
that mean basically the idea is that we'll use the neighbors of a word to represent that word itself it's a pretty
old concept and here's an example for instance for the word banking we might actually represent banking in terms of
all these other words that are around it so let's do a very simple example where
we look at a window around each word and so here the window length that's just
for simplicity say it's one we represent each word only with the words one to left and one to the right of it we'll
just use the symmetric context around each word and here's a simple example
corpus so if the three sentences in my corpus of course we would always want to use
corpora with billions of words instead of just a couple but just to give you an idea of what's being captured in these
word vectors is I like people earning I like NLP and I enjoy flying and now this
is it's very simple so-called corcoran statistic you'll just simply see here I
for instance appears twice in its window size of one here the word like isn't its
window and its context and the word enjoy is once in its context and for
like you have twice to its left I and once deep and once NLP it turns out if
you just take those vectors now this could be a vector of presentation just each row could be a vector
representation for words unfortunately as soon as your vocabulary increases that vector dimensionality would change
and hence you have to retrain your whole model it's also very sparse and really
it's going to be somewhat noisy if you use that vector now another better thing
to do might be to run SVD or something simple like say dimensionality reduction on such a co-occurrence matrix and that
actually gives you a reasonable first approximation to word vectors very old method works reasonably well now what
works even better than simple PCA is actually a model introduced by Thomas McAuliffe in 2013 called word Tyvek so
instead of capturing Corcoran's counts directly out of a matrix like that you'll actually go through each window
in a large corpus and try to predict a word that's in the center of each window
and use that to predict the words around it that way you can very quickly train
you can train almost on line though few people do this and and add words to
vocabulary very quickly in this zooming fashion so now let's look a little bit
at this model where Tyvek because it's first very simple NLP model and to sort
of is very instructive we won't go into too many details but at least look at a couple of equations so again
main goal is to breeding words in a window of some length that we define em type or
parameter of every word now the objective function will essentially try to maximize here the log probability of
any of these contacts words given the Center word so we go through our entire corpus T very long sequence and at each
time step J we will basically look at all the words in the context of the
current word T and basically try to maximize here this probability of trying
to be able to predict that word that is around the current word T and theta are
all the parameters namely all the word vectors that we'd want to optimize so now how do we actually define this
probability P here the simplest way to do this and this is not the actual way
but it's the simplest and first to understand and derive this model is with
this very simple inner product here and that's why we can't quite call a deep there's not going to be many layers of
nonlinearities like we see in deep neural networks to be just a simple inner product and the higher debt in a
product is the more likely these two will be predicting one another so here
see the context is the dissenter word sorry oh is the outside word and
basically this inner product the larger it is the more likely we were going to predict this and these are both just
standard and dimensional vectors and now in order to get a real probability we'll
essentially apply softmax to all the potential inner products that you might have in your vocabulary and one thing
you will notice here is well this denominator is actually going to be a
very large sum I will want to sum here overall potential inner products for every single window that would be true
slow so now the real methods that we would use we're going to are going to
approximate the sum in a variety of clever ways now I could literally talk
to next hour and a half just about how to optimize the details of this equation but then we'll all deplete our mental
energy for the rest of the day and so I'm just going to point you to the class I taught earlier this year so yes 24d we
we have lots of different slides that go into all the details of this equation how to approximate it and then how to
optimize it it's going to be very similar to the way we optimize any other neural network we're going to use
stochastic gradient descent we're going to look at mini batches of a couple of hundred windows at a time and an update
those word vectors and we're just going to take simple gradients of each of these vectors as we go through windows
in a large corpus all right now we briefly mentioned PCA like methods and
based on senior Lu decomposition often or standard a simple PCA now we also had
this word Tyvek model there's actually one model that combines the best of both
worlds namely glove or global vectors introduced by Geoffrey Pennington in 2014 and it has a very similar idea and
you'll notice here there's some similarity you have this inner product again for different pairs but this model
will actually go over the Corcoran's matrix once you have this Corcoran's matrix it's much more efficient to try
to predict once how often two words appear next to each other rather than do it 50 times each time that that pair
appears in an actual corpus so in some sense you can be more efficiently going through all the current statistics and
you're going to basically try to minimize the this this subtraction here
and what that basically means is that each inner product will try to approximate the log probability of these
two words actually co-occurring now you have this function here which
essentially will allow us to not overly weight certain pairs that occur very
very frequently the for instance co-occurs with lots of different words and you want to basically lower the
importance of all the words that Corker with that so you can train this very
fast it scales to gigantic corpora in fact we train this on common crawl which
is a really great data set of most of the internet it's many billions of tokens and it gets also very good
performance on small corpora because it makes use very efficiently of these Corcoran
statistics and that's essentially what words well word vectors are always capturing so if in one sentence you just
want to remember every time you hear word vectors in deep learning one they're not quite deep even though we
call them sort of step one of deep learning and to it they're really just capturing Corcoran's counts how often
does a word appear in the context of other words so let's look at the some
interesting results of these glove vectors here the first thing we do is look at nearest neighbors so now that we
have these n dimensional vectors usually you say n between 50 to at most 500 good
general numbers 100 or 200 dimensional each of these each word is now represented as a single vector and so we
can look in this vector space for words that appear close by we started and
looked for the nearest neighbors of frog and well turned out
these are the nearest neighbors which was a little confusing since we're not biologists but fortunately when you
actually look up in Google what what those mean you'll see that they are actually all indeed different kinds of
frogs some appear very rarely in the corpus and others like toad or much more
frequent now one of the most exciting results that came out of word vectors
actually these word analogies so the idea here is can linearly can there be
relationships between different word vectors that simply fall out of very linear and simple addition and
subtraction so the idea here is what is meant a woman equal to king to something
else as in what is the right analogy when I try to basically fill in here the
last missing word now the way we're going to do this is very very simple cosine similarity or basically just take
let's take an example here the vector of woman we subtract the word vector we
learned of man and we add the word vector of king and the resulting vector I the art max for this
turns out to going to be Queen for a lot of these different models and that was
very surprising again we're capturing core current statistics so man might in
its context often have things like running and fighting other silly things
that men do and then you subtract those kinds of words from the context and you
add them again and in some sense it's intuitive though surprising that it works out that well for so many
different examples so here are some some other examples similar to the king and
queen example where we basically took these two hundred dimensional vectors and we projected them down to two
dimensions again with a very simple method like PCA and what we find is
actually quite interestingly even in just the two first principal components of this space we have some very
interesting sort of female male relationships so men to women is similar
to uncle and aunt brother and sister sir and madam and so on so this is an
interesting semantic relationship that falls out of essentially Corcoran's
counts in specific windows around each word and a large corpus here's another
one that's more of a syntactic relationship we actually have here superlatives like slow slower slowest is
in a similar vector relationship to short shorter and shortest or strong
stronger and strongest so this was very exciting and of course when you see an
interesting qualitative result you want to try to quantify who can do better in
trying to understand these analogies and what are the different modes and hyper parameters that modify the performance
now this is something that you will notice in pretty much every deep learning project ever which is more data
will give you better performance it's probably the single most useful thing you can do to machine learning or deep
learning system is to train it with more data and we found that too now they're different vector sizes too which is a
common hyper parameter like I said usually between 52 and so I wondered here we have 300
dimensional that essentially gave us the best performance for these different
kinds of semantics and tactic relationships now in many ways having a
single vector for words can be oversimplifying right some words have multiple meanings maybe they should have
multiple vectors sometimes the word meaning changes overtime and so on so
there's a lot of simplifying assumptions here but again our final goal for deep NLP is going to be to create useful
systems and it turns out this is a useful first step to create such systems
that mimic some human language behavior in order to create useful applications
for us all right but words word vectors are very useful but words of course never appear in isolation and what we
really want to do is understand words in their context and so this leads us to the second section here on recurrent
neural networks so we already went over the basic definition of standard neural
networks really the main difference between a standard neural network and a recurrent neural network which I'll
abbreviate as RN and now is that we will tie the weights at each time step and that will allow us to essentially
condition the neural network on all the previous words in theory and practice how we can optimize it it won't be
really all the previous words we've more like at most the last 30 words but in
theory this is what a powerful model can do so let's look at the definition of a
recurrent neural network and this is going to be a very important definition so we'll go into a little bit of details here so let's assume for now we have our
word vectors as given and we'll represent each sequence in the beginning it's just a list of these word vectors
now what we're going to do is we're computing a hidden state HT at each time
step and the way we're going to do this is with a simple neural network architecture in fact you can think of
this summation here is really just a single layer neural network if you were
to concatenate the two matrices in these two that but intuitively we basically will map
our current word vector at that time step T sometimes I use these square
brackets to denote that we're taking the word vector from that time step in there
we map that with a linear layer a simple matrix vector product and we sum up some
that matrix vector product to another matrix vector product of the previous hidden state at the previous time step
we sum those two and reapply in one case a simple sigmoid function to define this
standard neural network layer that will be HT and now at each time step we want
to predict some kind of class probability over a set of potential
events classes words and so on and we use the standard softmax classifier some other communities called logistic
regression classifier so here we have a
simple matrix WS for the softmax weights
we have basically a number of rows are going to be a number of classes that we have and the number of columns is the
same as the hidden dimension sometimes
we want to predict the next word in a sequence in order to be able to identify
the most likely sequence so for instance if I asked for a speech recognition system what is the price of wood now in
isolation if you hear wood you would probably assume it's the wo uld
auxiliary verb wood but in this particular context the price of it wouldn't make sense to have a verb
following that and so it's more like the wo D to find the price of wood so
language modeling is very useful task and it's also very instructive to use as an example for where recurrent neural
networks refine so in our case here this softmax is going to be quite a large
matrix that goes over the entire vocabulary of all the possible words that we have so each word is going to be
our class the classes for language models are the words in our vocabulary and so we can define here
this y hat T the jf1 is basically denoting here the probability that the J
word at the J index will come next after all the previous words very useful model
again for speech recognition for machine translation for just finding a prior for
language in general alright again main difference the standard
neural networks we just have the same set of W weights at all the different time steps everything else is pretty
much a standard neural network we often initialize the first h0 here just either
randomly or all zeroes and again in language modeling in particular the next
word is our class of the softmax now we can measure basically the performance of
language models with terms are called perplexity which really is here the
average log likelihood of the basically the probabilities of being able to
predict the next word so you want to really give the highest probability to the word that actually will appear next
in a long sequence and then the higher that probability is the lower your
perplexity in hence the models less perplexed to see the next word in some sense you can think of language modeling
as almost NLP complete and some silly sense that you just if you can actually
predict every single word that follows after any arbitrary sequence of words in a perfect way you would have
disambiguated a lot of things you can you can say for instance what is the answer to the following question ask the
question and then the next couple of words would be the predicted answer so there's no way we can actually ever do
perfect job in language modeling but there's certain contexts where we can give a very high probability to the
right next couple of words now this is the standard recurrent neural network
and one problem with this is that we will modify the hidden state here at every time set so even if I have words
like the and a and sentence period and things like that it will stick
frequently modify in my hidden state now that can be problematic let's say for
instance I want to train a sentiment analysis algorithm and I talk about
movies and I talk about the plot for a very long time then I say oh man this movie was really wonderful it's great to
watch and then especially the ending and you talk again for like fifty timesteps or 50 words or hundred words about the
plot now all these plot words will essentially modify my hidden states if at the end of that whole sequence I want
to classify the sentiment the word wonderful and great that I mentioned somewhere in the middle might be completely gone because I keep updating
my hidden state with all these content words to talk about the plot now the way
to improve this is by use better kinds of recurrent units and I'll introduce
here a particular kind so called gated recurrent units introduced by Cho in
some sense and we'll learn more about the LS TM tomorrow when Kwok gives his
lecture but G R user in some sense a special case of LS DMS and the main idea
is that we want to have the ability to keep certain memories around without having the current input modify modify
them at all so again this example of sentiment analysis I say something's great that should somehow be captured in
my hidden state and I don't want all the content words to talk about the plot in a movie review to modify that is
actually overall I was a great movie and then we also want to allow error messages to flow at different strengths
depending on the input so if I say great I want that to modify a lot of things in
the past so let's define a giryu fortunately since you already know the
basic Lego block of a standard neural network there's only really one or two subtleties here that are different there
are a couple of different steps that we'll need to compute at every time step so in the standard RNN
what we did was just have this one single neural network that we hope would capture all this complexity of the
sequence instead now we'll first compute a couple of gates at that time step so
the first thing will compute is the so called update gate it's just yet another neural network
layer based on the current input word vector and again the past hidden state so these look quite familiar but this
will just be an intermediate value and we'll call it the update gate then we'll also compute a reset gate is yet another
standard neural network layer again just matrix vector product summation matrix vector product some kind of
non-linearity here namely Sigma it's actually important in this case that it is a sigmoid just just basically both of
these will be vectors with numbers that are between 0 and 1 now we'll compute a
new memory content an intermediate age tilt here with yet another neural
network but then we have this little funky symbol in here basically this will
be an element-wise multiplication so basically what this will allow us to do
is if that reset gate is 0 we can essentially ignore all the previous
memory elements and only store the new word information so for instance if I
talked for a long time about the plot now I say this was an awesome movie now
you want to basically be able to ignore if your whole goal of this sequence classification model is to capture
sentiment I'm going to be able to ignore past content this is of course if this
was a 0 entirely a 0 vector now this will be more subtle this is a long vector if you know maybe a hundred or
200 dimensions so maybe some dimensions should be reset but others maybe not and then here we'll have our finally
final memory and that essentially combines these two states the previous
hidden state and this intermediate one at our current time step and what this will allow us to do is essentially also
say well maybe we want to ignore everything that's currently happening and only update the last time step we
basically copy over the previous time step in the hidden state of that and ignore the current thing again simple
example in sentiment maybe there's a lot of talk about the plot when a movie was released if you want to basically have
the ability to ignore that and just copy that in the beginning may have said it was an awesome movie so
here's an attempt at a clean illustration I have to say personally I in the end find the equations a little
more intuitive than the visualizations that we try to do but some people are are more visual here so this is in some
ways basically here we have our word vector and it goes through different layers and then some of these layers
will essentially modify other outputs of previous time steps so this is a pretty
nifty model and it's read the second most important basic Lego block that
we're going to learn about today and so just want to make sure we take a little
bit of time I'll repeat this here again if the reset gate this R value is close
to zero those kinds of hidden dimensions are basically allowed to be dropped and
if the update gates Z basically is one then we can copy information in of that
unit through many many different time steps and if you think about optimization a lot what this will also
mean is that the gradient can flow through the recurrent wheel network through multiple time steps until it
actually matters and you want to update a specific word for instance and go all the way through many different time
steps so then what this also allows us is to
actually have some units that have different update frequencies some you
might want to reset every other word other ones you might really cap like they have some long-term context and
they stay around for much longer all right this is the geo you it's the
second most important building block for today there are like I said a lot of other variants of recurrent neural
networks lots of amazing work in that space right now and tomorrow quoc will
we'll talk a lot about some more advanced methods so now that you've
understand word vectors and neural network sequence models you really have
the two most important concepts for deep NLP and that's pretty awesome so congrats we
can now in some ways really play around with those two Lego blocks plus some slight modifications of them very
creatively and build a lot of really cool models a lot of the models that I'll show you and that you can read and
see and read the latest papers that are now coming out almost every week on archive will have some kind of component
of these will use really these two components in a major way now this is
one of the few slides now with something really new because I want to keep it
exciting for the people who already knew all this stuff and took the class and everything this is tackling a important problem
which is and all these models that you'll see in pretty much most of these
papers we have in the end one final softmax here right and that softmax is
basically our default way of classifying what we can see next what kinds of classes we can predict the problem with
that is of course that that will only ever predict accurately frequently seen classes that we had at training time but
in the case of language modeling for instance where our classes are the words we may see a test time some completely
new words maybe I'm just going to introduce to you a new name srini for
instance and nobody may have like seen that word at training time but now that
I mentioned him and I will introduce him to you you should be able to predict the word trini and that person in a new
context and so the solution that we're literally going to release only next week and in a new paper is to essentially
combine the standard softmax that we can train with a pointer component and that pointer component will allow us to point
to previous contexts and then predict based on that to see that word so let's
for instance take the example you have language modeling again we may read a long article about the Fed chair Janet
Yellen and maybe the word Yellen had not appeared in training time before so we
couldn't ever predict it even though we just learned about it and now a couple of sentences later interest rates were
based and then missus and now we want to predict that next word now if that
hadn't appeared in our softmax standard training procedure at training time we would never be able to predict it what
this model will do and we're kind of calling it a pointer sentinel mixture model is it will essentially first try
to see what any of these previous words maybe be the right candidate so we can
really take into consideration the previous context of say the last hundred words and if we see that word and that
word makes sense after you know we train it of course then we might give a lot of probability mass to just that word at
this current position in our previous immediate context at test time and then
we have also the sentinel which is basically going to be the rest of the probability if we cannot refer to the
some of the words that we just saw and that one will go directly to our
standard softmax and then what we'll essentially have is a mixture model that allows us to say either we have or we
have a combination of both of essentially words that just appeared in this context and words that we saw in
our standard softmax language modeling system so I think this is a pretty
important next step because it will allow us to predict things we've never seen a training time and that's
something that's clearly a human capability that most or pretty much none of these language models had before and
so to look at how much it actually helps it'll be interesting to look at some of
the performance before so again what we're measuring here is perplexity and the lower the better because it's
essentially inverse here of the actual probability that we assigned to the
correct next word and in just 2010 so six years ago there this was some great
work early work by Thomas McAuliffe where he compared to a lot of standard
natural language processing methods syntactic neural net syntactic models
that essentially tried to predict the next word and had a perplexity of 107 and he was able to use the standard
recurrent neural networks and actually an ensemble of eight of them to really significantly push down the
perplexity especially when you combine it with standard count based methods for
language modeling so in 2010 he made great progress by pushing it down to 87
and now this is one of the great examples of how much progress is being
made in the field thanks to deep learning we're two years ago white
chicks are memba and and his collaborators were able to push that down even further to 78 with a very
large lsdm similar to a GRU like model but even more advanced quark will will
teach you the basics of LS CMS tomorrow then last year we pushed the the
performance was pushed down even further by yarn gull and then this one actually
came out just a couple of weeks ago variational recurrent highway networks pushed it down even further but this
pointer sentiment model is able to get it down to 70 so in just a short amount of time we pushed it down by more than
10 perplexity points and in two years and that is really an increased speed in
performance that we're seeing now that deep learning so if changing a lot of areas of natural language processing
alright now we have sort of our basic Lego blocks the word vectors and the GRU
sequence models and now we can talk a little bit about some of the ongoing
research that we're working on and I'll start that with maybe a controversial
question which is could we possibly reduce all NLP tasks to essentially
question answering tasks over some kind of input and in some ways that's a trivial observation that you could do
that but it actually might help us to think of models that could take any kind
of input a question about that input and try to produce an output sequence so let
me give you a couple of examples of what I mean by this so here we have the first
one is a task that we would standardly associate with answering I'll give you a couple of
facts Mary walk to the bathroom send her went to the garden Daniel went back to the garden Sandra took the milk
there where's the milk and now you might have to logically reason so I try to
find the sentence about milk maybe Sandra took the milk there and I
would have to maybe do an F for a resolution find out what does there refer to and then you try to find you
know the previous sentence that mentioned Sandra see that it's garden and then give an answer garden so this
is a simple logical reasoning question answering task and that's what most people in the QA field sort of
associated with some kinds of question answers but we can also say everybody's
happy and the question is what's the sentiment and the answer is positive all right so this is a different subfield of
NLP that tackles sentiment analysis we can go further and ask what are the
named entities of a sentence like Jane has a baby in Dresden and you want to find out that Jane is a person in
Dresden as a location this is an example of sequence tagging you can even go as
far and say you know I think the smile is incredible and the question is what's the translation into French and you get
you know Japan's kusuma del a on clay habla and dad in some ways would be
phenomenal if we're able to actually tackle all these different kinds of
tasks with the same kind of model so maybe it would be an interesting new
goal for NLP to try to develop a single joint model for general question
answering I think it would push us to think about new kinds of sequence models
and new kinds of reasoning capabilities in an interesting way now there are two major obstacles to actually achieving
the single joint model for arbitrary QA tests the first one is that we don't
even have a single model architecture that gets consistent state-of-the-art results across a variety of different
tasks so for instance for question answering and this is a data set called Bobby did face book published
last year strongly supervised memory networks get the state of the art for sentiment analysis you had tree lsdm
models developed by cashing ty here at Stanford last year and for part of
speech tagging you might have bi-directional lsdm conditional random fields one thing you do notice is all
the current state-of-the-art methods are deep learning sometimes they still connect to other traditional methods
like conditional random fields and undirected graphical models but there's always some some kind of deep learning
component in them so that is the first obstacle the second one is that really
fully joint multitask learning is very very hard usually when we do do it we
restrict it to lower layers so for instance in natural language processing all we're currently able to share in
some principled way our word vectors we take the same word vectors we trained for instance with glove or work avec and
we initialize our deep neural network sequence models with those word vectors
in computer vision and we're actually a little further ahead and you're able to
use multiple of the different layers and you initialize a lot of your CNN models
with first pre trained CNN that was pre trained on imagenet for instance now usually people evaluate
multitask learning with only two tasks they trained on for a first task and then they evaluate the model that they
initialize from the first on the second task but they often ignore how much the performance degrades on the original
task so when somebody takes an image net CNN and applies it to a new problem they rarely ever go back and say how much did
my accuracy actually decrease on the original data set and furthermore we
usually only look at tasks that are actually related and then we find out look there's some amazing transfer learning capability going on what we
don't look a look at often in the literature and in most people's work is that when the tasks aren't related to
one another they actually hurt each other and this is a so called catastrophic forgetting it's not there's
not too much work that right now now I also would like to
say that right now almost nobody uses the exact same decoder or classifier for
a variety of different kinds of outputs right we at least replace the softmax to
try to predict different kinds of problems all right so this is the second
obstacle now for now we'll only tackle the first obstacle and this is basically
what motivated us to come up with dynamic memory networks they are essentially an architecture to try to
tackle arbitrary question-answering paths when I'll talk about dynamic
memory networks is important to note here that for each of the different tasks I'll talk about it'll be a different dynamic memory network it
won't have the exact same weights will just be the same general architecture so
the high-level idea for DM ends is as follows imagine you had to read a bunch
of facts like these here they're all very simple in and of themselves but if
I now ask you a question I showed you these and I asked where Sandra you know
it'd be very hard even if you read them all of them and be kind of hard to remember and so the idea here is that
for complex questions we might actually want to allow you to have multiple glances at just at the input and just
like I promised our one of our most important basic Lego blocks will be this GRU we just introduced in the previous
section now here's this whole model in all its gory details and we'll dive into
all of that in the next couple of slides so don't worry it's it's a big model a
couple of observations so the first one is I think we're moving in deep learning now to try to use more proper software
engineering principles basically to modularize encapsulate certain
capabilities and then take those as basic Lego blocks and build more complex models on top of them a lot of times
nowadays you just have a CNN that's like one little block in a complex paper and then other things happen on top here
we'll have the gru or word vectors basically has you know one module a sub module in these
different ones here and I'm not even mentioning word vectors anymore but word vectors still play a crucial role and
each of these words is essentially represented as this word vector but we just kind of assume that it's there
okay so let's walk on a very high level through this model they're essentially four different modules there's the input
module which will be a neural network sequence model and giryu and there's a
question module an episodic memory module and an answering module and sometimes we also have these semantic
memory modules here but for now these are Ray just our word vectors and we'll ignore that for now so let's go through
this here is our corpus and our question is where is the football and this is our
input that should allow us to answer this question now if I ask this question I will essentially use the final
representation of this question to learn to pay attention to the right kinds of inputs that seem relevant for given what
I know to answer this question so whereas the football well it would make sense to basically pay attention to all
the sentences that mention football and maybe especially the last ones if the football moves around a lot so what we'll observe here is that this
last sentence will get a lot of attention so John put down the football and now what we'll basically do is that
this hidden state of this recurrent neural network model will be given as
input to another recurrent neural network because it seemed relevant to answer this current question at hand now
we'll basically agglomerate all these different facts that seem relevant at the time and is now the gru in this
final vector m and now this vector M together with the question will be used to go over the inputs again if the model
deems that doesn't have enough information yet to answer the question so if I ask you where's the football and
it's so far only found that John put down the football you don't know enough you still don't know where it is but you
now have a new fact namely John seems relevant to answer the question and that fact is now represented in this vector M
which is also just the last in the state of another Network now we'll go over the inputs
again now that we know that John and the football irrelevant will be learned to pay attention to John move to the
bedroom and John went to the hallway again those are going to get
agglomerated here in this recurrent neural network and now the model seems
thinks that it actually knows enough because it basically intrinsically
captured things about the football John found a location and so on of course we
didn't have to tell it anybody anything about their people their locations if X moves to Y and y is in the set of
locations then this happens none of that you just give it a lot of stories like that and in its hidden states it will capture these kinds of
patterns so then we have the final vector M and we'll give that to an
answer module which produces in our standard softmax way the answer all
right now let's zoom into the different modules of this overall dynamic memory
network architecture the input fortunately is just a standard GRU the way we defined it before so simple word
vectors hidden states reset gates update gates and so on the question module is
also just the GRU a separate one with its own weights and the final vector q
here is just going to be the last hidden state of that recurrent neural networks you can't model now the interesting
stuff happens in the episodic memory module which is essentially a sort of
meta gated GRU where this gate will
basically define is defined computed by the attention mechanism and will
basically say this current state sentence si here seems to matter and the
superscript T is the episode that we have so each episode basically means we're going over the input entirely one
time so it starts at g1 here and what
this basically will allow us to do is to say well if G is
zero then what we'll do is basically just copy over the past states from the
input nothing will happen and unlike before in all these GRU equations this G is just a single scalar number it will
basically say if G is zero then this sentence is completely irrelevant to my
current question at hand I can completely skip it all right and there are lots of examples like mary mary traveled to the hallway
that are just completely irrelevant to answering the current question in those cases this g will be zero and we're just
copying the previous hidden state of this recurrent neural network over otherwise we'll have a standard giryu
model so now of course the big question is how do we compute this G and this
might look a little ugly but it's quite simple basically we're going to compute two vector similarities multiplicative
an edit of one with absolute values of all the single values of the sentence
vector that we currently have and the question vector and the first the memory state of the previous pass of the input
and the first pass over the input the memory state is initialized to be just a
question and then afterwards at agglomerated relevant facts so intuitively here if the sentence
mentions John for instance and the question is or mentions football and the question is where is the football
then you'd hope that the question vector Q mentions has some units that are more active because football was mentioned
and the sentence vector mentions football so there's some units that are more active because football is mentioned and hence some of these inner
products or absolute values of subtractions are going to be large and then what we're going to do is just plug
that into a standard through standard single layer neural network and in a standard linear layer here and then we
apply a soft max to essentially weight all of these different potential sentences that we might have to compute
the final gate so this will basically a soft attention mechanism that sums to one and we'll pay most attention to the
facts that seem most relevant given what I no so far and the question then when the
end of the input has reached all these relevant facts here are summarized in another GRU that basically moves up here
and you can train a classifier also if you have the right kind of supervision
to basically train that the model knows enough to actually answer the question and stop iterating over the inputs if
you don't have that kind of supervision you can also just say I will go over the inputs a fixed number of times and that
that works reasonably well to all right there's a lot to sink in so I'll give
you a couple seconds basically we pay attention to different facts given a
certain question we iterate over the input multiple times and we agglomerate
the facts that seem relevant given the current knowledge and the question now I
don't usually talk about neuroscience I'm not a neuroscientist but there is a very interesting relationship here that
a friend of mine Sam Gershman pointed out which is that the episodic memory in general for humans is actually the
memory of autobiographical events so it's the time when we remember the first time I went to school or something like
that and essentially a collection of our past personal experiences that occurred at a particular time in a particular
place and just like our episodic memory that can be triggered with a variety of
different inputs this is also this episodic memory is also triggered with a
specific question at hand and what's also interesting is the hippocampus which is a seat of the episodic memory
in humans is actually active during transitive inference so transitive inference is you know going from A to B
to C to have some connection from A to C or in this case here with this football
for instance you first had to find facts about John into football and then finding where John was and then find the
location of John so those are examples of transitive inference and it turns out that you also need in the dmn these
multiple passes to enable the capability to do transitive inference now the final
module again is very simple G or UN softmax to produce the final answers the main difference here is that
instead of just having the current the previous hidden state 18 minus 1 as
input will also include the question at every time and we will include the
answer that was generated at the previous time step but rather than that it's our standard softmax from your
standard cross-entropy errors to minimize it and now beautiful thing of this whole model is that it's end-to-end
trainable these four different modules will actually all train based on the
cross entropy of that final softmax all these different modules communicate with vectors and we'll just have Delta
messages and back propagation to train them now there's been a lot of work in
the last two years on models like this in fact quoc will cover a lot of these
really interesting models tomorrow different types of memory structures and so on and the dynamic memory network is
in some sense one of those models one one particular model is a proper
comparison because it's there a lot of similarities namely memory networks from
jason weston those basically also have inputs and scoring and attention
response mechanisms the main difference is that they use different kinds of
basic Lego blocks for these different kinds of mechanisms for input they use
bag of words representation z' or non-linear on linear embeddings for the
attention and responses they have different kinds of iteratively to run functions the main interesting sort of
difference to the dmn is that the dmn really use this recurrent neural network
type sequence models for all of these different modules and capabilities and in some sense that helps us to have a
broader range of applications that include things like sequence tagging and so let me go over a couple of results
and experiments of this model so the first one is on this Bobbie dataset did
Facebook publish it basically has a lot
of these kinds of simple logical reasoning type questions in fact all these like where's the
Paul those were examples from the Facebook Bobby data set and it also includes things like yes/no questions
simple counting negation some indefinite knowledge where the answer might be may
be basic coreference where you have to realize what does she
who does she refer to or he reasoning over time if this happened before that
and so on and basically this dynamic memory network I think is currently the
state of the art on this data set of the simple simple logical reasoning now the
problem with this data set is that it's a synthetic data set and so it had only
a certain set of generating like human general human defined generative
functions that created certain patterns and in that sense it's only necessary
and not a sufficient condition of solving it with sometimes a hundred percent accuracy to real question
answering so there's still a lot of complexity the main interesting bit to
point out here is that there are different numbers of training examples for each of these different subtasks and
so you have basically a thousand examples of simple negation for instance and it's always a similar kind of
pattern and hence you're able to classify it very well now real language you will never have that many examples
for each type of pattern you want to learn and so it's still general question answering is still an open problem and
non-trivial now what's cool is this same architecture of allowing the model to go
over inputs multiple times also got state of the art and sentiment analysis very different kind of task and we
actually analyzed whether it's really helpful to have multiple passes over the input and it turns out it is so there's
certain things like reasoning over three facts or Counting where you really have to have this dynamic this episodic
memory module and it goes over the input maybe five times for sentiment it
actually turns out it hurts after going over the input more than two times and
that's actually one of the things we're now working on is can we find model that does the same thing for every
single input with the same weights to try to learn this different tasks we can
actually look at a couple of fun examples of this model and what happens
with tough sentiment sentences generally to be honest sentiment you can probably
get to like seventy five percent accuracy with some very simple models that just basically find like great
words like great and wonderful and awesome and you'll get to something that's roughly right here some of the
examples that those are the kinds of examples that you now need to get right to retry to push the state-of-the-art
further in sentiment analysis so here the sentences in its ragged cheap and
unassuming way the movie works so this sentence is incorrect even if you allow
the dmn but I have this whole architecture but only allow one pass over the input once you have two passes
over the input it actually learns to pay attention not just to these very strong
adjectives but in the end actually to the movie working so here these fields
are essentially the gating function G that we defined that pays attention to specific words and the darker it is the
larger that gate is and the more open it is amor that word effects the hidden
state in the episodic memory module so it goes over the input the first time
pays attention to cheap and unassuming and way and a little bit of works too
but the second time it basically figured out it agglomerate it's sort of the facts of that sentence and then learn to
pay attention more to specific words that seem more important just one more
example here my response to the film is best described as lukewarm so in general
sentiment analysis when you look at unique an scores like the word best is
basically some of the most one of the most positive words you could possibly use in a sentence and the first time the
model passes over the sentence that also pays most attention took this incredibly positive word maybe
best but then this site once it agglomerate at the context actually realizes well best actually here is not
used in its adjective way but it's actually an adverb that best describes
something and what it describes is actually lukewarm and hence it's actually a negative sentence so those
are the kinds of examples that you need to get to now to appreciate improvements in sentiment analysis where we basically
also went from on this particular data set these are all neural network type
models that started 82 until then that same data set existed for around 8 years
and none of the standard NLP models had reached above 80% accuracy and now we're
basically in the high high 80s and and those are the kinds of improvements that that you see across a variety of
different NLP tasks now that deep learning has come and deep learning
techniques are being used in NLP and now the last task in NLP that this model
turn out are also working for Ivy Wallen as part of speech tagging now part of speech tagging is less exciting of a task it's more of an intermediate task
but it's still fascinating to see that after this data set has been around for
over 20 years you can still improve the state of the art was the same kind of architecture
that also did well and fuzzy reasoning of sentiment and discrete logical reasoning for for question answering now
we had a new person joined a group Zhiming and he he thought well that's
cool but he was more of a computer vision researcher and so he thought well could
I use this create question-answering module now to do visual question-answering so combine sort of
some stat was going on in the group and NLP and apply it to a computer vision and he did not have to know all of the
different aspects of the code all he had to do was change the input module from
one that gives you hidden states at each word over a long sequence of you know
words and sentences to an input module that would give him vector years four sequences of regions in an
image and he literally did not touch some of the other parts of the code I
did have to look carefully at this input module aware again here our basic Lego
block that Andre introduced really well of our convolutional neural network and
then each the convolutional networks will essentially give us 14 by 14 many
vectors one for each and it's one of its top states one representing each region
of an image and then what we'll do is basically take those vectors and now replace the word vectors we used to have
with CNN vectors and then plug them into GRU now again the GRU we know as our
basic Lego block we already defined it one addition here is that it'll actually be a bi-directional GRU will go once
from left to right in this snake-like fashion and another one goes from right
to left backwards now both of these will basically have hidden state and you can
just concatenate the hidden states of both of these to compute the final hidden state at each for each block of
the image and that model to actually achieve state-of-the-art results this
data set has been only released last year so everybody now works on deep learning techniques to try to solve it
and I was at first a little skeptical it was just too good to be true that this
model we developed for NLP would work so well so we really dug in to looking at
the attention so what I showed you here these G values again that we computed
with this equation now instead of paying attention to words it paid attention to
different regions in the image and we started basically analyzing going
through a bunch of those on the Deaf set and analyzing what is it actually paying attention to again it's being trained
only with the image the question and the final answer that's what you get a
training time you do not get this sort of latent representation of where you
should actually pay it attention to in the image in order to answer that question correctly so when
the question was what is the main color on the bus and learned to actually pay attention here to that bus mic well okay
maybe that's not that impressive it's just the main object in the center of the image and you know what it types the
type of trees are in the background well maybe it just you know connects tree with anything that's green and pays
attention to that so I was neat but you know not not super impressive yet so is
this in the wild kind of more interesting and actually pays attention to a man-made structure in the background and correctly answer's no
then this one is kind of interesting who is on both photos the answers girl now
to be honest I don't think the model actually knows that there are two people tries to match them and so on it just
finds the main person or main object in in this in the scene the main object is
a little baby girl so it says girl this one's also relatively trivial what time
of day was this picture taken the answers night because it's very dark picture at least in the sky now this one
is getting a little more interesting what is the boy holding the answer a surfboard and it actually does pay
attention to both of the arms and then what's just below that arm so that's a little more interesting kind of
attention visualization and then for a while we're also worried well what if in
the data set it just learns really well from language alone yes it pays attention to things but maybe it'll just
say things that it often sees in the text so if I asked you what or what color are the bananas you don't really
have to look at an image in 95% of the cases you're right just saying yellow without seeing an image so it was really
this one I was kind of excited about because it actually paid attention to the bananas in the middle and then did
say green and kind of overruled the prior that it would get from from
language alone what's the pattern on the cat's fur on its tail pays attention
mostly to the tail and says stripes now this one here was interesting and fit
the player hit the ball the answer yes though I have to say that we later had a journalist want to do his own
question he he asked John marker from New York Times and we just put together
this demo and the night before and he's like well I want to ask my own question and I am like okay and he asked is the
girl wearing a hat and you know it wasn't made for production so it's kind of slow and the system was cranking it
like well you know like trying to come up with excuses it's kind of black background and the plaque hat and it
might be kind of hard to see and unfortunately I got it right and said yes and then after the interview I said
well maybe let's look and see if like what I imma just asked it myself less
stressful situation a bunch of questions on my own and these are all the questions like the first eight questions
that I could come up with and somewhat to my surprise it actually got them all right so what is the girl holding a
tennis racket what's she playing playing tennis or what's she doing I was to go wearing shorts what is the color of the
ground brown then I was like well okay let's try to break it by asking just like what's the color of like the sound
of this the smallest object the ball actually got that right to because her skirt white also kind of interesting
like when you asked him all what she's wearing shorts but in you asked about the skirt and it still sort of is you
know sort of capturing that you might call this different things what and then this one was interesting
what did the girl just hit tennis ball and then as like well what if I asked is
the girl about to hit the tennis ball and said yes and then did the girl just hit the tennis ball and it said yes
again so then I finally found a way to break it so it doesn't have enough the Corcoran statistics to understand and
again spare quote understand sort of which angles does the arm have to be in order to assume that the ball was just
adores about it but what it basically does show us is that once it saw a lot
of examples on a specific domain it really can capture quite a lot of different things now see if we can get
the demo up I have to be a VPN to make it work but so here's here's one
one example the best way to hope for any chance of enjoying this film is by lowering your expectations again one of
those kinds of sentences that you have to now get correct in order to get
improved performance on sentiment and actually correctly says that this is
this is negative now we can also actually ask that question in Chinese
this is one of the beautiful things off of the dmn and in general really of most
deep learning techniques we don't have to be experts in a domain or even in a language to create a very very accurate
model for for that language or that domain there's no more future
engineering I'm not going to make a fool of myself trying to read that one out loud but that's an interesting example
you can also this is the what parts of speech are there you can have other things like you know named entities and
other sequence problems I can also ask what are the men wearing on the head
answers helmets and then maybe a slightly more interesting question why are the men wearing helmets and the
answer is safety so especially we're close to the circle of death here at Stanford where a lot of bikes crash and
it's a good answer all right with that I'll leave a couple of minutes for for
questions so basically the summary is word vectors and recurrent neural networks are super useful building
blocks once you really appreciate and understand those two building blocks you're kind of ready to have some fun
and build more complex models really in the end this dmn is a way to combine that in just a variety of new ways to a
larger more complex model and that's also where the state I think of deep learning is for natural language
processing we've tackled a lot of these smaller sub-problems intermediate tasks and now we can work on more interesting
complex problems like dialogue and question answering machine translation and things like that all right
thank you
I mean all right cool yeah a quick
question in the dynamic memory Network you have the the RN and you also
mentioned that if you have better assumption of the input right so you
used to work on the tray LST M right so if you change they are in into a tree
structure would that help it's a good question I I actually loved researchers
at in my whole PhD about tree structures and somewhat surprising in the last
couple of weeks to actually some new results on SNL I understand for natural
language inference data said where tree structures are again the state of the art and I have to say that I think the
the dynamic memory Network by having this ability in the episodic memory to
keep track of different sub phrases and pay attention to those and then combine them over multiple passes I think you
can kind of get away with not having a tree structures so yes you might have a slight improvement representing
sentences as trees in your input module but I think they're only going to be slight and I think the episodic memory
module that has this capability to go over the input multiple times pay attention to certain sub phrases will capture a lot of the kinds of
complexities that you might want to capture in tree structures so I don't my short answer is I don't think you necessarily need it have you tried it we
have not no thanks hi a question is about question
answering say if we want to apply questions into some specific domains
that health healthcare but we don't really have the data we don't have questions appears and what sure we'll do
are there any general principles here it's a great question what do you do if
you want to question answering on a complex domain you don't have the data I think and this feels maybe like a
cop-out but I think it's very true both in practice and in theory create the data like if you cannot possibly create
more than a thousand examples of anything then maybe automating that process is not that important so clearly you
should be able to create some data and in many cases that is the best use of your time is just to sit down or ask the
domain expert to create a lot of questions and then have people find the answers and then measure how they
actually get to those answers try to have them in a constrained environment and so on I think most companies for
instance when you try to do automated email replies which is in some ways a little bit similar to question answering
well there's a nice nice nice domain because everybody had already emailed
there were already answered before so you can use sort of past behavior now if you had a search engine where people
asked a lot of questions then you can also use that too in bootstrap and see where did they actually fail and then
take all those really tough queries where they failed have some humans sit there and collect the data so that's
that's the simplest answer now the other answer is let's work together for the Mexican like many years on research for
smaller training data set sizes and complex reasoning the the fact of the
matter for that line of research will still be if you if a system has never seen a certain type of reasoning I'll be
hard for the systems to pick up that type of reasoning I think we're going to
get with these kinds of architectures to the space where at least if it has seen this type of reasoning a specific type
of transitive reasoning or temporal reasoning or sort of cause and effect type reasoning at least like a couple
hundred times then you should be able to train a system with these kinds of models to do it are these QA systems
currently robust to false input our questions for the woman playing tennis if you asked what's the man holding
would it replied there is no man it would not and largely because at
training time you never try to mess with it like that I'm pretty sure if you added a lot of training examples where
you had those it would probably eventually pick it up those would be important for like real-world implementations and so real-world
implementations of this in security are actually kind of tricky I think whenever you train a system we know we
can for instance both steal certain classifiers by using them a lot we know we can fool them into
classifying certain images for instance as others we have folks in the audience who worked on that exact line of work so
I would be careful using it in security environments right now yeah I have a
question oh wow up there yeah I have a question actually
uh there was a slide where you had the input module and and there were a bunch of sentences so what those sentences
themselves are n ends because you know sequence is basically made up of those individual words in sake love you know
representation so what those you know also when are n ends that word you know stitch together or so the answer there
is a little complex because we have two two papers with the dmn and the answer is different for each the simplest in
the simplest form of that there it is actually a single gru that goes from the first word through all the sentences as if there
are one gigantic sequence and but it has access to each sentence period at the end to pay a special attention to the
end of sentences and so yes in the simplest form it is just a giryu that
goes over all the words this is a normal process to basically just concatenate all the sentences into one gigantic you
know so the answer there and this is kind of why I split the the talk into
three different ones from like words single sentences and in multiple sentences I think if you just had a
single gru that goes over everything and now you try to reason over that entire sequence it would not work very well
your read to have an additional structure such as an intention mechanism or a pointer mechanism that has the
ability to pay attention to specific parts of your input to do that very accurately but yeah in general that's
fine as long as you have this additional mechanism thank you thank you great question so in the recurrent neural Nets
you're using sigmoids in visual recognition I guess are
rectified linear units for the more popular non-linearity that's right so rail users are great now when you look
at the GRU equations here and you have these reset gates and so these reset gates here
you want them to essentially be be between zero and one so that it can either ignore this input entirely or you
have it normally be part of the computation of H tilt so in some cases you really do want to have Sigma lights
there but other ones for instance some like simpler things where you actually
don't have that much recurrence such as going from one member state to another in the second iteration of this model
actually rail used were we're good mom good like activation functions to did
you guys try to after training this network try to take these weights for
the images and do object detection again so these weights would be augmented with
the text victors did you try to use that is a very cool idea that we did not
explore no there you go you got to do it
fast yeah feel this feel is moving fast you just let the cat out of the box so so
those attention models are pretty powerful when you have an opportunity data and then you can learn you know to
make make yourself with data but even
though those are some of the tasks are pretty gets a trivial to human but it's hard for model tuner so what do you
think of a casinos right now even right now we have not a non G base on the web right no inequity pedia we not we know a
lot about you know common sense but how what do you think about you cover those knowledge base into those models I
actually love that line of research too and that was kind of what we start out with this semantic memory module in the
simplest form is just word vectors I think in one next iteration would activity to have knowledge bases also
influence the reasoning there's very little work on combining text and
knowledge bases to do overall complex question answering that requires reasoning thing is a phenomenally
interesting area of research so where any night hints or any starting point
about it so there are some photos there are some papers that reasoning over knowledge bases alone so
we had a paper on recursive no tensor networks that basically takes a triplet a word vector for an entity might be in
freebase might be in word net a relation a vector for a relationship and a vector
for another entity and then basically pipe them into a neural network and say yes no are these two entities actually
in that relationship and you can have a variety of different architectures I think semi work done on that as well
wait that's a different brother different Benjy oh I think over there all right and it's true that's true yeah
if antoine board right that's right that's right so so i think you can also
reason over knowledge graphs and you could then try to combine that with reasoning over fuzzy text it has been a
boat it all has been done i think nobody has yet really combined it in a principled way great question yeah one last question
a whole question so so what the model answer my questions correctly so how do
i check the model actually understand understood my question and the woods which are logic was a models logic
behind that it's a good question in some ways it's a common question for for
neural network interpretability so income division at the sometimes we can at least the visualizes the features
right so how about the right and so i think the best thing that we could do right now is to show these attention
scores where you know for sentiment we're like oh how did it come up the sentiment oh it paid attention to the
movie working and likewise for question answering we can see like which facts at
which sentences that actually pay attention to in order to answer that overall question so that is I think the
best answer that we could come up with right now but how yeah there's certain other complexities that there's still an
area of open resources thank you all right thank you everybody
so thank you Richard we'll take another coffee break for 30 minutes so please come back at 2:45 but for a presentation
by sherry more

----------

-----

--10--     

-----
Date: 2016.09.27
Link: [# Deep Learning for Speech Recognition (Adam Coates, Baidu)](https://www.youtube.com/watch?v=g-sndkf7mCs)

Notes:

**Advantages:**

1. Deep learning significantly improves speech recognition accuracy, enabling more complex and natural user interactions.
2. Speech recognition technologies powered by deep learning are surpassing traditional methods, offering faster and more reliable transcription.
3. The ability to operate hands-free through voice commands enhances safety in scenarios like driving.

**Drawbacks:**

1. Dependence on large amounts of data and high computational power for training deep learning models.
2. Challenges in dealing with accents, background noise, and the nuances of spoken language.

**Tips and Advice:**

1. Utilize a combination of deep learning models and traditional language models to improve accuracy and handle linguistic nuances.
2. Consider the application context (e.g., noisy environment vs. quiet room) when collecting and preparing training data.
3. Implement strategies like "sorta grad" and batch normalization to improve training efficiency and model performance.
4. Pay attention to the model's structure to ensure it is suitable for real-time, online applications and does not overly delay responses.

**Lecture Content:**

- The lecture covered the integration of deep learning in speech recognition, focusing on the transition from traditional methods to deep learning approaches.
- Key components of speech recognition systems, such as acoustic models and language models, were discussed, along with their evolution due to deep learning.

**Main Challenges:**

1. Building a speech recognition system that is accurate across various languages and dialects.
2. Overcoming the limitations imposed by the need for large datasets and computational resources.

**The Importance and Usefulness of the Topic:**

- Speech recognition technology is crucial for developing interactive and accessible applications, enhancing user experience across various platforms and devices.

**Accomplishments:**

- Significant improvements in speech recognition accuracy, making it competitive with human transcription in certain languages.
- Development of robust models that can handle real-world speech, including noisy environments.

**Summary of the Content:** The lecture provided an overview of how deep learning has revolutionized speech recognition, highlighting the advancements over traditional methods. It discussed the components of speech recognition systems, challenges in the field, and strategies for improving model training and performance. The lecture also emphasized the importance of speech recognition in creating interactive and accessible technology.

**Interesting Quotes or Insightful Sentences:**

1. "Deep learning has been playing an increasingly large role in speech recognition."
2. "Speech recognition is at a place right now where it's becoming good enough to enable really exciting applications."
3. "The goal of building a speech pipeline is if you just give me a raw audio wave...I want to somehow build a speech recognizer that can do this very simple task of printing out 'hello world' when I actually say 'hello world'."

Transcription:

so I want to tell you guys about speech recognition and deep learning I think deep learning has been playing
an increasingly large role in speech recognition and one of the things I think is most exciting about this field
is that speech recognitions at a place right now where it's becoming good enough to enable really exciting
applications that end up the hands of users so for example if we want to
caption video content and make it accessible to to everyone it used to be that we would sort of try to do this but
you still need a human to get really good captioning for something like a lecture but it's possible that we can do
a lot of this with higher quality in the future with deep learning we can do things like hands-free interfaces in
cars make it safer to use technology while we're on the go keep people's eyes on the road of course and make mobile
devices home devices much easier much more efficient and enjoyable to use but
another actually sort of fun recent study that that some folks if I do
participated in along with Stanford and UW is to show that for even something straight forward that we sort of take
for granted as an application of speech which is just texting someone with voice
or writing a piece of text the study show you can actually go three times faster with voice recognition systems
that are available today so it's not just like a little bit faster now even with the errors that a speech
recognition system can make it's actually a lot faster and the reason I wanted to highlight this result which is
pretty recent is that the speech engine that was used for this study is actually powered by a lot of the deep learning
methods and I'm going to tell you about so hopefully when you walk away today you have an appreciation or an understanding of the sort of high-level
ideas that make a result like this possible so there are a whole bunch of
different components that make up a complete speech application so for
example there's speech transcription so if I just talk I want to come up with words that represent you know whatever I
just said there's also other tasks though like word spotting or triggering so for example if my phone is sitting
over there and I want to say hey phone go do something for me actually has to be listening continuously for me to say that word and
likewise there are things like speaker identification or verification so that if I want to authenticate myself or I
want to be able to tell apart different users in a room I've got to be able to recognize your voice even though I don't
know what you're saying so these are different tasks I'm not going to cover all of them today instead
I'm going to just focus on the bread and butter of speech recognition we're going to focus on building a speech engine
that can accurately transcribe audio into words so that's our main goal this
is a very basic goal of artificial intelligence right historically people
are very very good at listening to someone talk just like you guys are listening to me right now and you can
very quickly turn words turn audio into words and into meaning on your own
almost effortlessly and for machines this has historically been incredibly
hard so you think of this is like one of those sort of consummate AI tasks so the
goal of building a speech pipeline is if you just give me a raw audio wave like you recorded on your laptop or your cell
phone I want to somehow build a speech recognizer that can do this very simple task of printing out hello world when I
actually say hello world so before I dig into the deep learning part I want to
step back a little bit and spend maybe ten minutes talking about how a
traditional speech recognition pipeline is working for two reasons if you're out
in the wild you're doing an internship you're trying to build a speech recognition system with a lot of the
tools that are out there you're going to bump into a lot of systems that are built on technologies that look like
this so I want you to understand a little bit of the vocabulary and how those things are put together and also
this will sort of give you a story for what deep learning is doing in speech
recognition today that is kind of special and that I think paves the way
for for much bigger results in the future so traditional systems break the
problem of converting an audio wave of taking audio and break and turning it into a
transcription into a bunch of different pieces so I'm going to start out with my
raw audio and I'm just going to represent that by X and then usually we
have to decide on some kind of feature representation we have to convert this into some other form that's easier to
deal with than a raw audio wave and in a traditional speech system I often have
something called an acoustic model and the job of the acoustic model is to learn the relationship between these
features that represent my audio and the words that someone is trying to say and
then I'll often have a language model which encapsulate Sall of my knowledge
about what kinds of words what spellings and what combinations of words are most likely in the language that I'm trying
to transcribe and once you have all of these pieces so these might be these
different models might be driven by machine learning themselves what you would need to build in a traditional system is something called a decoder and
the job of a decoder which itself might involve some modeling efforts and
machine learning algorithms is to find the sequence of words W that maximizes
this probability the probability of the particular sequence W given your audio that's straightforward but that's
equivalent to maximizing the product of the contributions from your acoustic model and from your language model so a
traditional speech system is broken down into these pieces and a lot of the effort and getting that system to work
is is in developing this sort of portion that combines them all so it turns out
that if you want to just directly transcribe audio you can't just go
straight to characters and the reason is and it's especially apparent in English that the way something is spelled in
characters doesn't always correspond well to the way that it sounds so if if
I give you the word night for example without context you don't really know whether I'm talking about like a knight
in armor or whether I'm talking like knight like in like an evening and so a way to get around this to
abstract this problem away from a traditional system is to replace this with a sort of intermediate
representation instead of trying to predict characters I'll just try to predict something called phonemes so as
an example if I want to represent the word hello what I might try to do is
break it down into these units of sound so the first one is like the that H
sound in hello and then an a sound which is actually only one possible
pronunciation of an e and then an L and an O sound and that would be my string
that I try to come up with using all of my different speech components so this
in one sense makes the modeling problem easier my acoustic model and so on can be simpler because I don't have to worry
about spelling but it does have this problem that I have to think about where these things come from
so these phonemes are intuitively they're the perceptual e distinct units
of sound that we can use to distinguish words and they're very approximate this
might be our imagination that these things actually exist it's not clear how fundamental this is but they're sort of
standardized there are a bunch of different conventions for how to define these and if you're and if you end up
working on a system that uses phonemes one popular data set is called timet and
so this actually has a corpus of audio frames with examples of each of these phonemes so once you have this phoneme
representation unfortunately it adds even more complexity to this traditional
pipeline because now my acoustic model doesn't associate this audio feature
with words it actually associates them with another kind of transcription with the transcription into phonemes and so I
have to introduce yet another component into my pipeline that tries to understand how do I convert the
transcriptions in phonemes into actual Spelling's and so I need some kind of dick or a lexicon to tell me all of that so
this is a way of taking our knowledge about a language and baking it into this engineered pipeline and then once you've
got all that again all of your work now goes into this decoder that has a slightly more complicated task in order
to infer the most likely word transcription given the audio so this is
a tried and true pipeline it's been around for a long time you'll see a whole bunch of these systems out there
and we're still using a lot of the vocabulary from these systems but
traditionally the big advantage is that it's very tweakable if you want to go add a new pronunciation for a word
you've never heard before you can just drop it right in that's great but it's also really hard to get working
well if you start from scratch with this system and you have no experience in speech recognition it's actually quite
confusing and hard to debug it's very difficult to know which of these various models is the one that's behind your
error and especially once we start dealing with things like accents heavy noise different kinds of ambiguity that
makes the problem even harder to engineer around because trying to think ourselves about how do i tweaked my
pronunciation model for example to account for someone's accent that I haven't heard that's a very hard
engineering judgment for us to make so there are all kinds of design decisions
that go into this pipeline like choosing the future representation for example so
the first place that deep learning has started to make an impact in speech
recognition starting a few years ago is to just take one of the core machine
learning components of the system and replace it with a deep learning algorithm so I mentioned back in this
previous pipeline that we had this little model here whose job is to learn the relationship between a sequence of
phonemes and the audio that we're hearing so this is called the acoustic model and there are lots of different
methods for training this thing so take your favorite machine learning algorithm you can probably find someone who is
trained in acoustic model with that algorithm whether it's a Gaussian mixture model or a bunch of decision
trees and random forests anything for estimating these kinds of densities there's a lot of work and trying to make
better acoustic models so some work by George Dahl and co-authors took what was
a state of the art deep learning system back in 2011 which is a deep belief
network with some pre training strategies and dropped it into a state of the art pipeline in place of this
acoustic model and the results are actually pretty striking because even though we had neural networks and these
pipelines for a while what ended up happening is that when you replace the
Gaussian mixture model in hmm system that already existed with this deep
belief network as an acoustic model you actually got something between like a ten and twenty percent relative
improvement in accuracy which is a huge jump this is highly noticeable to a
person and if you compare this to the amount of progress that had been made in preceding years this is a giant leap for
a single paper to make compared to a progress we've been able to make previously so this is in some sense the
first generation of deep learning for speech recognition which is I take one of these components and I swap it out
for for my favorite deep learning algorithm so the picture looks sort of
like this so with these traditional speech recognition pipelines the problem that
we would always run into is that if you gave me a lot more data he gave me a much bigger computer so that I could
train a huge model that actually didn't help me because all the problems I had were in the construction of this
pipeline and so eventually if you gave me more data in a bigger computer the
performance of our speech recognition system would just kind of peter out it would just reach a ceiling that was very
hard to get over and so we just start coming up with lots of different strategies we start specializing for
each application we try to specialize for each user and try to make things a little bit
better around the edges and what these deep learning acoustic models did was in some sense moved that barrier a little
ways it made it possible for us to take a bit more data much faster computers
that let us try a whole lot of models and move that ceiling up quite a ways so
the question that many in the research community including folks if I do have been trying to answer is can we go to a
next-generation version of this insight can we for instance build a speech
engine that is powered by deep learning all the way from the audio input to the
transcription itself can we replace as much of that traditional system with deep learning as possible so that over
time is you give researchers more data and bigger computers and the ability to
try more models their speech recognition performance just keeps going up and we can potentially solve speech for
everybody so the goal of this tutorial is not to to get you up here which
requires a whole bunch of things that I'll tell you about near the end but what we want to try to do is give you
enough to get a point on this curve and then once you're on the curve the the
idea is that what remains is now a problem of scale it's about data and about getting bigger computers and
coming up with ways to build bigger models so that's my objective so that when you walk away from here you have a
picture of what you would need to build to get this point and then after that
it's hopefully all about scale so thanks to Vinay Rao who's been helping put this
tutorial together there is going to be some starter code live for the basic
pipeline the deep learning part of the pipeline that we're talking about so there are some open source implementations of things like CTC but
we wanted to make sure that there's a system out there that's pretty representative of the acoustic models that I'm going to be talking about in
the first half of the presentation here so this will be enough that you can get
a simple pipeline going with something called max Dakota which I'll tell you about later and the
idea is that this is sort of a scale model of the acoustic models that I do and other places are powering real
production speech engines so this will get you that point on the curve okay
so here's what we're going to talk about the first part I'm just going to introduce a few preliminaries talk about
pre-processing so we still have a little bit of pre-processing around but it's not really fundamental I think it's
probably going to go away in the long run we'll talk about what is probably the most mature piece of sequence
learning technologies for deep learning right now so it turns out that one of the fundamental problems of doing speech
recognition is how do I build a neural network that can map this audio signal to a transcription that can have a quite
variable length and so CTC is one highly mature method for doing this and I think
you're actually going to hear about maybe some some other solutions later today then I'll say a little bit about
training and just what that looks like oops and then finally say a bit about
decoding and language models which is sort of an addendum to the current acoustic models that we can build that
make them perform a lot better and then once you have this that's a picture of what you need to to get this point on
the curve and then I'll talk a little bit about what's remaining how do you scale up from this little scale model up
to the full thing what does what does that actually entail and then time permitting we'll talk a little bit about
production how could you put something like this into a cloud server and actually serve real users with it great
so how is audio represented this should be pretty straightforward I think unlike
a two dimensional image where we normally have a 2d grid of pixels audio is just a 1d signal and there are a
bunch of different formats for audio but typically this one-dimensional wave that that is actually me saying something
like hello world is something like 8,000 samples per second or 16,000 samples per
second and each wave is quantized into eight or 16 bits so when we represent this audio
signal that's going to go into our pipeline you could just think of that as a one dimensional vector so when I have
that box called X that represented my audio signal you can figure this was being broke down broken down into
samples X 1 X 2 and so forth and if I had a one-second audio clip this vector
would have a length of either say 8,000 or 16,000 samples and each element would
be say a floating-point number that I had extracted from this eight or 16-bit sample this is really simple now once I
have an audio clip we'll do a little bit of pre-processing so there are a couple of ways to start the first is to just do
some vanilla pre-processing like convert to a simple spectrogram so if you look
at a traditional speech pipeline you're going to see things like M FCC's which are mell frequency capital coefficients
you'll see a whole bunch of plays on spectrograms where you take differences
in different kinds of features and try to engineer complex representations but
for the stuff that we're going to do today a simple spectrogram is just fine and it turns out as you'll see in a
second we lose a little bit of information when we do this but it turns out not to not to be a huge difference
now I said a moment ago that I think probably this is going to go away in the long run and that's because today you
can actually find recent research and trying to do away with even this pre-processing part and having your
neural network process the audio wave directly and just train its own feature transformation so there's some
references at the end that you can look at for this so it's a quick straw poll
how many people have seen a spectrogram or computed a spectrogram before pretty
good maybe 50% ok so the idea behind a spectrogram is that it's sort of like a
frequency domain representation but instead of representing this entire signal in terms of frequencies I'm just
going to represent a small small window in terms of frequencies so to to process
this audio clip the first thing I'm going to do is cut out a little window that's typically about 20 milliseconds
long and when you get down to that scale it's usually very clear that these audio signals are made up of sort of a
combination of different frequencies of sine waves and then what we do is we
compute an FFT it basically converts this little signal into the frequency domain and then we just take the log of
the power at each frequency and so if you look at your what the result of this
is it basically tells us for every frequency of sine wave what is the
magnitude what's the amount of power represented by that sine wave that makes up this original signal so over here in
this example we have a very strong low frequency component in the signal and
then we have differing magnitudes at different differing frequencies so we
can just think of this as a vector so now instead of representing this little 20 millisecond slice as sort of a
sequence of audio samples instead I'm going to represent it as a vector here where each element represents sort of
the strengths of each frequency in this little window and the next step beyond
this is that if I just told you how to process one little window you can of course apply this to a whole bunch of
windows across the entire piece of audio and and that gives you what we call a
spectrogram and you can use either disjoint windows that are just sort of adjacent or you can apply them to
overlapping windows if you like so there's a little bit of parameter tuning there but this is an alternative
representation of this audio signal that happens to be easier to use for a lot of
purposes okay so our goal starting from
this representation is to build what I'm going to call an acoustic model but which is really to the extent we can
make it happen is really going to be an entire speech engine that is represented by a neural network
so what we would like to do is build a neural net that if we could train it
from a whole bunch of pairs X which is my original audio that I turn into a spectrogram and Y star that's the ground
truth transcription that some human is given me if I were to train this big neural network off of these pairs what
I'd like it to produce is some kind of output that I'm representing by the character C here so that I could later
extract the correct transcription which I'm going to denote by Y so if I said
hello the first thing I'm going to do is run pre-processing to get all these spectrogram frames and then I'm going to
have a recurrent neural network that consumes each frame and processes them into some new representation called C
and hopefully I can engineer my network in such a way but I can just read the
transcription off of these output neurons so that's kind of the the intuitive picture of what we want to
accomplish so as I mentioned back in the outline there's one obvious fundamental
problem here which is that the length of the input is not the same as the length
of the transcription so if I say hello very slowly then I can have a very long
audio signal even though I didn't change the length of the transcription or if I say hello very quickly then I kind of
very short transcript or a very short piece of audio and so that means that this output of my neural network is
changing length and I need to come up with some way to reprimand neural
network output to this fixed length transcription and also do it in a way that we can actually train this pipeline
so the traditional way to deal with this problem if you were building a speech
engine several years ago is to just try to bootstrap the whole system so I had actually train a neural network to
correctly predict the sounds at every frame using some kind of data set like
timet where someone has lovingly annotated all of the phonemes for me and then I try to figure out the
alignment between my saying hello in a phonetic transcription with the input audio and then once I've lined up all of
the sounds with the input audio now I don't care about length anymore because I can just make a one-to-one mapping
between the audio input and the phoneme outputs that I'm trying to target but
this alignment process is horribly error-prone you have to do a lot of extra work to make it work well and so
we really don't want to do this we really want to have some kind of solution that lets us solve this
straightaway so there are multiple ways to do it and as I mentioned there's some current
research on how to use things like attentional model sequence to sequence models that you'll hear about later in
order to solve this kind of problem but as I said we'll focus on something
called connexion connectionist temporal classification or ctc that is sort of
current state of the art for how to do this so here's the basic idea so our recurrent neural network has
these output neurons that I'm calling C and the job of these output neurons is
to encode a distribution over over the output symbols so as because of the
structure of the recurrent Network the length of this symbol sequence C is the same as the length of my audio input so
if my audio inputs a was two seconds long that might have a hundred audio
frames and that would mean that the length of C is also a hundred a hundred different values so if we were working
on a phoneme based model then C would be some kind of phoning representation I
mean we would also include a blank symbol which is special for CTC but if
as we'll do in the rest of this talk we're trying to just predict the
graphemes trying to predict the characters in this language directly from the audio then I would just let C
take on a value that's in my alphabet or take on a blank or a space if my
language has spaces in it and then the second thing I'm going to do sigh my RNN gives me a distribution over
these symbols see is what I'm going to try to define some kind of mapping that can convert this long transcription C
into the final transcription Y that's like hello that's the actual string that
I want and now recognizing that C is itself a probabilistic creature there's
a distribution over choices of C that correspond to the audio once I apply
this function that also means that there's a distribution over Y there's a distribution over the possible
transcriptions that I could get and what I'll want to do to train my network is to maximize the probability of the
correct transcription given the audio so those are the three steps that we have
to accomplish in order to make CTC work so let's start with the first one so we
have these output neurons C and they represent a distribution over the different symbols that I could be
hearing in the audio so I've got some audio signal down here you can see the spectrogram frames poking up and this is
being processed by this recurrent neural network and the output is a big bank of
softmax in herranz so for the first frame of audio I have a neuron that
corresponds to each of the symbols that C could represent and they and this set
of softmax neurons here the with the output summing to 1 represents the probability of say C 1 having the value
ABC and so on or this special blank character so for example if I pick one
of the neurons over here then the first row which it represents the character B
and the 17th column which is the 17th frame in time this represents the
probability that C 1 7 represents the character be given the audio so once I
have this that also means that I can just define a distribution not just over
the visual characters but if I just assume that all of the characters are independent which is kind of a naive
assumption but if I bake this into the system I can define a distribution over all possible sequences of characters in
this alphabet so if I gave you a specific instance a specific character
string using this alphabet for instance I represent the string hello as HHH e
blank e blank blank LL blank ello and then a bunch of blanks this is a string
in this alphabet for for C and I can just use this formula to compute the
probability of this specific sequence of characters so that's how we we compute
the probability for a sequence of characters when they have the same length as the audio input so the second
step and this is in some sense the kind of neat trick in CTC is to define a
mapping from this long encoding of the
audio into symbols that crunches it down to the actual transcription that we're
trying to predict and the rule is this operator takes this character sequence
and it picks up all the duplicates all of the adjacent characters that are repeated and discards the duplicates and
just keep some of them and then it drops all of the blanks so in this example you
see you have three H's together so I just keep one H and then I have a blank
I throw that away and I keep an e when I have two L's so I keep one of the LS over here and then another blank and an
elbow and the one key thing to note is that when I have two characters that are
different right next to each other I just end up keeping those two characters in my output but if I ever have a double
character like ll in hello then I'll need to have a blank character that that
gets put in between but if our neural network gave me this
transcription told me that this was the right answer we just have to apply this operator and we get back Vic string
hello so now that we have a way to
define a distribution over these sequences of symbols that are the same length as the audio and we now have a
mapping from those strings into transcriptions as I said this gives us a
probability distribution over the possible final transcriptions so if I
look at the probability distribution over all the different sequences of symbols right
I might have hello written out like on the last slide and maybe that has probability 0.1 and then I might have
hello but written a different way with a different by say replacing this H with a blank that has a smaller probability and
I have a whole bunch of different possible symbol sequences below that and what you'll notice is that if I go
through every possible combination of symbols here there are several combinations that all
map to the same transcription so here's one version of hello there's a second
version of hello there's a third version of hello and so if I now ask what's the probability of the transcription hello
the way that I compute that is I go through all of the possible character
sequences that correspond to the transcription hello and I add up all of
their probabilities so I have to sum over all possible choices of C that
could give me that transcription in the end so you can kind of think of this as
searching through all the possible alignments right I could shift these characters around a
little bit I can move them forward backward I could expand them by adding duplicates or squish them up depending
on how fast someone is talking and that corresponds to every possible alignment between the audio and the characters
that I want to transcribe it sort of solves the problem of the variable length and the way that I get the
probability of a specific transcription is to sum up to marginalize over all the different
alignments that could be feasible and then if we have a whole bunch of other
possibilities in here like the word yellow-eyed compute them in the same way and so this equation just says to sum
over all the character sequences see so that when I apply this little mapping operator I end up with the transcription
why is oh I'm missing a EE you're
talking about this one so when we apply this sort of squeezing operator here we
drop this double e to get a single Ian hello so we remove all the duplicates so
the same way we did for an H right so
whenever you see two characters together like this where they're adjacent duplicates you sort of squeeze all those
duplicates out and you just keep one of them but here we have a blank in between so if we drop all the duplicates first
then we still have two L's left and then we remove all the blanks so this gives
the algorithm a way to represent repeated characters in the transcription there's another one in the back
oh I see yeah this is maybe I put a
space in here really I'd have put a space character in here instead of a blank really this could be h-e-l-l-o H
yeah so the this space here is erroneous
okay very good okay so once I've defined this right I
just gave you a formula to compute the probability of a string given the audio
so as as with every good starting to a machine learning algorithm we go and we
try to apply maximum likelihood I now give you the correct transcription and your job is to tune the neural network
to maximize the probability of that transcription using this model that I just defined so in equations what I'm
going to do is I want to maximize the log probability of Y star for a given
example I want to maximize the probability of the correct transcription
given the audio X and then I'm just going to sum over all the examples and
then what I want to do is just replace this with the equation that I had on the
last page that says in order to compute the probability of a given transcription I have to sum over all of the possible
symbol sequences that could have given me that transcription sum over all the possible alignments that would map that
transcription to my audio so Alex grades and co-authors in 2006 actually show
that because of this independence assumption there is a clever way there
is a dynamic programming algorithm that can efficiently compute this summation for you and not only commute compute
this summation so that you can compute the objective function but actually compute its gradient with respect to to
the output neurons of your neural network so if you look at the paper the algorithm details are in there
what school right now in the history of speech and deep learning is that this is
at the level of a technology this is something that's now implemented in a bunch of places so that you can download
a software package that efficiently will calculate this ctc loss function for you
that can calculate this likelihood and can also just give you back the gradient so I won't go into the equations here
instead I'll tell you that there are a whole bunch of implementations on the web that you can now use as part of deep
learning packages so one of them from Baidu implements CTC on the GPU is
called warp CTC Stanford and group they're actually one of Andrews students
has a CTC implementation and there's also now CTC losses implemented in
packages like tensor flow so this is something that's sufficiently widely distributed that you can use use these
algorithms off the shelf so the way that these work the way that we go about
training is we start from our audio spectrogram we have our neural network structure where you get to choose how
it's put together and then it outputs this Bank of softmax neurons and then
there are pieces of off-the-shelf software that will compute for you the CTC cost function they'll compute this
log likelihood given a transcription and the output neurons from your recurrent
Network and then the software will also be able to tell you the gradient with
respect to the output neurons and once you've got that you're set you can feed them back into the rest of your code and
get the gradient with respect to all of these parameters so as I said this is all available now in sort of efficient
off-the-shelf software so you don't have to do this work yourself so that's pretty much all there is to the high
level algorithm with this it's actually enough to get a sort of a working
Drosophila of speech recognition going there are a few a few little tricks
though that you might need along the way on easy problems you might not need these but as you get to more
difficult datasets with a lot of noise they can become more and more important so the first one that we've been calling
sort of grad in the vein of all of the grad algorithms out there is basically a
trick to help with recurrent neural networks so it turns out that when you
try to train one of these big RNN models on some off-the-shelf speech data one of
the things that can really get you is seeing very long utterances early in the process because if you have a really
long audience then if your neural network is badly initialized you'll often end up with things like underflow
and overflow as you try to go and compute the probabilities and you end up with gradients exploding as you try to
do back propagation and it can make your optimization a real mess and it's coming
from the fact that these utterances are really long and really hard and the neural network just isn't ready to deal
with those transcriptions and so one of the fixes that you can use is during the early parts of training usually in the
first epic is you just sort all of your audio by length and now when you process
a mini batch you just take the short utterances first so that you're working with really short rnns that are quite
easy to train and don't blow up and don't have a lot of catastrophic numerical problems and then as time goes
by you start operating on longer and longer addresses that get more and more difficult so we call this sort of grad
it's basically a curriculum learning method and so you can see some work from yoshua bengio and his team on a whole
bunch of strategies for this but you can think of the short utterances as being the easy ones and if you start out with
the easy utterances and move to the longer ones your optimization algorithm can do better so here's what an example
from one of the models that we've trained where your CTC cost starts up here and you know after a while you
optimize and you sort of bottom out around you know what a log likelihood of maybe 30 and then if you add this sort
of grad strategy after the first epic you're actually doing better and you can reach a better optimum than you
without it and in addition another strategy that's extremely helpful for
recurrent networks and very deep neural networks is batch normalization so so
this becoming very popular and it's also available as sort of an off-the-shelf package inside of a lot of the different
frameworks that are available today so if you start having trouble you can consider putting batch normalization
into your network okay so our neural network now spits out this big bank of
softmax neurons we've got a training algorithm we're just doing gradient descent how do we actually get a
transcription this process as I said is meant to be as close to characters as
possible but we still sort of need to decode these outputs and you might think
that one simple solution which turns out to be approximate to get the correct transcription is just go through here
and pick the most likely sequence of symbols for C and then apply our little
squeeze operator to get back the transcription the way that we defined it so this turns out not to be the optimal
thing this actually doesn't give you the most likely transcription because it's not accounting for the fact that every
transcription might have multiple sequences of C's multiple alignments in
this representation but you can actually do this and this is called the max
decoding and so for this sort of contrived example here
I put little red dots on the most likely C and if you see there's a couple of
blanks a couple of C's is another blank a more blanks bees more blanks and if
you apply our little squeeze operator you just get the word cab if you do this
it is often terrible it'll often give you a very strange transcription that
doesn't look like English necessarily but the reason I mention it is that this
is a really handy diagnostic that if you're kind of wondering what's going on in the network glancing at a few of
these will often tell you if the network's starting to pick up any signal or if it's just outputting gobbled
cook so I'll give you a more detailed example in a second of how that happens
all right so these are all the concepts of our of our very simple pipeline and
the demo code that we're going to put up on the web will basically let you work on all of these pieces so once we try to
train these I want to give you an example of the sort of data that we're training on a tanker is a ship designed
to carry large volumes of oil okay so this is just a person sitting there
reading The Wall Street Journal to us so this is a sort of simple data set it's really popular in the speech research
community it's published by the linguistic data consortium there's also a free alternative called libera speech
that's very similar but instead of people reading The Wall Street Journal is people reading Creative Commons audiobooks so in the demo code that we
have a really simple network that works reasonably well it looks like this so there's a sort of family of models that
we've been working with where you start from your spectrogram you have maybe one layer or several of convolutional
filters at the bottom and then on top of that you have some kind of recurrent neural network it might just be a
vanilla RNN but but you can also use like LS TM or GRU cells any of your
favorite RNN creatures from the literature and then on top of that we have some fully connected layers that
produce these softmax outputs and those are the things that go into CTC for training so this is pretty
straightforward the implementation on the web uses the the work CTC code and then we would just train this big neural
network with stochastic gradient descent Nesterov momentum all the stuff that you've probably seen in a whole bunch of
other talks so far all right so if you actually run this what is going on
inside so I mentioned that looking at the max decoding is kind of a handy way
to see what's what's going on inside this creature so I wanted to show you an
example so this is a picture this is a visualization
those softmax neurons at the top of one of these big neural networks so this is
the representation of see from all the previous slides so on the horizontal
axis this is basically time this is the frame number or which chunk of the spectrogram we're seeing and then on the
vertical axis here you see these are all the characters in the English alphabet or a space or a blank so after three
hundred iterations of training which is not very much the system has learned something amazing which is that it
should just output blanks and spaces all the time because these are by far because of all the silence and things in
your data set these are the most common characters right I just want to fill up the whole space with blanks but you can
see it's kind of randomly poking out a few characters here and if you run your little Mac's decoding strategy to see
what is the system think the transcription is it thinks it transcription is at and so but after
three hundred iterations that's okay but this is a sign that the neural networks not going crazy your gradient isn't
busted it's at least learned what is the most likely characters then after maybe
1500 or so you start to get a little bit of structure and if you try to like
mouthed these words you might be able to sort of see that there's some English
like sounds in here like they are just in frightened something kind of odd but
it's actually looking much better than just h it's actually starting to output something go a little bit farther it's a
little bit more organized you could start to see that we have sort of
fragments of possibly words starting to form and then after you're getting close
to convergence it's still not a real sentence but does this make sense to people he guess like what the correct
transcription might be yeah so you might have a couple of candidates the the
correct one is actually there just in front and so you can see that sort of
it's sort of sounding it out with English characters like I have a young son and I kind of figure I'm eventually
going to see him producing max Dakota puts of English and you're just going to
like sound these things that we like if they're just in front there but but this is why this max decoding strategy is
really handy because you can kind of look at this output and say yeah it's starting to get some actual signal out of the data it's not just gobbledygook
so because this is like my favorite speech recognition party game I wanted
to show you a few more of these so here's the max decoded output the poor
little things cried Cynthia think of them having been turned to the wall all these years so you can hear like the
sound of the breath at the end turns into a little bit of a word Cynthia is sort of in this transcription
and you'll find that things like proper names and so on tend to get sounded out but if those names are not in your audio
data there's no way the network could have learned how to say the name Cynthia and we'll come back to how to solve that
later did you see the true label the poor little things cried Cynthia and
that the last word is actually all these years and there isn't a word hanging off at the end so here's another one that is
true bad grade how many people figured
out what this is this is the max decoded transcription sounds sounds good to you
it sounds good to me if you told me that this was the ground truth like oh that's weird I have to go
what lookup what this is here's the actual true label turns out this is a
French word that means something like rubbernecking I had no idea what this
word was so this is again the cool examples of what these neural networks are able to figure out with no knowledge
of the language itself okay so let's go
back to decoding we just talked about max decoding which is sort of an approximate way of going from these
probability vectors to a transcription Y and if you want to find the actual most
likely transcription Y there's actually no algorithm in general that can give
you the perfect solution efficiently so the reason for that remember is that for a
single transcription why I have an efficient algorithm to compute its probability but if I want to search over
every possible transcription I don't know how to do that because there combinatorially or exponentially many
possible transcriptions and I'd have to run this algorithm to compute the probability of all of them so we have to
resort to some kind of generic search strategy and so one proposed in the original paper briefly is a sort of
prefix decoding strategy so I don't want to spend a ton of time on this instead I
want to step to sort of the next piece of the picture so there were a bunch of
examples in there right like proper names like Cynthia and things like but Dow Derby where unless you had heard
this word before you have no hope of getting it right with your neural network and so there are lots of
examples like this in the literature of things that are sort of spelled out phonetically but aren't legitimate
English transcriptions and so what we'd like to do is come up with a way to fold
in just a little bit of that knowledge about the language that take a small
step backward from a perfect end-to-end system and make make these transcriptions better so as I said the
real problem here is that you don't have enough audio available to learn all these things if we had millions and
millions of hours of audio sitting around you could probably learn all these transcriptions because you just hear enough words that you know how to
spell them all maybe the way a human does but unfortunately we just don't
have enough audio for that so we have to find a way to get around that data problem there's also an example of
something that in the AI lab we've dubbed the Tchaikovsky problem which is that there are certain names in the
world right like proper names that if you've never heard of it before you have no idea how it's spelled and the only
way to know it is to have seen this word in text before and to see it in context so part of the purpose of these language
models is to get examples like this correct so there are a couple of solutions one
would be to just step back to a more traditional pipeline right use phonemes because then we can bake new words in
along with their phonetic pronunciation and the system will just get it right
but in in this case I want to focus on just fusing in a traditional language
model that gives us the probability a priori of any sequence of words so the
reason that this is helpful is that using a language model we can train these things from massive text corpora
we have way way more text in the world than we have transcribed audio and so
that makes it possible to train these giant language models with huge vocabulary and they can also pick up the
sort of contextual things that will tip you off to the fact that Tchaikovsky concerto is a reasonable thing for a
person to ask and that this particular transcription which we have seen in the
past trike offski concerto even though composed of legitimate English words is
is nonsense so there's actually not much to see on
the language modeling front for this except that the reasons for sticking with traditional and grand models are
kind of interesting if you're excited about speech applications so if you go use a package like Ken LM on the web to
go build yourself a giant and Grahm language model these are really simple and well supported and so that makes
them easy to get working and they'll let you train from lots of corpora but for
speech recognition in practice one of the nice things about Engram models as opposed to trying to say use like an RNN
model is that we can update these things very quickly if you have a big distributed cluster you can update that
Engram model very rapidly in parallel from new data to keep track of whatever the trending words are today that your
speech engine might need to deal with and we also have the need to query this
thing very rapidly inside our decoding loop that you'll see in just a second
and so being able to just look up the probabilities in a table the way an Engram model is structured is very
valuable so I hope someday all of this will go away and be replaced with an
amazing neural network but this is the really best practice today so in order
to fuse this into the system since to get the most likely transcription right
probably of Y given X to maximize that thing we need to use a generic search algorithm anyway this opens up a door
once we're using a generic search scheme to do our decoding and find the most likely transcription we can add some
extra cost terms so in a previous piece of work from Audi haneun and several
co-authors what you do is you take the probability of a given word sequence
from your audio so this is what you would get from your giant RNN and you
can just multiply it by some extra terms the probability of the word sequence according to your language model raised
to some power and then multiplied by the length we raised to another power you see that if you just take the log of
this objective function right then you get the log probability that was your original objective you get alpha times
the log probability of the language model and beta times the log of the
length and these alpha and beta parameters let you sort of trade-off the importance of getting a transcription
that makes sense to your language model versus getting a transcription that makes sense to your acoustic model and
actually sounds like the thing that you heard and the reason for this extra term over here is that as you're multiplying
in all of these terms you tend to penalize long transcriptions a bit too much and so having a little bonus or
penalty at the end to tweak to get the transcription length right is very helpful so the basic idea behind this is
just to use beam search so beam search really popular search algorithm a whole bunch of instances of it and the rough
strategy is this so starting from time zero starting from T equals one at the
very beginning of your audio input I start out with an empty list that I'm
going to pop you late with prefixes and these prefixes are just partial transcriptions that represent what I think I've heard so far
in the audio up to the current time and the way that this proceeds is I'm going
to take at the current time step each candidate prefix out of this list and then I'm going to try all of the
possible characters in my soft max neurons that can possibly follow it so
for example I can try adding a blank I say if the next element of C is actually
supposed to be a blank then what that would mean is that I don't change my prefix right because the blanks are just
going to get dropped later but I need to incorporate the probability of that blank character into the probability of
this prefix right it represents one of the ways that I could reach that prefix
and so I need to sum that probability into that candidate and likewise
whenever I add a space to the end of a prefix that signals that this prefix
represents the end of a word and so in addition to adding the probability of the space into my current estimate this
gives me the chance to go look up that word in my language model and fold that into my current score and then if I try
adding a new character onto this prefix it's just straightforward I just go and update the probabilities based on the
probability of that character and then at the end of this I'm going to have a huge list of possible prefixes that
could be generated and this is where you would normally get the exponential blow-up of trying all possible prefixes
to find the best one and what beam search does is it just says take the que
most probable prefixes after I remove all the duplicates in here and then go
and do this again and so if you have a really large que then your algorithm will be a bit more accurate in finding
the best possible solution to this maximization problem but it'll be slower
so here's what ends up happening if you run this decoding algorithm if you just
run it on the are n n outputs you'll see that you it's actually better than straight max
decoding you find slightly better solutions but you still make things like spelling errors like Boston with an AI
but once you add in a language model that can actually tell you that the word Boston with an O is much more probable
than Boston with an AI see this so one
place they can also drop in deep learning that I wanted to mention very rapidly is just if you're not happy with
your Engram model because it doesn't have enough context where you've seen a really amazing neural language modeling
paper that you'd like to fold in one really easy way to do this and Link it to your current pipeline is to do
rescore eeen so when this decoding strategy finishes it can give you the
most probable transcription but it also gives you this big list of the top K transcriptions in terms of probability
and what you can do is to take what you
can do is take your recurrent Network and just rescore all of these and
basically reorder them according to this new model so in the instance of a neural
language model let's say that this is my N best list right I have five candidates
that were output by my decoding strategy and the first one is I'm a connoisseur
looking for wine and pork chops sounds good to me I'm a connoisseur looking for
wine and pork shots so this is actually quite subtle and depending on what kind
of connoisseur you are sort of up to interpretation what you're looking for but perhaps a neural language model is
going to be a little bit better if figuring out that wine and port are closely related and if you're a connoisseur you might be looking for
wine import shots and so what you would hope to happen is that a neural language model trained on a bunch of text is
going to correctly reorder these things and figure out that the second beam
candid is actually the correct one even though your Engram model didn't help you
okay so that is really the scale model that is the set of concepts that you
need to get a working speech recognition engine based on deep learning and so the
thing that's left to go to state-of-the-art performance and start serving users is scale so I'm going to
kind of run through quickly a bunch of the different tactics that you can use to try to get there so the two pieces of
scale that I want to cover of course our data and computing power where do you get them so the first thing to know this
is just a number you can keep in the back of your head for all purposes which is that transcribing speech data is not
cheap but it's also not prohibitive it's about 50 cents to a dollar a minute depending on the quality you want and
who's transcribing it and the difficulty of the data so typical speech benchmarks
you'll see out there maybe hundreds to thousands of hours it's like the Liberty
speech data set is maybe hundreds of hours there's another data set called Vox Forge and you can kind of cobble
these together and get maybe hundreds to thousands of hours but the real challenge is that the application
matters a lot so all the utterances I was playing for you are examples of read
speech people are sitting in a nice quiet room they're reading something wonderful to me and so I'm going to end
up with a speech engine that's really awesome at listening to The Wall Street Journal but maybe not so good at
listening to someone in a crowded cafe so the application that you want to target really needs to match your data
set and so it's worth at the outset if you're thinking about going and buying a bunch of speech data to think of what is
the style of speech you're actually targeting are you worried about red speech like the ones we're hearing or do
you care about conversational speech it turns out that when people talk in a conversation it when they're spontaneous
they're just coming up with what to say on the fly versus if they have something that they're just dictating and they
already know what to say they behave differently and they can exhibit all of these effects like disfluency and
stuttering and then in addition to that we have all kinds of environmental factors that
might matter for an application like reverb and echo we start to care about the quality of microphones and whether
they have noise canceling there's something called Lombard effect that I'll mention again in a second and of
course things like speaker accents where you really have to think carefully about how you collect your data to make sure
that you you actually represent the kinds of cases you want to test on so
the reason that red speech is really popular is because we can get a lot of it and even if it doesn't perfectly
match your application it's cheap and getting a lot of it can still help you so I wanted to say a few things about
red speech because for less than ten bucks an hour's often a lot less you can get a whole bunch of data and it has the
disadvantage that you lose a lot of things like inflection and conversation allottee but but it can still be helpful
so one of the things that we've tried doing and I'm always interested to hear
more clever schemes for this is you can kind of engineer the way that people read to try to get the effects that you
want so so here's one which is that if you want a little bit more conversation
ality you want to get people out of that kind of humdrum dictation you can start giving them reading material that's a
little more exciting you can give them like movie scripts and books and people will actually start voice acting for you
creep in set the witch and see if it is properly heated so that we can put the
bread in so these are really wonderful workers right there like kind of really
getting into it to give you better data
the wolf is dead the wolf is dead and danced for joy around about the well with their mother
so yeah people reading poetry they get this sort of lyrical quality into it that you don't get from from just
reading The Wall Street Journal and finally there's something called the Lombard effect that happens when people
are in noisy environments so if you're in like a noisy party and you're trying to talk to you friend who's a couple of chairs away
you'll catch yourself involuntarily going hey over there what are you doing you raise your inflection and you kind
of you try to use different tactics to get your signal-to-noise ratio up you'll
sort of work around the the channel problem and so this this is very problematic when you're trying to do
transcription a noisy environment because people will talk to their phones using all these effects even though the
noise canceling and everything could actually help them so one strategy we've tried with varying levels of success
then they fell asleep and evening pass but no one came to the poor children is
to actually play loud noise in people's headphones to try to get them to elicit
this behavior again here this person is kind of raising their voice a little bit in a way that they wouldn't if they were
just reading and similarly as I mentioned there are a whole bunch of
different augmentation strategies so there are all these effects of environment like reverberation echo
background noise that we would like our speech engine to be robust to and one
way you could go about trying to solve this is to go collect a bunch of audio from those cases and then transcribe it
but but getting that raw audio is really expensive so instead an alternative is
to take the really cheap read speech that's very clean and use some like off
the shores off the source off the shelf open source audio toolkit to synthesize
all the things you want to be robust to so for example if we want to simulate
noise in a cafe here here's just me talking to my laptop in a quiet room
hello how are you so if I'm just asking how are you and then here's the sound of
a cafe so I can obviously collect these
independently very cheaply then I can synthesize this by just adding these signals together hello how are you which
actually sounds I don't know sounds to me like my talking to my laptop at a Starbucks or something
and so for our work on deep speech we actually take something like 10,000 hours of raw audio that sounds kind of
like this and then we pile on lots and lots of audio tracks from Creative
Commons videos it turns out there's a strange thing people upload like noise tracks to the web that last four hours
is like really soothing to listen to the highway or something and so you can
download all all these this free found data and you can just overlay it on this voice and you can synthesize perhaps
hundreds of thousands of hours of unique audio and so the idea here is that it's
just much easier to engineer your data pipeline to be robust than it is to
engineer the speech engine itself to be robust so whenever you encounter an environment that you've never seen
before and your speech engine is breaking down you should shift your instinct away from trying to engineer
the engine to fix it and toward this idea of how do I reproduce it really cheaply in my data so here's that Wall
Street Journal example again is it designed to carry large volumes of oil or other liquid cargo and so if I wanted
to for instance deal with a person reading Wall Street Journal on a tanker maybe taking a ship designed to carry
large volumes of oil or other liquid cargo there's lots of reverb in this room so you can't hear the reverb on the
audio but basically you know you can synthesize these things with one line of socks on the command line so from some
of our own work with building a large scale speech engine with these technologies this helps a ton and you
can actually see that when we run on clean and noisy test utterances as we
add more and more data all the way up to about 10,000 hours and using a lot of
these synthesis strategies we can just steadily improve the performance of the engine and in fact on
things like clean speech you can get down well below 10% word error rate which is a pretty pretty strong engine
okay let's talk about computation because the caveat on that last slide is
yes more data will help if you have a big enough model and big models usually
mean lots of computation so what I haven't talked about is how big are
these neural networks and how big is one experiment so if you actually want to train one of these things at scale what
are you in for so here's the the back of the envelope it's going to take at least
the number of connections in your neural network so take one slice of that are n
n the number of unique connections multiplied by the number of frames once you unroll the recurrent network once
you unfold it multiplied by the number of utterances you've got a process in your data set times the number of training epochs the
number of times you loop through the data set times three because you have to do forward propagation to flops for
every connection because there's a multiplying and add so if you multiply this out for some parameters from the
the deep speech engine if I do you get something like 1.2 times 10 to the 19
flops so about 10 XO flops and if you run this on a Titan X card this will
take about a month now if you already know what the model is that might be
tolerable if you're you're on your epic run to get your best performance so far then this is okay but if you don't know
what model is going to work you're targeting some new scenario then you want it done now so you can try lots and
lots of models quickly so the easy fix is just to try using a bunch more GPUs
with data parallelism and the good news is is that so far it looks like speech
recognition allows us to use mini batch sizes we can process enough utterances in parallel that this is actually
efficient so you'd like to keep you know maybe a bit more than 64 utterances on each GPU
and up to a total mini batch size of like a thousand or maybe two thousand it's still useful and so if you've got
if you're putting together your your infrastructure you can go out and you can buy a server that'll fit eight of
these Titan GP using them and that'll actually get you to less than a week training time which is pretty
respectable so there are a whole bunch of ways to use GPUs if I do we've been
using synchronous SGD it turns out that you've got to optimize things like all
reduce code once you leave one node you have to start worrying about your network and if you want to keep scaling
than thinking about things like network traffic and the right strategy for moving all of your data becomes
important but we've had success scaling really well all the way out to things
like 64 GPUs and just getting linear speed ups all over the way so if you've
got a big cluster available these things scale really well and there are a bunch of other solutions for instance
asynchronous SGD is now kind of a mainstay of distributed deep learning there's also been some work recently of
trying to go back to synchronous SGD that has a lot of nice properties but using things like backup workers so
that's sort of the easy thing just throw more GPUs at it and go faster one word
of warning as you're trying to build these systems is to watch for code that
isn't as optimized as you expected it to be and so this back of the envelope
calculation that we did of figuring out how many flops are involved in our network and then calculating how long it
would take to run if our GPU are running at full efficiency you should actually
do this for your network this we call this the speed of light this is the fastest your code could ever run on one
GPU and if you find that you're just drastically underperforming that number
what could be happening to you is that you've hit a little edge case in one of
the libraries that you're using and you're actually suffering a huge setback that you don't need to be feeling right
now so one of the things we found back in November is that in libraries like Kublai's you can actually use mini batch
sizes hit these weird catastrophic cases in the library where you could be suffering
like a factor of two or three performance reduction so that might take your wonderful one-week training time
and blow it up to say a three week training time so that's why I wanted to
go through this and ask you to keep in mind while you're training these things try to figure out how long it ought to
be taking and if it's going a lot slower be suspicious that there's some code you could be optimizing another good trick
that's particularly speech you can also use this for other recurrent networks is
to try to keep similar length utterances together so if you look at your data set
like a lot of things you have this sort of distribution over possible utterance lengths and so you see there's a whole
bunch that are you know maybe within about 50% of each other but there's also a large number of utterances that are
very short and so what happens is when we want to process a whole bunch of
these uh pterence --is in parallel if we just randomly select say a thousand
utterances to go into a mini batch there's a high probability that we're going to get a whole bunch of these
little short utterances along with some really long uh pterence --is and in order to make all the ctc libraries work
and all of our recurrent Network computations easy what we have to do is pad these audio signals with zero and
that lines up meaning that we're wasting huge amounts of computation maybe a factor of two or more and so one way to
get around it is just sort all of your utterances by length and then try to
keep the mini-batches to be similar lengths so that you just don't end up with quite as much waste in each MIDI
batch and and this kind of modifies your your algorithm a little bit but in the
end is worthwhile all right this is kind of all I want to say about computation
if you're if you've got a few GPUs keep an eye on your running time so that you
know what to optimize and pay attention to the easy wins like keeping your utterances together you can actually
scale really well and I think for a lot of the jobs we see you can have your
your GPU running at something like 50% of the peak and that's all in with
network time with all the bandwidth bound stuff you can actually run a two to three teraflops on a GPU that can
only do five teraflops in the perfect case so what can you actually do with
this I one of my favorite results from one of our largest models is actually in
Mandarin so we have a whole bunch of labeled Mandarin data if I do and so one of the things that we did was we scaled
up this model trained it on a huge amount of Mandarin data and then as we always do we sit down and we do error
analysis and what we would do is have a whole bunch of humans sitting around try
to debate the transcriptions and figure out the ground truth that tend to be very high quality and then we go and
we'd run now a sort of holdout test on some new people and on the speech engine itself and so if you benchmark a single
human being against this deep speech engine in Mandarin that's powered by all
the technologies we were just talking about it turns out that the speech engine can get an error rate that's down
below six percent character error rate so only about six percent of the characters are wrong and a single human
sitting there listening to these transcriptions actually does quite a bit worse it's almost ten percent if you
give people a bit of an advantage which is you going to you now assemble a committee of people and you get them a
fresh test set so that no one has seen it before and we run this test again it turns out that the two engines are that
the two cases are actually really similar and you can end up with a committee of native Mandarin speakers sitting around debating no no I think
this person said this or no they have an accent it's from the north I think they're actually saying that and then
when you show them the deep speech transcription they actually go ah that that's what it was and so you can
actually get this technology up to a point where it's highly competitive with human beings even human beings working
together and this is sort of where I think all the speech recognition systems are heading thanks to deep learning and
the technologies that we're talking about here any questions so far
yeah go ahead yep sorry yeah so the
question is if humans have such a hard time coming up with the correct transcription how do you know what the truth is and the real answer is you
don't really sometimes you might have a little bit of user feedback but in this instance we have very high quality
transcriptions that are coming from many labelers teamed up with a speech engine and so that could be wrong we do
occasionally find errors where we just think that's a label error but when you have a committee of humans around the
the really astonishing thing is that you can look at the output of the speech engines and the humans will suddenly
jump ship and say oh no no no no this each engine is actually correct because
it'll often come up with an obscure word or place that they weren't aware of yeah
so so this is a you know an inherently ambiguous result but let's say that a
community of human beings tend to disagree with another committee of human beings about the same amount as a as a
speech engine does yeah yeah so this is
a so this is using the CTC cost right that's really the core component of this
system it's how you deal with mapping one variable length sequence to another and the CTC cost is not perfect it has
this assumption of Independence baked into the probabilistic model and because
of that assumption we're introducing some bias into the system and for languages like English where the
characters are obviously not independent of each other this might be a limitation in practice the thing that we see is
that as you add a lot of data and your model gets much more powerful you can still find your way around it but it
might take more data and a bigger model than necessary and of course we hope that all the new
state-of-the-art methods coming out of the deep learning community are going to give us an even better solution okay
right
empirically determined yeah so the question is for a spectrogram with we
talked about these little spectrogram frames being computed from 20 milliseconds of audio and is that number special is there a reason for it so this
is really determined from years and years of experience this is captured from the traditional speech community we
know this works pretty well there's actually some fun things you can do you can take a spectrogram go back and find
the best audio that corresponds to that spectrogram to listen to it and see if
you lost anything and spectrograms of about this level of quantization you can kind of tell what
people are saying it's a little bit garbled but it's still actually pretty good so amongst all the hyper parameters
you could choose this one's kind of a good trade-off in keeping the information but also saving a little bit
of the phase by doing it frequently yeah
I think in a lot of the models the in the demo for example we don't use
overlapping windows they're just adjacent yeah
yeah so those results are from from in-house software it Baidu if you use
something like open MPI for example on a cluster of GPUs actually works pretty
well on a bunch of machines but I think
some of the algorithms like all reduce once you start moving huge amounts of data they're not optimal you'll suffer a
hit once you start going to that many GPUs within a single box if you use the
CUDA libraries to move data back and forth just on a local box that stuff is pretty well optimized and you can often
do it yourself okay so I want to take a few more questions at the end and maybe we can run into the
break a little bit I wanted to just dive right through a few comments about production here so of course the
ultimate goal of solving speech recognition is to improve people's lives and enable exciting products and so that
means even though so far we've trained a bunch of acoustic and language models we
also want to get these things in production and users tend to care about more than just accuracy accuracy of
course matters a lot but we also care about things like latency users want to see the engine send them some feedback
very quickly so that they know that it's responding and that it's understanding what they're saying and we also need
this to be economical so that we can serve lots of users without breaking the bank so in practice a lot of the neural
networks that we use in research papers because they're awesome for beating benchmark results turn out not to work
that well on a production engine so one in particular that I think is worth
keeping an eye on is that it's really common to use bi-directional recurrent neural networks and so throughout the
talk I've been drawing my RNN with connections that just go forward in time but you'll see a lot of research results
that also have a pass that goes backward in time and this works fine if you just
want to process data offline but the problem is that if I want to compute
this neurons output up at the top of my network I have to wait until I see the entire audio segment so that I can compute this
backward recurrence and get this response so this sort of anti causal
part of my neural network that gets to see the future means that I can't respond to a user on the fly because I
need to wait for the end of their signal so if you start out with these
bi-directional rnns that are actually much easier to get working and then you jump to using a recurrent network that
is forward only it'll turn out that you're going to lose some accuracy and you might kind of hope that CTC because
it doesn't care about the alignment would somehow magically learn to shift the output over to get better accuracy
and just artificially delay the response so that it could get more context on its own but it kind of turns out to only do
that a little bit in practice it's really tough to control it and so if you find that you're doing much worse
sometimes you have to sort of engage in model engineering so even though I've been talking about these recurrent
networks I want you to bear in mind that there's this dual optimization going on
you want to find a model structure that gives you really good accuracy but you also have to think carefully about how
you set up the structure so that this little neuron at the top can actually see enough context to get an accurate
answer and and not depend too much on the future so for example what we could
do is tweak this model so that this neuron at the top that's trying to output the character L and hello can see
some future frames but it doesn't have this backward recurrence so it only gets to see a little bit of context that lets
us kind of contain the amount of latency in the model you skip over this so in
terms of other online aspects of course we want this to be efficient right we
want to serve lots of users on a small number of machines if possible and one
of the things you think you might find if you have a really big deep neural network or recurrent neural network is that it's really hard to deploy them on
conventional CPUs CPUs are awesome for or serial jobs you just want to go as
fast as you can for this one string of instructions but as we've discovered with so much of deep learning GPUs are
really fantastic because when we work with neural networks we love processing lots and lots of arithmetic in parallel
but it's really only efficient if the batch that we're working on the hunks of audio that we're working on are are in a
big enough batch so if we just process one stream of audio so that my GPU is multiplying matrices times vectors then
my GPU is going to be really inefficient so for example unlike a K 1200 GPU this
is something you could put in a server in the cloud what you'll find is that you get really poor throughput
considering the the dollar value of this Hardware if you're only processing one
piece of audio at a time whereas if you could somehow batch up audio to have say 10 or 32 streams going at once then you
can actually squeeze out a lot more more performance from that piece of hardware so one of the things that we've been
working on that works really well is not too too bad to implement is to just
batch all of the packets as data comes in so if I have a whole bunch of users talking to my server and they're sending
me little hundred millisecond packets of audio what I can do is I can sit and I
can listen to all these users and when I catch a whole batch of utterances coming in or a whole bunch of audio packets
coming in from different people that start around the same time I plug those all into my GPU and I process those
matrix multiplications together so instead of multiplying a matrix times only one little audio piece I get to
multiply it by a batch of say four audio pieces and it's much more efficient and
if you actually do this on a live server and you plow a whole bunch of audio
streams through it you could support maybe 10 20 30 users in parallel and as
the load on that server goes up I have more and more users piling on what happens is that the GPU will naturally
start batching up more and more packets into single matrix multiplications so as
you get more users you actually get much more efficient as well and so in
practice when you have a whole bunch of users on one machine you usually don't see matrix multiplications happening
with fewer than maybe a batch sizes of four so the summary of all of this is
that deep learning is really making the the first steps to building a
state-of-the-art speech engine easier than they've ever been so if you want to build a new state-of-the-art speech engine for some new language all the
components that you need are things that we've covered so far and the performance
now is really significantly driven by data and models and I think as we were discussing earlier I think future models
from deep learning are going to make that influence of data and computing power even stronger and of course data
and compute is important so that we can try lots and lots of models and keep making progress and I think this
technology is now at a stage where it's not just a research system anymore we're
seeing that the end end deep learning technologies are now mature enough that we can get them into productions I think
you guys are going to be seeing deep learning play a bigger bigger role in the speech engines that are powering all
the devices that we use so thank you very much
I think we're right at the end of time sounds good
alright we had one in the back who's waiting patiently go ahead more than one
voice simultaneously so the question is how does the engine handle more than one voice simultaneously so right now
there's nothing in this formalism that allows you to account for multiple speakers and so usually when you listen
to an audio clip in practice it's clear that there's one dominant speaker and so
this beach engine of course learns whatever it was taught from the labels and it will try to filter out background
speakers and just transcribe the dominant one but if it's really ambiguous then then undefined results
you customize the transcription to the specific characteristics of a particular
speaker so we're not doing that in these
pipelines right now but of course a lot of different strategies have been
developed in the traditional speech literature there are things like I've Ector 'z that try to quantify someone's
voice and those make useful features for improving speech engines you could also imagine taking a lot of the concepts
like embeddings for example and tossing them in here so I think a lot of that is left open to future work I do a question
button I think we have to break for time but I'll step off stage here and you
guys can come to me with your questions thank you so much
so we'll reconvene at 2:45 for presentation by Alex

----------

-----

--09--

-----
Date: 2016.09.27
Link: [# Deep Reinforcement Learning (John Schulman, OpenAI)](https://www.youtube.com/watch?v=PtAIh9KSnjo)

Notes:
### Advantages

- General applicability to a variety of tasks and environments.
- Ability to handle continuous and complex state spaces using neural networks.
- Flexibility in learning policies for decision-making.
- Capability to approximate various components (policy, value functions) effectively.
- Potential for high performance in complex domains like robotics and game playing.

### Drawbacks

- Sample inefficiency, especially in environments where obtaining data is costly or slow.
- High variance in policy gradient methods, leading to instability in learning.
- Complexity in tuning and selecting appropriate algorithms for specific problems.
- Limited interpretability of learned policies and value functions.
- Difficulty in generalizing learned policies to slightly different tasks or environments.

### Tips and Advice

- Consider the trade-offs between policy gradient methods and Q-learning based approaches.
- Use experience replay and target networks to stabilize learning in Q-learning methods.
- For policy gradient methods, employing techniques like trust region policy optimization can enhance stability.
- Incorporate exploration strategies effectively to balance the exploitation-exploration trade-off.
- Regularly evaluate and adjust the reward function to align with desired outcomes.

### Lecture Content

- Introduction to deep reinforcement learning (RL) and its core techniques: policy gradient methods and Q-learning.
- Overview of reinforcement learning basics, including agents, environments, and the goal of maximizing cumulative rewards.
- Discussion on the applications of deep RL in various domains such as robotics, inventory management, and machine learning problems like attention mechanisms and structured prediction.
- Explanation of Markov Decision Processes (MDPs) as the foundational model for RL tasks.

### Main Challenges

- Sample inefficiency and the high computational cost of training models.
- Stability and convergence issues, particularly with policy gradient methods.
- Designing reward functions that accurately reflect the objectives without unintended consequences.
- Generalization across different tasks or slight variations in the environment.

### Importance and Usefulness

- Deep RL offers powerful tools for automated decision-making and optimization in complex environments.
- It has shown remarkable success in domains like game playing, robotics, and automated control systems.
- The ability to learn from interaction with the environment without explicit programming for each task makes deep RL a versatile approach for a wide range of applications.

### Accomplishments

- Achievements in playing Atari games and beating champion-level players at Go through deep RL methods.
- Advancements in robotic manipulation and locomotion tasks, demonstrating the practical utility of deep RL in real-world applications.

### Summary of Content

- The talk provided a comprehensive overview of deep reinforcement learning, covering its definition, applications, and core methods.
- It highlighted the advantages and drawbacks of policy gradient methods and Q-learning, providing insights into when and how to apply these techniques effectively.
- The importance of deep RL in solving complex decision-making problems was emphasized, along with notable achievements in various domains.

### Interesting Quotes/Insightful Sentences

- "Reinforcement learning is about taking the right actions to maximize a cumulative reward in an environment, making it a highly general problem-solving framework."
- "Deep reinforcement learning combines the generality of reinforcement learning with the power of neural networks, enabling us to tackle previously intractable problems."
- "Choosing between policy gradient methods and Q-learning involves balancing between sample efficiency and the ease of implementation and understanding."

Transcription:

so good morning everyone so I'm going to
talk about some of the core methods in deep reinforcement learning so the aim
of this talk is as follows first I'll do a brief introduction to what deep RL is
and whether it might make sense to apply it in your problem I'll talk about some
of the core techniques so there on the one hand we have the policy gradient
methods then on the other hand we have methods that learn a cue function
including cue learning and sarsa and I'll talk a little at the end about what
are the pros and cons of these different methods so first what is reinforcement
learning it's a branch of machine learning consider concerned with taking sequences of actions so often it's
described in terms of an age and inter interacting with the previously unknown environment and it's trying to maximize
some kind of cumulative reward some kind of reward function that we've defined accumulated over time and pretty much
any kind of task where you have some kind of goal that you want to achieve can be stated in these terms so this is
an extremely general formulation what's
deep reinforcement learning it's pretty simple it's just reinforcement learning where you're using neural networks as
function approximator x' so the interesting thing about reinforcement
learning in contrast to supervised learning is it's actually not totally obvious what you should use your neural
network to approximate in reinforcement learning and there are different kinds of algorithms that approximate different
things so one choice is to use the neural network to approximate your policy which is how the agent chooses
its actions another choice is to approximate the value functions which measure how good or bad different states
are or have or actions and last you can use the you can try to learn a model of
the system a dynamics model which will make predictions about neck States and rewards okay so I'll now give
a few examples of different different places where you might apply reinforcement learning and what the
observations and actions would be so one example is robotics so here you could
imagine a robot where the observations are the camera images and the joint angles of the robot the actions are the
joint torques you're applying and the reward is going to depend on what you
want the robot to do so so this is something we as the algorithm designer
get to define so the rewards could be to stay balanced to navigate to some target
location or something more abstract like serve and protect humans so
reinforcement learning has also been used in a lot of more practical applications
well applications that have been practical in the past I think robotics will be very practical in the future but
for example when a one area is inventory
management so this is just one example of how you could use reinforcement learning for a decision making problem
so you you have to decide how much to stock up on of every item and your
observations would be your current inventory levels actions would be how much of each item you're going to
purchase and reward is your profit so people in operations research this is
this is a subfield study this kind of problem a lot ok there are also a lot of
machine learning problems where people have started to apply reinforcement learning techniques so one example is
attention so the idea and attention is you don't want to look at the whole input at once you want to just focus on
part of it so one example of this is with a large image you might want to
just crop out part of it and use that and just do detection on that part of the image so
here your observation would be your current image window action is where to look or where to crop your image and
reward is your whether you make a classification error or not
so here the actions are trying to here
you have to try to choose the right area of the image to look at so you'll do the correct classification reinforcement
learning has also been used in structured prediction problems which
having which in the past often weren't considered to be reinforcement learning problems but it turns out that like to
actually properly solve them it actually is a reinforcement learning problem so machine translation for example you so
you get a sort a sentence in the source language and you have to admit a sentence in this target language and you
can hear your observations are the sentence in the source language you're omitting one word at a time in the
target language and you have some reward function that looks at the whole sentence and tells you how good your
translation was so since this is non differentiable and it's you yeah you
can't just like differentiate through the whole thing and do gradient descent so it turns out you have to do you can
use a policy gradient method to optimize your translation system so people have started to do that ok so that's just
those are just a few examples not exhaustive at all but I just want to
since I just want to say a little bit about how reinforcement learning fits into the fits into the picture of all
the other types of machine learning problems so previous I mean previous
courses in this series have talked about supervised learning and supervised learning so how does reinforcement
learning relate to them how is it different so let's just first compare it
to let's look at supervised learning so in supervised learning first the environment samples and input/output
pair from some distribution row the agent makes a prediction y hat using
its function f and it receives some loss which tells it if it made the right
prediction of the wrong prediction so the interpretation is environment ask
the agent a question and then tells her the right answer so contextual bandits
are make this problem a little harder in that they give the learning agent a
little bit less information so now the environment samples and input but notice
that there's not a correct output associated with it then the agent takes an action and the agent receives some
cost which is from some probability distribution so here C is the cost we're
sampling it from some probability distribution and the agent doesn't know what this probability distribution is so
that's what makes the problem hard so environment ask the agent a question the
agent answers and the environment gives you a noisy score on the answer so this
is applied this actually has a lot of applications so personalized recommendations is one big one along
with advertising so you have to decide like customers who like this
I mean you for you have a customer and you know what they liked in the past so you have to make a prediction about what
they're going to like in the future so you show them appropriate ads or links like what either
like what ad what book you want to try to advertise to them or what video you want to show them and so on so here you
can the big difference between this and the supervised learning setting is you don't have access to the function the
loss function you're trying to optimize so in particular you can't differentiate through it we don't know the process
that generates C so we can't compute the gradient of a loss function and use that to tune the agents parameters so that
makes it so that makes the problem a bit harder or you have to use a different kind of algorithm
lastly reinforcement learning is almost the same as the contextual
and it's setting except now the environment is stateful so now instead of sampling the initial state from
scratch every time step from the same distribution the state evolves over time
so you have some transition probability distribution called P here where the the
state X sub T is conditioned on the previous state and the previous action
and that makes the problem quite a bit harder because now well for a number of
reasons for one thing the inputs you're getting depends on what actions you're taking so now that makes it harder to
develop a stable reliable algorithm because now as the agent starts to learn it gets different inputs so that can
lead to all sorts of out-of-control behavior and it also means you have
delayed effects because since the system is stateful you might need to take a lot
of actions to get into the right State so you might need to you can't just act greedily every time
step you have to you have to think ahead effectively okay so just to summarize
these differences there are two differences the first one is you don't have full analytic access to the
function you're trying to optimize you have to query it through interaction second you're interacting with a
stateful world which means that the input you get is going to depend on your previous actions and if you just take
the first of those differences between supervised learning and reinforcement learning you get the contextual bandit
setting so that's sort of halfway in between okay so I realized that there
multiple this audience probably has people with different interests some people are doing research and want to
know about what's the latest in the research world and some people are want
to apply these machine learning techniques to practical applications so this slide is for the latter group of
people so if you're wondering if you have some problem where you think reinforcement learning might be relevant
and you're one if you should apply reinforcement learning so first I should say that the
answer might be no it might be overkill especially deep reinforcement learning so this is a set of fairly new
techniques where it's not going to work out of the box very well and it's these
techniques aren't that well established so they require a lot of they have a lot of knobs to be tuned so it might be
overkill and yeah these techniques aren't that well established at the moment so it might be worth
investigating some other methods first so one one so if your problem has a
small number of parameters you're trying to optimize over and you have a simulator that you can like just do lots
of experiments on then derivative free optimization methods are likely to be
better than reinforcement learning or they're likely to be easier to get working so these methods just look at
they just you give them a black box function where you put in a parameter vector and it'll give you a noisy
estimate of the score and these algorithms will just optimize over the
parameters of that black box I mean that are being put into that black box so
yeah there's a variety of different methods for derivative free optimization but these are easier to understand than
reinforcement learning and they do kind of work out of the box okay a lot of
problems are actually can be seen as content are contextual bandit problems
and the statefulness of the world isn't that relevant so for example in advertising this is where people people
look at advertising as a contextual bandit problem most of the time because you decide what ad to present the user
with and then they either click on it or they don't but it's really the user is
kind of stateful because if you show them a terrible ad they might just go and download adblock so there is like
your actions do have some repercussions but often you can just approximate it as
being a contextual bandit problem where there is no so there's a better theoretical
understanding of contextual bandit problems and methods that are that have some guarantees so in that case so if it
is a contextual bandit problem you might want to use those kind of algorithms instead and lastly the operations
research field has been using these methods for a while and real problems
and they have a set of methods which are just pretty much the basic algorithms
policy iteration and value iteration but they're sort of well they're well
developed ways of doing feature engineering for these problems that end up working pretty decently so these
techniques are also worth considering instead of trying to throw a big neural network at it okay so now well now that
I've talked about what why not to use deep reinforcement learning or what it's not good for I'll just talk about some
recent success stories and deep reinforcement learning which are achievements that probably wouldn't have
been possible using these other techniques so a few years ago there is a
pretty influential result by many at all from deep mind where they used a deep
queue learning algorithm to play Atari games using the screen images as input
and that's hard because you have these get these games or you're trying to do
different things in all these games and there some of them are kind of complicated so it's pretty remarkable that you can just use a simple but a
simple algorithm can solve them all this the same algorithm can solve them all so
since then people have also solved or solved this domain using policy
gradients and another algorithm called dagger so another big groundbreaking
result was beating a champion level player at go also by deep mind using a
combination of supervised learning from like from expert games plus policy gradients to
fine tune the supervised learning policy plus Monte Carlo tree search plus value
functions to make the search work better so a combination of techniques in reinforcement learning robotic so some
of my colleagues at Berkeley had some very nice results learning in real time how to do manipulation tasks using an
algorithm called guided policy search using the pr2 robot and some of my
colleagues and I have been working on robotic locomotion using policy gradient
methods and people have been working on
locomotion for a while and have been able to achieve pretty good results using very like highly engineered
domain-specific methods but previously there hadn't been much success using
general methods to solve it and last there have been some recent results
playing 3d games using policy gradients in fact there is even a contest I heard
about a couple days ago with this new viz Doom task which is pretty nice so
you might want to check out visit to meeeee ok so that's that's it for the
high level overview part of this now I'm going to start getting into the actual
formalism and the technical details ok
so the basic object in the field of
reinforcement learning is the Markov decision process so the Markov decision process is defined by the following
components you have a state space this is all the different states of the system the action space these are all
the actions the agent can take and you have this probability distribution which
which determines the probability of next state and reward so R is the reward s
prime is the next state SN a are the actions so it's a conditional probability distribution sometimes
people let this out into a separate reward function but that's basically an equivalent formulation okay and
sometimes there's some extra objects to find it we'll be interested in the will
consider in it an initial state distribution so this is on the world starts out in a certain state and the
typical optimization problem you want to solve given this MDP is to maximize expected cumulative reward though there
are various ways of defining that more precisely which I'll go into later ok so
there are various different settings of reinforcement learning where you define a slightly different optimization
problem the one will be most concerned with is called the episodic setting so here the agents experience is split up
into a series of episodes which have finite length so in each episode we
first sample the initial state of the world from some probability distribution view and then the agent keeps on acting
until the world ends up in some terminal state so just to give an example of what
terminal States might be like and how an episode episode ik reinforcement learning problem might look so one
example is when termination is good and you want to terminate the episode as fast as possible so if we imagine
setting up a task with some kind of taxi robot that should get to the destination as fast as possible then the episode
would be like one trip and its terminate it's trying to terminate the episode as
fast as possible another example is a
waiter robot where you have a fixed length shift but the waiter has to
accumulate it has to do as well as possible during that shift so there the episode has a fixed length the waiter
has to say maximize tips or a customer happiness and then you could imagine
another kind of task where termination is bad and you want the episode to last as long as
possible so you can view life as an example of that but also you could
imagine having a walking robot where you want it to walk as far as possible
before it falls over and in this setting
it's pretty easy to find to define what the goal is - we just want to maximize
the expectation of the total reward per episode okay and the last object we're
going to introduce here is a policy so the policy is just the function that the
agent uses to choose its actions so we have deterministic policies which are
just the policy is denoted by PI so we have the action is just some function of the state and we also have stochastic
policies where the policy is a conditional probability distribution so
here is just we're just going to make a little bit more precise on the setting of the episodic MVP so first we sample
the initial state from this distribution mu then we then we get we sample the
first action from the policy a zero from the policy then we sample next state and reward from the transition probability
distribution and so on until we reach a terminal state S sub T and then the
quantity we care about is the sum of all these rewards are 0 plus R 1 dot plus R
sub t minus 1 and we want to maximize yet so ADA is ADA of Pi is just defined
as the expected total reward of the policy PI here's the picture that
illustrates exactly the same thing so you can look at it as a graphical model
ok and lastly in the policy gradient section in particular we're going to be
interested in parameterised policies so here we have a parameter vector theta which specifies which specifies exactly
what the policy is so for sample the family of policies could be just a neural net we you have a certain
neural network architecture and theta specifies all the weights of this neural network so we could have a deterministic
policy of course or stochastic policy and if you're wondering like concretely
what where the policy look like I mean how do you use a neural network to represent your policy it's actually
exactly you do exactly the same thing you would do if this were a classification or a regression problem
so in so s here the state here is your input and the action is your output so
if you have a discrete action space a discrete set of actions then you would
use a network that outputs a vector of probabilities the probabilities of the different actions this is exactly like a
classifier and if you have a continuous action space your you would have your
neural network output the mean and the diagonal of a covariance matrix of a Gaussian distribution so this is just
like you're doing regression so you can use the same kind of architectures you'd use in supervised learning okay so
that's that's just the that's it for the formalism of MVPs so now I'm going to go
into policy gradient methods which are one broad and general class of
reinforcement learning methods which are quite effective so to give a brief
overview of this here's here's the intuition of what policy gradient
methods are going to do so here capital R means the sum of rewards of the whole
episode so our optimization problem is we want to maximize the expectation of
the total reward given our parameterised policy PI sub theta and the intuition of
how our algorithm is going to work is we we're going to collect a bunch of trajectories I mean this is just run a
bunch of episodes using our policy and then we want to make the good trajectories more probable so I mean
some of the edge trees were lucky and they were really good some of them the agent was unlucky and they are bad and the good the ones
that were good meaning there was high reward that means the agent probably took good actions there so we want to
increase the probability of the actions from those trajectories so so the most
basic version of policy gradient methods just try to make the good trajectories more probable without trying to figure
out which were the good actions in which were the bad actions slightly better methods or more elaborate methods try to
figure out which actions were good and which ones are bad and then they try to make the good actions more probable and
lastly there's another class of methods which which actually try to push the actions towards better actions so they
differentiate the loss function with respect to the actions and they try to push the actions to better actions so
we're mostly going to talk about 1 & 2 here oh there's a question oh yeah good
questions so well we're maximizing over the policy we're trying to find the best
policy but here the policy is assumed to be parametrized so there's some parameter vector theta that specifies
the policy and now we just want to maximize with respect to theta any other
questions ok so there's a very very
fundamental fundamental concept which is called the score function grading estimator which underlies policy grading
methods so actually to introduce this we're not going to talk about policies in RL at all we're just going to assume
we have some expectation we have expectation of f of X where X is sampled
from some parametrized probability distribution so we want to compute the
grading of this expectation with respect to theta so there's a general formula that will do this and the way you derive
it is you just write the expectation as an integral and then you just move some things
around you swap the integral with the derivative and you you turn it back into
an expectation and what you get at the end is this bottom line which says that you take the expectation of function
value times grad log probability so the this is an unbiased estimator of the
gradient meaning if we get enough samples it'll converge on the right thing so the way you can compute this
estimator meaning the way you can get a noisy estimate of the grading of the expectation is you just collect one you
just get one sample from this distribution and then you compute then you multiply f of X times grad log
probability so the only requirement for
being able to use this estimator is we need to be able to compute the probability density I mean we need to be
able to analytically compute it and we need to be able to differentiate it with respect to theta and often it needs to
be differentiable there's another way of
deriving it using important sampling so you write down the important sampling estimator for the expectation and then
you just swap the derivative with the expectation and you get the same thing okay so so now let me just give a little
bit of intuition about this estimator
okay so f of X is measuring how good the sample X is so that means that so G hat
here is our grading estimator meaning this is what we get if we take one sample X sub I and we compute our
estimator this is our estimate of the gradient so if we move in Direction G
hat that pushes up the log probability of our sample X sub I in proportion to
how good it is so if we have really good if we got a really good function value
then we're going to try to push up its log probability a lot and if it was a bad function value then we're not going
to try to push it up very much so pretty simple intuition the really nice thing
is this is valid even if f of X is discontinuous or if f of X is unknown
meaning you only you don't get to differentiate it you just get to see the function values or the sample space is a
discrete set so X doesn't even have to be continuous and this is quite this is
quite remarkable actually that you don't even need to have access to the full you
don't need to know exactly what the function is that you're optimizing you just have to be able to query it for the
function value and this means this is a way of being able to differentiate
functions through a system that has non differentiable pieces so for example in
in robotic locomotion one issue is that you have contacts between the robot's
foot and the ground and contact you make and break contact and that causes a
discontinuous change in the dynamics so that makes it really hard to do smooth optimization techniques to come up with
the right behavior so when you use this kind of grading estimator along with policy gradients which I'm going to talk
about very soon you can actually just differentiate you can optimize the
system even though it has differentiable pieces in it okay so okay so here's
another little picture of what's going on so we have our function f of X which
we're trying to maximize the expectation of and then we have our probability that's the DP of X so we just sample a
bunch of values from our probability density those are the blue dots on the x axis and then we so then we we look at
the function values and we're trying to push the probability distribution so
that the probability goes up at these samples in proportion to the function
value so over on the right side of the curve that means we're
trying to push that probability value up really hard and on the left side we're pushing it up softly so what's going to
happen is the probability density is going to slide to the right if you can
imagine a sort of physical analogy there okay so that's that's the score function
grading estimator this is a general technique it can be used in various
machine learning problems now we're going to apply it to the reinforcement
learning setting and we're going to take our random variable X to be a whole
trajectory so the trajectory consists of state action reward state action reward
and so on until the end of the episode and now to get our gradient estimator to
get the do to get the gradient of the expected reward all we've got to do is
compute the grad log probability times the total reward so so this probability
of the trajectory that sounds like a really unfriendly quantity because there's a long complicated process that
generates this trajectory with lots of lots of time steps but logged okay so we
can write out what this process is what this probability density is so we have it's just a product of probabilities
we've got our initials we've got our mu if s 0 which is just our initial state
distribution and then every time step we have we sample the action according to PI and we sample the next state and
reward according to our dynamics model so log turns that product into a sum and
here's the cool part everything that doesn't contain theta drops out so the
thing is we didn't know there are parts of this probability distribution P of
tau given theta that we don't have access to so if this is reinforcement learning we don't assume that we know
the dynamics model of the system we just find out about it by sampling by doing
sample doing episodes so nice so since this
product turns into a sum all the pieces like the log log P there and the log mu
which we don't know just drop out so it doesn't matter and what we get in the
end is we get a sum of log problem sum of log probabilities of actions so grad
log PI of action given State so our formula looks like our formula for the
grading of the expectation is just the expectation over trajectories of total
reward of the trajectory times grad grad of the sum of all the log probs so the
interpretation of this is we're taking our good trajectories and we're trying
to increase their probability and proportion to how good they are and you can think of this as being similar to
supervised learning where we treat the good trajectories with high rewards as positive examples in our supervised
learning problem so we're using those to train the policy on what which actions
are good we're basically treating those actions as positive examples okay now we
can improve this formula a little bit so that was just the most basic I mean this
is an unbiased estimator for the policy gradient so if we just take that expression inside the expectation on the
right hand side and we take one sample of that it has the right mean so if we
just get enough of them we're going to get the policy gradient okay so that's but we can also write down some other
formulas that have the same mean but have lower variance so we can come up with better estimators for the policy
gradient and that's actually quite important because the one from the previous slide is really bad when you
have along a large number of time steps meaning it has really high variance so
the first thing we can do is you we can use the temporal structure of the problem by the way
to derive these next bunch of formulas it just takes a bunch of really straightforward manipulation where you move around expectations and I'm not
going to go through all the math but I'll just say what the formulas are so
okay so we can repeat the same argument from the previous slide to just derive
the grading estimator for a single reward term so we end up with that reward term times the grad sum of log
probs and just summing over that we get a new formula where we're not
multiplying the sum of the the grad log probable thing times the sum of all
rewards now so let's look at that bottom formula now we have a sum over time of
grad log probability of the action at ty at that time times the sum of future
rewards um so so now I mean in the formula from the previous slide we would
have had all the rewards in that sum but now we just have the future rewards and
that kind of makes sense because an action can't affect the probability of the previous rewards so to figure out if
the action is good we should have only we should only be looking at the future rewards so this is a slightly better
formula than the one on the previous slide meaning it has the exact same mean except different the expression inside
the expectation there has lower variance and we can further reduce the variance by introducing a baseline so now we can
take any old function B which takes in a state and it outputs a real number and
we can subtract it from our sum of future rewards and we didn't affect the
mean of the estimator at all so we yeah we didn't change the expectation at all
by introducing this baseline so yeah for
any choice of B this gives us an unbiased estimator by the way if you're not that familiar with the terminology
of estimators what I'm saying is we have a expectation on the right hand side of
that for a formula and the quantity inside that expectation is what's called
the estimator and if we get a bunch of samples then we can get an estimate of of the thing on the left-hand side which
is what we care about so so when I say it's an unbiased estimator that just
means that well that just means that this equation is correct meaning that the thing on the right hand side equals
the thing on the left hand side so yeah this works for any choice of baseline
and a near optimal choice is to use the expected return so the expected sum of
future rewards and the interpretation of
that is if we took an action we only want to increase the probability of the
action if it was a good action so how do we tell if it was a good action well the sum of her words after that action
should have been better than expected so the B of S is the expected sum of
rewards and we're just taking the difference between the measured thing and the expect thing yeah okay so that's
okay that's the that was a pretty key thing for variance reduction and I'm
going to introduce one last variance reduction technique and actually all three of these are really important so
basically nothing's going to work except for maybe really small scale problems unless you do these things so the last
variance reduction technique is to use discounts so the discount factor ignores
delayed effects between actions and rewards so what we're going to do here looks kind of like a hack but there's an
explanation for it which is instead of taking the sum of rewards we're going to
take a discounted summer of rewards meaning that we we add this exponential
factor gamma so that when so when we're multiplying the grad log probability by
some future award we multiply it by some quantity that decays with time so people
typically use like equals point 99 or gamma equals point 95 so that means like if you use point 99
that means after a hundred time steps you're going to be you're going to be
reducing the reward by a factor of one over e so so you're exponentially you're
decaying the effect of the future rewards and the intuition is that an action the action shouldn't affect
rewards really far in the future like the system should this is this is like
the assumption is that the system doesn't have really long term memory and it's sort of reset sits or the there
aren't effect the effects aren't that far delayed so you can just ignore the interaction between action and a reward
way way in the future that's the intuition so now instead of
taking the baseline to be the expected sum of future rewards we want to do a discounted sum so now we're measuring if
the action was better than expected according to this like the according to the discounted sum and now there's a
more general class of formulas that looks like the one that I just wrote so this this one that's on the top of the
slide is pretty good and this is like almost as good as anything you're going to do to within a small constant factor
but there's there's a more general class of formulas that look like grad log
probability times some quantity a hat which we call the advantage estimate and
this is in general just going to be an estimate of this isn't it has a more
precise definition which is how much how like how much was this action better
than the average action taken by the policy but in but informally this just
means how much better was the action than expected so and and this formula
makes a lot of sense because we want to increase the probability of the good actions and decrease the probability of the bad ones
so we should we should increase it in proportion to the goodness of the action
okay so just to summarize so I just told you there's this gradient estimator meaning there's this expression you can
compute which gives you a noisy estimate of the policy gradient so how do you actually turn this into an algorithm so
this is silly algorithm seven so so
here's what the algorithm looks like it's pretty much what you'd expect you you take your policy you initialize your
policy parameter and your baseline function you for each each iteration you
execute the the current policy to get a bunch of whole episodes meaning whole
trajectories and each time step in the trajectory you should compute the return
meaning the sum of rewards following that time step there's some of discounted rewards and the advantage
estimate which is the sum of discounted rewards minus the baseline then you
refit the baseline by trying to make the baseline function equal of the returns and then you update the policy using a
policy grading estimator so you're just doing SGD while updating the baseline as you go along
yeah so that's that's the vanilla policy grading algorithm and this is I'll
briefly talk this has been used to obtain some pretty good results so it's not that bad of an algorithm but they're
there several different directions that it can be improved so one one issue that
you run into is with step sizes so in supervised learning step sizes aren't
that big of a deal because maybe you take too big of a step but that's okay
you'll fix it the next update and your current function your current classifier
for example doesn't affect what inputs you're getting so even if you just are doing really even if your network is
just kind of thrashing around for a while because you're taking two big steps that's not going to cause any problems but
yeah and reinforced so yeah so step sizes aren't that big of a deal you can just anneal them you can start off with
a large step size and anneal them down to zero and that works pretty well in
reinforcement learning if you take too big of a step you might wreck your policy and even if you don't actually
change the network that much so you don't lose all your nice features you
you might just change its behavior a little too much and now it's going to do something totally different and visit a
totally different part of state space so since in reinforcement learning the system is stateful and your state
distribution depends on your policy that makes that like brings a really a
different problem and now like after you took that step the next batch of data
you're going to get was collected by the bad policy and now you're never going to recover because you just forgot
everything yeah so one way that my
colleagues and I well one way to fix this is to try to to try to stop the
basically try to stop the policy from taking too big a step so you can look at
the KL divergence between the old policy and the new policy like before the
update and after the update and make sure that the distributions aren't that different so you're not taking too big
of a step it's kind of an obvious thing to do so my colleagues and I developed an algorithm called trust region policy
optimization which looks at the yeah it looks at the action distributions and tries to make sure the KL divergence
isn't too large and there's this is very closely related to previous method
natura policy gradient methods which which are based on which are doing is
something similar but usually it's not set up as a hard constraint on the KL divergence so another type of extension
of policy gradient methods is to do more to use value value functions to do more
variance reduction instead of just using them as a baseline you can also
you can use them more aggressively and introduce some bias so I won't go into
the details in this talk but sometimes these are called actor critic methods
there's also another type of approach which I briefly touched on in the earlier slide where instead of just
trying to increase the probability of the good actions you actually differentiate your loss with respect to the actions this is like the Reaper
amortization trick which is used for like for density modeling and unsupervised learning so here you're
trying to instead of just increasing the probability of the good actions you're trying to push the actions towards better actions and I'd say both of these
bullet points you're potentially decreasing your variance a lot but at
the cost of increasing bias so it's actually makes the algorithms a little harder to like to understand and to get
them working because with high variance if you just crank up the amount of data
you can always drive your variance down as much as you want but with bias even if no matter how much data you get
you're not going to get rid of the bias so if you're grading is pointing in the wrong direction then you're not going to
learn anything okay so now that that's
it for the policy gradient section of this on this talk so I wanted to show a
quick video of some work that my colleagues and I did on learning locomotion controllers with policy
grading methods which I think well I found pretty exciting when I saw it so
hopefully it's you find it interesting so here what we've got is a humanoid
simulated let's see okay yeah it's a simulated humanoid robot in a physics
simulator a realistic physics simulator called macoco and it has a neural
network policy which takes in the joint angles of the robot and maybe some and a
little bit of other kinematic formation like joint has got joint velocities and also positions of the
different links of the robot so that's what the input is it's pretty much the raw state of the robot like no clever
feature engineering there and the output is going to be the joint torques which are set a hundred times a second so
we're just mapping from joint angles to joint torques and we define a reward
function which is to move forward as fast as possible so it gets a reward for moving forward
and it gets a so the episode ends when
it its head goes below a certain height meaning it fell over so that's basically the setup there was a little bit of
tweaking for the reward function but not too extensive so oops
yeah so you can see first it just falls forward a lot of times and then slowly it starts to develop a half-decent
looking lock and eventually it gets it
down pretty well and at the very end of this it could just keep running indefinitely so I think it was actually
stable in a strong sense meaning I could just leave it for 15 minutes and it wouldn't fall over it would just keep
going so here's another robot model then we just created without too much thought
I mean we just decided to put a bunch of legs on this thing and so we don't even
know how this thing is supposed to walk and just give it to the same algorithm
and it just figures out some kind of crazy way to walk so that's the nice
thing about reinforcement learning you don't even need to know what you want it to do I think this is also the physics
are a little unrealistic here but here
we set up we use this a similar model to the one in the first demo but here we
just give it a reward for having its head at a certain height so there's the word telling it to get its head up as
high as possible and then it figures out how to get up off the ground oh let's see and I have a low battery
does anyone have a charger that I could
thanks a lot your lifesaver okay any
questions about policy gradients before I move on to the next part oh yeah so
the question was is the system time invariant yes the that's that's assumed is that it's stationary oh right and
also that it doesn't change from one episode to the next of course in some real-world problems that might not be
the case so that's I think that's also an interesting problem setting where you have a non stationary environment so the
question was for the baseline to learn a good baseline do you need to know the dynamics of the system so no you can
just learn it by doing regression you just estimate the empirical returns and
then you do regression to try to fit a function to that
yeah so the question is there's a discount factor which causes the which
should cause the policy to disregard any effects that are delayed by more than 100 time steps so how does it still work
that this guy learns how to stand up even though that might take more than 100 time steps is that correct yeah so
yeah you're right and in fact I would say that these methods aren't guaranteed to work well
if you have more than 100 time steps so sometimes they work anyway often they
work anyway but there's no guarantee so I think there's actually something pretty fundamental missing and how like
how to deal with really long timescales and people have recently been thinking about hierarchical reinforcement
learning where you have different levels of detail of the system where you might
have a like one level of description where you have a like a short time small
time step and then you have successively larger time steps and you can that allows you to plan over much longer
horizons so that's something that's currently an active area of research but yeah I would say that none of these
methods are going to do it are guaranteed to do anything reasonable if you have more than one over one minus
gamma time steps between action and reward oh yeah so in this kind of task
if you introduced terrain or something could I think if it didn't if you didn't
train it to deal with terrain then it then it might fail it probably would failed actually I don't think it would
fail because the funny thing about these policies are actually really robust because you train them with the
stochastic policy so there's a lot of noise being generated by the policy itself so in practice it's it's actually
so it's able to deal with huge noise introduced by the policy and as a result I found that if you change the dynamics
parameters a little it usually still work but yeah there's no guarantee that they'll do anything if you give it
something you didn't train it for I think that you probably could train it do the same kind of training with
terrain I didn't have any terrain so I didn't try it but I'd be nice to try ok
I'm going to move on to the next part of the talk feel free if you have more questions to find me afterwards
okay so now I'm going to talk about a different type of reinforcement learning algorithm so okay so these so the
previous kind of methods are distinguished by the fact that they learn they explicitly represent a policy
which is the function that uses your actions and they try to optimize it with respect to the parameters of the policy
so the nice thing about the policy grading methods we just talked about is that you're optimizing the thing you
care about so and you're optimizing it with gradient descent so that makes it
kind of easy to understand what's going on because if you take if you're getting the proper grading estimate and you take
small enough steps then you should be improving I mean of course you still could get stuck in a local minimum but
at least you get stuck in a bad local minimum but at least it's a local minimum and you can use the our
understanding of optimization to figure out what's going on so these next class
of methods are a little different because they're not optimizing the policy directly they're learning
something else called the cue function which measures how good state action
pairs are so it measures I'll say that more formally late later but it's just
measuring how good the actions are and these methods are actually the these are
able to exactly solve em DPS efficiently in the setting where you have a finite
number of states and actions so these are these are the preferred methods for exactly solving them in those settings
but you can also apply them with continuous States and actions and using
using expressive function approximator is like neural networks but it's a
little harder to understand what's going on in these methods like when they're going to work and when they're not going
to work so I'll define the relevant
quantities here so the Q function is defined as these expected sum of rewards
when we condition on the first state and the first action so
we're conditioning on s0 equals s a0 equals a and we're we're and the Q
function is the expected discounted sum of rewards when we're acting under the policy PI so by convention I'm starting
out with time step 0 I could have also said that we're taking RT plus RT plus 1
plus RT plus 2 and so on but since we're assuming the system is stationary it
should be exactly the same so I'm just by convention I'm going to say that the first I'm going to always use time 0 1 2
3 and so on just for ease of notation so the Q function is just telling you how
good in this state action para is under your current policy the value function
well the state value function usually called V is just conditioning on the
state it's telling you how good that
state is what's the expected reward at that state and lastly there's an it the advantage function is the difference
between the Q function in the state value function meaning how much better is that action than what the policy
would have done we're not going to talk about advantage functions in this section but it was actually this
corresponds to the notion of an advantage estimator we briefly mentioned in the previous section so here we're
going to consider methods that explicitly store and update the Q function instead of the policy and
updates them using what are called bellman equations so so the bellman
equation so a bellman equation in general is a consistency equation that should be satisfied by a value function
so here I'm writing down the bellman equation for Q PI and what it's saying
is that the expected sum of rewards should be the first reward plus this
expected sum of rewards after the first time step so it's saying something pretty simple that's so R 0 is the first reward
beep I of s1 is just adding up all the rewards at after at after time step 0 so
in the second equation we write out this relationship just involving the Q
function so we have a consistency equation that the Q function should satisfy we can slightly generalize this
to use K time steps instead of just one time step so we can expand out the
expectation the expected sum of rewards to write write out k rewards explicitly
and then cap it off with the value function at the very end which accounts for all the rewards after that okay so
here's the bellman equation from the previous slide so now I'm going to introduce a very important concept called a bellman back up so so we have
this equation that the value the value function Q PI should satisfy but we
don't know Q let's assume we don't know Q PI so let's say we have some some
other Q function so we define this bellman back up operator that that
operates on an arbitrary Q function so an absolute Q function to a new Q function and it's defined by just taking
the right-hand side of the bellman equation and plugging in our Q function
our new Q function Q instead of the Q PI
so Q PI is a fixed point of this operator meaning if we apply the backup
operator we get it the same thing back and and very nicely if we keep applying
this backup operator repeatedly to any old arbitrary initial Q function Q the
series will converge to Q Pi which is the fixed point of the operator so that's yeah so that's so that way you
can you can one way you can use an iterative
algorithm to estimate q pi by taking any old initial q function and repeatedly
applying this backup operator so now there's another kind of q function that
we're going to introduce call it Q star so the previous Q function q pi was this
is the telling you the value function under the current under some policy pi so it only makes sense with regard to
some particular fixed policy PI Q star is going to be it is going to involve
the optimal policy instead so so Q star is just defined as the q function of the
optimal policy so here we have PI star the optimal policy and Q star is just the q function of the optimal policy and
it also happens to be the point wise maximum over all policies of the q
function at each state action pair so so
the optimal policy is deterministic and it should satisfy this equation that it
takes the Arg max of the optimal q function so recall that the Q function tells you your expected return if you
take the given action so obviously the optimal policy should take the action
that has the best expected return so that's why that's why this last equation
is evident so so now now that we know
this property of the optimal policy we can rewrite the bellman equation so so
on the first equation is that's just the bellman equation from the previous slides for a given policy PI now we can
take that expectation over actions and replace it by what the optimal policy is going to do which is just going to take
it's going to take the Arg max of the optimal q function there's a typo on my
slide that should say Q star inside on the right-hand side so so now we have a
bellman equation that the optimal policy should satisfy now we can do the same thing with a
backup operator so we we take that bellman equation and we plug in an
arbitrary Q function on the right-hand side instead of the optimal Q function Q star so Q star is a fixed point of this
bellman operator that's just a restatement of the bellman equation and
again if we reply this bellman operator repeatedly to an arbitrary initial Q
function it converges to Q star which is the optimal Q function this is the
binocs fixed point theorem in both cases can be used to prove it okay so based on
these ideas there are two classic algorithms for exactly solving MDPs these are sometimes called dynamic
programming algorithms because they're actually quite related to the kind of dynamic programming algorithms that are
used to solve search problems so one is
called value iteration and you just initialize your Q function arbitrarily and you repeatedly do bellmen backups
until it converges now the second one is
called policy iteration you initialize your policy arbitrarily then each step
you first can compute either exactly or approximately the Q function of that
policy and then you update your policy
to be the greedy policy for the Q function you just compute it so that means that you your new policy just
takes the Arg max of the Q function so it takes the action that's best according to that Q function so I didn't
say anything about how you compute Q PI so one way to do it is to compute it you can compute it exactly because it
happens that the bellman equation for Q Pi is a linear system of equations so often you can just solve them exactly
more commonly well if you have a large-scale problem you might not be able to solve this system
so what people often do is they do a finite number of bellman backups which
gives you which doesn't exactly converge on Q pi but it gives you something that's approximately q pi okay so that's
I just told you algorithms that you can implement if you have full access to the MDP like you know the whole table of
probabilities but in reinforcement learning usually the assumption is that you don't know any of these probability
distributions you don't know they're a word function you don't know the transition probabilities so all these things have to be estimated from data or
they have to or you're only able to access the system through interaction so now it turns out that these algorithms
can be also implemented if you only access the system through interactions which is kind of remarkable I think um
so so the way it works is so let's recall our backup formulas for Q PI and
Q star so we can so we can in both cases
we have this a certain quantity inside and expectation in both both cases we
can compute an unbiased estimator of the right of that quantity inside the
expectation just using a single sample meaning if we have if we sampled some
data from our system using any old policy then we can get an unbiased
estimator of the quantity on the right hand side of those expectations I mean
the quantity on inside of the right hand expectations so basically we can do an
approximate version of this bell minim backup which is unbiased and even with
this noise so we're doing a noisy version of the bellmen backup even with this noise it can be proven that if you
do if you choose your step size appropriately with the right schedule you're still going to converge to q pi
or q star depending on which algorithm you're implementing
okay so now well I'll say at this point that this is pretty much the fundamental
idea and now you can you can come up with algorithms that can be applied in
the reinforcement learning setting where you're just accessing the system through sampling and you can also start
introducing function approximation here so in seventh said anything about what
the Q function is I've just told you it's a function of state and action but now we can start having neural network
cue functions for example so so we can
parametrize the Q function with the neural network let's call it Q theta and
now instead of doing the bellmen backup I mean it doesn't make sense to do the
bellmen backup exactly because we're not just setting the values of the neural network output the best we can do is try
to like encourage the neural network to have some output values so what we do is
instead of doing the the way we do this backup is we set up a least squares problem so we write down this quadratic
objective that says that the Q function should be approximately equal to the backed up value and then we just
minimize it with SVD so one version of
this algorithm which was introduced about ten years ago called neural fitted Q iteration well it works exactly the
way you'd expect use sample trajectories using your current policy which might be
determined by the Q function or it could be any old policy as it turns out and
then you you solve the least squares problem where you're trying to minimize
this quadratic you try to minimize this quadratic error which is based on the
bellmen backup the backup for Q star so
one thing I haven't mentioned so far is what do you actually use as your policy so I said sample trajectory using your
policy so if you have a Q function you can turn it into a policy by just taking
the action that has the highest Q value that's what you typically do so the Q function measures the goodness of
all your actions so you can easily turn that into a policy by taking your best action or by taking actions where the
log probability is proportional the goodness or something like that so you
you might take typically probability as is exponential of Q value over some kind
of temperature parameter that's called Boltzmann exploration whereas if you use
just the greedy if you just take the Arg max that's called the greedy policy so
it turns out that with these kind of Q learning algorithms you don't have to execute the greedy policy to for
learning to work there's you actually have some freedom in what policy you can execute which is actually one very nice
property of these algorithms that you can use an exploration technique which
where your policy is actively trying to reach new states or do something new and
still learn the correct still converge still move towards Q star or q pi as the
case may be okay so that's so that's a
very basic neural fitted Q iteration is sort of a basic way of doing this a more recent algorithm that's gotten a
lot of attention is the one that was from Mini at all from deep mind which is
basically an online version of this algorithm with with a couple of useful
tweaks in it so and but actually when you look at the two tricks they're
actually kind of very they make a lot of sense if you just think about what value
iteration is doing so one one technique is you use this replay pool where it's a
rolling history of your past data and that's just the data you're going to use to fit your Q function so that makes
sure you have like a representative sample of data to fit your Q function to
and the second the second idea is to use a target network so instead of using
your cute current Q function and just doing bellmen backups on that you have
some lags version of your q function so you have this target network which is a copy of your cue function at some
earlier time and you use that in the backups so that also if you think about value iteration you're trying to you
have your old cue function and you're trying to make the new one equal to the backed up version of the old one so using the target network just is sort of
the natural thing to do if you're trying to implement value iteration in an online way so and there have been many
extensions proposed since then I've got a bunch of citations at the bottom of the slide so this algorithm the dqn
algorithm is is using the backup B which
is the backup for Q star remember that I also introduced this other backup B PI
which is the backup for Q PI so so there's another algorithm like a very
classic algorithm called sarsa which is an online way of doing the B PI backup
essentially well it's sort of an online version of policy iteration but so it's
it's actually found to work as well or better than DQ a well better than using
the B back up in some settings not all settings so I think the jury's still out
on exactly how these things compare but it's I think it's worth considering both
policy iteration and value iteration and and all the different online versions these algorithms and taking them
seriously because it's not clear right now exactly which are how they all
compared each other in the function approximation setting okay so that's
that's the overview of all the technical parts and now I just have a couple
conclusion slides so so let me just summarize the current state of affairs I
introduced two kinds of algorithms policy grading algorithms which explicitly represent a policy and
optimize it and Q function learning algorithms which explicitly represent a
Q function which is the goodness of different actions and use that to implicitly represent a
policy so so policy grading methods there's a lot of so there have been some
successes with different kinds different variants of it so you have vanilla policy grading methods there is a recent
paper on this a three C method which is an async of implementation of it which
gets very good results there's also another kind of methods are the natural
policy gradient methods trust reagent methods so the video I showed you was obtained using trust region policy
optimization which is one of these in the second category so that makes it I think these trust region methods net and
natural policy grading methods are more sample efficient than the vanilla methods because you end up you're doing
more than one grading update with each little bit of data you collect so with the vanilla policy gradient you just
compute one little grading estimate and then you throw it away with natural policy gradient you're solving a little
optimization problem with it so you get more juice out of it so that's that's
what we have in the policy gradient world and in the Q function world we
have the DQ n algorithm and some of its relatives and these are sort of
descendants of value iteration where you're approximating the bellmen back up
using value iteration and then sarsa is also it's related to policy iteration
these are both different I mean these are estimating different they're dealing
with different bellman equations so it's kind of interesting that both kinds of methods work and they all they're both they have fairly similar behaviors as it
turns out so here's what I would say that here's how I would compare them and
this is like anecdotal evidence but I think this is the consensus right now
the q function methods are more sample efficient when they work but they don't
work as generally as policy grading methods and it's a little harder to figure out what's going on when they don't work and
that kind of makes sense because in the policy gradient methods you're optimizing exactly the thing you care about with gradient descent
whereas with cue function methods you're doing something indirect where your Optima you're trying to learn a cue
function and then you're hoping that it gives you a good policy and yeah so I
would also point out that there there are also some confounds so it's hard to make a good conclusion at this point
because people use different like time horizons in the policy gradient methods
versus the cue function methods so they do one step look Ahead's on the cue functions and multi-step look Ahead's on
the policy gradients so it's not clear if the extra if the differences come from like using different time horizons
or some differences in how the algorithms are working because you're
either doing regression for a cue function versus learning a policy using
policy grades so just to summarize it I would say here here are some of our core
model free reinforcement learning algorithms and they are whoops I'm
missing a word in the first column which I think should say wrote like
reliability and robustness so this just means like is it going to work on new
problems without like without parameter tuning or is it you're going to
mysteriously either work or not work so this this would be my slightly sloppy
summary of all these different algorithms I would say there's still
some room for improvement there might be some improvements in the basic methods because there are some nice properties
of the Q function methods that we don't have in the policy gradient methods like you can easily do off you can easily
explore with a different policy than the one that you're learning the Q function for and that's really important you
can't do that very easily with policy gradient methods whereas the policy
grading methods just seem like they're more you can just apply them in there like more likely to work and it's well
understood what's going on so I think yeah there's still I don't know if it's possible to get the
best of both worlds but that's that's the hope and that's it for my talk thank
you
any questions
oh yeah so in model-based reinforcement
learning what lines of research do I find most interesting i think the work
for my colleagues on guided policy search is very nice so i would say that's the kind of model-based reinforcement learning I also like there
are some methods that are using the model for faster learning like for variance reductions so there's a paper
called stochastic value gradients that I like a lot I think it's a pretty wide
open area so I don't think there have been a lot of really compelling results
where you're able to learn extremely fast like you're able to learn with much
better sample efficiency using a model so it seems like that should be possible but I don't think it's been demonstrated
yet so maybe in the next couple years we'll see that happen hello hi thanks
for the talk so I have a question is that is it true or not true that most of this problem requires some kind of
simulated well to to run experiments in the episodes right oh yeah so are you
asking does this work in the real world is that the question organs yeah I would
say it does work if you have a lot of patients and you're willing to execute
this thing for a while so the locomotion results I should add up to about two
weeks of real time so it's actually not that bad especially when you consider the babies toddlers take awhile to learn
how to walk properly even though evolution already puts in a lot of built-in information so I'd say
maybe yeah I'd say it's it can be run in the real world some of my colleagues in Berkeley are doing some experiments
where they are running just regular reinforcement learning algorithms in the real world very brave but I hope to see
some nice results from that soon thank you hi thanks for talking here on the other
side here I was wondering what was your intuition on the lost surface of those
deep reinforcement learning optimization problems and maybe especially how it
evolves in the from the as the policy learns and I should specify in the
policy gradient case so I think the situation is a little bit different in
reinforcement learning from a supervised learning so in reinforcement learning the loss you have you have one kind of
local minima in policy space so for
example let's say you want your so I'm going to keep going back to the locomotion example because I spent a lot
of time on it but let's say you want your robot to walk there's one local minimum where it just stands and it
doesn't bother to walk because there's too much penalty for falling over and there's another local minimum where it just dives forward because it gets a
little bit of reward for that before it falls to its doom so so even so I think
that that's actually the the hard part about the like the optimization problem
is actually define is because of the different space of behaviors and actually has nothing to do with the
neural network so I've also found that yeah it matters surprisingly little what
kind of architecture you use like what kind of neural network architecture you use because I think that most of the
hardness and the weirdness of the problem comes from like what the behavior space looks like rather than
what the actual numerical optimization landscape looks like OOP thank you so
there are many problems where the reward is only observed at the end of the task
so in the final in the terminal State in each episode and you don't see rewards
and intermediate states so how much harder to these problems become for deep reinforcement learning experience Thanks
yeah so you have if you don't get the reward until the end then then you can't
well then it's probably it might be harder to learn yeah I I don't have anything anything precise to say about
that I think it's going to be harder if you have less if your rewards are further away so for example for your in
your video for the last example of getting up and getting the head above a certain height yeah or example that
could be one where you only get a plus one if you're above and you don't get anything below all right doing something
that was kind of if you get your head higher then you still get something partial yeah so I think we came up with
a reward like distance from height squared which made the problem easier yeah the problem would have been a lot
harder if you get zero reward until you get your head above the height um and it's actually that would be a problem of
exploration which is that you have to explore all the different states people
to figure out where you're going to get good reward Thanks okay one last
question so I have a question about how do you choose to quantize the space-time
because in your locomotion example you clearly has the continuous system right
yeah so it's actually really important how you discretize time like what time step you use because if because the
algorithm has I mean the algorithm does care about what the time step is so it's
not like yeah because you you have discount factors and you're also
sampling a different action at every time step so yeah so if you choose too
small of a time step then you then the rewards will be delayed by more time
steps so that makes the like the credit assignment harder and also your
exploration will be more like a random walk because you're changing your minds really frequently so yeah the time step
is pretty important and I'd say that's that's a flaw in current methods okay
thank you
thank you so take a short break reconvene in 15 minutes

----------

-----

--08--

-----
Date: 2016.09.27
Link: [# Theano Tutorial (Pascal Lamblin, MILA)](https://www.youtube.com/watch?v=OU8I1oJ9HhI)

Notes:
#### Advantages:

- Tiano allows for easy manipulation of mathematical expressions using numpy syntax.
- Supports basic to complex mathematical operations and neural network architectures.
- Enables automatic and symbolic differentiation, optimizing for numerical stability and speed.
- Provides tools for debugging and code inspection.
- Has a global user and contributor base, driving research and industrial applications.
- Serves as a foundation for other software projects and machine learning libraries.

#### Drawbacks:

- The learning curve for understanding and using symbolic expressions and graph optimizations effectively.
- Dependency on Python for execution, complicating the distribution of models without requiring Python installation.

#### Tips and Advice:

- Utilize Tiano's GPU capabilities for improved performance, especially with float32 or float16 data types.
- Explore Tiano's debugging and diagnostic tools for better understanding and troubleshooting of models.
- Consider using docker containers for distributing models to alleviate the need for Python and compilers on the user's end.
- Engage with the Tiano community through mailing lists and Stack Overflow for support and feedback.

#### Lecture Content:

- Introduction to Tiano's concepts and capabilities.
- Practical examples demonstrating logistic regression on MNIST dataset, LinNet architecture, and LSTM for character-level text generation.
- Advanced topics like scan for loops in graphs, visualization, and debugging tools.
- Discussion on new features, optimizations, and future directions for Tiano.

#### Main Challenges:

- Mastering the symbolic expression system and graph optimizations for efficient model development.
- Navigating the complexities of GPU acceleration and memory management.
- Debugging and optimizing Tiano code for performance and accuracy.

#### The Importance and Usefulness of the Topic:

- Understanding Tiano is crucial for researchers and practitioners in machine learning and deep learning for developing, debugging, and optimizing models.
- The ability to use GPUs and perform symbolic differentiation significantly accelerates the experimentation and development process.

#### Accomplishments:

- Tiano has contributed to numerous research papers, prototypes, and industrial applications.
- The development of a vibrant ecosystem of libraries and tools building on Tiano.

#### Summary of the Content:

- The lecture provided a comprehensive overview of Tiano, covering its principles, advantages, practical applications, and troubleshooting methods. Through hands-on examples, the lecture demonstrated how to implement and optimize various neural network models using Tiano.

#### Interesting Quotes or Insightful Sentences:

- "Tiano is a mathematical symbolic expression compiler."
- "Automatic differentiation changes the game for neural network training."
- "Debugging in Tiano: Connecting execution errors back to their symbolic origins."
- "With Tiano, the power of GPUs is unleashed for deep learning."


Transcription:

okay so today I'm going to briefly introduce you tno how to use it and go
over the basic principles behind the libraries and if you paid attention during yesterday's presentation of
tensor flow some concepts will be familiar to you as well and if you paid
attention to you go lava Shell's introduction area talk you'll see some
some serie concept as well so there's going to be four main parts so the first
one is well this slide and introduction about what the concept of Tiano are
there is a companion ipython notebook that's on github so if you go on that
page or clone that github repository there is an eye Python notebook that
basically has all the code snippets from these slides so that you can run them at
the same time then we're going to have a more hands-on example basically applying
logistic regression on the Emnes digits data set and then if we have time we'll
go quickly over to more examples concepts so the basic Linette
architecture and an STM for character level generation of text so Tiano is we
can say mathematical symbolic expression compiler so what does that mean it means
that it makes it possible to define expressions that represent mathematical
expression using numpy syntax so it's
easy to use and it supports all the kind of basic mathematical operations like
main max addition subtraction all the kind of basic things not only larger
blocks like layers of neural nets whole networks or things like that it
makes it possible to manipulate those expressions during rough substitutions
cloning and replacement things like that and also making possible to go through
that graph and perform things like automatic differentiation a symbolic
differentiation actually all the our operator for forward differentiation
applying some optimizations for increased numerical stability and then
it's possible to use that optimized graph and the Endo's runtime to actually
compute some values some output values even inputs we also have a couple of
tools that help debug both pianos code
and the users code and try to inspect and understand better what's actually happening when you're using Tianna
so when I was currently more than 8 years old it started small with only a couple of
contributors from the ancestor of Mila and which was called Lisa at the time
and it grew a lot we now have contributors from all over the world users from all over the world
and it's been used to drive a lot of research papers prototypes for
industrial application in startups and in larger companies tno has also been
the base of other software projects that build on top of the nose so for instance
blocks Kara's Lezyne our machine learning deep learning libraries that
used ya know as a back-end and provides user interface that is a higher level so
that has concepts of layers of training algorithms of this kind of things
whereas ya know is modern backends SK don't ya know as well which is nice
because it has a converter to load cafe models from the cafe zoo and use them in
Tiano and does a lot of other things as well pi MC 3 actually uses t anode not to do
machine learning but for ballistic programming and we have two other
libraries platoon that Mira is developing and TN o MP I developed a 12
with our layers on top of T and O to help train on multiple machines multiple
GPUs and have some level of model parallelism and data parallelism so how
to use TN well first of all we are working with symbolic expression
symbolic variables so that will make up
a computation graph so let's see how how to do that so to define the symbolic
expression so we defined the expression first then we want to compile a function
and then execute that function on values so to define the expression we start by
defining inputs so the inputs are symbolic variables that have some type
so you have to define in advance whether like this variable is like a vector or
matrix what's its data type is floating-point integers and so on so things like the
number of dimensions have to be known in advance but the shape is not fixed the
memory layout is not fixed so you could have shapes that change between like 1
mini-batch and the next or different calls to do to the function in general so x and y are purely symbolic variables
here we will give them values later but
for now that's just that's just empty there's another kind of input variables
that is share variables and they they're symbolic but they also hold
a value and that value is persistent across function calls it's shared
between different IANA functions it's usually used for instance for storing
parameters of the model that you want to learn and yet these values can be updated as well so here we create two
other variables from social variables from from values this one has two
dimensions because its initial values after dimensions and this one has only
one so that's basically weight matrix and the bias we can name variables by assigning to the name attribute short
variable do not have a fixed side either there are usually kept fixed in most
models but it's not a requirement then from these inputs we can define
expressions that will build new variables intermediate variables which are the result of some computation and
so for instance here we can define well the product of X and W at the bias apply
sigmoid function on that and they say this is our output variable and from the
output Y ball and Y we can define just say the squared error cost so those new
variables are connected to the previous ones through the operations that we define and we can visualize the graph
structure like that by using for instance by dot print which is a helper function so variables are those square
boxes and we have other nodes here we call apply nodes that represent the
mathematical operation that connects them so input variables and shared
variables do not have any ancestors they don't have any road connecting from them
but then you see that intermediate result and and more of them
usually when we visualize we don't necessarily care about all the
intermediate variables unless they have a name or something and so this is a simplified version of exactly the same
the same graph where we hide the unnamed intermediate variables but you can still see all the operations and actually you
see that the type on the edges so once
you have defined some graph say your forward computation for your model we
want to be able to use back propagation to to get your idioms so this is just
the basic concept of the chain rule we have a scalar crossed we have
intermediate variables that here are vectors here's just the general starting
from the from the cost and so the whole
derivative of say that that function G is actually a whole Jacobian matrix
that's M by n if the intermediate variables are vectors of size N and M
and usually you don't need that and it's actually usually a bad idea to compute
it explicitly unless you need it for some other purposes what the only thing you need is an expression that given any
vector representing the gradient of the cost with respect to the output will
compute you the gradient of the cost with respect to the input so basically
the dot product between that vector and the whole Jacobian matrix so that's also
called the L operator sometimes and so almost all operations in Tiano implement
a function that returns that and it
actually returns not numbers not a numerical expression for that but it
returns a symbolic expression that represents that computation
again usually without having to explicitly represent or define that
whole Jacobian matrix so you can call
Tia no grant which will back propagate through the graph from the cost towards
the inputs that that you give and along the way it will call that grad method of
each operation back propagating means starting from one for the cost and back propagating through the whole graph
accumulating when you have the same variables that used more than once and
so on and again here so DCW and this is DB they are symbolic expression the same
way as if you had manually defined the gradient expression using T&O operations
like the dot product the sigmoid and so on that we that we've seen earlier so we
have non numerical values at that point and they are part of the computation
graph so the completion graph was extended to add these these variables
and we can continue extending the graph from these variables for instance to
compute update expressions corresponding to gradient descent something like that like we do here so for instance this is
what the extended graph for the gradient looks like so you see there's like a lot
of small operations that have been inserted and outputs you have actually
here the gradients with respect to the bias which is both an output and an
intermediate result that will help compute the gradient with respect to the
weights and here's the graph or the
update expressions so you have as intermediate as intermediate variables
the gradients that we had on the previous slide and then this uses the scaled version
with constant 0.1 that's somewhere so
once we have defined the whole graph the whole expression that we actually care
about from the input and initial weights to the weight updates for our training
algorithm we want to compile a function that we'll be able to actually compute
those numbers given inputs and perform the weight updates so to compute values
what we do is called Tiano dot function and you provide it with the input
variables that you want to feel and the output variables that you want to get and you don't have necessarily to
provide values for all the inputs that you might have declared especially if
you don't want to go all the way through the end of the graph you can have a
function that only computes sub set expression for a subset of the graph for
instance we can have a predict function here that goes only from X to out we don't need values from Y we don't need
and so the gradient and so on will not be computed it's just going to take a
small part of the graph and make a function out of it so so that's it you
can first compile it get value and call it so you have to provide values for all
the input variables that that you define you don't have to provide values for
shared variables W and B that we declared earlier there are implicit inputs to all the functions and their
value will automatically be be fetched when it's needed can declare other
functions like monitoring function that computes both the output and the cost so
you have two output you also need the second input Y you can compute the
function that does not start from the beginning like for instance I want an error function that only computes the
the mismatch between the prediction and the actual targets then I don't have to
start from the input I can just start from the prediction and compute the cost
then the next thing that you might we want to do is update your Bibles for
training it's necessary and again you can pass duty and functions updates a
list of updates and updates are pairs of shared variable and the symbolic
expression that will compute the new value for that shared Bible so you can
see a big W and up they'd be here as implicit outputs of the function like W
and B were implicit inputs update W update B are implicit outputs that will compute it that will be completed at the
same time as C and then after all the outputs are computed the updates are
actually effective and the values are updated so here if we print the value of
B before and after having calling after
having called the same function then we see the value has changed what happens
also during graph compilation is that the graph that we selected for that
particular function gets optimized and what we mean by that is that it's going
to be rewritten in parts there are some expressions that will be substituted and so on and there are different different
goals for that some are quite simple that for instance if we have the same computation being
defined twice we only want it to be executed once if you have expressions
that are not necessary you don't want to compute them at all for instance if you have X divided by X you don't know and
and X is not used anywhere else we just want to replace that by one there are
numerical stability optimizations for instance well log of one plus
can under fill' if X is really small and this would give 0 whereas which would be
close to X things like log of softmax get optimized into more stable locks of
Max operation it's also the time where in place and destructive operations are
inserted for instance if an operation is the last to be executed on some numbers it can instead of allocating output
memory I can just work in place on its input and so on also the transfer of the
graph expression to the GPU is due is done during the optimization phase so by
default Kanno tries to apply most of the optimizations so that you have the run
time that's almost as fast as possible except for a couple of checks and assertions but if you're iterating and
want fast feedback and don't care that much about Timothy about the runtime
speed then you have a couple of ways of enabling and disabling some set of
optimizations and you can do that either globally or function by function so to
have a look at for instance what happens during the the graph up to my different
phase here's the the original and optimized graph going from the inputs X
and W going to the output prediction it's the same one that we've seen before
and if we compare that with the function the compile function that goes from
these input variables to out which was called predicts this is what we have I
won't go into details about what's happening in there but here you have a gem G operation which basically calls an
optimized Blas routine that can also
do multiplication and accumulation at the same time we have a sigmoid
operation here can will work in place destructively on its input which is
denoted by the red arrow here if you have a look at for instance the
operation optimized graph completing the expression for the updated W and B this
was the original one and the optimized one is much smaller
it has also in place operations it has fused LM wise operations like for
instance if you have a whole tensor and then you do an element-wise a addition
with with a constant and then a sigma eight and then something else and so on you want to only loop once through the
array and apply all these carrier operations on each element and then go
to the next and so on and not iterate each time that you want to apply a new new person and those kind of things
happen often when you have automatically generated gradient expressions oh and
here you see the update for the shared eyeballs which are inputs so you see the
cost and the implicit outputs for the updated wnb here and here another
graphitization tool that exists is the back print which basically prints
text-based tree like structure of of the graph assigning arbitrary ids and
printing the variable names and so on so
here you can see more in detail like what the structure is and you see the
inputs of gmv and the scaling parameters and so on so when the function is
compiled then we can actually run it so T no function is call a ball python
objects that that we can that we can call and we've seen those examples
here for instance where we call train and so on but what happens to have say
optimized run time it's not only the degree of optimizations but we also
generate C++ or CUDA code for instance for the LMS loop fusion that I mentioned
we can't know in advance which elementwise operation will be will occur
in which order in any drive that the user might define so we have on-the-fly
code generations for that you generate Python module written in C++ or in CUDA
that gets compiled and imported back so that we can use it from Python the
runtime environment then calls in the
right order the different operations that have to be executed from the inputs to the outputs so that we so that we get
the desired results we have a couple of different ones and in particular there's
one which was written in C++ which avoids having to switch contacts between
the Python interpreter and the C++ execution engine something else that's
really crucial for speed and performance is GPU so how to use a GPU in TN oh we
wanted to make it as simple as possible in usual cases so now it supports a
couple of different data types not only float 32 but double precision
if you really need that integers as well and we have now easier interaction with
GPU arrays from Python itself so you can just use Python code to handle GP arrays
outside of a Tiano function if you'd like all of that he will be in
future 0.9 release that we hope to get out soon and to use it well you select
the device that you want to use the primary device that you want to use with
just the configuration flag for instance you could to get the first GPU that's
available or one specific one and if you specify that in the configuration then
all share variable will by default be created in GPU memory and the
optimizations that move the computation from CPU to GPU so that replace the CPU
operation by GPU operations are going to be applied usually you want to make sure
you use 432 or even float16 for storage which is experimental but because most
GPUs don't have a good performance for for for double precision so how you set
those configuration flags you have in order that you never see configuration
file that you can it's just basic configuration file from for for Python
you have an environment variable where you can define those and the environment variable overrides the config file and
you can also set things directly from Python but some flags have to be known
in advance before you know is is imported so for instance the device
itself you have to set it either in the configuration file or throw flags
so I'm going to quickly go over more advanced topics and if you want to learn
more about that there's other tutorials available online and there's a documentation on the planning up net so
to have loops in the graph we've seen that the expression graph is basically a
directed acyclic graph and we cannot have loops in there one way if you know
if you know in advance the number of iterations it's just to unroll the loop use a for loop in Python that builds all
the nodes for all the time steps it doesn't work if you want for instance
to have dynamic no dynamic size for the
loop for models that generate sequences for instance it can be an issue so what
we have for that in India know is called scan and basically it's one node that
encapsulate another whole T&O function and that the end of function or step
function is going to compute the is going to represent the computation that
has to be done at each time step so you have at the end of function that performs the competition for one time
step and you have the scan node that calls it in the loop taking care of the
bookkeeping of indices and sequences and feeding the right slice at the right point and feeding back the outputs where
needed and having that structure makes it also possible to define gradient for
that node which is basically another scan node another loop that goes backwards and applies back drops with
time and it can be transferred to GPU as well in which case the internal function is going to be transferred to G and
recompile on GPU and there's an example of scan in the
lsdm example later this is just a small
small example but it's we don't really have time for that we also have a
visualization debugging and diagnostic tools one of the reason it's important
is that in piano like in terms of flow the definition of a function is separate
from its execution and if something doesn't work during the execution if you
encounter errors and so on then it's not obvious how to connect
that from where the expression was actually defined so we try to have
infirmity of error messages and we have some completion modes that enable to for
instance check for not a number fall out values you can assign test values to the
symbolic variables so that each time you create a new symbolic intermediate
variable each time you define a new expression then it the test value gets
computed and so you can evaluate on one piece of data at the same time as you
build a graph which can be useful to detect shape mismatch errors or it's
like that it's possible to extend ya know a couple of ways you can create an
app just from Python by calling python
wrappers for existing efficient libraries you can extend ya know by
writing C or CUDA code and you can also add optimizations either for increased
numerical stability for instance or for more efficient computation or for
introducing your new ops instead of the nave versions that that a user might
have used we have a couple of new
features that have been recently added to to the analyst I mentioned the new GPU back-end
with support for many data types and we've had some performance improvements
especially for convolution 2d and 3d and especially on GPU we made some progress
on the time of the graph optimization phase and also have introduced new ways
of avoiding recompiling the same graph over and over again and we have new diagnostic tools that are quite useful
and interactive visualization an interactive graphical ization tool and pdb breakpoints that enables you to
monitor a couple of eyeballs and only break if some condition is met rather
than monitoring something every time the before for every every piece of data in
the future well we're still working on new operations on GPU we still want to
wrap more convenient operations for for better performance in particular the
basic errand ends should be completed in the following days hopefully someone has
been working on that a lot recently we want better support for 3d convolutions
still faster optimization and more work on data parallelism as well so what we
want to thank well most of my colleagues and main tno developers and people who
contributed one way or another to a lab and the software development efforts and
of course recognizing the organizers for volley school now yeah so the slides are
available online as I mentioned as a companion notebook and now we can start
to go and and more resources if you want to go to go further and now I think that
it's time to start the practical examples so for
those who have not clone the repository yet then this is the command line you
want to two nouns for those who had cloned it you might want to do a git
ball just to get the latest to make sure we have the latest versions and you can
launch Jupiter notebook on the on the
repository itself so we have three examples that we are going to go over
logistic regression comes net and the rest yeah so I've launched the Jupiter
notebook here and let's start with so intro TN o was the companion notebooks
there's nothing new in there just the code snippets I've showed your alrighty and okay let's go with a logic
regression is that big enough for do we need to increase the font size okay so
I'm going to skip over the text because you probably know already about the model we have some we've packaged the
amnesty database with the on on github
with the repository so let's load the data and here let's see how we define
the model so it's basically the same way that we did in in the styles we define
sizes that will be useful for the shell variables we define an input variable
here it's a matrix because we want to use mini-batches and we have survived
balls initialized from zeros then we
define the our model so here's our
predictor so the probability of the class given the input and we're
going to use well so here the fine model
and then the softmax on top of it and the prediction if you want to help
prediction it's going to be the class of maximum probability so hard max over
that axis because we still want one prediction for each element of of the
mini batch then we define the loss function so here is going to be the log
likelihood of the label given the input or the cross entropy and we define it
simply we don't have like we don't need to have one croissants for P or log
likelihood operation by itself you can just build it from the basic building
blocks so we take the log of the probability you take the index of the
actual target and then you take the mean of that to have them in prediction over
the mini batch then derived equations
derive the update rules so again we don't have like one gradient descent
objects or something like that we just build whatever rule we we want so yeah
we could use momentum by defining other shape variables that will hold the velocity and then you have that
expressions for both the velocity and the survival itself and then we compile
a training function going from X&Y outputting the laws and the dating W and
B so while the code is getting generated
and compiled and the graph is getting optimized let's see the next step well
we also want to monitor not only the log-likelihood but actually actually the misclassification
rate on validation and test set so it's
simply the different like how many elements are different between the
prediction which was the arc max and the actual target and the rate is the mean
or the mini-batch and we create another we compile another two and a function
outputting that and not doing any updates of course so to train the model
well first we need to process the data a little bit so we want to feed the model
one mini batch of data at a time so here we have simply a generator I mean not
really pay attention right over just a helper function that gives us the mini batch number I and it's going to be the
same fraction used both for the training and validation and test set
we define a couple of parameters for early stopping in that training loop
it's not necessary it's just like a way
of knowing when to stop and use only like the best model that was encountered
during the optimization so let's let's define that and this is the main
training loop it's a bit more complex that it might be but it's because we use
this early stopping and we want to only validate when we are confident that the
training error has gone down enough but basically the the most important part is
you loop over the epochs unless unless
you encounter the early stopping conditions and then during each epoch
you want to loop over the mini batches and call train model then every once in
a while you want to validate and print some result of the validation error so
here we call test model on the validation set for that and then keep
track of what the best model currently is and get the the test error as well
and save the best one so to save the best one to save the model we usually
just save the values of all parameters which is more robust than trying to pick
all the whole Python object and it also enables more easily transferred to other
frameworks to visualization frameworks and so on so let's try to execute that
so of course it's a simple model the data is not that big so it should it
should not take that long so you see
that at the beginning well almost at each iteration we are better on the training set and then
after a while the progress is slower and
okay so just wait a little bit more seems to stall more and more and okay
and here it's the end after 96 epochs so
now if we want to visualize what filters
were learned or what the final train model looks like we just using a helper
function call here to visualize the filters it's not really important but
here what we use is we call get value on the weights to access the internal value
of the shell variable and then we use that to to plot the different filters
and we can see it's kind of reasonable like this is the filter for class zero and see
kind of like zero one part did what's important for the two is to have like an
opening here and so on so yeah if we
have a look at the final error well we can see that the training error is well
to hit training you know not plotting it but the validation and the test error I are quite high and we know that the
human level performance is quite low and the performance of our model is quite low so it really means that the model is
too simple and we should use something more advanced so to use something more
advanced if you go back to the home of
the Jupiter notebook can have a look at the continent and run Lynnette so this
new example is basically it's the same data it's still amnesty because it has the other edge of training fast even on
an older laptop and but this time we're going to use a completion net we look up
all of conclusion layers and then fully connected layers and then the final
classifier so I'm going to make for that float X is float 32 here and let's see
how we could use Tiano to define helper classes that are layers that can make it
easier for a user to compose them if they want to you to replicate some
results or use some classical architectures this is done usually in
frameworks built on top of Tiano like carrots like blocks like lasagna some
people also develop their own mini framework with their own versions of layers and so
on that they find useful and intuitive so
this logistic regression layer basically holds well parameters weight and bias
and compute the well the conditional
probability of classes prediction holds the params and have expressions for the
negative log likelihood and errors so if you were to use only that class then
it's doing essentially the same as what we did by hand in the previous notebook
and in the same way we can define a
layer that has convolution and pooling so again in the init methods we pass it
well filter shape image shape data side of pooling and so on we initialize the
weights using the formula from grow and venture at 2010 and buyers from zeros
and then from the inputs while we compute to the convolution with the
filters we then computes max pooling and output wealth and H of the pooling plus
the bias and here the bias is only like one number for each channel so which
means that you don't have a different bias for each location in the image so
you could actually apply such a layer on images of various size without having to
initialize new parameters or return that and then the same way we define the
hidden layer which is just a fully connected layer again initializing
weight and by and expression going from so the symbolic expression going from the input
and the shared variables to the output after activation and again we want to
collect the parameters so that we know what we will want to Train and then
here's a function that has that the main the main loop in the main training loop
so we have a mini batch generator again it's synced as as before and here we are
building the whole graph so always the same the same process we define input
symbol symbolic input variables matrix and a vector of int here so L vector is
a vector of long because the targets here are in this's and not not one Hots
vectors or masks or something like that and we create the first layer which is a
Linette compo layer with size we want to have the next one with also so yeah here
the image size changes this is mostly for efficiency actually you don't really
have to to pass that for for those particular models but you still need
like the shape of filters I mean you have the filters anyway and then it's
useful to have those size still because even if the convolution layers can
handle arbitrary sized images then after that we want to flatten the whole the
whole feature Maps and feed that into a fully connected layer and then to the projection layer so this one has to be
fixed so we have to know what the last comes layer will will have four
dimensions and here we here we go a fully connected layer and the output
layer that's just logic regression class same as before we want the final cost to
be the log likelihood of that we have
again the errors which is the misclassification rate parameters or the
concatenation of the parameters of all layers and once we have that we can
build the gradient so just one call of grad of cost with respect to parameter
updates so again just regular SGD but we could
have a class or something that performs like momentum a degree that a delta
whatever you need compile the function and here we have again the early
stopping routine with the same main loop for all a parks until we are done then
loop over the mini-batches and validate every once in a while and stop when it's finished so let's just declare that
loading the data exactly the same as before and here we can actually run run
that so this was the result of a previous run it that took 5 minutes so I
will probably not have time to do that but here you can see basically what
happens and if you want to run it or try that during the lunch break or or later
you're welcome to to play with it and after that yeah you can visualize the
the the round filters as well here you you have them for the first layer and
for the and here you have the an example of the
activations of the first layer for one example so we have just a little bit
more time to cover the lsdm tutorial
I mean example so if you go back to the
home of the Jupiter notebook and go to ASTM
then so this model is an SEM network that tries to predict the next character
of our sentence given the previous ones so not going to go into details but here
you can see that the LSM layer is defined here with like shot variables
for all the the matrices that that you
need and the different biases for the different gates and so on so you have a
lot of parameters it would be possible and sometimes more efficient to actually
define say only one variable that contains the concatenation of a couple
of matrices and that way you can do more efficient bigger matrix matrix multiply
but this is just one one simple implementation and here's an example of
how to use scan for the loop so here we define the step function that takes well
a couple of different different inputs so you have like the different
activation and so on from the previous time steps you have the current sequence
input and so on and from them here's basically the DSM formula where you have
the dot product and Sigma 8 or 10 H of the different connection inside the cell
and in the end you have the hidden and
that it so once you have that that's
step function is going to be passed to Tiano dot scan where the sequences are
the masks and input so the mask is is useful because
we're using mini batches of sequences and not all the sequences in the same
batch have the same length also for efficiency we usually want to group them with two group example of similar length
together but they may not always be exactly the same length so in that case
we pad that to only the longest sequence in the mini batch not the longest sequence in the whole set just for the
mini batch but we still have to pad and remember like what's the length of the
different sequences is in order for us to correctly predict and back propagate
so let's define that here we define the
cost function that's the categorical cross-entropy of the sequence and here again you see that the mask is used so
that we don't consider the predictions after the end of the sequence logistic
regression the same as before does the final cost here for processing the data
we're using fuel which is another tool being developed by students at Mira and
it's nice because it can read from just
plain text data do some pre-processing on-the-fly including things that I mentioned earlier like grouping
sequences by similar length and then shuffling them and padding and doing all
of that and so it outputs like a
generator that you can then feed in your main loop through a channel function so
that whole processing happens outside of tno and then the processed values are
fed into into the channel function so
yeah here we build our final key on a graph we have symbolic inputs for well
the input and masks we create lsdm layered a lot
correct layer define our cost parameters are the concatenation of the parameters
of logistic regression and the current layer take the gradients of course with
right to all parameters so as I mentioned it's going to use back prop
through time to get the gradient through the scan operation the update rule again
simple SGD no momentum nothing it's something that you could add if you want to play with it and compile to function
to evaluate the model so here the main
loop is training and we also have
another function that generates one character at a time given the previous ones that's why we will declare like
input here and so does that speak function that get probability
predictions we normalize them because we are working in float32 and sometimes if you divide by the sum and RISM then it
doesn't add up to one so we want a higher precision for just that operation and then try to generate to generate a
sequence every once in a while so again this is the result of a previous run so
we see in the so for for monitoring we
seed that prediction with the meaning of
life is and then we let the network generate so if I try to run it now it's
going to be long but here's some examples that I generated yesterday in
the previous run so it starts with not that much and it has like a couple of
unusual characters I mean it's usually it's not usual to have like
one Chinese character in the middle of words you have like concentration in the
middle of word and so on but then as it as it progresses you see
that it's getting slowly better and
better and the meaning of life is is the
dets and so of course this is not what's
going to give you the the actual meaning of life but yeah a tons lot of ham why
not and and this is this so so yeah so I
interrupted the the training at some point but you can play with it a little
bit and here are some suggestions of things you might want to do like better
training algorithms different nonlinearities inside the lsdm sell
different initialization of weights try to generate something else that the
meaning of life is and yeah so I hope I
could give you a good introduction of what you know is what it can be used for
and what you can build on top of it and if you have if you have any questions
later then we have general users mailing
lists we are answering questions on Stack Overflow as well and we would be
happy to have your feedback
have time for a few quick quick questions that's right here could you go to the
mic can you just give a quick example of
what debugging might look like in Theon Oh could you just break something in there and show us what happens and how you figure out what it was
actually yeah I think I had one okay so let's let's go to say a simple simpler
example okay so I'm just going to go to the logistic regression 1 and say for
instance that when I initialize my thing
I don't have the right I don't have the
right shape so you can still build the the whole symbolic graph and at the time
where you want to actually execute it then you have an error message that
tells you shape mismatch X has of Cowen's and some rows but Y has only
that number of rows and the apply node that caused the error is that dot
product and gives the inputs again and in that case it tells you it's not
really able to tell where it was defined but if you remove the optimizations then
it might so we can we can do that and we
can go back to where the train operation was defined train Model T a new function
and then I'll just say optimizer equals none
sorry I have to do my Audi calls piano
note optimized or not that's correct yes
so it's recompiling the function let's
record everything
and then he updated our message says
back-trace when the node was created and it's somewhere in my kernel and it's on
the line py given X equals that so of course we have like lots of things in
there but you know that there's a dot product and it's probably a mismatch
between those so that's that's one example then there are other techniques
that we can use we can have the breakpoints as I said and so on I don't
have right now tutorial about that but have some one line and I could point you to that I have some models I'd like to
distribute and I don't want to require people to install Python and a bunch of compilers and so unfortunately at the
time we're pretty intermingled with Python a lot because all the memory
management during the execution is done by Python and we use an umpire and
arrays for our intermediate values on the CPU and the similar structure on the GPU even though that one might be easier
to convert but yeah all our C code deals with Python and does the ink ref and
Decker F and so on so that Python manages the memory so if you want to distribute that I would suggest like a
docker container something like that recently even for GPU and video docker
is quite efficient and we don't have any modest allowance that that we had seen
earlier so it's not ideal and if like
someone has some time and the wheel to to help us disentangle tno from the
Python runtime it would be awesome but that's a use project
okay let's thank Pascal again and we
reconvene in 55 minutes for the next talk have a good lunch

----------

-----

--07--  

-----
Date: 2016.09.27
Link: [# Torch Tutorial (Alex Wiltschko, Twitter)](https://www.youtube.com/watch?v=L1sHcj3qDNc)
Notes:
### Lecture Notes on "Machine Learning with Torch and AutoGrad"

#### Summary of Content:

- The lecture covers practical applications of Torch, focusing on its AutoGrad feature and the underlying concepts shared across all deep learning libraries.
- Emphasis is placed on the differences and commonalities among deep learning libraries and the rationale behind the multiplicity of these libraries.
- A significant portion of the talk is dedicated to explaining the Lua programming language, its advantages for deep learning applications, and how Torch leverages Lua for efficient computation, especially on GPUs.
- The lecture introduces the core data structure in Torch, the tensor, and provides a walkthrough of basic and advanced operations possible in Torch.
- An overview of Torch's ecosystem, including its community-driven nature, is provided along with a comparison with other deep learning libraries and languages.
- The second half of the lecture delves into AutoGrad, explaining its importance for deep learning, illustrating its usage in Torch, and comparing it with similar functionalities in other libraries.

#### Advantages of Using Torch:

- Torch offers an efficient array programming framework similar to NumPy but in Lua, making it highly suitable for deep learning applications.
- It supports interactive GPU computation seamlessly, allowing easy data manipulation and computational operations on the GPU without extensive CUDA programming.
- Lua's performance, coupled with its simplicity and small footprint, makes Torch an excellent choice for embedded deep learning applications.
- Torch has a vibrant, community-driven ecosystem, not owned by any single industry player, fostering innovation and rapid implementation of cutting-edge research.

#### Drawbacks:

- Lua is less popular than Python, resulting in a smaller community and fewer resources for beginners.
- Data visualization and certain other ecosystem features may not be as developed as in Python.

#### Tips and Advice:

- For those transitioning from Python to Lua, the learning curve is relatively gentle, and one can become productive in a short period.
- Utilize the extensive Torch documentation and GitHub repositories for learning materials and examples.

#### Main Challenges:

- Navigating the transition from other languages to Lua might initially be challenging for some users.
- Understanding and effectively leveraging Torch's GPU capabilities requires some learning.

#### Importance and Usefulness of the Topic:

- Understanding Torch and its AutoGrad feature is crucial for researchers and practitioners aiming for efficient deep learning model development and deployment, especially in scenarios where computational resources are limited or where GPU utilization is critical.
- The lecture highlights the significance of automatic differentiation in modern deep learning, underlining the foundational role of AutoGrad across various libraries.

#### Accomplishments:

- The development of Torch and its adoption in both academic and industrial settings demonstrate its effectiveness in addressing deep learning challenges.
- Successful deployment of Torch models in production environments, like at Twitter, showcases its reliability and performance at scale.

#### Interesting Quotes/Insightful Sentences:

- "Lua is unreasonably fast for how convenient it is to use."
- "Automatic differentiation mechanically calculates derivatives as functions expressed as computer programs."
- "In deep learning, AutoGrad has democratized the experimentation with complex models by abstracting the gradient computation."

#### Lecture Content:

- Introduction to Torch and Lua for deep learning.
- Deep dive into Torch's AutoGrad feature.
- Comparison of deep learning libraries and discussion on the reasons for their diversity.
- Practical demonstrations of Torch's capabilities, including GPU acceleration and tensor operations.
- Overview of the Torch ecosystem, its community-driven nature, and its position relative to other deep learning tools.


Transcription:

so I'm gonna tell you about machine learning with torch and with torture Auto grads so the the description of the
talk isn't entirely correct I'm gonna do practical stuff for the first half and then what I want to do is dive into
torch Auto grad and some of the concepts that are behind it and those concepts also happen to be shared amongst all
deep learning libraries so I really want to give you a perspective of the common thread that links all deep learning
software you could possibly use and then also talk a bit about what makes each of the libraries different and why there's
I will I will hypothesize why there's so many and the different choices so one
thing I want to try there's been a lot of questions and we've gone over time but if there's not questions that go
over time in the room there's a lot of people watching online and if there's extra time we'll of course prioritize
people here but if you ask a question with the DL school hashtag or if you tweet at me directly I will try to
answer those questions from online and I'll certainly answer them offline as well so ask if you're watching at home
maybe that will kind of increase you know meaningful participation for people watching through the stream that aren't
here today umm a lot of this material was developed with sumus chintala at
Facebook he's kind of the Czar of the torch ecosystem these days and Hugo la
rochelle who you heard from yesterday and also Ryan Adams who's at Twitter with us and all this some material is
available on this github repository that you got actually on a printed sheet for
installing torch so all the examples that I'll show you will be in in one notebook and then there's a separate
notebook which it actually won't reference in the talk that's a full end-to-end walkthrough of how to train a convolutional neural network on CFR 10
so that's kind of a self-paced tutorial notebook that you can work through on your own time but I'm going to focus on
the basics on the fundamentals and hopefully give you some of the concepts and vocabulary that you can use to
really dive into torch on your own time so let's let's get going so torch is an
array programming language for Lua right so it's like numpy it's like MATLAB but
it's in the Lua language so torch is - Lua as numpy is - pi right so what you can do in torch you
can do in you know any language this is the absolute minimum basics you can grab strings and print them you can put
things in associative data types in Python there's tuples and lists and sets
and dictionaries in lua there's just one data type called a table so you'll see that a lot but you can do all those
things that I mentioned before with with a table and you got four loops and if statements the core type of torch is the
tensor just like in in numpy when you have the ND array which is a way of shaping sets of numbers into matrices or
tensors we have the tensor and you can fill it up with random numbers you can
multiply them standard stuff but the tensor is the core data type of torch and we've got plotting functionality
going over at a very high level I'll show you some more specific code in a moment so you can do all the kind of
standard stuff that you'd do in any other array based language there's all
the tensor functions that you'd like to like to use including all the linear algebra and convolutions and and you
know blast functions and I'm leaving this link here when the slides get uploaded you can follow this and kind of
dive into the documentation and see exactly what what kind of tools you have at your disposal in in the notebook and
the eye torch notebook which is something that seumas put together you can prepend any torch function with a
question mark and that gives you the help for that function so it makes it really nice to discover functionality in
the torch library in the notebook so why
is it in Lua alright it's kind of a maybe a strange maybe esoteric language to write things in Lua is is
unreasonably fast for how convenient it is to use especially a flavor of Lua
called Lua jet for loops in Lua jet are basically the same speed as C so this
for loop here is actually in production code in master and torch it's not C code
but this is perfectly fast enough right so that's a really nice aspect of Lua is
you can depend on super high-performance c-code and then on top
of it you've got this very convenient glue layer but you don't pay much of a speed penalty to use that glue layer so
that's one of the reasons why we've used Lua another advantage that some people might see as a plus is the language
itself is quite small so there's 10,000 lines of C code that define the whole language of Lua so you can really sit
down with the manual in an afternoon and understand most of the language on your own that same day another aspect
which is pretty critical for deep learning but also for other fields is that it's really easy to interoperate
with C libraries it was designed originally to be embedded so Lua was a
language that was designed to run inside of another C program but have a little scripting layer inside of it so it's
very easy to call indicee it's very easy for c to call into Lua so this is another reason why it's kind of an
appropriate choice for deep learning libraries the FFI for like the FF I call
signature and the idea has been copied into many other languages so C FF I and Python is a Python version of the Lua FF
I julia has something similar as well and as I mentioned it was originally
designed to be embedded and it's in all kinds of crazy places that you maybe wouldn't expect Lua to be so in World of
Warcraft all the graphics are in C++ or whatever they wrote it in but like the boss battles or the quests so like when
you go give the gem to the blacksmith or whatever and they give you back the magic sword the scripting of those
events that happens in Lua and if you write scripts for world of warcraft to make your own quests that's Lua Adobe
Lightroom is a photo processing app all the image processing is done in C++ but
all the UI and everything was done in Lua so again it was used to bind together high-performance code with a
with kind of a scripting layer and Redis and nginx which are kind of workhorses in the field of web development are both
scriptable with Lua and in fact if you go to github pages like my page github I
oh if somebody's hosting a web page on github that's served in part by Lua the
apocryphal story of why I was originally chosen maybe you could correct me is klimova Oh BAE was trying to build an
embedded machine learning application some device he could whereas helmut and classify the world with the CNN when he was a young student and he
was trying to do this with Python and it's incredibly frustrating to get Python to run on embedded chips maybe
it's easier now with raspberry pi but that just wasn't the case and then he stumbled upon Lua and turns out people had been building
Lua into embedded applications for years before that and so that kind of was the snowballing effect so that's that's the
hearsay for how we arrived at Lua but maybe there's there's another story
another really nice feature of torch is we have first-class support for GPU
computation interactive GPU computation so it's very very easy to get some data
from the CPU to the GPU and then everything that you do with that data happens on the GPU without you having to
worry about writing CUDA kernels right so this has been a feature of Lua torch which is becoming maybe a little bit
less unique now but this was this was a pretty solid feature when it first came out so interactive GPU computing and
I'll go very quickly over some of the basic features and all of these examples again are in a notebook which you can do
kind of at your own pace if you'd like so there's all the basic arithmetic like
creating matrices and and doing arithmetic between them taking maxes of
numbers and arrays clamping building tensors out of ranges boolean operations
over entire arrays special functions this is supported through a wrapper
around the Cepheus library this is what numpy uses to support things like 10h and atan2 and other kinds of functions
that I guess are in the special class and then sumif again has wrapped the
Bocage a/s library which is originally just for python but it provides really nice and beautiful plots in the eye
torch notebook and so we can you know draw random numbers from our favorite distributions and make nice histograms
of these so you can do nice data exploration in the eye torch notebook along with deep learning so one feature
that is attractive to some folks but just an interesting feature of the torch ecosystem is that although there's a lot
of industries support it is not industry owned so at Twitter and at Facebook air research in
at Nvidia we all contribute a lot to the torch community but we don't own it we can't
really steer it to go one way or the other definitively and there's a ton of other people that participate
academically in this ecosystem and that's a really nice feature and along
with I guess because of the really nice habits of people in deep learning when a
paper comes out there's often a high quality code implementation that follows it not not always but but very often at
least compared with with other fields and torch is one of the environments in which you'll often see high quality
implementations of really cutting-edge stuff so if you just browsed through github and you kind of follow
researchers on github you can see really high quality implementations of image captioning of neural style transfer so
you can just clone this github repository and run this yourself seek to seek models kind of the what is
whatever is the state of the art there's usually a torch implementation of it some of the recent work in generating
very realistic synthetic images with generative adversarial networks also has great torch code implementing it so
given that there's this active community on github in deep learning for torch how
does that stack up against other communities just to give you some context so the Python data science community is is pretty enormous and its
focuses are also very very varied if you enter into the data science
community in torch and lua you'll likely find deep learning people but not a lot
of other people so it's strengthened deep learning compared to its size is actually quite enormous and for those
that are kind of thinking of switching between Python and Lua and giving torch a try the effort to switch from Python
to Lua you can probably do that in a day if you've tried some Python programming so I was a Python programmer for a while
and getting started on Lua took took me maybe a couple days and I was you know actually productive at work and maybe a
week or so but you can actually run your code and understand and write new things pretty quickly if you've worked in a
scripting language like MATLAB or or Python so if you were intimidated or waiting to try it you should just dive in so how does torch compared to other
deep learning libraries specifically as opposed to languages and the first thing I'll say is there's really no silver
bullet right now there are a lot of deep learning libraries out there I say
tensorflow is by far the largest and this is a plot that was made by a
colleague of SU myths and I wish it kind of had confidence intervals on it because it's not strictly that these are
like you know points in in deep learning space but maybe this is a good guess of
where things kind of fit it seems as if tensorflow was engineered to be very good in an industrial production setting
and it seems like it's really fulfilling that Theano seems to have always had a research goal
in mind and has been really awesome in the research community for some time Torche tends to be more towards research
than industry I think Twitter maybe has pulled it a little bit towards production we maybe are the only example
I'd love to learn of others but were maybe the only example of a large company that uses torch in production to
serve models so every piece of media that comes in to Twitter goes through a torch model at this point so we're
really dealing with an enormous amount of data in a live setting the
development of torch just to give you a sense of how we think about how it was built and how we're extending it is
there's some kind of tenets of our core philosophy and if really the first is things should be as not to this isn't
necessarily good or bad this but this is our choice whenever you hit enter on a particular line and your I torch
notebook or on the command line you should get an answer back and this is something that we've we've tried to
stick to pretty pretty tightly so no compilation time imperative programming right so just write your code and you
know each each line of code executes something and passes it to the next line and minimal abstraction what I mean by
minimal abstraction is if you want a reason about how your code is performing it shouldn't take you that many jumps to
go to the C code that's actually being run in fact it usually is one or two jumps from the file that defines the
function that you care about to the actual C code so if you want a reason about performance or really understand what's going on it's it's it's quite
easy to do so in torch I want to take a little bit of a detour
and tell you about how torch thinks about its objects how it thinks about the tensor because this can help you
also reason about performance a lot of the reason why people come to torch is to build high-performance models very
quickly and easily so I mentioned tensors before so attentional tensor a
tensor is an N dimensional array and a tensor is actually just a pointer it's a
view into your member into your data that's sitting in memory all right so it's just a it's a shape it's um it's a
view into into what's actually being stored in your RAM and it's stored in a row major way so that means if I go to the first
element of my tensor in memory and I move over one I'm moving over one in a row and not one in a column column major
memory storage does exist it's just less common today so you often see row major so this tensor is defined by its link to
some storage and it's size 4 by 6 and it's tried six by one and six by one means if I move one down in the column
direction I actually have to skip six elements in memory right whereas the one
here means if I move over one in the second axis the row axis I have to go over one in memory so if I take a slice
of this tensor using the Select command so I select along the first dimension
the third element what he gives me back is a new tensor it doesn't give me a new memory this is a thing that that happens
a lot in torch is you'll deal with views into memory you won't do memory copies right so usually working with kind of
the raw data in RAM and so this creates a new tensor with the size of six
because there's six elements astride of one because we've pulled out a row not a column and an offset of 13 that means I
have to go 13 elements from the beginning of the original storage to find that piece of memory so if I pull
out a column then something different happens which is they still have or I have a size of four here and my stride
is now six because in order to grab each element of the column I have to skip six and then the offset of three is because
I grab the third element there all right so that's kind of a view of the of the memory model and if we act
run something like this like we instantiate a double-a tensor of double of foot double values inside of the
tensor and fill it with you know uniform uniform distribution and print it we can
see the values here and then we grab a slice B and print it it's just this row
and then we can fill B with just some number and print it now it's filled with that number now if we go back and print
a we've actually overwritten the values there so this is something you see a lot in torches is working on one big piece
of shared memory and as I mentioned before working with CUDA is really
really easy so if you just require ku torch which is installed automatically if you have a CUDA GPU using the
instructions on the github repository you can instantiate a tensor on the GPU and do the same thing and it will just
work so now I want to talk a bit about the frameworks that you'll use to
actually train neural networks in torch so this is a schematic kind of cartoon
of how we of the pieces we typically need to train a neural network so we've got our data stored on you know hard
drive or on a big distributed file system and we have some system for loading that data off of that file
system which goes into a nice queue and then some training code which orchestrates a neural network so the
thing actually making the prediction a cost function which is a measure of how good our neural network is at any point
in our training and an optimizer which is going to take the gradient of the cost with respect to the parameters in
the neural network and try to make the neural network better so in the torch ecosystem we've got some packages that
tackle each one of these separately so I won't talk about threads here there's actually several different libraries that will do this there's actually
several different libraries that will do each one of these things but this one is maybe the most common or the easiest to
start with and and then here we'll cover both the specification of the neural
network and the cost function as well as the mechanisms to push data through the neural network in the cost function and
pull the gradients back from the cost to the parameters and then the optimizer which is we've heard mentioned several
times today is to cast a gradient descent or we're outta grad so let me talk about NN
first give you a flavor of kind of how it works and what the pieces are so NN
is a package for building feed-forward neural networks mostly feed-forward
neural networks but kind of clicking Lego blocks together right so you might start with your input
and then click together a fully connected layer and then another fully connected layer and then maybe some output right so here I've defined a
sequential container which is going to be a container for all my Lego blocks and then I might click in a spatial
convolution so I'm going to be working with images maybe a non-linearity some max pooling some other layers as well to
kind of complete the whole neural network and then I might add a log softmax at the end to to compute class
probabilities so this this kind of the structure that you'll build neural networks with in NN is define a
container and then one by one add pieces down a processing hierarchy and I
mentioned the sequential container which is starting from inputs and then proceeding linearly there's two other types of containers that you might use
but generally NN shines when your architecture is linear right not when
it's got some crazy branches or anything like that the there's not a lot of API
to the NN package so if you if you learn these couple functions which will be in the slides for later if you want to
refer to them back you will understand all the mechanisms that you need to know to push data through a neural network
and then to push it through a criterion or a loss function and then to pull those gradients back in order to make a
gradient update to your model so these are really the API is the levers that you need to know to kind of drive your
neural network and of course we have a CUDA back-end for n n so in the same way
that you'll just call CUDA on some data you can call CUDA on a container and that will move the whole model onto the
GPU and then anything that you do with that model will occur on the GPU so it's kind of a one-liner to start training
models on a graphics processor so for doing feed-forward neural networks n n
is pretty great but for starting too weirder architectures like richard social yesterday mentioned a pretty
complicated NLP model that starts with glove vectors which are kind of like shallow neural networks and then a
recursive neural network and then an attention mechanism and all these things were interacting in strange ways that's
actually pretty hard to specify in NN at Twitter we have a package called torch Auto grab which makes these kinds of
gluing different model pieces together really easy and in fact the pieces can be as small as addition division
multiplication and subtraction so you can glue together any size piece of computation and still get a correct
model out and I'll talk more about that in a moment the optin package is what you need in
order to train models with like stochastic gradient descent or a degrade or out of delta whatever your optimizer
is that you that's your favor the API is pretty straightforward but
maybe a little bit different for people kind of coming from the Python world it's got a bit of a functional approach where it will actually you'll you'll
pass a function to opt in that will evaluate your neural network and pass back the gradients so that's just
something to be aware of it's a little bit of a different style another gotcha with optin that you might run into and
you'll see in some of the notebooks that are online is your parameters should be
linear in memory so if you want to optimize to neural networks that are interacting in some way you actually
need to first bring their parameters together into one tensor and then pass that to opt in there's just something to
be aware of so I want to talk for the rest of the talk about torch Auto grad
but also about some of the ideas that are behind torch Auto grad and how those link all the deep learning libraries
that you possibly could choose so first I want to take a step back and say that
just appreciate the wonderful stable abstractions that we have in scientific computing right so Fortran you know back
in 57 I don't think anybody uses Fortran 57 but people might actually still use Fortran 90 the idea of an array was
didn't exist on a computer and it really took some pretty crazy thinking I think
to build a system that made arrays something we take for granted same with linear algebra over about a 20-year
period starting in the late 70s people decided oh maybe we should think about linear algebra in a systematic way and
now we don't really worry about this if you want to multiply two matrices that used to be you know a phd's worth of
work to do that at scale and now we just you know we don't even actually import
Blas there's so many wrappers of blasts that we don't even think about this anymore so this is another abstraction and also the idea that we should have
all of the routines that we would possibly want to call in one place available that we don't have to write that was kind of invented I would say by
MATLAB in the mid-80s and then really popularized in the open-source community by numpy and we should take them for
granted we should totally forget about them that because they make us faster they make us better for us to assume
these things will work so machine learning has other abstractions besides
these computational ones that we take for granted all gradient based optimization that includes neural nets
as a subset relies on automatic differentiation to calculate those gradients right and and I like this
definition from Barack Perlmutter automatic differentiation mechanically calculates derivatives as functions
expressed as computer programs right so it doesn't derive things are right on a piece of paper with a pencil it derives
computer programs app machine precision and with complexity guarantees those
last two clauses differentiate it from finite differences where you take the input to a program you perturb it
slightly and you measure the gradient that way that's a very bad way to measure gradients it's it's numerically
very unstable and it's not symbolic differentiation so it's not writing down the symbolic expression of a neural
network putting it in Mathematica or maple and then it asking for the the derivative because your expression might
go from this to this so you get expressions well when you do naive symbolic differentiation and you don't
get that with automatic differentiation so automatic differentiation I would say
is the abstraction for gradient based machine learning it's been rediscovered
several times there's a review by Woodrow and there I think the first implementation where
it actually operates on a computer program was by Bert's bill pending in 1980 although it has been described back
you know in 1964 by Wengert in in neural networks rumble heart is the one that I
suppose popularized it as back propagation although back propagation is a special case of auto-da-fé this this I
think is important in nuclear science and computational fluid dynamics and in weather modeling these people have been
using auto-da-fé for years decades and their tools in many ways are much more sophisticated than we have in machine
learning there's a lot of ideas that we have yet to import from people that model the weather that would really
benefit our ability to train larger and larger models and I would clarify that
our abstraction and machine learning is actually reverse mode automatic differentiation there's two different
types two extremes I should say forward mode in Reverse mode you never hear about forward mode and you never hear
about forward mode of machine learning because it's a very bad idea to try forward mode and machine learning and I'll show you why so here is a cat
picture from the internet and my job at my job is to decide that that is in fact
a cat picture this is actually something that we do do at Twitter what I am doing
is passing this cat through successive layers of transformations than eventually producing a probability over
classes I'm getting it wrong my classifier thinks it's a dog so I'd like to train my neural net to think it's a
cat so I have a loss a gradient of my loss and I have it with respect to my
parameters and this is my gradient that will let me update my parameters and it is composed of multiple pieces and using
the chain rule I know that I can fold this together to actually compute the loss I want which is the gradient of the law through the respect to the
parameters the issue is I can do it either left to right or right to left so going from left to right looks like this
whoops that was very fast okay I'll do
two big matrix matrix multiplies so this is bad this is not good because we had
these huge matrix matrix products that we're keeping around it's actually worse than this and I'll show you in another
view of forward node so see I have a computer program so no longer a symbolic representation of a neural net this is
just some computer program and let's say I'd like to optimize a write a is the single parameter of my neural net it's a
very silly trivial example but I think it will help illustrate the point so I can execute this program and look at all
of the arithmetic operations that occur and build what's called a trace so I'll define say a is 3 I'll define B
is to C is 1 and then I'll start executing the code I'm actually going to look if B is greater than C and choose a
branch to operate on but then ignore it in my trace so I've chosen one of those
traces that one of those branches which is the first because B is greater than C and I have some output value D and I'll
return the output value all right so this is a trace execution of my program given some inputs so to calculate in
forward mode the derivative of my output D with respect to a I'll define a is 3
and then initialize a gradient of a with respect to itself and the idea is I eventually want the derivative of D with
respect to a and I'll build it up sequentially da da and then I'll do D be da and then Dissidia in ddd a so I'm
moving from the left to the right building up my gradient I can't do much about the derivative of B with respect
to a right now so I'll define C and remove C with respect to a and then I
have my value D and then I can define my target value which is the gradient of D with respect to a so if I wanted the
gradient of D with respect to B so if I had a two parameter neural network and I wanted optimize both at once I would
have to execute this whole thing again and initialize this guy here as DB DB
has one right so if you have a million parameters in your neural network or tens of millions if you have to do a
million evaluations of forward mode or tens of millions of evaluations of fort mode so it is a very bad idea to try
forward mode automatic differentiation on neural network and that's why you probably never heard of it so now you
can forget about it but the alternative is reverse mode and that's starting from
the right to the left so now I've got this nice matrix that your products which are much smaller and
the complexity is much better and there's an interesting difference when I actually go to do this in computer code
and you'll see these words are closer together and that's because for reverse
mode I actually have to evaluate the whole program before I can start deriving because I'm starting with the
derivative of D with respect to D and then decrementing derivative of D with respect to C with respect to D with
respect to a so I'm going the other way but I have to have all the information first before I start that so now I can
initialize derivative of D with respect to D and I can walk backwards and return
both the value and get gradient what's really nice about this is you'll notice
here I actually have all the information I need to calculate the derivatives of D with respect to these other parameters
so that's why we really like reverse mode auto-da-fé aka back propagation for
neural nets is if you have a million of these guys you really want to be ready to compute them all at once right and
doing these with matrices is very efficient thing to do on the computer so we've implemented this trace based
automatic differentiation in a package called Auto grad and this is the entirety of a neural network so this is
how you would specify and train a neural network and autocrat so I'll initialize
my parameters we'll just be some random numbers and then here is my neural network function I'm multiplying my you
know image that I'm passing in by my white matrix and adding a bias non-linearity doing it again and then
returning some probabilities and I have a loss which will take in an image and
return a prediction so just using this function and then I'll just take the mean squared error or it's the sum
squared error in order to get the gradients of this function the derivative of the loss with respect to
these parameters all I have to do is import this autograph package and then call grad on this function this returns
a new function that returns the gradients of my original function so
it's a what's called a higher-order function it's inputs and its outputs are a function so whenever you see that
Noblet that upside-down triangle grad triangle this is the coding equivalent of that and then to Train
we'll just call our D loss function on our parameters our image and our label which I'm just pretending like you
already have a system to get here when we have our gradients and then we're updating with stochastic gradient
descent here all right so it's a very thin it's it's really just this this is the interface with which you talk with
Auto grad so what's actually happening so here's my simple function as we
evaluate it we're actually keeping track of everything that you're doing in order to be able to reverse it so we're actually
building that trace list that I described before and keeping track of it internally so we'll start online I guess
that's five so we'll multiply some things we'll keep track of the fact you multiplied and the inputs will keep
track of the addition and the inputs and also the output of addition will keep track of inputs outputs in the function
every time and we'll kind of walk down this function and build your compute graph just in time so as you're running
your code we're learning what you've done and the way we track that and I won't go into details we actually
replace every function and torch with like a like a spy function so instead of just running torch dot some our spy
function says oh I hear you're running torch dot some let me remember the parameters you gave me let me run some
on those parameters remember the output and then return it like nothing happened but internally we're remembering all
those things and the way we do this to actually compute the gradients is we're
walking back this list like I described before and every time we get to a point where we need to calculate a partial
derivative we look it up so we've written all of the partial derivatives for Torche functions and it really every
neural network library is going to do this at some level of granularity so let me walk you through another couple
examples just to show you what it could do so this is kind of a pretty vanilla one we can you know add and multiply
scalars and get the correct gradient this is where things get a little bit more interesting if there's an if
statement all right so this control flow can be a little bit difficult or awkward and a lot of existing deep learning libraries because we just listen to what
era medic functions get run we ignore control flow so we just go right through this stuff all right so we can get the
correct gradient even with if statements we actually care about tensors when
we're doing optimization or machine learning so everything I've shown you that works with scalars also works with
tensors just as easily this is in the notebook that is on the github repository if you want to play with it
this is where things get a little bit interesting for loops also work just fine and not just for loops that have a
fixed length which is something that is perhaps easy to unroll but for loops whose duration can depend on data you
just computed right or while loops whose stopping condition can depend on a computation that occurs in the while
loop we don't really care we're building your graph dynamically and when it's done and when you return some value will
calculate the derivative derivatives of the graph that we have you can turn any for loop into a recursive function this
is kind of wacky I mean I don't know how you would actually use this in practice but you can cook up a lot of crazy
things you might try with autograph and they just work so here we have a function f if B is at some stopping
condition will return a otherwise we'll call F and we're gonna differentiate this right so we're gonna differentiate
a fully recursive function and it works just fine another aspect which is coming
up more and more as papers are coming out that basically disrespect the sanctity of the partial you know of the derivative of the gradient and people
are computing synthetic gradients they're you know adding they're clipping two gradients or people are messing with
kind of the the internals of back propagation or of auto-da-fé it's actually pretty easy to start to engage
with in Auto grad so say I'm going to sum the floor of a to the third power so
the floor operation is piecewise constant so the derivative is zero almost everywhere except for where it's undefined why would I want to do this
for instance if you wanted to build a differentiable JPEG encoder or differentiable MPEG encoder in
compression algorithms like that there's often a quantization step that will floor around or truncate numbers and if
you wanted to differentiate through that to build like a neural Jake algorithm or something you need to pass gradients through something that
ordinarily does not and so if we look at what the gradient is at zero everywhere I won't go into the details but you can
ask Auto grad to use your own gradient for anything so if you have a new module that you want to define and either
you've written high-performance code for it and you want to use it or you want to redefine or overwrite you know the
gradients that we have there's a pretty easy mechanism for doing that and then when you call your special dot floor you
can propagate gradients through it right and here I was just saying basically ignore the gradient of floor so this is
a toy example but there are real places where you have a non differentiable
bottleneck inside of your computer off and you want to either hop over it or find some approximation and auto grad
has a mechanism for very easily plugging those types of things in so that's a bit
of what auto grad is and what it can do and I want to turn our attention to how
autograph relates to other deep learning libraries and maybe how they're common and how they're similar and how they're
different so one big difference that I
found between different deep learning libraries is the level of granularity at which you are allowed to specify your
neural network so there's a lot of libraries where you say you get a confident or you get a feed-forward
neural network and that's it right so the menu is two items long and that's
fine I think Andre I really hit it on the head where if you want to solve a problem don't be a hero use somebody else's network so maybe this is vgg that
you've downloaded from from the model Zoo or something like that right so this is the don't be a hero regime on the left in the middle there's a lot of
really convenient neural net specific libraries like torch and n and Karras and lasagna and you get to put together
big layers and you don't really get to see what's inside those layers but you get to click together linear layers or
convolutions and usually that's kind of what you want to do and on the far end of the spectrum the things you can click
together are the function the the numeric functions in your kind of host
scientific computing library right like add multiply subtract and these are
features of projects like Otto grad and Theano and tensor flow and the reason why these boundaries are
made is because the developers have chosen to give you partial derivatives at these interfaces all right so this is
how they've defined their api's and these are the interfaces with you know across which you as a user cannot pass
if you want to new one of these modules for the type on the left or the type in
the middle you have to go in and build a whole new model and actually implement the partial derivatives but with the
types of libraries on the right you can build your own models by modules by composing primitive operations all right
so that's one difference that you can find in practice how these things are
implemented under the hood usually means this is the totally shrink-wrap stuff
and maybe they implemented this whole thing by hand usually these guys in the middle are rappers they're rapping some
other library and the guys on the right are usually actually implementing automatic differentiation so Auto grad
in theano and tensorflow all implement auto death and the guys in the middle are taking advantage of that to make
more convenient wrappers so another aspect that's different is how these
graphs are built so I'll remind you in Auto grad we build these things just in time by listening to what you're doing
and recording it but that's not how all neural network libraries are built and
this is an axis along which I think that they are differentiated meaningfully so there's a lot of libraries that build
these graphs explicitly where you say I'm going to click this Lego block into this Lego block where I'm going to give you this yamo specification file the
graph is totally static and you really have no opportunity for compiler optimizations there and then there are
the just-in-time library so Auto grad and chain ER is another one where you
get any graph the graph can be anything it can change from sample to sample it can be you know to the length of the graph can be determined by the compute
that occurs in the graph you have very little opportunity for compiler optimizations there so speed can be an
issue sometimes and in the middle there's a head of time libraries like tensorflow and Theano where you construct your graph using a
domain-specific language you hand it off to their runtime and then they can do crazy stuff to make it faster the
problem with that is it can be awkward to work with I guess that got cut off it can be awkward to work with control flow and I think
there's a reason why it can be awkward to work with control flow and it's because of the types of graphs that
these libraries are actually manipulating so we say compute graph a lot we say data flow graph a lot data
flow graph has a pretty restricted meaning and it means that the nodes in
your graph do computation and the edges are data and there's no room for control flow in a graph that is a data flow
graph right so static data flow is the type of graph that N and n Cafe use because all the ops are the nodes and
the edges are just the data and the graph can't change get data flow just in
time compiled data flow like Auto grad and chain ER has the same characteristics but the graph can change from iteration to iteration because we
wait until you're done computing the forward pass to build the graph in the middle there's kind of a hybrid and I
don't know what to call that graph type the ops are nodes the edges are data but
then there's special information that the runtime gets in order to expand control flow or for loops so scan is in
Theano is an instance of this where the Theano runtime has special information that allows it to make scan work but
it's kind of it's it's it's conspiring with the graph data type to do that there's actually another graph type that
naturally expresses control flow and data flow together that I haven't seen implemented in a deep learning library
it's called see of nodes from cliff clicks thesis in the mid-90s it seems
like a really natural thing to try and man maybe that's something that comes up in the future but that's kind of a big question marks
maybe one of you will we'll try that out and see how well it works so in practice
this level of granularity can sometimes slow us down having to work with addition and multiplication can be nice
if you want to try crazy stuff but if you know you want to make a confident why don't you just rush all the way over
to the left if you want to take you know inception and add another layer where you want to use the type in the middle
an autograph allows you to do that so I'll just kind of walk through writing a
neural net three ways very quickly and then and then close questions shortly thereafter so using
the fully granular approach there's a lot of text on the screen but the top half is basically let's instantiate our
parameters the way that we want to and then here just like I've showed you in previous slides let's do a multiply and
let's do an addition and put it through non-linearity we're being very explicit right so we're breaking all the abstraction boundaries and we're just
using primitive operations we can use the layer based approach so in Auto grad we have a facility to turn all of the N
and modules of which there are a lot may be an exhaustive list for what you'd want to use for standard deep learning
applications you can turn them into functions and then just use them so linear one on the linear parameters and
your input and some activation you can go through your neural network this way so you can use a layer based approach if
you want and if you just want your network just a feed-forward neural network we've got a couple of these kind
of standard models just ready to go so you can just say give me a neural network give me log softmax and a loss
and let me blow these guys together so you can do it any of those three ways
Auto grad at Twitter has had a pretty cool impact we use NN for a lot of stuff
when we use Auto grat as well but being able to reach for autograph to try something totally crazy and just knowing
that you're going to get the right gradients has really accelerated the pace of high risk potentially high payoff attempts that we make so one
crazy thing you might want to try is experiment with loss functions so instead of I have a hundred image
classes and I want to have my convolutional neural network be good at classifying this hundred image classes
maybe you have a taxonomy of classes maybe you have a vehicle and then a bus
a car and a motorcycle and if you guess any one of those you kind of want partial credit for vehicle or if you guess motorcycle you want partial credit
for for car so building that kind of a tree loss is actually really straightforward an auto grad and you can
do that in in just one sitting but might be more complicated to do that in other libraries we have to crack open the
abstraction barrier write your own partial derivatives glue it back together and then use that module that you've built we've trained models that
are in production in auto grad so this is something that's a battle-tested to a sense and is running on
large amount of media Twitter in a sense Auto grad doesn't actually matter when you're running in production because you
just you have your function definition for your prediction of your neural network and then the gradient part just
goes away or so all the fancy stuff where we play Storch with our secret you know listener functions all that just
goes away and you just have some numerical code so there's actually no speed penalty a test time at all and we
have an optimized mode which does a little bit of compiler stuff still work in progress but for the average model
it's as fast sometimes faster than n N and for really complicated stuff if you
wrote that by hand you'd probably be faster but the time to first model fit using Auto grad is dramatically reduced
because you don't have to worry about correctness so this is a big wall of text but it's meant to put in your head
some ideas of things from automatic differentiation from that world that we
don't have yet that we really want right to be able to train models faster and better so the first is checkpointing
this does not check pointing where you save your model every 10 iterations this is check pointing where on your forward
pass you might you in normal reverse mode automatic differentiation you have
to remember every single piece of computation you do because you might need it to calculate the derivatives and checkpointing you just delete them you
let them go away because you think that some of those might actually be easier to recompute than to store alright so
for point wise nonlinearities for instance it might be easier once you've loaded your data just to recompute the
reloj as opposed to saving the result of reloj and loading that back in again mixing forward and reverse mode is
something that you can imagine being important for kind of complicated architectures although I don't really
know how much impact that would have so in the chain rule you can either go from left to right or you could start in the middle and go out you can do all kinds
of crazy stuff if you want and we really just do reverse mode for diamond shape
graphs where your computation explodes out and it comes back in that might be
useful to start with forward mode and then finish with the reverse mode or an hourglass you might want to start with reverse mode and end with forward mode
stencils are a generalization of convolutions that people use a lot in
computer graphics automatically calculate really efficient derivatives of image processing just general image processing
algorithms is under active investigation in the graphics world and in the computer vision world so these are two
references that are kind of neat papers source to source transformations is something that hasn't really made it it
basically has kind of been dormant for about ten or fifteen years so the gold standard used to be you take a piece of
code as text and you output another piece of code as text what we're doing now in deep learning is we're always
building runtimes we're always building some domain-specific layer that depends on you actually running code it used to
be that you just read that text and kind of like a compiler spit out the gradient this this was the gold standard it might
not be now but I think it's worth three investigating and then higher order gradients so Hessian vector products and
kind of Hessian based optimization maybe doesn't always have full payoff I actually don't recall hearing anything
about this at this school so far because it's very expensive and difficult to do
expensive computationally fashion is just if you take the grad of F it gives you the gradients if you want the second
derivative right so you take grad a grad of F so there's efficient ways to do this it's still kind of an open problem
but there are libraries out there the Python version of autograph dust as well diff sharp and hype both also do this as
well so to kind of close out you should just try it out it's really easy to get
it if you have anaconda if you use Python we've made it so that Lua is
fully installable with anaconda so if you're already using it it's very very easy to get all of the tools that I've
showed you today and that's kind of the single line to interface with it and if
you have any questions you can find me on Twitter or email or github but I'm happy to to answer any questions that
you have
oh yeah I have no idea
thanks thanks for the great talk oh yeah I was wondering what's the state
of the data visualization facilities in Lua compared to say Python if I'm Frank
it's it's not as good python has been at this for you know five ten years really actively building matplotlib and you
know Seabourn and all these other libraries and in Lua were importing other people's work so book ajs is
really the best that i've seen so far and that's something you can use in a notebook so you have the full suite of
that of that particular library yeah
hey thanks for the luck is it possible to convert a model train with torch in
into a C model that's deployable in you know production we just run torch in
production we use a little model but you want to run it and see so the whole
layer of torch that's actually doing the work is in C and calling torch from C I
don't have a specific website I can point you to but you can very easily call and execute a Lua script from C
it's like three or four lines of code in C thank you the follow-up the question
about see just now just like if I'm gonna compile I mean I want to have Tosh into my sequence passcode what kind of
overhead do I see I see just animations yourself like I have a 10,000 line - what just-in-time compiler
I need to put that in there right oh I can I avoid that because for example I
think about if I'm going to put the one in an embedded system they have a mouth resource of anything during inference
time so I'm sorry during yet during inference time there's there's no appreciable overhead if I'm
understanding your question right so you you are importing a Louis so in your C code you're going to basically say Lua
please run this Lua script and that's going to call out into other C code so all this overhead I talked about with
autograph that's training time that doesn't exist at test time at all so so
during test time but the thing is I still need to have Lua compile into my C code right yeah so this is something
people have been doing for like 15 20 years it's pretty mature so Lua is in like microwaves for instance people have
done very embedded applications of Lua yeah I think the binary for Lu is like I
don't want to it's like a round it's a kilobytes it's very very small there's 10,000 lines of code so when it compiles
down on small
so there's a question from the twitters says i'm using a combination of Karros
and tensor flow why should I use torture auto grad if you're happy then you know
that's great I guess so people tend to reach for torch when they would like to be able to
reason very easily about performance the
kind of the more of a compiler infrastructure that gets added to a deep learning environment the harder it can
be for the end user right away from the people that originally made the library can be harder for the end user to reason
why is this slow why is this not working you might eventually see some github issue later my network is slow in these
conditions and then it gets closed a year after you had to have shipped your project right I mean these things can happen it's not the fault of anybody
it's just that torch was designed to basically be very thin a thin layer over C code so if that's something that you
care about torch is a really good thing to work for if careless and tensorflow is working great for you then keep deep
learning you know that's awesome so I'm
trying to see
it's hard to filter where will the slides be posted it's not
a deep learning question but they will be posted that's the answer to that
question I have a question now how do I access through so normally all the web
services production generally are another you know fast based application in Python or you know Java based Web
Services right or maybe in you know in the cellphone through Android which is also Java right so how do you call these
models which were you know trained in torch how would you actually access those there's a couple different ways
you can do that if you're using a feed-forward neural network writing the
Java code to do the matrix multiplies can be pretty straightforward and we've actually done that before or it's just
simpler tor just write the deep learning code load in the weights we'll serialize it however you know it needs to be
loaded that's one approach is kind of you know hacking short term at Twitter we've engineered a system where we
actually have Lua virtual machines running inside of Java and we talked over the j'ni so we have like a more
permanent solution for that but if you're using standard model architectures you might try to serialize
your weights and then use the native deep learning library that exists to load up those weights and then run for
it and that with some debugging I think that's perfectly fair approach if you have this split between testing and kind
of deployment where you're constrained by language or environment that's generally the thing that you know I mean
you do basically just you know C realize your model and then try to read it what about the latency actually so related to
you know this so when you see realize that hackish way at least you can get you know that latency things sold out
but is there any plan basically to have you know interfaces available for other languages so that you know you don't
have to do this extra step of serializing and then you know loading into language if you if you don't like
in your case you were mentioning that in Twitter you have
- available inside your Java JVM our access to the JVM using j'ni so what
what what impact does it have on the latency and by latency you mean time to
ship the model not the latency of how long it takes many predictions oh that's
gonna be very engineering dependent so if you're calling torch from C code the latency is not appreciable over if
you're just running Lua code and that can be extremely fast if you're going through some wrapper like through the
J&I or something like that you will incur an overhead and you should just try to pick the interfaces that reduce
that as much even if you incur engineering overhead to do so I don't know if that answers your question I'm a
little bit distant from the server side so I can't give you I just don't know but generally I think what I can say
this that's fair is we're constrained by machine learning you know model complexity latency we are not
constrained by overhead of like figuring out how to actually get those predictions like to an HTTP request for
instance serving which you know which is
kind of sort of solving this problem yeah not that I'm aware of
again the torch community is not centralized and so people could be working on a totally awesome
you know complement to the the tensorflow server but I am not aware of
it thank you okay we're going to take a
short break of 15 minutes let's thanks Alex again

----------

-----

--06--

-----
Date: 2016.09.27
Link: [Sequence to Sequence Deep Learning (Quoc Le, Google)](https://www.youtube.com/watch?v=G5RY_SUJih4)
Transcription:

eating that were divided in two parts so number one and we work with you and
develop the sequence to sequence learning and then that's the second part I would I will place sequin to sequence
in a broader context or a lot of exciting work in this area now so let's
multiply this by a an example so a week
ago I came back from vacation and my in my inbox I have five hundred and eight
emails and reply emails and a lot of emails I basically just require just yes
and no answer so let's try to see whether we can do a system that can
automatically reply these emails to say yes and no and for example so some of
the email would be you know from my my friend on she said hi in the subject and
she said are you visiting Vietnam for the New Year walk that would be her content and then my probable reply would
be yes so you can gather another set like this and then you know you have
some inputs content so less for now let's ignore the the the on the author
of the email and the subject but let's focus on the content so let's suppose that you gather some email and some
input would be something like are you visited in Vietnam for the New Year Kwok and the answer will be yes and then the
another email would be are you hanging out with us tonight the answer is no because I'm quite busy
so the third email would be did you read the coolness paper on breast net the
answer is yes because I liked it now let's let's do a little bit of
processing we're basically in the in the previous slide we have gear and comma
and then kwok and then question mark and so on so let's let's do a little bit of
processing and then put the the comma a
space between gear and comma and then Kwok and question mark and so on so this
step a lot of people call tokenization and normalization so let's do that with our emails now so and then the second
step I would do would be to do feature representation so in this step what I'm going to do is the following I'm going
to construct a 2,000 dimensional vector 2,000 represent the size of English
vocabulary and then I'm going to go through email I'm going to count how many times a particular word occur in my
email for example for example the world
are occur one in my email so I increase the counter and then you occur one so I
increased another counter and s etc and then I will reserve at the end a token
to reserve to just count all the words that just our vocabulary okay and then
now you now use successful you if you do this project a process you're going to
convert all of you or your email from input to output pairs where the input would be fixed line representation of
20,000 dimensional vector and output would be either year or one okay any
questions so far okay good
okay so I will get so as you said somebody in the audience that the order
of the words don't matter matter and the answer is yes so I'm going to get back to that issue later now so
that's x and y and now your job my job now is to try to find some W search that
W time X can approximate Y Y is the output right and Y here is yes and no so
because of this problem is has two categories you can think of it as a
logistic regression problem now if anybody follow the gray cs2 10:29 class
by andrew probably can formulate this very quickly but in a very short you the
album comes as follow you kind of try to come up with a vector for every email
your w is a two column matrix okay
the first column will find the probability for the eat whether the email have to be answer as yes second
column will be answered as no and then you basically take the dot product
between w1 at the first column now Adam is called the stochastic gwendy set so
you run for iteration one to like a million you run for a long long time you sample a random email X and then some
reply and then if the reply is yes then you want to update your w1 and w2 such
that you increase the probability that the answer is yes so you increase the
first probability now if your reply is if the correct reply is no then you're
gonna update w1 and w2 so that you can increase the probability of the is email
to be answered as you know so the second probability okay so let's call those a p1 and p2 now so because to
update I said to update the increase what does that mean what that means is that you find the gradient of the
partial gradient of the objective function with respect to some parameter so now you have to pick some alpha which
is the learning rate and then you say W 1 is equal to W 1 plus some alpha the
partial derivative of block of P 1 with respect to D of W 1 ok
now I cheated a little bit here because I used the log function it turns out because the log function is a mono is a
monotonic increasing function so increasing P 1 is equivalent to increase in the log of P 1 ok and it usually with
this formulation stochastic gradient descent works better any question so far
and then you can also update you know W 2 if the email is to be reply is yes and
you can you can have different way to update and to if the reply is no so
what's a and then if you have a new email coming in then you take X and then
then you control into the vector then you compute the first probability ok W 1
time X divided by W exponential W 1 time X plus exponential or W 2 time X and if
that probability is larger than 0.5 then you say yes and if that probability is
less than 0.5 then you say no ok so that's how you do prediction with this
now now this there's a problem with this representation is that there's some
information loss so somebody in the audience just said that the order of the words don't matter and that's that's
true now let's let's fix this problem by using something called the recurrent
Network and I think a rigid soldier already talked about recurrent networks
and some part of it yesterday and Andrei as well now there the idea of a
recurrent Network is basically you have also have fixed representation for your
input but it actually preserves some sort of info ordering information and
the way that you compute the hidden units the following so the function hash of Euro is
basically hyperbolic hyperbolic tangent of some some matrix you time the work
vector for the world are okay so Richard also talk about what vectors yesterday
so you you can take what vectors coming out of what to back or you can just
actually randomly initialize them if you want to okay so let's suppose that that's H of zero now H of one would be a
function of H zero and the vector for
you which is a times H of zero plus u
times V of vector u and then you can keep going with that to see one of my
three three most complicated slides so you are you should ask questions no
questions so everybody familiar with recording that sir well
okay so to make predictions with this but you you tack on the label at the
last step and then you say try to predict why for me how do you do that now here I I basically you you went the
way you did before and basically you make update on the W matrix which is the
the classifier at the top like what I said earlier now but you also have to
update all the relevant matrices which is the matrix you the matrix a and some
work vectors right so this is basically you have to compute the partial
derivative of the last function with respect to those parameters now that's
going to be very complicated and usually I when I do that I do that myself I get
that wrong but there's a lot of tools out there that you can use which is you
can use auto auto differentiation in tensor flow or you can call torch or you
can call piano to actually compute the derivatives and once you have the derivatives you can just make the update
right yeah yes so you the matrix you are
share so I'm going to go back to one side so this matrix you I share all for
all vertical matrices right and the size
you have to determine ahead of time for example the number of column would be
the size of the work vectors but the number of rows must be like like a
thousand if you want or maybe 255 you want so this is model selection and it
depends on whether you under fit in over fitting to choose a bigger model or a smaller model and your compute power so
that you can train a larger model a smaller model
the matrix you yeah so the the work
vectors the world vectors the number of work vectors that you use are the size
of vocabulary right which is so you gonna tend to end up with 20,000 work
vectors right but the the size of so that means you have 20,000 rows in
matrix U but the number of column you can sorry the number of column is 20,000
but the number of row would be you have to determine up just yourself okay any
other questions now okay so what's a big
picture so the big picture is I started with bag-of-words representations and
then I talked about a and n as a new way to represent variable size input that
can capture some sort of ordering information then I'll talk about Auto differentiation so that you can compute
the partial derivatives and these you can find auto intensive flow or piano or
torch now then I talked about stochastic when descent as a way to train the
neural networks and the question so far
okay you have a question oh that's also
depends on how big your your training set and how big is your computer and so
on right but usually if you use an N and if you used like a hidden state of a hundred you should take like a couple
hours yeah but it depends largely largely depends on you know size of
training data because you want to iterate for all a lot of you sample a lot of emails right you and you want
your algorithm to see as many emails as possible right so okay so if you use
such algorithm to just say yes no and just know then you might end up losing a lot of friends
because because because we don't just
say yes no because we went to say when
for example my friend asked me are you visiting Vietnam for the new year walk then maybe the better answer would be yes see you soon right that's not better
nicer way to approach this and then if if my friends ask me are you hanging out
with us tonight so instances say no I would say no I'm too busy or did you read the coop ok
right so let's let's see how we're going to fix this so so before I'm gonna tell
you the solution I would say this is the this problem is drew it basically
requires you to map between variable size input and some variable to some
variable size output right and if you can do something like this then there's a lot of applications because you can do
auto reply which is what we've been working on so far but we can also work on user to do translation just like
between English French you can do image captioning so input would be an a fixed
like vector or representation coming from conflict and then output would be the cat sat on the mat right or you can
do summarization the input will be a document and output would be some summer summary of it or you can do two speech
transcription where you can have input would be speech frames and output would
be words or you can do conversation so basically the input would be the
conversation so far and the output could be might reply or you can do cue night etc etc so we can keep going on now so
how do we solve this problem so so this is this is hard so let's check out what
Android capacity has to say about recurrent networks okay so so Android
say that there's more than one way that you can configure your network to do things so we can do you could use your
network to map recurrent networks to map one two right so the at the bottom that's an
input the the green would be the hidden state and the output would be the what
you want to predict now 1 1 2 1 is not what we want right because we have many
too many so it's probably more like the last two to the right right but we
arrived as the solution that I said in the red box and the reason why it does
that's a better solution is because the the the size of the input and the size
of output can vary a lot sometimes you have smaller input but larger output but
sometimes you have larger input and smaller output so if you do the one in
the red circle you can be very flexible right if you do the one to the extreme
right then maybe the output has to be smaller or at least the same with the
with the input right which what we are that's what we don't want so let's construct a solution that look
like that so okay so here's the solution so the input would be something like hi
how are you right and then let's put a special token unless let's say the token
is end and then you're going to predict the first token which is M and then you
predict the second token fine and then you predict the throat Oken thanks and then you keep going on until you predict
the world end and then you stopped now I
want to mention that B in the previous set of slides I was just talking about
yes and no and ingest no you have only two choices okay now you have more than
two choices you have actually 20,000 choices and you can actually use the
algorithm that are the the logistic regression and you can expand it to cover that more than one more than two
choices you can have a lot of choices okay and then the algorithm uses just
follow the same way now so dizzy my first solution when I say walk - sick
- sick but it turns out it didn't work very well and the reason why I didn't work very well is the model never know
what it actually predicted in the in the last step so it keep a keep going and
you keep synthesizing output but it didn't know what it said it didn't know what decision it committed in the
previous step so a better simpler solution would look like this a better solution is you back basically you feed
what the model predicts in the previous step as input to the next step alright
so for example in this case I'm going to take am I'm going to feed it in to the next step so that I'm conduct completing
the dance in the second world which is fine and etc so a lot of people call
this concept auto regressive so you you take your you eat your own output and
make it as your input any questions so far or whenever it produced end then
just stop there's a special token end yeah now okay so the so relevant architecture
here would be the end code people also call the encoder as the what the
recurrent network in the input and the decoder would be the recurrent network in the output okay okay so how do you
train this so again so you basically you run for a million steps you see all your
emails and then you say you sample and for each iteration you sample an email X
and a reply why why would be you know I'm fine thanks right and then the
sample random work YT in Y and then you update the iron and encoder and decoder
parameters so that you can increase the probability that Y of T is correct given
all what you seen before which is your YT minus 1 YT minus 2 etc and also all
the axes right and then you have to compute the partial derivatives to make
it work so the computing part partial this is very difficult so again I recommend you to use something like Auto
differentiation intensive flow or torch or Tiano okay you have a question yeah
but the recurrent Network the number of parameters didn't change because you have U and V a UV and I are fixed right
okay so the question in the in the audience is that there's um if the iron
and are different in four different example and the answer is yes so the number of steps and are different I have
a question there okay yeah I'm gonna get
to that in the next slide yeah okay all right so the question is a
in practice how long would I go to for the RN I would say if you usually stop
at like 400 steps or something like that because outside of that it's going to be too long to make the update and compute
it's very expensive to compute but you
can go more if you want to yeah I have a question yeah
yeah yeah yeah so that's a problem so if I'm going to talk about the prediction
next so let me go to the prediction and then you can ask questions so okay so how do you do prediction so this the
first algorithm that can we can you can do is go greedy decoding okay in greedy
decoding is for any incoming email X I'm going to find I'm going to predict the
first word okay and then you find the most likely word and then you feed back in and then you find the next most
likely word and then then you feed back in and etc so if you keep going you keep
going until you see the world end and then stop all it is exceed a certain length you stop okay
now that's just do greedy okay so let's let's do a little bit less greedy so it
turns out that so given X you can predict more than one candidate so let's say you can predict a candidate's let's
say three okay so you take three candidates and then for each candidate
you're going to feed in the next step and then you arrive at three so the next step you're going to be have nine candidates right and then you're going
to end up going that way so here's a picture so given input X I'm going to
predict the first token there would be hi yes and please and given every first
token like this I'm going to feed back into the network and the network will produce another three and etc so you're
going to end up with a lot of a lot of candidates so how did you select the best candidate well you can traverse
each beam and then you compute the John probability at each step and then you
find the sequence I have the highest probability to be the sequence of choice
what is your reply any question to see
the most complicated slide in my talk oh yeah yes so the question is what do
you do with our vocabulary works now it turns out in this algorithm what you do is that for any word that is our
vocabulary you create a token call unknown and you map everything to
unknown or anything that our vocal every vocabulary to be unknown so it doesn't
seem very nicely but usually it works well there's a bunch of algorithms to
address these issues for example they break it into like characters and things like that and then it you could fix this problem
yeah yeah the cost function is that so I
go back one slide so the cost function one more slide so the cost function is
that you sample a random were YT here
let's suppose that here I this is my input sofa or an input and I'm sample YT
let's say T is equal to 2 so which means the work fine okay I'm at the work fine
I want to increase the probability of the model to predict whoa fine
so the every time the model will make a lot of predictions some a lot of them
will be incorrect right so you have a lot of probabilities you have probability for the water and
the probably a and etc and then probably for zzzzz right and you have a lot of
probabilities you want the probability probabilities for the worst for the work
fine to be as high as possible you increase the probability does that make
sense or you condition on IIM so you condition
so when I'm at fine my input would be hi how are you and and um okay that's
that's all I see and then I need to make a prediction and I have to make that prediction right right and you know if
I'm at the world thanks my input would be hi how are you and I'm fine and I
gotta get my thanks for probability right okay yeah I have a question here
oh I haven't thought about it yet so the
question is how do you personalize so well one way to do it is basically embed a user as a vector so let's suppose that
you have a lot of users and you embed a user as a vector that's one way to do it yeah I have a question here
yeah yeah so the question is that let's
suppose that my beam search is 10 then you go to from 10 like a hundred and
then a thousand and suddenly it grows very quickly right it go to rule a if
you if your sequence is long then you end up with K to the N or something like that well one way to do it is basically
you do truncate that beam search where any any sequence with very low probability you just pick it up you
don't use it anymore so you go so you can do this you can do 3 9 and then you
ten to seven and then you go back up to 9 right and then you keep going so that
way you don't end up with a huge beam and usually in practice using like a
beam size of three or ten would work just fine and whoops wait yeah yeah I
have a question okay so for because it's
a 9n we don't have to Pat the input now to be fast sometimes we have to Pat the
input because we want to make use make sure that batch processing what's very
well so you'd be bad but we paired with only like zero tokens
okay yeah so let's suppose that you have
a sequence of ten then you have a graph of ten when you have a sequence a batch of all twenty you haven't made a graph
for twenty and etc yeah that will make the GPU very happy I have a question
that oh so so you are you asking sort of so
my interpretation of your question is how do you insert the world embedding into the model is that correct our user
embed an old if you want to personalize the thing then at the beginning you have a vector and that's a vector for quoc
with a ID one two three four five and then if is Peter then the vector would
be five six seven eight yeah yeah that's
one way to do it yeah well there's more than one way you can do it at the end or you can do it at
the beginning or you can insert a tab at every prediction steps but my proposal
is just predict put it at the beginning the simpler okay I have a question there yeah you
yeah
that's a very good question the question is what if the model details right if we
make a prediction and then that's a bad prediction and your model never see and then it keeps detailing and it will
pretty produce garbage yeah that's a that's a good question so I'm going to get to that so well so this is sly so
there's an algorithm for scheduled sampling so in scheduled sampling what you do is you you instead of feeding the
truth during training you can fee feet what sample from the sub max so what
generated by the model and then feed in as input so that the model understands
that if it produce something bad it would suck actually can recover from it right so that's that's one way to
address this issue is that make sense yeah any question there's a question
here okay yeah yeah yeah so in this
algorithm yeah the question is how large is the the size of the Dakota well my
answer is that try to be as large as possible but it's going to be very slow and in this algorithm what happens is
that you you use the same you use like
fixed length embedding for like to represent the very very much the long
term dependency like a huge input right and that's going to be a problem so I'm
going to come back to that issue with the attention model in a second okay
any question okay here's a question
ah so does the model learn synonyms is
that a question or what's the question oh I see well yeah it turns out that if
you learn it turns out that it mapped good and if you visualize embedding the good and fine and so on I'm not very
closely to the to the embedding space but in the output there's we don't know
what else to do the other approach is basically to train the world embeddings using water vac and then try to ask the
model to regress to the world imbalance right so that's one way to address this issue we tried something like that did
not work very well so whatever we have in here was pretty good okay I have to
keep going but like any way the algorithm that you've seen so far turns
out actually answer some emails so if you use the smart reply feature in inbox
it's already used this system in production now for example in the indc
me email my colleague Ricardo got an email from his friend saying that hey we
wanted to invite you to join us from the early Thanksgiving on November 22nd
beginning around 2:00 p.m. please bring your favorite dish and reserve by next week and then it would propose three
answers for example the first answer would be telecine second answer would be
will be there and the third answer is sorry we won't be able to make it now
this where do these three answer come from those those are the beams now there's an algorithm to actually figure
out the diversity as well of the beams so that you don't end up with very similar answers so there's an algorithm
that like a heuristic that make these beams a little bit more diverse and then
they pick the best three to present to you
okay any question yeah I have a question here
yeah there's no guarantees so the question is how do I guarantee that the the beam would terminate an end now
there's no guarantee it can go on forever the indeed there are certain cases like that if you don't train the
model very well now but if you train the model well with with very good accuracy then the model usually terminates highly
see any cases that it don't terminate it doesn't terminate yeah but there are
some corner cases that it will do funny things but you you can stop the model
after like a thousand or hundred or something like that so that you make sure that the model doesn't do that
doesn't go on crazy right I have a question here
that's very interesting yeah it just comes out because there's a lot of emails and if you invite someone there's
more than one person and it might be it learns about Thanksgiving it just mean inviting the whole family things like
that yeah it just learned from statistics yeah or
maybe that something like that yeah okay okay oh in industry algorithm so the
question is do I do any post processing to correct the grammar of the beams in this algorithm we did not have to do it
yeah okay I have another question
so okay so the question how contextual so I would say we don't have any user embedding in this so it's pretty general
the input would be the previous emails and the output would be the prediction
the reply that's all we have so it sees a context which is the threat sofa okay
did I answer your question okay yeah we
you can catch me up after the talk yeah oh yeah it ran down too so yeah slow
question oh oh I see
so the question is there's some some emails are not relevant for a smart apply maybe they've too long or you
should not reply or something like that so in fact we have two algorithms so one hour with them this is to say yes or no
to reply right and then after it passes
the threshold there's an algorithm to run to produce the threshold so it's a combine of two our rhythms that are
actually I presented earlier yeah I have
to get going but you can get back to the question so there's a lot of a more interesting stuff coming along okay so
so what's a big picture so far so the big picture is that we have an i NN encoder that it's all the input and then
we have an iron and decoder the trying to predict one token at a time in the output now everything else force is the
same way so you can use stochastic when you sent to train the algorithm and then
you you do beam search decoding usually you do app in search of up 3 and then
you should be able to find good food good beam with the highest probability now someone in the audience brought up
the issue that we use fixed length representation so just before you you make a prediction
the Japan the hm and the white thing right before you go to the Dakota okay
that is the fixed-line representation and you can think of it as like it's a vector that capture all everything in
the in the input right it could be a thousand words or could be five words
and you use a fixed length representation for a variable length input which is kind of not so nice so we
want to to fix that issue so there's an algorithm coming along and it's actually
invented at a at University of Montreal you're sure he's here so the idea is to
use an attention so how does an attention work so in principle what you
want is something like this every time before you make a prediction let's say you predict the world am you kind of won
a loop again at all the hidden state so far you want to look at all what you see
in the input software okay now say when you do fine you also want to see all the
all the hidden state of the input sofa and and on now how do you do that in as
a program so well you can do this so you H of M you predict a vector C let's say
that vector is the same dimension with all the H okay
so if the your H of one each dimension of 100 then C also have a dimension of
100 okay and then you take C and then you do dot product dot product with all the H okay and then you have
coefficients a 0 a 1 blah blah blah to a
to the N okay and those are scalars okay
and then after you have those scalars you compute something called the beta which is basically I stop max of all the
Alpha right so 2q compute that you take the exponent bi is an exponential our AI
divided by the sum of Exponential's okay okay and then you take those bi and then
multiply by H by and then you take the weighted average and then you take the sum and then you
send it to add additional signal to predict the war and and then you keep
going with that right so in the next step you also predict another C and then you take that C to compute the dot
product you compute the B the a and then you can compute the B you can take the B you do the weighted average and then you
send it to the next time to send it to the prediction and then you use stochastic when you send to Train
everything okay and this autumn is implemented in
tensorflow okay so how how into table
what is going on here so let's suppose that you want to use this for translation so in translation you wanna
for example the input would be hi how are you and the output is Ola combos
paths or something like that okay and then when you put it the first word you
want Ola to correspond to the world hi okay because there's an one-to-one
mapping between the word high and Ola so if you use the attention model the
beta's that you learn will put a strong wait for the words Ola for the world
high and then it has a smaller wait for all the stuff and then if you keep going then when you say Como's then it will
focus on how and etc okay so it moves that coefficient it put a strong
emphasis on the relevant world and especially for translation it's extremely useful because you know the
one-to-one mapping between the input and output any question so far this is
definitely very complicated yeah I have a question
all right now the beta other day and be alone so I don't I don't
and so the question is how do I deal with languages where the order them like reverse for example English to Chinese
Japanese right so some of the verbs get moved and things like that well I didn't I did not have cold air be they are
learned so by virtue of learning they will figure out what beta to put right
to wait the input and those are computer basically computed migrated set right so
they just keep on learning okay I have a
questionnaire okay yeah so the question
is are they any work on putting attention in the output yeah I think I think you can do that I'm not too
familiar with any work in here but I think it's possible to do it I think some people explore something like that
yeah any question oh I have a question another question
yeah yeah yeah yeah yeah so so the question
is less about because right now the world hi is capitalized at the first
character it doesn't mean I'm using two n or n vocabulary size so in practice
you we should do some normalization if you have a small data set what you should do is you normalize the tax so
high will be like lowercase and etc now if you have a huge data set doesn't
matter we just learn okay yeah I have a question there right yeah so it
so the question is in a sense it's capture the the positional information in the import yeah I agree I have a
question there a pattern punctuation ah
so the question is what do I do with punctuation well they are in right now
I just present the algorithm as if it's a very simple implementation like the
very basic but one thing that you can do is you you before you train the
algorithm you put a space between the world and the punctuation so that you do
some that is that step is called tokenization or normalization in language processing so you can use any
like a stanford NLP package or something like that to normalize your text so that
is easy to train now if you have infinite data then if you just learn itself okay so I should get going
because there's a lot of other interesting stuff okay so it turns out that the the basic implementation but if
you want to get good results and if you have big data sets so one thing that you can do is to make the network deep and
one way to make deep is is in the following way so you stack your your recurrent network
on top of each other right so you know like in the first sequence of sequence paper we use a network of four but
people are gradually increasing to like six I and so on right now and they getting better and better result like in image
net if you make a network people you also get better results okay so i if you
wanna train sequin to sequins with attention then do a couple years ago
when we like many laps working on this problem were behind the state-of-the-art
but right now in translation many translation tasks basically this model
our audio already achieved state-of-the-art without in a lot of these the pomt datasets so to train this
model so number one is that as i said you might end up with a lot of
vocabulary our vocal vocabulary issues
so what Barack Obama will be this an unknown right Hillary Clinton and season
unknown now you you might use something like what segments right so you segment
the words out for example Barack Obama would be bar and drag and etc or you can
use all the smart algorithms for example word character split you can split words
that have unknown to be in two characters and then you treat the meta character there's some work at Stanford
and they prove that it works very well so that's one way to do it you know tip number two is that you you when you
train this algorithm because you when you do back propagation or forward propagation you multiply you essentially
multiply a matrix many many times so you have explosion of function value or or
the gradient or implosion as well now one thing that you can do is you click
the grade in a certain value right so you say that if the gradient magnitude
of the gradient is larger than 10 set it to ten okay then tip number three is to
use giu or in our work we use a long short term memory okay so I want to
revisit this long short-term memory business a little bit okay so what's the long short-term memory so in
use an iron cell basically you can catenate your input and your the the
hidden state and then you multiply by some theta and then you apply with some
activation function let's say that's a hyperbolic tangent okay now that's the
simple function for n n now in lsdm you
basically you multiply the input and hash by a huge big matrix let's call
that theta that theta is four times bigger than the theta I said in the iron
and cell and then you're going to take that Z okay that coming out you split it
into four blocks its block you can compute the gates and then you you use
the the value of a something called like the cell and then you keep adding the newly computed computed values to the
cell so there's this apart here that I say that the integral of C is that what
it does is basically it keep a hidden state where it keep adding information to it so it doesn't multiply information
but it's keep adding information you don't need to know a lot of this if you want to just apply a SDM because it's
already implemented intensive law any
questions so far okay so in terms of applications you can
use this thing to do summarization so I've seen I started seeing work in some radiation pretty
exciting you can do image captioning so and the input in that case would just be
a representation of an image coming out from vgg or coming out for google net
and etc and then you send it to the I end and and we do the decoding for you or you can use it for speech recognition
or transcription or you can use it for QA so to the next part of the project
the top and we'll talk a little bit about speech recognition okay so well in speech recognition the
input could be maybe waveforms right and then an output could be some words you know hi how's it well
one thing that you can do is you drop your input into Windows that's the green
box is there and then you crop a lot of them and then you send a lot of them to an iron and then you convert it into MFC
see before you send to Ana MFC see or spectrogram or something like that okay and then you use the algorithm that I
said earlier and then with attention and then you do the transcription you
predict one word at a time in the output now the problem with this algorithm is
that in turn when it comes to speech you end up with a lot of input right you can
end up with thousands and thousand steps so back propagating in time even with attention can be difficult now one thing
that you can do is basically you do some kind of a pyramid to map the input so
you if you do enough layers you can divide your input into a factor of eight
or sixteen if you do enough layers right and then you produce the output so we we
work in on an implementation where the output is actually characters like like
the in the by - squawk where they have the ctc now I have to say that the
strength of this algorithm is that you actually have an implicit language model in the output so when I say I when I
have the word how is actually conditioned on hi and stop before right and including the
input so there's an implicit language model already but the problem with this
is that actually you have to wait until the end of the input to do the coding so
the decoding has to be done offline okay so if you use this for voice search it
might not be too nice because people want to see the some some output right
away okay so in that case there's an algorithm that can use it do it in an online fashion
block-by-block now also I have to
mention that in translation this hour the sequence sequence a wit attention
works great it's a among the stay of the art but when it comes to speech it doesn't work
as well as the CDC at least in published results we're not as good as CDC which
is whatever what Adam talked earlier or some of the hmm DNN hybrid which is
which is the most Wylie speech system currently so I want to pause there and
then I can take questions any questions I have a question at the back yeah yeah
yeah yeah
Oh so how does the book in translation
well in translation what we do is basically we have pairs of sentences so
for example hi how are you and then hola como estas right and then we have pairs
of sentences like this and then we just feed it into the turns out into the sequence two sequences attention at
every step we again we're going to predict one word at a time but before we make a prediction the model has the
attention so it actually see the the input once more before it makes a
prediction that's how it works now what is can you repeat okay what is the issue with with a model again please
yeah
I see well I I can't quite follow the question but let's take it offline
is that okay yeah yeah and then we can do some paper okay together
I have a question yeah yeah yeah okay so
the model I did the inbox thing that I presented it was on in English but there's no limitation in the model in
terms of language so let's suppose that you in your inbox that you sometimes you
write in English and sometimes you you write in in Vietnamese or sometimes you write it in Spanish whatever and you
personalize by user embedding that I would say that it will just learn your behavior and then we will basically
predict the world that you want you make you but make sure that your your output bank vocabulary is large enough so that
it covers not only the English words but also the Spanish word and etc like
Vietnamese and so on so your vocabulary gonna be not going to be 20,000 it's going to be like a hundred thousand
because you have more choices and then you have to change your model on on those examples yeah it's a matter of the
training data that's all okay I have a questionnaire yeah
yeah yeah I saw the question is that in the case of voice search right now you have to wait at the end to make a
prediction is there any otherwise yeah yeah the answer yes you can make a prediction block by block so you can
actually figure out like an algorithm a simple algorithm to actually segment the speech and then make a prediction and
then take the prediction and feed it it as input at the next block so you can keep going like that so you in theory
you can actually do online decoding but but I'm saying that the work on you can
do online decoding but that work is currently work in progress how about
that okay I have a question there yeah
over here so we have some input email and then some output email where export
written emails reply and then you can just strain it that way yeah yeah okay I
have a couple questions
yeah yeah the question is that in speech
recognition the CDC seems to be a very nice framework because it match it laser like a monotonic increase Minh in the
output and the input but let CTC make this independent assumption it doesn't
have a language model in it maybe that's the the sequence of sequence I can address this oh yeah I
think that's a great idea maybe we should write a paper together okay I think I think I haven't seen it
but I think that's a very good idea question
I say okay great so so the question is that is there because right now we
predict one step at a time is there any way to actually look globally at the output and maybe use some kind of
reinforcement learning to adjust the output and the answer is yes so there's a recently a recent paper at Facebook
who I think sequence level training or something like that where they don't optimize for one step at time but they
predict they look at the globally and then they try to improve world at a rate or they try to improve blue score or
things like that for translation and it seems to be making some improvement in the metrics that they care about now if
you show it to humans though people still prefer the output from this model
so some of the metrics that we use in translation and so on might not be what
the metrics that we optimize and the next step prediction seem to be what people like a lot in translation yeah so
so the question is can we add the GaN loss like it again lost yeah I think that's a great idea yeah I have a
question here yeah yeah
change yeah yeah
so let's suppose that you type the first ha hola then you can actually start the
beam from there so the question is is there any way to incorporate user input
so I say yeah it let's suppose that you wanna you say hola sorry
hi how are you right and then as soon as the person type hola that actually restrict your beam so you
can actually condition your beam on the first world Ola and your beam will be better yeah I think that's a good idea
I have a question oh so how much data
did we use so in translation for example we use the several several WMT coppices
Cobra and the W empty copper I usually have tens of millions of seven pairs of
tendencies something like that and every every sentence have like 20 words on
average twenty thirty words on average I can't remember but that's something like that order of magnitude yeah yeah I have a question there I
can't really hear also how's it compared
to Google search auto-completion I honestly I don't know what to use
underneath a Google search auto-completion but if I were if they you if I think they should use something
like this because it's okay I have still
lots of interesting stuff coming along so okay okay so what's a big picture so
the big picture is so far I talked about sequin to sequence learning and
yesterday Andrew was talking about most of the big trends in deep learning and
it talking about the second trend was basically doing end-to-end deep learning so you can characterize sequence of
sequence learning as an 2n deep learning as well now so the framework is very
general so it should work from a lot of NLP related tasks because a lot of them
you would have input sequence and output sequence in our NLP it could be input
would be some text and output would be some you know passing trees that's also possible but it works great when you
have a lot of data now when you don't have enough data then maybe you want to consider dividing your problems into
smaller components and then creating your sequin to sequence in the sub components and then merge them okay now
if you don't have a lot of data but you have a lot of related tasks then it's
also possible to actually merge all these tasks by combining the data and then have an indicator bit to say this
is translation this is summarization this is email reply and then change only
and that should improve your your output to now this basically conclude the parts
about sequence sequence and then the next part I'm going to apply sequence to sequence in a big picture of the active
on ongoing work in neural nets for NLP
so if you have any questions you you can ask now I take maybe two questions because I think I running out of time so
I have a question yeah
also the question is does the modem handle emoji I don't know but it's emoji
is like a piece of text to write so you can just like feed it into as another extra token if you make them if you make
your vocabulary 200,000 then you should be able to cover emoji as well yeah I
have a question also if you have new
data coming in so should I return the model where you I think towards the end
we lower the learning rate so if you add new data it just it will not make a lot
of good updates so usually we make you you can add new data increase the learning rate and then continue to Train
yeah that should work okay so I already took two questions let's keep going so
so this is an active area that actually is a very exciting which is in the area
of automatic unite so you can think that maybe the set up would be can you read a
Wikipedia page and then answer a question or can you read a book and answer your question now you in theory
you can use sequin to sequence with attention and then to do this task so
it's going to look like this you're going to read the book right one token a time and with the book then treat a
question and then you're going to use the attention to look at all the pages
and then you make a prediction of the tokens right so so that cut up that's
kind of sometimes you do we do answer this question that way sometimes we don't have knowledge about the fact so
we actually read the book again to answer the fact but a lot of the time if you ask me is Barack Obama the president
of the United States I would say yes because it's already in my memory so
maybe it's better to actually akhmet the iron with some kind of memory okay so that it will not to do this look
back again right it's kind of annoying look back again so there's an active area of this research
I'm not a definite expert but I'm very aware so I can place you in the right
context here so work in this area would be memory networks by Western and folks
at Facebook there will be new rotating machines that deepmind dynamic memory networks would
be a richer soldier presented yesterday and then stuck augmented iron ends by
Facebook again and etc now well let's list so I want to show you a like
high-level what is this augmented memory means okay so let's think about the
attention so the attention looked like this so you and in the end coder you're going to look at at some input okay and then
you have a controller which is your H variable and then you keep updating very high variable but along the side you're
gonna write down into memory your h1 h2 h3 and etc right you store it into a
memory clear-rite and in the decoder what you're going to do is you gonna continue
continue producing some output right are you going to update your controller G but you're going to read from memory
your H okay right so that so so again so
in the import you write to memory in and then in the output you read from memory
now now let's let's try to be a little bit more general and the general would
be at any point in time you can read and write right you have a controller and
you can read and write read and write all the time now to do that you you have to follow in architectures you have some
memory bank big memory back ok and then you you can use the right you can decide
to write some information into it from by a combination of the memory bank in
the previous step and the hidden variable in the previous step and then you also read into the hidden state to
and then you could make an amount update and then you can keep going forever like that so this concept is called an N with
augmented memory okay is that is that
somewhat clear any question you have a
question the question is when you read
do you read the entire memory bank a lot of these algorithms are actually soft
attention so yes it will look the entire memory you can actually predict where to
look right and then read that only that block now with the problem with that is
you end up with very it's not differentiable anymore right because this the thing that you
don't read don't contribute to the gradient so it's going to be hard to train but you can use to reinforce and
so on to train it so there's a reason our paper reinforcement learning new row
Turing machines but actually so there's something like this right not exactly but it will deal with discrete actions
okay any question no question Wow okay
so the another extension that a lot of people talk about is using an N with
augmented operations so you want to augment the neural network with some
kind of operations like addition subtraction multiplication the sine
function etc lot of love functions so to motivate you you can think about Q and I
can fall into this for example histor context the building was constructed in the year 2000 and then it was in later
all people say oh it was then destroyed in the year 2010 and then the question
would be how long it the building survived and the answer would be ten years now how would you answer this
question where you say 2010 subtract two thousand ten years now neural nets if
you can train with a lot example it can do that too you can learn too subtract numbers and things like that it
requires a lot of data to do so all right so maybe is better to augment them
with functions like addition and subtraction right so the way you can do
it is that the neural network will read all the token so far and we'll push the
numbers into a stack and then you get the more the neural net is augmented by
a subtraction and a addition function and these two phone and then you assign
these a probability for these two functions so green the more duck does
mean the higher probability okay so you aside to probability and these two you compute the weighted average of the
values coming out of these two function and then you take that and then you pop it and you push it into the stack in the
next step and then in the next step you will call the addition and subtraction again and etc that's the principle of
something called neural programmers or new neural programmer interpreters so there are two papers last year from
Google brain and nygma was talking about this so so that's that's some of the
related work in the area of augmenting recurrent networks with with operations
with memory etc now what's a big picture ok so the big picture I want to revisit
and I say so what I've talked to today
is sequin to sequence learning and it's an end-to-end deep learning task so it's
one of the big trends happening in natural language it's very general so
you can use if you have a lot and a lot of supervised data it's a very supervised learning algorithm so if you
have a lot of data it should work well but if you don't have enough supervised data then you consider dividing your
problem and then training different in different components or you can train jointly in an multitask settings and
people also train it jointly with auto encoder namely to read the input sentence and then predict the output
sentence again and that's also and then you train jointly with all the tasks and
works as well if you if you go home and
then you want to make impact at your work tomorrow then so far that that's so far so good that that can make some
impact now if you want to do some research and I think like things with memory operation operation augmentation
are some of the exciting areas but but it seems like still work in progress but
I would expect a lot of advances in this area in the near future so so you if you
want to know more you can take a look at pre-solar block you talk about attention
and of my augmented recurrent networks I also wrote some tutorials pretty simple
this the sequin to sequence with attention for translation is implemented
intensive flow so you can download and you can use you can actually download tensor flow and train it what I said
today now this there's a lot of work going on
in this area not on many of these are not mine so I so as you can see you can
even read the world just means how many papers come along in this this area so I
can pause there and I have five minutes to answer questions I have a question
there yeah yeah
yeah
yeah I see okay can you speak to the
microphone because I can't hear very well add a microphone and then I think people can hear that as well when you're
treating a Q&A network so you're taking the example of training from a book to answer questions yeah so if let's say
Harry Potter who was Harry Potter's father now there could be many books that have a character Harry so he has a
context resolution issue which is which Harry should I answer the question for ya how do you solve the context context
problem in your training this kind of Q&A type Network I think that's a great question so I think one thing is that
you can always personalize for example you know that the guy when I talk about you can have a representation for the
user and then you know that when he say Harry his because he actually been reading a lot of books about Harry
Potter so it's more likely to be Harry Potter but I think with the hour time I
said I just want to make sure that it's as simple as possible so the father if you do the juicer has to ask the
question Harry Potter rather than Harry but I'm saying if you
represent user vectors and then you inject more additional knowledge about
the users about the context into as additional token in the input of the net
the net can figure it out by itself yes so that's one way to do it yeah okay I
have a question yeah you did some work on Doc to Vic yeah do you have an idea
what the state of the art in generalizing were two veggies to more than one word oh I see
I think skip thoughts are interested in
directions here so dr. that is one way but skip thought so that the idea of
skip thoughts was Ruslan salakhutdinov with author on this a his idea is basically using sequence
to sequence to predict the next sentence so the input would be the current
sentence the output we would be the the the the previous sentence all connect sentence and then you can train a model
like that if the model is called skip four and I have heard a lot of good things about skip thoughts where you can
take the embedding at the end and then you can do document classification and
things like that and it works very well so that's that's probably one place that you can you know can go my colleague at
Google is also working on something called auto encoder so he instead of predicting the next sentence he predict
the current sentence so trying to repeat the current sentence and and that's kind of work well too yeah yeah see what was
your thoughts on how to solve the common sense reasoning problem Oh common sense I'm deeply interested in common sense
but I gotta say I have no idea I think maybe you can do something like I think
common sense is about a lot of first of all there's a lot of knowledge about the world that is not captured in text right
for example gravity and things like that so maybe you really need to actually combine a lot of morality that's that's
one way to think about it all the way all the thing is do you make sure that unsupervised learning work that's
another approach but I think this digital research area I think I'm just
making guesses right now is there a good way to have sent all these rules and you
know using some soft yes yes so the question is how do you represent
Dru's so so if you think about this network the neural programmer network that it actually augmented by addition
and and subtraction then these are rules
right you can augment it with a table of proofs and then ask the network to
actually attend into the truth table people have looked
to this direction so that's one way to do it okay saying basically argument is to do some logical reasoning yeah yeah
yeah hey okay great talk yeah thank you um are is there like a practical rule of
thumb for how many sequence pairs you need to train such a model successfully yes a is there are there any tips to
reduce how many pairs you need if you don't I said okay so usually the bigger
data set the better but like the corpus that people train this on translation for example English to German it's only
about about 3 5 million pairs of sentences or something like that so that's kind of small 3 million right and
still people are able to make it to the state of the art so that's that's pretty encouraging now if you don't even don't
have a lot of data that I would say things like pre-trained your work vectors with language models or a word
to vac right that's that's one area that you have a lot of parameters you can pre
train your model with some kind of language model and then you reduce the sub max that's another area that you
have a lot of parameters or use drop out in the input embed in or drop out some random word in the input sentence so
those things can improve the regular radiation when you don't have a lot of data okay yeah thank you okay yeah
thank you all so we'll reconvene at 6 o'clock for yoshua bengio
closing keynote

----------

-----

--05-- 

-----
Date: 2016.09.27
Link: [TensorFlow Tutorial (Sherry Moore, Google Brain)](https://www.youtube.com/watch?v=Ejec3ID_h0w)

Summary:
In this lecture, Sherry Moore from the Google Brain team delivers a comprehensive tutorial on TensorFlow, a machine learning library developed by Google. The session begins with an introduction to TensorFlow, explaining its purpose, functionalities, and its extensive use at Google. Sherry emphasizes TensorFlow's flexibility and suitability for machine learning applications, attributing its design to close collaboration with researchers.

The tutorial progresses to hands-on coding, guiding attendees through building models to address classic machine learning problems, particularly focusing on linear regression and classification. Sherry meticulously explains the core concepts, such as tensors, dataflow graphs, nodes, and how TensorFlow's architecture enables asynchronous operations.

The practical part of the session includes the construction of neural networks, with detailed walkthroughs of creating variable objects, inference graphs, training graphs, and the use of placeholders. Sherry introduces TensorFlow's modular design, emphasizing its front-end libraries, execution runtime, and compatibility with various devices, including CPUs, GPUs, TPUs, and mobile devices.

Throughout the tutorial, Sherry engages with the audience, answering questions, and encouraging exploration of TensorFlow's capabilities. She introduces advanced features like saving checkpoints, loading models, running evaluations, and adjusting hyperparameters. The practical exercises are designed to solidify understanding, encouraging attendees to modify and experiment with the code.

Sherry underscores TensorFlow's capability to streamline the process from research to prototyping to production, encouraging contributions to the open-source project and highlighting the active support and continual development of TensorFlow by the team.

In the Q&A session, Sherry and her team address various inquiries about TensorFlow's functionalities, including C++ API usage, Windows support, model portability, data loading, and integration with other frameworks. The session concludes with a note on TensorFlow's commitment to advancing machine learning, fostering a collaborative environment, and the availability of resources and support for users.

Transcription:

Introduction
so I'm going to take a picture so I remember how many of you are here smile
like Sammy says my name is sherry Moore I work in a Google brain team so today
I'll be giving a tutorial on tensor flow first I'll talk up a little bit about what tends to flow is and how it works
how we use it at Google and then the important part is that I'm going to work
with you together to build a couple models to solve the most classic machine
learning problems so Cal get your feet beat for those of you from New Zealand anybody from New Zealand so hopefully at
the end you'll be going home with all the tools that you have to build all the
wonderful things that you have watched today like all the image recognition the
training of different colors arts making music so that's the goal so before I go
any further has everybody installed tensorflow yay
Thank you
brilliant thank you and I would like to acknowledge so I know the link here says Syrian but if you have Wolff g TF
tutorial is perfectly fine Wolff is actually the my colleague who spent all the time verifying installation and
every single platform so I would really like to thank him thanks wolf if you're watching and also I have my wonderful
product bus a product manager in the audience somewhere so if you guys have any requests for tensorflow
make sure that you go find him and tell him why that tencel must support this
feature or exact somewhere all right so there he is so with that we can move
forward to talk about tensor flow so what exactly is tends to flow tensor
flow is a machine learning library that we developed at Google and we open-source the last November and ever
What is TensorFlow
since then we have become the most most popular machine learning library and get
help how do we know because we have over
32,000 stars those of you who track github you know how hard it is to get
rid of those acknowledgement and we also have over 14,000 Forks and we have over
800 no 8,000 contributions from 400 developers 400 individual developers and
we designed this specifically for machine learning however is your see
later because of its really flexible dataflow infrastructure it makes it
really suitable for pretty much any application that can fit into that model basically if your model can be
asynchronous in fire on when data is ready you can probably use tinder for it
originally we worked alongside with all the researchers as a matter of fact I was really fortunate when I joined the
team I sit right next to Alex the person who invented alex net so that's how closely we work together as we develop
tends to flow they would tell us no this is how we use it yes when you do this it
makes our lives a lot easier and this is why we believe that we have developed an infrastructure that will work really
well for researchers and also being Google we also always have in mind that we would like to take from research to
prototyping to production in no time we don't want to want you to write all the code that's typically you're just
throwing away we want to write code that can learn to cut and paste and save in the file and privatize it immediately so
tensile is really designing with that in mind so we will have way into your deep
learning school so can anybody tell me if you want to build a neural net what
must you have what are the primitives what are the yeah primitive I think is
the word I'm looking for what must you have to build neural net
anybody what is in the neural net
This American history so in an Iran that you have neurons that's right
so in and you need so all these neurons what do they operate on what do all
these neurons do they process data data and they operate on data and they do
something such as convolution matrix multiplication max pooling average
pooling dropout whatever that is so intensive flow all the data is held in
something called a tensor tensor is nothing more than a multi-dimensional
array for those of you who are familiar with numpy arrays it's very similar to the ND array and the graph I think one
of the gentlemen earlier this morning described there's this concept that the graph which is a composition of all
these neurons that do different functions and all these neurons are
connected to each other through the inputs and outputs so as data become available they would fire by firing men
they do what they're designed to do such as doing matrix multiplication or convolution and then they will produce
output for the next competition know that's computer connected to the output so by doing this so I don't know how
many of you can actually see this animation yeah so this is to really
How TensorFlow works
visualize how tensor flow works all these nodes the Oval ones are
computation this rectangle ones are staple nodes so all these nodes they would generate
output or they take input and as soon as all the inputs for a particular node are
available it would do its thing produce output and then the tensor all the data
which are how in tensors will flow through your network therefore tensor
flow yeah so everybody's like wow this sounds like
magic how does it work so who said is it sir other car glasses any sufficiently was
the word any sufficiently advanced technology is indistinguishable from magic so that's what this is it's just
really awesome excuse me for a second I
know I want I want to get through this as quickly as possible so we can actually do the lab that you're all dying to do so as any good
infrastructure so this is I want to give you a little image of you know how we design this in tensorflow just like any
well-designed infrastructure has to be really modular because being module allows you to innovate to upgrade to
improve to modify to do what everyone with any piece as long as you keep the api's consistent everybody can work in
parallel it's really empowering I think that's one of the wonderful things that's done at Google pretty much any
infrastructure at Google is really modular they talked really about to to each other all you need to maintain is
the API was stability so in this case we
have a front end I think you guys must have seen some examples of how you construct a graph so we have the
Frontend libraries
front-end libraries written your favorite language and if C++ and Python is no your favorite language feel free
to contribute we always welcome contribution so you write you can show your graph in your favorite language and
this graph will be sent to we call the core a tensile execution system that's
your runtime and that's what you all will be running today on your laptop when you open your up your Python
notebook or should be the notebook so the execution runtime depending on where
you are going to run this application it will send the kernel to the
corresponding device so it could be a CPU could be GPO could be your phone could be CPU anybody knows what TPU is
brilliant very nice I was a stratum say anybody knows what TPU is ever there's
like mmm translation so this is good so just to highlight our portability today
Portability
you'll be running intensive roll in your laptop we run it in our data center you everybody can run on your iOS on your
iPhone your Android phone I would love to see people putting it on Raspberry Pi
because can you imagine you can just write on tensorflow application it could
be your security system because you know somebody just stole my bike and my security camera capture all this grainy
stuff that I cannot tell wouldn't it be nice if you do machine learning on this
thing and they just start taking high-resolution pictures you know when when things are moving rather than
constantly capturing all this grainy images which is totally useless so I think the application literally
applications are limitless you know your imagination is delivered so we talked
about what tensorflow is how it works how do we use it at Google we use it
How we use it
everywhere I think you have seen some of the examples we use it to recognize pictures this is actually done with
inception they can recognize after the box one of thousand images you have to
retrain it if you wanted to recognize they're all your relatives or you know your pets it's not difficult and we I
have links you know for you to actually if you want to train on your own images it's really easy they should totally try
it will they be funny we go to your relative your own 40 year reunion you just go hi you know you who you I know
who you are you know just show off a little it would be brilliant and we also use it to do Google Voice Search this is
the one that's super awesome so how many of you use smart reply have you ever
Smart Reply
used smart reply yeah yeah this is awesome especially for those of you who are doing what you're not supposed to do
you know texting while driving your new song email coming in and you can just say oh yes I'll be there you know so
based on the statistics that collected in February over 10% of the
other responses and on mobile is actually done by our smart reply that's or I believe if we have maybe exact can
collect some stats for me later maybe by now you'll be like 80% it's actually
really funny at the very beginning when we train it the first answer is always I love you like that's probably it right
not the right answer we also play games
of you I'm sure have follow this the all kinds of games that are being developed
Games
it's really fun to watch if you watch it literally come up with scenarios for you to play as well it not only learns to
play the game but learns how to make a game for you is fascinating and of
course art everything many of you have done the Steve dream if we have time in the end of the lab we can we can try
this so if you're super fast we can all try to mix a Mart and all those what I
Models
just talked about of course Google being this wonderful generous company and wants to share our knowledge so we have
actually published our models so if you go to that link you'll find all these
inception and captioning language model on the billion words the latest rest net
on c14 sequence the sequence which I think Kwok will be talking about tomorrow and in the world we have many
Highlevel libraries
other high-level libraries so today my lab the lab that we would do will be on
the core tensorflow api's but there are tons of new higher level API such as
some of the mentioned cares and we have slim we have pretty tensor we have TF
learn we have many libraries that's developed on top of the court in several api's then we encourage people to do so
if whatever is out there does not fit your needs perfectly go for it develop yo and we welcome the contribution we
published a lot of that here I might have blurred some of the boundaries but these are basically all the models and
libraries that we have produced and we really love contribution if you have
developable really cool model please do send to us and we would you know we would showcase
your your work so that's the
introduction of tensorflow how does everybody feel are you all ready to get started
alright so okay before you bring up your Python notebook I want to say what we
are going to do first okay so as I mentioned there are two classic machine learning problems everybody does one is
linear regression the other is classification so we are going to do two simple laps to cover those I do have a
lot of small exercises you can play with I encourage you to play with it to be a lot more comfortable so the first one is
Linear Regression
a linear regression so I'm sure it has been covered yeah in today's lectures
somebody must have covered linear regression can you can anybody give me a
one-line summary what is the linear regression problem anybody the
professors well if you don't know go
google it so I didn't know the the audience you know when when semi asked
Mystery Creation
me to do this so I wanted to I wrote this for one of the high schools so I
think it's doom kind of makes sense right because all of us have done have played this game at one point of our
lives like I you know if you if you tell me a five or tell you ten and you try to
guess you know about the equation is we must have all done this I think my friends are still doing on Facebook
saying oh you know only Genius can solve this kind of equation and then they would be like yeah you I solved it I was
like my god if anybody you know I one friend you guys if you click on another one of those sir
but basically this is what we are trying to do in the first lab so we will have a
mystery creation it's really simple it's just a linear you know literally a line and then we I will tell you that this is
you know the formula but I'm not going to give you a weight W and B you know
all of you have learned by now W stands for weight and bias B stands for bias so the idea is that if you are given
enough samples if you're given enough x and y values you should be able to make
a pretty good guess what W and B is so that's what we are going to do so now
Jupiter Notebook
you can bring up your Jupiter notebook if you don't have it up already
yeah everybody have it up yes can I see show them hands everybody
those are yeah brilliant alright so um for pretty much any models
these are going to come up over and over again and just to make sure that you're all paying attention I do have I asked
them if I was supposed to bring Shrek and he said no but I do have a lot of tensorflow stickers and I have all kinds
of little toys so later I'm going to ask this question whoever can answer will
get some mystery present so really pay attention okay so pretty much with it
whenever you build any model there are I would say four things that you need you need input you need data so you're going
to see in both labs we're going to be defining some data you're going to be built building an inference graph I
think in other lectures is also called a forward graph to the point that it produces logits or the logistic outputs
and then you're going to have a training training operations which is where you
would define a loss an optimizer and I
think that's pretty much it hanging and there's the fourth thing yeah and then
you will basically run the graph so the three important things okay you'll always have your data your inference
graph you always have to define your laws and your optimizer and the training is
basically to minimize your loss so I'm going to be asking that later all right so now we know what we're going to do so
you can go start go to that lab yeah everybody have it so shift returned
we'll run the first one you said I have no idea what happening here return again still
nothing however let's see what we are producing here so you can also do the
same on your laptop you can uncomment that plot you can say so you know what
kind of data you're generating so in this case when he returned why are we seeing this is your input data this is
when you try to make a guess when your friend tell me oh you don't give me your x and y so this is how you know when
your X is 0.2 you know your Y is 0.32 so this is basically your input data
yeah everybody following if at any point you're kind of lost raise your hand and
your buddy next you will be able to help you so now
it's all okay I want to say one more thing so today the laughs are all on really core tends to flow ap is the
reason I want to do that I know there are a lot of people who will use carrots use another thing that we have heavily
advertised which is contribute contribute you've learned so I feel like I'm giving you all the ingredients so
even though you could go to Whole Foods and buy the packaged meal you know maybe
one day you don't like the way they cook it so I'm giving you all your lobsters your Kobe beef okay so that you can
actually assemble whatever you want to build to yourself so this next one is
very key it's a very key concept here you see variables so variable intensive
flow is how is corresponding to the square any of you remember this slide
okay I'm going to switch quickly don't freak out so actually I wanted you all
to commit this little graph to to your memory because you'll be seeing this
over and over again and it makes a lot more sense when you have this visual representation so intensive flow the way
we hold all the data the ways and the biases associated associated with your
network is using something called variable it's a state fold operation I'm going to switch back
okay so this is what we are doing in Section 1.3 we are building those square
Variable Objects
nodes in your network to hold these ways and variables and they are the ones when you train that's where their gradients
will be applied to so that they will eventually resemble the target network
that you are trying to to train for so now you have built it wonderful okay so
you can shift return do you see anything nope so exactly we'll have rebuilt let's
uncomment and take a look so these are called the variable objects so at the
bottom of the slide for this lab I have a link which is our Google 3 dogs the
API Docs which is available in github I think you should always have that up so
whenever you want to do something you will know what kind of operations are possible with this object for example I
can say here what's the name of this oh it's called variable 6y so call
variable 6 oh it's because when I create this variable I didn't give it a name so
I can say Sherri's sure you wait I hope that's not
but so see now my variable is called Sheree wait same thing with my so this
would be a good practice because late later
cheery-bye is
well because I ran this so many times every single time you run if you don't restart that it's going to continue to
grow your current path so to avoid that confusion let me restart it restart
ja I had the word sorry
so now so we have done built our input build an inference graph now we can
Training Graph
actually build our training graph and as you have all learned we need to define a
loss function we need to define an optimizer I think it's also called
something else record regulator maybe some other terms and your ultimate goal
is to minimize your loss so I'm not going to do it here but you can do it at your your leisure you can you know
income and all the these things that you have created and see what they are and I
can tell you these are different operations so that's how you actually get to learn about the network that you
have built really well in the next line I'm also not going to uncomment but you should at one point this is how you
cannot you can see what you have built so actually why don't do that because this is really critical and as you debug
this will become so this is the network
that you have built they have names different names they have inputs and outputs they have attributes and this is
how we connect all these nodes together this is your neural net so what you have
what you're seeing right now is your neural net that you have just built yeah everybody following so now the next step
now you're done right you build your network you build all your training now you can let's do some training so in
tensor flow do you remember in the architecture that I showed you have the front-end C++ and Python front-end you
use that to build your graphs and then you send a graph to your runtime and this is exactly what we're doing here
whenever you this is how we talk to the runtime we create something called session you get a handle to the session
and then when you say run you're basically sending this session your graph so this is different from the
other machine learning libraries I forgot which one those are so comparative your happens as you type
tensor flow is different you have to construct your graph and then you'll create session to talk to your runtime
so that it knows how to run on your different devices that's a very important concept
because people constantly compare and it's just different okay so now you can
also commented to see what the initial values are but we're not going to do that we're just going to run it and now
we're going to train the data is not so
what do you think of the data did we succeed in guessing is everybody
following what we're trying to do yeah yes no so what was our job objective
before I started the lab what did I say my objective was yes to guess the
Results
mystery function so have we succeeded it's really hard to tell all right so
now all of you can go to the end and income in this part let's see how
successful we are
so the Greenline was what we have initialized our weight and buyers - yeah
the blue dots were the initial value of the target values and the red dots is
our trained value makes sense so how successful are we great big success yeah
I would say so so any questions any questions so far so
other things so everybody should play with this you're not going to break it this is a notebook Python notebook the
worst that happens is they're just they okay clear all like what I just did and change it so what can you play with
since today you learn all these concepts about different loss motions different optimizers all this crazy different
inputs different data so now you can play with that how about instead of let's pick one so instead of gradient
Other optimizers
descent what are the other optimizers how can you find out I guess that's a
better question if I want to know what other optimizers are available in tensor flow how can I find out very good yes
the github good Google 3 the G 3 doc link with the AP is I'm going to switch
one more tab bear with me so this is when you go there this is what you can
find you can find all that I mean make it bigger so you can find all the
different optimizers so you can play with that so maybe gradient descent is not the
best optimizer you can use so you go there and say why the other optimizers and then you can learn a come here in
search optimizer oh you can say wow you know I have added Delta a dag red Adam
I'm sure there are more a momentum so we also welcome contribution if you don't
like any of these please do you know go contribute write a new optimizer send a
pull request we would love to have it so I would like to say this over and over again we love contribution is an open-source project
so keep that in mind we would love to see your code or your models on github so back to this one how is everybody
feeling this is too simple yeah should we go wet just yes can I say that
oh is that right
Learn something new
he tapped to see all the other optimizers human Oh brilliant
see I didn't even know that learn something new every day let me go there tap here oh yay so this is even easier
thank you clearly I don't program in notebook as often as I should have
so this is where you can all the wonderful things that you can do thank you this is probably a little too low
level I think it has everything but that's a very good tip thank you so
anything else you would like to see what linear regression is too simple you guys all want to register commend some digits
alright so that sounds like a consensus to me so let's move if you just go to
the bottom you can say click on this one
What is M
so this is our M this model so before you start the lab so once again more
return to do so we have all these handwritten digits what does M this
stand for does anybody know what is M does stand for
very good see somebody can Google very good so it has a stencil I think makes
National Institute of Standards and Technology something like that so they
have this giant collection of digits so you know if you go to the post office
you already know that it's the trivial to solve problem but I don't know if they actually use machine learning but
our goal today is to build little never using tensorflow that can recognize these digits once
again we will not have all the answers right so all we know is that the network
the input will give us a 1 and it will say it's a 9 and then the IMP and then
we have the so-called ground truth and then they will look at and say no you're wrong and then we have to say ok fine
this is a difference we are going to train the network that way so that's our goal yeah everybody see the network on
the side so now we can go to the lab so
What is important when building a network
can anybody tell me why the three or four things that's really important whenever you build a network what's the
first one your data second one inference
graph third one your train graph and with this slab I'm going to teach you a
little bit more they are like the rock you know it like when you go to restaurant I not only give you your
lobstery or your Kobe beef I'm also going to give you a little rock so you can cook it ok so in this lab I've also
teach some absolute absolutely critical additional infrastructure pieces such as
how to save a checkpoint how to load from a checkpoint and how do you evaluate your network I think somebody
at one point asked how do you know the network is enough you evaluated to see if it's good enough so those are the
three new pieces of information that I'll be teaching you and also I'll teach
you a really really useful concept is called place holder that was requested
by all the researchers we didn't used to have it but they they all came to us and say when I trained I want to be able to feed my
network any day that we want so that's a really key concept that's really useful for any practical training whenever you
start writing real training code I think you that will come in handy so those are the I think four concepts now that I
will introduce in this lab that's slightly different from the previous on how to save checkpoint how to go from
checkpoint how to run evaluation and how to use placeholders I think the placeholder is actually going to be the
first one so once again we have our typical boilerplate stuff so that you hit return you import a bunch of
libraries the second one this is just for convenience I define a set of
constants some of them you can play with such as the maximum number of steps
where you're going to save all your data how big the batch sizes are but some
other things that you cannot change because of the data that I am providing you for example the amnesties any
questions so far so now we'll read some data it's
everybody there in 2.3 I'm a 2.3 right now so now I use if you don't have slash
temp it might be an issue but hopefully you do if you don't have slash lim
change the directory directory name so
the next one is where we build inference so can anybody is just glancing and tell me what we're building what kind of
network how many layers am i building
I have two hidden layers you have all learned hidden layers here today and I
also have a linear layer which will produce logits that's correct so that's
what all the inference graphs will always do they always construct and they
produce logistic outputs so once again here you can uncomment it and see it what kind of graph you have built once
you have done the whole tutorial by yourself you can actually run tensor
board and you can actually load this graph that you have saved and you can visualize it like what I have shown in
the slide I didn't draw the slide by hand it's actually produced by tensor
boards so you can see the connection of all your notes so I feel that that visual representation is really
important also it's very easy for you to validate that you have indeed build a graph that you thought sometimes people
call something repeatedly and they have generated this check and they grab they're like oh that wasn't what I meant
so being able to visualize it's really important any questions so far see here
I have good habits I actually gave all my variables names once again the hidden layer one hidden layer two they all have
weights and biases weights and biases etc so now we're going to build our
train graphs so here is actually here
Train graphs
there's no new concept once again you define a loss function we once again pick gradient descent as our optimizer
we added a global step variable that's what we will use later when we save our
checkpoints so you actually know at which point what checkpoint this
corresponds to otherwise if you'll always save it to the same name then later you know you said wow this this
result is so wonderful but how long did it take you have no idea so that's a
training concept that we introduced it's called global step basically how long you have trained and we usually save
that with a chair point so you know which chair point has the best information yeah everybody is good
at 2.5 so now the next one is the additional stuff that I just mentioned oh that piece of rock that I'm giving
Placeholders
you now to cook yourself so one is the place holder so we are going to define
two one two hold your image and the other two hold your labels there we
build it this way so that we only need to build a graph once and we will be able to use it for both training
inference and evaluation later it's very handy you don't have to do it this way
and one of the exercises I put in my slides to try to do it differently but this is a very handy way and get you
very far with minimum work so as I said in the slides I know I don't have any
highlighters beam's but you see there it says after you create your placeholders
I said add to collection and remember this up and later we'll see how we're
going to recall this up and how we're going to use it in the next one we're
going to call inference build our inference is everybody following this
part okay and once again we remember our logits and then we create our train up
and our los up just like with linear regression just like with the linear
regression we're going to initialize all variables and now at the bottom of this
Saver
cell that's the second new concept that I'm introducing which is the saver this
is what you will use to do checkpoints to save the states of your network so that later you can evaluate it or if
your training was interrupted you can know from a previous checkpoint and continue training from there rather than
always we initialize all your variables and start from scratch when your training really big networks such as
Inception is absolutely critical because when I I think when I first trained
inception it took probably six days and then later when we have 50 replicas it
took still like stay of the Rs do two and a half days you don't want to have to start from scratch every single time so yeah
everybody got that the placeholder and the saver so now it's 2.7 we're going to
Reduce Loss
go to 2.7 hmm lots of code can anybody
tell me what it's trying to do so this
is an yes so it's trying to minimize loss we can actually see this so I will
run it once okay where did I go okay
very fast it's done but what if I really
want to see what it's doing so python is wonderful so I would like to actually
see did somebody show like how you know your training is going wow they show the
loss going down going down low I think my training is going really well so we're going to do something similar
sorry so I'm going to create a variable audio car losses which is just an array
so here I'm actually going to remember
it
pinned so am i collecting
man plot map la lip anybody remember
this is a plot let's try this whoa look
at that now do you see you're lost going down so it's you train your loss
actually goes down so this is how when you do large-scale training this is what
we typically do we have a gazillion of this jobs running in the morning with just glanced at it and we know which one
is doing really really well so of course you know that that's just when you are up for the typing that's a really really
handy tool but I'm going to show you something even better oh that's part of the exercise me and I
don't have it so it's one of the exercise I also put the answers in the
backup slides that you guys are welcome to cut and paste into a cell they can
actually run all all the evaluation sets against your checkpoint so that you know
how well you're performing so you don't have to rely on your eyes you know cleansing or my loss is going down or
relying on validating a single image but see this is how easy it is this is how
easy the prototype and you can learn it very often our researchers would cut and
paste their collab code and put in a file and and that's basically their
algorithm and they will publish that with their paper they would send it to
our data scientists or production people we would actually privatize some of their research this this is how easy
literally from research to prototyping to production really streamlined and you can do it in no time so for those of you
LS
who have run the step can you do an LS in your data path wherever you'll save
to that wherever you declare your trainer to be what do you see in there
checkpoints that's right that's the that's the money that's after all this
work well the Oldham one during all this training on all these gazillion machines that's where all your ways your biases
are stored so that later you can you know load this network up and do your
inception to recognize images to reply to email to do art etc etc so that's
really critical but how do we use it have no fear all right let's move on to
Checkpoint
2.8 if you are not already there so can somebody tell me what we're trying to do
first that's right first we load the
checkpoint and you remember all the things that we told them told our program to remember the logits
and the image placeholder in the label placeholder how are we going to use it now we're going to feed in some images
from our evaluation and see what it thinks so now if you hit return
Return
what's the ground truth 5 what's our prediction 3 what's the
actual image could be 3 could be 5 you
know but so the machine is getting pretty close why I would I would say that's a 3 ok let's try a different
different one so you can hear return again in the same cell ohai need to
somehow move this so what's the ground truth this time yeah I got it right so you can keep
hitting you know you can keep hitting return and see you know how well it's doing but instead of validating you know
instead of hitting return a hundred times and count how many times I had gotten it wrong as I said in one of the
exercises and I also put the answer in the slide so you can cut and paste and
actually do a complete validation on the whole validation set but what do you
think I really so you can actually hand write a different digit but the trick is that
a lot of people actually try there and told me it doesn't seem to work so remember in on the slide I said this is
what the machine sees this is where I see s and this is more the machine sees so in the end instead of set all the
numbers are between 0 and 1 I believe I could be wrong but I believe it's between 0 & 1 so if you just use a
random tool like your phone you write the number and you upload it number one the picture might be too big and need to
scale it down number two it might have a different representation sometimes it's
from 0 to 255 and you need to scale it you know to the range that M this that
how you have trained your network if you train your network with those data and then it should be able to recognize the
same set of data just like when we teach a baby right if if you have never been exposed to something you're not going to
be able to recognize it just like with oriole one of our colleagues caption was at that program a
while ago anytime when I see something that it doesn't recognize have anybody play with that captioning software is
super fun so you can take a picture and say you know two people eating pizza or
you know dog surfing but any time it sees something that has never been
trained on it would say men talking on the cell phone so for a while we had a
lot of fun with it we would put a watermelon on the post and they would say men talking on the cell phone you put a bunch of furniture in the room you
know with nothing and it was they men talking on the cell phone so it was really fun but just like with your
numbers if you have never trained it with that style like if I write Chinese
characters here it's never going to recognize it but this is pretty fun so you can play with it you know you can
Exercises
see how well see every time see so far is 100 percent other than the first one which I cannot tell either so what are
some of the exercises that we can do here what do you want to do with this lab it's too easy huh because I made it
so easy because know that you guys are all experts but now otherwise I would have done it much harder now let me see what things we can
do so you can uncomment all the graphs
oh so here's one actually you already see it so try this can you guys try
saving the checkpoints say every 100 steps and you're going to have a
gazillion but they're tiny tiny checkpoints so it's okay and try to run evaluation with a different checkpoint
and see what you get do you know how to do that yeah everybody not to do that so the idea is
that when you run the evaluation is in the it's very similar so we typically
run training in the evaluation in parallel or validation so us it trains
Training Evaluations
every so often say every half an hour depending on the the depending on your
problem so with inception every ten minutes we're also the run evaluation to see how well our model is doing so if
our model gets to say 78.6% which I believe is the state of the art we'll be like ooh my mother's done training so
that's how that's why you want to save checkpoints often and then you know validate them often if you're done with
that already did you notice anything if you try to load from a really already checkpoint how is your how good is it
when it tries to identify the the digits just take a wild guess
yeah very bad maybe whenever you every other one is wrong but this M this is
such a small data set is very easy to train and we have such a you know deep network if you only have one layer or
maybe it won't get it right so another
exercise I think all these you can you can do after the lecture after this session is that really try to learn too
evaluation from scratch rather than actually another part but run evaluation
on the complete validation set that's a that's a really necessary skill to
develop as you build bigger models and need to run validation so I think this
is the end of my my lab I do have bonus laughs but I want to cover this first
the bottom line is that tensorflow is really it's for machine learning is really from research to prototyping to
TensorFlow is for Machine Learning
production it's really designed for that and I really hope everybody in the audience can give it a try and if there
are any features that you find it lacking that you would like to see implemented either send us pour requests
Questions
we always welcome contribution I'll talk to my wonderful product manager Zack sitting over there he is taking requests
for features so with that yeah things
that have fun
Thank You Shari did we have time for questions for those who actually tried
it see you so well done and everybody feel like their experts are all ready to
go make arts now right right goes deep dream cool if there are no questions I
hope there's one question I think someone who's trying desperately hi my
Peachy
name is peachy low and first of all thank you for the for introducing tensorflow and for designing it I have
two questions so the first questions is I know the tensorflow have C++ API right so let's
say if I use Kira's or any of the Python front-end I train a model can I have
that sense of loss support adjust I can pull out the C++ model of it and then
just use that yes you can so even if I use for example Kira's custom layer that
I caught using Python I still can get those things correct oh it's just a front-end that's different how you
construct the graph nice but we are not as complete on our C++ API designs for
example a lot of the training libraries are not complete yes so but for the
simple models yes you can do well let's say not the training but let's say if I just want the testing part because I
don't need to do I mean the training I was doing is we do have that already Oh actually if you go to our website
there's a label images does CC I think that's literally just loading from SharePoint and run the inference in C
then that's all written in C++ so that's a good example to follow Oh a second one so another thing that I
noticed that you support almost everything except windows everything acceptable I mean I always Android have
no fear actually we are actively doing that but when I first joined the team I
think there were 10 of us and we have to do everything like before open sourcing all of us were in the in the
in the conference from together we're all riding dog we're fixing everything so now we have more people that's like
the top of our list we would love to support it so so I'm just curious because I I mean when I look at the road
man I didn't see a clear timeline for Windows but the thing I know they just
like the reason why you cannot support Windows is because of basil basil doesn't support Windows so let's say
theoretically well I mean what you think just like I know basil they're just that you will get window Phi at some someone
November that is why they say so once Plato can run in Windows can I expect
wedges I could immediately do tens of law do you foresee some other problem maybe Zac would like to take that
question okay this so yeah let's talk
offline yeah sure thank you very much sorry I great presentation yeah my name
is Yuri fish I have a question about GPUs are they available right now for testing and playing for non Google
employees are we I don't think so at the
moment and do you know when it might be available in the Google well would you like to take that one
I'm so glad we have a Prada boss here so he can okay thank you nice to Tori I
Tori
have a question are there any like plans to integrate tensorflow
with the like open-source framework like my sauce and HDFS to make the distribute
tensorflow easy so there are definitely plans we are also always actively
working on new features but we cannot provide a solid timeline right now so
that we do have like like is you know we do have plans we do have projects in
progress but we cannot commit on a timeline so I cannot give you a time
saying yes by November you have so thank you but if you have this type
of question I think Zac is the best person to answer today oh hi I was
Load your own data
wondering um the sensor flow having examples to load your own data of what witch did um so the current example has
a m nest of data set are there examples out there to load your own data set yes yes definitely I think we have two ones
called the tencel flow poet I think that one that example shows you how you can
know your own data set I think is there
another one Zack are you aware of another one that might be a loading your own data set I know we have retraining
model you know if you go to tensorflow we have an example to do retraining those you can download from anywhere so
in our example we just downloaded a bunch of flowers so you can definitely download whatever pictures that you want
to return thank you hello thank you for
your presentation I have a question concerning the the training you can't you can train using throw tensorflow
in any virtually any system like Android and what about the model is do you
provide anything to move the model to Android is there because I'm generally
you programming Java there and yes so that's a beautiful thing you remember the architecture that I showed yes you
build a model and they just send it to the runtime it's the same model running on any of the different platforms it can
be a laptop and Roy you have your own specific format for the model or it's
Justin you build a model is just bunch of matrix and matrix and values yeah is
there any special special format for your model because I sometimes it will
it is big yes comparable I will not recommend training the inception on your phone because all the convolution is a
bad problem probably kill it ten times over so definitely
so there will be that type of limitation like I think you guys talked about the number of parameters if it blows the
memory footprint on your phone it's just not going to work and if the compute like it special for convolution it uses
of other computers yes that's for straining but what inference you can run it anywhere okay thank you it's the same
model you just restore actually are examples like label image that's our C++
version I think I also wrote one's called classify images in Python that's all so you can run it on your phone so
any of these you can write your own and though the sharepoint and run it on your phone as well so definitely I encourage
you to do that thank you hi I have a question related to tens of
Writing TensorFlow in Python
flow solving so I went through the the online documentation and currently I
think it requires some coding in C++ and then combined with Python is there only
going to be you know only Python solution that's going to be provided or is it always going to be you know I
think you need to do some first step you need to create a module and then you know it just imported into water I am
actually surprised to hear that because I'm pretty sure that you can write the model in just Python or just C++ you
don't have to write it in one way or the other they might have a special exporter tool at one point that was the case they
wrote their exporter in C++ I think that's well probably what you were talking about but you don't have to
build it in any specific way the model is just you can write in whatever
language you like as long as it produces that graph and that's all it needs so so
tender for serving the tutorial actually if you go on the side it had yeah a
little steps actually okay so I will look into that so maybe you can come find me later and now I'll see what the
situations I do know that at one point they were writing the exporter in C++ only but that should have changed by now
because we are doing another version of the serving tensorflow serving and is
there any plan to you know provide API is for other languages like you know
like MX night has something called MX like J's and you know you mean that the front-end front-end yeah yeah we have Co
I think we have Co we have some other languages maybe as I can speak more to it and once again if those languages on
our favorite please do contribute and if you would like us to do it talk to Zach
and maybe he can put out you know maybe I don't know because there's somebody else for the Android you need Java for
nicely so I think that's going to help out in integrating these models with us yeah that's great great feedback will
definitely take note thank you thank you I have a caution I'm having embedded GP
board TX 1 which is an ARM processor and I really wanted to work with the tensorflow but I got to know that it can
only run on x86 boards so when can we expect the tensorflow can support ARM
processors we will have to get back to you after I have consulted with my Prada
boss say when we can add that support thank you sorry one last question thanks
for the presentation sherry I have a question regarding D when you have the model you want to run variants is it
possible to make an executable out of it so we can drop it into a container or
run it separately from serving is that that's something that you guys are looking into just run the inference yeah
just have it as the time as a binary yeah yeah you can definitely do that right now you can yeah you can all use
you are always able to do that you mean just save you man just save the you
won't what I mean is that if you can package it into a single binary source
that you can just pass around yes yes we actually do that today that's how the label image works it's just it's only
individual binary okay they actually converted all the chair points into constants so it doesn't even
need to do this lo etc it just reads a bunch of constants and runs it so it's super fast
yep okay that's a thanks sherry again
we are going to take a short break of ten minutes let me remind you for those who haven't noticed yet but all the
slides of all the talks will be available on the website so do not worry they will be available at some point as
soon as we get them from the speakers oh I forgot to ask my bonus question but in any case I have a lot of tensorflow
stickers up here if you like one to put proudly display your laptop come get it

----------

-----

--04--

-----
Date: 2016.09.27
Link: [Foundations of Deep Learning (Hugo Larochelle, Twitter)](https://www.youtube.com/watch?v=zij_FTbJHsk)
Transcription:

The talks at the Deep Learning School on September 24/25, 2016 were amazing. I clipped out individual talks from the full live streams and provided links to each below in case that's useful for people who want to watch specific talks several times (like I do). Please check out the official website ([http://www.bayareadlschool.org](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbks4OTJuUFNUSkNVeFZEQWRhdkM0cmNNSkN0UXxBQ3Jtc0ttNEY4RVk3QlhKMmJfZk4tRzJ2M25CUlRiaDY2a3hxMHJkMXhtRV84T1U0eUlxN09jczdUZVdzd3k1ZHlkSjd2dGhscnJuazZNMXBYcGplNWJYNmRMOFNuNi1jWmt1VXpFbGhxZzM3eUk3VDZWUmhyRQ&q=http%3A%2F%2Fwww.bayareadlschool.org%2F&v=zij_FTbJHsk)) and full live streams below. Having read, watched, and presented deep learning material over the past few years, I have to say that this is one of the best collection of introductory deep learning talks I've yet encountered. Here are links to the individual talks and the full live streams for the two days:
Intro

that's good all right cool so yes I was asked to give this presentation on the

foundations of deep learning which is mostly going over basic feed-forward neural networks and motivating a little

bit deep learning and some of the more recent developments and and some of the topics that you'll see across the next

two days so I as Andrew mentioned I have

just an hour so I'm gonna go fairly quickly on a lot of these things which I think will mostly be fine if you're

familiar enough with some machine learning and a little bit about neural nets but if you'd like to go into some

of the more specific details you can go check out my online lectures on YouTube it's now taught by a much younger

version of myself and so just search for you go to a shell and I am NOT the guy

doing a bunch of skateboarding and the geek teaching about neural nets so go

check those out if you want more details but so well I'll cover today is I'll

start with just describing and laying out the notation on feverel neural

FOUNDATIONS OF DEEP LEARNING

networks that is models that take an input vector X that might be an image or some text and produces an output f of X

so I'll just describe for propagation and the different types of units and the type of functions we can represent with

those and then I'll talk about how we actually train neural nets describing things like loss functions back

propagation that allows us to get a gradient for training with stochastic gradient descent and mention a few

tricks of the trade so some of the things we do in practice to successfully Train neural nets and then I'll end by

talking about some developments that are specifically useful in the context of

deep learning that is neural networks with several hidden layers that came out you know at the very after the beginning

of deep learning say in 2006 that is things like drop out batch normalization and if I have some time unsupervised

pre-training so let's get started and just talk about assuming we have some

neural network how do they actually functions how do they make predictions so let me lay down the notation so a

multi-layer neural feed-forward neural network is a model that takes as input

some vector X which I'm representing here with a different note for each of the dimensions in my input vector so each

dimension is essentially a unit in that neural network and then it eventually produces at its output layer a an output

and we'll focus on classification mostly so you have multiple units here and each

unit would correspond to one of the potential classes in which we would want to classify our input so if we're

identifying digits in handwritten character images and so we're focusing

on digits you'd have ten digits or you would have sort of zero from zero to nine so you'd have ten output units and

to produce an output the neural net will go through a series of hidden layers and

those will be essentially the components that introduce non-linearity that allows us to capture and perform very

sophisticated types of classification functions so if we have L hidden layers

the way we compute all the layers in our neural net is as follows we first start

by computing what I'm going to call a pre activation I'm going to note that a and imma go I'm going to index the

layers by K so a K is just the pre activation at layer K and that is only

simply going to be a linear transformation of the previous layer so

I'm going to note HK as the activation and the layer and by default I'll assume

that layer zero is going to be the input and so using that notation the pre

activation at layer K is going to correspond to taking the activation at the previous layer K minus one

multiplying it by a matrix WK those are the parameters of the layer those

essentially corresponds to the connections between the units between adjacent layers and I'm going to add a

bias vector that's another parameter in my layer so that gives me the pre activation and then next I'm going to

get a hidden layer activation by applying an activation function this will introduce some non-linearity in the

model so I'm going to call that function G and we'll go over a few choices we

have four common choices for the activation function and so I do this from

layer 1 to layer L and when it comes to the output layer I'll also compute a pre

activation by performing a linear transformation but then I'll usually apply a different activation function

depending on the problem I'm trying to solve so having said that let's go to

some of the choices for the activation function so some of the activation functions you'll see one common one is

this sigmoid activation function it's this function here it's just 1 divided by 1 plus the exponential of minus the

pre activation the shape of this function you can focus on that is this here it takes the pre activation which

can vary from minus infinity to plus infinite and it squashes this between 0 & 1 so it's bounded by below and above

below by 0 and above by 1 okay so it's a it's a function that saturates if you

have very large or very large magnitude positive or negative pre activations

another common choice is the hyperbolic tangent or tange activation function on

this picture here so squash is everything but instead of being between 0 & 1 s between minus 1 and 1 and 1

that's become quite popular in neural nets is what's known as the rectified

linear activation function or in papers you will see the relative unit that

refers to the use of this activation function so this one is different from

the others in that it's not bounded above but it is bounded below and it's actually it will output zeros exactly if

the pre activation is negative so those are the choices of activation functions

for the hidden layers and for the output layer if we're performing classification as I said in the our output layer we

will have as many units as there are classes in which an input could belong and what we'd like is potentially and

what we often do is interpret each units activation as the probability according

to the neural network that the input belongs to the corresponding class that it's labeled Y is the corresponding

class C so C would be like the index of that you in the output layer so we need an

activation function that produces probabilities produces a multinomial distribution over all the different

classes and the activation function we use for that is known as the softmax activation function it is simply as

follows you take your pre activations and you exponentiate them so that's going to give us positive numbers and

then we divide each of the exponentiated pre activations by the sum of all the PD

exponentiated pre activations so because I'm normalizing this way it means that all my values in my output layer are

going to sum to 1 and they're positive because I took the exponential so I can interpret that as a multinomial

distribution over the choice of all the SI different classes ok so that's what I'll use as the activation function at

the output layer and and now beyond the math in terms of conceptually and also

in the way we're going to program neural networks often we will do is that all these different operations the linear

transformations the different types of activation functions will essentially implement all of them as an object and

object that take arguments and the arguments would essentially be what other things are being combined to

produce the next value so for instance we would have an object that might correspond to the computation of pre

activation which would take as argument what is the weight matrix and the bias vector for that layer and take some

layer to transform and that would this object we sort of compute its value by applying the linear activation the

linear transformation and then we might have objects that correspond the specific you know activation functions

or like a sigmoid object or a 10 shop jacked or raloo object and we just combine these objects together chain

them into what ends up being a graph which I refer to as a flow graph that represents the computation done when you

do a forward pass in your neural network up until you reach the output layer so I mentioned it now because that's you'll

see you know the different software's that we presented over a weekend will essentially sort of you know exploit

some of that representation of the computation and neural nets it also be handy for computing gradients which I'll

talk about in a few minutes and so that's how we

perform predictions in neural network so we get an input we eventually reach an

output layer that gives us a distribution over classes if we're performing classification if I want to actually classify I would just assign

the class corresponding to the unit that has the highest activation that would correspond to classifying into the class

that has the highest probability according to the neural net and but then

you might ask the question okay what kind of problems can we solve with neural networks or more technically what

kind of functions can we represent mapping from some input X into some arbitrary output and so if you look at

if you go look at my videos I try to give more intuition as to why we have this result here but essentially if we

have a single hidden layer a neural network it's been shown that with a linear output we can approximate any continuous function arbitrarily well as

CAPACITY OF NEURAL NETWORK

long as we have enough hidden units so that is there's a value for these biases and these weights such that any

continuous function I can actually represent it as well as I want I just need to add enough hidden units so this

result applies if you use activation functions nonlinear activation functions like sigmoid and tan H so as I said in

my videos if you want a bit more intuition as to why that would be you can go check that out but that's a

really nice result it means that by focusing on this family of machine learning models that our neural networks

I can pretty much potentially represent any kind of classification function however this result does not tell us how

do we actually find the weights and the bias values such that I can represent a given function it doesn't essentially

tell us how do we train a neural network and so that's what we'll discuss next

let's talk about that how do we actually from a data set train a neural network

to perform good classification on for that problem so what we'll typically do

is use a framework that's very generic in machine learning known as empirical risk minimization or structural risk

MACHINE LEARNING

minimization if you're using regularization so this framework essentially transformed

a problem of learning as a problem of optimizing so what we'll do is that will

first choose a loss function that I'm noting as L and the last function it

compares the output of my model so the output layer of my neural network with the actual target

so I'm indexing with it exponent here with T to essentially ask the index over

all my different examples in my training set and so my loss function will tell me

is this output good or bad given that the label is actually Y and well I'll do

I'll also define a regularizer so theta here is you can think of it as it's just

the concatenation of all my biases and all of my weights in my neural net so those are all the parameters of my

neural network and the regularizer will essentially penalize certain values of

these weights so as I'll talk more specifically later on for instance you might want to have your way to not be

too far from zero that's a frequent intuition that we implement with regularizer and so the optimization problem that

we'll try to solve when learning is to minimize the average loss of my neural

network over my training example so summing over all training examples I have capital T examples plus some weight

here that's known as the weight DK some hyper parameter lambda times my regular Iser so in other words I'm going to try

to have my loss on my training set as small as possible over all the training

example and also try to satisfy my regularizer as much as possible and so now we have this optimization

problem and we learning will just correspond to trying to solve this problem so performing this finding this

argument here for over my weights and my biases and if I want to do this I can

just invoke some optimization procedure from the optimization community and the

one algorithm that you'll see constantly in deep learning is stochastic gradient descent this is the optimization

algorithm that will often use for training neural networks so SGD

stochastic gradient descent functions as follows you first initialize all of your parameters that

is finding initial values for my weight matrices and all of my bio C's and then

for a certain number of epochs so an epoch will be a full pass over all my examples that's what I'll call an epoch

so for a certain number of full iterations over my training set

I'll draw each training example so I pair X input X target Y and then I'll

compute what is the gradient of my loss with respect to my parameters all of my

parameters all my weights and all my biases this is what this notation here so nabla for the gradient of the loss

function and here I'm indexing with respect to which parameter I want the gradient so I'm going to compute what is

the gradient of my last function with respect to my parameters and plus lambda

times the gradient of my regularizer as well and then I'm going to get a direction in which I should move my

parameters since the greyman tells me how to increase the loss I want to go in

the opposite direction and decrease it so my direction will be the opposite so that's why I have a minus here and so

this Delta is going to be the direction in which I'll move my parameters by taking a step and the step is just a

step size alpha which is often referred to as a learning rate times my direction

which I just add to my current values of my parameters my biases and my weights

and that's going to give me my new value for all of my parameters and I iterate like that over going over all pairs x

wise computing my gradient taking a steps out in the opposite direction and then doing that several times okay so

that's how stochastic gradient descent works and that's essentially the learning procedure it's represented by

this this procedure so in this algorithm there are few things we need to specify to be able to implement it and execute

it we need a loss function the choice for the loss function we need a procedure that's efficient for computing the

gradient of the loss with respect to my parameters we need to choose a regularizer if you want one and we need

a way of initializing my parameters so next what I'll do is go through each of these these four

different things we need to choose before actually being able to execute the classic gradient descent so first

LOSS FUNCTION

the last function so as I said we will interpret the output layer as assigning probabilities to each potential class in

which I can classify my input X well in this case something that would be

natural is to try to maximize the probability of the correct class the actual class in which my example XT

belongs to I'd like to increase the value of the probability assigned by computed by my neural network and so

because we set up the problem in which we have a loss that we minimize instead

of maximizing the probability what we'll actually do is minimize the negative and the actual log probability so the log

likelihood of assigning X to the correct class Y so this is represented here so

given my output layer and the true label Y my loss will be minus the log of the

probability of Y for minor according to my neural net and that would be well take my output layer and look at the

unit so index the unit corresponding to the correct class so that's why I'm indexing by Y here we take the log

because numerically it turns out to be more stable we get nicer looking gradients and sometimes in certain

software's you'll see instead of talking about the negative log likelihood or log probability you'll see it referred as

the cross entropy and that's because you can think of this as performing a sum

over all possible classes and then for each class checking well is this potential class the target class so I

have an indicator function that is one if Y is equal to C so if my iterator

Class C is actually equal to the real class I'm going to multiply that by the

log of the probability actually assigned to that class C and this this function

here so this expression here is like a cross entropy between the empirical distribution which assigns 0 probability

to all the other classes but a probability of 1 to the correct class and the actual distribution over

that my neural net is computing which is f of X okay that's just a technical

detail you can just think about this here I only mention it because in certain libraries it's actually mentioned as the cross-entropy a loss so

that's for the loss then we need also a procedure for computing what is the gradient of my loss with respect to all

of my parameters in my neural net so the biases and the weights you can go look

at my videos if on the actual derivation of all the details for all of these different expressions I don't have time

for that so all I'll do and presumably a lot of you I actually seen you know these derivations if you haven't just go

check out the videos in any case I'm going to go through what the algorithm is I'm going to highlight some of the

key points that will come up later in understanding out actually back propagation functions so the basic idea

is that we'll compute gradients by exploiting the chain rule and we'll go from the top layer all the way to the

bottom computing gradients for layers that are closer and closer to the input as we go

and exploiting the chain rule to exploit or reuse previous computations we've made at upper layers to compute the

gradients at the layers of below so we usually start by computing what is the

gradient at the output layer so what's the gradient of my loss with respect to

BACKPROPAGATION

my output layer it actually it's more convenient to compute the loss with respect to the pre activation it's

actually a very simple expression so that that's why I have the gradient of this vector a L plus 1 that's the pre

activation at the very last layer of the loss function which is minus the log f of XY and it turns out this gradient is

super simple it's minus II of Y so that's the one Hut vector for class Y so

what this means is a of Y is just a vector filled with a bunch of zeros and then the one at the correct class so if

Y was the fourth class then in this case it would be this vector we have a one at the fourth dimension so e of Y is just a

vector it's we call it the one Hut vector full of zeros and the single one at the position corresponding to the

correct class so this part of the grain is essentially saying is that I'm going to increase I

want to increase the probability of the correct class I want to increase the pre activation which will increase the

probability of the correct class and I'm going to subtract what is the current probabilities assigned by my neural net

to all of the classes so f of X that's my output layer and that's the current beliefs of the neural net as to in which

class what's the probably of signing the input to each class so what this is

doing is essentially trying to decrease the probability of everything and specifically decrease it as much as I

the neural net currently believes that the input belongs to it and so if you

think about the subtraction of these two things well for the class that's the correct class I'm going to have one

minus some number between zero and one because it's a probability so that's going to be positive so I'm going to

increase the probability of the correct class and for everything else it's going to be zero minus a positive number so

it's going to be negative I'm actually going to decrease the probability of everything else so in two Li and it

makes sense this gradient has the right behavior and I'm going to take that pre activation gradient I'm going to

propagate it from the top to the bottom and and essentially iterating from the

last layer which is the output layer l plus 1 all the way down to the first layer and as I'm going down I'm going to

compute the gradient with respect to my parameters and then compute what's the gradient for the pre activation that the

layer below and then iterate like that so at each iteration of that loop I take

what is the current gradient of the loss function with respect to the pre

activation at the current layer and I can compute the gradient of the loss function with respect to my weight

matrix so not doing the derivation here it it's actually simply this vector so

my in my notation I assume that all the vectors are column vectors so this pre activation gradient vector and I

multiply it by the transpose of the activations so the value of the layer right below the layer K minus one so

because I take the transpose that's a multiplication like this you can see if I do the outer product essentially between these two vectors

I'm going to get a matrix of the same size as my weight matrix so it all checks out that makes sense it turns out that the

gradient of the loss with respect to the bias is exactly the gradient of the loss with respect to the pre activation so

that's very simple so that gives me now my gradients for my parameters and now I need to compute okay what is going to be

the gradient of the pre activations at the layer below well first I'm going to get the gradient

of the last function with respect to the activation at the layer below well

that's just taking my pre activation gradient vector and multiplying it by for some reason does it show here but

and multiplied by the transpose of my weight matrix super simple operation just a linear transformation of my

gradients at layer cake linear and transform to get my gradients of the activation at the layer K minus one and

then to get the gradients of the pre activation so before the activation function

I mean to I'm gonna take this gradient here which is the gradient of the activation function at the layer K minus

one and then I applied the gradient corresponding to the partial derivative of my nonlinear activation function so

this here this refers to an element-wise product so I'm taking these two vectors this vector here in this vector here I'm

going to do an element-wise product between the two and this vector here is just a partial derivative of the

activation function for each unit individually that I've put together into a vector okay this is what this

corresponds to now the key things to notice is first that this path computing

all the gradients and doing all these iterations is actually fairly cheap its complexity is essentially the same as

the one is doing a forward pass so all I'm doing are linear transformations

multiplying by matrices in this case the transpose of my weight matrix and then I'm also doing this sort of nonlinear

operation where I'm multiplying by the gradient of the activation function that's the first thing to notice and the

second thing to notice is that here I'm doing this element-wise product so if any of these terms here for a unit is

very close to zero then the pre activation gradient is going to be zero for the next layer and I highlight this

point because essentially whenever that's something to think about a lot when you're training neural nets

whenever this gradient here these partial derivatives come close to zero that it means the grain will not

propagate well to the next layer which means that you're not going to get a good gradient to update your parameters

now when does that happen when will you see these terms here being close to zero

ACTIVATION FUNCTION

well that's going to be when the partial derivatives of these nonlinear activation functions are close to zero

or zero so we can look at the partial derivative say of the sigmoid function it turns out it's super easy to compute

it's just the Sigma itself times 1 minus the sigmoid itself so that means that

whenever the activation of the unit for sigmoid unit is close to 1 or close to 0 I essentially get a partial there that's

close to zero you can kind of see it here the slope here is essentially flat and the slope here is flat that's the

value of the partial derivative so in other words if my pre activations are

very negative or very positive so if my unit is very saturated then gradients will have a hard time propagating to the

next layer that's the key inside here same thing for the tension so the turns

out the partial derivative is also easy to compute you just take the tangible you square it and going to subtract it

to 1 and yeah indeed if it's close to minus 1 or close to 1 you can see that

the slope is flat so again if the unit is saturating gradients will propagate I

have a hard time propagating to the next layer and for the relu the rectified

linear activation function the gradient is even simpler it's you just check

whether the pre activation is greater than 0 if it is the partial derivative is 1 if it's not at 0 so actually either

we're going to multiply by 1 or 0 you essentially get a binary mask when you're performing the propagation

through their value and you can see it the the slope here is flat and otherwise you have a linear function so actually

here at the shrinking of the grade and toward 0 is even harder it's exactly multiplying by

zero if your have a unit that's saturating below and beyond all the math

in terms of actually using those in practice during the weekend you'll see three different libraries that

essentially allows you to compute these gradients for you you actually usually don't write down backdrop you just use

all of these modules that you've implemented and it turns out there's a way of automatic automatic ly differentiating your loss function and

getting gradients for free in terms of effort in terms of programming effort with respect to your parameters so

conceptually the way you do this and you see essentially three different libraries doing it in slightly different

ways what you do is you up meant your flow graph by adding at the very end the

FLOW GRAPH

computation of your loss function and then each of these boxes which are conceptually objects that are taking

arguments and computing a value you're going to augment them to also have a method that's a backdrop or B prop

method you'll often see actually this expression being used be prop and what this method should do is that it should

take as input what is the gradient of the loss with respect to myself and then it should propagate to its arguments so

the things that its parents in the flow graph the things that takes to compute its own value it's going to propagate them using the chain rule what is their

gradients with respect to the loss so what this means is that you would sort

of start the process by initializing well the gradient of the loss with respect to itself is 1 and then you pass

the B prop method here 1 and then it's going to propagate to its argument what

is by using the chain rule what is the gradient of the loss with respect to f of X and then you're going to call B

prop on this object here and it's going to compute well add the gradient of the loss with respect to myself f of X from

this I can compute what's the gradient of my argument which is the pre activation at layer 2 which is back to

the loss so I'm going to reuse the computation I just got and update it using my what is essentially the

Jacobian and then I'm going to take the pre activation here which now knows what is the gradient of the loss with respect

to itself activation it's going to propagate to the weights and the biases and the layer

below update them with informing them of what is the grain into the last with respect to themselves and you continue

like this essentially going through the flow graph but in the opposite direction so the library torch the basic library

torch essentially functions like this quite explicitly it you construct you chain these elements together and then

when you're performing back propagation you're going in the reverse order of these chained elements and then you have

libraries like torch other grand piano and tens of which you learn about which are doing things slightly more

sophisticated there and you'll learn about that later on okay so that's the

REGULARIZATION

discussion of how you actually compute gradients of the last with respect to the parameters so that's another

component we need in stochastic grain in this end we can choose a regular Weiser one that's often used is the l2

regularization so that's just the sum of the squared of the all the weights and the gradient of that is just twice times

the weight so it's a super simple gradient to compute we usually don't regularize the biases

there's no particularly important reason for that it's just it there much for

your by see so it seems less important and often this l2 regularization is

often referred to as weight DK so if you hear about weight decayed that often refers to l2 regularization and then

INITIALIZATION

finally and this is also a very important point you have to initialize

the parameters before you actually start doing back prop and there are a few tricky cases you need to make sure that

you don't fall into so the biases often we initialize them to 0 there are

certain exceptions but for the most part we initialize them to 0 but for the weights there are a few things we can't

do so we can't initialize the weights to 0 and especially if you have 10 H activations the reason and I won't

explain it here but it's not a bad exercise to try to figure out why is that essentially when you do your first

pass you're going to get gradients for all your parameters that are going to be 0 so I'm going to be stuck at this 0

initialization so we can do that we can't initialize all the weights to

exactly the same value if again you think about it a little bit what's going

to happen is essentially that all the weights coming into a unit within the layer are going to have exactly the same

gradients which means they're going to be updated exactly the same way which means they're going to stay constant the

same that comes them but they're going to stay the same the whole time so it's as if you have multiple copies of the

same unit so you essentially have to break that initial symmetry that you would create if you initialize

everything to the same value so we end up doing most of the time is initialized the weights to some randomly generated

value often we generate them there are few other recipes but one of them is to initialize them from some uniform

distribution between lower and upper bound this is a recipe here that is

often used that has some theoretical grounding that's was derived specifically for the 10h there's this

pepper paper here by exactly Goho and yoshua bengio you can check out for some intuition as to oh you know how you

should initialize the weights but essentially this should be initially random and this should be initially close to zero random to break symmetry

and close to zero so that initially the units are not already saturated because

if the units are saturated then there are no gradients that are going to pass through the units you essentially going to get gradients very close to zero at

the lower layers so that's the main intuitions they have weights that are small and close to zero small and random

okay so those are the pieces we need for running stochastic gradient descent so

that allows us to take a training set and run the certain number of epochs and app the neural nets learn from that

training set now there are other quantities in our neural network that we haven't specified out to choose them so

those are the hyper parameters so usually we can have a separate validation set most people here are

familiar with machine learning so that's a typical procedure and then we need to select things like ok how many layers do

I want how many units per layer do I want what's the step size the learning rate of my stochastic gradient descent

procedure that alpha number what is the weight decay that I'm going to use so a

standard thing in machine learning is to perform a grid search that is if I have to our

MODEL SELECTION

parameters I list out a bunch of values I want to try so for the number of hidden units maybe I want to try a hundred a thousand and two thousand say

and then for the learning rate maybe I want to try 0.01 and 0.001 so a grid

search would just try all combinations of these three values for their hidden units and these two values for the

learning rates so that means that the more I providers there are it's the

number of configurations you have to try out blows up and grows exponentially so

another procedure that is now more more common which is more practical is to

perform a form of random search in this case what you do is for each parameter you actually determine a distribution of

likely values you'd like to try so it could be so for the number of hidden units maybe I do a uniform distribution

over all integers from a hundred to a thousand say or maybe a log uniform distribution and for the learning rate

may be again the log uniform distribution but from 0.001 to 0.01 say

and then to get an experiment to get values for my hyper parameters to do an

experiment with and get a performance of my validation set I just independently sample from these distributions for each

hyper parameter to get a full configuration for my experiment and then because I have this way of getting one

experiment I do it independently for all of my jobs all of my experiment that I will do so in this case if I know I have

like enough compute power to do 50 experiments I just sample 15 dependent

samples from these distributions for parameters perform these 50 experiments

and I just take the best one what's nice about it is that there are no unlike grid search there are never any holes in

the grid that is you just specify how many experiments you do if one of your jobs died well you just have one less

but there's no hole in your experiment and also one reason why it's particularly useful this approach is

that if you have a specific value in grid search for one of the hyper parameters that just makes the

experiment not work at all so learning rates are a lot like this if you have a learning rate that's too high it's quite

possible that convergence of the optimization will not converge well if you're using a grid search it means that

for all the experiments that use that specific value of the learning rate they're all going to be garbage they're all not going to be useful and you don't

really get this sort of big waste of computation if you do random search because most likely all the values of

your hyperparameters are going to be unique because their sample say from a uniform distribution over some some

range so that actually works quite well and and and quite recommended and there

are more advanced methods like methods based on machine learning bayesian optimization and or sometimes known as

sequential model based optimization that I won't talk about but that works a bit

better than random search and and that's another alternative if you think you

have an issue finding good hyper parameters is to investigate some of these more advanced methods now you do

KNOWING WHEN TO STOP

this for most of your hyper parameters but for the number of epochs the number of times you go through all of your

examples in your training set what we usually do is not grid search or random

search but we use a thing known as early stopping the idea here is that if I've trained a neural net for 10 epochs while

training a neural net with all the other hyper parameters kept constant but one more epoch is easy I just do one more

epoch so I shouldn't try to I shouldn't start over and then do say eleven epochs from scratch and so what we would do is

we would just track what is the performance on the validation set as I do more and more epochs and what we will

typically see is the training error will go down but the validation set performance will go down and eventually

go up the intuition here is that the gap between the performance on the training

set and the performance on the validation set will tend to increase and since the training curve cannot go below

usually some bound then eventually the validation set performance has to go up

sometimes it won't sell go up oh is sort of stay stable so with early stopping what we do is that if we reach a point

where the validation set performance hasn't improved from some certain number of iterations which we refer to as the

look-ahead we just stop we go back to the neural net that had the best performance overall in the validation set and that's

my neural network so I have now a very cheap way of actually getting the number of iterations or the number of epochs

over my training set a few more tricks of the trade so it's always useful to

OTHER TRICKS OF THE TRADE

normalize your data it will often have the effect of speeding up training if you have real valued data for binary

data that usually keep it as it is so what I mean by that is just subtract for

each dimension what is the average in the training set of that dimension and then dividing by the standard deviation

of each dimension again in my input space so this can speed up training we

often use a decay on the learning rate there are a few methods for doing this

one that's very simple is to start with a large learning rate and then track the performance on the validation set and

once on the validation set it stops improving you decrease your learning rate by some ratio maybe you're divided

by two and then you continue training for some time hopefully the validation set performance starts improving and

then at some point it stops improving and then you stop or you divide again by two so that sort of gives you an

adaptive using the validation set an adaptive way of changing your learning rate and that can again work better than

having a very small learning rate than waiting for a long time so making very fast progress initially and then slower

progress towards TM also I've described

so far the approach for training neural nets that is based on a single example

at a time but in practice we actually use what's called mini batches that is we compute the last function on the

small subset of example say 64 128 and then we take the average of the loss of

all these examples in that mini batch and that's actually we compute the gradient of this average loss on that

mini batch the reason why we do this is that it turns out that you can very

efficiently implement the forward pass over all of these 64 128 examples in my

mini batch in one pass by instead of doing vector matrix multiplications when

we come the pre activations doing matrix matrix multiplications which are faster than

doing multiple matrix vector multiplications so in your code often there will be this other hyper parameter

which is mostly optimized for speed in terms of how quickly training will proceed of the number of examples in

your mini batch other things to improve optimization might be using a thing like

momentum that is instead of using as the descent direction the gradient of your

last function I'm actually going to track a descent direction which I'm going to compute as the current gradient

for my current example or mini-batch plus some fraction of the previous

update the previous direction of update and better now is a hyper parameter you

have to optimize so what this does is if all the update directions agree oh across multiple updates then it will

start picking up momentum and actually make bigger steps in those directions and there are multiple even more

advanced methods for adding adaptive types of learning rates I mentioned them

here very quickly because you might see them in papers there's a method known as a de grab where the learning rate is

actually scaled for each descent for each dimension so for each weight and each by seize it's going to be scaled by

what is the square root of the cumulative sum of the squared gradients

so what I track is I take my gradient vector at each step I do an element-wise square of all the dimensions on my

gradients my gradient vector and then I accumulate that in some variables that I'm noting as gamma here and then for my

descent direction I take the gradient and I do an element-wise division by the square root of this cumulative sum of

squared gradients there's also rmsprop which is essentially like a de grab but instead of doing a cumulative stuff a sum we're

going to do an exponential moving average so we take the previous value x sub factor plus one minus this factor

times the current squared gradient so that's rmsprop and then there's adam which is essentially a combination of

rmsprop with momentum which is more involved and i won't have time to describe it here but that's

method that's often you know actually implemented in these different softwares and that people seem to use with a lot

of success and finally in terms of

GRADIENT CHECKING

actually debugging your implementations so for instance if you're lucky you can

build your neural network without difficulty using the current tools that are available in torch or 10 to Flora

Theano but maybe sometimes you actually have to implement certain gradients for a new module and a new box in your flow graph

that isn't currently supported if you do this you should check that you've implemented your gradients correctly and

one way of doing that is to actually compare the gradients computed by your code with a finite difference of

estimate so what you do is for each parameter you add some very small epsilon value say 10 to the minus 6 and

you compute what is the output of your module and then you subtract the same thing but where you've subtracted the

small quantity and then the divide by 2 epsilon so if epsilon is converges to

zero then you actually get the partial derivative but if it's small it's going to be an approximate and usually this

finite difference estimate will be very close to a correct implementation of the real gradient so you should definitely

do that if you actually implemented some of the gradients in your code and in another useful thing to do is to

DEBUGGING ON SMALL DATASET

actually do a very small experiment on the small data set before you actually run your full experiment on your

complete data set so you say 50 examples so just taking a random subset of 50

examples from your your data set actually just make sure that your code can over fit to that data can

essentially classify it perfectly given you know enough capacity that you would

think it should get it so if it's not the case then there's a few things that

you might want to investigate maybe your initialization is such that the units are already saturated initially and so

there's no actual optimization happening because some of the gradients on some of the weights are exactly zero so you

might want to check your initialization maybe your gradients are just you know you're using a model you implemented

gradients for and maybe there are gradients are not properly implemented maybe you haven't normalized your input

which creates some instability making it harder for stochastic gradient descent to work successfully maybe your

learning rate is too large then you should consider trying smaller learning rates that's actually a pretty good way

of having a some idea of the magnitude of the learning rate you should be using and and then once you actually over fit

in your small trainings that you're ready to do a full experiment on on a larger data set that said this is not a

replacement for gradient checking so backdrop is and stochastic gradient descent it's a great algorithm that's

very bug resistant you will pretend potentially see some learning happening

even if some of your gradients are wrong or say exactly zero so you should that's great you know if you're an engineer and

you're implementing things spun would code is somewhat bug resistant but if you're actually doing science and try to

understand what's going on that's that can be a complication so do do both gradient checking and a small experiment

like that all right and so for the last few minutes I'll actually try to

motivate what you'll be learning quite a bit about in the next two days that is

the specific case for deep learning so I've already told you that if I have a

neural net win enough hidden units theoretically I can potentially represent pretty much any function any

classification function so why would I want multiple layers so there are a few motivations behind this the first one is

taken directly from our own brains so we know in the visual cortex that the light

that hits our retina eventually goes through several regions in the visual cortex eventually reaching narrow known

as v1 when you have units that are or neurons that are essentially tuned to small forms like edges and then it goes

on to v4 where it's likely more complex patterns that the units are tuned for and then you reach AIT where you

actually have neurons are specific to certain objects or certain units and so the idea here is that perhaps that's

also what we want another artificial say you know vision system we'd like it if

it's detecting faces to have a first layer that detects simple edges and then another layer that perhaps puts these

edges together detecting slightly more complex things nose or mouth or eyes and then eventually have a layer that combines

these slightly less abstract or more abstract units to get something even

more abstract like a complete phase there's also some theoretical justification for doing using multiple

layers so the early results were mostly based on studying boolean functions or a

function that takes as input can think of it as a vector of just zeros and ones and you could show that there are

certain functions that if you add the essentially a boolean neural network or

essentially a boolean circuit and you restricted the number of layers of that

circuit that there are certain functions that in this case to represent certain boolean functions exactly you would need

an exponential number of units in each of these layers whereas if you allowed yourself to have multiple layers then

you could represent these functions more compactly and so there's that's another motivation that perhaps with more layers

we can represent fairly complex functions in a more compact way and then

there's the reason that they just work so we've seen in the past few years great success in speech recognition

where it's essentially revolutionized the field where everyone's using deep learning for speech recognition and same

thing for visual object recognition where again deep learning is sort of the method of choice for identifying objects

and images so then why are we doing this only recently why didn't we do deep

learning way back when back prop was invented which is essentially in 1980s and even

before that so it turns out training deep neural networks is actually not that easy there are few hurdles that one

can be confronted with I've already mentioned one of the issue which is that some of the gradients might be fading as

you go from the top layer to the bottom layer because we keep multiplying by the derivative of the activation function so

that makes training hard it could be that the lower layers at very small gradients are barely moving and

exploring the space of correct you know features to learn for a given problem so

that sometimes that's the problem you find you have a hard time just fitting your data and you're essentially underfitting

or it could be that with you know deeper neural nets Oh bigger neural nets we

have more parameters so perhaps sometimes actually overfitting we're in a situation where all the functions that

we can represent with the same neural net represented by this gray area function actually includes yes the right

function but it's so large that for a finite training set the odds that I'm going to find the one that's close to

the true classifying function the real system that like to have is going to be very different so in this case I mean

I'm essentially overfitting and that might also be a situation we're in and

unfortunately there's never there are many situations where one problem is

observed over fitting or under fitting and so we essentially have you know in

the field develop tools for finding both situations and I'm going to rapidly touch a few of those which you will see

will come up later on in multiple talks so one of the first hypothesis which

might be that you're under fitting well you can essentially just fight this by waiting longer so training longer if you

have your grayness are too small and this is essentially why you're progressing very slowly when you're training well if you're using GPUs and

are able to do more iterations over the same training set within less time that

might just you know solve your problem of underfitting and I think we've seen some of that and this is partly why GPUs

have been so game-changing for deep learning or you can use just better optimization methods also and if you're

overfitting well we just need better regularization i've been involved early

on in my PhD on using unsupervised learning as a way to regularize neural

nets if I have time I'll talk a little bit about that then there's another method you might have learned heard

about known as dropout so I'll try to touch at least two methods that are

essentially trying to address some of these issues so the first one that I'll talk about this dropout it's actually

DROPOUT

very easy very simple so the idea of if our neural net is essentially

overfitting so it's too good at training on the training set well we're essentially going to training

when I make it harder to fit the training set and where we're going to do that and dropout is that we will

stochastically remove hidden units independently so for each hidden unit

before we do a forward pass we'll flip a coin and we'd probably have we will

multiply the activation by zero with probability 1/2 we'll multiply it by 1

so what this means is that if a unit is multiplied by 0 it's effectively not in the neural net anymore and we're doing

this independently for each hidden units so that means that in a layer a unit

cannot rely anymore on the presence on any other units to try to sort of

synchronize and adapt to perform a complex classification or learn a

complex feature and that was partly the motivation behind dropout is that this procedure might encourage types of

features that are not co-adapted and are less likely to overfit so we often use

0.5 as the probability of dropping out a unit it turns out it often surprisingly

is the best value but that's another hyper parameter you might want to tune and in terms of how it impacts an

implementation of back prop it's it's very simple so the forward pass before I do it I just sample my binary masks for

all my layers and and then when I'm performing back drop well my gradient on

the oh sorry so that's the Ford pass yeah I'm just multiplying by this binary mask here so super simple change and

then in terms of back prop well I'm also going to multiply by the mask when I get

my gradient on the pre activation and also you know don't forget that the activations are now different they

actually include the masks in in my notation it's a very simple change the forward and backward pass when you're

training and also another thing that I shouldn't emphasize is that the mask is being resampled for every example so

before you do a forward pass you resample the mask you don't keep it you know sample at once and then use it the

whole time and then that test time because we don't really like a model

that sort of randomly changes its output because it will if we stochastically change the masks what we do is we

replace the mask by the probability of dropping out a unit so actually of

keeping a unit so if we 0.5 that's just 0.5 we can actually show

that if you have a neural net with a single hidden layer doing this transformation at test time multiplying

by 0.5 is equivalent to doing a geometric average of all the possible neural networks with all the different

binary mask patterns so it's essentially one way of thinking about drop out in the single layer case is that it's kind

of an in sembly method we have a lot of models an exponential number of models which are all sharing the same weights

but have different masks that intuition though doesn't transfer for deep neural

nets in the sense that you cannot show this result it really only applies to a single neural networks in gold hidden

layer so in practice it's very effective but do expect some slowdown in training

so often we tend to see that training or network to completion will take twice as many epochs if you're using dropout with

0.5 and here you have the reference if you want to learn more about different variations of dropouts and so on and

I'll and I'll probably won't talk about the unsupervised retraining for lack of time but I'll talk about another thing

that you'll definitely probably hear about and that's implementing these different packages which is Bachelor

organization Bachelor ization is kind of interesting in the sense that it's been shown to better optimize that is certain

networks that would otherwise under fit would not under fit as much anymore fuse Bachelor ization

but also it's been shown that when you use batch normalization dropout is not as useful and drop out being a

regularization method that suggests that perhaps patch normalization is also regularizing in some way so these things

are not you know one or the other they're not mutually exclusive you can have a regularizer that also turns out

helps you better optimize so the intuition behind batch normalization is

BATCH NORMALIZATION

you know much like I've suggested that normalizing your inputs actually can help speeding up training well how about

we also normalize all the hidden layers when I'm doing my forward pass so now

the problem in doing this is that I can compute the mean and the standard deviations of my inputs once and for all

because they're constant but my hidden layers are constantly changing because I'm training these parameters

so the mean and the standard deviation of my units will change and so I it

would be very expensive if every time I did an update of my parameters I recomputed the means and the standard

deviations of all of my units so bachelors ation addresses some of these issues as follows so the way works is

first batch the normalization is going to be applied on actually the pre activation so not the activation of the

unit but before the non-linearity during training to address the issue that we

don't want to compute means over the full training set because that would be too slow I'm actually going to compute it on each mini batch so I have to do

mini batch training here I'm going to take my small mini batch of 64 128 examples and that's the set of examples

on which I'm going to compute my means and standard deviations and then when I do back prop I'm actually going to take

into account the normalization so now there's going to be a gradient going through the computation of the mean and

the standard deviation because they depend on the parameters of the neural network and then that test time we'll

just use the global mean and global standard deviation once I finished training I can actually do a full pass

over the whole training set and got all of my means and standard deviations so

that's the essentially the pseudocode for that taken out of the paper directly so if X is a pre activation for a unit

and have multiple pre activations for a single unit across my mini batch I would

compute what is the average for that unit pre activation across my examples in my mini batch compute my variance and

then subtract the mean and divide by the square root of the variance plus some epsilon for numerical stability in case

the variance is too close to zero and then another thing is that actually batch normalization doesn't just perform

this normalization and outputs the normalize pre activation it then actually performs a linear

transformation on it so it multiplies it by this parameter gamma which is going to be trained by gradient descent and

it's often called a gain parameter of batchelomez ation and it adds a bias

better and the reason is that if I'm subtracting by the mean then each of these you

have the biased parameter so if I subtracted then this essentially here

there's no bias anymore it was present here was present here and now it's been subtracted to have to add the bias but

after the bachelor ization essentially so these betters here are essentially the new bias parameters and those will

actually be trained so we do gradient descent also on those so bachelor ization adds a few parameters all right

and I as I said I'm just gonna skip over this and you know I'm not showing what the gradients are when your backdrop through the mean and so on it's

describing the paper for Necedah gradients but otherwise in the different packages you actually have access to

you'll get the gradients automatically it's usually been implemented skipping

UNSUPERVISED PRE-TRAINING

over that I'll just finish if you actually want to learn about unsupervised retraining and why it works

NEURAL NETWORK ONLINE COURSE

videos on that so you can check that out and I guess that's it thank you

thanks you go so we have a few minutes for questions which are intermingled with a break so feel free to I your go

for our break or ask questions to Google I believe there are microphones and I'll also stick around so if you want to ask

your questions offline that's also fine if you want ask questions you can go to the mic

go to the microphone hi I mentioned the

rail ooh adds varsity can you explain why yeah so um so the first thing is

that it's observed in practice and they add some sparse some sparsity in part because you have the non-linearity at

zero below so it means that units are going to be exactly potentially exactly sparse exactly essentially absent of the

hidden layer the real there are a few reasons to sort of explain why you get

sparsity it turns out that this process of doing a linear transformation followed by the value activation

function is very close to some of the steps you would do when you're optimizing for sparse codes in the

sparse coding model if you know about sparse coding so they're like essentially in optimization methods that

given some sparse coding model we'll find what is the sparse representation hidden representation for some input and

it's mostly a sequence of linear transformations followed by this sort of like relu like activation function and I

think this is partly the explanation otherwise I don't I don't know a like solid you know explanation for why that

is beyond you know it's observed in practice more questions if not let's

thank you again and we are we reconvene

in ten minutes

summary:
**Key Points**:

1. **Introduction to Deep Learning**:
    
    - Hugo Larochelle presented on the foundations of deep learning, focusing on feed-forward neural networks, deep learning motivation, and recent developments.
    - Covered topics include basic neural network structure, loss functions, backpropagation, stochastic gradient descent, and various practical tips for training neural networks effectively.
2. **Neural Network Functioning**:
    
    - Explained the computation of neural networks starting with input vectors, going through hidden layers introducing non-linearity, and producing outputs for classification tasks.
    - Discussed the importance of non-linear activation functions like sigmoid, hyperbolic tangent (tanh), and rectified linear activation (ReLU) for hidden layers.
    - For the output layer, the softmax activation function is used for classification tasks to produce probabilities for each class.
3. **Training Neural Networks**:
    
    - Discussed the use of empirical risk minimization framework which includes choosing a loss function, an optimizer like stochastic gradient descent, a regularizer, and parameter initialization methods.
    - Highlighted the importance of the loss function in training, specifically the negative log likelihood or cross-entropy for classification tasks.
    - Emphasized the backpropagation algorithm, which is used to efficiently compute gradients of the loss function with respect to network parameters, utilizing the chain rule.
    - Talked about the importance of proper weight initialization to avoid issues like vanishing or exploding gradients.
4. **Challenges and Solutions in Deep Learning**:
    
    - Addressed common challenges such as underfitting and overfitting, emphasizing the use of GPUs for faster training and methods like dropout and batch normalization for regularization.
    - Dropout randomly deactivates neurons during training to prevent co-adaptation and overfitting.
    - Batch normalization normalizes the output of each layer to stabilize learning and also acts as a regularizer.
5. **Hyperparameter Tuning and Model Selection**:
    
    - Discussed methods for selecting hyperparameters like the number of layers, units per layer, learning rate, and weight decay, including grid search, random search, and more advanced methods like Bayesian optimization.
    - Introduced the concept of early stopping to prevent overfitting and select the number of training epochs based on validation set performance.
6. **Debugging and Improving Models**:
    
    - Highlighted the importance of normalizing input data, using learning rate decay, mini-batch training, momentum, and other optimization methods like AdaGrad, RMSprop, and Adam.
    - Advised on using gradient checking to ensure correct implementation of gradients and starting with a small dataset to ensure the model can overfit to it, indicating a correctly functioning model.
7. **Closing Remarks**:
    
    - Hugo concluded by reiterating the potential and challenges of deep learning, referencing his online course for a deeper understanding of the topics discussed.
    - The session ended with a Q&A, addressing specific questions about the ReLU activation function and its ability to add sparsity to the model.

The presentation provided a comprehensive overview of deep learning foundations, practical training tips, and strategies for effectively training and tuning neural network models.


----------

-----

--03--

-----
Date: 2014.12.23
Link: [Jimmy Pedro: Judo | Take It Uneasy Podcast](https://www.youtube.com/watch?v=7bO8rKtvDoE)
Transcription:

Jimmy Pedro is an American judo competitor and coach, World champion, 3x World medalist, 2x Olympic medalist; we talk about his father (Big Jim Pedro Sr), his early career, the times he wanted to quit, overcoming a neck injury, coming back from retirement, the life of an athlete vs the life of a coach, a system for developing elite-level judoka, Japanese vs Russian judo, periodization, a weekly program for an elite-level judoka, toughest moment as a coach, watching Travis Stevens lose the semifinals at the Olympics, mental game, visualization, IJF, judo as a spectator sport, the future of judo in the United States and the rest of the world, and more.
Based on the comments, the interview with Jimmy Pedro, an acclaimed American judo competitor and coach, was highly appreciated and resonated deeply with the judo community and listeners. The interview appears to have covered a comprehensive range of topics, reflecting Jimmy Pedro's extensive experience in the judo world. Here are the main takeaways based on the audience's reactions:

1. **Inspiring and Sincere**: Viewers found Jimmy Pedro's narrative inspiring and appreciated his sincerity and straightforwardness. His experiences, especially those involving his father, his early career struggles, and his coaching journey, seemed to strike a chord with many.
    
2. **Insightful on Professional Judo**: The interview provided valuable insights into the professional life of a judoka, discussing the intricacies of training, competition, and coaching at an elite level. Comments indicated that listeners found the discussion on the development of elite-level judoka, periodization, and weekly training programs particularly enlightening.
    
3. **Emotional Connection**: Some comments reflected a personal connection with Jimmy Pedro, indicating that his guidance and career had a significant impact on their judo journey. The mention of watching Travis Stevens lose in the Olympics suggested that the interview didn't shy away from discussing the emotional aspects of the sport.
    
4. **Educational Content**: The interview seems to have offered an in-depth look into the mind of an Olympic-level athlete, with Jimmy Pedro sharing detailed insights into mental preparation, visualization techniques, and the overall mindset required for high-level competition.
    
5. **Addressed Contemporary Judo Topics**: The interview tackled current issues and developments in judo, such as the rule changes by the International Judo Federation (IJF) and the future of judo in the United States and globally. This aspect of the discussion appeared to resonate well with judo enthusiasts concerned about the sport's direction and representation in the Olympics.
    
6. **Judo as a Martial Art and Sport**: Comments indicated that the interview addressed the balance between judo as a martial art and as a competitive sport. Discussions about judo's self-defense applications and its evolution for television ratings and Olympic standards seemed to engage listeners who are passionate about the sport's integrity and future.
    
7. **Affirmation of Jimmy Pedro's Legacy**: Numerous comments recognized Jimmy Pedro as a legendary figure in American judo, applauding his contributions to the sport both as a competitor and a coach. His influence on American judo and his role in shaping the careers of other notable judokas like Kayla Harrison, Ronda Rousey, and Travis Stevens were highlighted and celebrated.
    

In summary, the interview with Jimmy Pedro was well-received, with listeners praising the depth, honesty, and comprehensiveness of the conversation. It seemed to offer a blend of personal storytelling, professional insights, and thoughtful discussions on the future of judo, making it a valuable and enjoyable experience for the audience.

The interview with Jimmy Pedro, an American judo competitor and coach, covers a broad range of topics related to his illustrious career in judo, his coaching experiences, and his insights into the sport. Key discussion points include:


1. **Early Life and Career**: Jimmy talks about his upbringing and the influence of his father, Big Jim Pedro Sr, on his judo career. He reflects on the initial phase of his career and moments when he contemplated quitting.
    
2. **Injury and Comeback**: The conversation delves into a significant neck injury Jimmy sustained and how he overcame this obstacle, including his remarkable comeback from retirement.
    
3. **Athlete vs. Coach**: Jimmy contrasts the life of an athlete with that of a coach, shedding light on the different challenges and rewards each role presents.
    
4. **Development System for Elite Judoka**: The discussion covers Jimmy's approach and system for nurturing and developing elite-level judoka, offering insights into his coaching philosophy.
    
5. **Judo Styles and Techniques**:
   
   

----------

-----

--02--

-----
Date: 2014.06.05
Link:  [Ryan Hall: Value of Competition | Take It Uneasy Podcast](https://www.youtube.com/watch?v=94MBVD_tZeU)
Transcription:

Ryan Hall is an American black belt and instructor in Brazilian jiu-jitsu, and a professional mixed martial artist currently competing in the featherweight division of the Ultimate Fighting Championship (UFC). He is known for a number of competitive achievements, ranging from Mundial and ADCC victories to dozens of Grapplers Quest championships. He is the winner of The Ultimate Fighter Season 22. He holds notable victories over former UFC Lightweight and Welterweight Champion BJ Penn, former UFC Lightweight Title challenger Gray Maynard and Artem Lobov.

  
you have been in both the supporter and

a critic of competition what do you

think is the value of competition for

martial artists I believe that the value

of competition is in that it teaches you

the true purpose of martial arts and in

ending and the true purpose of martial

arts is being able to defend yourself

and whatnot in all of these other things

in real life yes because you let's say

you win a DCCC gold medal but you know

you get slapped around by someone bigger

and stronger you at a bar that people

will talk about how sweet that gold

medal is but for the rest of your life

it'll feel pretty Hollow that wouldn't

you know that's not what we're looking

for but what I'm talking about I guess

is what I believe competition develops

if approached properly is proper focused

proper dedication because anytime you

have a very defined goal and strong

opposition it will force you to be

better period the better your opposition

is if you focus and you take your what

you're doing seriously the better you

become period people are better

wrestlers today than they once were

people are better basketball players

today than they once were military is

better now that it was in the past

because of all of the competition

that you know that is existed over the

course of time and you know if you go

out competition if you go out and just

kind of it if you're like oh

I'm going to go out and see how it

happens like that's a cowardly way to

approach competition and that gets you

nothing that doesn't teach you to really

do the right things and the same thing

not for pot not properly preparing even

if you win that was a cowardly way to

approach it because you intentionally

left yourself an out which was if I win

man I'm talented in blah-dee-blah and if

I lose it's well you know I mean I could

I didn't really train that hard well if

that's the case then you shouldn't have

been out there win lose or draw I don't

care if I've got a student that I think

is going to win gold at the World

Championships he or she does not train

properly ahead of time I will not allow

them to go and if they go I will send

them off the team you know and hey they

can do what they want they're a grown

adult I'm not the boss of them but I am

the boss of my team it wasn't my gym and

that's not how we conduct ourselves and

it has way less to do about the physical

you know the result and it does about

the proper preparation is proper

preparation and proper focus and

dedication over the long haul yields

positive results but most importantly

it's about are we conducting ourselves

in a in an honorable and respectable

manner so I believe that the competition

really teaches us that because in the

room you know there's always like oh it

was practice so I was kind of this -

that happened today the other thing when

you go to competition everyone is that's

on everyone is on that day because

everyone is trained

for that specific moment and we'll see

what happens so you get the most honesty

out of it out of a time like that and

the higher the level the better it gets

in you know provided that there's not a

lot of cheating but regardless you know

from an athletic performance perspective

it is the most honest thing because and

it's the it's the toughest as well

because it takes it takes courage and it

takes some heart to really properly

prepare and put it on the line because

you're risking horrible disappointment

I've prepared so hard before and tried

so hard and I've won and I've prepared

other times and I've tried so hard and

I've failed and it hurts it really hurts

it doesn't hurt nearly as much if you

kind of half-ass it because you didn't

put that much into it but again that's

how a coward approaches things if you

have if you're going to conduct yourself

the right way you prepare properly you

train hard and then win lose or draw you

deal with the results and that's what I

believe is the real benefit of

competition if approached properly do

you admire somebody who sacrifices you

know like 10 20 years of their life in

that singular pursuit of competition

towards a gold medal at the Olympics a

almost of the Olympians do goodness

absolutely I mean I admire anyone that's

willing to sacrifice and willing to work

hard in any area of life actually a book

that I'm reading again that I really

really like is dune it's a I'm kind of

like sci-fi nerd hangout on everybody

but basically a you know one of the

things that you know one of the one of

the you know things that the the author

was going to Frank Herbert and it's why

the regarded is one of the you know

greatest science fiction novels ever if

not the preeminent but anyway well the

things you said you know is if you if

you search for freedom you actually end

up becoming a slave to your own desires

ironically and if you search for

discipline you find liberty because

you're able to make yourself do what you

want in the long run whereas if I'm like

oh I'm going to do whatever I want all

the time and screw you dead I'm going to

do what I want that's kind of like a

teenager type attitude you end up

getting into a bunch of nonsense but

anyone that's able and again this

doesn't matter it doesn't mean that it's

athletic it could be in any area of

human endeavor any area of life it could

be parenting it could be military it

could be athletics to be business it

could be school to be anything but as

long as you're making you know an

incredibly large commitment I have an

immense amount of respect for the for

the level of dedication that and the

level of commitment and a level of

risk that it that you're taking

emotionally psychologically because hey

like you said you work twenty years you

get that gold medal but there's other

people that work twenty years and got

the silver most people know the medal

now most people most people that think

they work hard don't I'll be frank

you know like seriously I said that in

class the other day like again it's like

I don't want to be too negative but most

the people that most people to think

they work hard do not how do you know

that if you're working hard or not I

think you know but most people are not

very honest with themselves they were

most people would press a button in my

experience you know they would prefer to

be look like the thing and then be the

thing and you know that's that's fine

but it really I can't I think Sun Tzu

said it's a victory is reserved for

those willing to pay its price and there

is a price and now that doesn't

guarantee that if you pay the price that

you will have victory but you guarantee

but I mean from a physical perspective

but you will have the moral victory

regardless because you will have you

will have learned discipline you'll have

shown not only to others forget others

you do it not for others but for

yourself you you show that you are the

master of your own mind and of your own

body and of your own circumstance and

you can discipline yourself and focus

and you deny yourself certain things in

the pursuit of something something that

is valuable to you and that is

incredibly useful in any area of life

and that's not mean not shocking to me

why the same reason that you'll see guys

that were you know like high-level

military like kind of big dogs on SF

world get hired by let's say for

instance a fortune 500 company because

what would they know about business

nothing but also everything because that

level of focus and dedicate like you

don't get to that level of ability in

something by accident and that's what I

think you know like again the value of

competition and what they do competition

only it's as serious as it gets you know

because if you don't get the gold medal

it you may not you may not walk out of

it but basically I have an immense

amount of respect for anyone that is

willing and able to over the long haul

put that time in but I have to trying

hard doesn't mean just getting on an air

Don bike and walking off the mat or

having to be carried off the mat it

means thinking approaching reassessing

reevaluating saying how could I be

better and it takes honest on a

self-analysis and

and also it takes a lot of times because

let's say you know I think I'm doing

well but I got to say hey Lex you know I

mean no matter how how well I believe I

look at myself I'm still biased I'm

still looking at myself what should I be

doing better I'm gonna find other people

that I respect and people that I think

can tell me and I'm gonna ask them and

then I'm gonna have the courage to

listen to them and not just dismiss what

they're saying out of hand and if you're

doing those things then I believe that a

lot of times you're working hard but I

know plenty of people that come in it's

just like in jiu-jitsu this point if you

limit training for 15 years it frankly

suck and there's plenty of people that

have been training for four that are

pretty dang good you know for real and

again are they the best person that's

been training for four years is still

compared to like Kareena not that good

but they could be really really really

good because they understand how to be

directed and how to focus and I believe

this is something I've discussed you

know before with some other you know

friends of mine you know that some of

whom were at a very high level may

others that are the high level of

jiu-jitsu wrestling or whatever um look

at guys like Randy Couture guys a Rick

Hawn they're on their second career they

started MMA when they were like 32 and

yet they got to the top maybe they

weren't always champion but they were

fricking good why because they're 26

year old self would be scary but you

know like hey um they know what it is to

be dedicated and work hard and because

again they're Olympians like you said on

a level that a regular person has no

concept of so I think that that is

ultimately the skill it's not the oh man

this person's dangerous because he's got

good judo or good wrestling no this

person is dangerous because he or she

knows how to work their ass off and be

focused on a level that most people

can't comprehend and that's what

produces success in any area of life in

might hit you yeah be brutally honest

with yourself at all times and it stings

sometimes you know I think yeah it's

like the price of of looking inward you

know objectively is that you're not

going to like what you see a lot you

know and because even if you're like oh

man I'm 90% the way I want to be it's

like that if you are going to take that

next step in my opinion it's you're

going to focus on the 10% because it's

like oh man we're doing a lot of things

good yeah who gives a let's talk

about what we need to improve on you

know and that's a little bit less fun

but in the long run I think it's what's

it's what's going to drive you to a

higher level but at the same time I

think it's what makes a lot of people

that are like that a little bit neurotic

and nutty by compared by a normal

standard

right but again you show me someone

that's super well adjusted and I'll show

you someone that's probably not a high

achiever

you talked about moral victory can you

explain how your morality contributes to

the way see the value of winning sure

I think there's absolutely such a thing

as a moral victory and sometimes people

that are trying to manipulate you or

trying to get you to buy something will

tell you differently and you know there

is there it goes in two directions for

instance let's say you're a blue belt

and you compete against you know a real

black goal and there's plenty of people

running around plat belts that are not

particularly at this point but you know

let's say for instance your blue belt

and you compete against a real black

belt the likelihood of you winning is

almost zero however if you go out there

and you try hard and you do your best

and again whether you come off the mat

you know a winner which would be very

fortunate and unlikely but or you come

off the mat you know on the other side

of things if you went after and you

tried and you you know let's say you had

some nerves but you kept that in check

and you fought hard you didn't let it

get the better of you you know that

would be in my opinion a moral victory

and and there would be nothing wrong for

recognizing it as such now that's not

the same thing as an actual physical

victory but there's nothing wrong with

saying let's say you're your opponent's

260 pounds in your 120 and you tie they

get the decision hey you know I remember

that happened to me at the quarter-final

or not the quarter-final rather in the

the third round at the absolute in the

Worlds in 2008 you know and you know

it's against a heavyweight or a super

heavyweight and in the 0-0 and I wasn't

happy about losing by any stretch of the

imagination but looking back I'm like

okay well you know generally speaking if

you end up level considering that I have

all of the resources you don't that is

you know you definitely performed a

little bit better than I did now at the

end of the day you know wins and losses

do matter and you do want to try to make

sure that I'm not shooting for the moral

victory I'm shooting for the actual

victory but every now and then it's very

very important to keep in mind that you

know am I just actually myself am i

conducting myself in a way that I

respect that hopefully other people of

value or respect and also a way that I

believe is going to produce actual

victory and actual positive results in

the long run as well I think it's

important to recognize that because

sometimes you'll see people get very

frustrated let's say for instance if I

box against people that are much more

experienced than me all the time

you know I'm not going to win anyone

that tells you differently has either

not training with people that are very

good or B they have no idea what they're

talking about

but what I can say is hey did I do a

little bit better today and better

doesn't mean that I land more punches in

this it was I more under control was I

more able to kind of keep my keep my

focus and execute what I wanted to

execute and if the answer to that is yes

you know I'm moving in the right

direction so as far as I'm concerned

there's all sorts of different types of

moral victory but it would be the the

same thing as you know let's say for

instance you know fade or slaps your

mother you got to hit him

you have to he's going to kick the

out of you almost certainly but you have

to hit him it would not be it would be a

technical like well I didn't get hurt so

that's a win if you ran away but that

would be the opposite of the moral

victory in that case trying your best

and losing would still be I would say

the honorable thing to do so what you're

saying is sometimes you have to pay the

price for a moral victory

absolutely but the reality is is that

martial arts doesn't just teach us about

how to beat someone up or technique or

this is that that's really not the core

of the martial arts the core of the

martial arts is heart discipline

dedication focus and if you have those

things they'll always be people better

than you and they'll always be people

lesser than you but that's not the only

metric by which you can judge

performance or judge a person

yeah I competed in boxing judo wrestling

jujitsu MMA have a man yeah now what do

you think is the best martial art for

defending yourself against an untrained

opponent there's so many different

factors but let's say for instance okay

most fights I've seen are one-on-one

they're the fights we hear about are an

ass-whipping like seven people versus

three people and okay the more variables

you add in it gets very very difficult I

would say them the best fighting style

is using your brain and because less

voiding the fight well avoid in the

fight but I would say intelligent it's

just like investment now I know nothing

about investing which is why I don't do

it but um let's say for instance a

Warren Buffett is looking at a stock

page now I'm speculating because I don't

know mr. Buffett but I do have someone

who's standing up how the world works so

I would say that some days he looks at

the page it says haha there's a good

investment here and other days

regardless of his skill and investment

he says there's nothing to do the best

thing to do is wait but your Warren

Buffett tell me the best investment yeah

the best investment today still sucks

and I'm not going to make it talked to

me next week and I'll see what's out

there

so till next week we're gonna make we're

gonna we're going to invest some money

maybe and then you know he'll make the

read as he sees it so let's say for

instance you walk into a room and your

goal was to kill everyone in the room

and you are armed but you walk in to

50/50 Jitsu and you're going to shoot

everybody but for whatever reason it's

bringing your gun to the gym Tuesday and

everyone else is sitting there polishing

their fully-loaded again rounding the

chamber safety off weapons hot all that

good stuff and you see everyone else is

armed what do you do wait until

Wednesday

you come back in on Wednesday when no

one's armed then you shoot us all to be

great so it's that would being the best

tactical shooter you could be as ninja

as you want we're going to kill you

there's too many of us in too few of you

could you make it out of there and like

some sort of Boondock Saints awesome

luckiness and managed to get everybody

sure I wouldn't bet on it

that's like Floyd Mayweather against

three people I would bet on him sometime

seriously anybody that tells you

differently is never fought an untrained

person because regular people can't

fight for [ __ ] and the other thing is

they get scared so the one Floyd

literally cripples the first guy with a

right hand the other two guys unless

they're really seriously probably go

oh and then hesitate but they may not

but let's so if you think about it

though four people five people three

people ah let's say it's one on one but

Floyd's minding his own business against

snuck over the shoulder as he's sitting

there ordering a drink at a bar all

these different things factored in so I

would say that when it comes to the

physical expression of how to best

defend yourself the most important thing

is situational awareness and

understanding what's going on around you

because you could be the world's

greatest ninja warrior and still run

yourself into a lose-lose situation

could I knock out Floyd Mayweather yeah

sure I could if you let me hit him but I

don't think I would come within spitting

distance of him if he didn't want me to

I would have no teeth before I even

tried but if he sits there and lets you

hit him he is a man he is mortal so

basically under the right circumstances

anyone can win onto the wrong

circumstances anyone can lose so I would

say that understanding that is two step

one to being able to be an effective

effective strategist who can read a

situation you say should I fight this

one out should I not should I get out of

here should I fight for four seconds and

run for it and you know when you take

into account the physical expression of

everything and you want to let's say for

instance you know the most important

things for defending yourself in real

life I would say probably wrestling or

jiu-jitsu probably jiu-jitsu really in

my opinion but that's just perfect for

fighting I would say other things if I

want to be able to beat up more than one

person I know it implies that I can

wrestle or I can because regular people

can't wrestle for [ __ ] you will you

could pick him up and slam your head on

the ground or something horrible you

know but boxing would be nice as well

but let's say you're a great boxer and

someone tackles you could a regular

person tackle a good boxer yes alright

could a regular person sucker a good

jujitsu guide for sure but it also

really comes down to the to the mental

and everything like that but basically

if I had to pick one art and the

everyone knows nothing I would picture

issue but in my opinion jiu-jitsu at a

high level involves wrestling so just

like you said grappling is this bigger

thing that involves wrestling's you know

everything no doubt that's like you take

an Olympic level wrestler and you let

him lean on top of your inside control

it's not pleasant

in class you you emphasize that we're

working with basic laws of physics so I

just read Einstein's biography he was

obsessed with finding a single theory

that would unify all the fundamental

forces of nature Wow

do you think there exists the unified

theory of grappling we can boil

everything down to just a few principles

I will

well first off if Einstein wasn't able

to come up with a unified theory I would

sincerely question my ability to go that

way but do I believe that something like

that could potentially exist absolutely

and I think that even if it doesn't a

belief in the possibility of it and the

search for it would would leave you

better off than where you started

whereas if I was a no no that's [ __ ]

that would never and then I don't look

even if I'm right because I didn't look

there's certain things I won't learn so

I think you know a lot of times just

let's say alchemy the idea that you're

going to turn lead to gold all right

let's a little bit nuts but who knows

maybe that's that kind of nutty and you

know on highly unlikely is highly

unlikely probability of success pursuit

yielded scientific progress elsewhere in

the search for that even though again

someone would look back and say oh

that's stupid who would blush and who

would do that

well if you spent years trying to figure

it out I guarantee you're going to learn

some other things as well so I think

that there at the very least the

principle based approach to grappling is

incredibly important with your process

like for learning new details and

understanding the principles behind the

techniques I certainly don't believe

that I have like a singular or perfect

approach by any stretch of the

imagination but you know I guess what I

try to do is block out extraneous

nonsense like for instance both Pete a

lot of people want to talk about 55

details and reasons for something that's

going on and the reality is is that

you're clouding your thought process for

instance there was a recent not to get

too political but there was a recent

issue where I remember an inmate was

executed and they used a new drug and it

was painful and oh my god and he died it

was horrible again that's when whether

you believe that capital punishment is

valid or not I think there's plenty of

arguments against it in fact I think

most of the arguments that make sense

are against it but pain has fuck-all to

do with it you know I don't care that's

like done hey Lex I'm going to kill you

but don't worry it's not going to hurt

man I mean don't know okay then yeah

it's like that doesn't make it okay it's

like believe me I'm for free I'm is

again if you're gonna kill me I prefer

that you don't burn me at the stake but

if someone was like don't worry it's not

even a sting I'm still going to try to

fight you to the death I'm absolutely

not allowing this to happen if someone

wants to say okay hold on let's get

let's cut the [ __ ] like feely

feelings out of here and say look forget

the pain does this person deserve it

uh-uh

let's let's step that back again is

there a potential for human error is

there potential for someone having this

guy behind bars for political gain like

okay these are the real reasons that you

say hey no way on the death penalty it

has nothing to do with does it hurt or

which drug is it are blah-dee-blah

or is it inhumane it's like none of that

if hey we're focusing on the wrong thing

so it reminds me of jiu-jitsu in the

same sense and again we're fighting were

generally speaking in my opinion debates

that happen in the public you know arena

they always focus on the wrong dang

thing and always focus on the wrong

aspect again there's 25 good reasons or

bad reasons to do almost anything but

generally speaking people will focus on

the hundred other ones that are

extraneous and [ __ ] so what I want I

guess what I would say is it reminds me

of jiu-jitsu is striking like man Floyd

likes to hold his hand this way or that

way or the other way and and this guy

likes to jab like this and it's really

important this person says you land with

this knuckle in that person says you

land with net knuckle and in jiu-jitsu

it's very very important that you grip

three inches up on the lapel and two to

the right

but Roger Gracie doesn't like this but

cabrini says it like this clearly they

all work under the right circumstances

and don't work on to the wrong ones and

it has nothing to do or very little to

do with these other things like hey does

it matter again I'm going to kill you

would you prefer for it to be painless

or horrific ly painful okay if it's

already a foregone conclusion death

alright yeah now we'll start to talk

about the the extreme like whether or

not it's going to sting but until we get

to that point

hey let's focus on the do we is it even

right or do I have the ability or the

capacity to do this justifiably okay so

that's where you come down to the

principles in my opinion say all right

yeah it doesn't matter which knuckle you

land with yeah I'm sure it does but it's

a hell of a lot less important than 25

other little things that make all of the

difference and in my experience a lot of

coaches and a lot of people particularly

guys that are trying to [ __ ] you

will focus on 45 little details and oh

it's there's 15 details to this ten

okay that's true but what are the two

most important ones because hey don't

get me wrong I'm not saying that these

details don't matter but just like

anything else in life there's a

hierarchy because would you say that

would you say that happiness and

self-actualization is a valuable thing

in life yes I would as well and you know

what we have the luxury of saying that

type of thing because we're sitting at

fifty fifty Jitsu in Falls Church

Virginia and there's no one trying to

kill us rape us and we are also I know

where food is tonight yeah if you were

to walk down if you were to talk to

someone like 2,000 years ago I'll be

like how are you feeling they would

stare a chili what are you [ __ ]

[ __ ] I'm starving yeah I'm hungry

that's my issue

are you are you satisfied in your life

it's like I'll be satisfied when you get

out of my way so I can find some food so

that's even the deeper question is are

you eating something tonight right and

so it's Maslow's hierarchy of needs when

we take care of the base needs first

then we start to work our way up toward

self-actualization and this and that and

but until you got your food water

shelter don't tell me about where you're

placing your grip it's like you're all

leaning out and you're you know your

posture is poor and you're out of

balance and you want to tell me your

grip that's like I'm starving to death

the you know the barbarians are at the

gates but I'm sitting here giving you a

philosophy lesson it's like this is

[ __ ] it doesn't make any sense

build a better wall a sharper knife and

get some food and then we'll cover all

the other stuff so I think that in my

when it comes to how I approach martial

arts in terms of learning as well as

teaching I really try to boil it down to

what I feel to be the most important

component parts and then if I one day

reached the level of where these tiny

details matter that's fantastic because

again the difference between you know

the ability to pass that try to pass

successfully against a cabrini or how

file Mendez and against a regular

run-of-the-mill black belt or you know

does come down to little details but

it's also presupposing that you're in

proper position that even allow these

details become relevant and I think that

a lot of times we put the cart before

the horse and that's not that's

problematic there's still in your

opinion undiscovered position

submissions of techniques and you just I

would say that there have to be there

absolutely are um you know I think that

what we see is jiu-jitsu now don't get

me wrong the core never changes because

physics doesn't change physics is the

same thing that's why I get a kick out

of

love like self-defense arguments it's

like [ __ ] it has another no physical

difference in self-defense beyond the

fact yes you can I guess mean though

I've never seen anything like that in

real life that you're crossing a pretty

serious psychological line if you're

putting your knuckles to you know your

thumb to knuckles deep into somebody's I

forget the fact that did you know that

we're legal more all other things like

that it's like I've never done that

before I wouldn't do it lightly there

probably be some hesitation there what

is so anyway what makes it different is

the the psychological component and all

these other things going on but

physically there's no difference again

people like Aldridge it's is really

different in MMA no it's not not in my

opinion not in my experience it is

absolutely not what are you talking

about physics are different inside of a

cage than they are on a mat and they are

out in a field

it's exactly the same now if I try to

sport grapple you under a non sport

grappling rule set then I may run myself

into trouble but that had nothing to do

with jiu-jitsu jiu-jitsu is physics is

proper expression of physics the same

way boxing is and the same way of

wrestling is the same way all these

things are so I would say that as long

as something adheres to the principles

that that allow something to be

effective and you know and fundamentally

sound that you can do almost anything

and I think that people will continue

particularly in the ghee it's going to

get nuts you know just the level of the

amount of things that you can get away

with and do and different grips that you

can make but I'd say what we're looking

at right now is going to look only

somewhat like what jujitsu is going to

look like in 30 years the same way the

jujitsu we see now is so much

fundamentally better honestly and and

more evolved and adaptive than it was

twenty years ago and people will swear

up and down like all back in the day

it's back in the day people did not

fight very well even twenty years ago

the level of people understanding how to

deal with jujitsu was very reduced so

you could get away with all sorts of

pretty questionable stuff like sitting

in front of someone in close guard and

have them not completely kick the [ __ ]

out of you but um yeah I think you know

with particularly the advent of Baron

bull the 50/50 position all these

different things which have always

existed there's they've always existed

and one that's I always hesitate to say

invent I don't like the word invent like

that certain people use a lot

I'd say Discoverer because you could

show me I can come up with something

let's say Lex you know you've got a

really good straight foot lock I was

watching a train last night

and I could be doing that in a way that

no one ever taught me that doesn't mean

I invented it because you've been doing

it forever but basically it's let's say

no one showed me the details you were

using and I managed to stumble across

them I didn't invent those details eyes

go yeah I discovered them that was neat

but again none of us have invented a

dang thing people have had two arms and

two legs for certainly as long as I can

remember and probably longer than that

and today here yeah that's that's the

word so in the history books

you

summary:

Ryan Hall, a notable martial artist and UFC fighter, delves into the intricacies of competition, dedication, and the essence of martial arts in this insightful interview. Here are the key points from the discussion:

1. **Value of Competition in Martial Arts**:
    
    - Hall recognizes competition as a means to understand the real purpose of martial arts: self-defense and real-life applicability. He emphasizes that the worth of a competition medal pales in comparison to the ability to defend oneself in practical situations.
2. **Competition as a Catalyst for Improvement**:
    
    - He argues that defined goals and formidable opposition in competitive environments compel individuals to improve. This principle, he notes, is evident in the evolution of various fields, including sports and the military, over time.
3. **Approach to Competition**:
    
    - Hall criticizes a lackadaisical approach to competition, labeling it cowardly. He stresses the importance of proper preparation, focus, and dedication, regardless of the outcome, and condemns using lack of preparation as an excuse for failure.
4. **Integrity and Team Standards**:
    
    - He maintains strict standards for his team, insisting on proper training and preparation for competitions. Hall values the process and integrity over results, advocating for honorable and respectable conduct in and out of competition.
5. **Honesty in Competition**:
    
    - According to Hall, competitions are the most honest platform where everyone brings their best due to the focused preparation for the specific moment, making it the toughest and most revealing environment.
6. **The Pain of Failure and Moral Victory**:
    
    - He openly discusses the pain associated with trying hard and failing in competitions, highlighting the importance of full commitment and dealing with the results, whether positive or negative. Hall believes in the concept of moral victory, where the effort and character shown in competition are as important as the actual outcome.
7. **Respect for Dedication in Any Field**:
    
    - Hall expresses immense respect for individuals who show long-term dedication and sacrifice in any field, emphasizing the importance of discipline and focus, which are applicable and beneficial across various aspects of life.
8. **Unified Theory of Grappling**:
    
    - While skeptical about formulating a unified theory of grappling akin to Einstein's pursuit of a unified theory of physics, Hall believes in the value of searching for fundamental principles that govern effective grappling techniques.
9. **Principle-based Approach to Learning**:
    
    - He advocates for focusing on the most important components in martial arts, cautioning against getting lost in minor details. Hall emphasizes the importance of understanding the fundamental principles and building upon them.
10. **Evolution and Discovery in Martial Arts**:
    
    - Acknowledging the constant evolution of martial arts, Hall anticipates future discoveries and innovations, especially in disciplines like jiu-jitsu. He prefers the term "discovery" over "invention," recognizing that martial arts techniques are often rediscoveries of pre-existing principles given the unchanging nature of human physiology.

The interview with Ryan Hall offers a profound look into the mindset of a dedicated martial artist, highlighting the importance of commitment, integrity, and continuous learning in the pursuit of mastery in martial arts and beyond.

----------

-----
--01--

-----
Date: 2014.05.08
Link: [Ido Portal: Movement](https://www.youtube.com/watch?v=o8nZaDw_mOs)
Transcription:

Ido Portal has spent the past few decades honing a physical credo and method that's now practiced by thousands of people all over the world - from office workers, to former CrossFitters, to NBA players, to the ever-controversial UFC titan Conor McGregor. Known as The Ido Portal Method, or simply "movement," his approach purports to take the "most potent" parts from a range of physical disciplines by shedding the dogmas that often accompany them. As he puts it: "I want the contents, not the container."
Intro

we choose to go to the moon and district eight and do the other things not

because they are easy but because they are hard

[Music]

in any particular sport with well-defined rules mastery is achieved

through specialization taking a few skills and perfecting them so naturally

most experts and teachers of movement are specialists of skillsets like

gymnastics hand balancing Olympic lifting capoeira Jitsu wrestling judo

and other martial arts so it's rare to come across a generalist someone who

takes a holistic approach to movement my guest today is IDO portal he is a guru

of movement a teacher with a large and quickly growing following as he says

movement is big bigger than any specific discipline were all human first mover

second and only then specialists I actually just finished reading a

Journey to becoming a generalist

biography of Albert Einstein by Walter Isaacson and the two of you have

something in common I desire to arrive at a unified theory in his case there's

a unified theory of physics you know like forces of nature in your case it's a unified theory of movement can you

tell me the story of your journey to becoming a generalist first I'd just say

that I'm no guru you know it's something that people use but I have a really hard

time with the word master or guru and I didn't arrive with the gospel truth I'm

not sitting on any mountains and I'm I'm on my way so people who join me as students are

basically following you know in the same journey maybe in certain circumstances

I'm a bit further ahead or sometimes I'm a bit behind and but it's definitely

walk along and not walk behind kind of thing yeah my journey I started as a

mover first and then I became a specialist and then I went back to

movement basically so yeah it all started in a young age and some some

Chinese martial arts and developed into some physical sports and

games in school primary school and high school and then I met capoeira and I I

was completely amazed basically by this dis art form and then pursued that for a

good 15 years in the middle somewhere military service and other physical a

physical pursuit and throughout changing and developing and moving between

disciplines and exploring just kind of got the same realization again and again

that there is some thread through all these disciplines something that is

attracting me back and basically it was movement I realized and the next thing

was okay I want to learn movement I want to get better as a mover in a general

way I seeked out a movement teachers and went around the world and looked around

and read a lot of books and there were some people who mentioned the word movement and I went to them and you know

heard myself as a student and they kept on teaching me disciplines another

isolated approach another speciality and I was very disappointed so eventually I

decided okay I'm going to become that person I'm going to become the movement teacher and the next realization after

years and years of trying was it's impossible and with that I stayed

basically because I realized if that's impossible it's a good goal to have in life something that will keep on moving

myself and my students and anybody involved forward that's where I'm at

right now I'm in teaching and learning moving around and trying to try to gain

some more knowledge about this impossible task yes you're still yourself or forever a student I would

prefer I prefer to be a student any day of the week than a teacher and but being

a teacher is part of human culture we are all teachers we we teach all the

time but whether you want it or not somebody asks you for direction in to it you become the teacher you have a

child he looks at you you're a teacher practicing teaching and practicing to

the student the discipleship both of them are extremely important for your development as a movie what is the price

of specialization what do we lose when we specialize we lose humanity first and foremost as humans we we evolved to

become humans as generalist we are the most generalist of all animals we are

able to imitate the ape and imitate the tiger and and we can hold our breath

underwater and we can do everything just a tiny bit we can't really run very fast

we can't really fight very well we can't you know climb as good as other animals

but we can do the most complex and generalize tasks out of all animals and

no animal even come close so speciality the price is humanity the price is your happiness the price is

your fulfillment as a human being it's deep beats it's philosophical but that's

that's we are do you think there is some beauty and fulfillment and some value

Specialization

and specialization in becoming the best at a very specific movement at a particular sport giving your body to you

know dedicating it to that sport that's an interesting thing because as a human race we benefited tremendously from the

work of specialists but those specialists suffered that's a very very

important points like without specialists we would never be here we would never be skyping right now on

these computers and and you know wearing these t-shirts and all kinds of stuff

but those specialists those human beings suffered the result of their highly

specialized nature and we become more and more specialized the reason move

towards being generalist again in the last few years maybe the last decade

there is a bit more talk about that but definitely we are also still

pursuing highly specialized fields if I make a joke in my workshop and I say

nowadays you go to it if you break your you know you break your hand you go to a hand specialist orthopedic surgeon in

five or ten years you'll go to a left hand specialist and the most evident problem is also our

leaders who are experts but now they're required to be generalist leaders of a

lot of stuff and their shitty leaders we keep on having the same problems again

and again because they are ex specialists whether it's a lawyer or a

military person or an economist these are not specialities that allow you the

full grasp of running a country yeah I think I think you put it beautifully that in my specialization might lead to

innovation but you lose the humanity mmm what do you find is the most

underdeveloped range of motion in athletes like what movement is most

restricted in pi level athletes in your experience is there any one that stands

out shoulders any particular other joints well it's it all depends on their

speciality of course in habits the shoulder the glenohumeral joint is the

most hyper mobile joint in the body even when it's restricted it still offers tremendous range of motion compared to

other areas but when it's restricted even if it's just a little bit it can

cause huge problems because we are dependent on that range of motion and

mobility around the glenohumeral joint and the simple reason is because with

the hands humans manipulate that's what we're meant to do with our hands and we

need that complexity around the scapula it's been a few years since I've said it

first that the scapula craves complexity but this complexity around the scapula

and range of motion is so important across the board I've read of your concept of isolate in

are graded and improvised okay describe the role of improvisation in movement

Improvisation

any profession and speciality should arrive at improvisation in the top and

tier the top level and whether you play the violin or you know you box you're

going to reach improvisation improvisation above all is the human condition it's the human the human

ability the highest form of living is improvisation you improvise basically life is improvisation you're born you

die and in between you improvise a shitload of improvisation movement is no

different the thing is people started to isolate concept and some people went the

next level and integrated them they present themselves as improvisation but

actually they're cheating people it's just a bit more integration yet it's

just another integration improvisation open improvisation real improvisation as

we call it that's very rare and that's the most enjoyable state it's also

called the zone it's also called the tunnel you just experience this

beautiful thing to be empty just to let things happen through you as Bruce Lee said I don't hit it hit it just happens

you know and that is improv that's what you need to do with movement if you

aspire for the highest things I like how a guy on reddit described you as IDO

portal may not be the nicest guy in the world but he's a great coach so that nicest

guy part I come from the wrestling world where the goal of a good coach and a

good program is to basically make you quit to break you there's zero patience for people who don't want to put in the

work to work hard do you find that tough love is the best approach to coaching

Tough Love

people whatever their level of ability no not necessarily I don't like the term

tough love because it kind of assumes the it's importance is itself it's not

enough for me it's like that's how that's the best way why that's the best way but on the other hand I don't think

people are made of sugar and I really believe that we've lost a bit side of

you know how resilient we are and another is people don't like the truth

you know it's dishonesty is above all so when people describe me is tough love

it's not because I believe in Tuffle 100% of the people who has been who have

had issues with me on a personal level or through coaching are people who

couldn't accept criticism what I offered you know took it personally weren't able

to deal with it etc I can't even you know in my head find one example of a person I've been

working with who received the criticism worked with it and still complained but

it's always these complainers and who cares complain first and do nothing yes yeah yeah you know it's like

when you go mainstream as we've went to a certain level you have to deal with it

because I'm not operating my elite unit my Special Op unit anymore now it's an

army and I need to accept the fact that I'm gonna meet a lot of slackers a lot of Poindexter's and all kinds of

you know they don't want to work they want to talk about it they want to do this they want to do that they don't

want to hear the truth they don't want to accept criticism or hear how much they suck and I just don't do that so

you know I'll have to accept the fact that from now from now and again you know what I'll have this issue and I'm

sure it will continue you've travelled all over the world you think there's a difference in this aspect in attitudes

in the United States and Israel and other countries big time horse big time

yeah there are many countries where I don't have this issue or very rarely we

have a word in in Hebrew actually it comes from Jay and I think or Yiddish it says touchless

it's like down to it you know the heart of it tough less people are people who

are like no you know directly tell me as it is and this stuff less it

it exists in certain cultures in other cultures it's a lot of chitchat and walk

around and you know I didn't know how to chitchat a few days ago one of my

students told me you know I can't cheat you it's exactly how I felt you know when I first came out of Israel started

to teach around it was Russia thank God and that was so similar to him where I

come from in many ways so no problem but then when I went to the US or Canada I

had a lot of issues with the chitchat with politically correct and walking

around the bush and don't give it to me too harshly you know cover it with a lot of sponges around it soft in the heat

and yeah it's definitely different between various countries and I need

nowadays I need filters which are my my stood my top students were helping me

teach and some of them are great filters in and in certain countries they'll do

much better than me what is perfect practice look like for you so do you believe in the value maybe this applies

more to specialized sports but like I I come from Russia actually and from the

wrestling world where repetition you know putting in ten fifty thousand hundred thousand repetitions on a

specific movement is is how you achieve success do you believe in the value of

that repetition even for generalist framework the repetition is the mother of skill yes there have been those that

corrected and said perfect repetition is the mother of skill well those who

usually say it are those who don't achieve Heights usually usually so I'll

be very frank again I'll be very extremely honest a lot of people talk about perfect perfect perfect but but

life is not perfect itself our surroundings are not perfect and when I

practice and when I move it's never on the perfect conditions it's never with the right optimal blood

sugar level and under the specific you know height of I don't know what and and

riding the wave of super compensation in the perfect way and usually when people try to adhere to that concept in a

perfect way they end up falling off the wagon on the other side don't be don't

be stupid don't just drill yourself into the wall and lose sight of everything it's not black and white the truth is

somewhere in between and it varies between people for me after seventeen

years teaching 18 years now teaching moving seeing people the hardest workers

are usually the elite performers of course some of them are carrying a

certain talent or this or that but it's always with very dedicated practice they

have built up that work capacity through that dedicated practice and they can then move that ability to other

disciplines true in a grappling world I'm not sure how much you're aware of it but Marcel Garcia is one of the Great's

and he believes boldly against the status quo I think that you should only

train jiu-jitsu his sport jiu-jitsu and not do anything else so to achieve

success trained only that but the majority of other athletes in the sport believe that you should do strength and

conditioning programs and all around that so they at least move slightly towards the more generalist framework

what do you think do you think that's value for the generalist mindset for like an elite athlete or should they

Generalist Mindset

just focus on their sport to some level to some level speciality can can reach a

plateau because of lack of general base of the pyramid in some cases but it's

not a very high level of you know Janet generalism nowadays you're you're

practicing against specialists and they devote more and more time to this specialty

when you're doing other stuff so it's a complex rhythm you know and and to each case his own but I'll tell you something

else when you reach the top of your field like marcelo garcia did in BJJ you

stopped being inspired by your own scene you can't gain inspiration knowledge and

motivation from your own scene because you are the leader you're on top of the mountain you have nowhere else to climb

so what you do you look to other scenes and that's where it's really really

valuable to become a bit more generalized yes you mentioned an

interview related to that a very interesting point the many people in the US in particular focus on learning more

than doing so focus too much on acquiring knowledge versus using that knowledge do you struggle this yourself

like how do you approach learning new things versus putting more time into old

things that you've already met Sinead it's not only a u.s. thing or North

American thing it's generally all across the globe all those are more practical people and less practical people you

know in each country has its own orientation habits you know characteristics but it's a good question

you need to be it's kind of being super intelligent and oriented towards the

information but then have this dumbed down practical mind it's like okay now I need

to work you know and having a balance across that and that's probably it that

probably means that you know a certain IQ for example will start to work

against you in certain fields and vice versa so you when you become too much

you know as the Chinese say the man who lives inside his head you start to have

this issue you know you you have a thirst for information great thirst but

information is toxic it's exactly like water water is toxic as well almost all compounds

toxic and then we drink we drink with it we kill ourselves we kill the process

and the knowledge it turns against us and that's a serious problem and that's

the problem of the age of misinformation that we live in it's not only that the

knowledge is toxic even when it's good knowledge now we also have bad knowledge

mostly bad knowledge mostly shitty advice the combination is listen just

people become paralyzed or just you know move from link to link to link with a

you know glazy eyes and just never actually do anything yes I know you

advocate building a huge word capacity so how many hours a day do you think this is also a debate for specialists

how many hours a day do you think is the most a person can train movement

intelligently before becomes not sustainable before their mind becomes

uninspired maybe as you said 24 hours 24 hours 24 hours a day there is a

choreographer in Israel very known choreographer called ohad Naveen he says when you wake up in the morning in bed

between the sheets you can you can practice movement and and is not there

talking about with your partner yeah so even there you can practice you know breathing moving it's it's all the time

around you but serious practice you know practice oriented that you know

repetition and success and building skill and moving from isolation to integration to improvisation in most

disciplines it's around six to eight hours a day some people go more and reach even the

ten hour mark and I've done that for periods of time in the military you go

even further than that other disciplines require less and it's also a highly

individual thing so let's say even within the sports of gymnastics you have a woman like in Nast who trains eight

hours a day and neck to her the same team also winning gold medals at the same level more or less

you have Shawn Johnson training three hours a day and she reached the top of

her field or liquid gold medal in the Olympics so how highly individual this

is very rare to see this three hour gold medal thing but definitely it

exists the difference there might be mental so the question I have is out of

the various elements like mind breathing developing muscular strength or joints

which is the biggest challenge to master as a student a movement highly

individual it depends on the person depends on is orientation some people

never require any form of mental training for example or psychological training especially in fields and like

sports and then team sports yeah so so that aspect is covered they're winners

they're oriented they're focused you know and then other people require help

in that regard some people have great difficulty developing mobility and just the nervous

system is panicked it holds on it protects them too much other people are hyper mobile and have a

difficulty creating tonus and in strength and that is a great challenge

for them and other people are you know great complex learners they can name

they can coordinate complex actions and learn movement very quickly while others are highly limited so it's very

individual for that process of learning that journey is individual to everyone

Listen to your body

so how does one take that journey just listen to your own body now now you can

listen to your body until tomorrow Hypatia you're not hearing anything you

know you're not hearing anything you need to learn you need to create a relationship with your body and you need

the help of of teachers right that's there is only you know a lot of

people say no I'll do it myself then you deny collective knowledge the most

powerful knowledge that mankind holds you know because we're the only animal that have collective knowledge we've

been able to move knowledge across generations and that's how we have reached space build the Internet

you know do all these crazy surgeries and and you know solve you know genetic

issues and etc it's you're not gonna do it by yourself you're just one small

person and we have collected knowledge generations upon generations so listen

to your body that's nice to say most people don't hear it's completely

silent and then you need to start to decipher the signals that the body gives

you and that goes through a practice and learning discipleship and exploring a

lot of different different stuff and it's a highly individual thing nowadays we don't have so much any anymore this

mentor student or teacher disciple relationship but I I really believe in

that I wouldn't be here without my mentors and my teachers the shoulders of

giants that lifted me up I still believe in it in in a way there is no other way

yeah on that do you think that training and learning movement for the majority

of the time is a fundamentally solitary activity or do we gain from like the

presence of others so when you when you think of movement when you're training is most of your training like the

repetitions done alone or with others both and I've trained years you know

alone and with my students and I spend large periods of time alone just

training alone but I also spend a lot of time being in a community in movement is

the best reason for gathering around in a community and you know people for

example nowadays they go do CrossFit or they do yoga what ever and then they have their yoga

friends and they have the real friends that that's you know your yoga friends can be your real friends because

we've been gathering around movement since the age of time creating communities around movement around

hunting gathering dance around the fire we've been moving together nowadays I can recommend move with your loved ones

moved with the people around you you know you join a BJJ Club it's a community you know you go there you meet

you move around you go to a capoeira Club it's a tribe you go to a CrossFit

gym it's a community you go to yoga it's a community you can move with your

children you can move with your dog in the park and it's important to move

together but it can also be done alone and some things are better done alone and some things are better than together

how do you think movement changes from solo movement you know that that whole

Movement

pattern of movement where you're moving alone versus the pattern of movement where there's two people either working

together against each other so together is like dancing partner dancing and against each other is like wrestling or

jiu-jitsu do you think the principles of movement are different for when it's two

people versus one person this is a whole nother world first they spend more time

moving with others against others in martial art because I spend most of my

life in martial arts and less time exploring stuff alone but definitely

there are some concepts that still exist like the quality of movement how you

organize your body in space not in relation to the partner only but first a

BJJ practitioner or or a stand up fighter he needs to organize his body in

relation to space first and then in relation to the partners well so some of

the concepts exist in both while others are very different and you can train

alone or all your life when somebody else is in the equation it's going to change the game completely a major

reason why we are under the fight laboratory we've departed in reality from a lot of

traditional martial arts and the delusions of training alone and doing forms and and repetitive you know

movements alone and then it's a shitstorm and you can't apply anything

and you you don't have any live practice and now we see that and definitely in

the fight game and the practices that stayed very real stayed very dirty in a

way but very real they are the ones who are providing tools for the chaotic

environment of a fight terms of injury how do you treat recover and work around

Injury

injury hmm injuries are a certainty

they're not a learnt the probability injuries and diseases they are also

required as nothing talib one of my biggest inspirations this day is a great

philosopher and in order to to anti fragile eyes to become anti fragile to

become robust to become more than resilient you must be able to enjoy

volatility you must be able to grow from this stuff and so first I oh I said I

said it before and I'll say it again I injure my students this happens and I

can do anything beneficial without it and basically we all get injured

constantly on a micro level a macro level it's part of our lives of course

we don't want to push into meaningless injury and we want to be able to grow

from it an in and basically develop from it how do you train around it how do you

train around it it's a hard question it involves a lot of stuff first and a big

believer in movement as a therapeutic tool movement itself if it offers you

adaptation and it does it's the way out not lack of movement rest

I don't believe in rest I believe in moving which means when I'm resting

I might help on the short term with certain aspects of the injury but at the

same time I'm creating a new problem because there that the adaptive process is taking me somewhere else

I'm not recovering towards movement I'm recovering towards no movement so we

have a problem here now in some cases you must rest and then deal with the

consequences later but in most cases there is a better approach than just

resting in that that requires a lot more taking responsibility which doctors

don't believe in your ability to take responsibility for yourself to be

intelligent and to know the amounts and the levels and that requires some some

form of a knowledge and experience and most people can't be trusted with it so we offer them you know this advice of

like just rest resting stop yeah but but definitely after years and years of working with

people and and taking them through crazy injuries near my right hand or Delia she

she went through a car accident she lost the kidney she broke her back she went through three knee surgeries which my

sister performed by the way nowadays she can move like few people I know on this

planet and and just the answer was always movement movement going back into

movement beautiful continue move continue to move yeah don't move

stupidly don't don't hurt yourself but that's an obvious no I guess not because when I say these things people write a

comment the but the bad people you know yeah but you're gonna injure yourself yeah genius

haha don't go into the injury and and

again deteriorate the escalate the situation of course not you must move

around it and you must be smart in the way that you allow adaptation to take you out like a wave you need to ride the

wave of adaptation out of the out the problem and that's tricky we know

and that's something that we need to educate people on and we need to believe in people's intelligence and ability to

take this responsibility in China where they still have in some areas and they

used to have bone setters they didn't put you in a cast you broke your hand or they they did it through bone setting

and yes they didn't have x-ray so that's a lot more complex to do and not as

successful as nowadays but having said that they did achieve amazing rates of

recovery because these reps that they use and the process allows some form of

movement and that creates an adaptation now take an arm a healthy arm your right

arm put it in a cast for six months take it down the cast what do you see the

observer the arm is basically moving towards death yes it's gotten good at not moving the arm

is great you have weird hairs growing out of it it stinks it really smells and

looks like death because movement is life no movement death we know that we like to just kill your

arm a tiny bit so that so the bones can reform together and then we'll bring it

back to life that's one approach but in other cases you can maintain the life

and the demands on the tissue safely enough at the same time allow the

recovery to happen yes and diet what are

Diet

some diet principles you follow well diet is very individual thing I've

been personally following a Paleolithic a caveman diet for a long time long

before it was called the Paleo diet and since 1997 or even 96 I've been doing

this for a long time I feel great on it still you know growing older and older

and functioning only better and being able to sustain maintain improve but that is

very very individual there is a lot of exploration to be done there what you can withstand how resilient is your

system yes nowadays there is a new movement towards not improving the fuel

sources not improving the quality and the quantities of the food but actually

making the system more resilient so it's able to basically withstand any almost

any quality and source and that's where we have been lacking and we will be

neglecting this area and that's something that and I believe is the latest innovation although it's still

highly misunderstood and a lot of a lot of folks are abusing this concept and

giving really poor advice just to be different just to say I'm not the paleo

guy you know so that's that's a small addition that will get bigger and bigger

I think so it's almost like how you recommend a movement to go outside of

quote-unquote proper alignment this is kind of the diet version of that is going outside of some kind of proper

framework of diet to some level but that's so that was an obvious thing you

know always right the problem is it's not enough because in fact it's more

what I'm suggesting with movement to go outside of the proper alignment it creates an adaptation but what if

that adaptation cannot happen for example a celiac disease person you'll

expose him to gluten and you'll have terrible consequences now maybe if you

can minimize enough the amounts and the dosages you can actually train him out

of tell yak to some level but death adaptational last very very far down the

road he's going to get some gains and then is going to plateau but what if you could take that celiac disease person

put them in the garage fix his mechanisms change his tires change his

engine you know oil him up everything and then put him back on the track as a

new animal and that that is where you know a lot of stuff is happening

nowadays so the genetic part of it and the gut biome and our digestive tract

that is is so so complex and and we discover that you know we live in

symbiosis with all these microorganisms that just are all over skin inside of us

and we live in combination with them and that's how you see some dudes in Brazil

and in Russia walking around with you know 5% body fat eating one cracker for

breakfast one cracker for dinner and you know training BJJ all day long

high-performance fueling with coca-cola and then at the same time you see people

doing everything almost perfectly and still having poor poor performance and

inability and they gain weight with any you know extra calorie or macronutrient

that they brought in because their system is different and it's not only

about genetics it's more about epigenetics and it's more about what

kind of system besides your own DNA what about these organisms that are supposed

to help us and live in symbiosis with you what kind of a system do you have there and that's just two areas and I

think it's going to get it's going to expand more and more in work and we're going to realize that there is a lot to

learn there do you think technology and science is ultimately a positive force for you know you look at movement as as

an element of our humanity do you think technology is taking humanity away or

it's adding to it I'm not smart enough to answer you that man yeah it's a big

question you know it's a I have no idea it's just it's a huge question and I think we're going to

struggle with that question for many generations to come still it definitely

created a lot of positive stuff but also brought tremendous suffering and

problems and perhaps will be the you know the end of us so technology might

have been you know the most terrible thing that ever happened to us who knows yes that beautiful no how can

people join the IDO portal movement if you have a website a hero portal calm

yeah IDO portal calm in phase B we are

on facebook you can find us on Facebook they do aim it or portal method a little

portal I do P ort al you can join the

movement culture on our website and that will lead to some updates coming up soon

you have a beautiful website by the way amazing thanks very much hey thank you very much I've been a very

fortunate to have a great team around me that helped me with that so I saw that you posted a couple of Tom

Waits songs and I even a Bukowski reference on your Facebook page and I

immediately understood something that I think only another fan or maybe I should

say student of weights and Bukowski can understand you don't shy away from the

strange and the profound wherever you can find it maybe that's how one way to put it is there a Tom Waits song that you find

yourself returning to often in your life mmm so many man so many is just that Tom

way you know I I can barely listen to anything else frankly it's been a real issue and Tom Tom Waits is his

discography it's like it it's a lifetime of discoveries I I it's been

accompanying me for years now it's not only it's not you know it's not something you go through very quickly

and I've spent a lot of time on Alice for example and

yeah just so much stuff so much that's always discover also you know I I find

this this weirdness this is eccentric part of things it's so important it's

the only thing really that can be you in many ways because as a culture

we're so blend we're becoming this one thing you know like you walk around in London it looks exactly like Hong Kong

it looks exactly like Tokyo it looks exactly like you know Sydney and we have

this like huge human thing going on which is great and we communicate very

easily but then we lost a lot on our our own stuff there is only one Tom Waits

you know because of his eccentric part because of his you know this this weird

genius and that's why it's so beautiful to me and then I try not to not to shy

away from my own eccentric side and when I was younger I I definitely hit that part more and you know you know guarded

and try to try to be to fit in but that's definitely an important thing I think so you recommend we cultivate the

weird yeah yeah cultivating the words cultivating yourself because that that's

truly you you know everybody's weird everybody there is no Homer Simpson you

know and everybody has this bar everything he'll everybody has this interesting stuff that's what also

interests me when I teach I want to see that weird you know I want to see that weird in your movement I want to see

that weird in you and that then I really met you but most people they hide it and

they don't a lie and they put this perfect picture but it well I'm not

stupid I know it's not perfect you know so just allow the weirdness to come out I think

it's a great lesson yeah from-from weights and and Bukovsky as well or so if you don't mind I'm gonna torture you

or something I would like to close by reading a Bukowski poem roll the dice

I want to force you to listen to it go ahead if you're going to try go all the way

otherwise don't even start this could mean losing girlfriends wives relative's

jobs maybe your mind it could be not eating for three or four days it could mean freezing on a park

bench it could mean jail it could mean division it could mean mockery isolation

isolation is the gift all the others are a test of your endurance of how much you

really want to do it and you'll do it despite rejection and the worst odds and it will be better than anything else you

can imagine if you're going to try go all the way there's no other feeling

like that you will be alone with the gods and the nights will flame with fire you will ride life straight to perfect

laughter it's the only good fight there is amen thanks al thanks for talking to

Daymond thank you so much man for

Summary:
The interview with Ido Portal, a prominent figure in the movement culture, offers a wealth of insights into his philosophy and approach to physical movement, teaching, and the human experience. Here are the key points from the interview:

1. **Holistic Approach to Movement**:
    
    - Ido Portal emphasizes a holistic, generalist approach to movement, transcending the confines of specialized disciplines like gymnastics, martial arts, or Olympic lifting. He believes movement is fundamental to human experience, preceding specialization.
2. **Journey to Generalism**:
    
    - Portal's journey began with early involvement in martial arts, evolving through various physical disciplines. His realization that movement is the common thread across all these led him to seek a generalist path, ultimately deciding to become a movement teacher himself.
3. **Challenges of Generalism**:
    
    - The quest to become a generalist in movement is an ongoing, perhaps impossible goal, which Portal embraces. It's a journey shared with his students, not a fixed destination or a set of absolute truths.
4. **Humanity and Specialization**:
    
    - Portal warns against the loss of humanity and fulfillment when one over-specializes. While specialization has driven technological and societal advancements, it often comes at the individual's expense, leading to a narrow, less fulfilled human experience.
5. **Movement and Community**:
    
    - Movement is not just a solitary activity but also a communal one. Portal values the communal aspect of movement seen in practices like yoga or martial arts, where people come together, forming communities and bonds.
6. **The Role of Improvisation**:
    
    - Improvisation is seen as the pinnacle of any discipline, including movement. It represents the ability to adapt, create, and live in the moment – an expression of the highest form of human ability.
7. **Approach to Coaching and Criticism**:
    
    - Portal believes in honesty and directness in coaching, distancing himself from the notion of 'tough love'. He emphasizes the importance of criticism and feedback for growth, acknowledging that not everyone is receptive to this approach.
8. **Movement and Adaptation**:
    
    - The human body is adaptable and should be exposed to a variety of movements and conditions. Over-specialization can lead to a plateau in performance. Exposure to a range of movements contributes to a broader base of skills and physical capabilities.
9. **Dealing with Injuries**:
    
    - Portal views injuries as opportunities for growth and adaptation. Rest is not always the best response to injury; instead, intelligent, adaptive movement can lead to better recovery and resilience.
10. **Diet and Individuality**:
    
    - Diet is highly individual. Portal follows a Paleolithic diet but acknowledges the need for resilience and adaptability in dietary habits. The relationship with food should be flexible and responsive to individual needs and environmental conditions.
11. **Technology and Humanity**:
    
    - Portal is cautious about the role of technology in human life, recognizing its immense benefits but also acknowledging the potential for it to lead to disconnect and even existential threats.
12. **Cultivating Individuality and Eccentricity**:
    
    - Embracing one's unique, 'weird' qualities is essential for true self-expression and fulfillment. Portal encourages embracing individual eccentricities, believing that they make us authentically human and contribute to genuine connections and learning.

The interview provides a rich tapestry of ideas on movement, teaching, human nature, and the importance of embracing a broad, adaptable, and deeply human approach to life and learning.

----------
